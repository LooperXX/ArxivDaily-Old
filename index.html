 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-19">2021-08-19</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Table Caption Generation in Scholarly Documents Leveraging Pre-trained Language Models. (arXiv:2108.08111v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Junjie H. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinden_K/0/1/0/all/0/1">Kohei Shinden</a>, <a href="http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1">Makoto P. Kato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08111">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of generating table captions for scholarly
documents, which often require additional information outside the table. To
this end, we propose a method of retrieving relevant sentences from the paper
body, and feeding the table content as well as the retrieved sentences into
pre-trained language models (e.g. T5 and GPT-2) for generating table captions.
The contributions of this paper are: (1) discussion on the challenges in table
captioning for scholarly documents; (2) development of a dataset DocBank-TB,
which is publicly available; and (3) comparison of caption generation methods
for scholarly documents with different strategies to retrieve relevant
sentences from the paper body. Our experimental results showed that T5 is the
better generation model for this task, as it outperformed GPT-2 in BLEU and
METEOR implying that the generated text are clearer and more precise. Moreover,
inputting relevant sentences matching the row header or whole table is
effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fake News and Phishing Detection Using a Machine Learning Trained Expert System. (arXiv:2108.08264v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fitzpatrick_B/0/1/0/all/0/1">Benjamin Fitzpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xinyu &quot;Sherwin&quot; Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Straub_J/0/1/0/all/0/1">Jeremy Straub</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08264">
                                    <div class="article-summary-box-inner">
                                        <span>Expert systems have been used to enable computers to make recommendations and
decisions. This paper presents the use of a machine learning trained expert
system (MLES) for phishing site detection and fake news detection. Both topics
share a similar goal: to design a rule-fact network that allows a computer to
make explainable decisions like domain experts in each respective area. The
phishing website detection study uses a MLES to detect potential phishing
websites by analyzing site properties (like URL length and expiration time).
The fake news detection study uses a MLES rule-fact network to gauge news story
truthfulness based on factors such as emotion, the speaker&#x27;s political
affiliation status, and job. The two studies use different MLES network
implementations, which are presented and compared herein. The fake news study
utilized a more linear design while the phishing project utilized a more
complex connection structure. Both networks&#x27; inputs are based on commonly
available data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeltaLM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders. (arXiv:2106.13736v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shuming Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Li Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaohan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Muzio_A/0/1/0/all/0/1">Alexandre Muzio</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_S/0/1/0/all/0/1">Saksham Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadalla_H/0/1/0/all/0/1">Hany Hassan Awadalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xia Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13736">
                                    <div class="article-summary-box-inner">
                                        <span>While pretrained encoders have achieved success in various natural language
understanding (NLU) tasks, there is a gap between these pretrained encoders and
natural language generation (NLG). NLG tasks are often based on the
encoder-decoder framework, where the pretrained encoders can only benefit part
of it. To reduce this gap, we introduce DeltaLM, a pretrained multilingual
encoder-decoder model that regards the decoder as the task layer of
off-the-shelf pretrained encoders. Specifically, we augment the pretrained
multilingual encoder with a decoder and pre-train it in a self-supervised way.
To take advantage of both the large-scale monolingual data and bilingual data,
we adopt the span corruption and translation span corruption as the
pre-training tasks. Experiments show that DeltaLM outperforms various strong
baselines on both natural language generation and translation tasks, including
machine translation, abstractive text summarization, data-to-text, and question
generation. The code and pretrained models are available at
\url{https://aka.ms/deltalm}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CUSTOM: Aspect-Oriented Product Summarization for E-Commerce. (arXiv:2108.08010v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jiahui Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Junwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Youzheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08010">
                                    <div class="article-summary-box-inner">
                                        <span>Product summarization aims to automatically generate product descriptions,
which is of great commercial potential. Considering the customer preferences on
different product aspects, it would benefit from generating aspect-oriented
customized summaries. However, conventional systems typically focus on
providing general product summaries, which may miss the opportunity to match
products with customer interests. To address the problem, we propose CUSTOM,
aspect-oriented product summarization for e-commerce, which generates diverse
and controllable summaries towards different product aspects. To support the
study of CUSTOM and further this line of research, we construct two Chinese
datasets, i.e., SMARTPHONE and COMPUTER, including 76,279 / 49,280 short
summaries for 12,118 / 11,497 real-world commercial products, respectively.
Furthermore, we introduce EXT, an extraction-enhanced generation framework for
CUSTOM, where two famous sequence-to-sequence models are implemented in this
paper. We conduct extensive experiments on the two proposed datasets for CUSTOM
and show results of two famous baseline models and EXT, which indicates that
EXT can generate diverse, high-quality, and consistent summaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniT: Multimodal Multitask Learning with a Unified Transformer. (arXiv:2102.10772v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Ronghang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amanpreet Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10772">
                                    <div class="article-summary-box-inner">
                                        <span>We propose UniT, a Unified Transformer model to simultaneously learn the most
prominent tasks across different domains, ranging from object detection to
natural language understanding and multimodal reasoning. Based on the
transformer encoder-decoder architecture, our UniT model encodes each input
modality with an encoder and makes predictions on each task with a shared
decoder over the encoded input representations, followed by task-specific
output heads. The entire model is jointly trained end-to-end with losses from
each task. Compared to previous efforts on multi-task learning with
transformers, we share the same model parameters across all tasks instead of
separately fine-tuning task-specific models and handle a much higher variety of
tasks across different domains. In our experiments, we learn 7 tasks jointly
over 8 datasets, achieving strong performance on each task with significantly
fewer parameters. Our code is available in MMF at https://mmf.sh.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdapterHub Playground: Simple and Flexible Few-Shot Learning with Adapters. (arXiv:2108.08103v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1">Tilman Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohlender_B/0/1/0/all/0/1">Bela Bohlender</a>, <a href="http://arxiv.org/find/cs/1/au:+Viehmann_C/0/1/0/all/0/1">Christina Viehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Hane_V/0/1/0/all/0/1">Vincent Hane</a>, <a href="http://arxiv.org/find/cs/1/au:+Adamson_Y/0/1/0/all/0/1">Yanik Adamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Khuri_J/0/1/0/all/0/1">Jaber Khuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Brossmann_J/0/1/0/all/0/1">Jonas Brossmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1">Jonas Pfeiffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08103">
                                    <div class="article-summary-box-inner">
                                        <span>The open-access dissemination of pretrained language models through online
repositories has led to a democratization of state-of-the-art natural language
processing (NLP) research. This also allows people outside of NLP to use such
models and adapt them to specific use-cases. However, a certain amount of
technical proficiency is still required which is an entry barrier for users who
want to apply these models to a certain task but lack the necessary knowledge
or resources. In this work, we aim to overcome this gap by providing a tool
which allows researchers to leverage pretrained models without writing a single
line of code. Built upon the parameter-efficient adapter modules for transfer
learning, our AdapterHub Playground provides an intuitive interface, allowing
the usage of adapters for prediction, training and analysis of textual data for
a variety of NLP tasks. We present the tool&#x27;s architecture and demonstrate its
advantages with prototypical use-cases, where we show that predictive
performance can easily be increased in a few-shot learning scenario. Finally,
we evaluate its usability in a user study. We provide the code and a live
interface at https://adapter-hub.github.io/playground.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks. (arXiv:2105.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kayser_M/0/1/0/all/0/1">Maxime Kayser</a>, <a href="http://arxiv.org/find/cs/1/au:+Camburu_O/0/1/0/all/0/1">Oana-Maria Camburu</a>, <a href="http://arxiv.org/find/cs/1/au:+Salewski_L/0/1/0/all/0/1">Leonard Salewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Emde_C/0/1/0/all/0/1">Cornelius Emde</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Virginie Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing number of efforts to introduce models
capable of generating natural language explanations (NLEs) for their
predictions on vision-language (VL) tasks. Such models are appealing, because
they can provide human-friendly and comprehensive explanations. However, there
is a lack of comparison between existing methods, which is due to a lack of
re-usable evaluation frameworks and a scarcity of datasets. In this work, we
introduce e-ViL and e-SNLI-VE. e-ViL is a benchmark for explainable
vision-language tasks that establishes a unified evaluation framework and
provides the first comprehensive comparison of existing approaches that
generate NLEs for VL tasks. It spans four models and three datasets and both
automatic metrics and human evaluation are used to assess model-generated
explanations. e-SNLI-VE is currently the largest existing VL dataset with NLEs
(over 430k instances). We also propose a new model that combines UNITER, which
learns joint embeddings of images and text, and GPT-2, a pre-trained language
model that is well-suited for text generation. It surpasses the previous state
of the art by a large margin across all datasets. Code and data are available
here: https://github.com/maximek3/e-ViL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affective Decoding for Empathetic Response Generation. (arXiv:2108.08102v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chengkun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chenghua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruizhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhigang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08102">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding speaker&#x27;s feelings and producing appropriate responses with
emotion connection is a key communicative skill for empathetic dialogue
systems. In this paper, we propose a simple technique called Affective Decoding
for empathetic response generation. Our method can effectively incorporate
emotion signals during each decoding step, and can additionally be augmented
with an auxiliary dual emotion encoder, which learns separate embeddings for
the speaker and listener given the emotion base of the dialogue. Extensive
empirical studies show that our models are perceived to be more empathetic by
human evaluations, in comparison to several strong mainstream methods for
empathetic responding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Do Your Biomedical Named Entity Models Generalize to Novel Entities?. (arXiv:2101.00160v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunjae Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jaewoo Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00160">
                                    <div class="article-summary-box-inner">
                                        <span>The number of biomedical literature on new biomedical concepts is rapidly
increasing, which necessitates a reliable biomedical named entity recognition
(BioNER) model for identifying new and unseen entity mentions. However, it is
questionable whether existing BioNER models can effectively handle them. In
this work, we systematically analyze the three types of recognition abilities
of BioNER models: memorization, synonym generalization, and concept
generalization. We find that although BioNER models achieve state-of-the-art
performance on BioNER benchmarks based on overall performance, they have
limitations in identifying synonyms and new biomedical concepts such as
COVID-19. From this observation, we conclude that existing BioNER models are
overestimated in terms of their generalization abilities. Also, we identify
several difficulties in recognizing unseen mentions in BioNER and make the
following conclusions: (1) BioNER models tend to exploit dataset biases, which
hinders the models&#x27; abilities to generalize, and (2) several biomedical names
have novel morphological patterns with little name regularity such as COVID-19,
and models fail to recognize them. We apply a current statistics-based
debiasing method to our problem as a simple remedy and show the improvement in
generalization to unseen mentions. We hope that our analyses and findings would
be able to facilitate further research into the generalization capabilities of
NER models in a domain where their reliability is of utmost importance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">De-identification of Unstructured Clinical Texts from Sequence to Sequence Perspective. (arXiv:2108.07971v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anjum_M/0/1/0/all/0/1">Md Monowar Anjum</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammed_N/0/1/0/all/0/1">Noman Mohammed</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07971">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a novel problem formulation for de-identification of
unstructured clinical text. We formulate the de-identification problem as a
sequence to sequence learning problem instead of a token classification
problem. Our approach is inspired by the recent state-of -the-art performance
of sequence to sequence learning models for named entity recognition. Early
experimentation of our proposed approach achieved 98.91% recall rate on i2b2
dataset. This performance is comparable to current state-of-the-art models for
unstructured clinical text de-identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning. (arXiv:2108.05067v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yinghong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fuyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaolin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuixing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05067">
                                    <div class="article-summary-box-inner">
                                        <span>Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EviDR: Evidence-Emphasized Discrete Reasoning for Reasoning Machine Reading Comprehension. (arXiv:2108.07994v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yongwei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Junwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haipeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jiahui Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Youzheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tiejun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07994">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning machine reading comprehension (R-MRC) aims to answer complex
questions that require discrete reasoning based on text. To support discrete
reasoning, evidence, typically the concise textual fragments that describe
question-related facts, including topic entities and attribute values, are
crucial clues from question to answer. However, previous end-to-end methods
that achieve state-of-the-art performance rarely solve the problem by paying
enough emphasis on the modeling of evidence, missing the opportunity to further
improve the model&#x27;s reasoning ability for R-MRC. To alleviate the above issue,
in this paper, we propose an evidence-emphasized discrete reasoning approach
(EviDR), in which sentence and clause level evidence is first detected based on
distant supervision, and then used to drive a reasoning module implemented with
a relational heterogeneous graph convolutional network to derive answers.
Extensive experiments are conducted on DROP (discrete reasoning over
paragraphs) dataset, and the results demonstrate the effectiveness of our
proposed approach. In addition, qualitative analysis verifies the capability of
the proposed evidence-emphasized discrete reasoning for R-MRC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GGP: A Graph-based Grouping Planner for Explicit Control of Long Text Generation. (arXiv:2108.07998v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuming Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shaobo Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhongzhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haiqing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07998">
                                    <div class="article-summary-box-inner">
                                        <span>Existing data-driven methods can well handle short text generation. However,
when applied to the long-text generation scenarios such as story generation or
advertising text generation in the commercial scenario, these methods may
generate illogical and uncontrollable texts. To address these aforementioned
issues, we propose a graph-based grouping planner(GGP) following the idea of
first-plan-then-generate. Specifically, given a collection of key phrases, GGP
firstly encodes these phrases into an instance-level sequential representation
and a corpus-level graph-based representation separately. With these two
synergic representations, we then regroup these phrases into a fine-grained
plan, based on which we generate the final long text. We conduct our
experiments on three long text generation datasets and the experimental results
reveal that GGP significantly outperforms baselines, which proves that GGP can
control the long text generation by knowing how to say and in what order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparative study of universal quantum computing models: towards a physical unification. (arXiv:2108.07909v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_D/0/1/0/all/0/1">D.-S. Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07909">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum computing has been a fascinating research field in quantum physics.
Recent progresses motivate us to study in depth the universal quantum computing
models (UQCM), which lie at the foundation of quantum computing and have tight
connections with fundamental physics. Although being developed decades ago, a
physically concise principle or picture to formalize and understand UQCM is
still lacking. This is challenging given the diversity of still-emerging
models, but important to understand the difference between classical and
quantum computing. In this work, we carried out a primary attempt to unify UQCM
by classifying a few of them as two categories, hence making a table of models.
With such a table, some known models or schemes appear as hybridization or
combination of models, and more importantly, it leads to new schemes that have
not been explored yet. Our study of UQCM also leads to some insights into
quantum algorithms. This work reveals the importance and feasibility of
systematic study of computing models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforced Generative Adversarial Network for Abstractive Text Summarization. (arXiv:2105.15176v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chunyun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15176">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-sequence models provide a viable new approach to generative
summarization, allowing models that are no longer limited to simply selecting
and recombining sentences from the original text. However, these models have
three drawbacks: their grasp of the details of the original text is often
inaccurate, and the text generated by such models often has repetitions, while
it is difficult to handle words that are beyond the word list. In this paper,
we propose a new architecture that combines reinforcement learning and
adversarial generative networks to enhance the sequence-to-sequence attention
model. First, we use a hybrid pointer-generator network that copies words
directly from the source text, contributing to accurate reproduction of
information without sacrificing the ability of generators to generate new
words. Second, we use both intra-temporal and intra-decoder attention to
penalize summarized content and thus discourage repetition. We apply our model
to our own proposed COVID-19 paper title summarization task and achieve close
approximations to the current model on ROUEG, while bringing better
readability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSI: an Ad Text Strength Indicator using Text-to-CTR and Semantic-Ad-Similarity. (arXiv:2108.08226v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Shaunak Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Changwei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_M/0/1/0/all/0/1">Manisha Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_K/0/1/0/all/0/1">Kevin Yen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yifan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sviridenko_M/0/1/0/all/0/1">Maxim Sviridenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08226">
                                    <div class="article-summary-box-inner">
                                        <span>Coming up with effective ad text is a time consuming process, and
particularly challenging for small businesses with limited advertising
experience. When an inexperienced advertiser onboards with a poorly written ad
text, the ad platform has the opportunity to detect low performing ad text, and
provide improvement suggestions. To realize this opportunity, we propose an ad
text strength indicator (TSI) which: (i) predicts the click-through-rate (CTR)
for an input ad text, (ii) fetches similar existing ads to create a
neighborhood around the input ad, (iii) and compares the predicted CTRs in the
neighborhood to declare whether the input ad is strong or weak. In addition, as
suggestions for ad text improvement, TSI shows anonymized versions of superior
ads (higher predicted CTR) in the neighborhood. For (i), we propose a BERT
based text-to-CTR model trained on impressions and clicks associated with an ad
text. For (ii), we propose a sentence-BERT based semantic-ad-similarity model
trained using weak labels from ad campaign setup data. Offline experiments
demonstrate that our BERT based text-to-CTR model achieves a significant lift
in CTR prediction AUC for cold start (new) advertisers compared to bag-of-words
based baselines. In addition, our semantic-textual-similarity model for similar
ads retrieval achieves a precision@1 of 0.93 (for retrieving ads from the same
product category); this is significantly higher compared to unsupervised
TF-IDF, word2vec, and sentence-BERT baselines. Finally, we share promising
online results from advertisers in the Yahoo (Verizon Media) ad platform where
a variant of TSI was implemented with sub-second end-to-end latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Natural Language Processing for LinkedIn Search Systems. (arXiv:2108.08252v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Weiwei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sida Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazi_M/0/1/0/all/0/1">Michaeel Kazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhoutong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Huiji Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jun Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08252">
                                    <div class="article-summary-box-inner">
                                        <span>Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles and documents, where deep learning based natural
language processing techniques (deep NLP) can be of great help. In this paper,
we introduce a comprehensive study of applying deep NLP techniques to five
representative tasks in search engines. Through the model design and
experiments of the five tasks, readers can find answers to three important
questions: (1) When is deep NLP helpful/not helpful in search systems? (2) How
to address latency challenges? (3) How to ensure model robustness? This work
builds on existing efforts of LinkedIn search, and is tested at scale on a
commercial search engine. We believe our experiences can provide useful
insights for the industry and research communities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHAQ: Single Headed Attention with Quasi-Recurrence. (arXiv:2108.08207v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bharwani_N/0/1/0/all/0/1">Nashwin Bharwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kushner_W/0/1/0/all/0/1">Warren Kushner</a>, <a href="http://arxiv.org/find/cs/1/au:+Dandona_S/0/1/0/all/0/1">Sangeet Dandona</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreiber_B/0/1/0/all/0/1">Ben Schreiber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08207">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing research has recently been dominated by large
scale transformer models. Although they achieve state of the art on many
important language tasks, transformers often require expensive compute
resources, and days spanning to weeks to train. This is feasible for
researchers at big tech companies and leading research universities, but not
for scrappy start-up founders, students, and independent researchers. Stephen
Merity&#x27;s SHA-RNN, a compact, hybrid attention-RNN model, is designed for
consumer-grade modeling as it requires significantly fewer parameters and less
training time to reach near state of the art results. We analyze Merity&#x27;s model
here through an exploratory model analysis over several units of the
architecture considering both training time and overall quality in our
assessment. Ultimately, we combine these findings into a new architecture which
we call SHAQ: Single Headed Attention Quasi-recurrent Neural Network. With our
new architecture we achieved similar accuracy results as the SHA-RNN while
accomplishing a 4x speed boost in training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modulating Language Models with Emotions. (arXiv:2108.07886v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruibo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chenyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1">Soroush Vosoughi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07886">
                                    <div class="article-summary-box-inner">
                                        <span>Generating context-aware language that embodies diverse emotions is an
important step towards building empathetic NLP systems. In this paper, we
propose a formulation of modulated layer normalization -- a technique inspired
by computer vision -- that allows us to use large-scale language models for
emotional response generation. In automatic and human evaluation on the
MojiTalk dataset, our proposed modulated layer normalization method outperforms
prior baseline methods while maintaining diversity, fluency, and coherence. Our
method also obtains competitive performance even when using only 10% of the
available training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MeDiaQA: A Question Answering Dataset on Medical Dialogues. (arXiv:2108.08074v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suri_H/0/1/0/all/0/1">Huqun Suri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_W/0/1/0/all/0/1">Wenhua Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Chunsheng Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08074">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce MeDiaQA, a novel question answering(QA) dataset,
which constructed on real online Medical Dialogues. It contains 22k
multiple-choice questions annotated by human for over 11k dialogues with 120k
utterances between patients and doctors, covering 150 specialties of diseases,
which are collected from haodf.com and dxy.com. MeDiaQA is the first QA dataset
where reasoning over medical dialogues, especially their quantitative contents.
The dataset has the potential to test the computing, reasoning and
understanding ability of models across multi-turn dialogues, which is
challenging compared with the existing datasets. To address the challenges, we
design MeDia-BERT, and it achieves 64.3% accuracy, while human performance of
93% accuracy, which indicates that there still remains a large room for
improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Multiple Intent Detection and Slot Filling via Self-distillation. (arXiv:2108.08042v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lisong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Peilin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08042">
                                    <div class="article-summary-box-inner">
                                        <span>Intent detection and slot filling are two main tasks in natural language
understanding (NLU) for identifying users&#x27; needs from their utterances. These
two tasks are highly related and often trained jointly. However, most previous
works assume that each utterance only corresponds to one intent, ignoring the
fact that a user utterance in many cases could include multiple intents. In
this paper, we propose a novel Self-Distillation Joint NLU model (SDJN) for
multi-intent NLU. First, we formulate multiple intent detection as a weakly
supervised problem and approach with multiple instance learning (MIL). Then, we
design an auxiliary loop via self-distillation with three orderly arranged
decoders: Initial Slot Decoder, MIL Intent Decoder, and Final Slot Decoder. The
output of each decoder will serve as auxiliary information for the next
decoder. With the auxiliary knowledge provided by the MIL Intent Decoder, we
set Final Slot Decoder as the teacher model that imparts knowledge back to
Initial Slot Decoder to complete the loop. The auxiliary loop enables intents
and slots to guide mutually in-depth and further boost the overall NLU
performance. Experimental results on two public multi-intent datasets indicate
that our model achieves strong performance compared to others.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RTE: A Tool for Annotating Relation Triplets from Text. (arXiv:2108.08184v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mullick_A/0/1/0/all/0/1">Ankan Mullick</a>, <a href="http://arxiv.org/find/cs/1/au:+Bera_A/0/1/0/all/0/1">Animesh Bera</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_T/0/1/0/all/0/1">Tapas Nayak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08184">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present a Web-based annotation tool &#x60;Relation Triplets
Extractor&#x27; \footnote{https://abera87.github.io/annotate/} (RTE) for annotating
relation triplets from the text. Relation extraction is an important task for
extracting structured information about real-world entities from the
unstructured text available on the Web. In relation extraction, we focus on
binary relation that refers to relations between two entities. Recently, many
supervised models are proposed to solve this task, but they mostly use noisy
training data obtained using the distant supervision method. In many cases,
evaluation of the models is also done based on a noisy test dataset. The lack
of annotated clean dataset is a key challenge in this area of research. In this
work, we built a web-based tool where researchers can annotate datasets for
relation extraction on their own very easily. We use a server-less architecture
for this tool, and the entire annotation operation is processed using
client-side code. Thus it does not suffer from any network latency, and the
privacy of the user&#x27;s data is also maintained. We hope that this tool will be
beneficial for the researchers to advance the field of relation extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics. (arXiv:2108.08217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yehao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yingwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Ting Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08217">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise and development of deep learning over the past decade, there
has been a steady momentum of innovation and breakthroughs that convincingly
push the state-of-the-art of cross-modal analytics between vision and language
in multimedia field. Nevertheless, there has not been an open-source codebase
in support of training and deploying numerous neural network models for
cross-modal analytics in a unified and modular fashion. In this work, we
propose X-modaler -- a versatile and high-performance codebase that
encapsulates the state-of-the-art cross-modal analytics into several
general-purpose stages (e.g., pre-processing, encoder, cross-modal interaction,
decoder, and decode strategy). Each stage is empowered with the functionality
that covers a series of modules widely adopted in state-of-the-arts and allows
seamless switching in between. This way naturally enables a flexible
implementation of state-of-the-art algorithms for image captioning, video
captioning, and vision-language pre-training, aiming to facilitate the rapid
development of research community. Meanwhile, since the effective modular
designs in several stages (e.g., cross-modal interaction) are shared across
different vision-language tasks, X-modaler can be simply extended to power
startup prototypes for other tasks in cross-modal analytics, including visual
question answering, visual commonsense reasoning, and cross-modal retrieval.
X-modaler is an Apache-licensed codebase, and its source codes, sample projects
and pre-trained models are available on-line:
https://github.com/YehLi/xmodaler.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Implicit User Profiles for Personalized Retrieval-Based Chatbot. (arXiv:2108.07935v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">Hongjin Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhicheng Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yutao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yueyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07935">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the problem of developing personalized chatbots. A
personalized chatbot is designed as a digital chatting assistant for a user.
The key characteristic of a personalized chatbot is that it should have a
consistent personality with the corresponding user. It can talk the same way as
the user when it is delegated to respond to others&#x27; messages. We present a
retrieval-based personalized chatbot model, namely IMPChat, to learn an
implicit user profile from the user&#x27;s dialogue history. We argue that the
implicit user profile is superior to the explicit user profile regarding
accessibility and flexibility. IMPChat aims to learn an implicit user profile
through modeling user&#x27;s personalized language style and personalized
preferences separately. To learn a user&#x27;s personalized language style, we
elaborately build language models from shallow to deep using the user&#x27;s
historical responses; To model a user&#x27;s personalized preferences, we explore
the conditional relations underneath each post-response pair of the user. The
personalized preferences are dynamic and context-aware: we assign higher
weights to those historical pairs that are topically related to the current
query when aggregating the personalized preferences. We match each response
candidate with the personalized language style and personalized preference,
respectively, and fuse the two matching signals to determine the final ranking
score. Comprehensive experiments on two large datasets show that our method
outperforms all baseline models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021): Workshop and Shared Task Report. (arXiv:2108.07865v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hurriyetoglu_A/0/1/0/all/0/1">Ali H&#xfc;rriyeto&#x11f;lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanev_H/0/1/0/all/0/1">Hristo Tanev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zavarella_V/0/1/0/all/0/1">Vanni Zavarella</a>, <a href="http://arxiv.org/find/cs/1/au:+Piskorski_J/0/1/0/all/0/1">Jakub Piskorski</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeniterzi_R/0/1/0/all/0/1">Reyyan Yeniterzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoruk_E/0/1/0/all/0/1">Erdem Y&#xf6;r&#xfc;k</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07865">
                                    <div class="article-summary-box-inner">
                                        <span>This workshop is the fourth issue of a series of workshops on automatic
extraction of socio-political events from news, organized by the Emerging
Market Welfare Project, with the support of the Joint Research Centre of the
European Commission and with contributions from many other prominent scholars
in this field. The purpose of this series of workshops is to foster research
and development of reliable, valid, robust, and practical solutions for
automatically detecting descriptions of socio-political events, such as
protests, riots, wars and armed conflicts, in text streams. This year workshop
contributors make use of the state-of-the-art NLP technologies, such as Deep
Learning, Word Embeddings and Transformers and cover a wide range of topics
from text classification to news bias detection. Around 40 teams have
registered and 15 teams contributed to three tasks that are i) multilingual
protest news detection, ii) fine-grained classification of socio-political
events, and iii) discovering Black Lives Matter protest events. The workshop
also highlights two keynote and four invited talks about various aspects of
creating event data sets and multi- and cross-lingual machine learning in few-
and zero-shot settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextualizing Variation in Text Style Transfer Datasets. (arXiv:2108.07871v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schoch_S/0/1/0/all/0/1">Stephanie Schoch</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1">Wanyu Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yangfeng Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07871">
                                    <div class="article-summary-box-inner">
                                        <span>Text style transfer involves rewriting the content of a source sentence in a
target style. Despite there being a number of style tasks with available data,
there has been limited systematic discussion of how text style datasets relate
to each other. This understanding, however, is likely to have implications for
selecting multiple data sources for model training. While it is prudent to
consider inherent stylistic properties when determining these relationships, we
also must consider how a style is realized in a particular dataset. In this
paper, we conduct several empirical analyses of existing text style datasets.
Based on our results, we propose a categorization of stylistic and dataset
properties to consider when utilizing or comparing text style datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Higher-Order Concurrency for Microcontrollers. (arXiv:2108.07805v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Abhiroop Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Krook_R/0/1/0/all/0/1">Robert Krook</a>, <a href="http://arxiv.org/find/cs/1/au:+Svensson_B/0/1/0/all/0/1">Bo Joel Svensson</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheeran_M/0/1/0/all/0/1">Mary Sheeran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07805">
                                    <div class="article-summary-box-inner">
                                        <span>Programming microcontrollers involves low-level interfacing with hardware and
peripherals that are concurrent and reactive. Such programs are typically
written in a mixture of C and assembly using concurrent language extensions
(like $\texttt{FreeRTOS tasks}$ and $\texttt{semaphores}$), resulting in
unsafe, callback-driven, error-prone and difficult-to-maintain code.

We address this challenge by introducing $\texttt{SenseVM}$ - a
bytecode-interpreted virtual machine that provides a message-passing based
$\textit{higher-order concurrency}$ model, originally introduced by Reppy, for
microcontroller programming. This model treats synchronous operations as
first-class values (called $\texttt{Events}$) akin to the treatment of
first-class functions in functional languages. This primarily allows the
programmer to compose and tailor their own concurrency abstractions and,
additionally, abstracts away unsafe memory operations, common in shared-memory
concurrency models, thereby making microcontroller programs safer, composable
and easier-to-maintain.

Our VM is made portable via a low-level $\textit{bridge}$ interface, built
atop the embedded OS - Zephyr. The bridge is implemented by all drivers and
designed such that programming in response to a software message or a hardware
interrupt remains uniform and indistinguishable. In this paper we demonstrate
the features of our VM through an example, written in a Caml-like functional
language, running on the $\texttt{nRF52840}$ and $\texttt{STM32F4}$
microcontrollers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teachers Do More Than Teach: Compressing Image-to-Image Models. (arXiv:2103.03467v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodford_O/0/1/0/all/0/1">Oliver J. Woodford</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiazhuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1">Sergey Tulyakov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03467">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have achieved huge success in
generating high-fidelity images, however, they suffer from low efficiency due
to tremendous computational cost and bulky memory usage. Recent efforts on
compression GANs show noticeable progress in obtaining smaller generators by
sacrificing image quality or involving a time-consuming searching process. In
this work, we aim to address these issues by introducing a teacher network that
provides a search space in which efficient network architectures can be found,
in addition to performing knowledge distillation. First, we revisit the search
space of generative models, introducing an inception-based residual block into
generators. Second, to achieve target computation cost, we propose a one-step
pruning algorithm that searches a student architecture from the teacher model
and substantially reduces searching cost. It requires no l1 sparsity
regularization and its associated hyper-parameters, simplifying the training
procedure. Finally, we propose to distill knowledge through maximizing feature
similarity between teacher and student via an index named Global Kernel
Alignment (GKA). Our compressed networks achieve similar or even better image
fidelity (FID, mIoU) than the original models with much-reduced computational
cost, e.g., MACs. Code will be released at
https://github.com/snap-research/CAT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks. (arXiv:2105.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kayser_M/0/1/0/all/0/1">Maxime Kayser</a>, <a href="http://arxiv.org/find/cs/1/au:+Camburu_O/0/1/0/all/0/1">Oana-Maria Camburu</a>, <a href="http://arxiv.org/find/cs/1/au:+Salewski_L/0/1/0/all/0/1">Leonard Salewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Emde_C/0/1/0/all/0/1">Cornelius Emde</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Virginie Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing number of efforts to introduce models
capable of generating natural language explanations (NLEs) for their
predictions on vision-language (VL) tasks. Such models are appealing, because
they can provide human-friendly and comprehensive explanations. However, there
is a lack of comparison between existing methods, which is due to a lack of
re-usable evaluation frameworks and a scarcity of datasets. In this work, we
introduce e-ViL and e-SNLI-VE. e-ViL is a benchmark for explainable
vision-language tasks that establishes a unified evaluation framework and
provides the first comprehensive comparison of existing approaches that
generate NLEs for VL tasks. It spans four models and three datasets and both
automatic metrics and human evaluation are used to assess model-generated
explanations. e-SNLI-VE is currently the largest existing VL dataset with NLEs
(over 430k instances). We also propose a new model that combines UNITER, which
learns joint embeddings of images and text, and GPT-2, a pre-trained language
model that is well-suited for text generation. It surpasses the previous state
of the art by a large margin across all datasets. Code and data are available
here: https://github.com/maximek3/e-ViL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self Context and Shape Prior for Sensorless Freehand 3D Ultrasound Reconstruction. (arXiv:2108.00274v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Mingyuan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaoqiong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuhao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuxin Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xindi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_N/0/1/0/all/0/1">Nishant Ravikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F Frangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1">Dong Ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00274">
                                    <div class="article-summary-box-inner">
                                        <span>3D ultrasound (US) is widely used for its rich diagnostic information.
However, it is criticized for its limited field of view. 3D freehand US
reconstruction is promising in addressing the problem by providing broad range
and freeform scan. The existing deep learning based methods only focus on the
basic cases of skill sequences, and the model relies on the training data
heavily. The sequences in real clinical practice are a mix of diverse skills
and have complex scanning paths. Besides, deep models should adapt themselves
to the testing cases with prior knowledge for better robustness, rather than
only fit to the training cases. In this paper, we propose a novel approach to
sensorless freehand 3D US reconstruction considering the complex skill
sequences. Our contribution is three-fold. First, we advance a novel online
learning framework by designing a differentiable reconstruction algorithm. It
realizes an end-to-end optimization from section sequences to the reconstructed
volume. Second, a self-supervised learning method is developed to explore the
context information that reconstructed by the testing data itself, promoting
the perception of the model. Third, inspired by the effectiveness of shape
prior, we also introduce adversarial training to strengthen the learning of
anatomical shape prior in the reconstructed volume. By mining the context and
structural cues of the testing data, our online learning methods can drive the
model to handle complex skill sequences. Experimental results on developmental
dysplasia of the hip US and fetal US datasets show that, our proposed method
can outperform the start-of-the-art methods regarding the shift errors and path
similarities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HuMoR: 3D Human Motion Model for Robust Pose Estimation. (arXiv:2105.04668v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rempe_D/0/1/0/all/0/1">Davis Rempe</a>, <a href="http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1">Tolga Birdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertzmann_A/0/1/0/all/0/1">Aaron Hertzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jimei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_S/0/1/0/all/0/1">Srinath Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas J. Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04668">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce HuMoR: a 3D Human Motion Model for Robust Estimation of temporal
pose and shape. Though substantial progress has been made in estimating 3D
human motion and shape from dynamic observations, recovering plausible pose
sequences in the presence of noise and occlusions remains a challenge. For this
purpose, we propose an expressive generative model in the form of a conditional
variational autoencoder, which learns a distribution of the change in pose at
each step of a motion sequence. Furthermore, we introduce a flexible
optimization-based approach that leverages HuMoR as a motion prior to robustly
estimate plausible pose and shape from ambiguous observations. Through
extensive evaluations, we demonstrate that our model generalizes to diverse
motions and body shapes after training on a large motion capture dataset, and
enables motion reconstruction from multiple input modalities including 3D
keypoints and RGB(-D) videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M6-UFC: Unifying Multi-Modal Controls for Conditional Image Synthesis. (arXiv:2105.14211v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianxin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhikang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Ming Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14211">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional image synthesis aims to create an image according to some
multi-modal guidance in the forms of textual descriptions, reference images,
and image blocks to preserve, as well as their combinations. In this paper,
instead of investigating these control signals separately, we propose a new
two-stage architecture, UFC-BERT, to unify any number of multi-modal controls.
In UFC-BERT, both the diverse control signals and the synthesized image are
uniformly represented as a sequence of discrete tokens to be processed by
Transformer. Different from existing two-stage autoregressive approaches such
as DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the
second stage to enhance the holistic consistency of the synthesized image, to
support preserving specified image blocks, and to improve the synthesis speed.
Further, we design a progressive algorithm that iteratively improves the
non-autoregressively generated image, with the help of two estimators developed
for evaluating the compliance with the controls and evaluating the fidelity of
the synthesized image, respectively. Extensive experiments on a newly collected
large-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal
CelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply
with flexible multi-modal controls.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning. (arXiv:2108.05067v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yinghong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fuyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaolin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuixing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05067">
                                    <div class="article-summary-box-inner">
                                        <span>Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICE: Inter-instance Contrastive Encoding for Unsupervised Person Re-identification. (arXiv:2103.16364v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagadec_B/0/1/0/all/0/1">Benoit Lagadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Bremond_F/0/1/0/all/0/1">Francois Bremond</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16364">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised person re-identification (ReID) aims at learning discriminative
identity features without annotations. Recently, self-supervised contrastive
learning has gained increasing attention for its effectiveness in unsupervised
representation learning. The main idea of instance contrastive learning is to
match a same instance in different augmented views. However, the relationship
between different instances has not been fully explored in previous contrastive
methods, especially for instance-level contrastive loss. To address this issue,
we propose Inter-instance Contrastive Encoding (ICE) that leverages
inter-instance pairwise similarity scores to boost previous class-level
contrastive ReID methods. We first use pairwise similarity ranking as one-hot
hard pseudo labels for hard instance contrast, which aims at reducing
intra-class variance. Then, we use similarity scores as soft pseudo labels to
enhance the consistency between augmented and original views, which makes our
model more robust to augmentation perturbations. Experiments on several
large-scale person ReID datasets validate the effectiveness of our proposed
unsupervised method ICE, which is competitive with even supervised methods.
Code is made available at https://github.com/chenhao2345/ICE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TeliNet: Classifying CT scan images for COVID-19 diagnosis. (arXiv:2107.04930v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Teli_M/0/1/0/all/0/1">Mohammad Nayeem Teli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04930">
                                    <div class="article-summary-box-inner">
                                        <span>COVID-19 has led to hundreds of millions of cases and millions of deaths
worldwide since its onset. The fight against this pandemic is on-going on
multiple fronts. While vaccinations are picking up speed, there are still
billions of unvaccinated people. In this fight against the virus, diagnosis of
the disease and isolation of the patients to prevent any spread play a huge
role. Machine Learning approaches have assisted in the diagnosis of COVID-19
cases by analyzing chest X-rays and CT-scan images of patients. To push
algorithm development and research in this direction of radiological diagnosis,
a challenge to classify CT-scan series was organized in conjunction with ICCV,
2021. In this research we present a simple and shallow Convolutional Neural
Network based approach, TeliNet, to classify these CT-scan images of COVID-19
patients presented as part of this competition. Our results outperform the F1
&#x60;macro&#x27; score of the competition benchmark and VGGNet approaches. Our proposed
solution is also more lightweight in comparison to the other methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">F-Drop&amp;Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02343">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks built from deep convolutional neural networks
(GANs) lack the ability to exactly replicate the high-frequency components of
natural images. To alleviate this issue, we introduce two novel training
techniques called frequency dropping (F-Drop) and frequency matching (F-Match).
The key idea of F-Drop is to filter out unnecessary high-frequency components
from the input images of the discriminators. This simple modification prevents
the discriminators from being confused by perturbations of the high-frequency
components. In addition, F-Drop makes the GANs focus on fitting in the
low-frequency domain, in which there are the dominant components of natural
images. F-Match minimizes the difference between real and fake images in the
frequency domain for generating more realistic images. F-Match is implemented
as a regularization term in the objective functions of the generators; it
penalizes the batch mean error in the frequency domain. F-Match helps the
generators to fit in the high-frequency domain filtered out by F-Drop to the
real image. We experimentally demonstrate that the combination of F-Drop and
F-Match improves the generative performance of GANs in both the frequency and
spatial domain on multiple image benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification and reconstruction of spatially overlapping phase images using diffractive optical networks. (arXiv:2108.07977v1 [physics.optics])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Mengu_D/0/1/0/all/0/1">Deniz Mengu</a>, <a href="http://arxiv.org/find/physics/1/au:+Veli_M/0/1/0/all/0/1">Muhammed Veli</a>, <a href="http://arxiv.org/find/physics/1/au:+Rivenson_Y/0/1/0/all/0/1">Yair Rivenson</a>, <a href="http://arxiv.org/find/physics/1/au:+Ozcan_A/0/1/0/all/0/1">Aydogan Ozcan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07977">
                                    <div class="article-summary-box-inner">
                                        <span>Diffractive optical networks unify wave optics and deep learning to
all-optically compute a given machine learning or computational imaging task as
the light propagates from the input to the output plane. Here, we report the
design of diffractive optical networks for the classification and
reconstruction of spatially overlapping, phase-encoded objects. When two
different phase-only objects spatially overlap, the individual object functions
are perturbed since their phase patterns are summed up. The retrieval of the
underlying phase images from solely the overlapping phase distribution presents
a challenging problem, the solution of which is generally not unique. We show
that through a task-specific training process, passive diffractive networks
composed of successive transmissive layers can all-optically and simultaneously
classify two different randomly-selected, spatially overlapping phase images at
the input. After trained with ~550 million unique combinations of phase-encoded
handwritten digits from the MNIST dataset, our blind testing results reveal
that the diffractive network achieves an accuracy of &gt;85.8% for all-optical
classification of two overlapping phase images of new handwritten digits. In
addition to all-optical classification of overlapping phase objects, we also
demonstrate the reconstruction of these phase images based on a shallow
electronic neural network that uses the highly compressed output of the
diffractive network as its input (with e.g., ~20-65 times less number of
pixels) to rapidly reconstruct both of the phase images, despite their spatial
overlap and related phase ambiguity. The presented phase image classification
and reconstruction framework might find applications in e.g., computational
imaging, microscopy and quantitative phase imaging fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Urban Driving by Imitating a Reinforcement Learning Coach. (arXiv:2108.08265v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhejun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liniger_A/0/1/0/all/0/1">Alexander Liniger</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Dengxin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fisher Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08265">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end approaches to autonomous driving commonly rely on expert
demonstrations. Although humans are good drivers, they are not good coaches for
end-to-end algorithms that demand dense on-policy supervision. On the contrary,
automated experts that leverage privileged information can efficiently generate
large scale on-policy and off-policy demonstrations. However, existing
automated experts for urban driving make heavy use of hand-crafted rules and
perform suboptimally even on driving simulators, where ground-truth information
is available. To address these issues, we train a reinforcement learning expert
that maps bird&#x27;s-eye view images to continuous low-level actions. While setting
a new performance upper-bound on CARLA, our expert is also a better coach that
provides informative supervision signals for imitation learning agents to learn
from. Supervised by our reinforcement learning coach, a baseline end-to-end
agent with monocular camera-input achieves expert-level performance. Our
end-to-end agent achieves a 78% success rate while generalizing to a new town
and new weather on the NoCrash-dense benchmark and state-of-the-art performance
on the more challenging CARLA LeaderBoard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Denoising Using Unsupervised Disentangled Spatio-Spectral Deep Priors. (arXiv:2102.12310v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Miao_Y/0/1/0/all/0/1">Yu-Chun Miao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_X/0/1/0/all/0/1">Xi-Le Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jian-Li Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1">Yu-Bang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12310">
                                    <div class="article-summary-box-inner">
                                        <span>Image denoising is often empowered by accurate prior information. In recent
years, data-driven neural network priors have shown promising performance for
RGB natural image denoising. Compared to classic handcrafted priors (e.g.,
sparsity and total variation), the &quot;deep priors&quot; are learned using a large
number of training samples -- which can accurately model the complex image
generating process. However, data-driven priors are hard to acquire for
hyperspectral images (HSIs) due to the lack of training data. A remedy is to
use the so-called unsupervised deep image prior (DIP). Under the unsupervised
DIP framework, it is hypothesized and empirically demonstrated that proper
neural network structures are reasonable priors of certain types of images, and
the network weights can be learned without training data. Nonetheless, the most
effective unsupervised DIP structures were proposed for natural images instead
of HSIs. The performance of unsupervised DIP-based HSI denoising is limited by
a couple of serious challenges, namely, network structure design and network
complexity. This work puts forth an unsupervised DIP framework that is based on
the classic spatio-spectral decomposition of HSIs. Utilizing the so-called
linear mixture model of HSIs, two types of unsupervised DIPs, i.e., U-Net-like
network and fully-connected networks, are employed to model the abundance maps
and endmembers contained in the HSIs, respectively. This way, empirically
validated unsupervised DIP structures for natural images can be easily
incorporated for HSI denoising. Besides, the decomposition also substantially
reduces network complexity. An efficient alternating optimization algorithm is
proposed to handle the formulated denoising problem. Semi-real and real data
experiments are employed to showcase the effectiveness of the proposed
approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions. (arXiv:2105.07404v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Runyu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Gangshan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07404">
                                    <div class="article-summary-box-inner">
                                        <span>Spatio-temporal action detection is an important and challenging problem in
video understanding. The existing action detection benchmarks are limited in
aspects of small numbers of instances in a trimmed video or low-level atomic
actions. This paper aims to present a new multi-person dataset of
spatio-temporal localized sports actions, coined as MultiSports. We first
analyze the important ingredients of constructing a realistic and challenging
dataset for spatio-temporal action detection by proposing three criteria: (1)
multi-person scenes and motion dependent identification, (2) with well-defined
boundaries, (3) relatively fine-grained classes of high complexity. Based on
these guide-lines, we build the dataset of MultiSports v1.0 by selecting 4
sports classes, collecting 3200 video clips, and annotating 37701 action
instances with 902k bounding boxes. Our datasets are characterized with
important properties of high diversity, dense annotation, and high quality. Our
Multi-Sports, with its realistic setting and detailed annotations, exposes the
intrinsic challenges of spatio-temporal action detection. To benchmark this, we
adapt several baseline methods to our dataset and give an in-depth analysis on
the action detection results in our dataset. We hope our MultiSports can serve
as a standard benchmark for spatio-temporal action detection in the future. Our
dataset website is at https://deeperaction.github.io/multisports/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation. (arXiv:2107.11443v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiabo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shaogang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hailin Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11443">
                                    <div class="article-summary-box-inner">
                                        <span>Video activity localisation has recently attained increasing attention due to
its practical values in automatically localising the most salient visual
segments corresponding to their language descriptions (sentences) from
untrimmed and unstructured videos. For supervised model training, a temporal
annotation of both the start and end time index of each video segment for a
sentence (a video moment) must be given. This is not only very expensive but
also sensitive to ambiguity and subjective annotation bias, a much harder task
than image labelling. In this work, we develop a more accurate
weakly-supervised solution by introducing Cross-Sentence Relations Mining (CRM)
in video moment proposal generation and matching when only a paragraph
description of activities without per-sentence temporal annotation is
available. Specifically, we explore two cross-sentence relational constraints:
(1) Temporal ordering and (2) semantic consistency among sentences in a
paragraph description of video activities. Existing weakly-supervised
techniques only consider within-sentence video segment correlations in training
without considering cross-sentence paragraph context. This can mislead due to
ambiguous expressions of individual sentences with visually indiscriminate
video moment proposals in isolation. Experiments on two publicly available
activity localisation datasets show the advantages of our approach over the
state-of-the-art weakly supervised methods, especially so when the video
activity descriptions become more complex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scarce Data Driven Deep Learning of Drones via Generalized Data Distribution Space. (arXiv:2108.08244v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Schyler C. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhuangkun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsourdos_A/0/1/0/all/0/1">Antonios Tsourdos</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Weisi Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08244">
                                    <div class="article-summary-box-inner">
                                        <span>Increased drone proliferation in civilian and professional settings has
created new threat vectors for airports and national infrastructures. The
economic damage for a single major airport from drone incursions is estimated
to be millions per day. Due to the lack of diverse drone training data,
accurate training of deep learning detection algorithms under scarce data is an
open challenge. Existing methods largely rely on collecting diverse and
comprehensive experimental drone footage data, artificially induced data
augmentation, transfer and meta-learning, as well as physics-informed learning.
However, these methods cannot guarantee capturing diverse drone designs and
fully understanding the deep feature space of drones. Here, we show how
understanding the general distribution of the drone data via a Generative
Adversarial Network (GAN) and explaining the missing features using Topological
Data Analysis (TDA) - can allow us to acquire missing data to achieve rapid and
more accurate learning. We demonstrate our results on a drone image dataset,
which contains both real drone images as well as simulated images from
computer-aided design. When compared to random data collection (usual practice
- discriminator accuracy of 94.67\% after 200 epochs), our proposed GAN-TDA
informed data collection method offers a significant 4\% improvement (99.42\%
after 200 epochs). We believe that this approach of exploiting general data
distribution knowledge form neural networks can be applied to a wide range of
scarce data open challenges.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rendering and Tracking the Directional TSDF: Modeling Surface Orientation for Coherent Maps. (arXiv:2108.08115v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Splietker_M/0/1/0/all/0/1">Malte Splietker</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08115">
                                    <div class="article-summary-box-inner">
                                        <span>Dense real-time tracking and mapping from RGB-D images is an important tool
for many robotic applications, such as navigation or grasping. The recently
presented Directional Truncated Signed Distance Function (DTSDF) is an
augmentation of the regular TSDF and shows potential for more coherent maps and
improved tracking performance. In this work, we present methods for rendering
depth- and color maps from the DTSDF, making it a true drop-in replacement for
the regular TSDF in established trackers. We evaluate and show, that our method
increases re-usability of mapped scenes. Furthermore, we add color integration
which notably improves color-correctness at adjacent surfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pixel-Perfect Structure-from-Motion with Featuremetric Refinement. (arXiv:2108.08291v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lindenberger_P/0/1/0/all/0/1">Philipp Lindenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarlin_P/0/1/0/all/0/1">Paul-Edouard Sarlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsson_V/0/1/0/all/0/1">Viktor Larsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08291">
                                    <div class="article-summary-box-inner">
                                        <span>Finding local features that are repeatable across multiple views is a
cornerstone of sparse 3D reconstruction. The classical image matching paradigm
detects keypoints per-image once and for all, which can yield poorly-localized
features and propagate large errors to the final geometry. In this paper, we
refine two key steps of structure-from-motion by a direct alignment of
low-level image information from multiple views: we first adjust the initial
keypoint locations prior to any geometric estimation, and subsequently refine
points and camera poses as a post-processing. This refinement is robust to
large detection noise and appearance changes, as it optimizes a featuremetric
error based on dense features predicted by a neural network. This significantly
improves the accuracy of camera poses and scene geometry for a wide range of
keypoint detectors, challenging viewing conditions, and off-the-shelf deep
features. Our system easily scales to large image collections, enabling
pixel-perfect crowd-sourced localization at scale. Our code is publicly
available at https://github.com/cvg/pixel-perfect-sfm as an add-on to the
popular SfM software COLMAP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparsely Activated Networks. (arXiv:1907.06592v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bizopoulos_P/0/1/0/all/0/1">Paschalis Bizopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Koutsouris_D/0/1/0/all/0/1">Dimitrios Koutsouris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.06592">
                                    <div class="article-summary-box-inner">
                                        <span>Previous literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features. However, this was done
without considering the description length of the learned representations which
is a direct and unbiased measure of the model complexity. In this paper, first
we introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined $\varphi$. We lastly present Sparsely Activated Networks
(SANs) that consist of kernels with shared weights that, during encoding, are
convolved with the input and then passed through a sparse activation function.
During decoding, the same weights are convolved with the sparse activation map
and subsequently the partial reconstructions from each weight are summed to
reconstruct the input. We compare SANs using the five previously defined
activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,
FMNIST) and show that models that are selected using $\varphi$ have small
description representation length and consist of interpretable kernels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Does TERRA-REF&#x27;s High Resolution, Multi Sensor Plant Sensing Public Domain Data Offer the Computer Vision Community?. (arXiv:2107.14072v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+LeBauer_D/0/1/0/all/0/1">David LeBauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnette_M/0/1/0/all/0/1">Max Burnette</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahlgren_N/0/1/0/all/0/1">Noah Fahlgren</a>, <a href="http://arxiv.org/find/cs/1/au:+Kooper_R/0/1/0/all/0/1">Rob Kooper</a>, <a href="http://arxiv.org/find/cs/1/au:+McHenry_K/0/1/0/all/0/1">Kenton McHenry</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1">Abby Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14072">
                                    <div class="article-summary-box-inner">
                                        <span>A core objective of the TERRA-REF project was to generate an open-access
reference dataset for the evaluation of sensing technologies to study plants
under field conditions. The TERRA-REF program deployed a suite of
high-resolution, cutting edge technology sensors on a gantry system with the
aim of scanning 1 hectare (10$^4$) at around 1 mm$^2$ spatial resolution
multiple times per week. The system contains co-located sensors including a
stereo-pair RGB camera, a thermal imager, a laser scanner to capture 3D
structure, and two hyperspectral cameras covering wavelengths of 300-2500nm.
This sensor data is provided alongside over sixty types of traditional plant
phenotype measurements that can be used to train new machine learning models.
Associated weather and environmental measurements, information about agronomic
management and experimental design, and the genomic sequences of hundreds of
plant varieties have been collected and are available alongside the sensor and
plant phenotype data.

Over the course of four years and ten growing seasons, the TERRA-REF system
generated over 1 PB of sensor data and almost 45 million files. The subset that
has been released to the public domain accounts for two seasons and about half
of the total data volume. This provides an unprecedented opportunity for
investigations far beyond the core biological scope of the project.

The focus of this paper is to provide the Computer Vision and Machine
Learning communities an overview of the available data and some potential
applications of this one of a kind data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WildGait: Learning Gait Representations from Raw Surveillance Streams. (arXiv:2105.05528v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1">Adrian Cosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1">Emilian Radoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05528">
                                    <div class="article-summary-box-inner">
                                        <span>The use of gait for person identification has important advantages such as
being non-invasive, unobtrusive, not requiring cooperation and being less
likely to be obscured compared to other biometrics. Existing methods for gait
recognition require cooperative gait scenarios, in which a single person is
walking multiple times in a straight line in front of a camera. We aim to
address the challenges of real-world scenarios in which camera feeds capture
multiple people, who in most cases pass in front of the camera only once. We
address privacy concerns by using only motion information of walking
individuals, with no identifiable appearance-based information. As such, we
propose a novel weakly supervised learning framework, WildGait, which consists
of training a Spatio-Temporal Graph Convolutional Network on a large number of
automatically annotated skeleton sequences obtained from raw, real-world,
surveillance streams to learn useful gait signatures. We collected the training
data and compiled the largest dataset of walking skeletons called Uncooperative
Wild Gait, containing over 38k tracklets of anonymized walking 2D skeletons. We
release the dataset for public use. Our results show that, with fine-tuning, we
surpass the current state-of-the-art pose-based gait recognition solutions. Our
proposed method is reliable in training gait recognition methods in
unconstrained environments, especially in settings with scarce amounts of
annotated data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robust Human Trajectory Prediction in Raw Videos. (arXiv:2108.08259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Rui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zihan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08259">
                                    <div class="article-summary-box-inner">
                                        <span>Human trajectory prediction has received increased attention lately due to
its importance in applications such as autonomous vehicles and indoor robots.
However, most existing methods make predictions based on human-labeled
trajectories and ignore the errors and noises in detection and tracking. In
this paper, we study the problem of human trajectory forecasting in raw videos,
and show that the prediction accuracy can be severely affected by various types
of tracking errors. Accordingly, we propose a simple yet effective strategy to
correct the tracking failures by enforcing prediction consistency over time.
The proposed &quot;re-tracking&quot; algorithm can be applied to any existing tracking
and prediction pipelines. Experiments on public benchmark datasets demonstrate
that the proposed method can improve both tracking and prediction performance
in challenging real-world scenarios. The code and data are available at
https://git.io/retracking-prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neuromorphic Computing for Content-based Image Retrieval. (arXiv:2008.01380v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Te-Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahjoubfar_A/0/1/0/all/0/1">Ata Mahjoubfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Prusinski_D/0/1/0/all/0/1">Daniel Prusinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_L/0/1/0/all/0/1">Luis Stevens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01380">
                                    <div class="article-summary-box-inner">
                                        <span>Neuromorphic computing mimics the neural activity of the brain through
emulating spiking neural networks. In numerous machine learning tasks,
neuromorphic chips are expected to provide superior solutions in terms of cost
and power efficiency. Here, we explore the application of Loihi, a neuromorphic
computing chip developed by Intel, for the computer vision task of image
retrieval. We evaluated the functionalities and the performance metrics that
are critical in content-based visual search and recommender systems using
deep-learning embeddings. Our results show that the neuromorphic solution is
about 2.5 times more energy-efficient compared with an ARM Cortex-A72 CPU and
12.5 times more energy-efficient compared with NVIDIA T4 GPU for inference by a
lightweight convolutional neural network without batching while maintaining the
same level of matching accuracy. The study validates the potential of
neuromorphic computing in low-power image retrieval, as a complementary
paradigm to the existing von Neumann architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-Det3D: Self-Attention Based Context-Aware 3D Object Detection. (arXiv:2101.02672v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Prarthana Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chengjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Czarnecki_K/0/1/0/all/0/1">Krzysztof Czarnecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02672">
                                    <div class="article-summary-box-inner">
                                        <span>Existing point-cloud based 3D object detectors use convolution-like operators
to process information in a local neighbourhood with fixed-weight kernels and
aggregate global context hierarchically. However, non-local neural networks and
self-attention for 2D vision have shown that explicitly modeling long-range
interactions can lead to more robust and competitive models. In this paper, we
propose two variants of self-attention for contextual modeling in 3D object
detection by augmenting convolutional features with self-attention features. We
first incorporate the pairwise self-attention mechanism into the current
state-of-the-art BEV, voxel and point-based detectors and show consistent
improvement over strong baseline models of up to 1.5 3D AP while simultaneously
reducing their parameter footprint and computational cost by 15-80% and 30-50%,
respectively, on the KITTI validation set. We next propose a self-attention
variant that samples a subset of the most representative features by learning
deformations over randomly sampled locations. This not only allows us to scale
explicit global contextual modeling to larger point-clouds, but also leads to
more discriminative and informative feature descriptors. Our method can be
flexibly applied to most state-of-the-art detectors with increased accuracy and
parameter and compute efficiency. We show our proposed method improves 3D
object detection performance on KITTI, nuScenes and Waymo Open datasets. Code
is available at https://github.com/AutoVision-cloud/SA-Det3D.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongquan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yiming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jiayi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhongxi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14956">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from noisy labels is an important concern because of the lack of
accurate ground-truth labels in plenty of real-world scenarios. In practice,
various approaches for this concern first make some corrections corresponding
to potentially noisy-labeled instances, and then update predictive model with
information of the made corrections. However, in specific areas, such as
medical histopathology whole slide image analysis (MHWSIA), it is often
difficult or even impossible for experts to manually achieve the noisy-free
ground-truth labels which leads to labels with complex noise. This situation
raises two more difficult problems: 1) the methodology of approaches making
corrections corresponding to potentially noisy-labeled instances has
limitations due to the complex noise existing in labels; and 2) the appropriate
evaluation strategy for validation/testing is unclear because of the great
difficulty in collecting the noisy-free ground-truth labels. In this paper, we
focus on alleviating these two problems. For the problem 1), we present
one-step abductive multi-target learning (OSAMTL) that imposes a one-step
logical reasoning upon machine learning via a multi-target learning procedure
to constrain the predictions of the learning model to be subject to our prior
knowledge about the true target. For the problem 2), we propose a logical
assessment formula (LAF) that evaluates the logical rationality of the outputs
of an approach by estimating the consistencies between the predictions of the
learning model and the logical facts narrated from the results of the one-step
logical reasoning of OSAMTL. Applying OSAMTL and LAF to the Helicobacter pylori
(H. pylori) segmentation task in MHWSIA, we show that OSAMTL is able to enable
the machine learning model achieving logically more rational predictions, which
is beyond various state-of-the-art approaches in handling complex noisy labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics. (arXiv:2108.08217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yehao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yingwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Ting Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08217">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise and development of deep learning over the past decade, there
has been a steady momentum of innovation and breakthroughs that convincingly
push the state-of-the-art of cross-modal analytics between vision and language
in multimedia field. Nevertheless, there has not been an open-source codebase
in support of training and deploying numerous neural network models for
cross-modal analytics in a unified and modular fashion. In this work, we
propose X-modaler -- a versatile and high-performance codebase that
encapsulates the state-of-the-art cross-modal analytics into several
general-purpose stages (e.g., pre-processing, encoder, cross-modal interaction,
decoder, and decode strategy). Each stage is empowered with the functionality
that covers a series of modules widely adopted in state-of-the-arts and allows
seamless switching in between. This way naturally enables a flexible
implementation of state-of-the-art algorithms for image captioning, video
captioning, and vision-language pre-training, aiming to facilitate the rapid
development of research community. Meanwhile, since the effective modular
designs in several stages (e.g., cross-modal interaction) are shared across
different vision-language tasks, X-modaler can be simply extended to power
startup prototypes for other tasks in cross-modal analytics, including visual
question answering, visual commonsense reasoning, and cross-modal retrieval.
X-modaler is an Apache-licensed codebase, and its source codes, sample projects
and pre-trained models are available on-line:
https://github.com/YehLi/xmodaler.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval. (arXiv:2103.15049v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Song Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Haoqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1">Shengsheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiru Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenkui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15049">
                                    <div class="article-summary-box-inner">
                                        <span>Video-Text Retrieval has been a hot research topic with the growth of
multimedia data on the internet. Transformer for video-text learning has
attracted increasing attention due to its promising performance. However,
existing cross-modal transformer approaches typically suffer from two major
limitations: 1) Exploitation of the transformer architecture where different
layers have different feature characteristics is limited; 2) End-to-end
training mechanism limits negative sample interactions in a mini-batch. In this
paper, we propose a novel approach named Hierarchical Transformer (HiT) for
video-text retrieval. HiT performs Hierarchical Cross-modal Contrastive
Matching in both feature-level and semantic-level, achieving multi-view and
comprehensive retrieval results. Moreover, inspired by MoCo, we propose
Momentum Cross-modal Contrast for cross-modal learning to enable large-scale
negative sample interactions on-the-fly, which contributes to the generation of
more precise and discriminative representations. Experimental results on the
three major Video-Text Retrieval benchmark datasets demonstrate the advantages
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images. (arXiv:2108.03788v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation. (arXiv:2108.08202v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jiaming Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_M/0/1/0/all/0/1">Ming Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_K/0/1/0/all/0/1">Kaixin Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1">Xiaoqi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shizun Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoqing Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_E/0/1/0/all/0/1">Enhua Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1">Chuang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_M/0/1/0/all/0/1">Ming Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08202">
                                    <div class="article-summary-box-inner">
                                        <span>Internet video delivery has undergone a tremendous explosion of growth over
the past few years. However, the quality of video delivery system greatly
depends on the Internet bandwidth. Deep Neural Networks (DNNs) are utilized to
improve the quality of video delivery recently. These methods divide a video
into chunks, and stream LR video chunks and corresponding content-aware models
to the client. The client runs the inference of models to super-resolve the LR
chunks. Consequently, a large number of models are streamed in order to deliver
a video. In this paper, we first carefully study the relation between models of
different chunks, then we tactfully design a joint training framework along
with the Content-aware Feature Modulation (CaFM) layer to compress these models
for neural video delivery. {\bf With our method, each video chunk only requires
less than $1\% $ of original parameters to be streamed, achieving even better
SR performance.} We conduct extensive experiments across various SR backbones,
video time length, and scaling factors to demonstrate the advantages of our
method. Besides, our method can be also viewed as a new approach of video
coding. Our primary experiments achieve better video quality compared with the
commercial H.264 and H.265 standard under the same storage cost, showing the
great potential of the proposed method. Code is available
at:\url{https://github.com/Neural-video-delivery/CaFM-Pytorch-ICCV2021}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reparametrization of Multi-Frame Super-Resolution and Denoising. (arXiv:2108.08286v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bhat_G/0/1/0/all/0/1">Goutam Bhat</a>, <a href="http://arxiv.org/find/eess/1/au:+Danelljan_M/0/1/0/all/0/1">Martin Danelljan</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_F/0/1/0/all/0/1">Fisher Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/eess/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08286">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a deep reparametrization of the maximum a posteriori formulation
commonly employed in multi-frame image restoration tasks. Our approach is
derived by introducing a learned error metric and a latent representation of
the target image, which transforms the MAP objective to a deep feature space.
The deep reparametrization allows us to directly model the image formation
process in the latent space, and to integrate learned image priors into the
prediction. Our approach thereby leverages the advantages of deep learning,
while also benefiting from the principled multi-frame fusion provided by the
classical MAP formulation. We validate our approach through comprehensive
experiments on burst denoising and burst super-resolution datasets. Our
approach sets a new state-of-the-art for both tasks, demonstrating the
generality and effectiveness of the proposed formulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepMiner: Discovering Interpretable Representations for Mammogram Classification and Explanation. (arXiv:1805.12323v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jimmy Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Peck_D/0/1/0/all/0/1">Diondra Peck</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_S/0/1/0/all/0/1">Scott Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dialani_V/0/1/0/all/0/1">Vandana Dialani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>, <a href="http://arxiv.org/find/cs/1/au:+Patterson_G/0/1/0/all/0/1">Genevieve Patterson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1805.12323">
                                    <div class="article-summary-box-inner">
                                        <span>We propose DeepMiner, a framework to discover interpretable representations
in deep neural networks and to build explanations for medical predictions. By
probing convolutional neural networks (CNNs) trained to classify cancer in
mammograms, we show that many individual units in the final convolutional layer
of a CNN respond strongly to diseased tissue concepts specified by the BI-RADS
lexicon. After expert annotation of the interpretable units, our proposed
method is able to generate explanations for CNN mammogram classification that
are consistent with ground truth radiology reports on the Digital Database for
Screening Mammography. We show that DeepMiner not only enables better
understanding of the nuances of CNN classification decisions but also possibly
discovers new visual knowledge relevant to medical diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Confidence Adaptive Regularization for Deep Learning with Noisy Labels. (arXiv:2108.08212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yangdi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bo_Y/0/1/0/all/0/1">Yang Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wenbo He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08212">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies on the memorization effects of deep neural networks on noisy
labels show that the networks first fit the correctly-labeled training samples
before memorizing the mislabeled samples. Motivated by this early-learning
phenomenon, we propose a novel method to prevent memorization of the mislabeled
samples. Unlike the existing approaches which use the model output to identify
or ignore the mislabeled samples, we introduce an indicator branch to the
original model and enable the model to produce a confidence value for each
sample. The confidence values are incorporated in our loss function which is
learned to assign large confidence values to correctly-labeled samples and
small confidence values to mislabeled samples. We also propose an auxiliary
regularization term to further improve the robustness of the model. To improve
the performance, we gradually correct the noisy labels with a well-designed
target estimation strategy. We provide the theoretical analysis and conduct the
experiments on synthetic and real-world datasets, demonstrating that our
approach achieves comparable results to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LOKI: Long Term and Key Intentions for Trajectory Prediction. (arXiv:2108.08236v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girase_H/0/1/0/all/0/1">Harshayu Girase</a>, <a href="http://arxiv.org/find/cs/1/au:+Gang_H/0/1/0/all/0/1">Haiming Gang</a>, <a href="http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1">Srikanth Malla</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanehara_A/0/1/0/all/0/1">Akira Kanehara</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1">Karttikeya Mangalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1">Chiho Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08236">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in trajectory prediction have shown that explicit reasoning
about agents&#x27; intent is important to accurately forecast their motion. However,
the current research activities are not directly applicable to intelligent and
safety critical systems. This is mainly because very few public datasets are
available, and they only consider pedestrian-specific intents for a short
temporal horizon from a restricted egocentric view. To this end, we propose
LOKI (LOng term and Key Intentions), a novel large-scale dataset that is
designed to tackle joint trajectory and intention prediction for heterogeneous
traffic agents (pedestrians and vehicles) in an autonomous driving setting. The
LOKI dataset is created to discover several factors that may affect intention,
including i) agent&#x27;s own will, ii) social interactions, iii) environmental
constraints, and iv) contextual information. We also propose a model that
jointly performs trajectory and intention prediction, showing that recurrently
reasoning about intention can assist with trajectory prediction. We show our
method outperforms state-of-the-art trajectory prediction methods by upto
$27\%$ and also provide a baseline for frame-wise intention estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Attention Module for Convolutional Neural Networks. (arXiv:2108.08205v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baozhou_Z/0/1/0/all/0/1">Zhu Baozhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofstee_P/0/1/0/all/0/1">Peter Hofstee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Ars_Z/0/1/0/all/0/1">Zaid Al-Ars</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08205">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism has been regarded as an advanced technique to capture
long-range feature interactions and to boost the representation capability for
convolutional neural networks. However, we found two ignored problems in
current attentional activations-based models: the approximation problem and the
insufficient capacity problem of the attention maps. To solve the two problems
together, we initially propose an attention module for convolutional neural
networks by developing an AW-convolution, where the shape of attention maps
matches that of the weights rather than the activations. Our proposed attention
module is a complementary method to previous attention-based schemes, such as
those that apply the attention mechanism to explore the relationship between
channel-wise and spatial features. Experiments on several datasets for image
classification and object detection tasks show the effectiveness of our
proposed attention module. In particular, our proposed attention module
achieves 1.00% Top-1 accuracy improvement on ImageNet classification over a
ResNet101 baseline and 0.63 COCO-style Average Precision improvement on the
COCO object detection on top of a Faster R-CNN baseline with the backbone of
ResNet101-FPN. When integrating with the previous attentional activations-based
models, our proposed attention module can further increase their Top-1 accuracy
on ImageNet classification by up to 0.57% and COCO-style Average Precision on
the COCO object detection by up to 0.45. Code and pre-trained models will be
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Min-Max affine approximants of convex or concave real valued functions from $\mathbb R^k$, Chebyshev equioscillation and graphics. (arXiv:1812.02302v10 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Damelin_S/0/1/0/all/0/1">Steven B. Damelin</a>, <a href="http://arxiv.org/find/math/1/au:+Ragozin_D/0/1/0/all/0/1">David L. Ragozin</a>, <a href="http://arxiv.org/find/math/1/au:+Werman_M/0/1/0/all/0/1">Michael Werman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.02302">
                                    <div class="article-summary-box-inner">
                                        <span>We study Min-Max affine approximants of a continuous convex or concave
function $f:\Delta\subset \mathbb R^k\xrightarrow{} \mathbb R$ where $\Delta$
is a convex compact subset of $\mathbb R^k$. In the case when $\Delta$ is a
simplex we prove that there is a vertical translate of the supporting
hyperplane in $\mathbb R^{k+1}$ of the graph of $f$ at the vertices which is
the unique best affine approximant to $f$ on $\Delta$. For $k&#x3D;1$, this result
provides an extension of the Chebyshev equioscillation theorem for linear
approximants. Our result has interesting connections to the computer graphics
problem of rapid rendering of projective transformations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-patch Feature Pyramid Network for Weakly Supervised Object Detection in Optical Remote Sensing Images. (arXiv:2108.08063v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shamsolmoali_P/0/1/0/all/0/1">Pourya Shamsolmoali</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zareapoor_M/0/1/0/all/0/1">Masoumeh Zareapoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08063">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection is a challenging task in remote sensing because objects only
occupy a few pixels in the images, and the models are required to
simultaneously learn object locations and detection. Even though the
established approaches well perform for the objects of regular sizes, they
achieve weak performance when analyzing small ones or getting stuck in the
local minima (e.g. false object parts). Two possible issues stand in their way.
First, the existing methods struggle to perform stably on the detection of
small objects because of the complicated background. Second, most of the
standard methods used hand-crafted features, and do not work well on the
detection of objects parts of which are missing. We here address the above
issues and propose a new architecture with a multiple patch feature pyramid
network (MPFP-Net). Different from the current models that during training only
pursue the most discriminative patches, in MPFPNet the patches are divided into
class-affiliated subsets, in which the patches are related and based on the
primary loss function, a sequence of smooth loss functions are determined for
the subsets to improve the model for collecting small object parts. To enhance
the feature representation for patch selection, we introduce an effective
method to regularize the residual values and make the fusion transition layers
strictly norm-preserving. The network contains bottom-up and crosswise
connections to fuse the features of different scales to achieve better
accuracy, compared to several state-of-the-art object detection models. Also,
the developed architecture is more efficient than the baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Research on Gender-related Fingerprint Features. (arXiv:2108.08233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yong Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanping Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Huawei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiashu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_H/0/1/0/all/0/1">Huaiguang Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08233">
                                    <div class="article-summary-box-inner">
                                        <span>Fingerprint is an important biological feature of human body, which contains
abundant gender information. At present, the academic research of fingerprint
gender characteristics is generally at the level of understanding, while the
standardization research is quite limited. In this work, we propose a more
robust method, Dense Dilated Convolution ResNet (DDC-ResNet) to extract valid
gender information from fingerprints. By replacing the normal convolution
operations with the atrous convolution in the backbone, prior knowledge is
provided to keep the edge details and the global reception field can be
extended. We explored the results in 3 ways: 1) The efficiency of the
DDC-ResNet. 6 typical methods of automatic feature extraction coupling with 9
mainstream classifiers are evaluated in our dataset with fair implementation
details. Experimental results demonstrate that the combination of our approach
outperforms other combinations in terms of average accuracy and separate-gender
accuracy. It reaches 96.5% for average and 0.9752 (males)/0.9548 (females) for
separate-gender accuracy. 2) The effect of fingers. It is found that the best
performance of classifying gender with separate fingers is achieved by the
right ring finger. 3) The effect of specific features. Based on the
observations of the concentrations of fingerprints visualized by our approach,
it can be inferred that loops and whorls (level 1), bifurcations (level 2), as
well as line shapes (level 3) are connected with gender. Finally, we will open
source the dataset that contains 6000 fingerprint images</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GNeRF: GAN-based Neural Radiance Field without Posed Camera. (arXiv:2103.15606v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Quan Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anpei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haimin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minye Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15606">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce GNeRF, a framework to marry Generative Adversarial Networks
(GAN) with Neural Radiance Field (NeRF) reconstruction for the complex
scenarios with unknown and even randomly initialized camera poses. Recent
NeRF-based advances have gained popularity for remarkable realistic novel view
synthesis. However, most of them heavily rely on accurate camera poses
estimation, while few recent methods can only optimize the unknown camera poses
in roughly forward-facing scenes with relatively short camera trajectories and
require rough camera poses initialization. Differently, our GNeRF only utilizes
randomly initialized poses for complex outside-in scenarios. We propose a novel
two-phases end-to-end framework. The first phase takes the use of GANs into the
new realm for optimizing coarse camera poses and radiance fields jointly, while
the second phase refines them with additional photometric loss. We overcome
local minima using a hybrid and iterative optimization scheme. Extensive
experiments on a variety of synthetic and natural scenes demonstrate the
effectiveness of GNeRF. More impressively, our approach outperforms the
baselines favorably in those scenes with repeated patterns or even low textures
that are regarded as extremely challenging before.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Deep and Efficient: A Deep Siamese Self-Attention Fully Efficient Convolutional Network for Change Detection in VHR Images. (arXiv:2108.08157v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongruixuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08157">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, FCNs have attracted widespread attention in the CD field. In
pursuit of better CD performance, it has become a tendency to design deeper and
more complicated FCNs, which inevitably brings about huge numbers of parameters
and an unbearable computational burden. With the goal of designing a quite deep
architecture to obtain more precise CD results while simultaneously decreasing
parameter numbers to improve efficiency, in this work, we present a very deep
and efficient CD network, entitled EffCDNet. In EffCDNet, to reduce the
numerous parameters associated with deep architecture, an efficient convolution
consisting of depth-wise convolution and group convolution with a channel
shuffle mechanism is introduced to replace standard convolutional layers. In
terms of the specific network architecture, EffCDNet does not use mainstream
UNet-like architecture, but rather adopts the architecture with a very deep
encoder and a lightweight decoder. In the very deep encoder, two very deep
siamese streams stacked by efficient convolution first extract two highly
representative and informative feature maps from input image-pairs.
Subsequently, an efficient ASPP module is designed to capture multi-scale
change information. In the lightweight decoder, a recurrent criss-cross
self-attention (RCCA) module is applied to efficiently utilize non-local
similar feature representations to enhance discriminability for each pixel,
thus effectively separating the changed and unchanged regions. Moreover, to
tackle the optimization problem in confused pixels, two novel loss functions
based on information entropy are presented. On two challenging CD datasets, our
approach outperforms other SOTA FCN-based methods, with only benchmark-level
parameter numbers and quite low computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CapillaryNet: An Automated System to Quantify Skin Capillary Density and Red Blood Cell Velocity from Handheld Vital Microscopy. (arXiv:2104.11574v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Helmy_M/0/1/0/all/0/1">Maged Helmy</a>, <a href="http://arxiv.org/find/cs/1/au:+Dykyy_A/0/1/0/all/0/1">Anastasiya Dykyy</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Tuyen Trung Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferreira_P/0/1/0/all/0/1">Paulo Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Jul_E/0/1/0/all/0/1">Eric Jul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11574">
                                    <div class="article-summary-box-inner">
                                        <span>Capillaries are the smallest vessels in the body responsible for the delivery
of oxygen and nutrients to the surrounding cells. Various diseases have been
shown to alter the density of nutritive capillaries and the flow velocity of
erythrocytes. In previous studies, capillary density and flow velocity have
been assessed manually by trained specialists. Manual analysis of a standard
20-second long microvascular video takes on average 20 minutes and requires
extensive training. Several studies have reported that manual analysis hinders
the application of microvascular microscopy in a clinical setting. In this
paper, we present a fully automated state-of-the-art system, called
CapillaryNet, that can quantify skin nutritive capillary density and red blood
cell velocity from handheld microscopy videos. Moreover, CapillaryNet measures
several novel microvascular parameters that researchers were previously unable
to quantify, i.e. capillary hematocrit and Intra-capillary flow velocity
heterogeneity. Our system has been used to analyze skin microcirculation videos
from various patient groups (COVID-19, pancreatitis, and acute heart diseases).
Our proposed system excels from existing capillary detection systems as it
combines the speed of traditional computer vision algorithms and the accuracy
of convolutional neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LIGA-Stereo: Learning LiDAR Geometry Aware Representations for Stereo-based 3D Detector. (arXiv:2108.08258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaoyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shaoshuai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08258">
                                    <div class="article-summary-box-inner">
                                        <span>Stereo-based 3D detection aims at detecting 3D object bounding boxes from
stereo images using intermediate depth maps or implicit 3D geometry
representations, which provides a low-cost solution for 3D perception. However,
its performance is still inferior compared with LiDAR-based detection
algorithms. To detect and localize accurate 3D bounding boxes, LiDAR-based
models can encode accurate object boundaries and surface normal directions from
LiDAR point clouds. However, the detection results of stereo-based detectors
are easily affected by the erroneous depth features due to the limitation of
stereo matching. To solve the problem, we propose LIGA-Stereo (LiDAR Geometry
Aware Stereo Detector) to learn stereo-based 3D detectors under the guidance of
high-level geometry-aware representations of LiDAR-based detection models. In
addition, we found existing voxel-based stereo detectors failed to learn
semantic features effectively from indirect 3D supervisions. We attach an
auxiliary 2D detection head to provide direct 2D semantic supervisions.
Experiment results show that the above two strategies improved the geometric
and semantic representation capabilities. Compared with the state-of-the-art
stereo detector, our method has improved the 3D detection performance of cars,
pedestrians, cyclists by 10.44%, 5.69%, 5.97% mAP respectively on the official
KITTI benchmark. The gap between stereo-based and LiDAR-based 3D detectors is
further narrowed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visformer: The Vision-friendly Transformer. (arXiv:2104.12533v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengsu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lingxi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_J/0/1/0/all/0/1">Jianwei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuefeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Longhui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12533">
                                    <div class="article-summary-box-inner">
                                        <span>The past year has witnessed the rapid development of applying the Transformer
module to vision problems. While some researchers have demonstrated that
Transformer-based models enjoy a favorable ability of fitting data, there are
still growing number of evidences showing that these models suffer over-fitting
especially when the training data is limited. This paper offers an empirical
study by performing step-by-step operations to gradually transit a
Transformer-based model to a convolution-based model. The results we obtain
during the transition process deliver useful messages for improving visual
recognition. Based on these observations, we propose a new architecture named
Visformer, which is abbreviated from the &#x60;Vision-friendly Transformer&#x27;. With
the same computational complexity, Visformer outperforms both the
Transformer-based and convolution-based models in terms of ImageNet
classification accuracy, and the advantage becomes more significant when the
model complexity is lower or the training set is smaller. The code is available
at https://github.com/danczs/Visformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FOX-NAS: Fast, On-device and Explainable Neural Architecture Search. (arXiv:2108.08189v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chia-Hsiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yu-Shin Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yuan-Yao Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hung-Yueh Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kai-Chiang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08189">
                                    <div class="article-summary-box-inner">
                                        <span>Neural architecture search can discover neural networks with good
performance, and One-Shot approaches are prevalent. One-Shot approaches
typically require a supernet with weight sharing and predictors that predict
the performance of architecture. However, the previous methods take much time
to generate performance predictors thus are inefficient. To this end, we
propose FOX-NAS that consists of fast and explainable predictors based on
simulated annealing and multivariate regression. Our method is
quantization-friendly and can be efficiently deployed to the edge. The
experiments on different hardware show that FOX-NAS models outperform some
other popular neural network architectures. For example, FOX-NAS matches
MobileNetV2 and EfficientNet-Lite0 accuracy with 240% and 40% less latency on
the edge CPU. FOX-NAS is the 3rd place winner of the 2020 Low-Power Computer
Vision Challenge (LPCVC), DSP classification track. See all evaluation results
at https://lpcv.ai/competitions/2020. Search code and pre-trained models are
released at https://github.com/great8nctu/FOX-NAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MBRS : Enhancing Robustness of DNN-based Watermarking by Mini-Batch of Real and Simulated JPEG Compression. (arXiv:2108.08211v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhaoyang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Han Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08211">
                                    <div class="article-summary-box-inner">
                                        <span>Based on the powerful feature extraction ability of deep learning
architecture, recently, deep-learning based watermarking algorithms have been
widely studied. The basic framework of such algorithm is the auto-encoder like
end-to-end architecture with an encoder, a noise layer and a decoder. The key
to guarantee robustness is the adversarial training with the differential noise
layer. However, we found that none of the existing framework can well ensure
the robustness against JPEG compression, which is non-differential but is an
essential and important image processing operation. To address such
limitations, we proposed a novel end-to-end training architecture, which
utilizes Mini-Batch of Real and Simulated JPEG compression (MBRS) to enhance
the JPEG robustness. Precisely, for different mini-batches, we randomly choose
one of real JPEG, simulated JPEG and noise-free layer as the noise layer.
Besides, we suggest to utilize the Squeeze-and-Excitation blocks which can
learn better feature in embedding and extracting stage, and propose a &quot;message
processor&quot; to expand the message in a more appreciate way. Meanwhile, to
improve the robustness against crop attack, we propose an additive diffusion
block into the network. The extensive experimental results have demonstrated
the superior performance of the proposed scheme compared with the
state-of-the-art algorithms. Under the JPEG compression with quality factor
Q&#x3D;50, our models achieve a bit error rate less than 0.01% for extracted
messages, with PSNR larger than 36 for the encoded images, which shows the
well-enhanced robustness against JPEG attack. Besides, under many other
distortions such as Gaussian filter, crop, cropout and dropout, the proposed
framework also obtains strong robustness. The code implemented by PyTorch
\cite{2011torch7} is avaiable in https://github.com/jzyustc/MBRS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Visual-Inertial Cooperative Localization. (arXiv:2103.12770v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Pengxiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geneva_P/0/1/0/all/0/1">Patrick Geneva</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1">Wei Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guoquan Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12770">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present a consistent and distributed state estimator for
multi-robot cooperative localization (CL) which efficiently fuses environmental
features and loop-closure constraints across time and robots. In particular, we
leverage covariance intersection (CI) to allow each robot to only estimate its
own state and autocovariance and compensate for the unknown correlations
between robots. Two novel multi-robot methods for utilizing common
environmental SLAM features are introduced and evaluated in terms of accuracy
and efficiency. Moreover, we adapt CI to enable drift-free estimation through
the use of loop-closure measurement constraints to other robots&#x27; historical
poses without a significant increase in computational cost. The proposed
distributed CL estimator is validated against its non-realtime centralized
counterpart extensively in both simulations and real-world experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding. (arXiv:2011.02523v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roberts_M/0/1/0/all/0/1">Mike Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramapuram_J/0/1/0/all/0/1">Jason Ramapuram</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranjan_A/0/1/0/all/0/1">Anurag Ranjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Atulit Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bautista_M/0/1/0/all/0/1">Miguel Angel Bautista</a>, <a href="http://arxiv.org/find/cs/1/au:+Paczan_N/0/1/0/all/0/1">Nathan Paczan</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_R/0/1/0/all/0/1">Russ Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1">Joshua M. Susskind</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02523">
                                    <div class="article-summary-box-inner">
                                        <span>For many fundamental scene understanding tasks, it is difficult or impossible
to obtain per-pixel ground truth labels from real images. We address this
challenge by introducing Hypersim, a photorealistic synthetic dataset for
holistic indoor scene understanding. To create our dataset, we leverage a large
repository of synthetic scenes created by professional artists, and we generate
77,400 images of 461 indoor scenes with detailed per-pixel labels and
corresponding ground truth geometry. Our dataset: (1) relies exclusively on
publicly available 3D assets; (2) includes complete scene geometry, material
information, and lighting information for every scene; (3) includes dense
per-pixel semantic instance segmentations and complete camera information for
every image; and (4) factors every image into diffuse reflectance, diffuse
illumination, and a non-diffuse residual term that captures view-dependent
lighting effects.

We analyze our dataset at the level of scenes, objects, and pixels, and we
analyze costs in terms of money, computation time, and annotation effort.
Remarkably, we find that it is possible to generate our entire dataset from
scratch, for roughly half the cost of training a popular open-source natural
language processing model. We also evaluate sim-to-real transfer performance on
two real-world scene understanding tasks - semantic segmentation and 3D shape
prediction - where we find that pre-training on our dataset significantly
improves performance on both tasks, and achieves state-of-the-art performance
on the most challenging Pix3D test set. All of our rendered image data, as well
as all the code we used to generate our dataset and perform our experiments, is
available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Spatial Dimensions of Vision Transformers. (arXiv:2103.16302v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heo_B/0/1/0/all/0/1">Byeongho Heo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Sangdoo Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongyoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Sanghyuk Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1">Junsuk Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Seong Joon Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16302">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformer (ViT) extends the application range of transformers from
language processing to computer vision tasks as being an alternative
architecture against the existing convolutional neural networks (CNN). Since
the transformer-based architecture has been innovative for computer vision
modeling, the design convention towards an effective architecture has been less
studied yet. From the successful design principles of CNN, we investigate the
role of spatial dimension conversion and its effectiveness on transformer-based
architecture. We particularly attend to the dimension reduction principle of
CNNs; as the depth increases, a conventional CNN increases channel dimension
and decreases spatial dimensions. We empirically show that such a spatial
dimension reduction is beneficial to a transformer architecture as well, and
propose a novel Pooling-based Vision Transformer (PiT) upon the original ViT
model. We show that PiT achieves the improved model capability and
generalization performance against ViT. Throughout the extensive experiments,
we further show PiT outperforms the baseline on several tasks such as image
classification, object detection, and robustness evaluation. Source codes and
ImageNet models are available at https://github.com/naver-ai/pit</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Conditioned Probabilistic Learning of Video Rescaling. (arXiv:2107.11639v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_X/0/1/0/all/0/1">Xiongkuo Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1">Zhaohui Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1">Guodong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhiyong Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11639">
                                    <div class="article-summary-box-inner">
                                        <span>Bicubic downscaling is a prevalent technique used to reduce the video storage
burden or to accelerate the downstream processing speed. However, the inverse
upscaling step is non-trivial, and the downscaled video may also deteriorate
the performance of downstream tasks. In this paper, we propose a
self-conditioned probabilistic framework for video rescaling to learn the
paired downscaling and upscaling procedures simultaneously. During the
training, we decrease the entropy of the information lost in the downscaling by
maximizing its probability conditioned on the strong spatial-temporal prior
information within the downscaled video. After optimization, the downscaled
video by our framework preserves more meaningful information, which is
beneficial for both the upscaling step and the downstream tasks, e.g., video
action recognition task. We further extend the framework to a lossy video
compression system, in which a gradient estimator for non-differential
industrial lossy codecs is proposed for the end-to-end training of the whole
system. Extensive experimental results demonstrate the superiority of our
approach on video rescaling, video compression, and efficient action
recognition tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Photo Scan: Semi-Supervised Learning for dealing with the real-world degradation in Smartphone Photo Scanning. (arXiv:2102.06120v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_M/0/1/0/all/0/1">Man M. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jinjia Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06120">
                                    <div class="article-summary-box-inner">
                                        <span>Physical photographs now can be conveniently scanned by smartphones and
stored forever as a digital version, yet the scanned photos are not restored
well. One solution is to train a supervised deep neural network on many digital
photos and the corresponding scanned photos. However, it requires a high labor
cost, leading to limited training data. Previous works create training pairs by
simulating degradation using image processing techniques. Their synthetic
images are formed with perfectly scanned photos in latent space. Even so, the
real-world degradation in smartphone photo scanning remains unsolved since it
is more complicated due to lens defocus, lighting conditions, losing details
via printing. Besides, locally structural misalignment still occurs in data due
to distorted shapes captured in a 3-D world, reducing restoration performance
and the reliability of the quantitative evaluation. To solve these problems, we
propose a semi-supervised Deep Photo Scan (DPScan). First, we present a way of
producing real-world degradation and provide the DIV2K-SCAN dataset for
smartphone-scanned photo restoration. Also, Local Alignment is proposed to
reduce the minor misalignment remaining in data. Second, we simulate many
different variants of the real-world degradation using low-level image
transformation to gain a generalization in smartphone-scanned image properties,
then train a degradation network to generalize all styles of degradation and
provide pseudo-scanned photos for unscanned images as if they were scanned by a
smartphone. Finally, we propose a Semi-Supervised Learning that allows our
restoration network to be trained on both scanned and unscanned images,
diversifying training image content. As a result, the proposed DPScan
quantitatively and qualitatively outperforms its baseline architecture,
state-of-the-art academic research, and industrial products in smartphone photo
scanning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidential Deep Learning for Open Set Action Recognition. (arXiv:2107.10161v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1">Wentao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1">Yu Kong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10161">
                                    <div class="article-summary-box-inner">
                                        <span>In a real-world scenario, human actions are typically out of the distribution
from training data, which requires a model to both recognize the known actions
and reject the unknown. Different from image data, video actions are more
challenging to be recognized in an open-set setting due to the uncertain
temporal dynamics and static bias of human actions. In this paper, we propose a
Deep Evidential Action Recognition (DEAR) method to recognize actions in an
open testing set. Specifically, we formulate the action recognition problem
from the evidential deep learning (EDL) perspective and propose a novel model
calibration method to regularize the EDL training. Besides, to mitigate the
static bias of video representation, we propose a plug-and-play module to
debias the learned representation through contrastive learning. Experimental
results show that our DEAR method achieves consistent performance gain on
multiple mainstream action recognition models and benchmarks. Code and
pre-trained models are available at
{\small{\url{https://www.rit.edu/actionlab/dear}}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perception-Aware Multi-Sensor Fusion for 3D LiDAR Semantic Segmentation. (arXiv:2106.15277v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhuangwei Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanqing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15277">
                                    <div class="article-summary-box-inner">
                                        <span>3D LiDAR (light detection and ranging) semantic segmentation is important in
scene understanding for many applications, such as auto-driving and robotics.
For example, for autonomous cars equipped with RGB cameras and LiDAR, it is
crucial to fuse complementary information from different sensors for robust and
accurate segmentation. Existing fusion-based methods, however, may not achieve
promising performance due to the vast difference between the two modalities. In
this work, we investigate a collaborative fusion scheme called perception-aware
multi-sensor fusion (PMF) to exploit perceptual information from two
modalities, namely, appearance information from RGB images and spatio-depth
information from point clouds. To this end, we first project point clouds to
the camera coordinates to provide spatio-depth information for RGB images.
Then, we propose a two-stream network to extract features from the two
modalities, separately, and fuse the features by effective residual-based
fusion modules. Moreover, we propose additional perception-aware losses to
measure the perceptual difference between the two modalities. Extensive
experiments on two benchmark data sets show the superiority of our method. For
example, on nuScenes, our PMF outperforms the state-of-the-art method by 0.8 in
mIoU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-to-many Approach for Improving Super-Resolution. (arXiv:2106.10437v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Sieun Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_E/0/1/0/all/0/1">Eunho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10437">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been discussions on the ill-posed nature of
super-resolution that multiple possible reconstructions exist for a given
low-resolution image. Using normalizing flows, SRflow[23] achieves
state-of-the-art perceptual quality by learning the distribution of the output
instead of a deterministic output to one estimate. In this paper, we adapt the
concepts of SRFlow to improve GAN-based super-resolution by properly
implementing the one-to-many property. We modify the generator to estimate a
distribution as a mapping from random noise. We improve the content loss that
hampers the perceptual training objectives. We also propose additional training
techniques to further enhance the perceptual quality of generated images. Using
our proposed methods, we were able to improve the performance of ESRGAN[1] in
x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16 perceptual
extreme SR by applying our methods to RFB-ESRGAN[21].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VariTex: Variational Neural Face Textures. (arXiv:2104.05988v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Buhler_M/0/1/0/all/0/1">Marcel C. B&#xfc;hler</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1">Abhimitra Meka</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gengyan Li</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Beeler_T/0/1/0/all/0/1">Thabo Beeler</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a> (1) ((1) ETH Zurich, (2) Google)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05988">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models can synthesize photorealistic images of human faces
with novel identities. However, a key challenge to the wide applicability of
such techniques is to provide independent control over semantically meaningful
parameters: appearance, head pose, face shape, and facial expressions. In this
paper, we propose VariTex - to the best of our knowledge the first method that
learns a variational latent feature space of neural face textures, which allows
sampling of novel identities. We combine this generative model with a
parametric face model and gain explicit control over head pose and facial
expressions. To generate complete images of human heads, we propose an additive
decoder that adds plausible details such as hair. A novel training scheme
enforces a pose-independent latent space and in consequence, allows learning a
one-to-many mapping between latent codes and pose-conditioned exterior regions.
The resulting method can generate geometrically consistent images of novel
identities under fine-grained control over head pose, face shape, and facial
expressions. This facilitates a broad range of downstream tasks, like sampling
novel identities, changing the head pose, expression transfer, and more. Code
and models are available for research on https://mcbuehler.github.io/VariTex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The surprising impact of mask-head architecture on novel class segmentation. (arXiv:2104.00613v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Birodkar_V/0/1/0/all/0/1">Vighnesh Birodkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhichao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathod_V/0/1/0/all/0/1">Vivek Rathod</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jonathan Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00613">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation models today are very accurate when trained on large
annotated datasets, but collecting mask annotations at scale is prohibitively
expensive. We address the partially supervised instance segmentation problem in
which one can train on (significantly cheaper) bounding boxes for all
categories but use masks only for a subset of categories. In this work, we
focus on a popular family of models which apply differentiable cropping to a
feature map and predict a mask based on the resulting crop. Under this family,
we study Mask R-CNN and discover that instead of its default strategy of
training the mask-head with a combination of proposals and groundtruth boxes,
training the mask-head with only groundtruth boxes dramatically improves its
performance on novel classes. This training strategy also allows us to take
advantage of alternative mask-head architectures, which we exploit by replacing
the typical mask-head of 2-4 layers with significantly deeper off-the-shelf
architectures (e.g. ResNet, Hourglass models). While many of these
architectures perform similarly when trained in fully supervised mode, our main
finding is that they can generalize to novel classes in dramatically different
ways. We call this ability of mask-heads to generalize to unseen classes the
strong mask generalization effect and show that without any specialty modules
or losses, we can achieve state-of-the-art results in the partially supervised
COCO instance segmentation benchmark. Finally, we demonstrate that our effect
is general, holding across underlying detection methodologies (including
anchor-based, anchor-free or no detector at all) and across different backbone
networks. Code and pre-trained models are available at https://git.io/deepmac.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniT: Multimodal Multitask Learning with a Unified Transformer. (arXiv:2102.10772v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Ronghang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amanpreet Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10772">
                                    <div class="article-summary-box-inner">
                                        <span>We propose UniT, a Unified Transformer model to simultaneously learn the most
prominent tasks across different domains, ranging from object detection to
natural language understanding and multimodal reasoning. Based on the
transformer encoder-decoder architecture, our UniT model encodes each input
modality with an encoder and makes predictions on each task with a shared
decoder over the encoded input representations, followed by task-specific
output heads. The entire model is jointly trained end-to-end with losses from
each task. Compared to previous efforts on multi-task learning with
transformers, we share the same model parameters across all tasks instead of
separately fine-tuning task-specific models and handle a much higher variety of
tasks across different domains. In our experiments, we learn 7 tasks jointly
over 8 datasets, achieving strong performance on each task with significantly
fewer parameters. Our code is available in MMF at https://mmf.sh.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Vision Transformers with Hierarchical Pooling. (arXiv:2103.10619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zizheng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Bohan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Haoyu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10619">
                                    <div class="article-summary-box-inner">
                                        <span>The recently proposed Visual image Transformers (ViT) with pure attention
have achieved promising performance on image recognition tasks, such as image
classification. However, the routine of the current ViT model is to maintain a
full-length patch sequence during inference, which is redundant and lacks
hierarchical representation. To this end, we propose a Hierarchical Visual
Transformer (HVT) which progressively pools visual tokens to shrink the
sequence length and hence reduces the computational cost, analogous to the
feature maps downsampling in Convolutional Neural Networks (CNNs). It brings a
great benefit that we can increase the model capacity by scaling dimensions of
depth/width/resolution/patch size without introducing extra computational
complexity due to the reduced sequence length. Moreover, we empirically find
that the average pooled visual tokens contain more discriminative information
than the single class token. To demonstrate the improved scalability of our
HVT, we conduct extensive experiments on the image classification task. With
comparable FLOPs, our HVT outperforms the competitive baselines on ImageNet and
CIFAR-100 datasets. Code is available at https://github.com/MonashAI/HVT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Articulated Radiance Field. (arXiv:2104.03110v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noguchi_A/0/1/0/all/0/1">Atsuhiro Noguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Stephen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1">Tatsuya Harada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03110">
                                    <div class="article-summary-box-inner">
                                        <span>We present Neural Articulated Radiance Field (NARF), a novel deformable 3D
representation for articulated objects learned from images. While recent
advances in 3D implicit representation have made it possible to learn models of
complex objects, learning pose-controllable representations of articulated
objects remains a challenge, as current methods require 3D shape supervision
and are unable to render appearance. In formulating an implicit representation
of 3D articulated objects, our method considers only the rigid transformation
of the most relevant object part in solving for the radiance field at each 3D
location. In this way, the proposed method represents pose-dependent changes
without significantly increasing the computational complexity. NARF is fully
differentiable and can be trained from images with pose annotations. Moreover,
through the use of an autoencoder, it can learn appearance variations over
multiple instances of an object class. Experiments show that the proposed
method is efficient and can generalize well to novel poses. The code is
available for research purposes at https://github.com/nogu-atsu/NARF</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Admix: Enhancing the Transferability of Adversarial Attacks. (arXiv:2102.00436v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaosen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuanran He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00436">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are known to be extremely vulnerable to adversarial
examples under white-box setting. Moreover, the malicious adversaries crafted
on the surrogate (source) model often exhibit black-box transferability on
other models with the same learning task but having different architectures.
Recently, various methods are proposed to boost the adversarial
transferability, among which the input transformation is one of the most
effective approaches. We investigate in this direction and observe that
existing transformations are all applied on a single image, which might limit
the adversarial transferability. To this end, we propose a new input
transformation based attack method called Admix that considers the input image
and a set of images randomly sampled from other categories. Instead of directly
calculating the gradient on the original input, Admix calculates the gradient
on the input image admixed with a small portion of each add-in image while
using the original label of the input to craft more transferable adversaries.
Empirical evaluations on standard ImageNet dataset demonstrate that Admix could
achieve significantly better transferability than existing input transformation
methods under both single model setting and ensemble-model setting. By
incorporating with existing input transformations, our method could further
improve the transferability and outperforms the state-of-the-art combination of
input transformations by a clear margin when attacking nine advanced defense
models under ensemble-model setting. Code is available at
https://github.com/JHL-HUST/Admix.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bifurcated backbone strategy for RGB-D salient object detection. (arXiv:2007.02713v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1">Yingjie Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jufeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1">Ali Borji</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junwei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02713">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-level feature fusion is a fundamental topic in computer vision. It has
been exploited to detect, segment and classify objects at various scales. When
multi-level features meet multi-modal cues, the optimal feature aggregation and
multi-modal learning strategy become a hot potato. In this paper, we leverage
the inherent multi-modal and multi-level nature of RGB-D salient object
detection to devise a novel cascaded refinement network. In particular, first,
we propose to regroup the multi-level features into teacher and student
features using a bifurcated backbone strategy (BBS). Second, we introduce a
depth-enhanced module (DEM) to excavate informative depth cues from the channel
and spatial views. Then, RGB and depth modalities are fused in a complementary
way. Our architecture, named Bifurcated Backbone Strategy Network (BBS-Net), is
simple, efficient, and backbone-independent. Extensive experiments show that
BBS-Net significantly outperforms eighteen SOTA models on eight challenging
datasets under five evaluation measures, demonstrating the superiority of our
approach ($\sim 4 \%$ improvement in S-measure $vs.$ the top-ranked model:
DMRA-iccv2019). In addition, we provide a comprehensive analysis on the
generalization ability of different RGB-D datasets and provide a powerful
training set for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Shift Equivariance Impacts Metric Learning for Instance Segmentation. (arXiv:2101.05846v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rumberger_J/0/1/0/all/0/1">Josef Lorenz Rumberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaoyan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirsch_P/0/1/0/all/0/1">Peter Hirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohmen_M/0/1/0/all/0/1">Melanie Dohmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guarino_V/0/1/0/all/0/1">Vanessa Emanuela Guarino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mokarian_A/0/1/0/all/0/1">Ashkan Mokarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Mais_L/0/1/0/all/0/1">Lisa Mais</a>, <a href="http://arxiv.org/find/cs/1/au:+Funke_J/0/1/0/all/0/1">Jan Funke</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainmueller_D/0/1/0/all/0/1">Dagmar Kainmueller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05846">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning has received conflicting assessments concerning its
suitability for solving instance segmentation tasks. It has been dismissed as
theoretically flawed due to the shift equivariance of the employed CNNs and
their respective inability to distinguish same-looking objects. Yet it has been
shown to yield state of the art results for a variety of tasks, and practical
issues have mainly been reported in the context of tile-and-stitch approaches,
where discontinuities at tile boundaries have been observed. To date, neither
of the reported issues have undergone thorough formal analysis. In our work, we
contribute a comprehensive formal analysis of the shift equivariance properties
of encoder-decoder-style CNNs, which yields a clear picture of what can and
cannot be achieved with metric learning in the face of same-looking objects. In
particular, we prove that a standard encoder-decoder network that takes
$d$-dimensional images as input, with $l$ pooling layers and pooling factor
$f$, has the capacity to distinguish at most $f^{dl}$ same-looking objects, and
we show that this upper limit can be reached. Furthermore, we show that to
avoid discontinuities in a tile-and-stitch approach, assuming standard batch
size 1, it is necessary to employ valid convolutions in combination with a
training output window size strictly greater than $f^l$, while at test-time it
is necessary to crop tiles to size $n\cdot f^l$ before stitching, with $n\geq
1$. We complement these theoretical findings by discussing a number of
insightful special cases for which we show empirical results on synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image. (arXiv:2012.09854v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Ronghang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_N/0/1/0/all/0/1">Nikhila Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_A/0/1/0/all/0/1">Alexander C. Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1">Deepak Pathak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09854">
                                    <div class="article-summary-box-inner">
                                        <span>We present Worldsheet, a method for novel view synthesis using just a single
RGB image as input. The main insight is that simply shrink-wrapping a planar
mesh sheet onto the input image, consistent with the learned intermediate
depth, captures underlying geometry sufficient to generate photorealistic
unseen views with large viewpoint changes. To operationalize this, we propose a
novel differentiable texture sampler that allows our wrapped mesh sheet to be
textured and rendered differentiably into an image from a target viewpoint. Our
approach is category-agnostic, end-to-end trainable without using any 3D
supervision, and requires a single image at test time. We also explore a simple
extension by stacking multiple layers of Worldsheets to better handle
occlusions. Worldsheet consistently outperforms prior state-of-the-art methods
on single-image view synthesis across several datasets. Furthermore, this
simple idea captures novel views surprisingly well on a wide range of
high-resolution in-the-wild images, converting them into navigable 3D pop-ups.
Video results and code are available at https://worldsheet.github.io.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Resize Images for Computer Vision Tasks. (arXiv:2103.09950v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Talebi_H/0/1/0/all/0/1">Hossein Talebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09950">
                                    <div class="article-summary-box-inner">
                                        <span>For all the ways convolutional neural nets have revolutionized computer
vision in recent years, one important aspect has received surprisingly little
attention: the effect of image size on the accuracy of tasks being trained for.
Typically, to be efficient, the input images are resized to a relatively small
spatial resolution (e.g. 224x224), and both training and inference are carried
out at this resolution. The actual mechanism for this re-scaling has been an
afterthought: Namely, off-the-shelf image resizers such as bilinear and bicubic
are commonly used in most machine learning software frameworks. But do these
resizers limit the on task performance of the trained networks? The answer is
yes. Indeed, we show that the typical linear resizer can be replaced with
learned resizers that can substantially improve performance. Importantly, while
the classical resizers typically result in better perceptual quality of the
downscaled images, our proposed learned resizers do not necessarily give better
visual quality, but instead improve task performance. Our learned image resizer
is jointly trained with a baseline vision model. This learned CNN-based resizer
creates machine friendly visual manipulations that lead to a consistent
improvement of the end task metric over the baseline model. Specifically, here
we focus on the classification task with the ImageNet dataset, and experiment
with four different models to learn resizers adapted to each model. Moreover,
we show that the proposed resizer can also be useful for fine-tuning the
classification baselines for other vision tasks. To this end, we experiment
with three different baselines to develop image quality assessment (IQA) models
on the AVA dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tasks Structure Regularization in Multi-Task Learning for Improving Facial Attribute Prediction. (arXiv:2108.04353v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taherkhani_F/0/1/0/all/0/1">Fariborz Taherkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabouei_A/0/1/0/all/0/1">Ali Dabouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04353">
                                    <div class="article-summary-box-inner">
                                        <span>The great success of Convolutional Neural Networks (CNN) for facial attribute
prediction relies on a large amount of labeled images. Facial image datasets
are usually annotated by some commonly used attributes (e.g., gender), while
labels for the other attributes (e.g., big nose) are limited which causes their
prediction challenging. To address this problem, we use a new Multi-Task
Learning (MTL) paradigm in which a facial attribute predictor uses the
knowledge of other related attributes to obtain a better generalization
performance. Here, we leverage MLT paradigm in two problem settings. First, it
is assumed that the structure of the tasks (e.g., grouping pattern of facial
attributes) is known as a prior knowledge, and parameters of the tasks (i.e.,
predictors) within the same group are represented by a linear combination of a
limited number of underlying basis tasks. Here, a sparsity constraint on the
coefficients of this linear combination is also considered such that each task
is represented in a more structured and simpler manner. Second, it is assumed
that the structure of the tasks is unknown, and then structure and parameters
of the tasks are learned jointly by using a Laplacian regularization framework.
Our MTL methods are compared with competing methods for facial attribute
prediction to show its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Search Space for Neural Architecture Search. (arXiv:2011.10904v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ci_Y/0/1/0/all/0/1">Yuanzheng Ci</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10904">
                                    <div class="article-summary-box-inner">
                                        <span>The automation of neural architecture design has been a coveted alternative
to human experts. Recent works have small search space, which is easier to
optimize but has a limited upper bound of the optimal solution. Extra human
design is needed for those methods to propose a more suitable space with
respect to the specific task and algorithm capacity. To further enhance the
degree of automation for neural architecture search, we present a Neural
Search-space Evolution (NSE) scheme that iteratively amplifies the results from
the previous effort by maintaining an optimized search space subset. This
design minimizes the necessity of a well-designed search space. We further
extend the flexibility of obtainable architectures by introducing a learnable
multi-branch setting. By employing the proposed method, a consistent
performance gain is achieved during a progressive search over upcoming search
spaces. We achieve 77.3% top-1 retrain accuracy on ImageNet with 333M FLOPs,
which yielded a state-of-the-art performance among previous auto-generated
architectures that do not involve knowledge distillation or weight pruning.
When the latency constraint is adopted, our result also performs better than
the previous best-performing mobile models with a 77.9% Top-1 retrain accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Target Candidate Association to Keep Track of What Not to Track. (arXiv:2103.16556v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mayer_C/0/1/0/all/0/1">Christoph Mayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Danelljan_M/0/1/0/all/0/1">Martin Danelljan</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudel_D/0/1/0/all/0/1">Danda Pani Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16556">
                                    <div class="article-summary-box-inner">
                                        <span>The presence of objects that are confusingly similar to the tracked target,
poses a fundamental challenge in appearance-based visual tracking. Such
distractor objects are easily misclassified as the target itself, leading to
eventual tracking failure. While most methods strive to suppress distractors
through more powerful appearance models, we take an alternative approach.

We propose to keep track of distractor objects in order to continue tracking
the target. To this end, we introduce a learned association network, allowing
us to propagate the identities of all target candidates from frame-to-frame. To
tackle the problem of lacking ground-truth correspondences between distractor
objects in visual tracking, we propose a training strategy that combines
partial annotations with self-supervision. We conduct comprehensive
experimental validation and analysis of our approach on several challenging
datasets. Our tracker sets a new state-of-the-art on six benchmarks, achieving
an AUC score of 67.1% on LaSOT and a +5.8% absolute gain on the OxUvA long-term
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning with Hyperspherical Uniformity. (arXiv:2103.01649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01649">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the over-parameterization nature, neural networks are a powerful tool
for nonlinear function approximation. In order to achieve good generalization
on unseen data, a suitable inductive bias is of great importance for neural
networks. One of the most straightforward ways is to regularize the neural
network with some additional objectives. L2 regularization serves as a standard
regularization for neural networks. Despite its popularity, it essentially
regularizes one dimension of the individual neuron, which is not strong enough
to control the capacity of highly over-parameterized neural networks. Motivated
by this, hyperspherical uniformity is proposed as a novel family of relational
regularizations that impact the interaction among neurons. We consider several
geometrically distinct ways to achieve hyperspherical uniformity. The
effectiveness of hyperspherical uniformity is justified by theoretical insights
and empirical evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Collation: Matching illustrations in manuscripts. (arXiv:2108.08109v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaoua_R/0/1/0/all/0/1">Ryad Kaoua</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Durr_A/0/1/0/all/0/1">Alexandra Durr</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazaris_S/0/1/0/all/0/1">Stavros Lazaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Picard_D/0/1/0/all/0/1">David Picard</a>, <a href="http://arxiv.org/find/cs/1/au:+Aubry_M/0/1/0/all/0/1">Mathieu Aubry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08109">
                                    <div class="article-summary-box-inner">
                                        <span>Illustrations are an essential transmission instrument. For an historian, the
first step in studying their evolution in a corpus of similar manuscripts is to
identify which ones correspond to each other. This image collation task is
daunting for manuscripts separated by many lost copies, spreading over
centuries, which might have been completely re-organized and greatly modified
to adapt to novel knowledge or belief and include hundreds of illustrations.
Our contributions in this paper are threefold. First, we introduce the task of
illustration collation and a large annotated public dataset to evaluate
solutions, including 6 manuscripts of 2 different texts with more than 2 000
illustrations and 1 200 annotated correspondences. Second, we analyze state of
the art similarity measures for this task and show that they succeed in simple
cases but struggle for large manuscripts when the illustrations have undergone
very significant changes and are discriminated only by fine details. Finally,
we show clear evidence that significant performance boosts can be expected by
exploiting cycle-consistent correspondences. Our code and data are available on
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-DARTS: Towards Stable Architecture Search. (arXiv:2108.08128v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_P/0/1/0/all/0/1">Pengfei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Ying Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yukang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08128">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) marks a milestone in Neural
Architecture Search (NAS), boasting simplicity and small search costs. However,
DARTS still suffers from frequent performance collapse, which happens when some
operations, such as skip connections, zeroes and poolings, dominate the
architecture. In this paper, we are the first to point out that the phenomenon
is attributed to bi-level optimization. We propose Single-DARTS which merely
uses single-level optimization, updating network weights and architecture
parameters simultaneously with the same data batch. Even single-level
optimization has been previously attempted, no literature provides a systematic
explanation on this essential point. Replacing the bi-level optimization,
Single-DARTS obviously alleviates performance collapse as well as enhances the
stability of architecture search. Experiment results show that Single-DARTS
achieves state-of-the-art performance on mainstream search spaces. For
instance, on NAS-Benchmark-201, the searched architectures are nearly optimal
ones. We also validate that the single-level optimization framework is much
more stable than the bi-level one. We hope that this simple yet effective
method will give some insights on differential architecture search. The code is
available at https://github.com/PencilAndBike/Single-DARTS.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Specificity-preserving RGB-D Saliency Detection. (arXiv:2108.08162v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Geng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08162">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-D saliency detection has attracted increasing attention, due to its
effectiveness and the fact that depth cues can now be conveniently captured.
Existing works often focus on learning a shared representation through various
fusion strategies, with few methods explicitly considering how to preserve
modality-specific characteristics. In this paper, taking a new perspective, we
propose a specificity-preserving network (SP-Net) for RGB-D saliency detection,
which benefits saliency detection performance by exploring both the shared
information and modality-specific properties (e.g., specificity). Specifically,
two modality-specific networks and a shared learning network are adopted to
generate individual and shared saliency maps. A cross-enhanced integration
module (CIM) is proposed to fuse cross-modal features in the shared learning
network, which are then propagated to the next layer for integrating
cross-level information. Besides, we propose a multi-modal feature aggregation
(MFA) module to integrate the modality-specific features from each individual
decoder into the shared decoder, which can provide rich complementary
multi-modal information to boost the saliency detection performance. Further, a
skip connection is used to combine hierarchical features between the encoder
and decoder layers. Experiments on six benchmark datasets demonstrate that our
SP-Net outperforms other state-of-the-art methods. Code is available at:
https://github.com/taozh2017/SPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting. (arXiv:2108.08165v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kukleva_A/0/1/0/all/0/1">Anna Kukleva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehne_H/0/1/0/all/0/1">Hilde Kuehne</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiele_B/0/1/0/all/0/1">Bernt Schiele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08165">
                                    <div class="article-summary-box-inner">
                                        <span>Both generalized and incremental few-shot learning have to deal with three
major challenges: learning novel classes from only few samples per class,
preventing catastrophic forgetting of base classes, and classifier calibration
across novel and base classes. In this work we propose a three-stage framework
that allows to explicitly and effectively address these challenges. While the
first phase learns base classes with many samples, the second phase learns a
calibrated classifier for novel classes from few samples while also preventing
catastrophic forgetting. In the final phase, calibration is achieved across all
classes. We evaluate the proposed framework on four challenging benchmark
datasets for image and video few-shot classification and obtain
state-of-the-art results for both generalized and incremental few shot
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gastric Cancer Detection from X-ray Images Using Effective Data Augmentation and Hard Boundary Box Training. (arXiv:2108.08158v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Okamoto_H/0/1/0/all/0/1">Hideaki Okamoto</a>, <a href="http://arxiv.org/find/eess/1/au:+Nomura_T/0/1/0/all/0/1">Takakiyo Nomura</a>, <a href="http://arxiv.org/find/eess/1/au:+Nabeshima_K/0/1/0/all/0/1">Kazuhito Nabeshima</a>, <a href="http://arxiv.org/find/eess/1/au:+Hashimoto_J/0/1/0/all/0/1">Jun Hashimoto</a>, <a href="http://arxiv.org/find/eess/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08158">
                                    <div class="article-summary-box-inner">
                                        <span>X-ray examination is suitable for screening of gastric cancer. Compared to
endoscopy, which can only be performed by doctors, X-ray imaging can also be
performed by radiographers, and thus, can treat more patients. However, the
diagnostic accuracy of gastric radiographs is as low as 85%. To address this
problem, highly accurate and quantitative automated diagnosis using machine
learning needs to be performed. This paper proposes a diagnostic support method
for detecting gastric cancer sites from X-ray images with high accuracy. The
two new technical proposal of the method are (1) stochastic functional gastric
image augmentation (sfGAIA), and (2) hard boundary box training (HBBT). The
former is a probabilistic enhancement of gastric folds in X-ray images based on
medical knowledge, whereas the latter is a recursive retraining technique to
reduce false positives. We use 4,724 gastric radiographs of 145 patients in
clinical practice and evaluate the cancer detection performance of the method
in a patient-based five-group cross-validation. The proposed sfGAIA and HBBT
significantly enhance the performance of the EfficientDet-D7 network by 5.9% in
terms of the F1-score, and our screening method reaches a practical screening
capability for gastric cancer (F1: 57.8%, recall: 90.2%, precision: 42.5%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning RAW-to-sRGB Mappings with Inaccurately Aligned Supervision. (arXiv:2108.08119v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhilu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haolin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruohao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1">Wangmeng Zuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08119">
                                    <div class="article-summary-box-inner">
                                        <span>Learning RAW-to-sRGB mapping has drawn increasing attention in recent years,
wherein an input raw image is trained to imitate the target sRGB image captured
by another camera. However, the severe color inconsistency makes it very
challenging to generate well-aligned training pairs of input raw and target
sRGB images. While learning with inaccurately aligned supervision is prone to
causing pixel shift and producing blurry results. In this paper, we circumvent
such issue by presenting a joint learning model for image alignment and
RAW-to-sRGB mapping. To diminish the effect of color inconsistency in image
alignment, we introduce to use a global color mapping (GCM) module to generate
an initial sRGB image given the input raw image, which can keep the spatial
location of the pixels unchanged, and the target sRGB image is utilized to
guide GCM for converting the color towards it. Then a pre-trained optical flow
estimation network (e.g., PWC-Net) is deployed to warp the target sRGB image to
align with the GCM output. To alleviate the effect of inaccurately aligned
supervision, the warped target sRGB image is leveraged to learn RAW-to-sRGB
mapping. When training is done, the GCM module and optical flow network can be
detached, thereby bringing no extra computation cost for inference. Experiments
show that our method performs favorably against state-of-the-arts on ZRR and
SR-RAW datasets. With our joint learning model, a light-weight backbone can
achieve better quantitative and qualitative performance on ZRR dataset. Codes
are available at https://github.com/cszhilu1998/RAW-to-sRGB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Observer Visual Problem-Solving Methods are Dynamically Hypothesized, Deployed and Tested. (arXiv:2108.08145v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Solbach_M/0/1/0/all/0/1">Markus D. Solbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1">John K. Tsotsos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08145">
                                    <div class="article-summary-box-inner">
                                        <span>The STAR architecture was designed to test the value of the full Selective
Tuning model of visual attention for complex real-world visuospatial tasks and
behaviors. However, knowledge of how humans solve such tasks in 3D as active
observers is lean. We thus devised a novel experimental setup and examined such
behavior. We discovered that humans exhibit a variety of problem-solving
strategies whose breadth and complexity are surprising and not easily handled
by current methodologies. It is apparent that solution methods are dynamically
composed by hypothesizing sequences of actions, testing them, and if they fail,
trying different ones. The importance of active observation is striking as is
the lack of any learning effect. These results inform our Cognitive Program
representation of STAR extending its relevance to real-world tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Anchor Active Domain Adaptation for Semantic Segmentation. (arXiv:2108.08012v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ning_M/0/1/0/all/0/1">Munan Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Donghuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1">Cheng Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Chenglang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shuang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08012">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaption has proven to be an effective approach for
alleviating the intensive workload of manual annotation by aligning the
synthetic source-domain data and the real-world target-domain samples.
Unfortunately, mapping the target-domain distribution to the source-domain
unconditionally may distort the essential structural information of the
target-domain data. To this end, we firstly propose to introduce a novel
multi-anchor based active learning strategy to assist domain adaptation
regarding the semantic segmentation task. By innovatively adopting multiple
anchors instead of a single centroid, the source domain can be better
characterized as a multimodal distribution, thus more representative and
complimentary samples are selected from the target domain. With little workload
to manually annotate these active samples, the distortion of the target-domain
distribution can be effectively alleviated, resulting in a large performance
gain. The multi-anchor strategy is additionally employed to model the
target-distribution. By regularizing the latent representation of the target
samples compact around multiple anchors through a novel soft alignment loss,
more precise segmentation can be achieved. Extensive experiments are conducted
on public datasets to demonstrate that the proposed approach outperforms
state-of-the-art methods significantly, along with thorough ablation study to
verify the effectiveness of each component.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRDrV3: Complete Lesion Detection in Fundus Images Using Mask R-CNN, Transfer Learning, and LSTM. (arXiv:2108.08095v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shenavarmasouleh_F/0/1/0/all/0/1">Farzan Shenavarmasouleh</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohammadi_F/0/1/0/all/0/1">Farid Ghareh Mohammadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Amini_M/0/1/0/all/0/1">M. Hadi Amini</a>, <a href="http://arxiv.org/find/eess/1/au:+Taha_T/0/1/0/all/0/1">Thiab Taha</a>, <a href="http://arxiv.org/find/eess/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>, <a href="http://arxiv.org/find/eess/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08095">
                                    <div class="article-summary-box-inner">
                                        <span>Medical Imaging is one of the growing fields in the world of computer vision.
In this study, we aim to address the Diabetic Retinopathy (DR) problem as one
of the open challenges in medical imaging. In this research, we propose a new
lesion detection architecture, comprising of two sub-modules, which is an
optimal solution to detect and find not only the type of lesions caused by DR,
their corresponding bounding boxes, and their masks; but also the severity
level of the overall case. Aside from traditional accuracy, we also use two
popular evaluation criteria to evaluate the outputs of our models, which are
intersection over union (IOU) and mean average precision (mAP). We hypothesize
that this new solution enables specialists to detect lesions with high
confidence and estimate the severity of the damage with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hand Hygiene Video Classification Based on Deep Learning. (arXiv:2108.08127v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1">Rashmi Bakshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08127">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, an extensive review of literature in the field of gesture
recognition carried out along with the implementation of a simple
classification system for hand hygiene stages based on deep learning solutions.
A subset of robust dataset that consist of handwashing gestures with two hands
as well as one-hand gestures such as linear hand movement utilized. A
pretrained neural network model, RES Net 50, with image net weights used for
the classification of 3 categories: Linear hand movement, rub hands palm to
palm and rub hands with fingers interlaced movement. Correct predictions made
for the first two classes with &gt; 60% accuracy. A complete dataset along with
increased number of classes and training steps will be explored as a future
work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Target Adaptive Context Aggregation for Video Scene Graph Generation. (arXiv:2108.08121v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1">Yao Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Gangshan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08121">
                                    <div class="article-summary-box-inner">
                                        <span>This paper deals with a challenging task of video scene graph generation
(VidSGG), which could serve as a structured video representation for high-level
understanding tasks. We present a new {\em detect-to-track} paradigm for this
task by decoupling the context modeling for relation prediction from the
complicated low-level entity tracking. Specifically, we design an efficient
method for frame-level VidSGG, termed as {\em Target Adaptive Context
Aggregation Network} (TRACE), with a focus on capturing spatio-temporal context
information for relation recognition. Our TRACE framework streamlines the
VidSGG pipeline with a modular design, and presents two unique blocks of
Hierarchical Relation Tree (HRTree) construction and Target-adaptive Context
Aggregation. More specific, our HRTree first provides an adpative structure for
organizing possible relation candidates efficiently, and guides context
aggregation module to effectively capture spatio-temporal structure
information. Then, we obtain a contextualized feature representation for each
relation candidate and build a classification head to recognize its relation
category. Finally, we provide a simple temporal association strategy to track
TRACE detected results to yield the video-level VidSGG. We perform experiments
on two VidSGG benchmarks: ImageNet-VidVRD and Action Genome, and the results
demonstrate that our TRACE achieves the state-of-the-art performance. The code
and models are made available at \url{https://github.com/MCG-NJU/TRACE}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Batch Incremental Road Object Detection via Detector Fusion. (arXiv:2108.08048v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tambwekar_A/0/1/0/all/0/1">Anuj Tambwekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_K/0/1/0/all/0/1">Kshitij Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Majee_A/0/1/0/all/0/1">Anay Majee</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1">Anbumani Subramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08048">
                                    <div class="article-summary-box-inner">
                                        <span>Incremental few-shot learning has emerged as a new and challenging area in
deep learning, whose objective is to train deep learning models using very few
samples of new class data, and none of the old class data. In this work we
tackle the problem of batch incremental few-shot road object detection using
data from the India Driving Dataset (IDD). Our approach, DualFusion, combines
object detectors in a manner that allows us to learn to detect rare objects
with very limited data, all without severely degrading the performance of the
detector on the abundant classes. In the IDD OpenSet incremental few-shot
detection task, we achieve a mAP50 score of 40.0 on the base classes and an
overall mAP50 score of 38.8, both of which are the highest to date. In the COCO
batch incremental few-shot detection task, we achieve a novel AP score of 9.9,
surpassing the state-of-the-art novel class performance on the same by over 6.6
times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Hybrid Self-Prior for Full 3D Mesh Generation. (arXiv:2108.08017v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xingkui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengqing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhaopeng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinda Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08017">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning pipeline that leverages network self-prior to
recover a full 3D model consisting of both a triangular mesh and a texture map
from the colored 3D point cloud. Different from previous methods either
exploiting 2D self-prior for image editing or 3D self-prior for pure surface
reconstruction, we propose to exploit a novel hybrid 2D-3D self-prior in deep
neural networks to significantly improve the geometry quality and produce a
high-resolution texture map, which is typically missing from the output of
commodity-level 3D scanners. In particular, we first generate an initial mesh
using a 3D convolutional neural network with 3D self-prior, and then encode
both 3D information and color information in the 2D UV atlas, which is further
refined by 2D convolutional neural networks with the self-prior. In this way,
both 2D and 3D self-priors are utilized for the mesh and texture recovery.
Experiments show that, without the need of any additional training data, our
method recovers the 3D textured mesh model of high quality from sparse input,
and outperforms the state-of-the-art methods in terms of both the geometry and
texture quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Outdoor Architecture Reconstruction by Exploration and Classification. (arXiv:2108.07990v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fuyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nauata_N/0/1/0/all/0/1">Nelson Nauata</a>, <a href="http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1">Yasutaka Furukawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07990">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an explore-and-classify framework for structured
architectural reconstruction from an aerial image. Starting from a potentially
imperfect building reconstruction by an existing algorithm, our approach 1)
explores the space of building models by modifying the reconstruction via
heuristic actions; 2) learns to classify the correctness of building models
while generating classification labels based on the ground-truth, and 3)
repeat. At test time, we iterate exploration and classification, seeking for a
result with the best classification score. We evaluate the approach using
initial reconstructions by two baselines and two state-of-the-art
reconstruction algorithms. Qualitative and quantitative evaluations demonstrate
that our approach consistently improves the reconstruction quality from every
initial reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbiased IoU for Spherical Image Object Detection. (arXiv:2108.08029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yike Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1">Bailan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chenggang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_F/0/1/0/all/0/1">Feng Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08029">
                                    <div class="article-summary-box-inner">
                                        <span>As one of the most fundamental and challenging problems in computer vision,
object detection tries to locate object instances and find their categories in
natural images. The most important step in the evaluation of object detection
algorithm is calculating the intersection-over-union (IoU) between the
predicted bounding box and the ground truth one. Although this procedure is
well-defined and solved for planar images, it is not easy for spherical image
object detection. Existing methods either compute the IoUs based on biased
bounding box representations or make excessive approximations, thus would give
incorrect results. In this paper, we first identify that spherical rectangles
are unbiased bounding boxes for objects in spherical images, and then propose
an analytical method for IoU calculation without any approximations. Based on
the unbiased representation and calculation, we also present an anchor free
object detection algorithm for spherical images. The experiments on two
spherical object detection datasets show that the proposed method can achieve
better performance than existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Attention: Propagating Domain-Specific Knowledge for Multi-Domain Learning in Crowd Counting. (arXiv:2108.08023v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Binghui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhaoyi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pengyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Biao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1">Wangmeng Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08023">
                                    <div class="article-summary-box-inner">
                                        <span>In crowd counting, due to the problem of laborious labelling, it is perceived
intractability of collecting a new large-scale dataset which has plentiful
images with large diversity in density, scene, etc. Thus, for learning a
general model, training with data from multiple different datasets might be a
remedy and be of great value. In this paper, we resort to the multi-domain
joint learning and propose a simple but effective Domain-specific Knowledge
Propagating Network (DKPNet)1 for unbiasedly learning the knowledge from
multiple diverse data domains at the same time. It is mainly achieved by
proposing the novel Variational Attention(VA) technique for explicitly modeling
the attention distributions for different domains. And as an extension to VA,
Intrinsic Variational Attention(InVA) is proposed to handle the problems of
over-lapped domains and sub-domains. Extensive experiments have been conducted
to validate the superiority of our DKPNet over several popular datasets,
including ShanghaiTech A/B, UCF-QNRF and NWPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Image Generation with Infinite Generative Adversarial Networks. (arXiv:2108.07975v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ying_H/0/1/0/all/0/1">Hui Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_T/0/1/0/all/0/1">Tianjia Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kun Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07975">
                                    <div class="article-summary-box-inner">
                                        <span>Image generation has been heavily investigated in computer vision, where one
core research challenge is to generate images from arbitrarily complex
distributions with little supervision. Generative Adversarial Networks (GANs)
as an implicit approach have achieved great successes in this direction and
therefore been employed widely. However, GANs are known to suffer from issues
such as mode collapse, non-structured latent space, being unable to compute
likelihoods, etc. In this paper, we propose a new unsupervised non-parametric
method named mixture of infinite conditional GANs or MIC-GANs, to tackle
several GAN issues together, aiming for image generation with parsimonious
prior knowledge. Through comprehensive evaluations across different datasets,
we show that MIC-GANs are effective in structuring the latent space and
avoiding mode collapse, and outperform state-of-the-art methods. MICGANs are
adaptive, versatile, and robust. They offer a promising solution to several
well-known GAN issues. Code available: github.com/yinghdb/MICGANs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Panoramic Depth Estimation via Supervised and Unsupervised Learning in Indoor Scenes. (arXiv:2108.08076v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Keyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaiwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08076">
                                    <div class="article-summary-box-inner">
                                        <span>Depth estimation, as a necessary clue to convert 2D images into the 3D space,
has been applied in many machine vision areas. However, to achieve an entire
surrounding 360-degree geometric sensing, traditional stereo matching
algorithms for depth estimation are limited due to large noise, low accuracy,
and strict requirements for multi-camera calibration. In this work, for a
unified surrounding perception, we introduce panoramic images to obtain larger
field of view. We extend PADENet first appeared in our previous conference work
for outdoor scene understanding, to perform panoramic monocular depth
estimation with a focus for indoor scenes. At the same time, we improve the
training process of the neural network adapted to the characteristics of
panoramic images. In addition, we fuse traditional stereo matching algorithm
with deep learning methods and further improve the accuracy of depth
predictions. With a comprehensive variety of experiments, this research
demonstrates the effectiveness of our schemes aiming for indoor scene
perception.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Channel-Temporal Attention for First-Person Video Domain Adaptation. (arXiv:2108.07846v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1">Tao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07846">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) can transfer knowledge from labeled
source data to unlabeled target data of the same categories. However, UDA for
first-person action recognition is an under-explored problem, with lack of
datasets and limited consideration of first-person video characteristics. This
paper focuses on addressing this problem. Firstly, we propose two small-scale
first-person video domain adaptation datasets: ADL$_{small}$ and GTEA-KITCHEN.
Secondly, we introduce channel-temporal attention blocks to capture the
channel-wise and temporal-wise relationships and model their inter-dependencies
important to first-person vision. Finally, we propose a Channel-Temporal
Attention Network (CTAN) to integrate these blocks into existing architectures.
CTAN outperforms baselines on the two proposed datasets and one existing
dataset EPIC$_{cvpr20}$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SynFace: Face Recognition with Synthetic Data. (arXiv:2108.07960v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1">Haibo Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Baosheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1">Dihong Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07960">
                                    <div class="article-summary-box-inner">
                                        <span>With the recent success of deep neural networks, remarkable progress has been
achieved on face recognition. However, collecting large-scale real-world
training data for face recognition has turned out to be challenging, especially
due to the label noise and privacy issues. Meanwhile, existing face recognition
datasets are usually collected from web images, lacking detailed annotations on
attributes (e.g., pose and expression), so the influences of different
attributes on face recognition have been poorly investigated. In this paper, we
address the above-mentioned issues in face recognition using synthetic face
images, i.e., SynFace. Specifically, we first explore the performance gap
between recent state-of-the-art face recognition models trained with synthetic
and real face images. We then analyze the underlying causes behind the
performance gap, e.g., the poor intra-class variations and the domain gap
between synthetic and real face images. Inspired by this, we devise the SynFace
with identity mixup (IM) and domain mixup (DM) to mitigate the above
performance gap, demonstrating the great potentials of synthetic data for face
recognition. Furthermore, with the controllable face synthesis model, we can
easily manage different factors of synthetic face generation, including pose,
expression, illumination, the number of identities, and samples per identity.
Therefore, we also perform a systematically empirical analysis on synthetic
face images to provide some insights on how to effectively utilize synthetic
data for face recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WRICNet:A Weighted Rich-scale Inception Coder Network for Multi-Resolution Remote Sensing Image Change Detection. (arXiv:2108.07955v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongmei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07955">
                                    <div class="article-summary-box-inner">
                                        <span>Majority models of remote sensing image changing detection can only get great
effect in a specific resolution data set. With the purpose of improving change
detection effectiveness of the model in the multi-resolution data set, a
weighted rich-scale inception coder network (WRICNet) is proposed in this
article, which can make a great fusion of shallow multi-scale features, and
deep multi-scale features. The weighted rich-scale inception module of the
proposed can obtain shallow multi-scale features, the weighted rich-scale coder
module can obtain deep multi-scale features. The weighted scale block assigns
appropriate weights to features of different scales, which can strengthen
expressive ability of the edge of the changing area. The performance
experiments on the multi-resolution data set demonstrate that, compared to the
comparative methods, the proposed can further reduce the false alarm outside
the change area, and the missed alarm in the change area, besides, the edge of
the change area is more accurate. The ablation study of the proposed shows that
the training strategy, and improvements of this article can improve the
effectiveness of change detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Convolutions with Per-pixel Dynamic Filter Atom. (arXiv:2108.07895v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ze Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_Z/0/1/0/all/0/1">Zichen Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jun Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Q/0/1/0/all/0/1">Qiang Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07895">
                                    <div class="article-summary-box-inner">
                                        <span>Applying feature dependent network weights have been proved to be effective
in many fields. However, in practice, restricted by the enormous size of model
parameters and memory footprints, scalable and versatile dynamic convolutions
with per-pixel adapted filters are yet to be fully explored. In this paper, we
address this challenge by decomposing filters, adapted to each spatial
position, over dynamic filter atoms generated by a light-weight network from
local features. Adaptive receptive fields can be supported by further
representing each filter atom over sets of pre-fixed multi-scale bases. As
plug-and-play replacements to convolutional layers, the introduced adaptive
convolutions with per-pixel dynamic atoms enable explicit modeling of
intra-image variance, while avoiding heavy computation, parameters, and memory
cost. Our method preserves the appealing properties of conventional
convolutions as being translation-equivariant and parametrically efficient. We
present experiments to show that, the proposed method delivers comparable or
even better performance across tasks, and are particularly effective on
handling tasks with significant intra-image variance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Visual Representations Learning by Contrastive Mask Prediction. (arXiv:2108.07954v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yucheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zheng-Jun Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07954">
                                    <div class="article-summary-box-inner">
                                        <span>Advanced self-supervised visual representation learning methods rely on the
instance discrimination (ID) pretext task. We point out that the ID task has an
implicit semantic consistency (SC) assumption, which may not hold in
unconstrained datasets. In this paper, we propose a novel contrastive mask
prediction (CMP) task for visual representation learning and design a mask
contrast (MaskCo) framework to implement the idea. MaskCo contrasts
region-level features instead of view-level features, which makes it possible
to identify the positive sample without any assumptions. To solve the domain
gap between masked and unmasked features, we design a dedicated mask prediction
head in MaskCo. This module is shown to be the key to the success of the CMP.
We evaluated MaskCo on training datasets beyond ImageNet and compare its
performance with MoCo V2. Results show that MaskCo achieves comparable
performance with MoCo V2 using ImageNet training dataset, but demonstrates a
stronger performance across a range of downstream tasks when COCO or Conceptual
Captions are used for training. MaskCo provides a promising alternative to the
ID-based methods for self-supervised learning in the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Journey from SDRTV to HDRTV. (arXiv:2108.07978v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwen Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Ren_J/0/1/0/all/0/1">Jimmy S. Ren</a>, <a href="http://arxiv.org/find/eess/1/au:+Tian_L/0/1/0/all/0/1">Lynhoo Tian</a>, <a href="http://arxiv.org/find/eess/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07978">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays modern displays are capable to render video content with high
dynamic range (HDR) and wide color gamut (WCG). However, most available
resources are still in standard dynamic range (SDR). Therefore, there is an
urgent demand to transform existing SDR-TV contents into their HDR-TV versions.
In this paper, we conduct an analysis of SDRTV-to-HDRTV task by modeling the
formation of SDRTV/HDRTV content. Base on the analysis, we propose a three-step
solution pipeline including adaptive global color mapping, local enhancement
and highlight generation. Moreover, the above analysis inspires us to present a
lightweight network that utilizes global statistics as guidance to conduct
image-adaptive color mapping. In addition, we construct a dataset using HDR
videos in HDR10 standard, named HDRTV1K, and select five metrics to evaluate
the results of SDRTV-to-HDRTV algorithms. Furthermore, our final results
achieve state-of-the-art performance in quantitative comparisons and visual
quality. The code and dataset are available at
https://github.com/chxy95/HDRTVNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-task learning for jersey number recognition in Ice Hockey. (arXiv:2108.07848v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vats_K/0/1/0/all/0/1">Kanav Vats</a>, <a href="http://arxiv.org/find/cs/1/au:+Fani_M/0/1/0/all/0/1">Mehrnaz Fani</a>, <a href="http://arxiv.org/find/cs/1/au:+Clausi_D/0/1/0/all/0/1">David A. Clausi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelek_J/0/1/0/all/0/1">John Zelek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07848">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying players in sports videos by recognizing their jersey numbers is a
challenging task in computer vision. We have designed and implemented a
multi-task learning network for jersey number recognition. In order to train a
network to recognize jersey numbers, two output label representations are used
(1) Holistic - considers the entire jersey number as one class, and (2)
Digit-wise - considers the two digits in a jersey number as two separate
classes. The proposed network learns both holistic and digit-wise
representations through a multi-task loss function. We determine the optimal
weights to be assigned to holistic and digit-wise losses through an ablation
study. Experimental results demonstrate that the proposed multi-task learning
network performs better than the constituent holistic and digit-wise
single-task learning networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OncoPetNet: A Deep Learning based AI system for mitotic figure counting on H&amp;E stained whole slide digital images in a large veterinary diagnostic lab setting. (arXiv:2108.07856v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fitzke_M/0/1/0/all/0/1">Michael Fitzke</a>, <a href="http://arxiv.org/find/eess/1/au:+Whitley_D/0/1/0/all/0/1">Derick Whitley</a>, <a href="http://arxiv.org/find/eess/1/au:+Yau_W/0/1/0/all/0/1">Wilson Yau</a>, <a href="http://arxiv.org/find/eess/1/au:+Rodrigues_F/0/1/0/all/0/1">Fernando Rodrigues Jr</a>, <a href="http://arxiv.org/find/eess/1/au:+Fadeev_V/0/1/0/all/0/1">Vladimir Fadeev</a>, <a href="http://arxiv.org/find/eess/1/au:+Bacmeister_C/0/1/0/all/0/1">Cindy Bacmeister</a>, <a href="http://arxiv.org/find/eess/1/au:+Carter_C/0/1/0/all/0/1">Chris Carter</a>, <a href="http://arxiv.org/find/eess/1/au:+Edwards_J/0/1/0/all/0/1">Jeffrey Edwards</a>, <a href="http://arxiv.org/find/eess/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/eess/1/au:+Parkinson_M/0/1/0/all/0/1">Mark Parkinson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07856">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Histopathology is an important modality for the diagnosis and
management of many diseases in modern healthcare, and plays a critical role in
cancer care. Pathology samples can be large and require multi-site sampling,
leading to upwards of 20 slides for a single tumor, and the human-expert tasks
of site selection and and quantitative assessment of mitotic figures are time
consuming and subjective. Automating these tasks in the setting of a digital
pathology service presents significant opportunities to improve workflow
efficiency and augment human experts in practice. Approach: Multiple
state-of-the-art deep learning techniques for histopathology image
classification and mitotic figure detection were used in the development of
OncoPetNet. Additionally, model-free approaches were used to increase speed and
accuracy. The robust and scalable inference engine leverages Pytorch&#x27;s
performance optimizations as well as specifically developed speed up techniques
in inference. Results: The proposed system, demonstrated significantly improved
mitotic counting performance for 41 cancer cases across 14 cancer types
compared to human expert baselines. In 21.9% of cases use of OncoPetNet led to
change in tumor grading compared to human expert evaluation. In deployment, an
effective 0.27 min/slide inference was achieved in a high throughput veterinary
diagnostic pathology service across 2 centers processing 3,323 digital whole
slide images daily. Conclusion: This work represents the first successful
automated deployment of deep learning systems for real-time expert-level
performance on important histopathology tasks at scale in a high volume
clinical practice. The resulting impact outlines important considerations for
model development, deployment, clinical decision making, and informs best
practices for implementation of deep learning systems in digital histopathology
practices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Warp Consistency for Unsupervised Learning of Dense Correspondences. (arXiv:2104.03308v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Truong_P/0/1/0/all/0/1">Prune Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Danelljan_M/0/1/0/all/0/1">Martin Danelljan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fisher Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03308">
                                    <div class="article-summary-box-inner">
                                        <span>The key challenge in learning dense correspondences lies in the lack of
ground-truth matches for real image pairs. While photometric consistency losses
provide unsupervised alternatives, they struggle with large appearance changes,
which are ubiquitous in geometric and semantic matching tasks. Moreover,
methods relying on synthetic training pairs often suffer from poor
generalisation to real data.

We propose Warp Consistency, an unsupervised learning objective for dense
correspondence regression. Our objective is effective even in settings with
large appearance and view-point changes. Given a pair of real images, we first
construct an image triplet by applying a randomly sampled warp to one of the
original images. We derive and analyze all flow-consistency constraints arising
between the triplet. From our observations and empirical results, we design a
general unsupervised objective employing two of the derived constraints. We
validate our warp consistency loss by training three recent dense
correspondence networks for the geometric and semantic matching tasks. Our
approach sets a new state-of-the-art on several challenging benchmarks,
including MegaDepth, RobotCar and TSS. Code and models are at
github.com/PruneTruong/DenseMatching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation. (arXiv:2107.13467v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yubin Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Pengyi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13467">
                                    <div class="article-summary-box-inner">
                                        <span>The unsupervised domain adaptation (UDA) has been widely adopted to alleviate
the data scalability issue, while the existing works usually focus on
classifying independently discrete labels. However, in many tasks (e.g.,
medical diagnosis), the labels are discrete and successively distributed. The
UDA for ordinal classification requires inducing non-trivial ordinal
distribution prior to the latent space. Target for this, the partially ordered
set (poset) is defined for constraining the latent vector. Instead of the
typically i.i.d. Gaussian latent prior, in this work, a recursively conditional
Gaussian (RCG) set is adapted for ordered constraint modeling, which admits a
tractable joint distribution prior. Furthermore, we are able to control the
density of content vector that violates the poset constraints by a simple
&quot;three-sigma rule&quot;. We explicitly disentangle the cross-domain images into a
shared ordinal prior induced ordinal content space and two separate
source/target ordinal-unrelated spaces, and the self-training is worked on the
shared space exclusively for ordinal-aware domain alignment. Extensive
experiments on UDA medical diagnoses and facial age estimation demonstrate its
effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Focus for Efficient Video Recognition. (arXiv:2105.03245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhaoxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haojun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yizeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03245">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the spatial redundancy in video recognition with
the aim to improve the computational efficiency. It is observed that the most
informative region in each frame of a video is usually a small image patch,
which shifts smoothly across frames. Therefore, we model the patch localization
problem as a sequential decision task, and propose a reinforcement learning
based approach for efficient spatially adaptive video recognition (AdaFocus).
In specific, a light-weighted ConvNet is first adopted to quickly process the
full video sequence, whose features are used by a recurrent policy network to
localize the most task-relevant regions. Then the selected patches are inferred
by a high-capacity network for the final prediction. During offline inference,
once the informative patch sequence has been generated, the bulk of computation
can be done in parallel, and is efficient on modern GPU devices. In addition,
we demonstrate that the proposed method can be easily extended by further
considering the temporal redundancy, e.g., dynamically skipping less valuable
frames. Extensive experiments on five benchmark datasets, i.e., ActivityNet,
FCVID, Mini-Kinetics, Something-Something V1&amp;V2, demonstrate that our method is
significantly more efficient than the competitive baselines. Code is available
at https://github.com/blackfeather-wang/AdaFocus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RANK-NOSH: Efficient Predictor-Based Architecture Search via Non-Uniform Successive Halving. (arXiv:2108.08019v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruochen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Minhao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08019">
                                    <div class="article-summary-box-inner">
                                        <span>Predictor-based algorithms have achieved remarkable performance in the Neural
Architecture Search (NAS) tasks. However, these methods suffer from high
computation costs, as training the performance predictor usually requires
training and evaluating hundreds of architectures from scratch. Previous works
along this line mainly focus on reducing the number of architectures required
to fit the predictor. In this work, we tackle this challenge from a different
perspective - improve search efficiency by cutting down the computation budget
of architecture training. We propose NOn-uniform Successive Halving (NOSH), a
hierarchical scheduling algorithm that terminates the training of
underperforming architectures early to avoid wasting budget. To effectively
leverage the non-uniform supervision signals produced by NOSH, we formulate
predictor-based architecture search as learning to rank with pairwise
comparisons. The resulting method - RANK-NOSH, reduces the search budget by ~5x
while achieving competitive or even better performance than previous
state-of-the-art predictor-based methods on various spaces and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deployment of Deep Neural Networks for Object Detection on Edge AI Devices with Runtime Optimization. (arXiv:2108.08166v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stacker_L/0/1/0/all/0/1">Lukas St&#xe4;cker</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_J/0/1/0/all/0/1">Juncong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidenreich_P/0/1/0/all/0/1">Philipp Heidenreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonarens_F/0/1/0/all/0/1">Frank Bonarens</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambach_J/0/1/0/all/0/1">Jason Rambach</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08166">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have proven increasingly important for automotive scene
understanding with new algorithms offering constant improvements of the
detection performance. However, there is little emphasis on experiences and
needs for deployment in embedded environments. We therefore perform a case
study of the deployment of two representative object detection networks on an
edge AI platform. In particular, we consider RetinaNet for image-based 2D
object detection and PointPillars for LiDAR-based 3D object detection. We
describe the modifications necessary to convert the algorithms from a PyTorch
training environment to the deployment environment taking into account the
available tools. We evaluate the runtime of the deployed DNN using two
different libraries, TensorRT and TorchScript. In our experiments, we observe
slight advantages of TensorRT for convolutional layers and TorchScript for
fully connected layers. We also study the trade-off between runtime and
performance, when selecting an optimized setup for deployment, and observe that
quantization significantly reduces the runtime while having only little impact
on the detection performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effect of Parameter Optimization on Classical and Learning-based Image Matching Methods. (arXiv:2108.08179v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Efe_U/0/1/0/all/0/1">Ufuk Efe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ince_K/0/1/0/all/0/1">Kutalmis Gokalp Ince</a>, <a href="http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1">A. Aydin Alatan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08179">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based image matching methods are improved significantly during
the recent years. Although these methods are reported to outperform the
classical techniques, the performance of the classical methods is not examined
in detail. In this study, we compare classical and learning-based methods by
employing mutual nearest neighbor search with ratio test and optimizing the
ratio test threshold to achieve the best performance on two different
performance metrics. After a fair comparison, the experimental results on
HPatches dataset reveal that the performance gap between classical and
learning-based methods is not that significant. Throughout the experiments, we
demonstrated that SuperGlue is the state-of-the-art technique for the image
matching problem on HPatches dataset. However, if a single parameter, namely
ratio test threshold, is carefully optimized, a well-known traditional method
SIFT performs quite close to SuperGlue and even outperforms in terms of mean
matching accuracy (MMA) under 1 and 2 pixel thresholds. Moreover, a recent
approach, DFM, which only uses pre-trained VGG features as descriptors and
ratio test, is shown to outperform most of the well-trained learning-based
methods. Therefore, we conclude that the parameters of any classical method
should be analyzed carefully before comparing against a learning-based
technique.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Activity Recognition for Autism Diagnosis. (arXiv:2108.07917v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lakkapragada_A/0/1/0/all/0/1">Anish Lakkapragada</a>, <a href="http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1">Peter Washington</a>, <a href="http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1">Dennis Wall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07917">
                                    <div class="article-summary-box-inner">
                                        <span>A formal autism diagnosis is an inefficient and lengthy process. Families
often have to wait years before receiving a diagnosis for their child; some may
not receive one at all due to this delay. One approach to this problem is to
use digital technologies to detect the presence of behaviors related to autism,
which in aggregate may lead to remote and automated diagnostics. One of the
strongest indicators of autism is stimming, which is a set of repetitive,
self-stimulatory behaviors such as hand flapping, headbanging, and spinning.
Using computer vision to detect hand flapping is especially difficult due to
the sparsity of public training data in this space and excessive shakiness and
motion in such data. Our work demonstrates a novel method that overcomes these
issues: we use hand landmark detection over time as a feature representation
which is then fed into a Long Short-Term Memory (LSTM) model. We achieve a
validation accuracy and F1 Score of about 72% on detecting whether videos from
the Self-Stimulatory Behaviour Dataset (SSBD) contain hand flapping or not. Our
best model also predicts accurately on external videos we recorded of ourselves
outside of the dataset it was trained on. This model uses less than 26,000
parameters, providing promise for fast deployment into ubiquitous and wearable
digital settings for a remote autism diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ALLNet: A Hybrid Convolutional Neural Network to Improve Diagnosis of Acute Lymphocytic Leukemia (ALL) in White Blood Cells. (arXiv:2108.08195v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mattapalli_S/0/1/0/all/0/1">Sai Mattapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Athavale_R/0/1/0/all/0/1">Rishi Athavale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08195">
                                    <div class="article-summary-box-inner">
                                        <span>Due to morphological similarity at the microscopic level, making an accurate
and time-sensitive distinction between blood cells affected by Acute
Lymphocytic Leukemia (ALL) and their healthy counterparts calls for the usage
of machine learning architectures. However, three of the most common models,
VGG, ResNet, and Inception, each come with their own set of flaws with room for
improvement which demands the need for a superior model. ALLNet, the proposed
hybrid convolutional neural network architecture, consists of a combination of
the VGG, ResNet, and Inception models. The ALL Challenge dataset of ISBI 2019
(available here) contains 10,691 images of white blood cells which were used to
train and test the models. 7,272 of the images in the dataset are of cells with
ALL and 3,419 of them are of healthy cells. Of the images, 60% were used to
train the model, 20% were used for the cross-validation set, and 20% were used
for the test set. ALLNet outperformed the VGG, ResNet, and the Inception models
across the board, achieving an accuracy of 92.6567%, a sensitivity of 95.5304%,
a specificity of 85.9155%, an AUC score of 0.966347, and an F1 score of 0.94803
in the cross-validation set. In the test set, ALLNet achieved an accuracy of
92.0991%, a sensitivity of 96.5446%, a specificity of 82.8035%, an AUC score of
0.959972, and an F1 score of 0.942963. The utilization of ALLNet in the
clinical workspace can better treat the thousands of people suffering from ALL
across the world, many of whom are children.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thermal Image Processing via Physics-Inspired Deep Networks. (arXiv:2108.07973v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saragadam_V/0/1/0/all/0/1">Vishwanath Saragadam</a>, <a href="http://arxiv.org/find/eess/1/au:+Dave_A/0/1/0/all/0/1">Akshat Dave</a>, <a href="http://arxiv.org/find/eess/1/au:+Veeraraghavan_A/0/1/0/all/0/1">Ashok Veeraraghavan</a>, <a href="http://arxiv.org/find/eess/1/au:+Baraniuk_R/0/1/0/all/0/1">Richard Baraniuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07973">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce DeepIR, a new thermal image processing framework that combines
physically accurate sensor modeling with deep network-based image
representation. Our key enabling observations are that the images captured by
thermal sensors can be factored into slowly changing, scene-independent sensor
non-uniformities (that can be accurately modeled using physics) and a
scene-specific radiance flux (that is well-represented using a deep
network-based regularizer). DeepIR requires neither training data nor periodic
ground-truth calibration with a known black body target--making it well suited
for practical computer vision tasks. We demonstrate the power of going DeepIR
by developing new denoising and super-resolution algorithms that exploit
multiple images of the scene captured with camera jitter. Simulated and real
data experiments demonstrate that DeepIR can perform high-quality
non-uniformity correction with as few as three images, achieving a 10dB PSNR
improvement over competing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ME-PCN: Point Completion Conditioned on Mask Emptiness. (arXiv:2108.08187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Bingchen Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yinyu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yiqun Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaoguang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yizhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08187">
                                    <div class="article-summary-box-inner">
                                        <span>Point completion refers to completing the missing geometries of an object
from incomplete observations. Main-stream methods predict the missing shapes by
decoding a global feature learned from the input point cloud, which often leads
to deficient results in preserving topology consistency and surface details. In
this work, we present ME-PCN, a point completion network that leverages
&#x60;emptiness&#x27; in 3D shape space. Given a single depth scan, previous methods
often encode the occupied partial shapes while ignoring the empty regions (e.g.
holes) in depth maps. In contrast, we argue that these &#x60;emptiness&#x27; clues
indicate shape boundaries that can be used to improve topology representation
and detail granularity on surfaces. Specifically, our ME-PCN encodes both the
occupied point cloud and the neighboring &#x60;empty points&#x27;. It estimates
coarse-grained but complete and reasonable surface points in the first stage,
followed by a refinement stage to produce fine-grained surface details.
Comprehensive experiments verify that our ME-PCN presents better qualitative
and quantitative performance against the state-of-the-art. Besides, we further
prove that our &#x60;emptiness&#x27; design is lightweight and easy to embed in existing
methods, which shows consistent effectiveness in improving the CD and EMD
scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning. (arXiv:2108.07938v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenxu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yifan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_S/0/1/0/all/0/1">Saifeng Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Budagavi_M/0/1/0/all/0/1">Madhukar Budagavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaohu Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07938">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a talking face generation method that takes an
audio signal as input and a short target video clip as reference, and
synthesizes a photo-realistic video of the target face with natural lip
motions, head poses, and eye blinks that are in-sync with the input audio
signal. We note that the synthetic face attributes include not only explicit
ones such as lip motions that have high correlations with speech, but also
implicit ones such as head poses and eye blinks that have only weak correlation
with the input audio. To model such complicated relationships among different
face attributes with input audio, we propose a FACe Implicit Attribute Learning
Generative Adversarial Network (FACIAL-GAN), which integrates the
phonetics-aware, context-aware, and identity-aware information to synthesize
the 3D face animation with realistic motions of lips, head poses, and eye
blinks. Then, our Rendering-to-Video network takes the rendered face images and
the attention map of eye blinks as input to generate the photo-realistic output
video frames. Experimental results and user studies show our method can
generate realistic talking face videos with not only synchronized lip motions,
but also natural head movements and eye blinks, with better qualities than the
results of state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unmanned Aerial Vehicle Visual Detection and Tracking using Deep Neural Networks: A Performance Benchmark. (arXiv:2103.13933v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isaac_Medina_B/0/1/0/all/0/1">Brian K. S. Isaac-Medina</a>, <a href="http://arxiv.org/find/cs/1/au:+Poyser_M/0/1/0/all/0/1">Matt Poyser</a>, <a href="http://arxiv.org/find/cs/1/au:+Organisciak_D/0/1/0/all/0/1">Daniel Organisciak</a>, <a href="http://arxiv.org/find/cs/1/au:+Willcocks_C/0/1/0/all/0/1">Chris G. Willcocks</a>, <a href="http://arxiv.org/find/cs/1/au:+Breckon_T/0/1/0/all/0/1">Toby P. Breckon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13933">
                                    <div class="article-summary-box-inner">
                                        <span>Unmanned Aerial Vehicles (UAV) can pose a major risk for aviation safety, due
to both negligent and malicious use. For this reason, the automated detection
and tracking of UAV is a fundamental task in aerial security systems. Common
technologies for UAV detection include visible-band and thermal infrared
imaging, radio frequency and radar. Recent advances in deep neural networks
(DNNs) for image-based object detection open the possibility to use visual
information for this detection and tracking task. Furthermore, these detection
architectures can be implemented as backbones for visual tracking systems,
thereby enabling persistent tracking of UAV incursions. To date, no
comprehensive performance benchmark exists that applies DNNs to visible-band
imagery for UAV detection and tracking. To this end, three datasets with varied
environmental conditions for UAV detection and tracking, comprising a total of
241 videos (331,486 images), are assessed using four detection architectures
and three tracking frameworks. The best performing detector architecture
obtains an mAP of 98.6% and the best performing tracking framework obtains a
MOTA of 96.3%. Cross-modality evaluation is carried out between visible and
infrared spectrums, achieving a maximal 82.8% mAP on visible images when
training in the infrared modality. These results provide the first public
multi-approach benchmark for state-of-the-art deep learning-based methods and
give insight into which detection and tracking architectures are effective in
the UAV domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signal2Image Modules in Deep Neural Networks for EEG Classification. (arXiv:1904.13216v5 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bizopoulos_P/0/1/0/all/0/1">Paschalis Bizopoulos</a>, <a href="http://arxiv.org/find/eess/1/au:+Lambrou_G/0/1/0/all/0/1">George I Lambrou</a>, <a href="http://arxiv.org/find/eess/1/au:+Koutsouris_D/0/1/0/all/0/1">Dimitrios Koutsouris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.13216">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has revolutionized computer vision utilizing the increased
availability of big data and the power of parallel computational units such as
graphical processing units. The vast majority of deep learning research is
conducted using images as training data, however the biomedical domain is rich
in physiological signals that are used for diagnosis and prediction problems.
It is still an open research question how to best utilize signals to train deep
neural networks.

In this paper we define the term Signal2Image (S2Is) as trainable or
non-trainable prefix modules that convert signals, such as
Electroencephalography (EEG), to image-like representations making them
suitable for training image-based deep neural networks defined as &#x60;base
models&#x27;. We compare the accuracy and time performance of four S2Is (&#x60;signal as
image&#x27;, spectrogram, one and two layer Convolutional Neural Networks (CNNs))
combined with a set of &#x60;base models&#x27; (LeNet, AlexNet, VGGnet, ResNet, DenseNet)
along with the depth-wise and 1D variations of the latter. We also provide
empirical evidence that the one layer CNN S2I performs better in eleven out of
fifteen tested models than non-trainable S2Is for classifying EEG signals and
we present visual comparisons of the outputs of the S2Is.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptive 3D Detection with Multi-Level Consistency. (arXiv:2107.11355v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhipeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Changqing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11355">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based 3D object detection has achieved unprecedented success
with the advent of large-scale autonomous driving datasets. However, drastic
performance degradation remains a critical challenge for cross-domain
deployment. In addition, existing 3D domain adaptive detection methods often
assume prior access to the target domain annotations, which is rarely feasible
in the real world. To address this challenge, we study a more realistic
setting, unsupervised 3D domain adaptive detection, which only utilizes source
domain annotations. 1) We first comprehensively investigate the major
underlying factors of the domain gap in 3D detection. Our key insight is that
geometric mismatch is the key factor of domain shift. 2) Then, we propose a
novel and unified framework, Multi-Level Consistency Network (MLC-Net), which
employs a teacher-student paradigm to generate adaptive and reliable
pseudo-targets. MLC-Net exploits point-, instance- and neural statistics-level
consistency to facilitate cross-domain transfer. Extensive experiments
demonstrate that MLC-Net outperforms existing state-of-the-art methods
(including those using additional target domain information) on standard
benchmarks. Notably, our approach is detector-agnostic, which achieves
consistent gains on both single- and two-stage 3D detectors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M-ar-K-Fast Independent Component Analysis. (arXiv:2108.07908v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parisi_L/0/1/0/all/0/1">Luca Parisi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07908">
                                    <div class="article-summary-box-inner">
                                        <span>This study presents the m-arcsinh Kernel (&#x27;m-ar-K&#x27;) Fast Independent
Component Analysis (&#x27;FastICA&#x27;) method (&#x27;m-ar-K-FastICA&#x27;) for feature
extraction. The kernel trick has enabled dimensionality reduction techniques to
capture a higher extent of non-linearity in the data; however, reproducible,
open-source kernels to aid with feature extraction are still limited and may
not be reliable when projecting features from entropic data. The m-ar-K
function, freely available in Python and compatible with its open-source
library &#x27;scikit-learn&#x27;, is hereby coupled with FastICA to achieve more reliable
feature extraction in presence of a high extent of randomness in the data,
reducing the need for pre-whitening. Different classification tasks were
considered, as related to five (N &#x3D; 5) open access datasets of various degrees
of information entropy, available from scikit-learn and the University
California Irvine (UCI) Machine Learning repository. Experimental results
demonstrate improvements in the classification performance brought by the
proposed feature extraction. The novel m-ar-K-FastICA dimensionality reduction
approach is compared to the &#x27;FastICA&#x27; gold standard method, supporting its
higher reliability and computational efficiency, regardless of the underlying
uncertainty in the data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TAM: Temporal Adaptive Module for Video Recognition. (arXiv:2005.06803v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhaoyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wayne Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chen Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06803">
                                    <div class="article-summary-box-inner">
                                        <span>Video data is with complex temporal dynamics due to various factors such as
camera motion, speed variation, and different activities. To effectively
capture this diverse motion pattern, this paper presents a new temporal
adaptive module ({\bf TAM}) to generate video-specific temporal kernels based
on its own feature map. TAM proposes a unique two-level adaptive modeling
scheme by decoupling the dynamic kernel into a location sensitive importance
map and a location invariant aggregation weight. The importance map is learned
in a local temporal window to capture short-term information, while the
aggregation weight is generated from a global view with a focus on long-term
structure. TAM is a modular block and could be integrated into 2D CNNs to yield
a powerful video architecture (TANet) with a very small extra computational
cost. The extensive experiments on Kinetics-400 and Something-Something
datasets demonstrate that our TAM outperforms other temporal modeling methods
consistently, and achieves the state-of-the-art performance under the similar
complexity. The code is available at \url{
https://github.com/liu-zhy/temporal-adaptive-module}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometric Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2103.16694v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guizilini_V/0/1/0/all/0/1">Vitor Guizilini</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambrus_R/0/1/0/all/0/1">Rares Ambrus</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16694">
                                    <div class="article-summary-box-inner">
                                        <span>Simulators can efficiently generate large amounts of labeled synthetic data
with perfect supervision for hard-to-label tasks like semantic segmentation.
However, they introduce a domain gap that severely hurts real-world
performance. We propose to use self-supervised monocular depth estimation as a
proxy task to bridge this gap and improve sim-to-real unsupervised domain
adaptation (UDA). Our Geometric Unsupervised Domain Adaptation method (GUDA)
learns a domain-invariant representation via a multi-task objective combining
synthetic semantic supervision with real-world geometric constraints on videos.
GUDA establishes a new state of the art in UDA for semantic segmentation on
three benchmarks, outperforming methods that use domain adversarial learning,
self-training, or other self-supervised proxy tasks. Furthermore, we show that
our method scales well with the quality and quantity of synthetic data while
also improving depth prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Self-Discrepancy via Multiple Co-teaching for Cross-Domain Person Re-Identification. (arXiv:2104.02265v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_S/0/1/0/all/0/1">Suncheng Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yuzhuo Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_M/0/1/0/all/0/1">Mengyuan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02265">
                                    <div class="article-summary-box-inner">
                                        <span>Employing clustering strategy to assign unlabeled target images with pseudo
labels has become a trend for person re-identification (re-ID) algorithms in
domain adaptation. A potential limitation of these clustering-based methods is
that they always tend to introduce noisy labels, which will undoubtedly hamper
the performance of our re-ID system. To handle this limitation, an intuitive
solution is to utilize collaborative training to purify the pseudo label
quality. However, there exists a challenge that the complementarity of two
networks, which inevitably share a high similarity, becomes weakened gradually
as training process goes on; worse still, these approaches typically ignore to
consider the self-discrepancy of intra-class relations. To address this issue,
in this paper, we propose a multiple co-teaching framework for domain adaptive
person re-ID, opening up a promising direction about self-discrepancy problem
under unsupervised condition. On top of that, a mean-teaching mechanism is
leveraged to enlarge the difference and discover more complementary features.
Comprehensive experiments conducted on several large-scale datasets show that
our method achieves competitive performance compared with the
state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GyroFlow: Gyroscope-Guided Unsupervised Optical Flow Learning. (arXiv:2103.13725v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haipeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1">Kunming Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuaicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13725">
                                    <div class="article-summary-box-inner">
                                        <span>Existing optical flow methods are erroneous in challenging scenes, such as
fog, rain, and night because the basic optical flow assumptions such as
brightness and gradient constancy are broken. To address this problem, we
present an unsupervised learning approach that fuses gyroscope into optical
flow learning. Specifically, we first convert gyroscope readings into motion
fields named gyro field. Second, we design a self-guided fusion module to fuse
the background motion extracted from the gyro field with the optical flow and
guide the network to focus on motion details. To the best of our knowledge,
this is the first deep learning-based framework that fuses gyroscope data and
image content for optical flow learning. To validate our method, we propose a
new dataset that covers regular and challenging scenes. Experiments show that
our method outperforms the state-of-art methods in both regular and challenging
scenes. Code and dataset are available at
https://github.com/megvii-research/GyroFlow.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Alignment Constraint for Continuous Sign Language Recognition. (arXiv:2104.02330v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1">Yuecong Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_A/0/1/0/all/0/1">Aiming Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_X/0/1/0/all/0/1">Xiujuan Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xilin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02330">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-based Continuous Sign Language Recognition (CSLR) aims to recognize
unsegmented signs from image streams. Overfitting is one of the most critical
problems in CSLR training, and previous works show that the iterative training
scheme can partially solve this problem while also costing more training time.
In this study, we revisit the iterative training scheme in recent CSLR works
and realize that sufficient training of the feature extractor is critical to
solving the overfitting problem. Therefore, we propose a Visual Alignment
Constraint (VAC) to enhance the feature extractor with alignment supervision.
Specifically, the proposed VAC comprises two auxiliary losses: one focuses on
visual features only, and the other enforces prediction alignment between the
feature extractor and the alignment module. Moreover, we propose two metrics to
reflect overfitting by measuring the prediction inconsistency between the
feature extractor and the alignment module. Experimental results on two
challenging CSLR datasets show that the proposed VAC makes CSLR networks
end-to-end trainable and achieves competitive performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Unpaired Shape Transforming Method for Image Translation and Cross-Domain Retrieval. (arXiv:1812.02134v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaili Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Liqian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Oramas_J/0/1/0/all/0/1">Jose Oramas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1">Tinne Tuytelaars</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.02134">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of unpaired geometric image-to-image translation.
Rather than transferring the style of an image as a whole, our goal is to
translate the geometry of an object as depicted in different domains while
preserving its appearance characteristics. Our model is trained in an unpaired
fashion, i.e. without the need of paired images during training. It performs
all steps of the shape transfer within a single model and without additional
post-processing stages. Extensive experiments on the VITON, CMU-Multi-PIE and
our own FashionStyle datasets show the effectiveness of the method. In
addition, we show that despite their low-dimensionality, the features learned
by our model are useful to the item retrieval task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn-to-Race: A Multimodal Control Environment for Autonomous Racing. (arXiv:2103.11575v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herman_J/0/1/0/all/0/1">James Herman</a>, <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">Jonathan Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bingqing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhinav Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Skabelkin_A/0/1/0/all/0/1">Alexey Skabelkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhukov_I/0/1/0/all/0/1">Ivan Zhukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumskoy_M/0/1/0/all/0/1">Max Kumskoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Nyberg_E/0/1/0/all/0/1">Eric Nyberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11575">
                                    <div class="article-summary-box-inner">
                                        <span>Existing research on autonomous driving primarily focuses on urban driving,
which is insufficient for characterising the complex driving behaviour
underlying high-speed racing. At the same time, existing racing simulation
frameworks struggle in capturing realism, with respect to visual rendering,
vehicular dynamics, and task objectives, inhibiting the transfer of learning
agents to real-world contexts. We introduce a new environment, where agents
Learn-to-Race (L2R) in simulated competition-style racing, using multimodal
information--from virtual cameras to a comprehensive array of inertial
measurement sensors. Our environment, which includes a simulator and an
interfacing training framework, accurately models vehicle dynamics and racing
conditions. In this paper, we release the Arrival simulator for autonomous
racing. Next, we propose the L2R task with challenging metrics, inspired by
learning-to-drive challenges, Formula-style racing, and multimodal trajectory
prediction for autonomous driving. Additionally, we provide the L2R framework
suite, facilitating simulated racing on high-precision models of real-world
tracks. Finally, we provide an official L2R task dataset of expert
demonstrations, as well as a series of baseline experiments and reference
implementations. We make all code available:
https://github.com/learn-to-race/l2r.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Masked Face Recognition Challenge: The InsightFace Track Report. (arXiv:2108.08191v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiankang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jia Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+An_X/0/1/0/all/0/1">Xiang An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08191">
                                    <div class="article-summary-box-inner">
                                        <span>During the COVID-19 coronavirus epidemic, almost everyone wears a facial
mask, which poses a huge challenge to deep face recognition. In this workshop,
we organize Masked Face Recognition (MFR) challenge and focus on bench-marking
deep face recognition methods under the existence of facial masks. In the MFR
challenge, there are two main tracks: the InsightFace track and the WebFace260M
track. For the InsightFace track, we manually collect a large-scale masked face
test set with 7K identities. In addition, we also collect a children test set
including 14K identities and a multi-racial test set containing 242K
identities. By using these three test sets, we build up an online model testing
system, which can give a comprehensive evaluation of face recognition models.
To avoid data privacy problems, no test image is released to the public. As the
challenge is still under-going, we will keep on updating the top-ranked
solutions as well as this report on the arxiv.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Scene-Aware Motion Prediction. (arXiv:2108.08284v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1">Mohamed Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceylan_D/0/1/0/all/0/1">Duygu Ceylan</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_R/0/1/0/all/0/1">Ruben Villegas</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_J/0/1/0/all/0/1">Jun Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jimei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael Black</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08284">
                                    <div class="article-summary-box-inner">
                                        <span>A long-standing goal in computer vision is to capture, model, and
realistically synthesize human behavior. Specifically, by learning from data,
our goal is to enable virtual humans to navigate within cluttered indoor scenes
and naturally interact with objects. Such embodied behavior has applications in
virtual reality, computer games, and robotics, while synthesized behavior can
be used as a source of training data. This is challenging because real human
motion is diverse and adapts to the scene. For example, a person can sit or lie
on a sofa in many places and with varying styles. It is necessary to model this
diversity when synthesizing virtual humans that realistically perform
human-scene interactions. We present a novel data-driven, stochastic motion
synthesis method that models different styles of performing a given action with
a target object. Our method, called SAMP, for Scene-Aware Motion Prediction,
generalizes to target objects of various geometries while enabling the
character to navigate in cluttered scenes. To train our method, we collected
MoCap data covering various sitting, lying down, walking, and running styles.
We demonstrate our method on complex indoor scenes and achieve superior
performance compared to existing solutions. Our code and data are available for
research at https://samp.is.tue.mpg.de.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Motion Basis Learning for Unsupervised Deep Homography Estimation with Subspace Projection. (arXiv:2103.15346v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1">Nianjin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Haoqiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuaicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15346">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a new framework for unsupervised deep homography
estimation. Our contributions are 3 folds. First, unlike previous methods that
regress 4 offsets for a homography, we propose a homography flow
representation, which can be estimated by a weighted sum of 8 pre-defined
homography flow bases. Second, considering a homography contains 8
Degree-of-Freedoms (DOFs) that is much less than the rank of the network
features, we propose a Low Rank Representation (LRR) block that reduces the
feature rank, so that features corresponding to the dominant motions are
retained while others are rejected. Last, we propose a Feature Identity Loss
(FIL) to enforce the learned image feature warp-equivariant, meaning that the
result should be identical if the order of warp operation and feature
extraction is swapped. With this constraint, the unsupervised optimization is
achieved more effectively and more stable features are learned. Extensive
experiments are conducted to demonstrate the effectiveness of all the newly
proposed components, and results show that our approach outperforms the
state-of-the-art on the homography benchmark datasets both qualitatively and
quantitatively. Code is available at
https://github.com/megvii-research/BasesHomo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Disparity. (arXiv:2108.07939v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Ynjiun Paul Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07939">
                                    <div class="article-summary-box-inner">
                                        <span>Most of stereo vision works are focusing on computing the dense pixel
disparity of a given pair of left and right images. A camera pair usually
required lens undistortion and stereo calibration to provide an undistorted
epipolar line calibrated image pair for accurate dense pixel disparity
computation. Due to noise, object occlusion, repetitive or lack of texture and
limitation of matching algorithms, the pixel disparity accuracy usually suffers
the most at those object boundary areas. Although statistically the total
number of pixel disparity errors might be low (under 2% according to the Kitti
Vision Benchmark of current top ranking algorithms), the percentage of these
disparity errors at object boundaries are very high. This renders the
subsequence 3D object distance detection with much lower accuracy than desired.
This paper proposed a different approach for solving a 3D object distance
detection by detecting object disparity directly without going through a dense
pixel disparity computation. An example squeezenet Object Disparity-SSD
(OD-SSD) was constructed to demonstrate an efficient object disparity detection
with comparable accuracy compared with Kitti dataset pixel disparity ground
truth. Further training and testing results with mixed image dataset captured
by several different stereo systems may suggest that an OD-SSD might be
agnostic to stereo system parameters such as a baseline, FOV, lens distortion,
even left/right camera epipolar line misalignment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Bidirectional Unsupervised Domain Adaptation Segmentation Framework. (arXiv:2108.07979v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ning_M/0/1/0/all/0/1">Munan Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1">Cheng Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Chenglang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaohua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07979">
                                    <div class="article-summary-box-inner">
                                        <span>Domain shift happens in cross-domain scenarios commonly because of the wide
gaps between different domains: when applying a deep learning model
well-trained in one domain to another target domain, the model usually performs
poorly. To tackle this problem, unsupervised domain adaptation (UDA) techniques
are proposed to bridge the gap between different domains, for the purpose of
improving model performance without annotation in the target domain.
Particularly, UDA has a great value for multimodal medical image analysis,
where annotation difficulty is a practical concern. However, most existing UDA
methods can only achieve satisfactory improvements in one adaptation direction
(e.g., MRI to CT), but often perform poorly in the other (CT to MRI), limiting
their practical usage. In this paper, we propose a bidirectional UDA (BiUDA)
framework based on disentangled representation learning for equally competent
two-way UDA performances. This framework employs a unified domain-aware pattern
encoder which not only can adaptively encode images in different domains
through a domain controller, but also improve model efficiency by eliminating
redundant parameters. Furthermore, to avoid distortion of contents and patterns
of input images during the adaptation process, a content-pattern consistency
loss is introduced. Additionally, for better UDA segmentation performance, a
label consistency strategy is proposed to provide extra supervision by
recomposing target-domain-styled images and corresponding source-domain
annotations. Comparison experiments and ablation studies conducted on two
public datasets demonstrate the superiority of our BiUDA framework to current
state-of-the-art UDA methods and the effectiveness of its novel designs. By
successfully addressing two-way adaptations, our BiUDA framework offers a
flexible solution of UDA techniques to the real-world scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech Drives Templates: Co-Speech Gesture Synthesis with Learned Templates. (arXiv:2108.08020v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1">Shenhan Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhi Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_Y/0/1/0/all/0/1">YiHao Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shenghua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08020">
                                    <div class="article-summary-box-inner">
                                        <span>Co-speech gesture generation is to synthesize a gesture sequence that not
only looks real but also matches with the input speech audio. Our method
generates the movements of a complete upper body, including arms, hands, and
the head. Although recent data-driven methods achieve great success, challenges
still exist, such as limited variety, poor fidelity, and lack of objective
metrics. Motivated by the fact that the speech cannot fully determine the
gesture, we design a method that learns a set of gesture template vectors to
model the latent conditions, which relieve the ambiguity. For our method, the
template vector determines the general appearance of a generated gesture
sequence, while the speech audio drives subtle movements of the body, both
indispensable for synthesizing a realistic gesture sequence. Due to the
intractability of an objective metric for gesture-speech synchronization, we
adopt the lip-sync error as a proxy metric to tune and evaluate the
synchronization ability of our model. Extensive experiments show the
superiority of our method in both objective and subjective evaluations on
fidelity and synchronization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Graph Convolution for Point Cloud Analysis. (arXiv:2108.08035v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Haoran Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yidan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Mingsheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1">Mingqiang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08035">
                                    <div class="article-summary-box-inner">
                                        <span>Convolution on 3D point clouds that generalized from 2D grid-like domains is
widely researched yet far from perfect. The standard convolution characterises
feature correspondences indistinguishably among 3D points, presenting an
intrinsic limitation of poor distinctive feature learning. In this paper, we
propose Adaptive Graph Convolution (AdaptConv) which generates adaptive kernels
for points according to their dynamically learned features. Compared with using
a fixed/isotropic kernel, AdaptConv improves the flexibility of point cloud
convolutions, effectively and precisely capturing the diverse relations between
points from different semantic parts. Unlike popular attentional weight
schemes, the proposed AdaptConv implements the adaptiveness inside the
convolution operation instead of simply assigning different weights to the
neighboring points. Extensive qualitative and quantitative evaluations show
that our method outperforms state-of-the-art point cloud classification and
segmentation approaches on several benchmark datasets. Our code is available at
https://github.com/hrzhou2/AdaptConv-master.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Pooling, More than Meets the Eye: Position Information is Encoded Channel-Wise in CNNs. (arXiv:2108.07884v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md Amirul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowal_M/0/1/0/all/0/1">Matthew Kowal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1">Sen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Derpanis_K/0/1/0/all/0/1">Konstantinos G. Derpanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruce_N/0/1/0/all/0/1">Neil D. B. Bruce</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07884">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we challenge the common assumption that collapsing the spatial
dimensions of a 3D (spatial-channel) tensor in a convolutional neural network
(CNN) into a vector via global pooling removes all spatial information.
Specifically, we demonstrate that positional information is encoded based on
the ordering of the channel dimensions, while semantic information is largely
not. Following this demonstration, we show the real world impact of these
findings by applying them to two applications. First, we propose a simple yet
effective data augmentation strategy and loss function which improves the
translation invariance of a CNN&#x27;s output. Second, we propose a method to
efficiently determine which channels in the latent representation are
responsible for (i) encoding overall position information or (ii)
region-specific positions. We first show that semantic segmentation has a
significant reliance on the overall position channels to make predictions. We
then show for the first time that it is possible to perform a &#x60;region-specific&#x27;
attack, and degrade a network&#x27;s performance in a particular part of the input.
We believe our findings and demonstrated applications will benefit research
areas concerned with understanding the characteristics of CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calibration Method of the Monocular Omnidirectional Stereo Camera. (arXiv:2108.07936v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kawamata_R/0/1/0/all/0/1">Ryota Kawamata</a>, <a href="http://arxiv.org/find/eess/1/au:+Betsui_K/0/1/0/all/0/1">Keiichi Betsui</a>, <a href="http://arxiv.org/find/eess/1/au:+Yamazaki_K/0/1/0/all/0/1">Kazuyoshi Yamazaki</a>, <a href="http://arxiv.org/find/eess/1/au:+Sakakibara_R/0/1/0/all/0/1">Rei Sakakibara</a>, <a href="http://arxiv.org/find/eess/1/au:+Shimano_T/0/1/0/all/0/1">Takeshi Shimano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07936">
                                    <div class="article-summary-box-inner">
                                        <span>Compact and low-cost devices are needed for autonomous driving to image and
measure distances to objects 360-degree around. We have been developing an
omnidirectional stereo camera exploiting two hyperbolic mirrors and a single
set of a lens and sensor, which makes this camera compact and cost efficient.
We establish a new calibration method for this camera considering higher-order
radial distortion, detailed tangential distortion, an image sensor tilt, and a
lens-mirror offset. Our method reduces the calibration error by 6.0 and 4.3
times for the upper- and lower-view images, respectively. The random error of
the distance measurement is 4.9% and the systematic error is 5.7% up to objects
14 meters apart, which is improved almost nine times compared to the
conventional method. The remaining distance errors is due to a degraded optical
resolution of the prototype, which we plan to make further improvements as
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PLAD: A Dataset for Multi-Size Power Line Assets Detection in High-Resolution UAV Images. (arXiv:2108.07944v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vieira_e_Silva_A/0/1/0/all/0/1">Andr&#xe9; Luiz Buarque Vieira-e-Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Felix_H/0/1/0/all/0/1">Heitor de Castro Felix</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaves_T/0/1/0/all/0/1">Thiago de Menezes Chaves</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1">Francisco Paulo Magalh&#xe3;es Sim&#xf5;es</a>, <a href="http://arxiv.org/find/cs/1/au:+Teichrieb_V/0/1/0/all/0/1">Veronica Teichrieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1">Michel Mozinho dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Santiago_H/0/1/0/all/0/1">Hemir da Cunha Santiago</a>, <a href="http://arxiv.org/find/cs/1/au:+Sgotti_V/0/1/0/all/0/1">Virginia Ad&#xe9;lia Cordeiro Sgotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Neto_H/0/1/0/all/0/1">Henrique Baptista Duffles Teixeira Lott Neto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07944">
                                    <div class="article-summary-box-inner">
                                        <span>Many power line companies are using UAVs to perform their inspection
processes instead of putting their workers at risk by making them climb high
voltage power line towers, for instance. A crucial task for the inspection is
to detect and classify assets in the power transmission lines. However, public
data related to power line assets are scarce, preventing a faster evolution of
this area. This work proposes the Power Line Assets Dataset, containing
high-resolution and real-world images of multiple high-voltage power line
components. It has 2,409 annotated objects divided into five classes:
transmission tower, insulator, spacer, tower plate, and Stockbridge damper,
which vary in size (resolution), orientation, illumination, angulation, and
background. This work also presents an evaluation with popular deep object
detection methods, showing considerable room for improvement. The PLAD dataset
is publicly available at https://github.com/andreluizbvs/PLAD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimising Knee Injury Detection with Spatial Attention and Validating Localisation Ability. (arXiv:2108.08136v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belton_N/0/1/0/all/0/1">Niamh Belton</a>, <a href="http://arxiv.org/find/cs/1/au:+Welaratne_I/0/1/0/all/0/1">Ivan Welaratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahlan_A/0/1/0/all/0/1">Adil Dahlan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hearne_R/0/1/0/all/0/1">Ronan T Hearne</a>, <a href="http://arxiv.org/find/cs/1/au:+Hagos_M/0/1/0/all/0/1">Misgina Tsighe Hagos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawlor_A/0/1/0/all/0/1">Aonghus Lawlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Curran_K/0/1/0/all/0/1">Kathleen M. Curran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08136">
                                    <div class="article-summary-box-inner">
                                        <span>This work employs a pre-trained, multi-view Convolutional Neural Network
(CNN) with a spatial attention block to optimise knee injury detection. An
open-source Magnetic Resonance Imaging (MRI) data set with image-level labels
was leveraged for this analysis. As MRI data is acquired from three planes, we
compare our technique using data from a single-plane and multiple planes
(multi-plane). For multi-plane, we investigate various methods of fusing the
planes in the network. This analysis resulted in the novel &#x27;MPFuseNet&#x27; network
and state-of-the-art Area Under the Curve (AUC) scores for detecting Anterior
Cruciate Ligament (ACL) tears and Abnormal MRIs, achieving AUC scores of 0.977
and 0.957 respectively. We then developed an objective metric, Penalised
Localisation Accuracy (PLA), to validate the model&#x27;s localisation ability. This
metric compares binary masks generated from Grad-Cam output and the
radiologist&#x27;s annotations on a sample of MRIs. We also extracted explainability
features in a model-agnostic approach that were then verified as clinically
relevant by the radiologist.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARCH++: Animation-Ready Clothed Human Reconstruction Revisited. (arXiv:2108.07845v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuanlu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_S/0/1/0/all/0/1">Shunsuke Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_T/0/1/0/all/0/1">Tony Tung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07845">
                                    <div class="article-summary-box-inner">
                                        <span>We present ARCH++, an image-based method to reconstruct 3D avatars with
arbitrary clothing styles. Our reconstructed avatars are animation-ready and
highly realistic, in both the visible regions from input views and the unseen
regions. While prior work shows great promise of reconstructing animatable
clothed humans with various topologies, we observe that there exist fundamental
limitations resulting in sub-optimal reconstruction quality. In this paper, we
revisit the major steps of image-based avatar reconstruction and address the
limitations with ARCH++. First, we introduce an end-to-end point based geometry
encoder to better describe the semantics of the underlying 3D human body, in
replacement of previous hand-crafted features. Second, in order to address the
occupancy ambiguity caused by topological changes of clothed humans in the
canonical pose, we propose a co-supervising framework with cross-space
consistency to jointly estimate the occupancy in both the posed and canonical
spaces. Last, we use image-to-image translation networks to further refine
detailed geometry and texture on the reconstructed surface, which improves the
fidelity and consistency across arbitrary viewpoints. In the experiments, we
demonstrate improvements over the state of the art on both public benchmarks
and user studies in reconstruction quality and realism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepFake MNIST+: A DeepFake Facial Animation Dataset. (arXiv:2108.07949v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiajun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xueyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_P/0/1/0/all/0/1">Pei Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07949">
                                    <div class="article-summary-box-inner">
                                        <span>The DeepFakes, which are the facial manipulation techniques, is the emerging
threat to digital society. Various DeepFake detection methods and datasets are
proposed for detecting such data, especially for face-swapping. However, recent
researches less consider facial animation, which is also important in the
DeepFake attack side. It tries to animate a face image with actions provided by
a driving video, which also leads to a concern about the security of recent
payment systems that reply on liveness detection to authenticate real users via
recognising a sequence of user facial actions. However, our experiments show
that the existed datasets are not sufficient to develop reliable detection
methods. While the current liveness detector cannot defend such videos as the
attack. As a response, we propose a new human face animation dataset, called
DeepFake MNIST+, generated by a SOTA image animation generator. It includes
10,000 facial animation videos in ten different actions, which can spoof the
recent liveness detectors. A baseline detection method and a comprehensive
analysis of the method is also included in this paper. In addition, we analyze
the proposed dataset&#x27;s properties and reveal the difficulty and importance of
detecting animation datasets under different types of motion and compression
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatially and color consistent environment lighting estimation using deep neural networks for mixed reality. (arXiv:2108.07903v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marques_B/0/1/0/all/0/1">Bruno Augusto Dorta Marques</a>, <a href="http://arxiv.org/find/cs/1/au:+Clua_E/0/1/0/all/0/1">Esteban Walter Gonzalez Clua</a>, <a href="http://arxiv.org/find/cs/1/au:+Montenegro_A/0/1/0/all/0/1">Anselmo Antunes Montenegro</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Nader Vasconcelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07903">
                                    <div class="article-summary-box-inner">
                                        <span>The representation of consistent mixed reality (XR) environments requires
adequate real and virtual illumination composition in real-time. Estimating the
lighting of a real scenario is still a challenge. Due to the ill-posed nature
of the problem, classical inverse-rendering techniques tackle the problem for
simple lighting setups. However, those assumptions do not satisfy the current
state-of-art in computer graphics and XR applications. While many recent works
solve the problem using machine learning techniques to estimate the environment
light and scene&#x27;s materials, most of them are limited to geometry or previous
knowledge. This paper presents a CNN-based model to estimate complex lighting
for mixed reality environments with no previous information about the scene. We
model the environment illumination using a set of spherical harmonics (SH)
environment lighting, capable of efficiently represent area lighting. We
propose a new CNN architecture that inputs an RGB image and recognizes, in
real-time, the environment lighting. Unlike previous CNN-based lighting
estimation methods, we propose using a highly optimized deep neural network
architecture, with a reduced number of parameters, that can learn high complex
lighting scenarios from real-world high-dynamic-range (HDR) environment images.
We show in the experiments that the CNN architecture can predict the
environment lighting with an average mean squared error (MSE) of \num{7.85e-04}
when comparing SH lighting coefficients. We validate our model in a variety of
mixed reality scenarios. Furthermore, we present qualitative results comparing
relights of real-world scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Framework for 3D Lensless Imaging with Programmable Masks. (arXiv:2108.07966v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1">Yucheng Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Hua_Y/0/1/0/all/0/1">Yi Hua</a>, <a href="http://arxiv.org/find/eess/1/au:+Sankaranarayanan_A/0/1/0/all/0/1">Aswin C. Sankaranarayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Asif_M/0/1/0/all/0/1">M. Salman Asif</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07966">
                                    <div class="article-summary-box-inner">
                                        <span>Lensless cameras provide a framework to build thin imaging systems by
replacing the lens in a conventional camera with an amplitude or phase mask
near the sensor. Existing methods for lensless imaging can recover the depth
and intensity of the scene, but they require solving computationally-expensive
inverse problems. Furthermore, existing methods struggle to recover dense
scenes with large depth variations. In this paper, we propose a lensless
imaging system that captures a small number of measurements using different
patterns on a programmable mask. In this context, we make three contributions.
First, we present a fast recovery algorithm to recover textures on a fixed
number of depth planes in the scene. Second, we consider the mask design
problem, for programmable lensless cameras, and provide a design template for
optimizing the mask patterns with the goal of improving depth estimation.
Third, we use a refinement network as a post-processing step to identify and
remove artifacts in the reconstruction. These modifications are evaluated
extensively with experimental results on a lensless camera prototype to
showcase the performance benefits of the optimized masks and recovery
algorithms over the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Conditional Knowledge Distillation for Degraded-Reference Image Quality Assessment. (arXiv:2108.07948v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1">Heliang Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1">Huan Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zha_Z/0/1/0/all/0/1">Zheng-Jun Zha</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07948">
                                    <div class="article-summary-box-inner">
                                        <span>An important scenario for image quality assessment (IQA) is to evaluate image
restoration (IR) algorithms. The state-of-the-art approaches adopt a
full-reference paradigm that compares restored images with their corresponding
pristine-quality images. However, pristine-quality images are usually
unavailable in blind image restoration tasks and real-world scenarios. In this
paper, we propose a practical solution named degraded-reference IQA (DR-IQA),
which exploits the inputs of IR models, degraded images, as references.
Specifically, we extract reference information from degraded images by
distilling knowledge from pristine-quality images. The distillation is achieved
through learning a reference space, where various degraded images are
encouraged to share the same feature statistics with pristine-quality images.
And the reference space is optimized to capture deep image priors that are
useful for quality assessment. Note that pristine-quality images are only used
during training. Our work provides a powerful and differentiable metric for
blind IRs, especially for GAN-based methods. Extensive experiments show that
our results can even be close to the performance of full-reference settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Relighting against Face Recognition. (arXiv:2108.07920v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Ruijun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qing Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1">Felix Juefei-Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wei Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07920">
                                    <div class="article-summary-box-inner">
                                        <span>Deep face recognition (FR) has achieved significantly high accuracy on
several challenging datasets and fosters successful real-world applications,
even showing high robustness to the illumination variation that is usually
regarded as a main threat to the FR system. However, in the real world,
illumination variation caused by diverse lighting conditions cannot be fully
covered by the limited face dataset. In this paper, we study the threat of
lighting against FR from a new angle, i.e., adversarial attack, and identify a
new task, i.e., adversarial relighting. Given a face image, adversarial
relighting aims to produce a naturally relighted counterpart while fooling the
state-of-the-art deep FR methods. To this end, we first propose the physical
model-based adversarial relighting attack (ARA) denoted as
albedo-quotient-based adversarial relighting attack (AQ-ARA). It generates
natural adversarial light under the physical lighting model and guidance of FR
systems and synthesizes adversarially relighted face images. Moreover, we
propose the auto-predictive adversarial relighting attack (AP-ARA) by training
an adversarial relighting network (ARNet) to automatically predict the
adversarial light in a one-step manner according to different input faces,
allowing efficiency-sensitive applications. More importantly, we propose to
transfer the above digital attacks to physical ARA (Phy-ARA) through a precise
relighting device, making the estimated adversarial lighting condition
reproducible in the real world. We validate our methods on three
state-of-the-art deep FR methods, i.e., FaceNet, ArcFace, and CosFace, on two
public datasets. The extensive and insightful results demonstrate our work can
generate realistic adversarial relighted face images fooling FR easily,
revealing the threat of specific light directions and strengths.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affect-Aware Deep Belief Network Representations for Multimodal Unsupervised Deception Detection. (arXiv:2108.07897v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathur_L/0/1/0/all/0/1">Leena Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mataric_M/0/1/0/all/0/1">Maja J Matari&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07897">
                                    <div class="article-summary-box-inner">
                                        <span>Automated systems that detect the social behavior of deception can enhance
human well-being across medical, social work, and legal domains. Labeled
datasets to train supervised deception detection models can rarely be collected
for real-world, high-stakes contexts. To address this challenge, we propose the
first unsupervised approach for detecting real-world, high-stakes deception in
videos without requiring labels. This paper presents our novel approach for
affect-aware unsupervised Deep Belief Networks (DBN) to learn discriminative
representations of deceptive and truthful behavior. Drawing on psychology
theories that link affect and deception, we experimented with unimodal and
multimodal DBN-based approaches trained on facial valence, facial arousal,
audio, and visual features. In addition to using facial affect as a feature on
which DBN models are trained, we also introduce a DBN training procedure that
uses facial affect as an aligner of audio-visual representations. We conducted
classification experiments with unsupervised Gaussian Mixture Model clustering
to evaluate our approaches. Our best unsupervised approach (trained on facial
valence and visual features) achieved an AUC of 80%, outperforming human
ability and performing comparably to fully-supervised models. Our results
motivate future work on unsupervised, affect-aware computational approaches for
detecting deception and other social behaviors in the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Salient Object Detection with Transformer-based Asymmetric Bilateral U-Net. (arXiv:2108.07851v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yu Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Le Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jing Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07851">
                                    <div class="article-summary-box-inner">
                                        <span>Existing salient object detection (SOD) models mainly rely on CNN-based
U-shaped structures with skip connections to combine the global contexts and
local spatial details that are crucial for locating salient objects and
refining object details, respectively. Despite great successes, the ability of
CNN in learning global contexts is limited. Recently, the vision transformer
has achieved revolutionary progress in computer vision owing to its powerful
modeling of global dependencies. However, directly applying the transformer to
SOD is obviously suboptimal because the transformer lacks the ability to learn
local spatial representations. To this end, this paper explores the combination
of transformer and CNN to learn both global and local representations for SOD.
We propose a transformer-based Asymmetric Bilateral U-Net (AbiU-Net). The
asymmetric bilateral encoder has a transformer path and a lightweight CNN path,
where the two paths communicate at each encoder stage to learn complementary
global contexts and local spatial details, respectively. The asymmetric
bilateral decoder also consists of two paths to process features from the
transformer and CNN encoder paths, with communication at each decoder stage for
decoding coarse salient object locations and find-grained object details,
respectively. Such communication between the two encoder/decoder paths enables
AbiU-Net to learn complementary global and local representations, taking
advantage of the natural properties of transformer and CNN, respectively.
Hence, ABiU-Net provides a new perspective for transformer-based SOD. Extensive
experiments demonstrate that ABiU-Net performs favorably against previous
state-of-the-art SOD methods. The code will be released.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images. (arXiv:2108.03788v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M-ar-K-Fast Independent Component Analysis. (arXiv:2108.07908v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parisi_L/0/1/0/all/0/1">Luca Parisi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07908">
                                    <div class="article-summary-box-inner">
                                        <span>This study presents the m-arcsinh Kernel (&#x27;m-ar-K&#x27;) Fast Independent
Component Analysis (&#x27;FastICA&#x27;) method (&#x27;m-ar-K-FastICA&#x27;) for feature
extraction. The kernel trick has enabled dimensionality reduction techniques to
capture a higher extent of non-linearity in the data; however, reproducible,
open-source kernels to aid with feature extraction are still limited and may
not be reliable when projecting features from entropic data. The m-ar-K
function, freely available in Python and compatible with its open-source
library &#x27;scikit-learn&#x27;, is hereby coupled with FastICA to achieve more reliable
feature extraction in presence of a high extent of randomness in the data,
reducing the need for pre-whitening. Different classification tasks were
considered, as related to five (N &#x3D; 5) open access datasets of various degrees
of information entropy, available from scikit-learn and the University
California Irvine (UCI) Machine Learning repository. Experimental results
demonstrate improvements in the classification performance brought by the
proposed feature extraction. The novel m-ar-K-FastICA dimensionality reduction
approach is compared to the &#x27;FastICA&#x27; gold standard method, supporting its
higher reliability and computational efficiency, regardless of the underlying
uncertainty in the data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSI: an Ad Text Strength Indicator using Text-to-CTR and Semantic-Ad-Similarity. (arXiv:2108.08226v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Shaunak Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Changwei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_M/0/1/0/all/0/1">Manisha Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_K/0/1/0/all/0/1">Kevin Yen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yifan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sviridenko_M/0/1/0/all/0/1">Maxim Sviridenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08226">
                                    <div class="article-summary-box-inner">
                                        <span>Coming up with effective ad text is a time consuming process, and
particularly challenging for small businesses with limited advertising
experience. When an inexperienced advertiser onboards with a poorly written ad
text, the ad platform has the opportunity to detect low performing ad text, and
provide improvement suggestions. To realize this opportunity, we propose an ad
text strength indicator (TSI) which: (i) predicts the click-through-rate (CTR)
for an input ad text, (ii) fetches similar existing ads to create a
neighborhood around the input ad, (iii) and compares the predicted CTRs in the
neighborhood to declare whether the input ad is strong or weak. In addition, as
suggestions for ad text improvement, TSI shows anonymized versions of superior
ads (higher predicted CTR) in the neighborhood. For (i), we propose a BERT
based text-to-CTR model trained on impressions and clicks associated with an ad
text. For (ii), we propose a sentence-BERT based semantic-ad-similarity model
trained using weak labels from ad campaign setup data. Offline experiments
demonstrate that our BERT based text-to-CTR model achieves a significant lift
in CTR prediction AUC for cold start (new) advertisers compared to bag-of-words
based baselines. In addition, our semantic-textual-similarity model for similar
ads retrieval achieves a precision@1 of 0.93 (for retrieving ads from the same
product category); this is significantly higher compared to unsupervised
TF-IDF, word2vec, and sentence-BERT baselines. Finally, we share promising
online results from advertisers in the Yahoo (Verizon Media) ad platform where
a variant of TSI was implemented with sub-second end-to-end latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Characterizing Attitudinal Network Graphs through Frustration Cloud. (arXiv:2009.07776v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rusnak_L/0/1/0/all/0/1">Lucas Rusnak</a>, <a href="http://arxiv.org/find/cs/1/au:+Tesic_J/0/1/0/all/0/1">Jelena Te&#x161;i&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07776">
                                    <div class="article-summary-box-inner">
                                        <span>Attitudinal Network Graphs are signed graphs where edges capture an expressed
opinion; two vertices connected by an edge can be agreeable (positive) or
antagonistic (negative). A signed graph is called balanced if each of its
cycles includes an even number of negative edges. Balance is often
characterized by the frustration index or by finding a single convergent
balanced state of network consensus. In this paper, we propose to expand the
measures of consensus from a single balanced state associated with the
frustration index to the set of nearest balanced states. We introduce the
frustration cloud as a set of all nearest balanced states and use a
graph-balancing algorithm to find all nearest balanced states in a
deterministic way. Computational concerns are addressed by measuring consensus
probabilistically, and we introduce new vertex and edge metrics to quantify
status, agreement, and influence. We also introduce a new global measure of
controversy for a given signed graph and show that vertex status is a zero-sum
game in the signed network. We propose an efficient scalable algorithm for
calculating frustration cloud-based measures in social network and survey data
of up to 80,000 vertices and half-a-million edges. We also demonstrate the
power of the proposed approach to provide discriminant features for community
discovery when compared to spectral clustering and to automatically identify
dominant vertices and anomalous decisions in the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Performance and Energy trade-offs in Online Data-Intensive Applications. (arXiv:2108.08199v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Badita_A/0/1/0/all/0/1">Ajay Badita</a>, <a href="http://arxiv.org/find/cs/1/au:+Jinan_R/0/1/0/all/0/1">Rooji Jinan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vamanan_B/0/1/0/all/0/1">Balajee Vamanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Parag_P/0/1/0/all/0/1">Parimal Parag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08199">
                                    <div class="article-summary-box-inner">
                                        <span>We consider energy minimization for data-intensive applications run on large
number of servers, for given performance guarantees. We consider a system,
where each incoming application is sent to a set of servers, and is considered
to be completed if a subset of them finish serving it. We consider a simple
case when each server core has two speed levels, where the higher speed can be
achieved by higher power for each core independently. The core selects one of
the two speeds probabilistically for each incoming application request. We
model arrival of application requests by a Poisson process, and random service
time at the server with independent exponential random variables. Our model and
analysis generalizes to today&#x27;s state-of-the-art in CPU energy management where
each core can independently select a speed level from a set of supported speeds
and corresponding voltages. The performance metrics under consideration are the
mean number of applications in the system and the average energy expenditure.
We first provide a tight approximation to study this previously intractable
problem and derive closed form approximate expressions for the performance
metrics when service times are exponentially distributed. Next, we study the
trade-off between the approximate mean number of applications and energy
expenditure in terms of the switching probability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Implicit User Profiles for Personalized Retrieval-Based Chatbot. (arXiv:2108.07935v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">Hongjin Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhicheng Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yutao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yueyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07935">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the problem of developing personalized chatbots. A
personalized chatbot is designed as a digital chatting assistant for a user.
The key characteristic of a personalized chatbot is that it should have a
consistent personality with the corresponding user. It can talk the same way as
the user when it is delegated to respond to others&#x27; messages. We present a
retrieval-based personalized chatbot model, namely IMPChat, to learn an
implicit user profile from the user&#x27;s dialogue history. We argue that the
implicit user profile is superior to the explicit user profile regarding
accessibility and flexibility. IMPChat aims to learn an implicit user profile
through modeling user&#x27;s personalized language style and personalized
preferences separately. To learn a user&#x27;s personalized language style, we
elaborately build language models from shallow to deep using the user&#x27;s
historical responses; To model a user&#x27;s personalized preferences, we explore
the conditional relations underneath each post-response pair of the user. The
personalized preferences are dynamic and context-aware: we assign higher
weights to those historical pairs that are topically related to the current
query when aggregating the personalized preferences. We match each response
candidate with the personalized language style and personalized preference,
respectively, and fuse the two matching signals to determine the final ranking
score. Comprehensive experiments on two large datasets show that our method
outperforms all baseline models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework for Cross-Domain and Cross-System Recommendations. (arXiv:2108.07976v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaochao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Longfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guanfeng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07976">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-Domain Recommendation (CDR) and Cross-System Recommendation (CSR) have
been proposed to improve the recommendation accuracy in a target dataset
(domain/system) with the help of a source one with relatively richer
information. However, most existing CDR and CSR approaches are single-target,
namely, there is a single target dataset, which can only help the target
dataset and thus cannot benefit the source dataset. In this paper, we focus on
three new scenarios, i.e., Dual-Target CDR (DTCDR), Multi-Target CDR (MTCDR),
and CDR+CSR, and aim to improve the recommendation accuracy in all datasets
simultaneously for all scenarios. To do this, we propose a unified framework,
called GA (based on Graph embedding and Attention techniques), for all three
scenarios. In GA, we first construct separate heterogeneous graphs to generate
more representative user and item embeddings. Then, we propose an element-wise
attention mechanism to effectively combine the embeddings of common entities
(users/items) learned from different datasets. Moreover, to avoid negative
transfer, we further propose a Personalized training strategy to minimize the
embedding difference of common entities between a richer dataset and a sparser
dataset, deriving three new models, i.e., GA-DTCDR-P, GA-MTCDR-P, and
GA-CDR+CSR-P, for the three scenarios respectively. Extensive experiments
conducted on four real-world datasets demonstrate that our proposed GA models
significantly outperform the state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIFN: A Sentiment-aware Interactive Fusion Network for Review-based Item Recommendation. (arXiv:2108.08022v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">Hao Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiqiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianhui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08022">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies in recommender systems have managed to achieve significantly
improved performance by leveraging reviews for rating prediction. However,
despite being extensively studied, these methods still suffer from some
limitations. First, previous studies either encode the document or extract
latent sentiment via neural networks, which are difficult to interpret the
sentiment of reviewers intuitively. Second, they neglect the personalized
interaction of reviews with user/item, i.e., each review has different
contributions when modeling the sentiment preference of user/item. To remedy
these issues, we propose a Sentiment-aware Interactive Fusion Network (SIFN)
for review-based item recommendation. Specifically, we first encode user/item
reviews via BERT and propose a light-weighted sentiment learner to extract
semantic features of each review. Then, we propose a sentiment prediction task
that guides the sentiment learner to extract sentiment-aware features via
explicit sentiment labels. Finally, we design a rating prediction task that
contains a rating learner with an interactive and fusion module to fuse the
identity (i.e., user and item ID) and each review representation so that
various interactive features can synergistically influence the final rating
score. Experimental results on five real-world datasets demonstrate that the
proposed model is superior to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation. (arXiv:2107.13467v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yubin Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Pengyi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13467">
                                    <div class="article-summary-box-inner">
                                        <span>The unsupervised domain adaptation (UDA) has been widely adopted to alleviate
the data scalability issue, while the existing works usually focus on
classifying independently discrete labels. However, in many tasks (e.g.,
medical diagnosis), the labels are discrete and successively distributed. The
UDA for ordinal classification requires inducing non-trivial ordinal
distribution prior to the latent space. Target for this, the partially ordered
set (poset) is defined for constraining the latent vector. Instead of the
typically i.i.d. Gaussian latent prior, in this work, a recursively conditional
Gaussian (RCG) set is adapted for ordered constraint modeling, which admits a
tractable joint distribution prior. Furthermore, we are able to control the
density of content vector that violates the poset constraints by a simple
&quot;three-sigma rule&quot;. We explicitly disentangle the cross-domain images into a
shared ordinal prior induced ordinal content space and two separate
source/target ordinal-unrelated spaces, and the self-training is worked on the
shared space exclusively for ordinal-aware domain alignment. Extensive
experiments on UDA medical diagnoses and facial age estimation demonstrate its
effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Perturbations with Normalizing Flows for Improved Generalization. (arXiv:2108.07958v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yuksel_O/0/1/0/all/0/1">Oguz Kaan Yuksel</a>, <a href="http://arxiv.org/find/stat/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>, <a href="http://arxiv.org/find/stat/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>, <a href="http://arxiv.org/find/stat/1/au:+Chavdarova_T/0/1/0/all/0/1">Tatjana Chavdarova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07958">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation is a widely adopted technique for avoiding overfitting when
training deep neural networks. However, this approach requires domain-specific
knowledge and is often limited to a fixed set of hard-coded transformations.
Recently, several works proposed to use generative models for generating
semantically meaningful perturbations to train a classifier. However, because
accurate encoding and decoding are critical, these methods, which use
architectures that approximate the latent-variable inference, remained limited
to pilot studies on small datasets.

Exploiting the exactly reversible encoder-decoder structure of normalizing
flows, we perform on-manifold perturbations in the latent space to define fully
unsupervised data augmentations. We demonstrate that such perturbations match
the performance of advanced data augmentation techniques -- reaching 96.6% test
accuracy for CIFAR-10 using ResNet-18 and outperform existing methods,
particularly in low data regimes -- yielding 10--25% relative improvement of
test accuracy from classical training. We find that our latent adversarial
perturbations adaptive to the classifier throughout its training are most
effective, yielding the first test accuracy improvement results on real-world
datasets -- CIFAR-10/100 -- via latent-space perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Focus for Efficient Video Recognition. (arXiv:2105.03245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhaoxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haojun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yizeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03245">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the spatial redundancy in video recognition with
the aim to improve the computational efficiency. It is observed that the most
informative region in each frame of a video is usually a small image patch,
which shifts smoothly across frames. Therefore, we model the patch localization
problem as a sequential decision task, and propose a reinforcement learning
based approach for efficient spatially adaptive video recognition (AdaFocus).
In specific, a light-weighted ConvNet is first adopted to quickly process the
full video sequence, whose features are used by a recurrent policy network to
localize the most task-relevant regions. Then the selected patches are inferred
by a high-capacity network for the final prediction. During offline inference,
once the informative patch sequence has been generated, the bulk of computation
can be done in parallel, and is efficient on modern GPU devices. In addition,
we demonstrate that the proposed method can be easily extended by further
considering the temporal redundancy, e.g., dynamically skipping less valuable
frames. Extensive experiments on five benchmark datasets, i.e., ActivityNet,
FCVID, Mini-Kinetics, Something-Something V1&amp;V2, demonstrate that our method is
significantly more efficient than the competitive baselines. Code is available
at https://github.com/blackfeather-wang/AdaFocus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Implicit Networks via Non-Euclidean Contractions. (arXiv:2106.03194v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarpour_S/0/1/0/all/0/1">Saber Jafarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Davydov_A/0/1/0/all/0/1">Alexander Davydov</a>, <a href="http://arxiv.org/find/cs/1/au:+Proskurnikov_A/0/1/0/all/0/1">Anton V. Proskurnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bullo_F/0/1/0/all/0/1">Francesco Bullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03194">
                                    <div class="article-summary-box-inner">
                                        <span>Implicit neural networks, a.k.a., deep equilibrium networks, are a class of
implicit-depth learning models where function evaluation is performed by
solving a fixed point equation. They generalize classic feedforward models and
are equivalent to infinite-depth weight-tied feedforward networks. While
implicit models show improved accuracy and significant reduction in memory
consumption, they can suffer from ill-posedness and convergence instability.

This paper provides a new framework to design well-posed and robust implicit
neural networks based upon contraction theory for the non-Euclidean norm
$\ell_\infty$. Our framework includes (i) a novel condition for well-posedness
based on one-sided Lipschitz constants, (ii) an average iteration for computing
fixed-points, and (iii) explicit estimates on input-output Lipschitz constants.
Additionally, we design a training problem with the well-posedness condition
and the average iteration as constraints and, to achieve robust models, with
the input-output Lipschitz constant as a regularizer. Our $\ell_\infty$
well-posedness condition leads to a larger polytopic training search space than
existing conditions and our average iteration enjoys accelerated convergence.
Finally, we perform several numerical experiments for function estimation and
digit classification through the MNIST data set. Our numerical results
demonstrate improved accuracy and robustness of the implicit models with
smaller input-output Lipschitz bounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HAFLO: GPU-Based Acceleration for Federated Logistic Regression. (arXiv:2107.13797v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiaodian Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wanhang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xinyang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuihai Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13797">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, federated learning (FL) has been widely applied for
supporting decentralized collaborative learning scenarios. Among existing FL
models, federated logistic regression (FLR) is a widely used statistic model
and has been used in various industries. To ensure data security and user
privacy, FLR leverages homomorphic encryption (HE) to protect the exchanged
data among different collaborative parties. However, HE introduces significant
computational overhead (i.e., the cost of data encryption/decryption and
calculation over encrypted data), which eventually becomes the performance
bottleneck of the whole system. In this paper, we propose HAFLO, a GPU-based
solution to improve the performance of FLR. The core idea of HAFLO is to
summarize a set of performance-critical homomorphic operators (HO) used by FLR
and accelerate the execution of these operators through a joint optimization of
storage, IO, and computation. The preliminary results show that our
acceleration on FATE, a popular FL framework, achieves a 49.9$\times$ speedup
for heterogeneous LR and 88.4$\times$ for homogeneous LR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Variational Capsule Network for Open Set Recognition. (arXiv:2104.09159v2 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yunrui Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Camporese_G/0/1/0/all/0/1">Guglielmo Camporese</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenjing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1">Alessandro Sperduti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballan_L/0/1/0/all/0/1">Lamberto Ballan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09159">
                                    <div class="article-summary-box-inner">
                                        <span>In open set recognition, a classifier has to detect unknown classes that are
not known at training time. In order to recognize new categories, the
classifier has to project the input samples of known classes in very compact
and separated regions of the features space for discriminating samples of
unknown classes. Recently proposed Capsule Networks have shown to outperform
alternatives in many fields, particularly in image recognition, however they
have not been fully applied yet to open-set recognition. In capsule networks,
scalar neurons are replaced by capsule vectors or matrices, whose entries
represent different properties of objects. In our proposal, during training,
capsules features of the same known class are encouraged to match a pre-defined
gaussian, one for each class. To this end, we use the variational autoencoder
framework, with a set of gaussian priors as the approximation for the posterior
distribution. In this way, we are able to control the compactness of the
features of the same class around the center of the gaussians, thus controlling
the ability of the classifier in detecting samples from unknown classes. We
conducted several experiments and ablation of our model, obtaining state of the
art results on different datasets in the open set recognition and unknown
detection tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Positive-Unlabeled Classification under Class-Prior Shift: A Prior-invariant Approach Based on Density Ratio Estimation. (arXiv:2107.05045v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1">Shota Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05045">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from positive and unlabeled (PU) data is an important problem in
various applications. Most of the recent approaches for PU classification
assume that the class-prior (the ratio of positive samples) in the training
unlabeled dataset is identical to that of the test data, which does not hold in
many practical cases. In addition, we usually do not know the class-priors of
the training and test data, thus we have no clue on how to train a classifier
without them. To address these problems, we propose a novel PU classification
method based on density ratio estimation. A notable advantage of our proposed
method is that it does not require the class-priors in the training phase;
class-prior shift is incorporated only in the test phase. We theoretically
justify our proposed method and experimentally demonstrate its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforced Generative Adversarial Network for Abstractive Text Summarization. (arXiv:2105.15176v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chunyun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15176">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-sequence models provide a viable new approach to generative
summarization, allowing models that are no longer limited to simply selecting
and recombining sentences from the original text. However, these models have
three drawbacks: their grasp of the details of the original text is often
inaccurate, and the text generated by such models often has repetitions, while
it is difficult to handle words that are beyond the word list. In this paper,
we propose a new architecture that combines reinforcement learning and
adversarial generative networks to enhance the sequence-to-sequence attention
model. First, we use a hybrid pointer-generator network that copies words
directly from the source text, contributing to accurate reproduction of
information without sacrificing the ability of generators to generate new
words. Second, we use both intra-temporal and intra-decoder attention to
penalize summarized content and thus discourage repetition. We apply our model
to our own proposed COVID-19 paper title summarization task and achieve close
approximations to the current model on ROUEG, while bringing better
readability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VariTex: Variational Neural Face Textures. (arXiv:2104.05988v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Buhler_M/0/1/0/all/0/1">Marcel C. B&#xfc;hler</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1">Abhimitra Meka</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gengyan Li</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Beeler_T/0/1/0/all/0/1">Thabo Beeler</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a> (1) ((1) ETH Zurich, (2) Google)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05988">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models can synthesize photorealistic images of human faces
with novel identities. However, a key challenge to the wide applicability of
such techniques is to provide independent control over semantically meaningful
parameters: appearance, head pose, face shape, and facial expressions. In this
paper, we propose VariTex - to the best of our knowledge the first method that
learns a variational latent feature space of neural face textures, which allows
sampling of novel identities. We combine this generative model with a
parametric face model and gain explicit control over head pose and facial
expressions. To generate complete images of human heads, we propose an additive
decoder that adds plausible details such as hair. A novel training scheme
enforces a pose-independent latent space and in consequence, allows learning a
one-to-many mapping between latent codes and pose-conditioned exterior regions.
The resulting method can generate geometrically consistent images of novel
identities under fine-grained control over head pose, face shape, and facial
expressions. This facilitates a broad range of downstream tasks, like sampling
novel identities, changing the head pose, expression transfer, and more. Code
and models are available for research on https://mcbuehler.github.io/VariTex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amplitude Mean of Functional Data on $\mathbb{S}^2$. (arXiv:2107.13721v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Saparbayeva_B/0/1/0/all/0/1">Bayan Saparbayeva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13721">
                                    <div class="article-summary-box-inner">
                                        <span>Manifold-valued functional data analysis (FDA) recently becomes an active
area of research motivated by the raising availability of trajectories or
longitudinal data observed on non-linear manifolds. The challenges of analyzing
such data come from many aspects, including infinite dimensionality and
nonlinearity, as well as time-domain or phase variability. In this paper, we
study the amplitude part of manifold-valued functions on $\mathbb{S}^2$, which
is invariant to random time warping or re-parameterization. Utilizing the nice
geometry of $\mathbb{S}^2$, we develop a set of efficient and accurate tools
for temporal alignment of functions, geodesic computing, and sample mean
calculation. At the heart of these tools, they rely on gradient descent
algorithms with carefully derived gradients. We show the advantages of these
newly developed tools over its competitors with extensive simulations and real
data and demonstrate the importance of considering the amplitude part of
functions instead of mixing it with phase variability in manifold-valued FDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressing gradients by exploiting temporal correlation in momentum-SGD. (arXiv:2108.07827v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adikari_T/0/1/0/all/0/1">Tharindu B. Adikari</a>, <a href="http://arxiv.org/find/cs/1/au:+Draper_S/0/1/0/all/0/1">Stark C. Draper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07827">
                                    <div class="article-summary-box-inner">
                                        <span>An increasing bottleneck in decentralized optimization is communication.
Bigger models and growing datasets mean that decentralization of computation is
important and that the amount of information exchanged is quickly growing.
While compression techniques have been introduced to cope with the latter, none
has considered leveraging the temporal correlations that exist in consecutive
vector updates. An important example is distributed momentum-SGD where temporal
correlation is enhanced by the low-pass-filtering effect of applying momentum.
In this paper we design and analyze compression methods that exploit temporal
correlation in systems both with and without error-feedback. Experiments with
the ImageNet dataset demonstrate that our proposed methods offer significant
reduction in the rate of communication at only a negligible increase in
computation complexity. We further analyze the convergence of SGD when
compression is applied with error-feedback. In the literature, convergence
guarantees are developed only for compressors that provide error-bounds
point-wise, i.e., for each input to the compressor. In contrast, many important
codes (e.g. rate-distortion codes) provide error-bounds only in expectation and
thus provide a more general guarantee. In this paper we prove the convergence
of SGD under an expected error assumption by establishing a bound for the
minimum gradient norm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Schr\&quot;{o}dinger PCA: On the Duality between Principal Component Analysis and Schr\&quot;{o}dinger Equation. (arXiv:2006.04379v2 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Liu_Z/0/1/0/all/0/1">Ziming Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Qian_S/0/1/0/all/0/1">Sitian Qian</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/physics/1/au:+Yan_Y/0/1/0/all/0/1">Yuxuan Yan</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_T/0/1/0/all/0/1">Tianyi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04379">
                                    <div class="article-summary-box-inner">
                                        <span>Principal component analysis (PCA) has achieved great success in unsupervised
learning by identifying covariance correlations among features. If the data
collection fails to capture the covariance information, PCA will not be able to
discover meaningful modes. In particular, PCA will fail the spatial Gaussian
Process (GP) model in the undersampling regime, i.e. the averaged distance of
neighboring anchor points (spatial features) is greater than the correlation
length of GP. Counterintuitively, by drawing the connection between PCA and
Schr\&quot;odinger equation, we can not only attack the undersampling challenge but
also compute in an efficient and decoupled way with the proposed algorithm
called Schr\&quot;odinger PCA. Our algorithm only requires variances of features and
estimated correlation length as input, constructs the corresponding
Schr\&quot;odinger equation, and solves it to obtain the energy eigenstates, which
coincide with principal components. We will also establish the connection of
our algorithm to the model reduction techniques in the partial differential
equation (PDE) community, where the steady-state Schr\&quot;odinger operator is
identified as a second-order approximation to the covariance function.
Numerical experiments are implemented to testify the validity and efficiency of
the proposed algorithm, showing its potential for unsupervised learning tasks
on general graphs and manifolds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">F-Drop&amp;Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02343">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks built from deep convolutional neural networks
(GANs) lack the ability to exactly replicate the high-frequency components of
natural images. To alleviate this issue, we introduce two novel training
techniques called frequency dropping (F-Drop) and frequency matching (F-Match).
The key idea of F-Drop is to filter out unnecessary high-frequency components
from the input images of the discriminators. This simple modification prevents
the discriminators from being confused by perturbations of the high-frequency
components. In addition, F-Drop makes the GANs focus on fitting in the
low-frequency domain, in which there are the dominant components of natural
images. F-Match minimizes the difference between real and fake images in the
frequency domain for generating more realistic images. F-Match is implemented
as a regularization term in the objective functions of the generators; it
penalizes the batch mean error in the frequency domain. F-Match helps the
generators to fit in the high-frequency domain filtered out by F-Drop to the
real image. We experimentally demonstrate that the combination of F-Drop and
F-Match improves the generative performance of GANs in both the frequency and
spatial domain on multiple image benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective and scalable clustering of SARS-CoV-2 sequences. (arXiv:2108.08143v1 [q-bio.PE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Sarwan Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tamkanat-E-Ali/0/1/0/all/0/1">Tamkanat-E-Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khan_M/0/1/0/all/0/1">Muhammad Asad Khan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khan_I/0/1/0/all/0/1">Imdadullah Khan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Patterson_M/0/1/0/all/0/1">Murray Patterson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08143">
                                    <div class="article-summary-box-inner">
                                        <span>SARS-CoV-2, like any other virus, continues to mutate as it spreads,
according to an evolutionary process. Unlike any other virus, the number of
currently available sequences of SARS-CoV-2 in public databases such as GISAID
is already several million. This amount of data has the potential to uncover
the evolutionary dynamics of a virus like never before. However, a million is
already several orders of magnitude beyond what can be processed by the
traditional methods designed to reconstruct a virus&#x27;s evolutionary history,
such as those that build a phylogenetic tree. Hence, new and scalable methods
will need to be devised in order to make use of the ever increasing number of
viral sequences being collected.

Since identifying variants is an important part of understanding the
evolution of a virus, in this paper, we propose an approach based on clustering
sequences to identify the current major SARS-CoV-2 variants. Using a $k$-mer
based feature vector generation and efficient feature selection methods, our
approach is effective in identifying variants, as well as being efficient and
scalable to millions of sequences. Such a clustering method allows us to show
the relative proportion of each variant over time, giving the rate of spread of
each variant in different locations -- something which is important for vaccine
development and distribution. We also compute the importance of each amino acid
position of the spike protein in identifying a given variant in terms of
information gain. Positions of high variant-specific importance tend to agree
with those reported by the USA&#x27;s Centers for Disease Control and Prevention
(CDC), further demonstrating our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fake News and Phishing Detection Using a Machine Learning Trained Expert System. (arXiv:2108.08264v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fitzpatrick_B/0/1/0/all/0/1">Benjamin Fitzpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xinyu &quot;Sherwin&quot; Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Straub_J/0/1/0/all/0/1">Jeremy Straub</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08264">
                                    <div class="article-summary-box-inner">
                                        <span>Expert systems have been used to enable computers to make recommendations and
decisions. This paper presents the use of a machine learning trained expert
system (MLES) for phishing site detection and fake news detection. Both topics
share a similar goal: to design a rule-fact network that allows a computer to
make explainable decisions like domain experts in each respective area. The
phishing website detection study uses a MLES to detect potential phishing
websites by analyzing site properties (like URL length and expiration time).
The fake news detection study uses a MLES rule-fact network to gauge news story
truthfulness based on factors such as emotion, the speaker&#x27;s political
affiliation status, and job. The two studies use different MLES network
implementations, which are presented and compared herein. The fake news study
utilized a more linear design while the phishing project utilized a more
complex connection structure. Both networks&#x27; inputs are based on commonly
available data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Siamese Networks for One-Shot Intrusion Detection Model. (arXiv:2006.15343v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hindy_H/0/1/0/all/0/1">Hanan Hindy</a>, <a href="http://arxiv.org/find/cs/1/au:+Tachtatzis_C/0/1/0/all/0/1">Christos Tachtatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Atkinson_R/0/1/0/all/0/1">Robert Atkinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Brosset_D/0/1/0/all/0/1">David Brosset</a>, <a href="http://arxiv.org/find/cs/1/au:+Bures_M/0/1/0/all/0/1">Miroslav Bures</a>, <a href="http://arxiv.org/find/cs/1/au:+Andonovic_I/0/1/0/all/0/1">Ivan Andonovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Michie_C/0/1/0/all/0/1">Craig Michie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellekens_X/0/1/0/all/0/1">Xavier Bellekens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15343">
                                    <div class="article-summary-box-inner">
                                        <span>The use of supervised Machine Learning (ML) to enhance Intrusion Detection
Systems has been the subject of significant research. Supervised ML is based
upon learning by example, demanding significant volumes of representative
instances for effective training and the need to re-train the model for every
unseen cyber-attack class. However, retraining the models in-situ renders the
network susceptible to attacks owing to the time-window required to acquire a
sufficient volume of data. Although anomaly detection systems provide a
coarse-grained defence against unseen attacks, these approaches are
significantly less accurate and suffer from high false-positive rates. Here, a
complementary approach referred to as &#x27;One-Shot Learning&#x27;, whereby a limited
number of examples of a new attack-class is used to identify a new attack-class
(out of many) is detailed. The model grants a new cyber-attack classification
without retraining. A Siamese Network is trained to differentiate between
classes based on pairs similarities, rather than features, allowing to identify
new and previously unseen attacks. The performance of a pre-trained model to
classify attack-classes based only on one example is evaluated using three
datasets. Results confirm the adaptability of the model in classifying unseen
attacks and the trade-off between performance and the need for distinctive
class representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing MLPs With Dropouts, Batch Normalization, and Skip Connections. (arXiv:2108.08186v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taewoon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08186">
                                    <div class="article-summary-box-inner">
                                        <span>A multilayer perceptron (MLP) is typically made of multiple fully connected
layers with nonlinear activation functions. There have been several approaches
to make them better (e.g. faster convergence, better convergence limit, etc.).
But the researches lack in more structured ways to test them. We test different
MLP architectures by carrying out the experiments on the age and gender
datasets. We empirically show that by whitening inputs before every linear
layer and adding skip connections, our proposed MLP architecture can result in
better performance. Since the whitening process includes dropouts, it can also
be used to approximate Bayesian inference. We have open sourced our code
released models and docker images at https://github.com/tae898/age-gender/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistically Near-Optimal Hypothesis Selection. (arXiv:2108.07880v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bousquet_O/0/1/0/all/0/1">Olivier Bousquet</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1">Mark Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Efremenko_K/0/1/0/all/0/1">Klim Efremenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kol_G/0/1/0/all/0/1">Gillat Kol</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07880">
                                    <div class="article-summary-box-inner">
                                        <span>Hypothesis Selection is a fundamental distribution learning problem where
given a comparator-class $Q&#x3D;\{q_1,\ldots, q_n\}$ of distributions, and a
sampling access to an unknown target distribution $p$, the goal is to output a
distribution $q$ such that $\mathsf{TV}(p,q)$ is close to $opt$, where $opt &#x3D;
\min_i\{\mathsf{TV}(p,q_i)\}$ and $\mathsf{TV}(\cdot, \cdot)$ denotes the
total-variation distance. Despite the fact that this problem has been studied
since the 19th century, its complexity in terms of basic resources, such as
number of samples and approximation guarantees, remains unsettled (this is
discussed, e.g., in the charming book by Devroye and Lugosi &#x60;00). This is in
stark contrast with other (younger) learning settings, such as PAC learning,
for which these complexities are well understood.

We derive an optimal $2$-approximation learning strategy for the Hypothesis
Selection problem, outputting $q$ such that $\mathsf{TV}(p,q) \leq2 \cdot opt +
\eps$, with a (nearly) optimal sample complexity of~$\tilde O(\log
n/\epsilon^2)$. This is the first algorithm that simultaneously achieves the
best approximation factor and sample complexity: previously, Bousquet, Kane,
and Moran (COLT &#x60;19) gave a learner achieving the optimal $2$-approximation,
but with an exponentially worse sample complexity of $\tilde
O(\sqrt{n}/\epsilon^{2.5})$, and Yatracos~(Annals of Statistics &#x60;85) gave a
learner with optimal sample complexity of $O(\log n /\epsilon^2)$ but with a
sub-optimal approximation factor of $3$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-to-many Approach for Improving Super-Resolution. (arXiv:2106.10437v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Sieun Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_E/0/1/0/all/0/1">Eunho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10437">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been discussions on the ill-posed nature of
super-resolution that multiple possible reconstructions exist for a given
low-resolution image. Using normalizing flows, SRflow[23] achieves
state-of-the-art perceptual quality by learning the distribution of the output
instead of a deterministic output to one estimate. In this paper, we adapt the
concepts of SRFlow to improve GAN-based super-resolution by properly
implementing the one-to-many property. We modify the generator to estimate a
distribution as a mapping from random noise. We improve the content loss that
hampers the perceptual training objectives. We also propose additional training
techniques to further enhance the perceptual quality of generated images. Using
our proposed methods, we were able to improve the performance of ESRGAN[1] in
x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16 perceptual
extreme SR by applying our methods to RFB-ESRGAN[21].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning with Hyperspherical Uniformity. (arXiv:2103.01649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01649">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the over-parameterization nature, neural networks are a powerful tool
for nonlinear function approximation. In order to achieve good generalization
on unseen data, a suitable inductive bias is of great importance for neural
networks. One of the most straightforward ways is to regularize the neural
network with some additional objectives. L2 regularization serves as a standard
regularization for neural networks. Despite its popularity, it essentially
regularizes one dimension of the individual neuron, which is not strong enough
to control the capacity of highly over-parameterized neural networks. Motivated
by this, hyperspherical uniformity is proposed as a novel family of relational
regularizations that impact the interaction among neurons. We consider several
geometrically distinct ways to achieve hyperspherical uniformity. The
effectiveness of hyperspherical uniformity is justified by theoretical insights
and empirical evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Opportunities and Risks of Foundation Models. (arXiv:2108.07258v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bommasani_R/0/1/0/all/0/1">Rishi Bommasani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Altman_R/0/1/0/all/0/1">Russ Altman</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1">Simran Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Arx_S/0/1/0/all/0/1">Sydney von Arx</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernstein_M/0/1/0/all/0/1">Michael S. Bernstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1">Jeannette Bohg</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1">Antoine Bosselut</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1">Emma Brunskill</a>, <a href="http://arxiv.org/find/cs/1/au:+Brynjolfsson_E/0/1/0/all/0/1">Erik Brynjolfsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1">Shyamal Buch</a>, <a href="http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1">Dallas Card</a>, <a href="http://arxiv.org/find/cs/1/au:+Castellon_R/0/1/0/all/0/1">Rodrigo Castellon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri Chatterji</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Annie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Creel_K/0/1/0/all/0/1">Kathleen Creel</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jared Quincy Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Demszky_D/0/1/0/all/0/1">Dora Demszky</a>, <a href="http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1">Chris Donahue</a>, <a href="http://arxiv.org/find/cs/1/au:+Doumbouya_M/0/1/0/all/0/1">Moussa Doumbouya</a>, <a href="http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1">Esin Durmus</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>, <a href="http://arxiv.org/find/cs/1/au:+Etchemendy_J/0/1/0/all/0/1">John Etchemendy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ethayarajh_K/0/1/0/all/0/1">Kawin Ethayarajh</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Gale_T/0/1/0/all/0/1">Trevor Gale</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillespie_L/0/1/0/all/0/1">Lauren Gillespie</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_K/0/1/0/all/0/1">Karan Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>, <a href="http://arxiv.org/find/cs/1/au:+Grossman_S/0/1/0/all/0/1">Shelby Grossman</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_N/0/1/0/all/0/1">Neel Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1">Tatsunori Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Peter Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Hewitt_J/0/1/0/all/0/1">John Hewitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jenny Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_K/0/1/0/all/0/1">Kyle Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1">Thomas Icard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1">Dan Jurafsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalluri_P/0/1/0/all/0/1">Pratyusha Kalluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Keeling_G/0/1/0/all/0/1">Geoff Keeling</a>, <a href="http://arxiv.org/find/cs/1/au:+Khani_F/0/1/0/all/0/1">Fereshte Khani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1">Omar Khattab</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohd_P/0/1/0/all/0/1">Pang Wei Kohd</a>, <a href="http://arxiv.org/find/cs/1/au:+Krass_M/0/1/0/all/0/1">Mark Krass</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuditipudi_R/0/1/0/all/0/1">Rohith Kuditipudi</a>, et al. (62 additional authors not shown)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07258">
                                    <div class="article-summary-box-inner">
                                        <span>AI is undergoing a paradigm shift with the rise of models (e.g., BERT,
DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a
wide range of downstream tasks. We call these models foundation models to
underscore their critically central yet incomplete character. This report
provides a thorough account of the opportunities and risks of foundation
models, ranging from their capabilities (e.g., language, vision, robotics,
reasoning, human interaction) and technical principles(e.g., model
architectures, training procedures, data, systems, security, evaluation,
theory) to their applications (e.g., law, healthcare, education) and societal
impact (e.g., inequity, misuse, economic and environmental impact, legal and
ethical considerations). Though foundation models are based on standard deep
learning and transfer learning, their scale results in new emergent
capabilities,and their effectiveness across so many tasks incentivizes
homogenization. Homogenization provides powerful leverage but demands caution,
as the defects of the foundation model are inherited by all the adapted models
downstream. Despite the impending widespread deployment of foundation models,
we currently lack a clear understanding of how they work, when they fail, and
what they are even capable of due to their emergent properties. To tackle these
questions, we believe much of the critical research on foundation models will
require deep interdisciplinary collaboration commensurate with their
fundamentally sociotechnical nature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Techniques for Model Inversion Attacks. (arXiv:2010.04092v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruoxi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guo-Jun Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04092">
                                    <div class="article-summary-box-inner">
                                        <span>Model inversion (MI) attacks are aimed at reconstructing training data from
model parameters. Such attacks have triggered increasing concerns about
privacy, especially given a growing number of online model repositories.
However, existing MI attacks against deep neural networks (DNNs) have large
room for performance improvement. We present a novel inversion-specific GAN
that can better distill knowledge useful for performing attacks on private
models from public data. In particular, we train the discriminator to
differentiate not only the real and fake samples but the soft-labels provided
by the target model. Moreover, unlike previous work that directly searches for
a single data point to represent a target class, we propose to model a private
data distribution for each target class. Our experiments show that the
combination of these techniques can significantly boost the success rate of the
state-of-the-art MI attacks by 150%, and generalize better to a variety of
datasets and models. Our code is available at
https://github.com/SCccc21/Knowledge-Enriched-DMI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embed Me If You Can: A Geometric Perceptron. (arXiv:2006.06507v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Melnyk_P/0/1/0/all/0/1">Pavlo Melnyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1">Michael Felsberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadenback_M/0/1/0/all/0/1">M&#xe5;rten Wadenb&#xe4;ck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06507">
                                    <div class="article-summary-box-inner">
                                        <span>Solving geometric tasks involving point clouds by using machine learning is a
challenging problem. Standard feed-forward neural networks combine linear or,
if the bias parameter is included, affine layers and activation functions.
Their geometric modeling is limited, which motivated the prior work introducing
the multilayer hypersphere perceptron (MLHP). Its constituent part, i.e., the
hypersphere neuron, is obtained by applying a conformal embedding of Euclidean
space. By virtue of Clifford algebra, it can be implemented as the Cartesian
dot product of inputs and weights. If the embedding is applied in a manner
consistent with the dimensionality of the input space geometry, the decision
surfaces of the model units become combinations of hyperspheres and make the
decision-making process geometrically interpretable for humans. Our extension
of the MLHP model, the multilayer geometric perceptron (MLGP), and its
respective layer units, i.e., geometric neurons, are consistent with the 3D
geometry and provide a geometric handle of the learned coefficients. In
particular, the geometric neuron activations are isometric in 3D, which is
necessary for rotation and translation equivariance. When classifying the 3D
Tetris shapes, we quantitatively show that our model requires no activation
function in the hidden layers other than the embedding to outperform the
vanilla multilayer perceptron. In the presence of noise in the data, our model
is also superior to the MLHP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A new semi-supervised inductive transfer learning framework: Co-Transfer. (arXiv:2108.07930v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Ze Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yimin Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07930">
                                    <div class="article-summary-box-inner">
                                        <span>In many practical data mining scenarios, such as network intrusion detection,
Twitter spam detection, and computer-aided diagnosis, a source domain that is
different from but related to a target domain is very common. In addition, a
large amount of unlabeled data is available in both source and target domains,
but labeling each of them is difficult, expensive, time-consuming, and sometime
unnecessary. Therefore, it is very important and worthwhile to fully explore
the labeled and unlabeled data in source and target domains to settle the task
in target domain. In this paper, a new semi-supervised inductive transfer
learning framework, named \emph{Co-Transfer} is proposed. Co-Transfer first
generates three TrAdaBoost classifiers for transfer learning from the source
domain to the target domain, and meanwhile another three TrAdaBoost classifiers
are generated for transfer learning from the target domain to the source
domain, using bootstraped samples from the original labeled data. In each round
of co-transfer, each group of TrAdaBoost classifiers are refined using the
carefully labeled data. Finally, the group of TrAdaBoost classifiers learned to
transfer from the source domain to the target domain produce the final
hypothesis. Experiments results illustrate Co-Transfer can effectively exploit
and reuse the labeled and unlabeled data in source and target domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Look Before You Leap! Designing a Human-Centered AI System for Change Risk Assessment. (arXiv:2108.07951v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_B/0/1/0/all/0/1">Binay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1">Anirban Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Matha_H/0/1/0/all/0/1">Harika Matha</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_K/0/1/0/all/0/1">Kunal Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Parsai_L/0/1/0/all/0/1">Lalitdutt Parsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Agneeswaran_V/0/1/0/all/0/1">Vijay Agneeswaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07951">
                                    <div class="article-summary-box-inner">
                                        <span>Reducing the number of failures in a production system is one of the most
challenging problems in technology driven industries, such as, the online
retail industry. To address this challenge, change management has emerged as a
promising sub-field in operations that manages and reviews the changes to be
deployed in production in a systematic manner. However, it is practically
impossible to manually review a large number of changes on a daily basis and
assess the risk associated with them. This warrants the development of an
automated system to assess the risk associated with a large number of changes.
There are a few commercial solutions available to address this problem but
those solutions lack the ability to incorporate domain knowledge and continuous
feedback from domain experts into the risk assessment process. As part of this
work, we aim to bridge the gap between model-driven risk assessment of change
requests and the assessment of domain experts by building a continuous feedback
loop into the risk assessment process. Here we present our work to build an
end-to-end machine learning system along with the discussion of some of
practical challenges we faced related to extreme skewness in class
distribution, concept drift, estimation of the uncertainty associated with the
model&#x27;s prediction and the overall scalability of the system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Confidence Adaptive Regularization for Deep Learning with Noisy Labels. (arXiv:2108.08212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yangdi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bo_Y/0/1/0/all/0/1">Yang Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wenbo He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08212">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies on the memorization effects of deep neural networks on noisy
labels show that the networks first fit the correctly-labeled training samples
before memorizing the mislabeled samples. Motivated by this early-learning
phenomenon, we propose a novel method to prevent memorization of the mislabeled
samples. Unlike the existing approaches which use the model output to identify
or ignore the mislabeled samples, we introduce an indicator branch to the
original model and enable the model to produce a confidence value for each
sample. The confidence values are incorporated in our loss function which is
learned to assign large confidence values to correctly-labeled samples and
small confidence values to mislabeled samples. We also propose an auxiliary
regularization term to further improve the robustness of the model. To improve
the performance, we gradually correct the noisy labels with a well-designed
target estimation strategy. We provide the theoretical analysis and conduct the
experiments on synthetic and real-world datasets, demonstrating that our
approach achieves comparable results to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Collaborate. (arXiv:2108.07926v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Sen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Weishen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07926">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we focus on effective learning over a collaborative research
network involving multiple clients. Each client has its own sample population
which may not be shared with other clients due to privacy concerns. The goal is
to learn a model for each client, which behaves better than the one learned
from its own data, through secure collaborations with other clients in the
network. Due to the discrepancies of the sample distributions across different
clients, it is not necessarily that collaborating with everyone will lead to
the best local models. We propose a learning to collaborate framework, where
each client can choose to collaborate with certain members in the network to
achieve a &quot;collaboration equilibrium&quot;, where smaller collaboration coalitions
are formed within the network so that each client can obtain the model with the
best utility. We propose the concept of benefit graph which describes how each
client can benefit from collaborating with other clients and develop a Pareto
optimization approach to obtain it. Finally the collaboration coalitions can be
derived from it based on graph operations. Our framework provides a new way of
setting up collaborations in a research network. Experiments on both synthetic
and real world data sets are provided to demonstrate the effectiveness of our
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Multi-Function Computation with Private Remote Sources. (arXiv:2106.09485v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunlu_O/0/1/0/all/0/1">Onur G&#xfc;nl&#xfc;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_M/0/1/0/all/0/1">Matthieu Bloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaefer_R/0/1/0/all/0/1">Rafael F. Schaefer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09485">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a distributed function computation problem in which parties
observing noisy versions of a remote source facilitate the computation of a
function of their observations at a fusion center through public communication.
The distributed function computation is subject to constraints, including not
only reliability and storage but also privacy and secrecy. Specifically, 1) the
remote source should remain private from an eavesdropper and the fusion center,
measured in terms of the information leaked about the remote source; 2) the
function computed should remain secret from the eavesdropper, measured in terms
of the information leaked about the arguments of the function, to ensure
secrecy regardless of the exact function used. We derive the exact rate regions
for lossless and lossy single-function computation and illustrate the lossy
single-function computation rate region for an information bottleneck example,
in which the optimal auxiliary random variables are characterized for
binary-input symmetric-output channels. We extend the approach to lossless and
lossy asynchronous multiple-function computations with joint secrecy and
privacy constraints, in which case inner and outer bounds for the rate regions
differing only in the Markov chain conditions imposed are characterized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CapillaryNet: An Automated System to Quantify Skin Capillary Density and Red Blood Cell Velocity from Handheld Vital Microscopy. (arXiv:2104.11574v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Helmy_M/0/1/0/all/0/1">Maged Helmy</a>, <a href="http://arxiv.org/find/cs/1/au:+Dykyy_A/0/1/0/all/0/1">Anastasiya Dykyy</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Tuyen Trung Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferreira_P/0/1/0/all/0/1">Paulo Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Jul_E/0/1/0/all/0/1">Eric Jul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11574">
                                    <div class="article-summary-box-inner">
                                        <span>Capillaries are the smallest vessels in the body responsible for the delivery
of oxygen and nutrients to the surrounding cells. Various diseases have been
shown to alter the density of nutritive capillaries and the flow velocity of
erythrocytes. In previous studies, capillary density and flow velocity have
been assessed manually by trained specialists. Manual analysis of a standard
20-second long microvascular video takes on average 20 minutes and requires
extensive training. Several studies have reported that manual analysis hinders
the application of microvascular microscopy in a clinical setting. In this
paper, we present a fully automated state-of-the-art system, called
CapillaryNet, that can quantify skin nutritive capillary density and red blood
cell velocity from handheld microscopy videos. Moreover, CapillaryNet measures
several novel microvascular parameters that researchers were previously unable
to quantify, i.e. capillary hematocrit and Intra-capillary flow velocity
heterogeneity. Our system has been used to analyze skin microcirculation videos
from various patient groups (COVID-19, pancreatitis, and acute heart diseases).
Our proposed system excels from existing capillary detection systems as it
combines the speed of traditional computer vision algorithms and the accuracy
of convolutional neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework for Cross-Domain and Cross-System Recommendations. (arXiv:2108.07976v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaochao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Longfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guanfeng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07976">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-Domain Recommendation (CDR) and Cross-System Recommendation (CSR) have
been proposed to improve the recommendation accuracy in a target dataset
(domain/system) with the help of a source one with relatively richer
information. However, most existing CDR and CSR approaches are single-target,
namely, there is a single target dataset, which can only help the target
dataset and thus cannot benefit the source dataset. In this paper, we focus on
three new scenarios, i.e., Dual-Target CDR (DTCDR), Multi-Target CDR (MTCDR),
and CDR+CSR, and aim to improve the recommendation accuracy in all datasets
simultaneously for all scenarios. To do this, we propose a unified framework,
called GA (based on Graph embedding and Attention techniques), for all three
scenarios. In GA, we first construct separate heterogeneous graphs to generate
more representative user and item embeddings. Then, we propose an element-wise
attention mechanism to effectively combine the embeddings of common entities
(users/items) learned from different datasets. Moreover, to avoid negative
transfer, we further propose a Personalized training strategy to minimize the
embedding difference of common entities between a richer dataset and a sparser
dataset, deriving three new models, i.e., GA-DTCDR-P, GA-MTCDR-P, and
GA-CDR+CSR-P, for the three scenarios respectively. Extensive experiments
conducted on four real-world datasets demonstrate that our proposed GA models
significantly outperform the state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LightMove: A Lightweight Next-POI Recommendation for Taxicab Rooftop Advertising. (arXiv:2108.04993v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">Soyoung Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jo_M/0/1/0/all/0/1">Minju Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Seunghyeon Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seonghoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chiyoung Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile digital billboards are an effective way to augment brand-awareness.
Among various such mobile billboards, taxicab rooftop devices are emerging in
the market as a brand new media. Motov is a leading company in South Korea in
the taxicab rooftop advertising market. In this work, we present a lightweight
yet accurate deep learning-based method to predict taxicabs&#x27; next locations to
better prepare for targeted advertising based on demographic information of
locations. Considering the fact that next POI recommendation datasets are
frequently sparse, we design our presented model based on neural ordinary
differential equations (NODEs), which are known to be robust to
sparse/incorrect input, with several enhancements. Our model, which we call
LightMove, has a larger prediction accuracy, a smaller number of parameters,
and/or a smaller training/inference time, when evaluating with various
datasets, in comparison with state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unmanned Aerial Vehicle Visual Detection and Tracking using Deep Neural Networks: A Performance Benchmark. (arXiv:2103.13933v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isaac_Medina_B/0/1/0/all/0/1">Brian K. S. Isaac-Medina</a>, <a href="http://arxiv.org/find/cs/1/au:+Poyser_M/0/1/0/all/0/1">Matt Poyser</a>, <a href="http://arxiv.org/find/cs/1/au:+Organisciak_D/0/1/0/all/0/1">Daniel Organisciak</a>, <a href="http://arxiv.org/find/cs/1/au:+Willcocks_C/0/1/0/all/0/1">Chris G. Willcocks</a>, <a href="http://arxiv.org/find/cs/1/au:+Breckon_T/0/1/0/all/0/1">Toby P. Breckon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13933">
                                    <div class="article-summary-box-inner">
                                        <span>Unmanned Aerial Vehicles (UAV) can pose a major risk for aviation safety, due
to both negligent and malicious use. For this reason, the automated detection
and tracking of UAV is a fundamental task in aerial security systems. Common
technologies for UAV detection include visible-band and thermal infrared
imaging, radio frequency and radar. Recent advances in deep neural networks
(DNNs) for image-based object detection open the possibility to use visual
information for this detection and tracking task. Furthermore, these detection
architectures can be implemented as backbones for visual tracking systems,
thereby enabling persistent tracking of UAV incursions. To date, no
comprehensive performance benchmark exists that applies DNNs to visible-band
imagery for UAV detection and tracking. To this end, three datasets with varied
environmental conditions for UAV detection and tracking, comprising a total of
241 videos (331,486 images), are assessed using four detection architectures
and three tracking frameworks. The best performing detector architecture
obtains an mAP of 98.6% and the best performing tracking framework obtains a
MOTA of 96.3%. Cross-modality evaluation is carried out between visible and
infrared spectrums, achieving a maximal 82.8% mAP on visible images when
training in the infrared modality. These results provide the first public
multi-approach benchmark for state-of-the-art deep learning-based methods and
give insight into which detection and tracking architectures are effective in
the UAV domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Detection in Cough, Breath and Speech using Deep Transfer Learning and Bottleneck Features. (arXiv:2104.02477v4 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pahar_M/0/1/0/all/0/1">Madhurananda Pahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Klopper_M/0/1/0/all/0/1">Marisa Klopper</a>, <a href="http://arxiv.org/find/cs/1/au:+Warren_R/0/1/0/all/0/1">Robin Warren</a>, <a href="http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1">Thomas Niesler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02477">
                                    <div class="article-summary-box-inner">
                                        <span>We present an experimental investigation into the effectiveness of transfer
learning and bottleneck feature extraction in detecting COVID-19 from audio
recordings of cough, breath and speech.

This type of screening is non-contact, does not require specialist medical
expertise or laboratory facilities and can be deployed on inexpensive consumer
hardware.

We use datasets that contain recordings of coughing, sneezing, speech and
other noises, but do not contain COVID-19 labels, to pre-train three deep
neural networks: a CNN, an LSTM and a Resnet50.

These pre-trained networks are subsequently either fine-tuned using smaller
datasets of coughing with COVID-19 labels in the process of transfer learning,
or are used as bottleneck feature extractors.

Results show that a Resnet50 classifier trained by this transfer learning
process delivers optimal or near-optimal performance across all datasets
achieving areas under the receiver operating characteristic (ROC AUC) of 0.98,
0.94 and 0.92 respectively for all three sound classes (coughs, breaths and
speech).

This indicates that coughs carry the strongest COVID-19 signature, followed
by breath and speech.

Our results also show that applying transfer learning and extracting
bottleneck features using the larger datasets without COVID-19 labels led not
only to improve performance, but also to minimise the standard deviation of the
classifier AUCs among the outer folds of the leave-$p$-out cross-validation,
indicating better generalisation.

We conclude that deep transfer learning and bottleneck feature extraction can
improve COVID-19 cough, breath and speech audio classification, yielding
automatic classifiers with higher accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks. (arXiv:2105.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kayser_M/0/1/0/all/0/1">Maxime Kayser</a>, <a href="http://arxiv.org/find/cs/1/au:+Camburu_O/0/1/0/all/0/1">Oana-Maria Camburu</a>, <a href="http://arxiv.org/find/cs/1/au:+Salewski_L/0/1/0/all/0/1">Leonard Salewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Emde_C/0/1/0/all/0/1">Cornelius Emde</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Virginie Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing number of efforts to introduce models
capable of generating natural language explanations (NLEs) for their
predictions on vision-language (VL) tasks. Such models are appealing, because
they can provide human-friendly and comprehensive explanations. However, there
is a lack of comparison between existing methods, which is due to a lack of
re-usable evaluation frameworks and a scarcity of datasets. In this work, we
introduce e-ViL and e-SNLI-VE. e-ViL is a benchmark for explainable
vision-language tasks that establishes a unified evaluation framework and
provides the first comprehensive comparison of existing approaches that
generate NLEs for VL tasks. It spans four models and three datasets and both
automatic metrics and human evaluation are used to assess model-generated
explanations. e-SNLI-VE is currently the largest existing VL dataset with NLEs
(over 430k instances). We also propose a new model that combines UNITER, which
learns joint embeddings of images and text, and GPT-2, a pre-trained language
model that is well-suited for text generation. It surpasses the previous state
of the art by a large margin across all datasets. Code and data are available
here: https://github.com/maximek3/e-ViL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongquan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yiming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jiayi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhongxi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14956">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from noisy labels is an important concern because of the lack of
accurate ground-truth labels in plenty of real-world scenarios. In practice,
various approaches for this concern first make some corrections corresponding
to potentially noisy-labeled instances, and then update predictive model with
information of the made corrections. However, in specific areas, such as
medical histopathology whole slide image analysis (MHWSIA), it is often
difficult or even impossible for experts to manually achieve the noisy-free
ground-truth labels which leads to labels with complex noise. This situation
raises two more difficult problems: 1) the methodology of approaches making
corrections corresponding to potentially noisy-labeled instances has
limitations due to the complex noise existing in labels; and 2) the appropriate
evaluation strategy for validation/testing is unclear because of the great
difficulty in collecting the noisy-free ground-truth labels. In this paper, we
focus on alleviating these two problems. For the problem 1), we present
one-step abductive multi-target learning (OSAMTL) that imposes a one-step
logical reasoning upon machine learning via a multi-target learning procedure
to constrain the predictions of the learning model to be subject to our prior
knowledge about the true target. For the problem 2), we propose a logical
assessment formula (LAF) that evaluates the logical rationality of the outputs
of an approach by estimating the consistencies between the predictions of the
learning model and the logical facts narrated from the results of the one-step
logical reasoning of OSAMTL. Applying OSAMTL and LAF to the Helicobacter pylori
(H. pylori) segmentation task in MHWSIA, we show that OSAMTL is able to enable
the machine learning model achieving logically more rational predictions, which
is beyond various state-of-the-art approaches in handling complex noisy labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pitfalls in Machine Learning Research: Reexamining the Development Cycle. (arXiv:2011.02832v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1">Stella Biderman</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheirer_W/0/1/0/all/0/1">Walter J. Scheirer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02832">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning has the potential to fuel further advances in data science,
but it is greatly hindered by an ad hoc design process, poor data hygiene, and
a lack of statistical rigor in model evaluation. Recently, these issues have
begun to attract more attention as they have caused public and embarrassing
issues in research and development. Drawing from our experience as machine
learning researchers, we follow the machine learning process from algorithm
design to data collection to model evaluation, drawing attention to common
pitfalls and providing practical recommendations for improvements. At each
step, case studies are introduced to highlight how these pitfalls occur in
practice, and where things could be improved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nanosecond machine learning event classification with boosted decision trees in FPGA for high energy physics. (arXiv:2104.03408v3 [hep-ex] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ex/1/au:+Hong_T/0/1/0/all/0/1">Tae Min Hong</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Carlson_B/0/1/0/all/0/1">Benjamin Carlson</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Eubanks_B/0/1/0/all/0/1">Brandon Eubanks</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Racz_S/0/1/0/all/0/1">Stephen Racz</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Roche_S/0/1/0/all/0/1">Stephen Roche</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Stelzer_J/0/1/0/all/0/1">Joerg Stelzer</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Stumpp_D/0/1/0/all/0/1">Daniel Stumpp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03408">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel implementation of classification using the machine
learning / artificial intelligence method called boosted decision trees (BDT)
on field programmable gate arrays (FPGA). The firmware implementation of binary
classification requiring 100 training trees with a maximum depth of 4 using
four input variables gives a latency value of about 10 ns, independent of the
clock speed from 100 to 320 MHz in our setup. The low timing values are
achieved by restructuring the BDT layout and reconfiguring its parameters. The
FPGA resource utilization is also kept low at a range from 0.01% to 0.2% in our
setup. A software package called fwXmachina achieves this implementation. Our
intended user is an expert of custom electronics-based trigger systems in high
energy physics experiments or anyone that needs decisions at the lowest latency
values for real-time event classification. Two problems from high energy
physics are considered, in the separation of electrons vs. photons and in the
selection of vector boson fusion-produced Higgs bosons vs. the rejection of the
multijet processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-preserving Data Analysis through Representation Learning and Transformation. (arXiv:2011.08315v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hajihassani_O/0/1/0/all/0/1">Omid Hajihassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardakanian_O/0/1/0/all/0/1">Omid Ardakanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Khazaei_H/0/1/0/all/0/1">Hamzeh Khazaei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08315">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance of data collected by sensors in Internet of Things (IoT)
devices, and the success of deep neural networks in uncovering hidden patterns
in time series data have led to mounting privacy concerns. This is because
private and sensitive information can be potentially learned from sensor data
by applications that have access to this data. In this paper, we aim to examine
the tradeoff between utility and privacy loss by learning low-dimensional
representations that are useful for data obfuscation. We propose deterministic
and probabilistic transformations in the latent space of a variational
autoencoder to synthesize time series data such that intrusive inferences are
prevented while desired inferences can still be made with sufficient accuracy.
In the deterministic case, we use a linear transformation to move the
representation of input data in the latent space such that the reconstructed
data is likely to have the same public attribute but a different private
attribute than the original input data. In the probabilistic case, we apply the
linear transformation to the latent representation of input data with some
probability. We compare our technique with autoencoder-based anonymization
techniques and additionally show that it can anonymize data in real time on
resource-constrained edge devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying Reinforcement Learning Policies with $\mathcal{L}_1$ Adaptive Control. (arXiv:2106.02249v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yikun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_M/0/1/0/all/0/1">Manan Gandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1">Evangelos Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovakimyan_N/0/1/0/all/0/1">Naira Hovakimyan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02249">
                                    <div class="article-summary-box-inner">
                                        <span>A reinforcement learning (RL) policy trained in a nominal environment could
fail in a new/perturbed environment due to the existence of dynamic variations.
Existing robust methods try to obtain a fixed policy for all envisioned dynamic
variation scenarios through robust or adversarial training. These methods could
lead to conservative performance due to emphasis on the worst case, and often
involve tedious modifications to the training environment. We propose an
approach to robustifying a pre-trained non-robust RL policy with
$\mathcal{L}_1$ adaptive control. Leveraging the capability of an
$\mathcal{L}_1$ control law in the fast estimation of and active compensation
for dynamic variations, our approach can significantly improve the robustness
of an RL policy trained in a standard (i.e., non-robust) way, either in a
simulator or in the real world. Numerical experiments are provided to validate
the efficacy of the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Bias in Depression Detection Using Audio Features. (arXiv:2010.15120v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bailey_A/0/1/0/all/0/1">Andrew Bailey</a>, <a href="http://arxiv.org/find/cs/1/au:+Plumbley_M/0/1/0/all/0/1">Mark D. Plumbley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15120">
                                    <div class="article-summary-box-inner">
                                        <span>Depression is a large-scale mental health problem and a challenging area for
machine learning researchers in detection of depression. Datasets such as
Distress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ) have been created
to aid research in this area. However, on top of the challenges inherent in
accurately detecting depression, biases in datasets may result in skewed
classification performance. In this paper we examine gender bias in the
DAIC-WOZ dataset. We show that gender biases in DAIC-WOZ can lead to an
overreporting of performance. By different concepts from Fair Machine Learning,
such as data re-distribution, and using raw audio features, we can mitigate
against the harmful effects of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image. (arXiv:2012.09854v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Ronghang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_N/0/1/0/all/0/1">Nikhila Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_A/0/1/0/all/0/1">Alexander C. Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1">Deepak Pathak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09854">
                                    <div class="article-summary-box-inner">
                                        <span>We present Worldsheet, a method for novel view synthesis using just a single
RGB image as input. The main insight is that simply shrink-wrapping a planar
mesh sheet onto the input image, consistent with the learned intermediate
depth, captures underlying geometry sufficient to generate photorealistic
unseen views with large viewpoint changes. To operationalize this, we propose a
novel differentiable texture sampler that allows our wrapped mesh sheet to be
textured and rendered differentiably into an image from a target viewpoint. Our
approach is category-agnostic, end-to-end trainable without using any 3D
supervision, and requires a single image at test time. We also explore a simple
extension by stacking multiple layers of Worldsheets to better handle
occlusions. Worldsheet consistently outperforms prior state-of-the-art methods
on single-image view synthesis across several datasets. Furthermore, this
simple idea captures novel views surprisingly well on a wide range of
high-resolution in-the-wild images, converting them into navigable 3D pop-ups.
Video results and code are available at https://worldsheet.github.io.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inexact-ADMM Based Federated Meta-Learning for Fast and Continual Edge Learning. (arXiv:2012.08677v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1">Sheng Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Ju Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1">Jiang Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Sen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junshan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08677">
                                    <div class="article-summary-box-inner">
                                        <span>In order to meet the requirements for performance, safety, and latency in
many IoT applications, intelligent decisions must be made right here right now
at the network edge. However, the constrained resources and limited local data
amount pose significant challenges to the development of edge AI. To overcome
these challenges, we explore continual edge learning capable of leveraging the
knowledge transfer from previous tasks. Aiming to achieve fast and continual
edge learning, we propose a platform-aided federated meta-learning architecture
where edge nodes collaboratively learn a meta-model, aided by the knowledge
transfer from prior tasks. The edge learning problem is cast as a regularized
optimization problem, where the valuable knowledge learned from previous tasks
is extracted as regularization. Then, we devise an ADMM based federated
meta-learning algorithm, namely ADMM-FedMeta, where ADMM offers a natural
mechanism to decompose the original problem into many subproblems which can be
solved in parallel across edge nodes and the platform. Further, a variant of
inexact-ADMM method is employed where the subproblems are &#x60;solved&#x27; via linear
approximation as well as Hessian estimation to reduce the computational cost
per round to $\mathcal{O}(n)$. We provide a comprehensive analysis of
ADMM-FedMeta, in terms of the convergence properties, the rapid adaptation
performance, and the forgetting effect of prior knowledge transfer, for the
general non-convex case. Extensive experimental studies demonstrate the
effectiveness and efficiency of ADMM-FedMeta, and showcase that it
substantially outperforms the existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HuMoR: 3D Human Motion Model for Robust Pose Estimation. (arXiv:2105.04668v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rempe_D/0/1/0/all/0/1">Davis Rempe</a>, <a href="http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1">Tolga Birdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertzmann_A/0/1/0/all/0/1">Aaron Hertzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jimei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_S/0/1/0/all/0/1">Srinath Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas J. Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04668">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce HuMoR: a 3D Human Motion Model for Robust Estimation of temporal
pose and shape. Though substantial progress has been made in estimating 3D
human motion and shape from dynamic observations, recovering plausible pose
sequences in the presence of noise and occlusions remains a challenge. For this
purpose, we propose an expressive generative model in the form of a conditional
variational autoencoder, which learns a distribution of the change in pose at
each step of a motion sequence. Furthermore, we introduce a flexible
optimization-based approach that leverages HuMoR as a motion prior to robustly
estimate plausible pose and shape from ambiguous observations. Through
extensive evaluations, we demonstrate that our model generalizes to diverse
motions and body shapes after training on a large motion capture dataset, and
enables motion reconstruction from multiple input modalities including 3D
keypoints and RGB(-D) videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Listening to the city, attentively: A Spatio-Temporal Attention Boosted Autoencoder for the Short-Term Flow Prediction Problem. (arXiv:2103.00983v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fiorini_S/0/1/0/all/0/1">Stefano Fiorini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciavotta_M/0/1/0/all/0/1">Michele Ciavotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurino_A/0/1/0/all/0/1">Andrea Maurino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00983">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, studying and predicting alternative mobility (e.g., sharing
services) patterns in urban environments has become increasingly important as
accurate and timely information on current and future vehicle flows can
successfully increase the quality and availability of transportation services.
This need is aggravated during the current pandemic crisis, which pushes
policymakers and private citizens to seek social-distancing compliant urban
mobility services, such as electric bikes and scooter sharing offerings.
However, predicting the number of incoming and outgoing vehicles for different
city areas is challenging due to the nonlinear spatial and temporal
dependencies typical of urban mobility patterns. In this work, we propose
STREED-Net, a novel deep learning network with a multi-attention (spatial and
temporal) mechanism that effectively captures and exploits complex spatial and
temporal patterns in mobility data. The results of a thorough experimental
analysis using real-life data are reported, indicating that the proposed model
improves the state-of-the-art for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-Det3D: Self-Attention Based Context-Aware 3D Object Detection. (arXiv:2101.02672v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Prarthana Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chengjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Czarnecki_K/0/1/0/all/0/1">Krzysztof Czarnecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02672">
                                    <div class="article-summary-box-inner">
                                        <span>Existing point-cloud based 3D object detectors use convolution-like operators
to process information in a local neighbourhood with fixed-weight kernels and
aggregate global context hierarchically. However, non-local neural networks and
self-attention for 2D vision have shown that explicitly modeling long-range
interactions can lead to more robust and competitive models. In this paper, we
propose two variants of self-attention for contextual modeling in 3D object
detection by augmenting convolutional features with self-attention features. We
first incorporate the pairwise self-attention mechanism into the current
state-of-the-art BEV, voxel and point-based detectors and show consistent
improvement over strong baseline models of up to 1.5 3D AP while simultaneously
reducing their parameter footprint and computational cost by 15-80% and 30-50%,
respectively, on the KITTI validation set. We next propose a self-attention
variant that samples a subset of the most representative features by learning
deformations over randomly sampled locations. This not only allows us to scale
explicit global contextual modeling to larger point-clouds, but also leads to
more discriminative and informative feature descriptors. Our method can be
flexibly applied to most state-of-the-art detectors with increased accuracy and
parameter and compute efficiency. We show our proposed method improves 3D
object detection performance on KITTI, nuScenes and Waymo Open datasets. Code
is available at https://github.com/AutoVision-cloud/SA-Det3D.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive KL-UCB based Bandit Algorithms for Markovian and i.i.d. Settings. (arXiv:2009.06606v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Arghyadip Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06606">
                                    <div class="article-summary-box-inner">
                                        <span>In the regret-based formulation of Multi-armed Bandit (MAB) problems, except
in rare instances, much of the literature focuses on arms with i.i.d. rewards.
In this paper, we consider the problem of obtaining regret guarantees for MAB
problems in which the rewards of each arm form a Markov chain which may not
belong to a single parameter exponential family. To achieve logarithmic regret
in such problems is not difficult: a variation of standard Kullback-Leibler
Upper Confidence Bound (KL-UCB) does the job. However, the constants obtained
from such an analysis are poor for the following reason: i.i.d. rewards are a
special case of Markov rewards and it is difficult to design an algorithm that
works well independent of whether the underlying model is truly Markovian or
i.i.d. To overcome this issue, we introduce a novel algorithm that identifies
whether the rewards from each arm are truly Markovian or i.i.d. using a total
variation distance-based test. Our algorithm then switches from using a
standard KL-UCB to a specialized version of KL-UCB when it determines that the
arm reward is Markovian, thus resulting in low regret for both i.i.d. and
Markovian settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BIKED: A Dataset for Computational Bicycle Design with Machine Learning Benchmarks. (arXiv:2103.05844v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Regenwetter_L/0/1/0/all/0/1">Lyle Regenwetter</a>, <a href="http://arxiv.org/find/cs/1/au:+Curry_B/0/1/0/all/0/1">Brent Curry</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1">Faez Ahmed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05844">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present &quot;BIKED,&quot; a dataset comprised of 4500 individually
designed bicycle models sourced from hundreds of designers. We expect BIKED to
enable a variety of data-driven design applications for bicycles and support
the development of data-driven design methods. The dataset is comprised of a
variety of design information including assembly images, component images,
numerical design parameters, and class labels. In this paper, we first discuss
the processing of the dataset, then highlight some prominent research questions
that BIKED can help address. Of these questions, we further explore the
following in detail: 1) Are there prominent gaps in the current bicycle market
and design space? We explore the design space using unsupervised dimensionality
reduction methods. 2) How does one identify the class of a bicycle and what
factors play a key role in defining it? We address the bicycle classification
task by training a multitude of classifiers using different forms of design
data and identifying parameters of particular significance through
permutation-based interpretability analysis. 3) How does one synthesize new
bicycles using different representation methods? We consider numerous machine
learning methods to generate new bicycle models as well as interpolate between
and extrapolate from existing models using Variational Autoencoders. The
dataset and code are available at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Membership Inference Attacks are Easier on Difficult Problems. (arXiv:2102.07762v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shafran_A/0/1/0/all/0/1">Avital Shafran</a>, <a href="http://arxiv.org/find/cs/1/au:+Peleg_S/0/1/0/all/0/1">Shmuel Peleg</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07762">
                                    <div class="article-summary-box-inner">
                                        <span>Membership inference attacks (MIA) try to detect if data samples were used to
train a neural network model, e.g. to detect copyright abuses. We show that
models with higher dimensional input and output are more vulnerable to MIA, and
address in more detail models for image translation and semantic segmentation,
including medical image segmentation. We show that reconstruction-errors can
lead to very effective MIA attacks as they are indicative of memorization.
Unfortunately, reconstruction error alone is less effective at discriminating
between non-predictable images used in training and easy to predict images that
were never seen before. To overcome this, we propose using a novel
predictability error that can be computed for each sample, and its computation
does not require a training set. Our membership error, obtained by subtracting
the predictability error from the reconstruction error, is shown to achieve
high MIA accuracy on an extensive number of benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neuromorphic Computing for Content-based Image Retrieval. (arXiv:2008.01380v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Te-Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahjoubfar_A/0/1/0/all/0/1">Ata Mahjoubfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Prusinski_D/0/1/0/all/0/1">Daniel Prusinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_L/0/1/0/all/0/1">Luis Stevens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01380">
                                    <div class="article-summary-box-inner">
                                        <span>Neuromorphic computing mimics the neural activity of the brain through
emulating spiking neural networks. In numerous machine learning tasks,
neuromorphic chips are expected to provide superior solutions in terms of cost
and power efficiency. Here, we explore the application of Loihi, a neuromorphic
computing chip developed by Intel, for the computer vision task of image
retrieval. We evaluated the functionalities and the performance metrics that
are critical in content-based visual search and recommender systems using
deep-learning embeddings. Our results show that the neuromorphic solution is
about 2.5 times more energy-efficient compared with an ARM Cortex-A72 CPU and
12.5 times more energy-efficient compared with NVIDIA T4 GPU for inference by a
lightweight convolutional neural network without batching while maintaining the
same level of matching accuracy. The study validates the potential of
neuromorphic computing in low-power image retrieval, as a complementary
paradigm to the existing von Neumann architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Graph Memory Networks for Forgetting-Robust Knowledge Tracing. (arXiv:2108.08105v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdelrahman_G/0/1/0/all/0/1">Ghodai Abdelrahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08105">
                                    <div class="article-summary-box-inner">
                                        <span>Tracing a student&#x27;s knowledge is vital for tailoring the learning experience.
Recent knowledge tracing methods tend to respond to these challenges by
modelling knowledge state dynamics across learning concepts. However, they
still suffer from several inherent challenges including: modelling forgetting
behaviours and identifying relationships among latent concepts. To address
these challenges, in this paper, we propose a novel knowledge tracing model,
namely \emph{Deep Graph Memory Network} (DGMN). In this model, we incorporate a
forget gating mechanism into an attention memory structure in order to capture
forgetting behaviours dynamically during the knowledge tracing process.
Particularly, this forget gating mechanism is built upon attention forgetting
features over latent concepts considering their mutual dependencies. Further,
this model has the capability of learning relationships between latent concepts
from a dynamic latent concept graph in light of a student&#x27;s evolving knowledge
states. A comprehensive experimental evaluation has been conducted using four
well-established benchmark datasets. The results show that DGMN consistently
outperforms the state-of-the-art KT models over all the datasets. The
effectiveness of modelling forgetting behaviours and learning latent concept
graphs has also been analyzed in our experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Regression with Distributed Learning: A Generalization Error Perspective. (arXiv:2101.09001v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hellkvist_M/0/1/0/all/0/1">Martin Hellkvist</a>, <a href="http://arxiv.org/find/stat/1/au:+Ozcelikkale_A/0/1/0/all/0/1">Ay&#xe7;a &#xd6;z&#xe7;elikkale</a>, <a href="http://arxiv.org/find/stat/1/au:+Ahlen_A/0/1/0/all/0/1">Anders Ahl&#xe9;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09001">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed learning provides an attractive framework for scaling the
learning task by sharing the computational load over multiple nodes in a
network. Here, we investigate the performance of distributed learning for
large-scale linear regression where the model parameters, i.e., the unknowns,
are distributed over the network. We adopt a statistical learning approach. In
contrast to works that focus on the performance on the training data, we focus
on the generalization error, i.e., the performance on unseen data. We provide
high-probability bounds on the generalization error for both isotropic and
correlated Gaussian data as well as sub-gaussian data. These results reveal the
dependence of the generalization performance on the partitioning of the model
over the network. In particular, our results show that the generalization error
of the distributed solution can be substantially higher than that of the
centralized solution even when the error on the training data is at the same
level for both the centralized and distributed approaches. Our numerical
results illustrate the performance with both real-world image data as well as
synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fed-TGAN: Federated Learning Framework for Synthesizing Tabular Data. (arXiv:2108.07927v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zilong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Birke_R/0/1/0/all/0/1">Robert Birke</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunar_A/0/1/0/all/0/1">Aditya Kunar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lydia Y. Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07927">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) are typically trained to synthesize
data, from images and more recently tabular data, under the assumption of
directly accessible training data. Recently, federated learning (FL) is an
emerging paradigm that features decentralized learning on client&#x27;s local data
with a privacy-preserving capability. And, while learning GANs to synthesize
images on FL systems has just been demonstrated, it is unknown if GANs for
tabular data can be learned from decentralized data sources. Moreover, it
remains unclear which distributed architecture suits them best. Different from
image GANs, state-of-the-art tabular GANs require prior knowledge on the data
distribution of each (discrete and continuous) column to agree on a common
encoding -- risking privacy guarantees. In this paper, we propose Fed-TGAN, the
first Federated learning framework for Tabular GANs. To effectively learn a
complex tabular GAN on non-identical participants, Fed-TGAN designs two novel
features: (i) a privacy-preserving multi-source feature encoding for model
initialization; and (ii) table similarity aware weighting strategies to
aggregate local models for countering data skew. We extensively evaluate the
proposed Fed-TGAN against variants of decentralized learning architectures on
four widely used datasets. Results show that Fed-TGAN accelerates training time
per epoch up to 200% compared to the alternative architectures, for both IID
and Non-IID data. Overall, Fed-TGAN not only stabilizes the training loss, but
also achieves better similarity between generated and original data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOME/IP Intrusion Detection using Deep Learning-based Sequential Models in Automotive Ethernet Networks. (arXiv:2108.08262v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alkhatib_N/0/1/0/all/0/1">Natasha Alkhatib</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghauch_H/0/1/0/all/0/1">Hadi Ghauch</a>, <a href="http://arxiv.org/find/cs/1/au:+Danger_J/0/1/0/all/0/1">Jean-Luc Danger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08262">
                                    <div class="article-summary-box-inner">
                                        <span>Intrusion Detection Systems are widely used to detect cyberattacks,
especially on protocols vulnerable to hacking attacks such as SOME/IP. In this
paper, we present a deep learning-based sequential model for offline intrusion
detection on SOME/IP application layer protocol. To assess our intrusion
detection system, we have generated and labeled a dataset with several classes
representing realistic intrusions, and a normal class - a significant
contribution due to the absence of such publicly available datasets.
Furthermore, we also propose a simple recurrent neural network (RNN), as an
instance of deep learning-based sequential model, that we apply to our
generated dataset. The numerical results show that RNN excel at predicting
in-vehicle intrusions, with F1 Scores and AUC values of 0.99 for each type of
intrusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Pricing in Machine Learning Pipelines. (arXiv:2108.07915v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cong_Z/0/1/0/all/0/1">Zicun Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xuan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1">Pei Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feida Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07915">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning is disruptive. At the same time, machine learning can only
succeed by collaboration among many parties in multiple steps naturally as
pipelines in an eco-system, such as collecting data for possible machine
learning applications, collaboratively training models by multiple parties and
delivering machine learning services to end users. Data is critical and
penetrating in the whole machine learning pipelines. As machine learning
pipelines involve many parties and, in order to be successful, have to form a
constructive and dynamic eco-system, marketplaces and data pricing are
fundamental in connecting and facilitating those many parties. In this article,
we survey the principles and the latest research development of data pricing in
machine learning pipelines. We start with a brief review of data marketplaces
and pricing desiderata. Then, we focus on pricing in three important steps in
machine learning pipelines. To understand pricing in the step of training data
collection, we review pricing raw data sets and data labels. We also
investigate pricing in the step of collaborative training of machine learning
models, and overview pricing machine learning models for end users in the step
of machine learning deployment. We also discuss a series of possible future
directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining K-means type algorithms with Hill Climbing for Joint Stratification and Sample Allocation Designs. (arXiv:2108.08038v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+OLuing_M/0/1/0/all/0/1">Mervyn O&#x27;Luing</a>, <a href="http://arxiv.org/find/stat/1/au:+Prestwich_S/0/1/0/all/0/1">Steven Prestwich</a>, <a href="http://arxiv.org/find/stat/1/au:+Tarim_S/0/1/0/all/0/1">S. Armagan Tarim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08038">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we combine the k-means and/or k-means type algorithms with a
hill climbing algorithm in stages to solve the joint stratification and sample
allocation problem. This is a combinatorial optimisation problem in which we
search for the optimal stratification from the set of all possible
stratifications of basic strata. Each stratification being a solution the
quality of which is measured by its cost. This problem is intractable for
larger sets. Furthermore evaluating the cost of each solution is expensive. A
number of heuristic algorithms have already been developed to solve this
problem with the aim of finding acceptable solutions in reasonable computation
times. However, the heuristics for these algorithms need to be trained in order
to optimise performance in each instance. We compare the above multi-stage
combination of algorithms with three recent algorithms and report the solution
costs, evaluation times and training times. The multi-stage combinations
generally compare well with the recent algorithms both in the case of atomic
and continuous strata and provide the survey designer with a greater choice of
algorithms to choose from.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coverage Hole Detection for mmWave Networks: An Unsupervised Learning Approach. (arXiv:2108.07854v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anjinappa_C/0/1/0/all/0/1">Chethan K. Anjinappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Guvenc_I/0/1/0/all/0/1">Ismail Guvenc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07854">
                                    <div class="article-summary-box-inner">
                                        <span>The utilization of millimeter-wave (mmWave) bands in 5G networks poses new
challenges to network planning. Vulnerability to blockages at mmWave bands can
cause coverage holes (CHs) in the radio environment, leading to radio link
failure when a user enters these CHs. Detection of the CHs carries critical
importance so that necessary remedies can be introduced to improve coverage. In
this letter, we propose a novel approach to identify the CHs in an unsupervised
fashion using a state-of-the-art manifold learning technique: uniform manifold
approximation and projection. The key idea is to preserve the
local-connectedness structure inherent in the collected unlabelled channel
samples, such that the CHs from the service area are detectable. Our results on
the DeepMIMO dataset scenario demonstrate that the proposed method can learn
the structure within the data samples and provide visual holes in the
low-dimensional embedding while preserving the CH boundaries. Once the CH
boundary is determined in the low-dimensional embedding, channel-based
localization techniques can be applied to these samples to obtain the
geographical boundaries of the CHs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Casual Inference using Deep Bayesian Dynamic Survival Model (CDS). (arXiv:2101.10643v8 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1">Jie Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Gallego_B/0/1/0/all/0/1">Blanca Gallego</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10643">
                                    <div class="article-summary-box-inner">
                                        <span>Causal inference in longitudinal observational health data often requires the
accurate estimation of treatment effects on time-to-event outcomes in the
presence of time-varying covariates. To tackle this sequential treatment effect
estimation problem, we have developed a causal dynamic survival (CDS) model
that uses the potential outcomes framework with the recurrent sub-networks with
random seed ensembles to estimate the difference in survival curves of its
confidence interval. Using simulated survival datasets, the CDS model has shown
good causal effect estimation performance across scenarios of sample dimension,
event rate, confounding and overlapping. However, increasing the sample size is
not effective to alleviate the adverse impact from high level of confounding.
In two large clinical cohort studies, our model identified the expected
conditional average treatment effect and detected individual effect
heterogeneity over time and patient subgroups. CDS provides individualised
absolute treatment effect estimations to improve clinical decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Neural Networks With Benford&#x27;s Law. (arXiv:2102.03313v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1">Surya Kant Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1">Abhinav Java</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1">Arshad Shaikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilcher_Y/0/1/0/all/0/1">Yannic Kilcher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03313">
                                    <div class="article-summary-box-inner">
                                        <span>Benford&#x27;s Law (BL) or the Significant Digit Law defines the probability
distribution of the first digit of numerical values in a data sample. This Law
is observed in many naturally occurring datasets. It can be seen as a measure
of naturalness of a given distribution and finds its application in areas like
anomaly and fraud detection. In this work, we address the following question:
Is the distribution of the Neural Network parameters related to the network&#x27;s
generalization capability? To that end, we first define a metric, MLH (Model
Enthalpy),that measures the closeness of a set of numbers to Benford&#x27;s Law and
we show empirically that it is a strong predictor of Validation Accuracy.
Second, we use MLH as an alternative to Validation Accuracy for Early Stopping,
removing the need for a Validation set. We provide experimental evidence that
even if the optimal size of the validation set is known before-hand, the peak
test accuracy attained is lower than not using a validation set at all.
Finally, we investigate the connection of BL to Free Energy Principle and First
Law of Thermodynamics, showing that MLH is a component of the internal energy
of the learning system and optimization as an analogy to minimizing the total
energy to attain equilibrium.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCVA: Automated Commit-level Vulnerability Assessment with Deep Multi-task Learning. (arXiv:2108.08041v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Triet H. M. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Hin_D/0/1/0/all/0/1">David Hin</a>, <a href="http://arxiv.org/find/cs/1/au:+Croft_R/0/1/0/all/0/1">Roland Croft</a>, <a href="http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1">M. Ali Babar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08041">
                                    <div class="article-summary-box-inner">
                                        <span>It is increasingly suggested to identify Software Vulnerabilities (SVs) in
code commits to give early warnings about potential security risks. However,
there is a lack of effort to assess vulnerability-contributing commits right
after they are detected to provide timely information about the exploitability,
impact and severity of SVs. Such information is important to plan and
prioritize the mitigation for the identified SVs. We propose a novel Deep
multi-task learning model, DeepCVA, to automate seven Commit-level
Vulnerability Assessment tasks simultaneously based on Common Vulnerability
Scoring System (CVSS) metrics. We conduct large-scale experiments on 1,229
vulnerability-contributing commits containing 542 different SVs in 246
real-world software projects to evaluate the effectiveness and efficiency of
our model. We show that DeepCVA is the best-performing model with 38% to 59.8%
higher Matthews Correlation Coefficient than many supervised and unsupervised
baseline models. DeepCVA also requires 6.3 times less training and validation
time than seven cumulative assessment models, leading to significantly less
model maintenance cost as well. Overall, DeepCVA presents the first effective
and efficient solution to automatically assess SVs early in software systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure Parameter Optimized Kernel Based Online Prediction with a Generalized Optimization Strategy for Nonstationary Time Series. (arXiv:2108.08180v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Guo_J/0/1/0/all/0/1">Jinhua Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jingxin Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1">Sheng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08180">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, sparsification techniques aided online prediction algorithms
in a reproducing kernel Hilbert space are studied for nonstationary time
series. The online prediction algorithms as usual consist of the selection of
kernel structure parameters and the kernel weight vector updating. For
structure parameters, the kernel dictionary is selected by some sparsification
techniques with online selective modeling criteria, and moreover the kernel
covariance matrix is intermittently optimized in the light of the covariance
matrix adaptation evolution strategy (CMA-ES). Optimizing the real symmetric
covariance matrix can not only improve the kernel structure&#x27;s flexibility by
the cross relatedness of the input variables, but also partly alleviate the
prediction uncertainty caused by the kernel dictionary selection for
nonstationary time series. In order to sufficiently capture the underlying
dynamic characteristics in prediction-error time series, a generalized
optimization strategy is designed to construct the kernel dictionary
sequentially in multiple kernel connection modes. The generalized optimization
strategy provides a more self-contained way to construct the entire kernel
connections, which enhances the ability to adaptively track the changing
dynamic characteristics. Numerical simulations have demonstrated that the
proposed approach has superior prediction performance for nonstationary time
series.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpreting Zoonotic Potential of Betacoronavirus Sequences With Attention. (arXiv:2108.08077v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Wadhawan_K/0/1/0/all/0/1">Kahini Wadhawan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Han_B/0/1/0/all/0/1">Barbara A. Han</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Fischhoff_I/0/1/0/all/0/1">Ilya R. Fischhoff</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Castellanos_A/0/1/0/all/0/1">Adrian C. Castellanos</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Varsani_A/0/1/0/all/0/1">Arvind Varsani</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Varshney_K/0/1/0/all/0/1">Kush R. Varshney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08077">
                                    <div class="article-summary-box-inner">
                                        <span>Current methods for viral discovery target evolutionarily conserved proteins
that accurately identify virus families but remain unable to distinguish the
zoonotic potential of newly discovered viruses. Here, we apply an
attention-enhanced long-short-term memory (LSTM) deep neural net classifier to
a highly conserved viral protein target to predict zoonotic potential across
betacoronaviruses. The classifier performs with a 94% accuracy. Analysis and
visualization of attention at the sequence and structure-level features
indicate possible association between important protein-protein interactions
governing viral replication in zoonotic betacoronaviruses and zoonotic
transmission.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised tensor decomposition with features on multiple modes. (arXiv:1910.09499v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hu_J/0/1/0/all/0/1">Jiaxin Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_C/0/1/0/all/0/1">Chanwoo Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_M/0/1/0/all/0/1">Miaoyan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.09499">
                                    <div class="article-summary-box-inner">
                                        <span>Higher-order tensors have received increased attention across science and
engineering. While most tensor decomposition methods are developed for a single
tensor observation, scientific studies often collect side information, in the
form of node features and interactions thereof, together with the tensor data.
Such data problems are common in neuroimaging, network analysis, and
spatial-temporal modeling. Identifying the relationship between a
high-dimensional tensor and side information is important yet challenging.
Here, we develop a tensor decomposition method that incorporates multiple
feature matrices as side information. Unlike unsupervised tensor decomposition,
our supervised decomposition captures the effective dimension reduction of the
data tensor confined to feature space of interest. An efficient alternating
optimization algorithm with provable spectral initialization is further
developed. Our proposal handles a broad range of data types, including
continuous, count, and binary observations. We apply the method to diffusion
tensor imaging data from human connectome project and multi-relational
political network data. We identify the key global connectivity pattern and
pinpoint the local regions that are associated with available features. Our
simulation code, R-package tensorregress, and datasets used in the paper are
available at https://CRAN.R-project.org/package&#x3D;tensorregress.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Shift Equivariance Impacts Metric Learning for Instance Segmentation. (arXiv:2101.05846v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rumberger_J/0/1/0/all/0/1">Josef Lorenz Rumberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaoyan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirsch_P/0/1/0/all/0/1">Peter Hirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohmen_M/0/1/0/all/0/1">Melanie Dohmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guarino_V/0/1/0/all/0/1">Vanessa Emanuela Guarino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mokarian_A/0/1/0/all/0/1">Ashkan Mokarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Mais_L/0/1/0/all/0/1">Lisa Mais</a>, <a href="http://arxiv.org/find/cs/1/au:+Funke_J/0/1/0/all/0/1">Jan Funke</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainmueller_D/0/1/0/all/0/1">Dagmar Kainmueller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05846">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning has received conflicting assessments concerning its
suitability for solving instance segmentation tasks. It has been dismissed as
theoretically flawed due to the shift equivariance of the employed CNNs and
their respective inability to distinguish same-looking objects. Yet it has been
shown to yield state of the art results for a variety of tasks, and practical
issues have mainly been reported in the context of tile-and-stitch approaches,
where discontinuities at tile boundaries have been observed. To date, neither
of the reported issues have undergone thorough formal analysis. In our work, we
contribute a comprehensive formal analysis of the shift equivariance properties
of encoder-decoder-style CNNs, which yields a clear picture of what can and
cannot be achieved with metric learning in the face of same-looking objects. In
particular, we prove that a standard encoder-decoder network that takes
$d$-dimensional images as input, with $l$ pooling layers and pooling factor
$f$, has the capacity to distinguish at most $f^{dl}$ same-looking objects, and
we show that this upper limit can be reached. Furthermore, we show that to
avoid discontinuities in a tile-and-stitch approach, assuming standard batch
size 1, it is necessary to employ valid convolutions in combination with a
training output window size strictly greater than $f^l$, while at test-time it
is necessary to crop tiles to size $n\cdot f^l$ before stitching, with $n\geq
1$. We complement these theoretical findings by discussing a number of
insightful special cases for which we show empirical results on synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RANK-NOSH: Efficient Predictor-Based Architecture Search via Non-Uniform Successive Halving. (arXiv:2108.08019v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruochen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Minhao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08019">
                                    <div class="article-summary-box-inner">
                                        <span>Predictor-based algorithms have achieved remarkable performance in the Neural
Architecture Search (NAS) tasks. However, these methods suffer from high
computation costs, as training the performance predictor usually requires
training and evaluating hundreds of architectures from scratch. Previous works
along this line mainly focus on reducing the number of architectures required
to fit the predictor. In this work, we tackle this challenge from a different
perspective - improve search efficiency by cutting down the computation budget
of architecture training. We propose NOn-uniform Successive Halving (NOSH), a
hierarchical scheduling algorithm that terminates the training of
underperforming architectures early to avoid wasting budget. To effectively
leverage the non-uniform supervision signals produced by NOSH, we formulate
predictor-based architecture search as learning to rank with pairwise
comparisons. The resulting method - RANK-NOSH, reduces the search budget by ~5x
while achieving competitive or even better performance than previous
state-of-the-art predictor-based methods on various spaces and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OncoPetNet: A Deep Learning based AI system for mitotic figure counting on H&amp;E stained whole slide digital images in a large veterinary diagnostic lab setting. (arXiv:2108.07856v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fitzke_M/0/1/0/all/0/1">Michael Fitzke</a>, <a href="http://arxiv.org/find/eess/1/au:+Whitley_D/0/1/0/all/0/1">Derick Whitley</a>, <a href="http://arxiv.org/find/eess/1/au:+Yau_W/0/1/0/all/0/1">Wilson Yau</a>, <a href="http://arxiv.org/find/eess/1/au:+Rodrigues_F/0/1/0/all/0/1">Fernando Rodrigues Jr</a>, <a href="http://arxiv.org/find/eess/1/au:+Fadeev_V/0/1/0/all/0/1">Vladimir Fadeev</a>, <a href="http://arxiv.org/find/eess/1/au:+Bacmeister_C/0/1/0/all/0/1">Cindy Bacmeister</a>, <a href="http://arxiv.org/find/eess/1/au:+Carter_C/0/1/0/all/0/1">Chris Carter</a>, <a href="http://arxiv.org/find/eess/1/au:+Edwards_J/0/1/0/all/0/1">Jeffrey Edwards</a>, <a href="http://arxiv.org/find/eess/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/eess/1/au:+Parkinson_M/0/1/0/all/0/1">Mark Parkinson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07856">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Histopathology is an important modality for the diagnosis and
management of many diseases in modern healthcare, and plays a critical role in
cancer care. Pathology samples can be large and require multi-site sampling,
leading to upwards of 20 slides for a single tumor, and the human-expert tasks
of site selection and and quantitative assessment of mitotic figures are time
consuming and subjective. Automating these tasks in the setting of a digital
pathology service presents significant opportunities to improve workflow
efficiency and augment human experts in practice. Approach: Multiple
state-of-the-art deep learning techniques for histopathology image
classification and mitotic figure detection were used in the development of
OncoPetNet. Additionally, model-free approaches were used to increase speed and
accuracy. The robust and scalable inference engine leverages Pytorch&#x27;s
performance optimizations as well as specifically developed speed up techniques
in inference. Results: The proposed system, demonstrated significantly improved
mitotic counting performance for 41 cancer cases across 14 cancer types
compared to human expert baselines. In 21.9% of cases use of OncoPetNet led to
change in tumor grading compared to human expert evaluation. In deployment, an
effective 0.27 min/slide inference was achieved in a high throughput veterinary
diagnostic pathology service across 2 centers processing 3,323 digital whole
slide images daily. Conclusion: This work represents the first successful
automated deployment of deep learning systems for real-time expert-level
performance on important histopathology tasks at scale in a high volume
clinical practice. The resulting impact outlines important considerations for
model development, deployment, clinical decision making, and informs best
practices for implementation of deep learning systems in digital histopathology
practices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aggregated Customer Engagement Model. (arXiv:2108.07872v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gupta_P/0/1/0/all/0/1">Priya Gupta</a>, <a href="http://arxiv.org/find/stat/1/au:+Han_C/0/1/0/all/0/1">Cuize Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07872">
                                    <div class="article-summary-box-inner">
                                        <span>E-commerce websites use machine learned ranking models to serve shopping
results to customers. Typically, the websites log the customer search events,
which include the query entered and the resulting engagement with the shopping
results, such as clicks and purchases. Each customer search event serves as
input training data for the models, and the individual customer engagement
serves as a signal for customer preference. So a purchased shopping result, for
example, is perceived to be more important than one that is not. However, new
or under-impressed products do not have enough customer engagement signals and
end up at a disadvantage when being ranked alongside popular products. In this
paper, we propose a novel method for data curation that aggregates all customer
engagements within a day for the same query to use as input training data. This
aggregated customer engagement gives the models a complete picture of the
relative importance of shopping results. Training models on this aggregated
data leads to less reliance on behavioral features. This helps mitigate the
cold start problem and boosted relevant new products to top search results. In
this paper, we present the offline and online analysis and results comparing
the individual and aggregated customer engagement models trained on e-commerce
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XAI Methods for Neural Time Series Classification: A Brief Review. (arXiv:2108.08009v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simic_I/0/1/0/all/0/1">Ilija &#x160;imi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabol_V/0/1/0/all/0/1">Vedran Sabol</a>, <a href="http://arxiv.org/find/cs/1/au:+Veas_E/0/1/0/all/0/1">Eduardo Veas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08009">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models have recently demonstrated remarkable results in a
variety of tasks, which is why they are being increasingly applied in
high-stake domains, such as industry, medicine, and finance. Considering that
automatic predictions in these domains might have a substantial impact on the
well-being of a person, as well as considerable financial and legal
consequences to an individual or a company, all actions and decisions that
result from applying these models have to be accountable. Given that a
substantial amount of data that is collected in high-stake domains are in the
form of time series, in this paper we examine the current state of eXplainable
AI (XAI) methods with a focus on approaches for opening up deep learning black
boxes for the task of time series classification. Finally, our contribution
also aims at deriving promising directions for future work, to advance XAI for
deep learning on time series data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M-ar-K-Fast Independent Component Analysis. (arXiv:2108.07908v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parisi_L/0/1/0/all/0/1">Luca Parisi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07908">
                                    <div class="article-summary-box-inner">
                                        <span>This study presents the m-arcsinh Kernel (&#x27;m-ar-K&#x27;) Fast Independent
Component Analysis (&#x27;FastICA&#x27;) method (&#x27;m-ar-K-FastICA&#x27;) for feature
extraction. The kernel trick has enabled dimensionality reduction techniques to
capture a higher extent of non-linearity in the data; however, reproducible,
open-source kernels to aid with feature extraction are still limited and may
not be reliable when projecting features from entropic data. The m-ar-K
function, freely available in Python and compatible with its open-source
library &#x27;scikit-learn&#x27;, is hereby coupled with FastICA to achieve more reliable
feature extraction in presence of a high extent of randomness in the data,
reducing the need for pre-whitening. Different classification tasks were
considered, as related to five (N &#x3D; 5) open access datasets of various degrees
of information entropy, available from scikit-learn and the University
California Irvine (UCI) Machine Learning repository. Experimental results
demonstrate improvements in the classification performance brought by the
proposed feature extraction. The novel m-ar-K-FastICA dimensionality reduction
approach is compared to the &#x27;FastICA&#x27; gold standard method, supporting its
higher reliability and computational efficiency, regardless of the underlying
uncertainty in the data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Federated Representations and Recommendations with Limited Negatives. (arXiv:2108.07931v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ning_L/0/1/0/all/0/1">Lin Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1">Karan Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Ellie X. Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1">Sushant Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07931">
                                    <div class="article-summary-box-inner">
                                        <span>Deep retrieval models are widely used for learning entity representations and
recommendations. Federated learning provides a privacy-preserving way to train
these models without requiring centralization of user data. However, federated
deep retrieval models usually perform much worse than their centralized
counterparts due to non-IID (independent and identically distributed) training
data on clients, an intrinsic property of federated learning that limits
negatives available for training. We demonstrate that this issue is distinct
from the commonly studied client drift problem. This work proposes
batch-insensitive losses as a way to alleviate the non-IID negatives issue for
federated movie recommendation. We explore a variety of techniques and identify
that batch-insensitive losses can effectively improve the performance of
federated deep retrieval models, increasing the relative recall of the
federated model by up to 93.15% and reducing the relative gap in recall between
it and a centralized model from 27.22% - 43.14% to 0.53% - 2.42%. We
open-source our code framework to accelerate further research and applications
of federated deep retrieval models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformers predicting the future. Applying attention in next-frame and time series forecasting. (arXiv:2108.08224v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cholakov_R/0/1/0/all/0/1">Radostin Cholakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolev_T/0/1/0/all/0/1">Todor Kolev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08224">
                                    <div class="article-summary-box-inner">
                                        <span>Recurrent Neural Networks were, until recently, one of the best ways to
capture the timely dependencies in sequences. However, with the introduction of
the Transformer, it has been proven that an architecture with only
attention-mechanisms without any RNN can improve on the results in various
sequence processing tasks (e.g. NLP). Multiple studies since then have shown
that similar approaches can be applied for images, point clouds, video, audio
or time series forecasting. Furthermore, solutions such as the Perceiver or the
Informer have been introduced to expand on the applicability of the
Transformer. Our main objective is testing and evaluating the effectiveness of
applying Transformer-like models on time series data, tackling susceptibility
to anomalies, context awareness and space complexity by fine-tuning the
hyperparameters, preprocessing the data, applying dimensionality reduction or
convolutional encodings, etc. We are also looking at the problem of next-frame
prediction and exploring ways to modify existing solutions in order to achieve
higher performance and learn generalized knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TB-ICT: A Trustworthy Blockchain-Enabled System for Indoor COVID-19 Contact Tracing. (arXiv:2108.08275v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salimibeni_M/0/1/0/all/0/1">Mohammad Salimibeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiakhondi_Meybodi_Z/0/1/0/all/0/1">Zohreh Hajiakhondi-Meybodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1">Arash Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingxu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08275">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, as a consequence of the COVID-19 pandemic, dependence on Contact
Tracing (CT) models has significantly increased to prevent spread of this
highly contagious virus and be prepared for the potential future ones. Since
the spreading probability of the novel coronavirus in indoor environments is
much higher than that of the outdoors, there is an urgent and unmet quest to
develop/design efficient, autonomous, trustworthy, and secure indoor CT
solutions. Despite such an urgency, this field is still in its infancy. The
paper addresses this gap and proposes the Trustworthy Blockchain-enabled system
for Indoor Contact Tracing (TB-ICT) framework. The TB-ICT framework is proposed
to protect privacy and integrity of the underlying CT data from unauthorized
access. More specifically, it is a fully distributed and innovative blockchain
platform exploiting the proposed dynamic Proof of Work (dPoW) credit-based
consensus algorithm coupled with Randomized Hash Window (W-Hash) and dynamic
Proof of Credit (dPoC) mechanisms to differentiate between honest and dishonest
nodes. The TB-ICT not only provides a decentralization in data replication but
also quantifies the node&#x27;s behavior based on its underlying credit-based
mechanism. For achieving high localization performance, we capitalize on
availability of Internet of Things (IoT) indoor localization infrastructures,
and develop a data driven localization model based on Bluetooth Low Energy
(BLE) sensor measurements. The simulation results show that the proposed TB-ICT
prevents the COVID-19 from spreading by implementation of a highly accurate
contact tracing model while improving the users&#x27; privacy and security.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Belief Learning. (arXiv:2103.04000v5 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hengyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1">Adam Lerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Brandon Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">David Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1">Luis Pineda</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1">Noam Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04000">
                                    <div class="article-summary-box-inner">
                                        <span>The standard problem setting in Dec-POMDPs is self-play, where the goal is to
find a set of policies that play optimally together. Policies learned through
self-play may adopt arbitrary conventions and implicitly rely on multi-step
reasoning based on fragile assumptions about other agents&#x27; actions and thus
fail when paired with humans or independently trained agents at test time. To
address this, we present off-belief learning (OBL). At each timestep OBL agents
follow a policy $\pi_1$ that is optimized assuming past actions were taken by a
given, fixed policy ($\pi_0$), but assuming that future actions will be taken
by $\pi_1$. When $\pi_0$ is uniform random, OBL converges to an optimal policy
that does not rely on inferences based on other agents&#x27; behavior (an optimal
grounded policy). OBL can be iterated in a hierarchy, where the optimal policy
from one level becomes the input to the next, thereby introducing multi-level
cognitive reasoning in a controlled manner. Unlike existing approaches, which
may converge to any equilibrium policy, OBL converges to a unique policy,
making it suitable for zero-shot coordination (ZSC). OBL can be scaled to
high-dimensional settings with a fictitious transition mechanism and shows
strong performance in both a toy-setting and the benchmark human-AI &amp; ZSC
problem Hanabi.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bagging Supervised Autoencoder Classifier for Credit Scoring. (arXiv:2108.07800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdoli_M/0/1/0/all/0/1">Mahsan Abdoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbari_M/0/1/0/all/0/1">Mohammad Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahrabi_J/0/1/0/all/0/1">Jamal Shahrabi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07800">
                                    <div class="article-summary-box-inner">
                                        <span>Credit scoring models, which are among the most potent risk management tools
that banks and financial institutes rely on, have been a popular subject for
research in the past few decades. Accordingly, many approaches have been
developed to address the challenges in classifying loan applicants and improve
and facilitate decision-making. The imbalanced nature of credit scoring
datasets, as well as the heterogeneous nature of features in credit scoring
datasets, pose difficulties in developing and implementing effective credit
scoring models, targeting the generalization power of classification models on
unseen data. In this paper, we propose the Bagging Supervised Autoencoder
Classifier (BSAC) that mainly leverages the superior performance of the
Supervised Autoencoder, which learns low-dimensional embeddings of the input
data exclusively with regards to the ultimate classification task of credit
scoring, based on the principles of multi-task learning. BSAC also addresses
the data imbalance problem by employing a variant of the Bagging process based
on the undersampling of the majority class. The obtained results from our
experiments on the benchmark and real-life credit scoring datasets illustrate
the robustness and effectiveness of the Bagging Supervised Autoencoder
Classifier in the classification of loan applicants that can be regarded as a
positive development in credit scoring models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparsely Activated Networks. (arXiv:1907.06592v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bizopoulos_P/0/1/0/all/0/1">Paschalis Bizopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Koutsouris_D/0/1/0/all/0/1">Dimitrios Koutsouris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.06592">
                                    <div class="article-summary-box-inner">
                                        <span>Previous literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features. However, this was done
without considering the description length of the learned representations which
is a direct and unbiased measure of the model complexity. In this paper, first
we introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined $\varphi$. We lastly present Sparsely Activated Networks
(SANs) that consist of kernels with shared weights that, during encoding, are
convolved with the input and then passed through a sparse activation function.
During decoding, the same weights are convolved with the sparse activation map
and subsequently the partial reconstructions from each weight are summed to
reconstruct the input. We compare SANs using the five previously defined
activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,
FMNIST) and show that models that are selected using $\varphi$ have small
description representation length and consist of interpretable kernels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stack Index Prediction Using Time-Series Analysis. (arXiv:2108.08120v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raman_R/0/1/0/all/0/1">Raja CSP Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahadevan_R/0/1/0/all/0/1">Rohith Mahadevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Perumal_D/0/1/0/all/0/1">Divya Perumal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_V/0/1/0/all/0/1">Vedha Sankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1">Talha Abdur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08120">
                                    <div class="article-summary-box-inner">
                                        <span>The Prevalence of Community support and engagement for different domains in
the tech industry has changed and evolved throughout the years. In this study,
we aim to understand, analyze and predict the trends of technology in a
scientific manner, having collected data on numerous topics and their growth
throughout the years in the past decade. We apply machine learning models on
collected data, to understand, analyze and forecast the trends in the
advancement of different fields. We show that certain technical concepts such
as python, machine learning, and Keras have an undisputed uptrend, finally
concluding that the Stackindex model forecasts with high accuracy and can be a
viable tool for forecasting different tech domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LOKI: Long Term and Key Intentions for Trajectory Prediction. (arXiv:2108.08236v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girase_H/0/1/0/all/0/1">Harshayu Girase</a>, <a href="http://arxiv.org/find/cs/1/au:+Gang_H/0/1/0/all/0/1">Haiming Gang</a>, <a href="http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1">Srikanth Malla</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanehara_A/0/1/0/all/0/1">Akira Kanehara</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1">Karttikeya Mangalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1">Chiho Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08236">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in trajectory prediction have shown that explicit reasoning
about agents&#x27; intent is important to accurately forecast their motion. However,
the current research activities are not directly applicable to intelligent and
safety critical systems. This is mainly because very few public datasets are
available, and they only consider pedestrian-specific intents for a short
temporal horizon from a restricted egocentric view. To this end, we propose
LOKI (LOng term and Key Intentions), a novel large-scale dataset that is
designed to tackle joint trajectory and intention prediction for heterogeneous
traffic agents (pedestrians and vehicles) in an autonomous driving setting. The
LOKI dataset is created to discover several factors that may affect intention,
including i) agent&#x27;s own will, ii) social interactions, iii) environmental
constraints, and iv) contextual information. We also propose a model that
jointly performs trajectory and intention prediction, showing that recurrently
reasoning about intention can assist with trajectory prediction. We show our
method outperforms state-of-the-art trajectory prediction methods by upto
$27\%$ and also provide a baseline for frame-wise intention estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distinguishing Healthy Ageing from Dementia: a Biomechanical Simulation of Brain Atrophy using Deep Networks. (arXiv:2108.08214v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Silva_M/0/1/0/all/0/1">Mariana Da Silva</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sudre_C/0/1/0/all/0/1">Carole H. Sudre</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Garcia_K/0/1/0/all/0/1">Kara Garcia</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bass_C/0/1/0/all/0/1">Cher Bass</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cardoso_M/0/1/0/all/0/1">M. Jorge Cardoso</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Robinson_E/0/1/0/all/0/1">Emma C. Robinson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08214">
                                    <div class="article-summary-box-inner">
                                        <span>Biomechanical modeling of tissue deformation can be used to simulate
different scenarios of longitudinal brain evolution. In this work,we present a
deep learning framework for hyper-elastic strain modelling of brain atrophy,
during healthy ageing and in Alzheimer&#x27;s Disease. The framework directly models
the effects of age, disease status, and scan interval to regress regional
patterns of atrophy, from which a strain-based model estimates deformations.
This model is trained and validated using 3D structural magnetic resonance
imaging data from the ADNI cohort. Results show that the framework can estimate
realistic deformations, following the known course of Alzheimer&#x27;s disease, that
clearly differentiate between healthy and demented patterns of ageing. This
suggests the framework has potential to be incorporated into explainable models
of disease, for the exploration of interventions and counterfactual examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Dynamic Stability of Power Grids using Graph Neural Networks. (arXiv:2108.08230v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Nauck_C/0/1/0/all/0/1">Christian Nauck</a>, <a href="http://arxiv.org/find/physics/1/au:+Lindner_M/0/1/0/all/0/1">Michael Lindner</a>, <a href="http://arxiv.org/find/physics/1/au:+Schurholt_K/0/1/0/all/0/1">Konstantin Sch&#xfc;rholt</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhang_H/0/1/0/all/0/1">Haoming Zhang</a>, <a href="http://arxiv.org/find/physics/1/au:+Schultz_P/0/1/0/all/0/1">Paul Schultz</a>, <a href="http://arxiv.org/find/physics/1/au:+Kurths_J/0/1/0/all/0/1">J&#xfc;rgen Kurths</a>, <a href="http://arxiv.org/find/physics/1/au:+Isenhardt_I/0/1/0/all/0/1">Ingrid Isenhardt</a>, <a href="http://arxiv.org/find/physics/1/au:+Hellmann_F/0/1/0/all/0/1">Frank Hellmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08230">
                                    <div class="article-summary-box-inner">
                                        <span>The prediction of dynamical stability of power grids becomes more important
and challenging with increasing shares of renewable energy sources due to their
decentralized structure, reduced inertia and volatility. We investigate the
feasibility of applying graph neural networks (GNN) to predict dynamic
stability of synchronisation in complex power grids using the single-node basin
stability (SNBS) as a measure. To do so, we generate two synthetic datasets for
grids with 20 and 100 nodes respectively and estimate SNBS using Monte-Carlo
sampling. Those datasets are used to train and evaluate the performance of
eight different GNN-models. All models use the full graph without
simplifications as input and predict SNBS in a nodal-regression-setup. We show
that SNBS can be predicted in general and the performance significantly changes
using different GNN-models. Furthermore, we observe interesting transfer
capabilities of our approach: GNN-models trained on smaller grids can directly
be applied on larger grids without the need of retraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-DARTS: Towards Stable Architecture Search. (arXiv:2108.08128v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_P/0/1/0/all/0/1">Pengfei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Ying Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yukang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08128">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) marks a milestone in Neural
Architecture Search (NAS), boasting simplicity and small search costs. However,
DARTS still suffers from frequent performance collapse, which happens when some
operations, such as skip connections, zeroes and poolings, dominate the
architecture. In this paper, we are the first to point out that the phenomenon
is attributed to bi-level optimization. We propose Single-DARTS which merely
uses single-level optimization, updating network weights and architecture
parameters simultaneously with the same data batch. Even single-level
optimization has been previously attempted, no literature provides a systematic
explanation on this essential point. Replacing the bi-level optimization,
Single-DARTS obviously alleviates performance collapse as well as enhances the
stability of architecture search. Experiment results show that Single-DARTS
achieves state-of-the-art performance on mainstream search spaces. For
instance, on NAS-Benchmark-201, the searched architectures are nearly optimal
ones. We also validate that the single-level optimization framework is much
more stable than the bi-level one. We hope that this simple yet effective
method will give some insights on differential architecture search. The code is
available at https://github.com/PencilAndBike/Single-DARTS.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ALLNet: A Hybrid Convolutional Neural Network to Improve Diagnosis of Acute Lymphocytic Leukemia (ALL) in White Blood Cells. (arXiv:2108.08195v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mattapalli_S/0/1/0/all/0/1">Sai Mattapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Athavale_R/0/1/0/all/0/1">Rishi Athavale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08195">
                                    <div class="article-summary-box-inner">
                                        <span>Due to morphological similarity at the microscopic level, making an accurate
and time-sensitive distinction between blood cells affected by Acute
Lymphocytic Leukemia (ALL) and their healthy counterparts calls for the usage
of machine learning architectures. However, three of the most common models,
VGG, ResNet, and Inception, each come with their own set of flaws with room for
improvement which demands the need for a superior model. ALLNet, the proposed
hybrid convolutional neural network architecture, consists of a combination of
the VGG, ResNet, and Inception models. The ALL Challenge dataset of ISBI 2019
(available here) contains 10,691 images of white blood cells which were used to
train and test the models. 7,272 of the images in the dataset are of cells with
ALL and 3,419 of them are of healthy cells. Of the images, 60% were used to
train the model, 20% were used for the cross-validation set, and 20% were used
for the test set. ALLNet outperformed the VGG, ResNet, and the Inception models
across the board, achieving an accuracy of 92.6567%, a sensitivity of 95.5304%,
a specificity of 85.9155%, an AUC score of 0.966347, and an F1 score of 0.94803
in the cross-validation set. In the test set, ALLNet achieved an accuracy of
92.0991%, a sensitivity of 96.5446%, a specificity of 82.8035%, an AUC score of
0.959972, and an F1 score of 0.942963. The utilization of ALLNet in the
clinical workspace can better treat the thousands of people suffering from ALL
across the world, many of whom are children.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics. (arXiv:2108.08217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yehao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yingwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Ting Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08217">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise and development of deep learning over the past decade, there
has been a steady momentum of innovation and breakthroughs that convincingly
push the state-of-the-art of cross-modal analytics between vision and language
in multimedia field. Nevertheless, there has not been an open-source codebase
in support of training and deploying numerous neural network models for
cross-modal analytics in a unified and modular fashion. In this work, we
propose X-modaler -- a versatile and high-performance codebase that
encapsulates the state-of-the-art cross-modal analytics into several
general-purpose stages (e.g., pre-processing, encoder, cross-modal interaction,
decoder, and decode strategy). Each stage is empowered with the functionality
that covers a series of modules widely adopted in state-of-the-arts and allows
seamless switching in between. This way naturally enables a flexible
implementation of state-of-the-art algorithms for image captioning, video
captioning, and vision-language pre-training, aiming to facilitate the rapid
development of research community. Meanwhile, since the effective modular
designs in several stages (e.g., cross-modal interaction) are shared across
different vision-language tasks, X-modaler can be simply extended to power
startup prototypes for other tasks in cross-modal analytics, including visual
question answering, visual commonsense reasoning, and cross-modal retrieval.
X-modaler is an Apache-licensed codebase, and its source codes, sample projects
and pre-trained models are available on-line:
https://github.com/YehLi/xmodaler.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepExpress: Heterogeneous and Coupled Sequence Modeling for Express Delivery Prediction. (arXiv:2108.08170v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Siyuan Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Bin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Longbing Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiwen Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08170">
                                    <div class="article-summary-box-inner">
                                        <span>The prediction of express delivery sequence, i.e., modeling and estimating
the volumes of daily incoming and outgoing parcels for delivery, is critical
for online business, logistics, and positive customer experience, and
specifically for resource allocation optimization and promotional activity
arrangement. A precise estimate of consumer delivery requests has to involve
sequential factors such as shopping behaviors, weather conditions, events,
business campaigns, and their couplings. Besides, conventional sequence
prediction assumes a stable sequence evolution, failing to address complex
nonlinear sequences and various feature effects in the above multi-source data.
Although deep networks and attention mechanisms demonstrate the potential of
complex sequence modeling, extant networks ignore the heterogeneous and
coupling situation between features and sequences, resulting in weak prediction
accuracy. To address these issues, we propose DeepExpress - a deep-learning
based express delivery sequence prediction model, which extends the classic
seq2seq framework to learning complex coupling between sequence and features.
DeepExpress leverages an express delivery seq2seq learning, a
carefully-designed heterogeneous feature representation, and a novel joint
training attention mechanism to adaptively map heterogeneous data, and capture
sequence-feature coupling for precise estimation. Experimental results on
real-world data demonstrate that the proposed method outperforms both shallow
and deep baseline models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">De-identification of Unstructured Clinical Texts from Sequence to Sequence Perspective. (arXiv:2108.07971v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anjum_M/0/1/0/all/0/1">Md Monowar Anjum</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammed_N/0/1/0/all/0/1">Noman Mohammed</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07971">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a novel problem formulation for de-identification of
unstructured clinical text. We formulate the de-identification problem as a
sequence to sequence learning problem instead of a token classification
problem. Our approach is inspired by the recent state-of -the-art performance
of sequence to sequence learning models for named entity recognition. Early
experimentation of our proposed approach achieved 98.91% recall rate on i2b2
dataset. This performance is comparable to current state-of-the-art models for
unstructured clinical text de-identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CARE: Coherent Actionable Recourse based on Sound Counterfactual Explanations. (arXiv:2108.08197v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rasouli_P/0/1/0/all/0/1">Peyman Rasouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_I/0/1/0/all/0/1">Ingrid Chieh Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08197">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactual explanation methods interpret the outputs of a machine
learning model in the form of &quot;what-if scenarios&quot; without compromising the
fidelity-interpretability trade-off. They explain how to obtain a desired
prediction from the model by recommending small changes to the input features,
aka recourse. We believe an actionable recourse should be created based on
sound counterfactual explanations originating from the distribution of the
ground-truth data and linked to the domain knowledge. Moreover, it needs to
preserve the coherency between changed/unchanged features while satisfying
user/domain-specified constraints. This paper introduces CARE, a modular
explanation framework that addresses the model- and user-level desiderata in a
consecutive and structured manner. We tackle the existing requirements by
proposing novel and efficient solutions that are formulated in a
multi-objective optimization framework. The designed framework enables
including arbitrary requirements and generating counterfactual explanations and
actionable recourse by choice. As a model-agnostic approach, CARE generates
multiple, diverse explanations for any black-box model in tabular
classification and regression settings. Several experiments on standard data
sets and black-box models demonstrate the effectiveness of our modular
framework and its superior performance compared to the baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Resize Images for Computer Vision Tasks. (arXiv:2103.09950v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Talebi_H/0/1/0/all/0/1">Hossein Talebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09950">
                                    <div class="article-summary-box-inner">
                                        <span>For all the ways convolutional neural nets have revolutionized computer
vision in recent years, one important aspect has received surprisingly little
attention: the effect of image size on the accuracy of tasks being trained for.
Typically, to be efficient, the input images are resized to a relatively small
spatial resolution (e.g. 224x224), and both training and inference are carried
out at this resolution. The actual mechanism for this re-scaling has been an
afterthought: Namely, off-the-shelf image resizers such as bilinear and bicubic
are commonly used in most machine learning software frameworks. But do these
resizers limit the on task performance of the trained networks? The answer is
yes. Indeed, we show that the typical linear resizer can be replaced with
learned resizers that can substantially improve performance. Importantly, while
the classical resizers typically result in better perceptual quality of the
downscaled images, our proposed learned resizers do not necessarily give better
visual quality, but instead improve task performance. Our learned image resizer
is jointly trained with a baseline vision model. This learned CNN-based resizer
creates machine friendly visual manipulations that lead to a consistent
improvement of the end task metric over the baseline model. Specifically, here
we focus on the classification task with the ImageNet dataset, and experiment
with four different models to learn resizers adapted to each model. Moreover,
we show that the proposed resizer can also be useful for fine-tuning the
classification baselines for other vision tasks. To this end, we experiment
with three different baselines to develop image quality assessment (IQA) models
on the AVA dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modulating Language Models with Emotions. (arXiv:2108.07886v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruibo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chenyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1">Soroush Vosoughi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07886">
                                    <div class="article-summary-box-inner">
                                        <span>Generating context-aware language that embodies diverse emotions is an
important step towards building empathetic NLP systems. In this paper, we
propose a formulation of modulated layer normalization -- a technique inspired
by computer vision -- that allows us to use large-scale language models for
emotional response generation. In automatic and human evaluation on the
MojiTalk dataset, our proposed modulated layer normalization method outperforms
prior baseline methods while maintaining diversity, fluency, and coherence. Our
method also obtains competitive performance even when using only 10% of the
available training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparsely Activated Networks: A new method for decomposing and compressing data. (arXiv:1911.00400v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bizopoulos_P/0/1/0/all/0/1">Paschalis Bizopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.00400">
                                    <div class="article-summary-box-inner">
                                        <span>Recent literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features, but without considering
the description length of the representations. In this thesis, first we
introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined metric $\varphi$. We lastly present Sparsely Activated
Networks (SANs) that consist of kernels with shared weights that, during
encoding, are convolved with the input and then passed through a sparse
activation function. During decoding, the same weights are convolved with the
sparse activation map and subsequently the partial reconstructions from each
weight are summed to reconstruct the input. We compare SANs using the five
previously defined activation functions on a variety of datasets (Physionet,
UCI-epilepsy, MNIST, FMNIST) and show that models that are selected using
$\varphi$ have small description representation length and consist of
interpretable kernels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Graph Normalized Auto-Encoders. (arXiv:2108.08046v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Seong Jin Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Myoung Ho Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08046">
                                    <div class="article-summary-box-inner">
                                        <span>Link prediction is one of the key problems for graph-structured data. With
the advancement of graph neural networks, graph autoencoders (GAEs) and
variational graph autoencoders (VGAEs) have been proposed to learn graph
embeddings in an unsupervised way. It has been shown that these methods are
effective for link prediction tasks. However, they do not work well in link
predictions when a node whose degree is zero (i.g., isolated node) is involved.
We have found that GAEs/VGAEs make embeddings of isolated nodes close to zero
regardless of their content features. In this paper, we propose a novel
Variational Graph Normalized AutoEncoder (VGNAE) that utilize
$L_2$-normalization to derive better embeddings for isolated nodes. We show
that our VGNAEs outperform the existing state-of-the-art models for link
prediction tasks. The code is available at
https://github.com/SeongJinAhn/VGNAE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned holographic light transport. (arXiv:2108.08253v1 [physics.optics])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Kavakli_K/0/1/0/all/0/1">Koray Kavakl&#x131;</a>, <a href="http://arxiv.org/find/physics/1/au:+Urey_H/0/1/0/all/0/1">Hakan Urey</a>, <a href="http://arxiv.org/find/physics/1/au:+Aksit_K/0/1/0/all/0/1">Kaan Ak&#x15f;it</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08253">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-Generated Holography (CGH) algorithms often fall short in matching
simulations with results from a physical holographic display. Our work
addresses this mismatch by learning the holographic light transport in
holographic displays. Using a camera and a holographic display, we capture the
image reconstructions of optimized holograms that rely on ideal simulations to
generate a dataset. Inspired by the ideal simulations, we learn a
complex-valued convolution kernel that can propagate given holograms to
captured photographs in our dataset. Our method can dramatically improve
simulation accuracy and image quality in holographic displays while paving the
way for physically informed learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HyperSF: Spectral Hypergraph Coarsening via Flow-based Local Clustering. (arXiv:2108.07901v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aghdaei_A/0/1/0/all/0/1">Ali Aghdaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhiqiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhuo Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07901">
                                    <div class="article-summary-box-inner">
                                        <span>Hypergraphs allow modeling problems with multi-way high-order relationships.
However, the computational cost of most existing hypergraph-based algorithms
can be heavily dependent upon the input hypergraph sizes. To address the
ever-increasing computational challenges, graph coarsening can be potentially
applied for preprocessing a given hypergraph by aggressively aggregating its
vertices (nodes). However, state-of-the-art hypergraph partitioning
(clustering) methods that incorporate heuristic graph coarsening techniques are
not optimized for preserving the structural (global) properties of hypergraphs.
In this work, we propose an efficient spectral hypergraph coarsening scheme
(HyperSF) for well preserving the original spectral (structural) properties of
hypergraphs. Our approach leverages a recent strongly-local max-flow-based
clustering algorithm for detecting the sets of hypergraph vertices that
minimize ratio cut. To further improve the algorithm efficiency, we propose a
divide-and-conquer scheme by leveraging spectral clustering of the bipartite
graphs corresponding to the original hypergraphs. Our experimental results for
a variety of hypergraphs extracted from real-world VLSI design benchmarks show
that the proposed hypergraph coarsening algorithm can significantly improve the
multi-way conductance of hypergraph clustering as well as runtime efficiency
when compared with existing state-of-the-art algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FOX-NAS: Fast, On-device and Explainable Neural Architecture Search. (arXiv:2108.08189v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chia-Hsiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yu-Shin Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yuan-Yao Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hung-Yueh Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kai-Chiang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08189">
                                    <div class="article-summary-box-inner">
                                        <span>Neural architecture search can discover neural networks with good
performance, and One-Shot approaches are prevalent. One-Shot approaches
typically require a supernet with weight sharing and predictors that predict
the performance of architecture. However, the previous methods take much time
to generate performance predictors thus are inefficient. To this end, we
propose FOX-NAS that consists of fast and explainable predictors based on
simulated annealing and multivariate regression. Our method is
quantization-friendly and can be efficiently deployed to the edge. The
experiments on different hardware show that FOX-NAS models outperform some
other popular neural network architectures. For example, FOX-NAS matches
MobileNetV2 and EfficientNet-Lite0 accuracy with 240% and 40% less latency on
the edge CPU. FOX-NAS is the 3rd place winner of the 2020 Low-Power Computer
Vision Challenge (LPCVC), DSP classification track. See all evaluation results
at https://lpcv.ai/competitions/2020. Search code and pre-trained models are
released at https://github.com/great8nctu/FOX-NAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out-of-Distribution Detection using Outlier Detection Methods. (arXiv:2108.08218v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diers_J/0/1/0/all/0/1">Jan Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Pigorsch_C/0/1/0/all/0/1">Christian Pigorsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08218">
                                    <div class="article-summary-box-inner">
                                        <span>Out-of-distribution detection (OOD) deals with anomalous input to neural
networks. In the past, specialized methods have been proposed to reject
predictions on anomalous input. We use outlier detection algorithms to detect
anomalous input as reliable as specialized methods from the field of OOD. No
neural network adaptation is required; detection is based on the model&#x27;s
softmax score. Our approach works unsupervised with an Isolation Forest or with
supervised classifiers such as a Gradient Boosting machine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Verified Neural Networks via Floating Point Numerical Error. (arXiv:2003.03021v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kai Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1">Martin Rinard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03021">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers have developed neural network verification algorithms motivated
by the need to characterize the robustness of deep neural networks. The
verifiers aspire to answer whether a neural network guarantees certain
properties with respect to all inputs in a space. However, many verifiers
inaccurately model floating point arithmetic but do not thoroughly discuss the
consequences.

We show that the negligence of floating point error leads to unsound
verification that can be systematically exploited in practice. For a pretrained
neural network, we present a method that efficiently searches inputs as
witnesses for the incorrectness of robustness claims made by a complete
verifier. We also present a method to construct neural network architectures
and weights that induce wrong results of an incomplete verifier. Our results
highlight that, to achieve practically reliable verification of neural
networks, any verification system must accurately (or conservatively) model the
effects of any floating point computations in the network inference or
verification system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Moser Flow: Divergence-based Generative Modeling on Manifolds. (arXiv:2108.08052v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rozen_N/0/1/0/all/0/1">Noam Rozen</a>, <a href="http://arxiv.org/find/stat/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>, <a href="http://arxiv.org/find/stat/1/au:+Nickel_M/0/1/0/all/0/1">Maximilian Nickel</a>, <a href="http://arxiv.org/find/stat/1/au:+Lipman_Y/0/1/0/all/0/1">Yaron Lipman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08052">
                                    <div class="article-summary-box-inner">
                                        <span>We are interested in learning generative models for complex geometries
described via manifolds, such as spheres, tori, and other implicit surfaces.
Current extensions of existing (Euclidean) generative models are restricted to
specific geometries and typically suffer from high computational costs. We
introduce Moser Flow (MF), a new class of generative models within the family
of continuous normalizing flows (CNF). MF also produces a CNF via a solution to
the change-of-variable formula, however differently from other CNF methods, its
model (learned) density is parameterized as the source (prior) density minus
the divergence of a neural network (NN). The divergence is a local, linear
differential operator, easy to approximate and calculate on manifolds.
Therefore, unlike other CNFs, MF does not require invoking or backpropagating
through an ODE solver during training. Furthermore, representing the model
density explicitly as the divergence of a NN rather than as a solution of an
ODE facilitates learning high fidelity densities. Theoretically, we prove that
MF constitutes a universal density approximator under suitable assumptions.
Empirically, we demonstrate for the first time the use of flow models for
sampling from general curved surfaces and achieve significant improvements in
density estimation, sample quality, and training complexity over existing CNFs
on challenging synthetic geometries and real-world benchmarks from the earth
and climate sciences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affect-Aware Deep Belief Network Representations for Multimodal Unsupervised Deception Detection. (arXiv:2108.07897v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathur_L/0/1/0/all/0/1">Leena Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mataric_M/0/1/0/all/0/1">Maja J Matari&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07897">
                                    <div class="article-summary-box-inner">
                                        <span>Automated systems that detect the social behavior of deception can enhance
human well-being across medical, social work, and legal domains. Labeled
datasets to train supervised deception detection models can rarely be collected
for real-world, high-stakes contexts. To address this challenge, we propose the
first unsupervised approach for detecting real-world, high-stakes deception in
videos without requiring labels. This paper presents our novel approach for
affect-aware unsupervised Deep Belief Networks (DBN) to learn discriminative
representations of deceptive and truthful behavior. Drawing on psychology
theories that link affect and deception, we experimented with unimodal and
multimodal DBN-based approaches trained on facial valence, facial arousal,
audio, and visual features. In addition to using facial affect as a feature on
which DBN models are trained, we also introduce a DBN training procedure that
uses facial affect as an aligner of audio-visual representations. We conducted
classification experiments with unsupervised Gaussian Mixture Model clustering
to evaluate our approaches. Our best unsupervised approach (trained on facial
valence and visual features) achieved an AUC of 80%, outperforming human
ability and performing comparably to fully-supervised models. Our results
motivate future work on unsupervised, affect-aware computational approaches for
detecting deception and other social behaviors in the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diversity-based Trajectory and Goal Selection with Hindsight Experience Replay. (arXiv:2108.07887v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1">Tianhong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hengyan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Arulkumaran_K/0/1/0/all/0/1">Kai Arulkumaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1">Guangyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharath_A/0/1/0/all/0/1">Anil Anthony Bharath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07887">
                                    <div class="article-summary-box-inner">
                                        <span>Hindsight experience replay (HER) is a goal relabelling technique typically
used with off-policy deep reinforcement learning algorithms to solve
goal-oriented tasks; it is well suited to robotic manipulation tasks that
deliver only sparse rewards. In HER, both trajectories and transitions are
sampled uniformly for training. However, not all of the agent&#x27;s experiences
contribute equally to training, and so naive uniform sampling may lead to
inefficient learning. In this paper, we propose diversity-based trajectory and
goal selection with HER (DTGSH). Firstly, trajectories are sampled according to
the diversity of the goal states as modelled by determinantal point processes
(DPPs). Secondly, transitions with diverse goal states are selected from the
trajectories by using k-DPPs. We evaluate DTGSH on five challenging robotic
manipulation tasks in simulated robot environments, where we show that our
method can learn more quickly and reach higher performance than other
state-of-the-art approaches on all tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comprehensive Comparison of Deep Learning Models for Lung and COVID-19 Lesion Segmentation in CT scans. (arXiv:2009.06412v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bizopoulos_P/0/1/0/all/0/1">Paschalis Bizopoulos</a>, <a href="http://arxiv.org/find/eess/1/au:+Vretos_N/0/1/0/all/0/1">Nicholas Vretos</a>, <a href="http://arxiv.org/find/eess/1/au:+Daras_P/0/1/0/all/0/1">Petros Daras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06412">
                                    <div class="article-summary-box-inner">
                                        <span>Recently there has been an explosion in the use of Deep Learning (DL) methods
for medical image segmentation. However the field&#x27;s reliability is hindered by
the lack of a common base of reference for accuracy/performance evaluation and
the fact that previous research uses different datasets for evaluation. In this
paper, an extensive comparison of DL models for lung and COVID-19 lesion
segmentation in Computerized Tomography (CT) scans is presented, which can also
be used as a benchmark for testing medical image segmentation models. Four DL
architectures (Unet, Linknet, FPN, PSPNet) are combined with 25 randomly
initialized and pretrained encoders (variations of VGG, DenseNet, ResNet,
ResNext, DPN, MobileNet, Xception, Inception-v4, EfficientNet), to construct
200 tested models. Three experimental setups are conducted for lung
segmentation, lesion segmentation and lesion segmentation using the original
lung masks. A public COVID-19 dataset with 100 CT scan images (80 for train, 20
for validation) is used for training/validation and a different public dataset
consisting of 829 images from 9 CT scan volumes for testing. Multiple findings
are provided including the best architecture-encoder models for each experiment
as well as mean Dice results for each experiment, architecture and encoder
independently. Finally, the upper bounds improvements when using lung masks as
a preprocessing step or when using pretrained models are quantified. The source
code and 600 pretrained models for the three experiments are provided, suitable
for fine-tuning in experimental setups without GPU capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Corruption-robust exploration in episodic reinforcement learning. (arXiv:1911.08689v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1">Thodoris Lykouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1">Max Simchowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wen Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.08689">
                                    <div class="article-summary-box-inner">
                                        <span>We initiate the study of multi-stage episodic reinforcement learning under
adversarial corruptions in both the rewards and the transition probabilities of
the underlying system extending recent results for the special case of
stochastic bandits. We provide a framework which modifies the aggressive
exploration enjoyed by existing reinforcement learning approaches based on
&quot;optimism in the face of uncertainty&quot;, by complementing them with principles
from &quot;action elimination&quot;. Importantly, our framework circumvents the major
challenges posed by naively applying action elimination in the RL setting, as
formalized by a lower bound we demonstrate. Our framework yields efficient
algorithms which (a) attain near-optimal regret in the absence of corruptions
and (b) adapt to unknown levels corruption, enjoying regret guarantees which
degrade gracefully in the total corruption encountered. To showcase the
generality of our approach, we derive results for both tabular settings (where
states and actions are finite) as well as linear-function-approximation
settings (where the dynamics and rewards admit a linear underlying
representation). Notably, our work provides the first sublinear regret
guarantee which accommodates any deviation from purely i.i.d. transitions in
the bandit-feedback model for episodic reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Verifying Low-dimensional Input Neural Networks via Input Quantization. (arXiv:2108.07961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kai Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1">Martin Rinard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07961">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are an attractive tool for compressing the control
policy lookup tables in systems such as the Airborne Collision Avoidance System
(ACAS). It is vital to ensure the safety of such neural controllers via
verification techniques. The problem of analyzing ACAS Xu networks has
motivated many successful neural network verifiers. These verifiers typically
analyze the internal computation of neural networks to decide whether a
property regarding the input/output holds. The intrinsic complexity of neural
network computation renders such verifiers slow to run and vulnerable to
floating-point error.

This paper revisits the original problem of verifying ACAS Xu networks. The
networks take low-dimensional sensory inputs with training data provided by a
precomputed lookup table. We propose to prepend an input quantization layer to
the network. Quantization allows efficient verification via input state
enumeration, whose complexity is bounded by the size of the quantization space.
Quantization is equivalent to nearest-neighbor interpolation at run time, which
has been shown to provide acceptable accuracy for ACAS in simulation. Moreover,
our technique can deliver exact verification results immune to floating-point
error if we directly enumerate the network outputs on the target inference
implementation or on an accurate simulation of the target implementation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning distant cause and effect using only local and immediate credit assignment. (arXiv:1905.11589v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rawlinson_D/0/1/0/all/0/1">David Rawlinson</a>, <a href="http://arxiv.org/find/stat/1/au:+Ahmed_A/0/1/0/all/0/1">Abdelrahman Ahmed</a>, <a href="http://arxiv.org/find/stat/1/au:+Kowadlo_G/0/1/0/all/0/1">Gideon Kowadlo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11589">
                                    <div class="article-summary-box-inner">
                                        <span>We present a recurrent neural network memory that uses sparse coding to
create a combinatoric encoding of sequential inputs. Using several examples, we
show that the network can associate distant causes and effects in a discrete
stochastic process, predict partially-observable higher-order sequences, and
enable a DQN agent to navigate a maze by giving it memory. The network uses
only biologically-plausible, local and immediate credit assignment. Memory
requirements are typically one order of magnitude less than existing LSTM, GRU
and autoregressive feed-forward sequence learning models. The most significant
limitation of the memory is generalization to unseen input sequences. We
explore this limitation by measuring next-word prediction perplexity on the
Penn Treebank dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OACAL: Finding Module-Consistent Solutions to Weaken User Obligations. (arXiv:2108.08282v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Pengcheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tei_K/0/1/0/all/0/1">Kenji Tei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08282">
                                    <div class="article-summary-box-inner">
                                        <span>Users interacting with a UI-embedded machine or system are typically obliged
to perform their actions in a pre-determined order, to successfully achieve
certain functional goals. However, such obligations are often not followed
strictly by users, which may lead to the violation to security properties,
especially in security-critical systems. In order to improve the security with
the awareness of unexpected user behaviors, a system can be redesigned to a
more robust one by changing the order of actions in its specification.
Meanwhile, we anticipate that the functionalities would remain consistent
following the modifications. In this paper, we propose an efficient algorithm
to automatically produce specification revisions tackling with attack scenarios
caused by the weakened user obligations. By our algorithm, all the revisions
maintain the integrity of the functionalities as the original specification,
which are generated using a novel recomposition approach. Then, the qualified
revisions that can satisfy the security requirements would be efficiently
spotted by a hybrid approach combining model checking and machine learning
techniques. We evaluate our algorithm by comparing its performance with a
state-of-the-art approach regarding their coverage and searching speed of the
desirable revisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge AI without Compromise: Efficient, Versatile and Accurate Neurocomputing in Resistive Random-Access Memory. (arXiv:2108.07879v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1">Weier Wan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Kubendran_R/0/1/0/all/0/1">Rajkumar Kubendran</a> (2 and 5), <a href="http://arxiv.org/find/cs/1/au:+Schaefer_C/0/1/0/all/0/1">Clemens Schaefer</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Eryilmaz_S/0/1/0/all/0/1">S. Burc Eryilmaz</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenqiang Zhang</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dabin Wu</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Deiss_S/0/1/0/all/0/1">Stephen Deiss</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Raina_P/0/1/0/all/0/1">Priyanka Raina</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">He Qian</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1">Bin Gao</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Siddharth Joshi</a> (4 and 2), <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huaqiang Wu</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Wong_H/0/1/0/all/0/1">H.-S. Philip Wong</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Cauwenberghs_G/0/1/0/all/0/1">Gert Cauwenberghs</a> (2) ((1) Stanford University, (2) University of California San Diego, (3) Tsinghua University, (4) University of Notre Dame, (5) University of Pittsburgh)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07879">
                                    <div class="article-summary-box-inner">
                                        <span>Realizing today&#x27;s cloud-level artificial intelligence functionalities
directly on devices distributed at the edge of the internet calls for edge
hardware capable of processing multiple modalities of sensory data (e.g. video,
audio) at unprecedented energy-efficiency. AI hardware architectures today
cannot meet the demand due to a fundamental &quot;memory wall&quot;: data movement
between separate compute and memory units consumes large energy and incurs long
latency. Resistive random-access memory (RRAM) based compute-in-memory (CIM)
architectures promise to bring orders of magnitude energy-efficiency
improvement by performing computation directly within memory. However,
conventional approaches to CIM hardware design limit its functional flexibility
necessary for processing diverse AI workloads, and must overcome hardware
imperfections that degrade inference accuracy. Such trade-offs between
efficiency, versatility and accuracy cannot be addressed by isolated
improvements on any single level of the design. By co-optimizing across all
hierarchies of the design from algorithms and architecture to circuits and
devices, we present NeuRRAM - the first multimodal edge AI chip using RRAM CIM
to simultaneously deliver a high degree of versatility for diverse model
architectures, record energy-efficiency $5\times$ - $8\times$ better than prior
art across various computational bit-precisions, and inference accuracy
comparable to software models with 4-bit weights on all measured standard AI
benchmarks including accuracy of 99.0% on MNIST and 85.7% on CIFAR-10 image
classification, 84.7% accuracy on Google speech command recognition, and a 70%
reduction in image reconstruction error on a Bayesian image recovery task. This
work paves a way towards building highly efficient and reconfigurable edge AI
hardware platforms for the more demanding and heterogeneous AI applications of
the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Extensible Benchmark Suite for Learning to Simulate Physical Systems. (arXiv:2108.07799v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Otness_K/0/1/0/all/0/1">Karl Otness</a>, <a href="http://arxiv.org/find/cs/1/au:+Gjoka_A/0/1/0/all/0/1">Arvi Gjoka</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>, <a href="http://arxiv.org/find/cs/1/au:+Panozzo_D/0/1/0/all/0/1">Daniele Panozzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Peherstorfer_B/0/1/0/all/0/1">Benjamin Peherstorfer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_T/0/1/0/all/0/1">Teseo Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Zorin_D/0/1/0/all/0/1">Denis Zorin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07799">
                                    <div class="article-summary-box-inner">
                                        <span>Simulating physical systems is a core component of scientific computing,
encompassing a wide range of physical domains and applications. Recently, there
has been a surge in data-driven methods to complement traditional numerical
simulations methods, motivated by the opportunity to reduce computational costs
and/or learn new physical models leveraging access to large collections of
data. However, the diversity of problem settings and applications has led to a
plethora of approaches, each one evaluated on a different setup and with
different evaluation metrics. We introduce a set of benchmark problems to take
a step towards unified benchmarks and evaluation protocols. We propose four
representative physical systems, as well as a collection of both widely used
classical time integrators and representative data-driven methods
(kernel-based, MLP, CNN, nearest neighbors). Our framework allows evaluating
objectively and systematically the stability, accuracy, and computational
efficiency of data-driven methods. Additionally, it is configurable to permit
adjustments for accommodating other learning tasks and for establishing a
foundation for future developments in machine learning for scientific
computing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Deep and Efficient: A Deep Siamese Self-Attention Fully Efficient Convolutional Network for Change Detection in VHR Images. (arXiv:2108.08157v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongruixuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08157">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, FCNs have attracted widespread attention in the CD field. In
pursuit of better CD performance, it has become a tendency to design deeper and
more complicated FCNs, which inevitably brings about huge numbers of parameters
and an unbearable computational burden. With the goal of designing a quite deep
architecture to obtain more precise CD results while simultaneously decreasing
parameter numbers to improve efficiency, in this work, we present a very deep
and efficient CD network, entitled EffCDNet. In EffCDNet, to reduce the
numerous parameters associated with deep architecture, an efficient convolution
consisting of depth-wise convolution and group convolution with a channel
shuffle mechanism is introduced to replace standard convolutional layers. In
terms of the specific network architecture, EffCDNet does not use mainstream
UNet-like architecture, but rather adopts the architecture with a very deep
encoder and a lightweight decoder. In the very deep encoder, two very deep
siamese streams stacked by efficient convolution first extract two highly
representative and informative feature maps from input image-pairs.
Subsequently, an efficient ASPP module is designed to capture multi-scale
change information. In the lightweight decoder, a recurrent criss-cross
self-attention (RCCA) module is applied to efficiently utilize non-local
similar feature representations to enhance discriminability for each pixel,
thus effectively separating the changed and unchanged regions. Moreover, to
tackle the optimization problem in confused pixels, two novel loss functions
based on information entropy are presented. On two challenging CD datasets, our
approach outperforms other SOTA FCN-based methods, with only benchmark-level
parameter numbers and quite low computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Adversarial Robustness Distillation: Robust Soft Labels Make Student Better. (arXiv:2108.07969v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zi_B/0/1/0/all/0/1">Bojia Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shihao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xingjun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07969">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is one effective approach for training robust deep
neural networks against adversarial attacks. While being able to bring reliable
robustness, adversarial training (AT) methods in general favor high capacity
models, i.e., the larger the model the better the robustness. This tends to
limit their effectiveness on small models, which are more preferable in
scenarios where storage or computing resources are very limited (e.g., mobile
devices). In this paper, we leverage the concept of knowledge distillation to
improve the robustness of small models by distilling from adversarially trained
large models. We first revisit several state-of-the-art AT methods from a
distillation perspective and identify one common technique that can lead to
improved robustness: the use of robust soft labels -- predictions of a robust
model. Following this observation, we propose a novel adversarial robustness
distillation method called Robust Soft Label Adversarial Distillation (RSLAD)
to train robust small student models. RSLAD fully exploits the robust soft
labels produced by a robust (adversarially-trained) large teacher model to
guide the student&#x27;s learning on both natural and adversarial examples in all
loss terms. We empirically demonstrate the effectiveness of our RSLAD approach
over existing adversarial training and distillation methods in improving the
robustness of small models against state-of-the-art attacks including the
AutoAttack. We also provide a set of understandings on our RSLAD and the
importance of robust soft labels for adversarial robustness distillation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimising Knee Injury Detection with Spatial Attention and Validating Localisation Ability. (arXiv:2108.08136v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belton_N/0/1/0/all/0/1">Niamh Belton</a>, <a href="http://arxiv.org/find/cs/1/au:+Welaratne_I/0/1/0/all/0/1">Ivan Welaratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahlan_A/0/1/0/all/0/1">Adil Dahlan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hearne_R/0/1/0/all/0/1">Ronan T Hearne</a>, <a href="http://arxiv.org/find/cs/1/au:+Hagos_M/0/1/0/all/0/1">Misgina Tsighe Hagos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawlor_A/0/1/0/all/0/1">Aonghus Lawlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Curran_K/0/1/0/all/0/1">Kathleen M. Curran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08136">
                                    <div class="article-summary-box-inner">
                                        <span>This work employs a pre-trained, multi-view Convolutional Neural Network
(CNN) with a spatial attention block to optimise knee injury detection. An
open-source Magnetic Resonance Imaging (MRI) data set with image-level labels
was leveraged for this analysis. As MRI data is acquired from three planes, we
compare our technique using data from a single-plane and multiple planes
(multi-plane). For multi-plane, we investigate various methods of fusing the
planes in the network. This analysis resulted in the novel &#x27;MPFuseNet&#x27; network
and state-of-the-art Area Under the Curve (AUC) scores for detecting Anterior
Cruciate Ligament (ACL) tears and Abnormal MRIs, achieving AUC scores of 0.977
and 0.957 respectively. We then developed an objective metric, Penalised
Localisation Accuracy (PLA), to validate the model&#x27;s localisation ability. This
metric compares binary masks generated from Grad-Cam output and the
radiologist&#x27;s annotations on a sample of MRIs. We also extracted explainability
features in a model-agnostic approach that were then verified as clinically
relevant by the radiologist.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Identification of Covariate Shift in Image Data. (arXiv:2108.08000v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Olson_M/0/1/0/all/0/1">Matthew L. Olson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuy-Vy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixit_G/0/1/0/all/0/1">Gaurav Dixit</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratzlaff_N/0/1/0/all/0/1">Neale Ratzlaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1">Weng-Keen Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahng_M/0/1/0/all/0/1">Minsuk Kahng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08000">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying covariate shift is crucial for making machine learning systems
robust in the real world and for detecting training data biases that are not
reflected in test data. However, detecting covariate shift is challenging,
especially when the data consists of high-dimensional images, and when multiple
types of localized covariate shift affect different subspaces of the data.
Although automated techniques can be used to detect the existence of covariate
shift, our goal is to help human users characterize the extent of covariate
shift in large image datasets with interfaces that seamlessly integrate
information obtained from the detection algorithms. In this paper, we design
and evaluate a new visual interface that facilitates the comparison of the
local distributions of training and test data. We conduct a quantitative user
study on multi-attribute facial data to compare two different learned
low-dimensional latent representations (pretrained ImageNet CNN vs. density
ratio) and two user analytic workflows (nearest-neighbor vs.
cluster-to-cluster). Our results indicate that the latent representation of our
density ratio model, combined with a nearest-neighbor comparison, is the most
effective at helping humans identify covariate shift.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantitative Uniform Stability of the Iterative Proportional Fitting Procedure. (arXiv:2108.08129v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1">Valentin De Bortoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08129">
                                    <div class="article-summary-box-inner">
                                        <span>We establish the uniform in time stability, w.r.t. the marginals, of the
Iterative Proportional Fitting Procedure, also known as Sinkhorn algorithm,
used to solve entropy-regularised Optimal Transport problems. Our result is
quantitative and stated in terms of the 1-Wasserstein metric. As a corollary we
establish a quantitative stability result for Schr\&quot;odinger bridges.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Cluster Embedding. (arXiv:2108.08003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhirong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedov_D/0/1/0/all/0/1">Denis Sedov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1">Samuel Kaski</a>, <a href="http://arxiv.org/find/cs/1/au:+Corander_J/0/1/0/all/0/1">Jukka Corander</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08003">
                                    <div class="article-summary-box-inner">
                                        <span>Neighbor Embedding (NE) that aims to preserve pairwise similarities between
data items has been shown to yield an effective principle for data
visualization. However, even the currently best NE methods such as Stochastic
Neighbor Embedding (SNE) may leave large-scale patterns such as clusters hidden
despite of strong signals being present in the data. To address this, we
propose a new cluster visualization method based on Neighbor Embedding. We
first present a family of Neighbor Embedding methods which generalizes SNE by
using non-normalized Kullback-Leibler divergence with a scale parameter. In
this family, much better cluster visualizations often appear with a parameter
value different from the one corresponding to SNE. We also develop an efficient
software which employs asynchronous stochastic block coordinate descent to
optimize the new family of objective functions. The experimental results
demonstrate that our method consistently and substantially improves
visualization of data clusters compared with the state-of-the-art NE
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Existence, uniqueness, and convergence rates for gradient flows in the training of artificial neural networks with ReLU activation. (arXiv:2108.08106v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eberle_S/0/1/0/all/0/1">Simon Eberle</a>, <a href="http://arxiv.org/find/cs/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Riekert_A/0/1/0/all/0/1">Adrian Riekert</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1">Georg S. Weiss</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08106">
                                    <div class="article-summary-box-inner">
                                        <span>The training of artificial neural networks (ANNs) with rectified linear unit
(ReLU) activation via gradient descent (GD) type optimization schemes is
nowadays a common industrially relevant procedure. Till this day in the
scientific literature there is in general no mathematical convergence analysis
which explains the numerical success of GD type optimization schemes in the
training of ANNs with ReLU activation. GD type optimization schemes can be
regarded as temporal discretization methods for the gradient flow (GF)
differential equations associated to the considered optimization problem and,
in view of this, it seems to be a natural direction of research to first aim to
develop a mathematical convergence theory for time-continuous GF differential
equations and, thereafter, to aim to extend such a time-continuous convergence
theory to implementable time-discrete GD type optimization methods. In this
article we establish two basic results for GF differential equations in the
training of fully-connected feedforward ANNs with one hidden layer and ReLU
activation. In the first main result of this article we establish in the
training of such ANNs under the assumption that the probability distribution of
the input data of the considered supervised learning problem is absolutely
continuous with a bounded density function that every GF differential equation
admits for every initial value a solution which is also unique among a suitable
class of solutions. In the second main result of this article we prove in the
training of such ANNs under the assumption that the target function and the
density function of the probability distribution of the input data are
piecewise polynomial that every non-divergent GF trajectory converges with an
appropriate rate of convergence to a critical point and that the risk of the
non-divergent GF trajectory converges with rate 1 to the risk of the critical
point.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRDrV3: Complete Lesion Detection in Fundus Images Using Mask R-CNN, Transfer Learning, and LSTM. (arXiv:2108.08095v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shenavarmasouleh_F/0/1/0/all/0/1">Farzan Shenavarmasouleh</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohammadi_F/0/1/0/all/0/1">Farid Ghareh Mohammadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Amini_M/0/1/0/all/0/1">M. Hadi Amini</a>, <a href="http://arxiv.org/find/eess/1/au:+Taha_T/0/1/0/all/0/1">Thiab Taha</a>, <a href="http://arxiv.org/find/eess/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>, <a href="http://arxiv.org/find/eess/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08095">
                                    <div class="article-summary-box-inner">
                                        <span>Medical Imaging is one of the growing fields in the world of computer vision.
In this study, we aim to address the Diabetic Retinopathy (DR) problem as one
of the open challenges in medical imaging. In this research, we propose a new
lesion detection architecture, comprising of two sub-modules, which is an
optimal solution to detect and find not only the type of lesions caused by DR,
their corresponding bounding boxes, and their masks; but also the severity
level of the overall case. Aside from traditional accuracy, we also use two
popular evaluation criteria to evaluate the outputs of our models, which are
intersection over union (IOU) and mean average precision (mAP). We hypothesize
that this new solution enables specialists to detect lesions with high
confidence and estimate the severity of the damage with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Multimarginal Partial Optimal Transport: Equivalent Forms and Computational Complexity. (arXiv:2108.07992v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Le_K/0/1/0/all/0/1">Khang Le</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_H/0/1/0/all/0/1">Huy Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1">Tung Pham</a>, <a href="http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1">Nhat Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07992">
                                    <div class="article-summary-box-inner">
                                        <span>We study the multi-marginal partial optimal transport (POT) problem between
$m$ discrete (unbalanced) measures with at most $n$ supports. We first prove
that we can obtain two equivalence forms of the multimarginal POT problem in
terms of the multimarginal optimal transport problem via novel extensions of
cost tensor. The first equivalence form is derived under the assumptions that
the total masses of each measure are sufficiently close while the second
equivalence form does not require any conditions on these masses but at the
price of more sophisticated extended cost tensor. Our proof techniques for
obtaining these equivalence forms rely on novel procedures of moving mass in
graph theory to push transportation plan into appropriate regions. Finally,
based on the equivalence forms, we develop optimization algorithm, named
ApproxMPOT algorithm, that builds upon the Sinkhorn algorithm for solving the
entropic regularized multimarginal optimal transport. We demonstrate that the
ApproxMPOT algorithm can approximate the optimal value of multimarginal POT
problem with a computational complexity upper bound of the order
$\tilde{\mathcal{O}}(m^3(n+1)^{m}/ \varepsilon^2)$ where $\varepsilon &gt; 0$
stands for the desired tolerance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics. (arXiv:2108.08217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yehao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yingwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Ting Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08217">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise and development of deep learning over the past decade, there
has been a steady momentum of innovation and breakthroughs that convincingly
push the state-of-the-art of cross-modal analytics between vision and language
in multimedia field. Nevertheless, there has not been an open-source codebase
in support of training and deploying numerous neural network models for
cross-modal analytics in a unified and modular fashion. In this work, we
propose X-modaler -- a versatile and high-performance codebase that
encapsulates the state-of-the-art cross-modal analytics into several
general-purpose stages (e.g., pre-processing, encoder, cross-modal interaction,
decoder, and decode strategy). Each stage is empowered with the functionality
that covers a series of modules widely adopted in state-of-the-arts and allows
seamless switching in between. This way naturally enables a flexible
implementation of state-of-the-art algorithms for image captioning, video
captioning, and vision-language pre-training, aiming to facilitate the rapid
development of research community. Meanwhile, since the effective modular
designs in several stages (e.g., cross-modal interaction) are shared across
different vision-language tasks, X-modaler can be simply extended to power
startup prototypes for other tasks in cross-modal analytics, including visual
question answering, visual commonsense reasoning, and cross-modal retrieval.
X-modaler is an Apache-licensed codebase, and its source codes, sample projects
and pre-trained models are available on-line:
https://github.com/YehLi/xmodaler.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fighting Game Commentator with Pitch and Loudness Adjustment Utilizing Highlight Cues. (arXiv:2108.08112v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Junjie H. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhou Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qihang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohno_S/0/1/0/all/0/1">Satoru Ohno</a>, <a href="http://arxiv.org/find/cs/1/au:+Paliyawan_P/0/1/0/all/0/1">Pujana Paliyawan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08112">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a commentator for providing real-time game commentary in
a fighting game. The commentary takes into account highlight cues, obtained by
analyzing scenes during gameplay, as input to adjust the pitch and loudness of
commentary to be spoken by using a Text-to-Speech (TTS) technology. We
investigate different designs for pitch and loudness adjustment. The proposed
AI consists of two parts: a dynamic adjuster for controlling pitch and loudness
of the TTS and a real-time game commentary generator. We conduct a pilot study
on a fighting game, and our result shows that by adjusting the loudness
significantly according to the level of game highlight, the entertainment of
the gameplay can be enhanced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Promoting Mental Well-Being for Audiences in a Live-Streaming Game by Highlight-Based Bullet Comments. (arXiv:2108.08083v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Junjie H. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yulin Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhou Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Paliyawan_P/0/1/0/all/0/1">Pujana Paliyawan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08083">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a method for generating bullet comments for
live-streaming games based on highlights (i.e., the exciting parts of video
clips) extracted from the game content and evaluate the effect of mental health
promotion. Game live streaming is becoming a popular theme for academic
research. Compared to traditional online video sharing platforms, such as
Youtube and Vimeo, video live streaming platform has the benefits of
communicating with other viewers in real-time. In sports broadcasting, the
commentator plays an essential role as mood maker by making matches more
exciting. The enjoyment emerged while watching game live streaming also
benefits the audience&#x27;s mental health. However, many e-sports live streaming
channels do not have a commentator for entertaining viewers. Therefore, this
paper presents a design of an AI commentator that can be embedded in live
streaming games. To generate bullet comments for real-time game live streaming,
the system employs highlight evaluation to detect the highlights, and generate
the bullet comments. An experiment is conducted and the effectiveness of
generated bullet comments in a live-streaming fighting game channel is
evaluated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-18">2021-08-18</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Match-Ignition: Plugging PageRank into Transformer for Long-form Text Matching. (arXiv:2101.06423v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06423">
                                    <div class="article-summary-box-inner">
                                        <span>Neural text matching models have been widely used in community question
answering, information retrieval, and dialogue. However, these models designed
for short texts cannot well address the long-form text matching problem,
because there are many contexts in long-form texts can not be directly aligned
with each other, and it is difficult for existing models to capture the key
matching signals from such noisy data. Besides, these models are
computationally expensive for simply use all textual data indiscriminately. To
tackle the effectiveness and efficiency problem, we propose a novel
hierarchical noise filtering model, namely Match-Ignition. The main idea is to
plug the well-known PageRank algorithm into the Transformer, to identify and
filter both sentence and word level noisy information in the matching process.
Noisy sentences are usually easy to detect because previous work has shown that
their similarity can be explicitly evaluated by the word overlapping, so we
directly use PageRank to filter such information based on a sentence similarity
graph. Unlike sentences, words rely on their contexts to express concrete
meanings, so we propose to jointly learn the filtering and matching process, to
well capture the critical word-level matching signals. Specifically, a word
graph is first built based on the attention scores in each self-attention block
of Transformer, and key words are then selected by applying PageRank on this
graph. In this way, noisy words will be filtered out layer by layer in the
matching process. Experimental results show that Match-Ignition outperforms
both SOTA short text matching models and recent long-form text matching models.
We also conduct detailed analysis to show that Match-Ignition efficiently
captures important sentences and words, to facilitate the long-form text
matching process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EENLP: Cross-lingual Eastern European NLP Index. (arXiv:2108.02605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1">Alexey Tikhonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Malkhasov_A/0/1/0/all/0/1">Alex Malkhasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Manoshin_A/0/1/0/all/0/1">Andrey Manoshin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dima_G/0/1/0/all/0/1">George Dima</a>, <a href="http://arxiv.org/find/cs/1/au:+Cserhati_R/0/1/0/all/0/1">R&#xe9;ka Cserh&#xe1;ti</a>, <a href="http://arxiv.org/find/cs/1/au:+Asif_M/0/1/0/all/0/1">Md.Sadek Hossain Asif</a>, <a href="http://arxiv.org/find/cs/1/au:+Sardi_M/0/1/0/all/0/1">Matt S&#xe1;rdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02605">
                                    <div class="article-summary-box-inner">
                                        <span>This report presents the results of the EENLP project, done as a part of EEML
2021 summer school.

It presents a broad index of NLP resources for Eastern European languages,
which, we hope, could be helpful for the NLP community; several new
hand-crafted cross-lingual datasets focused on Eastern European languages, and
a sketch evaluation of cross-lingual transfer learning abilities of several
modern multilingual Transformer-based models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Social Chemistry 101: Learning to Reason about Social and Moral Norms. (arXiv:2011.00620v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Forbes_M/0/1/0/all/0/1">Maxwell Forbes</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jena D. Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1">Vered Shwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1">Maarten Sap</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00620">
                                    <div class="article-summary-box-inner">
                                        <span>Social norms -- the unspoken commonsense rules about acceptable social
behavior -- are crucial in understanding the underlying causes and intents of
people&#x27;s actions in narratives. For example, underlying an action such as
&quot;wanting to call cops on my neighbors&quot; are social norms that inform our
conduct, such as &quot;It is expected that you report crimes.&quot;

We present Social Chemistry, a new conceptual formalism to study people&#x27;s
everyday social norms and moral judgments over a rich spectrum of real life
situations described in natural language. We introduce Social-Chem-101, a
large-scale corpus that catalogs 292k rules-of-thumb such as &quot;it is rude to run
a blender at 5am&quot; as the basic conceptual units. Each rule-of-thumb is further
broken down with 12 different dimensions of people&#x27;s judgments, including
social judgments of good and bad, moral foundations, expected cultural
pressure, and assumed legality, which together amount to over 4.5 million
annotations of categorical labels and free-text descriptions.

Comprehensive empirical results based on state-of-the-art neural models
demonstrate that computational modeling of social norms is a promising research
direction. Our model framework, Neural Norm Transformer, learns and generalizes
Social-Chem-101 to successfully reason about previously unseen situations,
generating relevant (and potentially novel) attribute-aware social
rules-of-thumb.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who&#x27;s Waldo? Linking People Across Text and Images. (arXiv:2108.07253v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Claire Yuqing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1">Apoorv Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1">Yoav Artzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1">Noah Snavely</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1">Hadar Averbuch-Elor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07253">
                                    <div class="article-summary-box-inner">
                                        <span>We present a task and benchmark dataset for person-centric visual grounding,
the problem of linking between people named in a caption and people pictured in
an image. In contrast to prior work in visual grounding, which is predominantly
object-based, our new task masks out the names of people in captions in order
to encourage methods trained on such image-caption pairs to focus on contextual
cues (such as rich interactions between multiple people), rather than learning
associations between names and appearances. To facilitate this task, we
introduce a new dataset, Who&#x27;s Waldo, mined automatically from image-caption
data on Wikimedia Commons. We propose a Transformer-based method that
outperforms several strong baselines on this task, and are releasing our data
to the research community to spur work on contextual models that consider both
vision and language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction. (arXiv:2008.01377v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heid_S/0/1/0/all/0/1">Stefan Heid</a>, <a href="http://arxiv.org/find/cs/1/au:+Wever_M/0/1/0/all/0/1">Marcel Wever</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01377">
                                    <div class="article-summary-box-inner">
                                        <span>Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linguistic Resources for Bhojpuri, Magahi and Maithili: Statistics about them, their Similarity Estimates, and Baselines for Three Applications. (arXiv:2004.13945v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mundotiya_R/0/1/0/all/0/1">Rajesh Kumar Mundotiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Manish Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapur_R/0/1/0/all/0/1">Rahul Kapur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swasti Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Anil Kumar Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13945">
                                    <div class="article-summary-box-inner">
                                        <span>Corpus preparation for low-resource languages and for development of human
language technology to analyze or computationally process them is a laborious
task, primarily due to the unavailability of expert linguists who are native
speakers of these languages and also due to the time and resources required.
Bhojpuri, Magahi, and Maithili, languages of the Purvanchal region of India (in
the north-eastern parts), are low-resource languages belonging to the
Indo-Aryan (or Indic) family. They are closely related to Hindi, which is a
relatively high-resource language, which is why we compare with Hindi. We
collected corpora for these three languages from various sources and cleaned
them to the extent possible, without changing the data in them. The text
belongs to different domains and genres. We calculated some basic statistical
measures for these corpora at character, word, syllable, and morpheme levels.
These corpora were also annotated with parts-of-speech (POS) and chunk tags.
The basic statistical measures were both absolute and relative and were
exptected to indicate of linguistic properties such as morphological, lexical,
phonological, and syntactic complexities (or richness). The results were
compared with a standard Hindi corpus. For most of the measures, we tried to
the corpus size the same across the languages to avoid the effect of corpus
size, but in some cases it turned out that using the full corpus was better,
even if sizes were very different. Although the results are not very clear, we
try to draw some conclusions about the languages and the corpora. For POS
tagging and chunking, the BIS tagset was used to manually annotate the data.
The POS tagged data sizes are 16067, 14669 and 12310 sentences, respectively,
for Bhojpuri, Magahi and Maithili. The sizes for chunking are 9695 and 1954
sentences for Bhojpuri and Maithili, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MigrationsKB: A Knowledge Base of Public Attitudes towards Migrations and their Driving Factors. (arXiv:2108.07593v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sack_H/0/1/0/all/0/1">Harald Sack</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1">Mehwish Alam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07593">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing trend in the topic of migration in Europe, the public is
now more engaged in expressing their opinions through various platforms such as
Twitter. Understanding the online discourses is therefore essential to capture
the public opinion. The goal of this study is the analysis of social media
platform to quantify public attitudes towards migrations and the identification
of different factors causing these attitudes. The tweets spanning from 2013 to
Jul-2021 in the European countries which are hosts to immigrants are collected,
pre-processed, and filtered using advanced topic modeling technique. BERT-based
entity linking and sentiment analysis, and attention-based hate speech
detection are performed to annotate the curated tweets. Moreover, the external
databases are used to identify the potential social and economic factors
causing negative attitudes of the people about migration. To further promote
research in the interdisciplinary fields of social science and computer
science, the outcomes are integrated into a Knowledge Base (KB), i.e.,
MigrationsKB which significantly extends the existing models to take into
account the public attitudes towards migrations and the economic indicators.
This KB is made public using FAIR principles, which can be queried through
SPARQL endpoint. Data dumps are made available on Zenodo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering. (arXiv:2007.15207v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1">Shayne Longpre</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Daiber_J/0/1/0/all/0/1">Joachim Daiber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15207">
                                    <div class="article-summary-box-inner">
                                        <span>Progress in cross-lingual modeling depends on challenging, realistic, and
diverse evaluation sets. We introduce Multilingual Knowledge Questions and
Answers (MKQA), an open-domain question answering evaluation set comprising 10k
question-answer pairs aligned across 26 typologically diverse languages (260k
question-answer pairs in total). Answers are based on a heavily curated,
language-independent data representation, making results comparable across
languages and independent of language-specific passages. With 26 languages,
this dataset supplies the widest range of languages to-date for evaluating
question answering. We benchmark a variety of state-of-the-art methods and
baselines for generative and extractive question answering, trained on Natural
Questions, in zero shot and translation settings. Results indicate this dataset
is challenging even in English, but especially in low-resource languages</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Game Interface to Study Semantic Grounding in Text-Based Models. (arXiv:2108.07708v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mickus_T/0/1/0/all/0/1">Timothee Mickus</a>, <a href="http://arxiv.org/find/cs/1/au:+Constant_M/0/1/0/all/0/1">Mathieu Constant</a>, <a href="http://arxiv.org/find/cs/1/au:+Paperno_D/0/1/0/all/0/1">Denis Paperno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07708">
                                    <div class="article-summary-box-inner">
                                        <span>Can language models learn grounded representations from text distribution
alone? This question is both central and recurrent in natural language
processing; authors generally agree that grounding requires more than textual
distribution. We propose to experimentally test this claim: if any two words
have different meanings and yet cannot be distinguished from distribution
alone, then grounding is out of the reach of text-based models. To that end, we
present early work on an online game for the collection of human judgments on
the distributional similarity of word pairs in five languages. We further
report early results of our data collection campaign.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TellMeWhy: A Dataset for Answering Why-Questions in Narratives. (arXiv:2106.06132v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1">Yash Kumar Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06132">
                                    <div class="article-summary-box-inner">
                                        <span>Answering questions about why characters perform certain actions is central
to understanding and reasoning about narratives. Despite recent progress in QA,
it is not clear if existing models have the ability to answer &quot;why&quot; questions
that may require commonsense knowledge external to the input narrative. In this
work, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more
than 30k questions and free-form answers concerning why characters in short
narratives perform the actions described. For a third of this dataset, the
answers are not present within the narrative. Given the limitations of
automated evaluation for this task, we also present a systematized human
evaluation interface for this dataset. Our evaluation of state-of-the-art
models show that they are far below human performance on answering such
questions. They are especially worse on questions whose answers are external to
the narrative, thus providing a challenge for future QA and narrative
understanding research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Weak Supervised Dataset of Fine-Grained Emotions in Portuguese. (arXiv:2108.07638v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cortiz_D/0/1/0/all/0/1">Diogo Cortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1">Jefferson O. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Calegari_N/0/1/0/all/0/1">Newton Calegari</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1">Ana Lu&#xed;sa Freitas</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_A/0/1/0/all/0/1">Ana Ang&#xe9;lica Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Botelho_C/0/1/0/all/0/1">Carolina Botelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Rego_G/0/1/0/all/0/1">Gabriel Gaudencio R&#xea;go</a>, <a href="http://arxiv.org/find/cs/1/au:+Sampaio_W/0/1/0/all/0/1">Waldir Sampaio</a>, <a href="http://arxiv.org/find/cs/1/au:+Boggio_P/0/1/0/all/0/1">Paulo Sergio Boggio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07638">
                                    <div class="article-summary-box-inner">
                                        <span>Affective Computing is the study of how computers can recognize, interpret
and simulate human affects. Sentiment Analysis is a common task in NLP related
to this topic, but it focuses only on emotion valence (positive, negative,
neutral). An emerging approach in NLP is Emotion Recognition, which relies on
fined-grained classification. This research describes an approach to create a
lexical-based weak supervised corpus for fine-grained emotion in Portuguese. We
evaluate our dataset by fine-tuning a transformer-based language model (BERT)
and validating it on a Golden Standard annotated validation set. Our results
(F1-score&#x3D; .64) suggest lexical-based weak supervision as an appropriate
strategy for initial work in low resources environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IsoScore: Measuring the Uniformity of Vector Space Utilization. (arXiv:2108.07344v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rudman_W/0/1/0/all/0/1">William Rudman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillman_N/0/1/0/all/0/1">Nate Gillman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rayne_T/0/1/0/all/0/1">Taylor Rayne</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07344">
                                    <div class="article-summary-box-inner">
                                        <span>The recent success of distributed word representations has led to an
increased interest in analyzing the properties of their spatial distribution.
Current metrics suggest that contextualized word embedding models do not
uniformly utilize all dimensions when embedding tokens in vector space. Here we
argue that existing metrics are fragile and tend to obfuscate the true spatial
distribution of point clouds. To ameliorate this issue, we propose IsoScore: a
novel metric which quantifies the degree to which a point cloud uniformly
utilizes the ambient vector space. We demonstrate that IsoScore has several
desirable properties such as mean invariance and direct correspondence to the
number of dimensions used, which are properties that existing scores do not
possess. Furthermore, IsoScore is conceptually intuitive and computationally
efficient, making it well suited for analyzing the distribution of point clouds
in arbitrary vector spaces, not necessarily limited to those of word embeddings
alone. Additionally, we use IsoScore to demonstrate that a number of recent
conclusions in the NLP literature that have been derived using brittle metrics
of spatial distribution, such as average cosine similarity, may be incomplete
or altogether inaccurate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards. (arXiv:2108.07374v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McMillan_Major_A/0/1/0/all/0/1">Angelina McMillan-Major</a>, <a href="http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1">Salomey Osei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_J/0/1/0/all/0/1">Juan Diego Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ammanamanchi_P/0/1/0/all/0/1">Pawan Sasanka Ammanamanchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jernite_Y/0/1/0/all/0/1">Yacine Jernite</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07374">
                                    <div class="article-summary-box-inner">
                                        <span>Developing documentation guidelines and easy-to-use templates for datasets
and models is a challenging task, especially given the variety of backgrounds,
skills, and incentives of the people involved in the building of natural
language processing (NLP) tools. Nevertheless, the adoption of standard
documentation practices across the field of NLP promotes more accessible and
detailed descriptions of NLP datasets and models, while supporting researchers
and developers in reflecting on their work. To help with the standardization of
documentation, we present two case studies of efforts that aim to develop
reusable documentation templates -- the HuggingFace data card, a general
purpose card for datasets in NLP, and the GEM benchmark data and model cards
with a focus on natural language generation. We describe our process for
developing these templates, including the identification of relevant
stakeholder groups, the definition of a set of guiding principles, the use of
existing templates as our foundation, and iterative revisions based on
feedback.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACM-CR: A Manually Annotated Test Collection for Citation Recommendation. (arXiv:2108.07571v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boudin_F/0/1/0/all/0/1">Florian Boudin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07571">
                                    <div class="article-summary-box-inner">
                                        <span>Citation recommendation is intended to assist researchers in the process of
searching for relevant papers to cite by recommending appropriate citations for
a given input text. Existing test collections for this task are noisy and
unreliable since they are built automatically from parsed PDF papers. In this
paper, we present our ongoing effort at creating a publicly available, manually
annotated test collection for citation recommendation. We also conduct a series
of experiments to evaluate the effectiveness of content-based baseline models
on the test collection, providing results for future work to improve upon. Our
test collection and code to replicate experiments are available at
https://github.com/boudinfl/acm-cr</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPMoE: Generate Multiple Pattern-Aware Outputs with Sparse Pattern Mixture of Expert. (arXiv:2108.07535v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shaobo Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_X/0/1/0/all/0/1">Xintong Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuming Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhongzhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haiqing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07535">
                                    <div class="article-summary-box-inner">
                                        <span>Many generation tasks follow a one-to-many mapping relationship: each input
could be associated with multiple outputs. Existing methods like Conditional
Variational AutoEncoder(CVAE) employ a latent variable to model this
one-to-many relationship. However, this high-dimensional and dense latent
variable lacks explainability and usually leads to poor and uncontrollable
generations. In this paper, we innovatively introduce the linguistic concept of
pattern to decompose the one-to-many mapping into multiple one-to-one mappings
and further propose a model named Sparse Pattern Mixture of Experts(SPMoE).
Each one-to-one mapping is associated with a conditional generation pattern and
is modeled with an expert in SPMoE. To ensure each language pattern can be
exclusively handled with an expert model for better explainability and
diversity, a sparse mechanism is employed to coordinate all the expert models
in SPMoE. We assess the performance of our SPMoE on the paraphrase generation
task and the experiment results prove that SPMoE can achieve a good balance in
terms of quality, pattern-level diversity, and corpus-level diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Light-weight contextual spelling correction model for customizing transducer-based speech recognition systems. (arXiv:2108.07493v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07493">
                                    <div class="article-summary-box-inner">
                                        <span>It&#x27;s challenging to customize transducer-based automatic speech recognition
(ASR) system with context information which is dynamic and unavailable during
model training. In this work, we introduce a light-weight contextual spelling
correction model to correct context-related recognition errors in
transducer-based ASR systems. We incorporate the context information into the
spelling correction model with a shared context encoder and use a filtering
algorithm to handle large-size context lists. Experiments show that the model
improves baseline ASR model performance with about 50% relative word error rate
reduction, which also significantly outperforms the baseline method such as
contextual LM biasing. The model also shows excellent performance for
out-of-vocabulary terms not seen during training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Relation Linking for Question Answering over Knowledge Bases. (arXiv:2108.07337v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1">Gaetano Rossiello</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1">Nandana Mihindukulasooriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1">Ibrahim Abdelaziz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bornea_M/0/1/0/all/0/1">Mihaela Bornea</a>, <a href="http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1">Alfio Gliozzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Naseem_T/0/1/0/all/0/1">Tahira Naseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1">Pavan Kapanipathi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07337">
                                    <div class="article-summary-box-inner">
                                        <span>Relation linking is essential to enable question answering over knowledge
bases. Although there are various efforts to improve relation linking
performance, the current state-of-the-art methods do not achieve optimal
results, therefore, negatively impacting the overall end-to-end question
answering performance. In this work, we propose a novel approach for relation
linking framing it as a generative problem facilitating the use of pre-trained
sequence-to-sequence models. We extend such sequence-to-sequence models with
the idea of infusing structured data from the target knowledge base, primarily
to enable these models to handle the nuances of the knowledge base. Moreover,
we train the model with the aim to generate a structured output consisting of a
list of argument-relation pairs, enabling a knowledge validation step. We
compared our method against the existing relation linking systems on four
different datasets derived from DBpedia and Wikidata. Our method reports large
improvements over the state-of-the-art while using a much simpler model that
can be easily adapted to different knowledge bases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent Ethical Assessment of Text Classification Models: A Hate Speech Detection Case Study. (arXiv:2108.07627v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amitoj Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lihao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasekh_A/0/1/0/all/0/1">Amin Rasekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Golbin_I/0/1/0/all/0/1">Ilana Golbin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anand Rao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07627">
                                    <div class="article-summary-box-inner">
                                        <span>An independent ethical assessment of an artificial intelligence system is an
impartial examination of the system&#x27;s development, deployment, and use in
alignment with ethical values. System-level qualitative frameworks that
describe high-level requirements and component-level quantitative metrics that
measure individual ethical dimensions have been developed over the past few
years. However, there exists a gap between the two, which hinders the execution
of independent ethical assessments in practice. This study bridges this gap and
designs a holistic independent ethical assessment process for a text
classification model with a special focus on the task of hate speech detection.
The assessment is further augmented with protected attributes mining and
counterfactual-based analysis to enhance bias assessment. It covers assessments
of technical performance, data bias, embedding bias, classification bias, and
interpretability. The proposed process is demonstrated through an assessment of
a deep hate speech detection model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Multi-scale Convolution for Dialect Identification. (arXiv:2108.07787v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1">Tianlong Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1">Shouyi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_W/0/1/0/all/0/1">Wang Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dandan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jinwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Huiyu Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaorui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07787">
                                    <div class="article-summary-box-inner">
                                        <span>Time Delay Neural Networks (TDNN)-based methods are widely used in dialect
identification. However, in previous work with TDNN application, subtle variant
is being neglected in different feature scales. To address this issue, we
propose a new architecture, named dynamic multi-scale convolution, which
consists of dynamic kernel convolution, local multi-scale learning, and global
multi-scale pooling. Dynamic kernel convolution captures features between
short-term and long-term context adaptively. Local multi-scale learning, which
represents multi-scale features at a granular level, is able to increase the
range of receptive fields for convolution operation. Besides, global
multi-scale pooling is applied to aggregate features from different bottleneck
layers in order to collect information from multiple aspects. The proposed
architecture significantly outperforms state-of-the-art system on the
AP20-OLR-dialect-task of oriental language recognition (OLR) challenge 2020,
with the best average cost performance (Cavg) of 0.067 and the best equal error
rate (EER) of 6.52%. Compared with the known best results, our method achieves
9% of Cavg and 45% of EER relative improvement, respectively. Furthermore, the
parameters of proposed model are 91% fewer than the best known model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Not All Linearizations Are Equally Data-Hungry in Sequence Labeling Parsing. (arXiv:2108.07556v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Munoz_Ortiz_A/0/1/0/all/0/1">Alberto Mu&#xf1;oz-Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Strzyz_M/0/1/0/all/0/1">Michalina Strzyz</a>, <a href="http://arxiv.org/find/cs/1/au:+Vilares_D/0/1/0/all/0/1">David Vilares</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07556">
                                    <div class="article-summary-box-inner">
                                        <span>Different linearizations have been proposed to cast dependency parsing as
sequence labeling and solve the task as: (i) a head selection problem, (ii)
finding a representation of the token arcs as bracket strings, or (iii)
associating partial transition sequences of a transition-based parser to words.
Yet, there is little understanding about how these linearizations behave in
low-resource setups. Here, we first study their data efficiency, simulating
data-restricted setups from a diverse set of rich-resource treebanks. Second,
we test whether such differences manifest in truly low-resource setups. The
results show that head selection encodings are more data-efficient and perform
better in an ideal (gold) framework, but that such advantage greatly vanishes
in favour of bracketing formats when the running setup resembles a real-world
low-resource configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining speakers of multiple languages to improve quality of neural voices. (arXiv:2108.07737v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Latorre_J/0/1/0/all/0/1">Javier Latorre</a>, <a href="http://arxiv.org/find/cs/1/au:+Bailleul_C/0/1/0/all/0/1">Charlotte Bailleul</a>, <a href="http://arxiv.org/find/cs/1/au:+Morrill_T/0/1/0/all/0/1">Tuuli Morrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Conkie_A/0/1/0/all/0/1">Alistair Conkie</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_Y/0/1/0/all/0/1">Yannis Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07737">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we explore multiple architectures and training procedures for
developing a multi-speaker and multi-lingual neural TTS system with the goals
of a) improving the quality when the available data in the target language is
limited and b) enabling cross-lingual synthesis. We report results from a large
experiment using 30 speakers in 8 different languages across 15 different
locales. The system is trained on the same amount of data per speaker. Compared
to a single-speaker model, when the suggested system is fine tuned to a
speaker, it produces significantly better quality in most of the cases while it
only uses less than $40\%$ of the speaker&#x27;s data used to build the
single-speaker model. In cross-lingual synthesis, on average, the generated
quality is within $80\%$ of native single-speaker models, in terms of Mean
Opinion Score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Annotation Guidelines for the Turku Paraphrase Corpus. (arXiv:2108.07499v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanerva_J/0/1/0/all/0/1">Jenna Kanerva</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginter_F/0/1/0/all/0/1">Filip Ginter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_L/0/1/0/all/0/1">Li-Hsin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastas_I/0/1/0/all/0/1">Iiro Rastas</a>, <a href="http://arxiv.org/find/cs/1/au:+Skantsi_V/0/1/0/all/0/1">Valtteri Skantsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilpelainen_J/0/1/0/all/0/1">Jemina Kilpel&#xe4;inen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kupari_H/0/1/0/all/0/1">Hanna-Mari Kupari</a>, <a href="http://arxiv.org/find/cs/1/au:+Piirto_A/0/1/0/all/0/1">Aurora Piirto</a>, <a href="http://arxiv.org/find/cs/1/au:+Saarni_J/0/1/0/all/0/1">Jenna Saarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Sevon_M/0/1/0/all/0/1">Maija Sev&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarkka_O/0/1/0/all/0/1">Otto Tarkka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07499">
                                    <div class="article-summary-box-inner">
                                        <span>This document describes the annotation guidelines used to construct the Turku
Paraphrase Corpus. These guidelines were developed together with the corpus
annotation, revising and extending the guidelines regularly during the
annotation work. Our paraphrase annotation scheme uses the base scale 1-4,
where labels 1 and 2 are used for negative candidates (not paraphrases), while
labels 3 and 4 are paraphrases at least in the given context if not everywhere.
In addition to base labeling, the scheme is enriched with additional
subcategories (flags) for categorizing different types of paraphrases inside
the two positive labels, making the annotation scheme suitable for more
fine-grained paraphrase categorization. The annotation scheme is used to
annotate over 100,000 Finnish paraphrase pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An NLP approach to quantify dynamic salience of predefined topics in a text corpus. (arXiv:2108.07345v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bock_A/0/1/0/all/0/1">A. Bock</a>, <a href="http://arxiv.org/find/cs/1/au:+Palladino_A/0/1/0/all/0/1">A. Palladino</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_Heisters_S/0/1/0/all/0/1">S. Smith-Heisters</a>, <a href="http://arxiv.org/find/cs/1/au:+Boardman_I/0/1/0/all/0/1">I. Boardman</a>, <a href="http://arxiv.org/find/cs/1/au:+Pellegrini_E/0/1/0/all/0/1">E. Pellegrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bienenstock_E/0/1/0/all/0/1">E.J. Bienenstock</a>, <a href="http://arxiv.org/find/cs/1/au:+Valenti_A/0/1/0/all/0/1">A. Valenti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07345">
                                    <div class="article-summary-box-inner">
                                        <span>The proliferation of news media available online simultaneously presents a
valuable resource and significant challenge to analysts aiming to profile and
understand social and cultural trends in a geographic location of interest.
While an abundance of news reports documenting significant events, trends, and
responses provides a more democratized picture of the social characteristics of
a location, making sense of an entire corpus to extract significant trends is a
steep challenge for any one analyst or team. Here, we present an approach using
natural language processing techniques that seeks to quantify how a set of
pre-defined topics of interest change over time across a large corpus of text.
We found that, given a predefined topic, we can identify and rank sets of
terms, or n-grams, that map to those topics and have usage patterns that
deviate from a normal baseline. Emergence, disappearance, or significant
variations in n-gram usage present a ground-up picture of a topic&#x27;s dynamic
salience within a corpus of interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Protein Using Large-scale Pretrain Language Model. (arXiv:2108.07435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yijia Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jiezhong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Chang-Yu Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07435">
                                    <div class="article-summary-box-inner">
                                        <span>Protein is linked to almost every life process. Therefore, analyzing the
biological structure and property of protein sequences is critical to the
exploration of life, as well as disease detection and drug discovery.
Traditional protein analysis methods tend to be labor-intensive and
time-consuming. The emergence of deep learning models makes modeling data
patterns in large quantities of data possible. Interdisciplinary researchers
have begun to leverage deep learning methods to model large biological
datasets, e.g. using long short-term memory and convolutional neural network
for protein sequence classification. After millions of years of evolution,
evolutionary information is encoded in protein sequences. Inspired by the
similarity between natural language and protein sequences, we use large-scale
language models to model evolutionary-scale protein sequences, encoding protein
biology information in representation. Significant improvements are observed in
both token-level and sequence-level tasks, demonstrating that our large-scale
model can accurately capture evolution information from pretraining on
evolutionary-scale individual sequences. Our code and model are available at
https://github.com/THUDM/ProteinLM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Incorrectness Logic and Kleene Algebra With Top and Tests. (arXiv:2108.07707v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Amorim_A/0/1/0/all/0/1">Arthur Azevedo de Amorim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1">Marco Gaboardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07707">
                                    <div class="article-summary-box-inner">
                                        <span>Kleene algebra with tests (KAT) is a foundational equational framework for
reasoning about programs, which has found applications in program
transformations, networking and compiler optimizations, among many other areas.
In his seminal work, Kozen proved that KAT subsumes propositional Hoare logic,
showing that one can reason about the (partial) correctness of while programs
by means of the equational theory of KAT.

In this work, we investigate the support that KAT provides for reasoning
about \emph{incorrectness}, instead, as embodied by Ohearn&#x27;s recently proposed
incorrectness logic. We show that KAT cannot directly express incorrectness
logic. The main reason for this limitation can be traced to the fact that KAT
cannot express explicitly the notion of codomain, which is essential to express
incorrectness triples. To address this issue, we study Kleene algebra with Top
and Tests (TopKAT), an extension of KAT with a top element. We show that TopKAT
is powerful enough to express a codomain operation, to express incorrectness
triples, and to prove all the rules of incorrectness logic sound. This shows
that one can reason about the incorrectness of while-like programs by means of
the equational theory of TopKAT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating harm in language models with conditional-likelihood filtration. (arXiv:2108.07790v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1">Helen Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Raterink_C/0/1/0/all/0/1">Cooper Raterink</a>, <a href="http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1">Jo&#xe3;o G.M. Ara&#xfa;jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_I/0/1/0/all/0/1">Ivan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Carol Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Morisot_A/0/1/0/all/0/1">Adrien Morisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Frosst_N/0/1/0/all/0/1">Nicholas Frosst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07790">
                                    <div class="article-summary-box-inner">
                                        <span>Language models trained on large-scale unfiltered datasets curated from the
open web acquire systemic biases, prejudices, and harmful views from their
training data. We present a methodology for programmatically identifying and
removing harmful text from web-scale datasets. A pretrained language model is
used to calculate the log-likelihood of researcher-written trigger phrases
conditioned on a specific document, which is used to identify and filter
documents from the dataset. We demonstrate that models trained on this filtered
dataset exhibit lower propensity to generate harmful text, with a marginal
decrease in performance on standard language modeling benchmarks compared to
unfiltered baselines. We provide a partial explanation for this performance gap
by surfacing examples of hate speech and other undesirable content from
standard language modeling benchmarks. Finally, we discuss the generalization
of this method and how trigger phrases which reflect specific values can be
used by researchers to build language models which are more closely aligned
with their values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Capsule Aggregation for Unaligned Multimodal Sequences. (arXiv:2108.07543v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_S/0/1/0/all/0/1">Sijie Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Haifeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07543">
                                    <div class="article-summary-box-inner">
                                        <span>Humans express their opinions and emotions through multiple modalities which
mainly consist of textual, acoustic and visual modalities. Prior works on
multimodal sentiment analysis mostly apply Recurrent Neural Network (RNN) to
model aligned multimodal sequences. However, it is unpractical to align
multimodal sequences due to different sample rates for different modalities.
Moreover, RNN is prone to the issues of gradient vanishing or exploding and it
has limited capacity of learning long-range dependency which is the major
obstacle to model unaligned multimodal sequences. In this paper, we introduce
Graph Capsule Aggregation (GraphCAGE) to model unaligned multimodal sequences
with graph-based neural model and Capsule Network. By converting sequence data
into graph, the previously mentioned problems of RNN are avoided. In addition,
the aggregation capability of Capsule Network and the graph-based structure
enable our model to be interpretable and better solve the problem of long-range
dependency. Experimental results suggest that GraphCAGE achieves
state-of-the-art performance on two benchmark datasets with representations
refined by Capsule Network and interpretation provided.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition. (arXiv:2108.07789v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xianrui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1">Philip C. Woodland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07789">
                                    <div class="article-summary-box-inner">
                                        <span>Language models (LMs) pre-trained on massive amounts of text, in particular
bidirectional encoder representations from Transformers (BERT), generative
pre-training (GPT), and GPT-2, have become a key technology for many natural
language processing tasks. In this paper, we present results using fine-tuned
GPT, GPT-2, and their combination for automatic speech recognition (ASR).
Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct
product of the output probabilities is no longer a valid language prior
probability. A conversion method is proposed to compute the correct language
prior probability based on bidirectional LM outputs in a mathematically exact
way. Experimental results on the widely used AMI and Switchboard ASR tasks
showed that the combination of the fine-tuned GPT and GPT-2 outperformed the
combination of three neural LMs with different architectures trained from
scratch on the in-domain text by up to a 12% relative word error rate reduction
(WERR). Furthermore, the proposed conversion for language prior probabilities
enables BERT to receive an extra 3% relative WERR, and the combination of BERT,
GPT and GPT-2 results in further improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Photon-Starved Scene Inference using Single Photon Cameras. (arXiv:2107.11001v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Goyal_B/0/1/0/all/0/1">Bhavya Goyal</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_M/0/1/0/all/0/1">Mohit Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11001">
                                    <div class="article-summary-box-inner">
                                        <span>Scene understanding under low-light conditions is a challenging problem. This
is due to the small number of photons captured by the camera and the resulting
low signal-to-noise ratio (SNR). Single-photon cameras (SPCs) are an emerging
sensing modality that are capable of capturing images with high sensitivity.
Despite having minimal read-noise, images captured by SPCs in photon-starved
conditions still suffer from strong shot noise, preventing reliable scene
inference. We propose photon scale-space a collection of high-SNR images
spanning a wide range of photons-per-pixel (PPP) levels (but same scene
content) as guides to train inference model on low photon flux images. We
develop training techniques that push images with different illumination levels
closer to each other in feature representation space. The key idea is that
having a spectrum of different brightness levels during training enables
effective guidance, and increases robustness to shot noise even in extreme
noise cases. Based on the proposed approach, we demonstrate, via simulations
and real experiments with a SPAD camera, high-performance on various inference
tasks such as image classification and monocular depth estimation under ultra
low-light, down to &lt; 1 PPP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoLT: Large-scale Long-tailed Video Recognition. (arXiv:2105.02668v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1">Zejia Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingjing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1">Larry Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02668">
                                    <div class="article-summary-box-inner">
                                        <span>Label distributions in real-world are oftentimes long-tailed and imbalanced,
resulting in biased models towards dominant labels. While long-tailed
recognition has been extensively studied for image classification tasks,
limited effort has been made for video domain. In this paper, we introduce
VideoLT, a large-scale long-tailed video recognition dataset, as a step toward
real-world video recognition. Our VideoLT contains 256,218 untrimmed videos,
annotated into 1,004 classes with a long-tailed distribution. Through extensive
studies, we demonstrate that state-of-the-art methods used for long-tailed
image recognition do not perform well in the video domain due to the additional
temporal dimension in video data. This motivates us to propose FrameStack, a
simple yet effective method for long-tailed video recognition task. In
particular, FrameStack performs sampling at the frame-level in order to balance
class distributions, and the sampling ratio is dynamically determined using
knowledge derived from the network during training. Experimental results
demonstrate that FrameStack can improve classification performance without
sacrificing overall accuracy. Code and dataset are available at:
https://github.com/17Skye17/VideoLT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-wise Inhibition based Feature Regularization for Robust Classification. (arXiv:2103.02152v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haozhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haoqian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weicheng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Linlin Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02152">
                                    <div class="article-summary-box-inner">
                                        <span>The convolutional neural network (CNN) is vulnerable to degraded images with
even very small variations (e.g. corrupted and adversarial samples). One of the
possible reasons is that CNN pays more attention to the most discriminative
regions, but ignores the auxiliary features when learning, leading to the lack
of feature diversity for final judgment. In our method, we propose to
dynamically suppress significant activation values of CNN by group-wise
inhibition, but not fixedly or randomly handle them when training. The feature
maps with different activation distribution are then processed separately to
take the feature independence into account. CNN is finally guided to learn
richer discriminative features hierarchically for robust classification
according to the proposed regularization. Our method is comprehensively
evaluated under multiple settings, including classification against
corruptions, adversarial attacks and low data regime. Extensive experimental
results show that the proposed method can achieve significant improvements in
terms of both robustness and generalization performances, when compared with
the state-of-the-art methods. Code is available at
https://github.com/LinusWu/TENET_Training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisBuddy -- A Smart Wearable Assistant for the Visually Challenged. (arXiv:2108.07761v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_I/0/1/0/all/0/1">Ishwarya Sivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Meenakshisundaram_N/0/1/0/all/0/1">Nishaali Meenakshisundaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_I/0/1/0/all/0/1">Ishwarya Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+D_S/0/1/0/all/0/1">Shiloah Elizabeth D</a>, <a href="http://arxiv.org/find/cs/1/au:+C_S/0/1/0/all/0/1">Sunil Retmin Raj C</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07761">
                                    <div class="article-summary-box-inner">
                                        <span>Vision plays a crucial role to comprehend the world around us as more than
85% of the external information is obtained through the vision system. It
largely influences our mobility, cognition, information access, and interaction
with the environment as well as with other people. Blindness prevents a person
from gaining knowledge of the surrounding environment and makes unassisted
navigation, object recognition, obstacle avoidance, and reading tasks major
challenges. Many existing systems are often limited by cost and complexity. To
help the visually challenged overcome these difficulties faced in everyday
life, we propose the idea of VisBuddy, a smart assistant which will help the
visually challenged with their day-to-day activities. VisBuddy is a voice-based
assistant, where the user can give voice commands to perform specific tasks.
VisBuddy uses the techniques of image captioning for describing the user&#x27;s
surroundings, optical character recognition (OCR) for reading the text in the
user&#x27;s view, object detection to search and find the objects in a room and web
scraping to give the user the latest news. VisBuddy has been built by combining
the concepts from Deep Learning and the Internet of Things. Thus, VisBuddy
serves as a cost-efficient, powerful and all-in-one assistant for the visually
challenged by helping them with their day-to-day activities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatially Conditioned Graphs for Detecting Human-Object Interactions. (arXiv:2012.06060v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Frederic Z. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1">Dylan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06060">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of detecting human-object interactions in images using
graphical neural networks. Unlike conventional methods, where nodes send scaled
but otherwise identical messages to each of their neighbours, we propose to
condition messages between pairs of nodes on their spatial relationships,
resulting in different messages going to neighbours of the same node. To this
end, we explore various ways of applying spatial conditioning under a
multi-branch structure. Through extensive experimentation we demonstrate the
advantages of spatial conditioning for the computation of the adjacency
structure, messages and the refined graph features. In particular, we
empirically show that as the quality of the bounding boxes increases, their
coarse appearance features contribute relatively less to the disambiguation of
interactions compared to the spatial information. Our method achieves an mAP of
31.33% on HICO-DET and 54.2% on V-COCO, significantly outperforming
state-of-the-art on fine-tuned detections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data. (arXiv:2107.10833v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xintao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xie_L/0/1/0/all/0/1">Liangbin Xie</a>, <a href="http://arxiv.org/find/eess/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>, <a href="http://arxiv.org/find/eess/1/au:+Shan_Y/0/1/0/all/0/1">Ying Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10833">
                                    <div class="article-summary-box-inner">
                                        <span>Though many attempts have been made in blind super-resolution to restore
low-resolution images with unknown and complex degradations, they are still far
from addressing general real-world degraded images. In this work, we extend the
powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN),
which is trained with pure synthetic data. Specifically, a high-order
degradation modeling process is introduced to better simulate complex
real-world degradations. We also consider the common ringing and overshoot
artifacts in the synthesis process. In addition, we employ a U-Net
discriminator with spectral normalization to increase discriminator capability
and stabilize the training dynamics. Extensive comparisons have shown its
superior visual performance than prior works on various real datasets. We also
provide efficient implementations to synthesize training pairs on the fly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-Resolving Cross-Domain Face Miniatures by Peeking at One-Shot Exemplar. (arXiv:2103.08863v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peike Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08863">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional face super-resolution methods usually assume testing
low-resolution (LR) images lie in the same domain as the training ones. Due to
different lighting conditions and imaging hardware, domain gaps between
training and testing images inevitably occur in many real-world scenarios.
Neglecting those domain gaps would lead to inferior face super-resolution (FSR)
performance. However, how to transfer a trained FSR model to a target domain
efficiently and effectively has not been investigated. To tackle this problem,
we develop a Domain-Aware Pyramid-based Face Super-Resolution network, named
DAP-FSR network. Our DAP-FSR is the first attempt to super-resolve LR faces
from a target domain by exploiting only a pair of high-resolution (HR) and LR
exemplar in the target domain. To be specific, our DAP-FSR firstly employs its
encoder to extract the multi-scale latent representations of the input LR face.
Considering only one target domain example is available, we propose to augment
the target domain data by mixing the latent representations of the target
domain face and source domain ones, and then feed the mixed representations to
the decoder of our DAP-FSR. The decoder will generate new face images
resembling the target domain image style. The generated HR faces in turn are
used to optimize our decoder to reduce the domain gap. By iteratively updating
the latent representations and our decoder, our DAP-FSR will be adapted to the
target domain, thus achieving authentic and high-quality upsampled HR faces.
Extensive experiments on three newly constructed benchmarks validate the
effectiveness and superior performance of our DAP-FSR compared to the
state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data. (arXiv:2101.06069v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1">Gaurav Kumar Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saksham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Anirban Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06069">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained deep models hold their learnt knowledge in the form of model
parameters. These parameters act as &quot;memory&quot; for the trained models and help
them generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them &quot;Data
Impressions&quot;, which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating data-free Universal Adversarial
Perturbations (UAPs) with better fooling rates. Extensive experiments performed
on benchmark datasets demonstrate competitive performance achieved using data
impressions in absence of original training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model-Based Explainability Methods for Point Cloud NNs. (arXiv:2107.13459v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanxiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotthaus_H/0/1/0/all/0/1">Helena Kotthaus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13459">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of autonomous driving and robotics, point clouds are showing
their excellent real-time performance as raw data from most of the mainstream
3D sensors. Therefore, point cloud neural networks have become a popular
research direction in recent years. So far, however, there has been little
discussion about the explainability of deep neural networks for point clouds.
In this paper, we propose a point cloud-applicable explainability approach
based on local surrogate model-based method to show which components contribute
to the classification. Moreover, we propose quantitative fidelity validations
for generated explanations that enhance the persuasive power of explainability
and compare the plausibility of different existing point cloud-applicable
explainability methods. Our new explainability approach provides a fairly
accurate, more semantically coherent and widely applicable explanation for
point cloud classification tasks. Our code is available at
https://github.com/Explain3D/LIME-3D</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Generative Models of Textured 3D Meshes from Real-World Images. (arXiv:2103.15627v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1">Dario Pavllo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1">Thomas Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1">Aurelien Lucchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15627">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in differentiable rendering have sparked an interest in
learning generative models of textured 3D meshes from image collections. These
models natively disentangle pose and appearance, enable downstream applications
in computer graphics, and improve the ability of generative models to
understand the concept of image formation. Although there has been prior work
on learning such models from collections of 2D images, these approaches require
a delicate pose estimation step that exploits annotated keypoints, thereby
restricting their applicability to a few specific datasets. In this work, we
propose a GAN framework for generating textured triangle meshes without relying
on such annotations. We show that the performance of our approach is on par
with prior work that relies on ground-truth keypoints, and more importantly, we
demonstrate the generality of our method by setting new baselines on a larger
set of categories from ImageNet - for which keypoints are not available -
without any class-specific hyperparameter tuning. We release our code at
https://github.com/dariopavllo/textured-3d-gan</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just One Moment: Structural Vulnerability of Deep Action Recognition against One Frame Attack. (arXiv:2011.14585v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jaehui Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jun-Hyuk Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jun-Ho Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jong-Seok Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14585">
                                    <div class="article-summary-box-inner">
                                        <span>The video-based action recognition task has been extensively studied in
recent years. In this paper, we study the structural vulnerability of deep
learning-based action recognition models against the adversarial attack using
the one frame attack that adds an inconspicuous perturbation to only a single
frame of a given video clip. Our analysis shows that the models are highly
vulnerable against the one frame attack due to their structural properties.
Experiments demonstrate high fooling rates and inconspicuous characteristics of
the attack. Furthermore, we show that strong universal one frame perturbations
can be obtained under various scenarios. Our work raises the serious issue of
adversarial vulnerability of the state-of-the-art action recognition models in
various perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parametric Contrastive Learning. (arXiv:2107.12028v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jiequan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhisheng Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12028">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle
long-tailed recognition. Based on theoretical analysis, we observe supervised
contrastive loss tends to bias on high-frequency classes and thus increases the
difficulty of imbalanced learning. We introduce a set of parametric class-wise
learnable centers to rebalance from an optimization perspective. Further, we
analyze our PaCo loss under a balanced setting. Our analysis demonstrates that
PaCo can adaptively enhance the intensity of pushing samples of the same class
close as more samples are pulled together with their corresponding centers and
benefit hard example learning. Experiments on long-tailed CIFAR, ImageNet,
Places, and iNaturalist 2018 manifest the new state-of-the-art for long-tailed
recognition. On full ImageNet, models trained with PaCo loss surpass supervised
contrastive learning across various ResNet backbones, e.g., our ResNet-200
achieves 81.8% top-1 accuracy. Our code is available at
https://github.com/dvlab-research/Parametric-Contrastive-Learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Emotion Recognition with Audio-visual Leader-follower Attentive Fusion. (arXiv:2107.01175v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the test (validation)
set of the Aff-Wild2 database, the achieved CCC is 0.463 (0.469) for valence
and 0.492 (0.649) for arousal, which significantly outperforms the baseline
method with the corresponding CCC of 0.200 (0.210) and 0.190 (0.230) for
valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer Network for Significant Stenosis Detection in CCTA of Coronary Arteries. (arXiv:2107.03035v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_X/0/1/0/all/0/1">Xinghua Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_G/0/1/0/all/0/1">Gongning Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_K/0/1/0/all/0/1">Kuanquan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03035">
                                    <div class="article-summary-box-inner">
                                        <span>Coronary artery disease (CAD) has posed a leading threat to the lives of
cardiovascular disease patients worldwide for a long time. Therefore, automated
diagnosis of CAD has indispensable significance in clinical medicine. However,
the complexity of coronary artery plaques that cause CAD makes the automatic
detection of coronary artery stenosis in Coronary CT angiography (CCTA) a
difficult task. In this paper, we propose a Transformer network (TR-Net) for
the automatic detection of significant stenosis (i.e. luminal narrowing &gt; 50%)
while practically completing the computer-assisted diagnosis of CAD. The
proposed TR-Net introduces a novel Transformer, and tightly combines
convolutional layers and Transformer encoders, allowing their advantages to be
demonstrated in the task. By analyzing semantic information sequences, TR-Net
can fully understand the relationship between image information in each
position of a multiplanar reformatted (MPR) image, and accurately detect
significant stenosis based on both local and global information. We evaluate
our TR-Net on a dataset of 76 patients from different patients annotated by
experienced radiologists. Experimental results illustrate that our TR-Net has
achieved better results in ACC (0.92), Spec (0.96), PPV (0.84), F1 (0.79) and
MCC (0.74) indicators compared with the state-of-the-art methods. The source
code is publicly available from the link (https://github.com/XinghuaMa/TR-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coping with Label Shift via Distributionally Robust Optimisation. (arXiv:2010.12230v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingzhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1">Andreas Veit</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1">Srinadh Bhojanapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1">Suvrit Sra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12230">
                                    <div class="article-summary-box-inner">
                                        <span>The label shift problem refers to the supervised learning setting where the
train and test label distributions do not match. Existing work addressing label
shift usually assumes access to an \emph{unlabelled} test sample. This sample
may be used to estimate the test label distribution, and to then train a
suitably re-weighted classifier. While approaches using this idea have proven
effective, their scope is limited as it is not always feasible to access the
target domain; further, they require repeated retraining if the model is to be
deployed in \emph{multiple} test environments. Can one instead learn a
\emph{single} classifier that is robust to arbitrary label shifts from a broad
family? In this paper, we answer this question by proposing a model that
minimises an objective based on distributionally robust optimisation (DRO). We
then design and analyse a gradient descent-proximal mirror ascent algorithm
tailored for large-scale problems to optimise the proposed objective. %, and
establish its convergence. Finally, through experiments on CIFAR-100 and
ImageNet, we show that our technique can significantly improve performance over
a number of baselines in settings where label shift is present.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised 3D Human Pose Estimation with Multiple-View Geometry. (arXiv:2108.07777v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bouazizi_A/0/1/0/all/0/1">Arij Bouazizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiederer_J/0/1/0/all/0/1">Julian Wiederer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kressel_U/0/1/0/all/0/1">Ulrich Kressel</a>, <a href="http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1">Vasileios Belagiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07777">
                                    <div class="article-summary-box-inner">
                                        <span>We present a self-supervised learning algorithm for 3D human pose estimation
of a single person based on a multiple-view camera system and 2D body pose
estimates for each view. To train our model, represented by a deep neural
network, we propose a four-loss function learning algorithm, which does not
require any 2D or 3D body pose ground-truth. The proposed loss functions make
use of the multiple-view geometry to reconstruct 3D body pose estimates and
impose body pose constraints across the camera views. Our approach utilizes all
available camera views during training, while the inference is single-view. In
our evaluations, we show promising performance on Human3.6M and HumanEva
benchmarks, while we also present a generalization study on MPI-INF-3DHP
dataset, as well as several ablation results. Overall, we outperform all
self-supervised learning methods and reach comparable results to supervised and
weakly-supervised learning approaches. Our code and models are publicly
available</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Autoregressive Transformer for Image Captioning. (arXiv:2106.09436v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuanen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhenzhen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09436">
                                    <div class="article-summary-box-inner">
                                        <span>Current state-of-the-art image captioning models adopt autoregressive
decoders, \ie they generate each word by conditioning on previously generated
words, which leads to heavy latency during inference. To tackle this issue,
non-autoregressive image captioning models have recently been proposed to
significantly accelerate the speed of inference by generating all words in
parallel. However, these non-autoregressive models inevitably suffer from large
generation quality degradation since they remove words dependence excessively.
To make a better trade-off between speed and quality, we introduce a
semi-autoregressive model for image captioning~(dubbed as SATIC), which keeps
the autoregressive property in global but generates words parallelly in local .
Based on Transformer, there are only a few modifications needed to implement
SATIC. Experimental results on the MSCOCO image captioning benchmark show that
SATIC can achieve a good trade-off without bells and whistles. Code is
available at {\color{magenta}\url{https://github.com/YuanEZhou/satic}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLiT: Neural Architecture Search for Global and Local Image Transformer. (arXiv:2107.02960v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+yan_J/0/1/0/all/0/1">Junjie yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02960">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first Neural Architecture Search (NAS) method to find a
better transformer architecture for image recognition. Recently, transformers
without CNN-based backbones are found to achieve impressive performance for
image recognition. However, the transformer is designed for NLP tasks and thus
could be sub-optimal when directly used for image recognition. In order to
improve the visual representation ability for transformers, we propose a new
search space and searching algorithm. Specifically, we introduce a locality
module that models the local correlations in images explicitly with fewer
computational cost. With the locality module, our search space is defined to
let the search algorithm freely trade off between global and local information
as well as optimizing the low-level design choice in each module. To tackle the
problem caused by huge search space, a hierarchical neural architecture search
method is proposed to search the optimal vision transformer from two levels
separately with the evolutionary algorithm. Extensive experiments on the
ImageNet dataset demonstrate that our method can find more discriminative and
efficient transformer variants than the ResNet family (e.g., ResNet101) and the
baseline ViT for image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Aware Universal Style Transfer. (arXiv:2108.04441v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1">Kibeom Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1">Seogkyu Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Huan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_H/0/1/0/all/0/1">Hyeran Byun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04441">
                                    <div class="article-summary-box-inner">
                                        <span>Style transfer aims to reproduce content images with the styles from
reference images. Existing universal style transfer methods successfully
deliver arbitrary styles to original images either in an artistic or a
photo-realistic way. However, the range of &#x27;arbitrary style&#x27; defined by
existing works is bounded in the particular domain due to their structural
limitation. Specifically, the degrees of content preservation and stylization
are established according to a predefined target domain. As a result, both
photo-realistic and artistic models have difficulty in performing the desired
style transfer for the other domain. To overcome this limitation, we propose a
unified architecture, Domain-aware Style Transfer Networks (DSTN) that transfer
not only the style but also the property of domain (i.e., domainness) from a
given reference image. To this end, we design a novel domainness indicator that
captures the domainness value from the texture and structural features of
reference images. Moreover, we introduce a unified framework with domain-aware
skip connection to adaptively transfer the stroke and palette to the input
contents guided by the domainness indicator. Our extensive experiments validate
that our model produces better qualitative results and outperforms previous
methods in terms of proxy metrics on both artistic and photo-realistic
stylizations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks. (arXiv:2011.11479v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alwassel_H/0/1/0/all/0/1">Humam Alwassel</a>, <a href="http://arxiv.org/find/cs/1/au:+Giancola_S/0/1/0/all/0/1">Silvio Giancola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11479">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the large memory footprint of untrimmed videos, current
state-of-the-art video localization methods operate atop precomputed video clip
features. These features are extracted from video encoders typically trained
for trimmed action classification tasks, making such features not necessarily
suitable for temporal localization. In this work, we propose a novel supervised
pretraining paradigm for clip features that not only trains to classify
activities but also considers background clips and global video information to
improve temporal sensitivity. Extensive experiments show that using features
trained with our novel pretraining strategy significantly improves the
performance of recent state-of-the-art methods on three tasks: Temporal Action
Localization, Action Proposal Generation, and Dense Video Captioning. We also
show that our pretraining approach is effective across three encoder
architectures and two pretraining datasets. We believe video feature encoding
is an important building block for localization algorithms, and extracting
temporally-sensitive features should be of paramount importance in building
more accurate models. The code and pretrained models are available on our
project website.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSR-GCN: Multi-Scale Residual Graph Convolution Networks for Human Motion Prediction. (arXiv:2108.07152v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang_L/0/1/0/all/0/1">Lingwei Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yongwei Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Chengjiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guiqing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07152">
                                    <div class="article-summary-box-inner">
                                        <span>Human motion prediction is a challenging task due to the stochasticity and
aperiodicity of future poses. Recently, graph convolutional network has been
proven to be very effective to learn dynamic relations among pose joints, which
is helpful for pose prediction. On the other hand, one can abstract a human
pose recursively to obtain a set of poses at multiple scales. With the increase
of the abstraction level, the motion of the pose becomes more stable, which
benefits pose prediction too. In this paper, we propose a novel Multi-Scale
Residual Graph Convolution Network (MSR-GCN) for human pose prediction task in
the manner of end-to-end. The GCNs are used to extract features from fine to
coarse scale and then from coarse to fine scale. The extracted features at each
scale are then combined and decoded to obtain the residuals between the input
and target poses. Intermediate supervisions are imposed on all the predicted
poses, which enforces the network to learn more representative features. Our
proposed approach is evaluated on two standard benchmark datasets, i.e., the
Human3.6M dataset and the CMU Mocap dataset. Experimental results demonstrate
that our method outperforms the state-of-the-art approaches. Code and
pre-trained models are available at https://github.com/Droliven/MSRGCN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who&#x27;s Waldo? Linking People Across Text and Images. (arXiv:2108.07253v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Claire Yuqing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1">Apoorv Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1">Yoav Artzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1">Noah Snavely</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1">Hadar Averbuch-Elor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07253">
                                    <div class="article-summary-box-inner">
                                        <span>We present a task and benchmark dataset for person-centric visual grounding,
the problem of linking between people named in a caption and people pictured in
an image. In contrast to prior work in visual grounding, which is predominantly
object-based, our new task masks out the names of people in captions in order
to encourage methods trained on such image-caption pairs to focus on contextual
cues (such as rich interactions between multiple people), rather than learning
associations between names and appearances. To facilitate this task, we
introduce a new dataset, Who&#x27;s Waldo, mined automatically from image-caption
data on Wikimedia Commons. We propose a Transformer-based method that
outperforms several strong baselines on this task, and are releasing our data
to the research community to spur work on contextual models that consider both
vision and language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. (arXiv:2103.14030v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ze Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yutong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yue Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yixuan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Stephen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14030">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new vision Transformer, called Swin Transformer, that
capably serves as a general-purpose backbone for computer vision. Challenges in
adapting Transformer from language to vision arise from differences between the
two domains, such as large variations in the scale of visual entities and the
high resolution of pixels in images compared to words in text. To address these
differences, we propose a hierarchical Transformer whose representation is
computed with \textbf{S}hifted \textbf{win}dows. The shifted windowing scheme
brings greater efficiency by limiting self-attention computation to
non-overlapping local windows while also allowing for cross-window connection.
This hierarchical architecture has the flexibility to model at various scales
and has linear computational complexity with respect to image size. These
qualities of Swin Transformer make it compatible with a broad range of vision
tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and
dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP
on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its
performance surpasses the previous state-of-the-art by a large margin of +2.7
box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the
potential of Transformer-based models as vision backbones. The hierarchical
design and the shifted window approach also prove beneficial for all-MLP
architectures. The code and models are publicly available
at~\url{https://github.com/microsoft/Swin-Transformer}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Multi-Target Domain Adaptation. (arXiv:2108.07792v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1">Chun-Han Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Hang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yukun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07792">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning methods enable us to train machine learning models on
distributed user data while preserving its privacy. However, it is not always
feasible to obtain high-quality supervisory signals from users, especially for
vision tasks. Unlike typical federated settings with labeled client data, we
consider a more practical scenario where the distributed client data is
unlabeled, and a centralized labeled dataset is available on the server. We
further take the server-client and inter-client domain shifts into account and
pose a domain adaptation problem with one source (centralized server data) and
multiple targets (distributed client data). Within this new Federated
Multi-Target Domain Adaptation (FMTDA) task, we analyze the model performance
of exiting domain adaptation methods and propose an effective DualAdapt method
to address the new challenges. Extensive experimental results on image
classification and semantic segmentation tasks demonstrate that our method
achieves high accuracy, incurs minimal communication cost, and requires low
computational resources on client devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Enhanced 3D Point Cloud Reconstruction from A Single Image. (arXiv:2108.07685v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ping_G/0/1/0/all/0/1">Guiju Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Esfahani_M/0/1/0/all/0/1">Mahdi Abolfazli Esfahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Han Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07685">
                                    <div class="article-summary-box-inner">
                                        <span>Solving the challenging problem of 3D object reconstruction from a single
image appropriately gives existing technologies the ability to perform with a
single monocular camera rather than requiring depth sensors. In recent years,
thanks to the development of deep learning, 3D reconstruction of a single image
has demonstrated impressive progress. Existing researches use Chamfer distance
as a loss function to guide the training of the neural network. However, the
Chamfer loss will give equal weights to all points inside the 3D point clouds.
It tends to sacrifice fine-grained and thin structures to avoid incurring a
high loss, which will lead to visually unsatisfactory results. This paper
proposes a framework that can recover a detailed three-dimensional point cloud
from a single image by focusing more on boundaries (edge and corner points).
Experimental results demonstrate that the proposed method outperforms existing
techniques significantly, both qualitatively and quantitatively, and has fewer
training parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixture-based Feature Space Learning for Few-shot Image Classification. (arXiv:2011.11872v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Afrasiyabi_A/0/1/0/all/0/1">Arman Afrasiyabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lalonde_J/0/1/0/all/0/1">Jean-Fran&#xe7;ois Lalonde</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagne_C/0/1/0/all/0/1">Christian Gagn&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11872">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Mixture-based Feature Space Learning (MixtFSL) for obtaining a
rich and robust feature representation in the context of few-shot image
classification. Previous works have proposed to model each base class either
with a single point or with a mixture model by relying on offline clustering
algorithms. In contrast, we propose to model base classes with mixture models
by simultaneously training the feature extractor and learning the mixture model
parameters in an online manner. This results in a richer and more
discriminative feature space which can be employed to classify novel examples
from very few samples. Two main stages are proposed to train the MixtFSL model.
First, the multimodal mixtures for each base class and the feature extractor
parameters are learned using a combination of two loss functions. Second, the
resulting network and mixture models are progressively refined through a
leader-follower learning procedure, which uses the current estimate as a
&quot;target&quot; network. This target network is used to make a consistent assignment
of instances to mixture components, which increases performance and stabilizes
training. The effectiveness of our end-to-end feature space learning approach
is demonstrated with extensive experiments on four standard datasets and four
backbones. Notably, we demonstrate that when we combine our robust
representation with recent alignment-based approaches, we achieve new
state-of-the-art results in the inductive setting, with an absolute accuracy
for 5-shot classification of 82.45 on miniImageNet, 88.20 with tieredImageNet,
and 60.70 in FC100 using the ResNet-12 backbone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Dense Video Captioning with Parallel Decoding. (arXiv:2108.07781v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Teng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruimao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhichao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_R/0/1/0/all/0/1">Ran Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07781">
                                    <div class="article-summary-box-inner">
                                        <span>Dense video captioning aims to generate multiple associated captions with
their temporal locations from the video. Previous methods follow a
sophisticated &quot;localize-then-describe&quot; scheme, which heavily relies on numerous
hand-crafted components. In this paper, we proposed a simple yet effective
framework for end-to-end dense video captioning with parallel decoding (PDVC),
by formulating the dense caption generation as a set prediction task. In
practice, through stacking a newly proposed event counter on the top of a
transformer decoder, the PDVC precisely segments the video into a number of
event pieces under the holistic understanding of the video content, which
effectively increases the coherence and readability of predicted captions.
Compared with prior arts, the PDVC has several appealing advantages: (1)
Without relying on heuristic non-maximum suppression or a recurrent event
sequence selection network to remove redundancy, PDVC directly produces an
event set with an appropriate size; (2) In contrast to adopting the two-stage
scheme, we feed the enhanced representations of event queries into the
localization head and caption head in parallel, making these two sub-tasks
deeply interrelated and mutually promoted through the optimization; (3) Without
bells and whistles, extensive experiments on ActivityNet Captions and YouCook2
show that PDVC is capable of producing high-quality captioning results,
surpassing the state-of-the-art two-stage methods when its localization
accuracy is on par with them. Code is available at
https://github.com/ttengwang/PDVC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Reduce Defocus Blur by Realistically Modeling Dual-Pixel Data. (arXiv:2012.03255v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Abuolaim_A/0/1/0/all/0/1">Abdullah Abuolaim</a>, <a href="http://arxiv.org/find/eess/1/au:+Delbracio_M/0/1/0/all/0/1">Mauricio Delbracio</a>, <a href="http://arxiv.org/find/eess/1/au:+Kelly_D/0/1/0/all/0/1">Damien Kelly</a>, <a href="http://arxiv.org/find/eess/1/au:+Brown_M/0/1/0/all/0/1">Michael S. Brown</a>, <a href="http://arxiv.org/find/eess/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03255">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown impressive results on data-driven defocus deblurring
using the two-image views available on modern dual-pixel (DP) sensors. One
significant challenge in this line of research is access to DP data. Despite
many cameras having DP sensors, only a limited number provide access to the
low-level DP sensor images. In addition, capturing training data for defocus
deblurring involves a time-consuming and tedious setup requiring the camera&#x27;s
aperture to be adjusted. Some cameras with DP sensors (e.g., smartphones) do
not have adjustable apertures, further limiting the ability to produce the
necessary training data. We address the data capture bottleneck by proposing a
procedure to generate realistic DP data synthetically. Our synthesis approach
mimics the optical image formation found on DP sensors and can be applied to
virtual scenes rendered with standard computer software. Leveraging these
realistic synthetic DP images, we introduce a recurrent convolutional network
(RCN) architecture that improves deblurring results and is suitable for use
with single-frame and multi-frame data (e.g., video) captured by DP sensors.
Finally, we show that our synthetic DP data is useful for training DNN models
targeting video deblurring applications where access to DP data remains
challenging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Internal Video Inpainting by Implicit Long-range Propagation. (arXiv:2108.01912v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1">Hao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tengfei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01912">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for video inpainting by adopting an internal
learning strategy. Unlike previous methods that use optical flow for
cross-frame context propagation to inpaint unknown regions, we show that this
can be achieved implicitly by fitting a convolutional neural network to known
regions. Moreover, to handle challenging sequences with ambiguous backgrounds
or long-term occlusion, we design two regularization terms to preserve
high-frequency details and long-term temporal consistency. Extensive
experiments on the DAVIS dataset demonstrate that the proposed method achieves
state-of-the-art inpainting quality quantitatively and qualitatively. We
further extend the proposed method to another challenging task: learning to
remove an object from a video giving a single object mask in only one frame in
a 4K video.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Appearance Based Deep Domain Adaptation for the Classification of Aerial Images. (arXiv:2108.07779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wittich_D/0/1/0/all/0/1">Dennis Wittich</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottensteiner_F/0/1/0/all/0/1">Franz Rottensteiner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07779">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses domain adaptation for the pixel-wise classification of
remotely sensed data using deep neural networks (DNN) as a strategy to reduce
the requirements of DNN with respect to the availability of training data. We
focus on the setting in which labelled data are only available in a source
domain DS, but not in a target domain DT. Our method is based on adversarial
training of an appearance adaptation network (AAN) that transforms images from
DS such that they look like images from DT. Together with the original label
maps from DS, the transformed images are used to adapt a DNN to DT. We propose
a joint training strategy of the AAN and the classifier, which constrains the
AAN to transform the images such that they are correctly classified. In this
way, objects of a certain class are changed such that they resemble objects of
the same class in DT. To further improve the adaptation performance, we propose
a new regularization loss for the discriminator network used in domain
adversarial training. We also address the problem of finding the optimal values
of the trained network parameters, proposing an unsupervised entropy based
parameter selection criterion which compensates for the fact that there is no
validation set in DT that could be monitored. As a minor contribution, we
present a new weighting strategy for the cross-entropy loss, addressing the
problem of imbalanced class distributions. Our method is evaluated in 42
adaptation scenarios using datasets from 7 cities, all consisting of
high-resolution digital orthophotos and height data. It achieves a positive
transfer in all cases, and on average it improves the performance in the target
domain by 4.3% in overall accuracy. In adaptation scenarios between datasets
from the ISPRS semantic labelling benchmark our method outperforms those from
recent publications by 10-20% with respect to the mean intersection over union.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for Depth Completion. (arXiv:2012.08270v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lina Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xibin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xiaoyang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diao_J/0/1/0/all/0/1">Junwei Diao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengmeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangjun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08270">
                                    <div class="article-summary-box-inner">
                                        <span>Depth completion aims to recover a dense depth map from a sparse depth map
with the corresponding color image as input. Recent approaches mainly formulate
depth completion as a one-stage end-to-end learning task, which outputs dense
depth maps directly. However, the feature extraction and supervision in
one-stage frameworks are insufficient, limiting the performance of these
approaches. To address this problem, we propose a novel end-to-end residual
learning framework, which formulates the depth completion as a two-stage
learning task, i.e., a sparse-to-coarse stage and a coarse-to-fine stage.
First, a coarse dense depth map is obtained by a simple CNN framework. Then, a
refined depth map is further obtained using a residual learning strategy in the
coarse-to-fine stage with a coarse depth map and color image as input.
Specially, in the coarse-to-fine stage, a channel shuffle extraction operation
is utilized to extract more representative features from the color image and
coarse depth map, and an energy based fusion operation is exploited to
effectively fuse these features obtained by channel shuffle operation, thus
leading to more accurate and refined depth maps. We achieve SoTA performance in
RMSE on KITTI benchmark. Extensive experiments on other datasets future
demonstrate the superiority of our approach over current state-of-the-art depth
completion approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the Reality Gap for Pose Estimation Networks using Sensor-Based Domain Randomization. (arXiv:2011.08517v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hagelskjaer_F/0/1/0/all/0/1">Frederik Hagelskjaer</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_A/0/1/0/all/0/1">Anders Glent Buch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08517">
                                    <div class="article-summary-box-inner">
                                        <span>Since the introduction of modern deep learning methods for object pose
estimation, test accuracy and efficiency has increased significantly. For
training, however, large amounts of annotated training data are required for
good performance. While the use of synthetic training data prevents the need
for manual annotation, there is currently a large performance gap between
methods trained on real and synthetic data. This paper introduces a new method,
which bridges this gap.

Most methods trained on synthetic data use 2D images, as domain randomization
in 2D is more developed. To obtain precise poses, many of these methods perform
a final refinement using 3D data. Our method integrates the 3D data into the
network to increase the accuracy of the pose estimation. To allow for domain
randomization in 3D, a sensor-based data augmentation has been developed.
Additionally, we introduce the SparseEdge feature, which uses a wider search
space during point cloud propagation to avoid relying on specific features
without increasing run-time.

Experiments on three large pose estimation benchmarks show that the presented
method outperforms previous methods trained on synthetic data and achieves
comparable results to existing methods trained on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks. (arXiv:2007.05785v5 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Wei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhaofei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Masquelier_T/0/1/0/all/0/1">Timothee Masquelier</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tiejun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05785">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs) have attracted enormous research interest due
to temporal information processing capability, low power consumption, and high
biological plausibility. However, the formulation of efficient and
high-performance learning algorithms for SNNs is still challenging. Most
existing learning methods learn weights only, and require manual tuning of the
membrane-related parameters that determine the dynamics of a single spiking
neuron. These parameters are typically chosen to be the same for all neurons,
which limits the diversity of neurons and thus the expressiveness of the
resulting SNNs. In this paper, we take inspiration from the observation that
membrane-related parameters are different across brain regions, and propose a
training algorithm that is capable of learning not only the synaptic weights
but also the membrane time constants of SNNs. We show that incorporating
learnable membrane time constants can make the network less sensitive to
initial values and can speed up learning. In addition, we reevaluate the
pooling methods in SNNs and find that max-pooling will not lead to significant
information loss and have the advantage of low computation cost and binary
compatibility. We evaluate the proposed method for image classification tasks
on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and
neuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment
results show that the proposed method outperforms the state-of-the-art accuracy
on nearly all datasets, using fewer time-steps. Our codes are available at
https://github.com/fangwei123456/Parametric-Leaky-Integrate-and-Fire-Spiking-Neuron.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully Convolutional Networks for Panoptic Segmentation with Point-based Supervision. (arXiv:2108.07682v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hengshuang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiaojuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yukang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zeming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07682">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a conceptually simple, strong, and efficient
framework for fully- and weakly-supervised panoptic segmentation, called
Panoptic FCN. Our approach aims to represent and predict foreground things and
background stuff in a unified fully convolutional pipeline, which can be
optimized with point-based fully or weak supervision. In particular, Panoptic
FCN encodes each object instance or stuff category with the proposed kernel
generator and produces the prediction by convolving the high-resolution feature
directly. With this approach, instance-aware and semantically consistent
properties for things and stuff can be respectively satisfied in a simple
generate-kernel-then-segment workflow. Without extra boxes for localization or
instance separation, the proposed approach outperforms the previous box-based
and -free models with high efficiency. Furthermore, we propose a new form of
point-based annotation for weakly-supervised panoptic segmentation. It only
needs several random points for both things and stuff, which dramatically
reduces the annotation cost of human. The proposed Panoptic FCN is also proved
to have much superior performance in this weakly-supervised setting, which
achieves 82% of the fully-supervised performance with only 20 randomly
annotated points per instance. Extensive experiments demonstrate the
effectiveness and efficiency of Panoptic FCN on COCO, VOC 2012, Cityscapes, and
Mapillary Vistas datasets. And it sets up a new leading benchmark for both
fully- and weakly-supervised panoptic segmentation. Our code and models are
made publicly available at https://github.com/dvlab-research/PanopticFCN</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepACC:Automate Chromosome Classification based on Metaphase Images using Deep Learning Framework Fused with Prior Knowledge. (arXiv:2006.15528v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunlong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tianqi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yufan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Manqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fuhai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yinhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1">Chan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1">Jie Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Li Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15528">
                                    <div class="article-summary-box-inner">
                                        <span>Chromosome classification is an important but difficult and tedious task in
karyotyping. Previous methods only classify manually segmented single
chromosome, which is far from clinical practice. In this work, we propose a
detection based method, DeepACC, to locate and fine classify chromosomes
simultaneously based on the whole metaphase image. We firstly introduce the
Additive Angular Margin Loss to enhance the discriminative power of model. To
alleviate batch effects, we transform decision boundary of each class
case-by-case through a siamese network which make full use of prior knowledges
that chromosomes usually appear in pairs. Furthermore, we take the clinically
seven group criterion as a prior knowledge and design an additional Group
Inner-Adjacency Loss to further reduce inter-class similarities. 3390 metaphase
images from clinical laboratory are collected and labelled to evaluate the
performance. Results show that the new design brings encouraging performance
gains comparing to the state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACAV100M: Automatic Curation of Large-Scale Datasets for Audio-Visual Video Representation Learning. (arXiv:2101.10803v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jiwan Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gunhee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Breuel_T/0/1/0/all/0/1">Thomas Breuel</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yale Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10803">
                                    <div class="article-summary-box-inner">
                                        <span>The natural association between visual observations and their corresponding
sound provides powerful self-supervisory signals for learning video
representations, which makes the ever-growing amount of online videos an
attractive source of training data. However, large portions of online videos
contain irrelevant audio-visual signals because of edited/overdubbed audio, and
models trained on such uncurated videos have shown to learn suboptimal
representations. Therefore, existing approaches rely almost exclusively on
datasets with predetermined taxonomies of semantic concepts, where there is a
high chance of audio-visual correspondence. Unfortunately, constructing such
datasets require labor intensive manual annotation and/or verification, which
severely limits the utility of online videos for large-scale learning. In this
work, we present an automatic dataset curation approach based on subset
optimization where the objective is to maximize the mutual information between
audio and visual channels in videos. We demonstrate that our approach finds
videos with high audio-visual correspondence and show that self-supervised
models trained on our data achieve competitive performances compared to models
trained on existing manually curated datasets. The most significant benefit of
our approach is scalability: We release ACAV100M that contains 100 million
videos with high audio-visual correspondence, ideal for self-supervised video
representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TOOD: Task-aligned One-stage Object Detection. (arXiv:2108.07755v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1">Chengjian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yujie Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Scott_M/0/1/0/all/0/1">Matthew R. Scott</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weilin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07755">
                                    <div class="article-summary-box-inner">
                                        <span>One-stage object detection is commonly implemented by optimizing two
sub-tasks: object classification and localization, using heads with two
parallel branches, which might lead to a certain level of spatial misalignment
in predictions between the two tasks. In this work, we propose a Task-aligned
One-stage Object Detection (TOOD) that explicitly aligns the two tasks in a
learning-based manner. First, we design a novel Task-aligned Head (T-Head)
which offers a better balance between learning task-interactive and
task-specific features, as well as a greater flexibility to learn the alignment
via a task-aligned predictor. Second, we propose Task Alignment Learning (TAL)
to explicitly pull closer (or even unify) the optimal anchors for the two tasks
during training via a designed sample assignment scheme and a task-aligned
loss. Extensive experiments are conducted on MS-COCO, where TOOD achieves a
51.1 AP at single-model single-scale testing. This surpasses the recent
one-stage detectors by a large margin, such as ATSS (47.7 AP), GFL (48.2 AP),
and PAA (49.0 AP), with fewer parameters and FLOPs. Qualitative results also
demonstrate the effectiveness of TOOD for better aligning the tasks of object
classification and localization. Code is available at
https://github.com/fcjian/TOOD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dense Interaction Learning for Video-based Person Re-identification. (arXiv:2103.09013v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tianyu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09013">
                                    <div class="article-summary-box-inner">
                                        <span>Video-based person re-identification (re-ID) aims at matching the same person
across video clips. Efficiently exploiting multi-scale fine-grained features
while building the structural interaction among them is pivotal for its
success. In this paper, we propose a hybrid framework, Dense Interaction
Learning (DenseIL), that takes the principal advantages of both CNN-based and
Attention-based architectures to tackle video-based person re-ID difficulties.
DenseIL contains a CNN encoder and a Dense Interaction (DI) decoder. The CNN
encoder is responsible for efficiently extracting discriminative spatial
features while the DI decoder is designed to densely model spatial-temporal
inherent interaction across frames. Different from previous works, we
additionally let the DI decoder densely attends to intermediate fine-grained
CNN features and that naturally yields multi-grained spatial-temporal
representation for each video clip. Moreover, we introduce Spatio-TEmporal
Positional Embedding (STEP-Emb) into the DI decoder to investigate the
positional relation among the spatial-temporal inputs. Our experiments
consistently and significantly outperform all the state-of-the-art methods on
multiple standard video-based person re-ID datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MVTN: Multi-View Transformation Network for 3D Shape Recognition. (arXiv:2011.13244v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamdi_A/0/1/0/all/0/1">Abdullah Hamdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Giancola_S/0/1/0/all/0/1">Silvio Giancola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13244">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view projection methods have demonstrated their ability to reach
state-of-the-art performance on 3D shape recognition. Those methods learn
different ways to aggregate information from multiple views. However, the
camera view-points for those views tend to be heuristically set and fixed for
all shapes. To circumvent the lack of dynamism of current multi-view methods,
we propose to learn those view-points. In particular, we introduce the
Multi-View Transformation Network (MVTN) that regresses optimal view-points for
3D shape recognition, building upon advances in differentiable rendering. As a
result, MVTN can be trained end-to-end along with any multi-view network for 3D
shape classification. We integrate MVTN in a novel adaptive multi-view pipeline
that can render either 3D meshes or point clouds. MVTN exhibits clear
performance gains in the tasks of 3D shape classification and 3D shape
retrieval without the need for extra training supervision. In these tasks, MVTN
achieves state-of-the-art performance on ModelNet40, ShapeNet Core55, and the
most recent and realistic ScanObjectNN dataset (up to 6% improvement).
Interestingly, we also show that MVTN can provide network robustness against
rotation and occlusion in the 3D domain. The code is available at
https://github.com/ajhamdi/MVTN .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-aware Contrastive Regression for Action Quality Assessment. (arXiv:2108.07797v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xumin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07797">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing action quality is challenging due to the subtle differences between
videos and large variations in scores. Most existing approaches tackle this
problem by regressing a quality score from a single video, suffering a lot from
the large inter-video score variations. In this paper, we show that the
relations among videos can provide important clues for more accurate action
quality assessment during both training and inference. Specifically, we
reformulate the problem of action quality assessment as regressing the relative
scores with reference to another video that has shared attributes (e.g.,
category and difficulty), instead of learning unreferenced scores. Following
this formulation, we propose a new Contrastive Regression (CoRe) framework to
learn the relative scores by pair-wise comparison, which highlights the
differences between videos and guides the models to learn the key hints for
assessment. In order to further exploit the relative information between two
videos, we devise a group-aware regression tree to convert the conventional
score regression into two easier sub-problems: coarse-to-fine classification
and regression in small intervals. To demonstrate the effectiveness of CoRe, we
conduct extensive experiments on three mainstream AQA datasets including AQA-7,
MTL-AQA and JIGSAWS. Our approach outperforms previous methods by a large
margin and establishes new state-of-the-art on all three benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Barriers to Data Sharing with Medical Image Generation: A Comprehensive Evaluation. (arXiv:2012.03769v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schutte_A/0/1/0/all/0/1">August DuMont Sch&#xfc;tte</a>, <a href="http://arxiv.org/find/eess/1/au:+Hetzel_J/0/1/0/all/0/1">J&#xfc;rgen Hetzel</a>, <a href="http://arxiv.org/find/eess/1/au:+Gatidis_S/0/1/0/all/0/1">Sergios Gatidis</a>, <a href="http://arxiv.org/find/eess/1/au:+Hepp_T/0/1/0/all/0/1">Tobias Hepp</a>, <a href="http://arxiv.org/find/eess/1/au:+Dietz_B/0/1/0/all/0/1">Benedikt Dietz</a>, <a href="http://arxiv.org/find/eess/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/eess/1/au:+Schwab_P/0/1/0/all/0/1">Patrick Schwab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03769">
                                    <div class="article-summary-box-inner">
                                        <span>Privacy concerns around sharing personally identifiable information are a
major practical barrier to data sharing in medical research. However, in many
cases, researchers have no interest in a particular individual&#x27;s information
but rather aim to derive insights at the level of cohorts. Here, we utilize
Generative Adversarial Networks (GANs) to create derived medical imaging
datasets consisting entirely of synthetic patient data. The synthetic images
ideally have, in aggregate, similar statistical properties to those of a source
dataset but do not contain sensitive personal information. We assess the
quality of synthetic data generated by two GAN models for chest radiographs
with 14 different radiology findings and brain computed tomography (CT) scans
with six types of intracranial hemorrhages. We measure the synthetic image
quality by the performance difference of predictive models trained on either
the synthetic or the real dataset. We find that synthetic data performance
disproportionately benefits from a reduced number of unique label combinations.
Our open-source benchmark also indicates that at low number of samples per
class, label overfitting effects start to dominate GAN training. We
additionally conducted a reader study in which trained radiologists do not
perform better than random on discriminating between synthetic and real medical
images for intermediate levels of resolutions. In accordance with our benchmark
results, the classification accuracy of radiologists increases at higher
spatial resolution levels. Our study offers valuable guidelines and outlines
practical conditions under which insights derived from synthetic medical images
are similar to those that would have been derived from real imaging data. Our
results indicate that synthetic data sharing may be an attractive and
privacy-preserving alternative to sharing real patient-level data in the right
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RandomRooms: Unsupervised Pre-training from Synthetic Shapes and Randomized Layouts for 3D Object Detection. (arXiv:2108.07794v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Benlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07794">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud understanding has made great progress in recent years.
However, one major bottleneck is the scarcity of annotated real datasets,
especially compared to 2D object detection tasks, since a large amount of labor
is involved in annotating the real scans of a scene. A promising solution to
this problem is to make better use of the synthetic dataset, which consists of
CAD object models, to boost the learning on real datasets. This can be achieved
by the pre-training and fine-tuning procedure. However, recent work on 3D
pre-training exhibits failure when transfer features learned on synthetic
objects to other real-world applications. In this work, we put forward a new
method called RandomRooms to accomplish this objective. In particular, we
propose to generate random layouts of a scene by making use of the objects in
the synthetic CAD dataset and learn the 3D scene representation by applying
object-level contrastive learning on two random scenes generated from the same
set of synthetic objects. The model pre-trained in this way can serve as a
better initialization when later fine-tuning on the 3D object detection task.
Empirically, we show consistent improvement in downstream 3D detection tasks on
several base models, especially when less training data are used, which
strongly demonstrates the effectiveness and generalization of our method.
Benefiting from the rich semantic knowledge and diverse objects from synthetic
data, our method establishes the new state-of-the-art on widely-used 3D
detection benchmarks ScanNetV2 and SUN RGB-D. We expect our attempt to provide
a new perspective for bridging object and scene-level 3D understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hybrid Sparse-Dense Monocular SLAM System for Autonomous Driving. (arXiv:2108.07736v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gallagher_L/0/1/0/all/0/1">Louis Gallagher</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Varun Ravi Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1">Senthil Yogamani</a>, <a href="http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1">John B. McDonald</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07736">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a system for incrementally reconstructing a dense
3D model of the geometry of an outdoor environment using a single monocular
camera attached to a moving vehicle. Dense models provide a rich representation
of the environment facilitating higher-level scene understanding, perception,
and planning. Our system employs dense depth prediction with a hybrid mapping
architecture combining state-of-the-art sparse features and dense fusion-based
visual SLAM algorithms within an integrated framework. Our novel contributions
include design of hybrid sparse-dense camera tracking and loop closure, and
scale estimation improvements in dense depth prediction. We use the motion
estimates from the sparse method to overcome the large and variable inter-frame
displacement typical of outdoor vehicle scenarios. Our system then registers
the live image with the dense model using whole-image alignment. This enables
the fusion of the live frame and dense depth prediction into the model. Global
consistency and alignment between the sparse and dense models are achieved by
applying pose constraints from the sparse method directly within the
deformation of the dense model. We provide qualitative and quantitative results
for both trajectory estimation and surface reconstruction accuracy,
demonstrating competitive performance on the KITTI dataset. Qualitative results
of the proposed approach are illustrated in https://youtu.be/Pn2uaVqjskY.
Source code for the project is publicly available at the following repository
https://github.com/robotvisionmu/DenseMonoSLAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Monocular Depth Estimation for All Day Images using Domain Separation. (arXiv:2108.07628v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lina Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xibin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengmeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangjun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07628">
                                    <div class="article-summary-box-inner">
                                        <span>Remarkable results have been achieved by DCNN based self-supervised depth
estimation approaches. However, most of these approaches can only handle either
day-time or night-time images, while their performance degrades for all-day
images due to large domain shift and the variation of illumination between day
and night images. To relieve these limitations, we propose a domain-separated
network for self-supervised depth estimation of all-day images. Specifically,
to relieve the negative influence of disturbing terms (illumination, etc.), we
partition the information of day and night image pairs into two complementary
sub-spaces: private and invariant domains, where the former contains the unique
information (illumination, etc.) of day and night images and the latter
contains essential shared information (texture, etc.). Meanwhile, to guarantee
that the day and night images contain the same information, the
domain-separated network takes the day-time images and corresponding night-time
images (generated by GAN) as input, and the private and invariant feature
extractors are learned by orthogonality and similarity loss, where the domain
gap can be alleviated, thus better depth maps can be expected. Meanwhile, the
reconstruction and photometric losses are utilized to estimate complementary
information and depth maps effectively. Experimental results demonstrate that
our approach achieves state-of-the-art depth estimation results for all-day
images on the challenging Oxford RobotCar dataset, proving the superiority of
our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal Jacobian Regularization for Unsupervised Disentanglement in Image Generation. (arXiv:2108.07668v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yuxiang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yupeng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zhilong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhongqin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1">Wangmeng Zuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07668">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised disentanglement learning is a crucial issue for understanding
and exploiting deep generative models. Recently, SeFa tries to find latent
disentangled directions by performing SVD on the first projection of a
pre-trained GAN. However, it is only applied to the first layer and works in a
post-processing way. Hessian Penalty minimizes the off-diagonal entries of the
output&#x27;s Hessian matrix to facilitate disentanglement, and can be applied to
multi-layers.However, it constrains each entry of output independently, making
it not sufficient in disentangling the latent directions (e.g., shape, size,
rotation, etc.) of spatially correlated variations. In this paper, we propose a
simple Orthogonal Jacobian Regularization (OroJaR) to encourage deep generative
model to learn disentangled representations. It simply encourages the variation
of output caused by perturbations on different latent dimensions to be
orthogonal, and the Jacobian with respect to the input is calculated to
represent this variation. We show that our OroJaR also encourages the output&#x27;s
Hessian matrix to be diagonal in an indirect manner. In contrast to the Hessian
Penalty, our OroJaR constrains the output in a holistic way, making it very
effective in disentangling latent dimensions corresponding to spatially
correlated variations. Quantitative and qualitative experimental results show
that our method is effective in disentangled and controllable image generation,
and performs favorably against the state-of-the-art methods. Our code is
available at https://github.com/csyxwei/OroJaR</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Backbone for Hyperspectral Image Reconstruction. (arXiv:2108.07739v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jiamian Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yulun Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_X/0/1/0/all/0/1">Xin Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1">Yun Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Tao_Z/0/1/0/all/0/1">Zhiqiang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07739">
                                    <div class="article-summary-box-inner">
                                        <span>The study of 3D hyperspectral image (HSI) reconstruction refers to the
inverse process of snapshot compressive imaging, during which the optical
system, e.g., the coded aperture snapshot spectral imaging (CASSI) system,
captures the 3D spatial-spectral signal and encodes it to a 2D measurement.
While numerous sophisticated neural networks have been elaborated for
end-to-end reconstruction, trade-offs still need to be made among performance,
efficiency (training and inference time), and feasibility (the ability of
restoring high resolution HSI on limited GPU memory). This raises a challenge
to design a new baseline to conjointly meet the above requirements. In this
paper, we fill in this blank by proposing a Spatial/Spectral Invariant Residual
U-Net, namely SSI-ResU-Net. It differentiates with U-Net in three folds--1)
scale/spectral-invariant learning, 2) nested residual learning, and 3)
computational efficiency. Benefiting from these three modules, the proposed
SSI-ResU-Net outperforms the current state-of-the-art method TSA-Net by over 3
dB in PSNR and 0.036 in SSIM while only using 2.82% trainable parameters. To
the greatest extent, SSI-ResU-Net achieves competing performance with over
77.3% reduction in terms of floating-point operations (FLOPs), which for the
first time, makes high-resolution HSI reconstruction feasible under practical
application scenarios. Code and pre-trained models are made available at
https://github.com/Jiamian-Wang/HSI_baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Look Who&#x27;s Talking: Active Speaker Detection in the Wild. (arXiv:2108.07640v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">You Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Heo_H/0/1/0/all/0/1">Hee-Soo Heo</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_S/0/1/0/all/0/1">Soyeon Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1">Soo-Whan Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1">Yoohwan Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Bong-Jin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1">Youngki Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Joon Son Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07640">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present a novel audio-visual dataset for active speaker
detection in the wild. A speaker is considered active when his or her face is
visible and the voice is audible simultaneously. Although active speaker
detection is a crucial pre-processing step for many audio-visual tasks, there
is no existing dataset of natural human speech to evaluate the performance of
active speaker detection. We therefore curate the Active Speakers in the Wild
(ASW) dataset which contains videos and co-occurring speech segments with dense
speech activity labels. Videos and timestamps of audible segments are parsed
and adopted from VoxConverse, an existing speaker diarisation dataset that
consists of videos in the wild. Face tracks are extracted from the videos and
active segments are annotated based on the timestamps of VoxConverse in a
semi-automatic way. Two reference systems, a self-supervised system and a fully
supervised one, are evaluated on the dataset to provide the baseline
performances of ASW. Cross-domain evaluation is conducted in order to show the
negative effect of dubbed videos in the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASCNet: Self-supervised Video Representation Learning with Appearance-Speed Consistency. (arXiv:2106.02342v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Deng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiwen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhihua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangmiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02342">
                                    <div class="article-summary-box-inner">
                                        <span>We study self-supervised video representation learning, which is a
challenging task due to 1) lack of labels for explicit supervision; 2)
unstructured and noisy visual information. Existing methods mainly use
contrastive loss with video clips as the instances and learn visual
representation by discriminating instances from each other, but they need a
careful treatment of negative pairs by either relying on large batch sizes,
memory banks, extra modalities or customized mining strategies, which
inevitably includes noisy data. In this paper, we observe that the consistency
between positive samples is the key to learn robust video representation.
Specifically, we propose two tasks to learn the appearance and speed
consistency, respectively. The appearance consistency task aims to maximize the
similarity between two clips of the same video with different playback speeds.
The speed consistency task aims to maximize the similarity between two clips
with the same playback speed but different appearance information. We show that
optimizing the two tasks jointly consistently improves the performance on
downstream tasks, e.g., action recognition and video retrieval. Remarkably, for
action recognition on the UCF-101 dataset, we achieve 90.8\% accuracy without
using any extra modalities or negative pairs for unsupervised pretraining,
which outperforms the ImageNet supervised pretrained model. Codes and models
will be available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Neural Architecture Search with Operation Embeddings. (arXiv:2105.04885v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatzianastasis_M/0/1/0/all/0/1">Michail Chatzianastasis</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasoulas_G/0/1/0/all/0/1">George Dasoulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Siolas_G/0/1/0/all/0/1">Georgios Siolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04885">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Architecture Search (NAS) has recently gained increased attention, as
a class of approaches that automatically searches in an input space of network
architectures. A crucial part of the NAS pipeline is the encoding of the
architecture that consists of the applied computational blocks, namely the
operations and the links between them. Most of the existing approaches either
fail to capture the structural properties of the architectures or use
hand-engineered vector to encode the operator information. In this paper, we
propose the replacement of fixed operator encoding with learnable
representations in the optimization process. This approach, which effectively
captures the relations of different operations, leads to smoother and more
accurate representations of the architectures and consequently to improved
performance of the end task. Our extensive evaluation in ENAS benchmark
demonstrates the effectiveness of the proposed operation embeddings to the
generation of highly accurate models, achieving state-of-the-art performance.
Finally, our method produces top-performing architectures that share similar
operation and graph patterns, highlighting a strong correlation between the
structural properties of the architecture and its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Evaluation of RGB and LiDAR Fusion for Semantic Segmentation. (arXiv:2108.07661v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Amr S. Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelkader_A/0/1/0/all/0/1">Ali Abdelkader</a>, <a href="http://arxiv.org/find/cs/1/au:+Anany_M/0/1/0/all/0/1">Mohamed Anany</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Behady_O/0/1/0/all/0/1">Omar El-Behady</a>, <a href="http://arxiv.org/find/cs/1/au:+Faisal_M/0/1/0/all/0/1">Muhammad Faisal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hangal_A/0/1/0/all/0/1">Asser Hangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Eraqi_H/0/1/0/all/0/1">Hesham M. Eraqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Moustafa_M/0/1/0/all/0/1">Mohamed N. Moustafa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07661">
                                    <div class="article-summary-box-inner">
                                        <span>LiDARs and cameras are the two main sensors that are planned to be included
in many announced autonomous vehicles prototypes. Each of the two provides a
unique form of data from a different perspective to the surrounding
environment. In this paper, we explore and attempt to answer the question: is
there an added benefit by fusing those two forms of data for the purpose of
semantic segmentation within the context of autonomous driving? We also attempt
to show at which level does said fusion prove to be the most useful. We
evaluated our algorithms on the publicly available SemanticKITTI dataset. All
fusion models show improvements over the base model, with the mid-level fusion
showing the highest improvement of 2.7% in terms of mean Intersection over
Union (mIoU) metric.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">spectrai: A deep learning framework for spectral data. (arXiv:2108.07595v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Horgan_C/0/1/0/all/0/1">Conor C. Horgan</a>, <a href="http://arxiv.org/find/eess/1/au:+Bergholt_M/0/1/0/all/0/1">Mads S. Bergholt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07595">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning computer vision techniques have achieved many successes in
recent years across numerous imaging domains. However, the application of deep
learning to spectral data remains a complex task due to the need for
augmentation routines, specific architectures for spectral data, and
significant memory requirements. Here we present spectrai, an open-source deep
learning framework designed to facilitate the training of neural networks on
spectral data and enable comparison between different methods. Spectrai
provides numerous built-in spectral data pre-processing and augmentation
methods, neural networks for spectral data including spectral (image)
denoising, spectral (image) classification, spectral image segmentation, and
spectral image super-resolution. Spectrai includes both command line and
graphical user interfaces (GUI) designed to guide users through model and
hyperparameter decisions for a wide range of applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight. (arXiv:2106.04263v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1">Qi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zejia Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1">Qi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04263">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformer (ViT) attains state-of-the-art performance in visual
recognition, and the variant, Local Vision Transformer, makes further
improvements. The major component in Local Vision Transformer, local attention,
performs the attention separately over small local windows. We rephrase local
attention as a channel-wise locally-connected layer and analyze it from two
network regularization manners, sparse connectivity and weight sharing, as well
as weight computation. Sparse connectivity: there is no connection across
channels, and each position is connected to the positions within a small local
window. Weight sharing: the connection weights for one position are shared
across channels or within each group of channels. Dynamic weight: the
connection weights are dynamically predicted according to each image instance.
We point out that local attention resembles depth-wise convolution and its
dynamic version in sparse connectivity. The main difference lies in weight
sharing - depth-wise convolution shares connection weights (kernel weights)
across spatial positions. We empirically observe that the models based on
depth-wise convolution and the dynamic variant with lower computation
complexity perform on-par with or sometimes slightly better than Swin
Transformer, an instance of Local Vision Transformer, for ImageNet
classification, COCO object detection and ADE semantic segmentation. These
observations suggest that Local Vision Transformer takes advantage of two
regularization forms and dynamic weight to increase the network capacity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Classification Equilibrium in Long-Tailed Object Detection. (arXiv:2108.07507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1">Chengjian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yujie Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weilin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07507">
                                    <div class="article-summary-box-inner">
                                        <span>The conventional detectors tend to make imbalanced classification and suffer
performance drop, when the distribution of the training data is severely
skewed. In this paper, we propose to use the mean classification score to
indicate the classification accuracy for each category during training. Based
on this indicator, we balance the classification via an Equilibrium Loss (EBL)
and a Memory-augmented Feature Sampling (MFS) method. Specifically, EBL
increases the intensity of the adjustment of the decision boundary for the weak
classes by a designed score-guided loss margin between any two classes. On the
other hand, MFS improves the frequency and accuracy of the adjustment of the
decision boundary for the weak classes through over-sampling the instance
features of those classes. Therefore, EBL and MFS work collaboratively for
finding the classification equilibrium in long-tailed detection, and
dramatically improve the performance of tail classes while maintaining or even
improving the performance of head classes. We conduct experiments on LVIS using
Mask R-CNN with various backbones including ResNet-50-FPN and ResNet-101-FPN to
show the superiority of the proposed method. It improves the detection
performance of tail classes by 15.6 AP, and outperforms the most recent
long-tailed object detectors by more than 1 AP. Code is available at
https://github.com/fcjian/LOCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Latent Transformer for Disentangled Face Editing in Images and Videos. (arXiv:2106.11895v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Newson_A/0/1/0/all/0/1">Alasdair Newson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gousseau_Y/0/1/0/all/0/1">Yann Gousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellier_P/0/1/0/all/0/1">Pierre Hellier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11895">
                                    <div class="article-summary-box-inner">
                                        <span>High quality facial image editing is a challenging problem in the movie
post-production industry, requiring a high degree of control and identity
preservation. Previous works that attempt to tackle this problem may suffer
from the entanglement of facial attributes and the loss of the person&#x27;s
identity. Furthermore, many algorithms are limited to a certain task. To tackle
these limitations, we propose to edit facial attributes via the latent space of
a StyleGAN generator, by training a dedicated latent transformation network and
incorporating explicit disentanglement and identity preservation terms in the
loss function. We further introduce a pipeline to generalize our face editing
to videos. Our model achieves a disentangled, controllable, and
identity-preserving facial attribute editing, even in the challenging case of
real (i.e., non-synthetic) images and videos. We conduct extensive experiments
on image and video datasets and show that our model outperforms other
state-of-the-art methods in visual quality and quantitative evaluation. Source
codes are available at https://github.com/InterDigitalInc/latent-transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Skeletal Graph Neural Networks for Hard 3D Pose Estimation. (arXiv:2108.07181v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_N/0/1/0/all/0/1">Nanxuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07181">
                                    <div class="article-summary-box-inner">
                                        <span>Various deep learning techniques have been proposed to solve the single-view
2D-to-3D pose estimation problem. While the average prediction accuracy has
been improved significantly over the years, the performance on hard poses with
depth ambiguity, self-occlusion, and complex or rare poses is still far from
satisfactory. In this work, we target these hard poses and present a novel
skeletal GNN learning solution. To be specific, we propose a hop-aware
hierarchical channel-squeezing fusion layer to effectively extract relevant
information from neighboring nodes while suppressing undesired noises in GNN
learning. In addition, we propose a temporal-aware dynamic graph construction
procedure that is robust and effective for 3D pose estimation. Experimental
results on the Human3.6M dataset show that our solution achieves 10.3\% average
prediction accuracy improvement and greatly improves on hard poses over
state-of-the-art techniques. We further apply the proposed technique on the
skeleton-based action recognition task and also achieve state-of-the-art
performance. Our code is available at
https://github.com/ailingzengzzz/Skeletal-GNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PlenOctrees for Real-time Rendering of Neural Radiance Fields. (arXiv:2103.14024v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1">Alex Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruilong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tancik_M/0/1/0/all/0/1">Matthew Tancik</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_R/0/1/0/all/0/1">Ren Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanazawa_A/0/1/0/all/0/1">Angjoo Kanazawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14024">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method to render Neural Radiance Fields (NeRFs) in real time
using PlenOctrees, an octree-based 3D representation which supports
view-dependent effects. Our method can render 800x800 images at more than 150
FPS, which is over 3000 times faster than conventional NeRFs. We do so without
sacrificing quality while preserving the ability of NeRFs to perform
free-viewpoint rendering of scenes with arbitrary geometry and view-dependent
effects. Real-time performance is achieved by pre-tabulating the NeRF into a
PlenOctree. In order to preserve view-dependent effects such as specularities,
we factorize the appearance via closed-form spherical basis functions.
Specifically, we show that it is possible to train NeRFs to predict a spherical
harmonic representation of radiance, removing the viewing direction as an input
to the neural network. Furthermore, we show that PlenOctrees can be directly
optimized to further minimize the reconstruction loss, which leads to equal or
better quality compared to competing methods. Moreover, this octree
optimization step can be used to reduce the training time, as we no longer need
to wait for the NeRF training to converge fully. Our real-time neural rendering
approach may potentially enable new applications such as 6-DOF industrial and
product visualizations, as well as next generation AR/VR systems. PlenOctrees
are amenable to in-browser rendering as well; please visit the project page for
the interactive online demo, as well as video and code:
https://alexyu.net/plenoctrees</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Transformer Network. (arXiv:2102.00719v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neimark_D/0/1/0/all/0/1">Daniel Neimark</a>, <a href="http://arxiv.org/find/cs/1/au:+Bar_O/0/1/0/all/0/1">Omri Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zohar_M/0/1/0/all/0/1">Maya Zohar</a>, <a href="http://arxiv.org/find/cs/1/au:+Asselmann_D/0/1/0/all/0/1">Dotan Asselmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00719">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents VTN, a transformer-based framework for video recognition.
Inspired by recent developments in vision transformers, we ditch the standard
approach in video action recognition that relies on 3D ConvNets and introduce a
method that classifies actions by attending to the entire video sequence
information. Our approach is generic and builds on top of any given 2D spatial
network. In terms of wall runtime, it trains $16.1\times$ faster and runs
$5.1\times$ faster during inference while maintaining competitive accuracy
compared to other state-of-the-art methods. It enables whole video analysis,
via a single end-to-end pass, while requiring $1.5\times$ fewer GFLOPs. We
report competitive results on Kinetics-400 and present an ablation study of VTN
properties and the trade-off between accuracy and inference speed. We hope our
approach will serve as a new baseline and start a fresh line of research in the
video recognition domain. Code and models are available at:
https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KCNet: An Insect-Inspired Single-Hidden-Layer Neural Network with Randomized Binary Weights for Prediction and Classification Tasks. (arXiv:2108.07554v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jinyung Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlic_T/0/1/0/all/0/1">Theodore P. Pavlic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07554">
                                    <div class="article-summary-box-inner">
                                        <span>Fruit flies are established model systems for studying olfactory learning as
they will readily learn to associate odors with both electric shock or sugar
rewards. The mechanisms of the insect brain apparently responsible for odor
learning form a relatively shallow neuronal architecture. Olfactory inputs are
received by the antennal lobe (AL) of the brain, which produces an encoding of
each odor mixture across ~50 sub-units known as glomeruli. Each of these
glomeruli then project its component of this feature vector to several of ~2000
so-called Kenyon Cells (KCs) in a region of the brain known as the mushroom
body (MB). Fly responses to odors are generated by small downstream neuropils
that decode the higher-order representation from the MB. Research has shown
that there is no recognizable pattern in the glomeruli--KC connections (and
thus the particular higher-order representations); they are akin to
fingerprints~-- even isogenic flies have different projections. Leveraging
insights from this architecture, we propose KCNet, a single-hidden-layer neural
network that contains sparse, randomized, binary weights between the input
layer and the hidden layer and analytically learned weights between the hidden
layer and the output layer. Furthermore, we also propose a dynamic optimization
algorithm that enables the KCNet to increase performance beyond its structural
limits by searching a more efficient set of inputs. For odorant-perception
tasks that predict perceptual properties of an odorant, we show that KCNet
outperforms existing data-driven approaches, such as XGBoost. For
image-classification tasks, KCNet achieves reasonable performance on benchmark
datasets (MNIST, Fashion-MNIST, and EMNIST) without any data-augmentation
methods or convolutional layers and shows particularly fast running time. Thus,
neural networks inspired by the insect brain can be both economical and perform
well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Semantic Relationships for Unpaired Image Captioning. (arXiv:2106.10658v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fenglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1">Meng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10658">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, image captioning has aroused great interest in both academic and
industrial worlds. Most existing systems are built upon large-scale datasets
consisting of image-sentence pairs, which, however, are time-consuming to
construct. In addition, even for the most advanced image captioning systems, it
is still difficult to realize deep image understanding. In this work, we
achieve unpaired image captioning by bridging the vision and the language
domains with high-level semantic information. The motivation stems from the
fact that the semantic concepts with the same modality can be extracted from
both images and descriptions. To further improve the quality of captions
generated by the model, we propose the Semantic Relationship Explorer, which
explores the relationships between semantic concepts for better understanding
of the image. Extensive experiments on MSCOCO dataset show that we can generate
desirable captions without paired datasets. Furthermore, the proposed approach
boosts five strong baselines under the paired setting, where the most
significant improvement in CIDEr score reaches 8%, demonstrating that it is
effective and generalizes well to a wide range of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Variational Capsule Network for Open Set Recognition. (arXiv:2104.09159v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yunrui Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Camporese_G/0/1/0/all/0/1">Guglielmo Camporese</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenjing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1">Alessandro Sperduti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballan_L/0/1/0/all/0/1">Lamberto Ballan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09159">
                                    <div class="article-summary-box-inner">
                                        <span>In open set recognition, a classifier has to detect unknown classes that are
not known at training time. In order to recognize new categories, the
classifier has to project the input samples of known classes in very compact
and separated regions of the features space for discriminating samples of
unknown classes. Recently proposed Capsule Networks have shown to outperform
alternatives in many fields, particularly in image recognition, however they
have not been fully applied yet to open-set recognition. In capsule networks,
scalar neurons are replaced by capsule vectors or matrices, whose entries
represent different properties of objects. In our proposal, during training,
capsules features of the same known class are encouraged to match a pre-defined
gaussian, one for each class. To this end, we use the variational autoencoder
framework, with a set of gaussian priors as the approximation for the posterior
distribution. In this way, we are able to control the compactness of the
features of the same class around the center of the gaussians, thus controlling
the ability of the classifier in detecting samples from unknown classes. We
conducted several experiments and ablation of our model, obtaining state of the
art results on different datasets in the open set recognition and unknown
detection tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathdreamer: A World Model for Indoor Navigation. (arXiv:2105.08756v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1">Jing Yu Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1">Jason Baldridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_P/0/1/0/all/0/1">Peter Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08756">
                                    <div class="article-summary-box-inner">
                                        <span>People navigating in unfamiliar buildings take advantage of myriad visual,
spatial and semantic cues to efficiently achieve their navigation goals.
Towards equipping computational agents with similar capabilities, we introduce
Pathdreamer, a visual world model for agents navigating in novel indoor
environments. Given one or more previous visual observations, Pathdreamer
generates plausible high-resolution 360 visual observations (RGB, semantic
segmentation and depth) for viewpoints that have not been visited, in buildings
not seen during training. In regions of high uncertainty (e.g. predicting
around corners, imagining the contents of an unseen room), Pathdreamer can
predict diverse scenes, allowing an agent to sample multiple realistic outcomes
for a given trajectory. We demonstrate that Pathdreamer encodes useful and
accessible visual, spatial and semantic knowledge about human environments by
using it in the downstream task of Vision-and-Language Navigation (VLN).
Specifically, we show that planning ahead with Pathdreamer brings about half
the benefit of looking ahead at actual observations from unobserved parts of
the environment. We hope that Pathdreamer will help unlock model-based
approaches to challenging embodied navigation tasks such as navigating to
specified objects and VLN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MVCNet: Multiview Contrastive Network for Unsupervised Representation Learning for 3D CT Lesions. (arXiv:2108.07662v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_P/0/1/0/all/0/1">Penghua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_H/0/1/0/all/0/1">Huaiwei Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Gangming Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Chaowei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07662">
                                    <div class="article-summary-box-inner">
                                        <span>With the renaissance of deep learning, automatic diagnostic systems for
computed tomography (CT) have achieved many successful applications. However,
they are mostly attributed to careful expert annotations, which are often
scarce in practice. This drives our interest to the unsupervised representation
learning. Recent studies have shown that self-supervised learning is an
effective approach for learning representations, but most of them rely on the
empirical design of transformations and pretext tasks. To avoid the
subjectivity associated with these methods, we propose the MVCNet, a novel
unsupervised three dimensional (3D) representation learning method working in a
transformation-free manner. We view each 3D lesion from different orientations
to collect multiple two dimensional (2D) views. Then, an embedding function is
learned by minimizing a contrastive loss so that the 2D views of the same 3D
lesion are aggregated, and the 2D views of different lesions are separated. We
evaluate the representations by training a simple classification head upon the
embedding layer. Experimental results show that MVCNet achieves
state-of-the-art accuracies on the LIDC-IDRI (89.55%), LNDb (77.69%) and
TianChi (79.96%) datasets for unsupervised representation learning. When
fine-tuned on 10% of the labeled data, the accuracies are comparable to the
supervised learning model (89.46% vs. 85.03%, 73.85% vs. 73.44%, 83.56% vs.
83.34% on the three datasets, respectively), indicating the superiority of
MVCNet in learning representations with limited annotations. Code is released
at: https://github.com/penghuazhai/MVCNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Person Re-Identification with Attribute-guided Metric Distillation. (arXiv:2103.01451v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaodong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Ping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01451">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great progress of person re-identification (ReID) with the
adoption of Convolutional Neural Networks, current ReID models are opaque and
only outputs a scalar distance between two persons. There are few methods
providing users semantically understandable explanations for why two persons
are the same one or not. In this paper, we propose a post-hoc method, named
Attribute-guided Metric Distillation (AMD), to explain existing ReID models.
This is the first method to explore attributes to answer: 1) what and where the
attributes make two persons different, and 2) how much each attribute
contributes to the difference. In AMD, we design a pluggable interpreter
network for target models to generate quantitative contributions of attributes
and visualize accurate attention maps of the most discriminative attributes. To
achieve this goal, we propose a metric distillation loss by which the
interpreter learns to decompose the distance of two persons into components of
attributes with knowledge distilled from the target model. Moreover, we propose
an attribute prior loss to make the interpreter generate attribute-guided
attention maps and to eliminate biases caused by the imbalanced distribution of
attributes. This loss can guide the interpreter to focus on the exclusive and
discriminative attributes rather than the large-area but common attributes of
two persons. Comprehensive experiments show that the interpreter can generate
effective and intuitive explanations for varied models and generalize well
under cross-domain settings. As a by-product, the accuracy of target models can
be further improved with our interpreter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">G-DetKD: Towards General Distillation Framework for Object Detectors via Contrastive and Semantic-guided Feature Imitation. (arXiv:2108.07482v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1">Lewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pi_R/0/1/0/all/0/1">Renjie Pi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07482">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the knowledge distillation (KD) strategy for
object detection and propose an effective framework applicable to both
homogeneous and heterogeneous student-teacher pairs. The conventional feature
imitation paradigm introduces imitation masks to focus on informative
foreground areas while excluding the background noises. However, we find that
those methods fail to fully utilize the semantic information in all feature
pyramid levels, which leads to inefficiency for knowledge distillation between
FPN-based detectors. To this end, we propose a novel semantic-guided feature
imitation technique, which automatically performs soft matching between feature
pairs across all pyramid levels to provide the optimal guidance to the student.
To push the envelop even further, we introduce contrastive distillation to
effectively capture the information encoded in the relationship between
different feature regions. Finally, we propose a generalized detection KD
pipeline, which is capable of distilling both homogeneous and heterogeneous
detector pairs. Our method consistently outperforms the existing detection KD
techniques, and works when (1) components in the framework are used separately
and in conjunction; (2) for both homogeneous and heterogenous student-teacher
pairs and (3) on multiple detection benchmarks. With a powerful
X101-FasterRCNN-Instaboost detector as the teacher, R50-FasterRCNN reaches
44.0% AP, R50-RetinaNet reaches 43.3% AP and R50-FCOS reaches 43.1% AP on COCO
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition. (arXiv:2106.10598v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wenyuan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Baosheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10598">
                                    <div class="article-summary-box-inner">
                                        <span>A table arranging data in rows and columns is a very effective data
structure, which has been widely used in business and scientific research.
Considering large-scale tabular data in online and offline documents, automatic
table recognition has attracted increasing attention from the document analysis
community. Though human can easily understand the structure of tables, it
remains a challenge for machines to understand that, especially due to a
variety of different table layouts and styles. Existing methods usually model a
table as either the markup sequence or the adjacency matrix between different
table cells, failing to address the importance of the logical location of table
cells, e.g., a cell is located in the first row and the second column of the
table. In this paper, we reformulate the problem of table structure recognition
as the table graph reconstruction, and propose an end-to-end trainable table
graph reconstruction network (TGRNet) for table structure recognition.
Specifically, the proposed method has two main branches, a cell detection
branch and a cell logical location branch, to jointly predict the spatial
location and the logical location of different cells. Experimental results on
three popular table recognition datasets and a new dataset with table graph
annotations (TableGraph-350K) demonstrate the effectiveness of the proposed
TGRNet for table structure recognition. Code and annotations will be made
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dense Siamese U-Net trained with Edge Enhanced 3D IOU Loss for Image Co-segmentation. (arXiv:2108.07491v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiabi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huiyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1">Xiaopeng Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07491">
                                    <div class="article-summary-box-inner">
                                        <span>Image co-segmentation has attracted a lot of attentions in computer vision
community. In this paper, we propose a new approach to image co-segmentation
through introducing the dense connections into the decoder path of Siamese
U-net and presenting a new edge enhanced 3D IOU loss measured over distance
maps. Considering the rigorous mapping between the signed normalized distance
map (SNDM) and the binary segmentation mask, we estimate the SNDMs directly
from original images and use them to determine the segmentation results. We
apply the Siamese U-net for solving this problem and improve its effectiveness
by densely connecting each layer with subsequent layers in the decoder path.
Furthermore, a new learning loss is designed to measure the 3D intersection
over union (IOU) between the generated SNDMs and the labeled SNDMs. The
experimental results on commonly used datasets for image co-segmentation
demonstrate the effectiveness of our presented dense structure and edge
enhanced 3D IOU loss of SNDM. To our best knowledge, they lead to the
state-of-the-art performance on the Internet and iCoseg datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DR{\AE}M -- A discriminatively trained reconstruction embedding for surface anomaly detection. (arXiv:2108.07610v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zavrtanik_V/0/1/0/all/0/1">Vitjan Zavrtanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kristan_M/0/1/0/all/0/1">Matej Kristan</a>, <a href="http://arxiv.org/find/cs/1/au:+Skocaj_D/0/1/0/all/0/1">Danijel Sko&#x10d;aj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07610">
                                    <div class="article-summary-box-inner">
                                        <span>Visual surface anomaly detection aims to detect local image regions that
significantly deviate from normal appearance. Recent surface anomaly detection
methods rely on generative models to accurately reconstruct the normal areas
and to fail on anomalies. These methods are trained only on anomaly-free
images, and often require hand-crafted post-processing steps to localize the
anomalies, which prohibits optimizing the feature extraction for maximal
detection capability. In addition to reconstructive approach, we cast surface
anomaly detection primarily as a discriminative problem and propose a
discriminatively trained reconstruction anomaly embedding model (DRAEM). The
proposed method learns a joint representation of an anomalous image and its
anomaly-free reconstruction, while simultaneously learning a decision boundary
between normal and anomalous examples. The method enables direct anomaly
localization without the need for additional complicated post-processing of the
network output and can be trained using simple and general anomaly simulations.
On the challenging MVTec anomaly detection dataset, DRAEM outperforms the
current state-of-the-art unsupervised methods by a large margin and even
delivers detection performance close to the fully-supervised methods on the
widely used DAGM surface-defect detection dataset, while substantially
outperforming them in localization accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Field Image Super-Resolution with Transformers. (arXiv:2108.07597v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zhengyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jungang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shilin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07597">
                                    <div class="article-summary-box-inner">
                                        <span>Light field (LF) image super-resolution (SR) aims at reconstructing
high-resolution LF images from their low-resolution counterparts. Although
CNN-based methods have achieved remarkable performance in LF image SR, these
methods cannot fully model the non-local properties of the 4D LF data. In this
paper, we propose a simple but effective Transformer-based method for LF image
SR. In our method, an angular Transformer is designed to incorporate
complementary information among different views, and a spatial Transformer is
developed to capture both local and long-range dependencies within each
sub-aperture image. With the proposed angular and spatial Transformers, the
beneficial information in an LF can be fully exploited and the SR performance
is boosted. We validate the effectiveness of our angular and spatial
Transformers through extensive ablation studies, and compare our method to
recent state-of-the-art methods on five public LF datasets. Our method achieves
superior SR performance with a small model size and low computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Robustness under Long-Tailed Distribution. (arXiv:2104.02703v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingqiu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02703">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial robustness has attracted extensive studies recently by revealing
the vulnerability and intrinsic characteristics of deep networks. However,
existing works on adversarial robustness mainly focus on balanced datasets,
while real-world data usually exhibits a long-tailed distribution. To push
adversarial robustness towards more realistic scenarios, in this work we
investigate the adversarial vulnerability as well as defense under long-tailed
distributions. In particular, we first reveal the negative impacts induced by
imbalanced data on both recognition performance and adversarial robustness,
uncovering the intrinsic challenges of this problem. We then perform a
systematic study on existing long-tailed recognition methods in conjunction
with the adversarial training framework. Several valuable observations are
obtained: 1) natural accuracy is relatively easy to improve, 2) fake gain of
robust accuracy exists under unreliable evaluation, and 3) boundary error
limits the promotion of robustness. Inspired by these observations, we propose
a clean yet effective framework, RoBal, which consists of two dedicated
modules, a scale-invariant classifier and data re-balancing via both margin
engineering at training stage and boundary adjustment during inference.
Extensive experiments demonstrate the superiority of our approach over other
state-of-the-art defense methods. To our best knowledge, we are the first to
tackle adversarial robustness under long-tailed distributions, which we believe
would be a significant step towards real-world robustness. Our code is
available at: https://github.com/wutong16/Adversarial_Long-Tail .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SaccadeCam: Adaptive Visual Attention for Monocular Depth Sensing. (arXiv:2103.12981v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tilmon_B/0/1/0/all/0/1">Brevin Tilmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppal_S/0/1/0/all/0/1">Sanjeev J. Koppal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12981">
                                    <div class="article-summary-box-inner">
                                        <span>Most monocular depth sensing methods use conventionally captured images that
are created without considering scene content. In contrast, animal eyes have
fast mechanical motions, called saccades, that control how the scene is imaged
by the fovea, where resolution is highest. In this paper, we present the
SaccadeCam framework for adaptively distributing resolution onto regions of
interest in the scene. Our algorithm for adaptive resolution is a
self-supervised network and we demonstrate results for end-to-end learning for
monocular depth estimation. We also show preliminary results with a real
SaccadeCam hardware prototype.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Experimental Urban Case Study with Various Data Sources and a Model for Traffic Estimation. (arXiv:2108.07698v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Genser_A/0/1/0/all/0/1">Alexander Genser</a>, <a href="http://arxiv.org/find/cs/1/au:+Hautle_N/0/1/0/all/0/1">Noel Hautle</a>, <a href="http://arxiv.org/find/cs/1/au:+Makridis_M/0/1/0/all/0/1">Michail Makridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouvelas_A/0/1/0/all/0/1">Anastasios Kouvelas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07698">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate estimation of the traffic state over a network is essential since it
is the starting point for designing and implementing any traffic management
strategy. Hence, traffic operators and users of a transportation network can
make reliable decisions such as influence/change route or mode choice. However,
the problem of traffic state estimation from various sensors within an urban
environment is very complex for several different reasons, such as availability
of sensors, different noise levels, different output quantities, sensor
accuracy, heterogeneous data fusion, and many more. To provide a better
understanding of this problem, we organized an experimental campaign with video
measurement in an area within the urban network of Zurich, Switzerland. We
focus on capturing the traffic state in terms of traffic flow and travel times
by ensuring measurements from established thermal cameras by the city&#x27;s
authorities, processed video data, and the Google Distance Matrix. We assess
the different data sources, and we propose a simple yet efficient Multiple
Linear Regression (MLR) model to estimate travel times with fusion of various
data sources. Comparative results with ground-truth data (derived from video
measurements) show the efficiency and robustness of the proposed methodology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COTR: Correspondence Transformer for Matching Across Images. (arXiv:2103.14167v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Trulls_E/0/1/0/all/0/1">Eduard Trulls</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosang_J/0/1/0/all/0/1">Jan Hosang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_A/0/1/0/all/0/1">Andrea Tagliasacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_K/0/1/0/all/0/1">Kwang Moo Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14167">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for finding correspondences in images based on a
deep neural network that, given two images and a query point in one of them,
finds its correspondence in the other. By doing so, one has the option to query
only the points of interest and retrieve sparse correspondences, or to query
all points in an image and obtain dense mappings. Importantly, in order to
capture both local and global priors, and to let our model relate between image
regions using the most relevant among said priors, we realize our network using
a transformer. At inference time, we apply our correspondence network by
recursively zooming in around the estimates, yielding a multiscale pipeline
able to provide highly-accurate correspondences. Our method significantly
outperforms the state of the art on both sparse and dense correspondence
problems on multiple datasets and tasks, ranging from wide-baseline stereo to
optical flow, without any retraining for a specific dataset. We commit to
releasing data, code, and all the tools necessary to train from scratch and
ensure reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Indoor Semantic Scene Understanding using Multi-modality Fusion. (arXiv:2108.07616v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gopinathan_M/0/1/0/all/0/1">Muraleekrishna Gopinathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_G/0/1/0/all/0/1">Giang Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Abu_Khalaf_J/0/1/0/all/0/1">Jumana Abu-Khalaf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07616">
                                    <div class="article-summary-box-inner">
                                        <span>Seamless Human-Robot Interaction is the ultimate goal of developing service
robotic systems. For this, the robotic agents have to understand their
surroundings to better complete a given task. Semantic scene understanding
allows a robotic agent to extract semantic knowledge about the objects in the
environment. In this work, we present a semantic scene understanding pipeline
that fuses 2D and 3D detection branches to generate a semantic map of the
environment. The 2D mask proposals from state-of-the-art 2D detectors are
inverse-projected to the 3D space and combined with 3D detections from point
segmentation networks. Unlike previous works that were evaluated on collected
datasets, we test our pipeline on an active photo-realistic robotic environment
- BenchBot. Our novelty includes rectification of 3D proposals using projected
2D detections and modality fusion based on object size. This work is done as
part of the Robotic Vision Scene Understanding Challenge (RVSU). The
performance evaluation demonstrates that our pipeline has improved on baseline
methods without significant computational bottleneck.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct domain adaptation through reciprocal linear transformations. (arXiv:2108.07600v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alkhalifah_T/0/1/0/all/0/1">Tariq Alkhalifah</a>, <a href="http://arxiv.org/find/cs/1/au:+Ovcharenko_O/0/1/0/all/0/1">Oleg Ovcharenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07600">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a direct domain adaptation (DDA) approach to enrich the training
of supervised neural networks on synthetic data by features from real-world
data. The process involves a series of linear operations on the input features
to the NN model, whether they are from the source or target domains, as
follows: 1) A cross-correlation of the input data (i.e. images) with a randomly
picked sample pixel (or pixels) of all images from that domain or the mean of
all randomly picked sample pixel (or pixels) of all images. 2) The convolution
of the resulting data with the mean of the autocorrelated input images from the
other domain. In the training stage, as expected, the input images are from the
source domain, and the mean of auto-correlated images are evaluated from the
target domain. In the inference/application stage, the input images are from
the target domain, and the mean of auto-correlated images are evaluated from
the source domain. The proposed method only manipulates the data from the
source and target domains and does not explicitly interfere with the training
workflow and network architecture. An application that includes training a
convolutional neural network on the MNIST dataset and testing the network on
the MNIST-M dataset achieves a 70% accuracy on the test data. A principal
component analysis (PCA), as well as t-SNE, show that the input features from
the source and target domains, after the proposed direct transformations, share
similar properties along with the principal components as compared to the
original MNIST and MNIST-M input features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CaT: Weakly Supervised Object Detection with Category Transfer. (arXiv:2108.07487v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tianyue Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lianyu Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Siheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan-Feng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07487">
                                    <div class="article-summary-box-inner">
                                        <span>A large gap exists between fully-supervised object detection and
weakly-supervised object detection. To narrow this gap, some methods consider
knowledge transfer from additional fully-supervised dataset. But these methods
do not fully exploit discriminative category information in the
fully-supervised dataset, thus causing low mAP. To solve this issue, we propose
a novel category transfer framework for weakly supervised object detection. The
intuition is to fully leverage both visually-discriminative and
semantically-correlated category information in the fully-supervised dataset to
enhance the object-classification ability of a weakly-supervised detector. To
handle overlapping category transfer, we propose a double-supervision mean
teacher to gather common category information and bridge the domain gap between
two datasets. To handle non-overlapping category transfer, we propose a
semantic graph convolutional network to promote the aggregation of semantic
features between correlated categories. Experiments are conducted with Pascal
VOC 2007 as the target weakly-supervised dataset and COCO as the source
fully-supervised dataset. Our category transfer framework achieves 63.5% mAP
and 80.3% CorLoc with 5 overlapping categories between two datasets, which
outperforms the state-of-the-art methods. Codes are avaliable at
https://github.com/MediaBrain-SJTU/CaT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating transformers in the decomposition of polygonal shapes as point collections. (arXiv:2108.07533v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alfieri_A/0/1/0/all/0/1">Andrea Alfieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yancong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07533">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers can generate predictions in two approaches: 1. auto-regressively
by conditioning each sequence element on the previous ones, or 2. directly
produce an output sequences in parallel. While research has mostly explored
upon this difference on sequential tasks in NLP, we study the difference
between auto-regressive and parallel prediction on visual set prediction tasks,
and in particular on polygonal shapes in images because polygons are
representative of numerous types of objects, such as buildings or obstacles for
aerial vehicles. This is challenging for deep learning architectures as a
polygon can consist of a varying carnality of points. We provide evidence on
the importance of natural orders for Transformers, and show the benefit of
decomposing complex polygons into collections of points in an auto-regressive
manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep MRI Reconstruction with Radial Subsampling. (arXiv:2108.07619v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yiasemis_G/0/1/0/all/0/1">George Yiasemis</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1">Chaoping Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sanchez_C/0/1/0/all/0/1">Clara I. S&#xe1;nchez</a>, <a href="http://arxiv.org/find/eess/1/au:+Sonke_J/0/1/0/all/0/1">Jan-Jakob Sonke</a>, <a href="http://arxiv.org/find/eess/1/au:+Teuwen_J/0/1/0/all/0/1">Jonas Teuwen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07619">
                                    <div class="article-summary-box-inner">
                                        <span>In spite of its extensive adaptation in almost every medical diagnostic and
examinatorial application, Magnetic Resonance Imaging (MRI) is still a slow
imaging modality which limits its use for dynamic imaging. In recent years,
Parallel Imaging (PI) and Compressed Sensing (CS) have been utilised to
accelerate the MRI acquisition. In clinical settings, subsampling the k-space
measurements during scanning time using Cartesian trajectories, such as
rectilinear sampling, is currently the most conventional CS approach applied
which, however, is prone to producing aliased reconstructions. With the advent
of the involvement of Deep Learning (DL) in accelerating the MRI,
reconstructing faithful images from subsampled data became increasingly
promising. Retrospectively applying a subsampling mask onto the k-space data is
a way of simulating the accelerated acquisition of k-space data in real
clinical setting. In this paper we compare and provide a review for the effect
of applying either rectilinear or radial retrospective subsampling on the
quality of the reconstructions outputted by trained deep neural networks. With
the same choice of hyper-parameters, we train and evaluate two distinct
Recurrent Inference Machines (RIMs), one for each type of subsampling. The
qualitative and quantitative results of our experiments indicate that the model
trained on data with radial subsampling attains higher performance and learns
to estimate reconstructions with higher fidelity paving the way for other DL
approaches to involve radial subsampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Flexible Three-Dimensional Hetero-phase Computed Tomography Hepatocellular Carcinoma (HCC) Detection Algorithm for Generalizable and Practical HCC Screening. (arXiv:2108.07492v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Chi-Tung Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jinzheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_W/0/1/0/all/0/1">Wei Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Youjing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">YuTing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Chao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chien-Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Youbao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wei-Chen Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_T/0/1/0/all/0/1">Ta-Sen Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jing Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Le Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Chien-Hung Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_A/0/1/0/all/0/1">Adam P. Harrison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07492">
                                    <div class="article-summary-box-inner">
                                        <span>Hepatocellular carcinoma (HCC) can be potentially discovered from abdominal
computed tomography (CT) studies under varied clinical scenarios, e.g., fully
dynamic contrast enhanced (DCE) studies, non-contrast (NC) plus venous phase
(VP) abdominal studies, or NC-only studies. We develop a flexible
three-dimensional deep algorithm, called hetero-phase volumetric detection
(HPVD), that can accept any combination of contrast-phase inputs and with
adjustable sensitivity depending on the clinical purpose. We trained HPVD on
771 DCE CT scans to detect HCCs and tested on external 164 positives and 206
controls, respectively. We compare performance against six clinical readers,
including two radiologists, two hepato-pancreatico-biliary (HPB) surgeons, and
two hepatologists. The area under curve (AUC) of the localization receiver
operating characteristic (LROC) for NC-only, NC plus VP, and full DCE CT
yielded 0.71, 0.81, 0.89 respectively. At a high sensitivity operating point of
80% on DCE CT, HPVD achieved 97% specificity, which is comparable to measured
physician performance. We also demonstrate performance improvements over more
typical and less flexible non hetero-phase detectors. Thus, we demonstrate that
a single deep learning algorithm can be effectively applied to diverse HCC
detection clinical scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Colorization Using Mono-Color Image Pairs. (arXiv:2108.07471v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1">Ze-Hua Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Hui-Liang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1">Bo-Wen Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huaqi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07471">
                                    <div class="article-summary-box-inner">
                                        <span>Compared to color images captured by conventional RGB cameras, monochrome
images usually have better signal-to-noise ratio (SNR) and richer textures due
to its higher quantum efficiency. It is thus natural to apply a mono-color
dual-camera system to restore color images with higher visual quality. In this
paper, we propose a mono-color image enhancement algorithm that colorizes the
monochrome image with the color one. Based on the assumption that adjacent
structures with similar luminance values are likely to have similar colors, we
first perform dense scribbling to assign colors to the monochrome pixels
through block matching. Two types of outliers, including occlusion and color
ambiguity, are detected and removed from the initial scribbles. We also
introduce a sampling strategy to accelerate the scribbling process. Then, the
dense scribbles are propagated to the entire image. To alleviate incorrect
color propagation in the regions that have no color hints at all, we generate
extra color seeds based on the existed scribbles to guide the propagation
process. Experimental results show that, our algorithm can efficiently restore
color images with higher SNR and richer details from the mono-color image
pairs, and achieves good performance in solving the color bleeding problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance Segmentation in 3D Scenes using Semantic Superpoint Tree Networks. (arXiv:2108.07478v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zhihao Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhihao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songcen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07478">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation in 3D scenes is fundamental in many applications of
scene understanding. It is yet challenging due to the compound factors of data
irregularity and uncertainty in the numbers of instances. State-of-the-art
methods largely rely on a general pipeline that first learns point-wise
features discriminative at semantic and instance levels, followed by a separate
step of point grouping for proposing object instances. While promising, they
have the shortcomings that (1) the second step is not supervised by the main
objective of instance segmentation, and (2) their point-wise feature learning
and grouping are less effective to deal with data irregularities, possibly
resulting in fragmented segmentations. To address these issues, we propose in
this work an end-to-end solution of Semantic Superpoint Tree Network (SSTNet)
for proposing object instances from scene points. Key in SSTNet is an
intermediate, semantic superpoint tree (SST), which is constructed based on the
learned semantic features of superpoints, and which will be traversed and split
at intermediate tree nodes for proposals of object instances. We also design in
SSTNet a refinement module, termed CliqueNet, to prune superpoints that may be
wrongly grouped into instance proposals. Experiments on the benchmarks of
ScanNet and S3DIS show the efficacy of our proposed method. At the time of
submission, SSTNet ranks top on the ScanNet (V2) leaderboard, with 2% higher of
mAP than the second best method. The source code in PyTorch is available at
https://github.com/Gorilla-Lab-SCUT/SSTNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MV-TON: Memory-based Video Virtual Try-on network. (arXiv:2108.07502v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1">Xiaojing Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Taizhe Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyao Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07502">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of Generative Adversarial Network, image-based virtual
try-on methods have made great progress. However, limited work has explored the
task of video-based virtual try-on while it is important in real-world
applications. Most existing video-based virtual try-on methods usually require
clothing templates and they can only generate blurred and low-resolution
results. To address these challenges, we propose a Memory-based Video virtual
Try-On Network (MV-TON), which seamlessly transfers desired clothes to a target
person without using any clothing templates and generates high-resolution
realistic videos. Specifically, MV-TON consists of two modules: 1) a try-on
module that transfers the desired clothes from model images to frame images by
pose alignment and region-wise replacing of pixels; 2) a memory refinement
module that learns to embed the existing generated frames into the latent space
as external memory for the following frame generation. Experimental results
show the effectiveness of our method in the video virtual try-on task and its
superiority over other existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Pretraining and Controlled Augmentation Improve Rare Wildlife Recognition in UAV Images. (arXiv:2108.07582v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiaochen Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kellenberger_B/0/1/0/all/0/1">Benjamin Kellenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Rui Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajnsek_I/0/1/0/all/0/1">Irena Hajnsek</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1">Devis Tuia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07582">
                                    <div class="article-summary-box-inner">
                                        <span>Automated animal censuses with aerial imagery are a vital ingredient towards
wildlife conservation. Recent models are generally based on deep learning and
thus require vast amounts of training data. Due to their scarcity and minuscule
size, annotating animals in aerial imagery is a highly tedious process. In this
project, we present a methodology to reduce the amount of required training
data by resorting to self-supervised pretraining. In detail, we examine a
combination of recent contrastive learning methodologies like Momentum Contrast
(MoCo) and Cross-Level Instance-Group Discrimination (CLD) to condition our
model on the aerial images without the requirement for labels. We show that a
combination of MoCo, CLD, and geometric augmentations outperforms conventional
models pre-trained on ImageNet by a large margin. Crucially, our method still
yields favorable results even if we reduce the number of training animals to
just 10%, at which point our best model scores double the recall of the
baseline at similar precision. This effectively allows reducing the number of
required annotations to a fraction while still being able to train
high-accuracy models in such highly challenging settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PR-RRN: Pairwise-Regularized Residual-Recursive Networks for Non-rigid Structure-from-Motion. (arXiv:2108.07506v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Haitian Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yuchao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07506">
                                    <div class="article-summary-box-inner">
                                        <span>We propose PR-RRN, a novel neural-network based method for Non-rigid
Structure-from-Motion (NRSfM). PR-RRN consists of Residual-Recursive Networks
(RRN) and two extra regularization losses. RRN is designed to effectively
recover 3D shape and camera from 2D keypoints with novel residual-recursive
structure. As NRSfM is a highly under-constrained problem, we propose two new
pairwise regularization to further regularize the reconstruction. The
Rigidity-based Pairwise Contrastive Loss regularizes the shape representation
by encouraging higher similarity between the representations of high-rigidity
pairs of frames than low-rigidity pairs. We propose minimum singular-value
ratio to measure the pairwise rigidity. The Pairwise Consistency Loss enforces
the reconstruction to be consistent when the estimated shapes and cameras are
exchanged between pairs. Our approach achieves state-of-the-art performance on
CMU MOCAP and PASCAL3D+ dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Geodesic-preserved Generative Adversarial Networks for Unconstrained 3D Pose Transfer. (arXiv:2108.07520v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Henglin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guoying Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07520">
                                    <div class="article-summary-box-inner">
                                        <span>With the strength of deep generative models, 3D pose transfer regains
intensive research interests in recent years. Existing methods mainly rely on a
variety of constraints to achieve the pose transfer over 3D meshes, e.g., the
need for the manually encoding for shape and pose disentanglement. In this
paper, we present an unsupervised approach to conduct the pose transfer between
any arbitrate given 3D meshes. Specifically, a novel Intrinsic-Extrinsic
Preserved Generative Adversarial Network (IEP-GAN) is presented for both
intrinsic (i.e., shape) and extrinsic (i.e., pose) information preservation.
Extrinsically, we propose a co-occurrence discriminator to capture the
structural/pose invariance from distinct Laplacians of the mesh. Meanwhile,
intrinsically, a local intrinsic-preserved loss is introduced to preserve the
geodesic priors while avoiding the heavy computations. At last, we show the
possibility of using IEP-GAN to manipulate 3D human meshes in various ways,
including pose transfer, identity swapping and pose interpolation with latent
code vector arithmetic. The extensive experiments on various 3D datasets of
humans, animals and hands qualitatively and quantitatively demonstrate the
generality of our approach. Our proposed model produces better results and is
substantially more efficient compared to recent state-of-the-art methods. Code
is available: https://github.com/mikecheninoulu/Unsupervised_IEPGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Photofit: Gaze-based Mental Image Reconstruction. (arXiv:2108.07524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strohm_F/0/1/0/all/0/1">Florian Strohm</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_E/0/1/0/all/0/1">Ekta Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayer_S/0/1/0/all/0/1">Sven Mayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_P/0/1/0/all/0/1">Philipp M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Bace_M/0/1/0/all/0/1">Mihai B&#xe2;ce</a>, <a href="http://arxiv.org/find/cs/1/au:+Bulling_A/0/1/0/all/0/1">Andreas Bulling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07524">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method that leverages human fixations to visually decode
the image a person has in mind into a photofit (facial composite). Our method
combines three neural networks: An encoder, a scoring network, and a decoder.
The encoder extracts image features and predicts a neural activation map for
each face looked at by a human observer. A neural scoring network compares the
human and neural attention and predicts a relevance score for each extracted
image feature. Finally, image features are aggregated into a single feature
vector as a linear combination of all features weighted by relevance which a
decoder decodes into the final photofit. We train the neural scoring network on
a novel dataset containing gaze data of 19 participants looking at collages of
synthetic faces. We show that our method significantly outperforms a mean
baseline predictor and report on a human study that shows that we can decode
photofits that are visually plausible and close to the observer&#x27;s mental image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LIF-Seg: LiDAR and Camera Image Fusion for 3D LiDAR Semantic Segmentation. (arXiv:2108.07511v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Lin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinge Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xiao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_W/0/1/0/all/0/1">Wenbing Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07511">
                                    <div class="article-summary-box-inner">
                                        <span>Camera and 3D LiDAR sensors have become indispensable devices in modern
autonomous driving vehicles, where the camera provides the fine-grained
texture, color information in 2D space and LiDAR captures more precise and
farther-away distance measurements of the surrounding environments. The
complementary information from these two sensors makes the two-modality fusion
be a desired option. However, two major issues of the fusion between camera and
LiDAR hinder its performance, \ie, how to effectively fuse these two modalities
and how to precisely align them (suffering from the weak spatiotemporal
synchronization problem). In this paper, we propose a coarse-to-fine LiDAR and
camera fusion-based network (termed as LIF-Seg) for LiDAR segmentation. For the
first issue, unlike these previous works fusing the point cloud and image
information in a one-to-one manner, the proposed method fully utilizes the
contextual information of images and introduces a simple but effective
early-fusion strategy. Second, due to the weak spatiotemporal synchronization
problem, an offset rectification approach is designed to align these
two-modality features. The cooperation of these two components leads to the
success of the effective camera-LiDAR fusion. Experimental results on the
nuScenes dataset show the superiority of the proposed LIF-Seg over existing
methods with a large margin. Ablation studies and analyses demonstrate that our
proposed LIF-Seg can effectively tackle the weak spatiotemporal synchronization
problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferring Knowledge with Attention Distillation for Multi-Domain Image-to-Image Translation. (arXiv:2108.07466v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Runze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fontanini_T/0/1/0/all/0/1">Tomaso Fontanini</a>, <a href="http://arxiv.org/find/cs/1/au:+Donati_L/0/1/0/all/0/1">Luca Donati</a>, <a href="http://arxiv.org/find/cs/1/au:+Prati_A/0/1/0/all/0/1">Andrea Prati</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhanu_B/0/1/0/all/0/1">Bir Bhanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07466">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient-based attention modeling has been used widely as a way to visualize
and understand convolutional neural networks. However, exploiting these visual
explanations during the training of generative adversarial networks (GANs) is
an unexplored area in computer vision research. Indeed, we argue that this kind
of information can be used to influence GANs training in a positive way. For
this reason, in this paper, it is shown how gradient based attentions can be
used as knowledge to be conveyed in a teacher-student paradigm for multi-domain
image-to-image translation tasks in order to improve the results of the student
architecture. Further, it is demonstrated how &quot;pseudo&quot;-attentions can also be
employed during training when teacher and student networks are trained on
different domains which share some similarities. The approach is validated on
multi-domain facial attributes transfer and human expression synthesis showing
both qualitative and quantitative results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Image Region Mining with Region Prototypical Network for Weakly Supervised Segmentation. (arXiv:2108.07413v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weide Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xiangfei Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_T/0/1/0/all/0/1">Tzu-Yi Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07413">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised image segmentation trained with image-level labels usually
suffers from inaccurate coverage of object areas during the generation of the
pseudo groundtruth. This is because the object activation maps are trained with
the classification objective and lack the ability to generalize. To improve the
generality of the objective activation maps, we propose a region prototypical
network RPNet to explore the cross-image object diversity of the training set.
Similar object parts across images are identified via region feature
comparison. Object confidence is propagated between regions to discover new
object areas while background regions are suppressed. Experiments show that the
proposed method generates more complete and accurate pseudo object masks, while
achieving state-of-the-art performance on PASCAL VOC 2012 and MS COCO. In
addition, we investigate the robustness of the proposed method on reduced
training sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffeomorphic Particle Image Velocimetry. (arXiv:2108.07438v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1">Shuang Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07438">
                                    <div class="article-summary-box-inner">
                                        <span>The existing particle image velocimetry (PIV) do not consider the curvature
effect of the non-straight particle trajectory, because it seems to be
impossible to obtain the curvature information from a pair of particle images.
As a result, the computed vector underestimates the real velocity due to the
straight-line approximation, that further causes a systematic error for the PIV
instrument. In this work, the particle curved trajectory between two recordings
is firstly explained with the streamline segment of a steady flow
(diffeomorphic transformation) instead of a single vector, and this idea is
termed as diffeomorphic PIV. Specifically, a deformation field is introduced to
describe the particle displacement, i.e., we try to find the optimal velocity
field, of which the corresponding deformation vector field agrees with the
particle displacement. Because the variation of the deformation function can be
approximated with the variation of the velocity function, the diffeomorphic PIV
can be implemented as iterative PIV. That says, the diffeomorphic PIV warps the
images with deformation vector field instead of the velocity, and keeps the
rest as same as iterative PIVs. Two diffeomorphic deformation schemes --
forward diffeomorphic deformation interrogation (FDDI) and central
diffeomorphic deformation interrogation (CDDI) -- are proposed. Tested on
synthetic images, the FDDI achieves significant accuracy improvement across
different one-pass displacement estimators (cross-correlation, optical flow,
deep learning flow). Besides, the results on three real PIV image pairs
demonstrate the non-negligible curvature effect for CDI-based PIV, and our FDDI
provides larger velocity estimation (more accurate) in the fast curvy
streamline areas. The accuracy improvement of the combination of FDDI and
accurate dense estimator means that our diffeomorphic PIV paves a new way for
complex flow measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning by Aligning: Visible-Infrared Person Re-identification using Cross-Modal Correspondences. (arXiv:2108.07422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyunjong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sanghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junghyup Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ham_B/0/1/0/all/0/1">Bumsub Ham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07422">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of visible-infrared person re-identification
(VI-reID), that is, retrieving a set of person images, captured by visible or
infrared cameras, in a cross-modal setting. Two main challenges in VI-reID are
intra-class variations across person images, and cross-modal discrepancies
between visible and infrared images. Assuming that the person images are
roughly aligned, previous approaches attempt to learn coarse image- or rigid
part-level person representations that are discriminative and generalizable
across different modalities. However, the person images, typically cropped by
off-the-shelf object detectors, are not necessarily well-aligned, which
distract discriminative person representation learning. In this paper, we
introduce a novel feature learning framework that addresses these problems in a
unified way. To this end, we propose to exploit dense correspondences between
cross-modal person images. This allows to address the cross-modal discrepancies
in a pixel-level, suppressing modality-related features from person
representations more effectively. This also encourages pixel-wise associations
between cross-modal local features, further facilitating discriminative feature
learning for VI-reID. Extensive experiments and analyses on standard VI-reID
benchmarks demonstrate the effectiveness of our approach, which significantly
outperforms the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating a Baseline Of Self Supervised Learning Towards Reducing Labeling Costs For Image Classification. (arXiv:2108.07464v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+AlQuabeh_H/0/1/0/all/0/1">Hilal AlQuabeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bawazeer_A/0/1/0/all/0/1">Ameera Bawazeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Alhashmi_A/0/1/0/all/0/1">Abdulateef Alhashmi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07464">
                                    <div class="article-summary-box-inner">
                                        <span>Data labeling in supervised learning is considered an expensive and
infeasible tool in some conditions. The self-supervised learning method is
proposed to tackle the learning effectiveness with fewer labeled data, however,
there is a lack of confidence in the size of labeled data needed to achieve
adequate results. This study aims to draw a baseline on the proportion of the
labeled data that models can appreciate to yield competent accuracy when
compared to training with additional labels. The study implements the
kaggle.com&#x27; cats-vs-dogs dataset, Mnist and Fashion-Mnist to investigate the
self-supervised learning task by implementing random rotations augmentation on
the original datasets. To reveal the true effectiveness of the pretext process
in self-supervised learning, the original dataset is divided into smaller
batches, and learning is repeated on each batch with and without the pretext
pre-training. Results show that the pretext process in the self-supervised
learning improves the accuracy around 15% in the downstream classification task
when compared to the plain supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization. (arXiv:2108.02183v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huabin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1">John See</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shuangrui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Weiyao Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02183">
                                    <div class="article-summary-box-inner">
                                        <span>The crux of self-supervised video representation learning is to build general
features from unlabeled videos. However, most recent works have mainly focused
on high-level semantics and neglected lower-level representations and their
temporal relationship which are crucial for general video understanding. To
address these challenges, this paper proposes a multi-level feature
optimization framework to improve the generalization and temporal modeling
ability of learned video representations. Concretely, high-level features
obtained from naive and prototypical contrastive learning are utilized to build
distribution graphs, guiding the process of low-level and mid-level feature
learning. We also devise a simple temporal modeling module from multi-level
features to enhance motion pattern learning. Experiments demonstrate that
multi-level feature optimization with the graph constraint and temporal
modeling can greatly improve the representation ability in video understanding.
Code is available at
https://github.com/shvdiwnkozbw/Video-Representation-via-Multi-level-Optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation. (arXiv:2103.10158v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1">Samuel G. M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10158">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic augmentation methods have recently become a crucial pillar for
strong model performance in vision tasks. While existing automatic augmentation
methods need to trade off simplicity, cost and performance, we present a most
simple baseline, TrivialAugment, that outperforms previous methods for almost
free. TrivialAugment is parameter-free and only applies a single augmentation
to each image. Thus, TrivialAugment&#x27;s effectiveness is very unexpected to us
and we performed very thorough experiments to study its performance. First, we
compare TrivialAugment to previous state-of-the-art methods in a variety of
image classification scenarios. Then, we perform multiple ablation studies with
different augmentation spaces, augmentation methods and setups to understand
the crucial requirements for its performance. Additionally, we provide a simple
interface to facilitate the widespread adoption of automatic augmentation
methods, as well as our full code base for reproducibility. Since our work
reveals a stagnation in many parts of automatic augmentation research, we end
with a short proposal of best practices for sustained future progress in
automatic augmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generation and Simulation of Yeast Microscopy Imagery with Deep Learning. (arXiv:2103.11834v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Reich_C/0/1/0/all/0/1">Christoph Reich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11834">
                                    <div class="article-summary-box-inner">
                                        <span>Time-lapse fluorescence microscopy (TLFM) is an important and powerful tool
in synthetic biological research. Modeling TLFM experiments based on real data
may enable researchers to repeat certain experiments with minor effort. This
thesis is a study towards deep learning-based modeling of TLFM experiments on
the image level. The modeling of TLFM experiments, by way of the example of
trapped yeast cells, is split into two tasks. The first task is to generate
synthetic image data based on real image data. To approach this problem, a
novel generative adversarial network, for conditionalized and unconditionalized
image generation, is proposed. The second task is the simulation of brightfield
microscopy images over multiple discrete time-steps. To tackle this simulation
task an advanced future frame prediction model is introduced. The proposed
models are trained and tested on a novel dataset that is presented in this
thesis. The obtained results showed that the modeling of TLFM experiments, with
deep learning, is a proper approach, but requires future research to
effectively model real-world experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FMODetect: Robust Detection of Fast Moving Objects. (arXiv:2012.08216v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1">Denys Rozumnyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Matas_J/0/1/0/all/0/1">Jiri Matas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sroubek_F/0/1/0/all/0/1">Filip Sroubek</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>, <a href="http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1">Martin R. Oswald</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08216">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the first learning-based approach for fast moving objects
detection. Such objects are highly blurred and move over large distances within
one video frame. Fast moving objects are associated with a deblurring and
matting problem, also called deblatting. We show that the separation of
deblatting into consecutive matting and deblurring allows achieving real-time
performance, i.e. an order of magnitude speed-up, and thus enabling new classes
of application. The proposed method detects fast moving objects as a truncated
distance function to the trajectory by learning from synthetic data. For the
sharp appearance estimation and accurate trajectory estimation, we propose a
matting and fitting network that estimates the blurred appearance without
background, followed by an energy minimization based deblurring. The
state-of-the-art methods are outperformed in terms of recall, precision,
trajectory estimation, and sharp appearance reconstruction. Compared to other
methods, such as deblatting, the inference is of several orders of magnitude
faster and allows applications such as real-time fast moving object detection
and retrieval in large video collections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching. (arXiv:2012.08950v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runzhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zetian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08950">
                                    <div class="article-summary-box-inner">
                                        <span>Graph matching (GM) has been a building block in many areas including
computer vision and pattern recognition. Despite the recent impressive
progress, existing deep GM methods often have difficulty in handling outliers
in both graphs, which are ubiquitous in practice. We propose a deep
reinforcement learning (RL) based approach RGM for weighted graph matching,
whose sequential node matching scheme naturally fits with the strategy for
selective inlier matching against outliers, and supports seed graph matching. A
revocable action scheme is devised to improve the agent&#x27;s flexibility against
the complex constrained matching task. Moreover, we propose a quadratic
approximation technique to regularize the affinity matrix, in the presence of
outliers. As such, the RL agent can finish inlier matching timely when the
objective score stop growing, for which otherwise an additional hyperparameter
i.e. the number of common inliers is needed to avoid matching outliers. In this
paper, we are focused on learning the back-end solver for the most general form
of GM: the Lawler&#x27;s QAP, whose input is the affinity matrix. Our approach can
also boost other solvers using the affinity input. Experimental results on both
synthetic and real-world datasets showcase its superior performance regarding
both matching accuracy and robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TUM-VIE: The TUM Stereo Visual-Inertial Event Dataset. (arXiv:2108.07329v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klenk_S/0/1/0/all/0/1">Simon Klenk</a>, <a href="http://arxiv.org/find/cs/1/au:+Chui_J/0/1/0/all/0/1">Jason Chui</a>, <a href="http://arxiv.org/find/cs/1/au:+Demmel_N/0/1/0/all/0/1">Nikolaus Demmel</a>, <a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1">Daniel Cremers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07329">
                                    <div class="article-summary-box-inner">
                                        <span>Event cameras are bio-inspired vision sensors which measure per pixel
brightness changes. They offer numerous benefits over traditional, frame-based
cameras, including low latency, high dynamic range, high temporal resolution
and low power consumption. Thus, these sensors are suited for robotics and
virtual reality applications. To foster the development of 3D perception and
navigation algorithms with event cameras, we present the TUM-VIE dataset. It
consists of a large variety of handheld and head-mounted sequences in indoor
and outdoor environments, including rapid motion during sports and high dynamic
range scenarios. The dataset contains stereo event data, stereo grayscale
frames at 20Hz as well as IMU data at 200Hz. Timestamps between all sensors are
synchronized in hardware. The event cameras contain a large sensor of 1280x720
pixels, which is significantly larger than the sensors used in existing stereo
event datasets (at least by a factor of ten). We provide ground truth poses
from a motion capture system at 120Hz during the beginning and end of each
sequence, which can be used for trajectory evaluation. TUM-VIE includes
challenging sequences where state-of-the art visual SLAM algorithms either fail
or result in large drift. Hence, our dataset can help to push the boundary of
future research on event-based visual-inertial perception algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects. (arXiv:2108.07368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lou_A/0/1/0/all/0/1">Ange Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Shuyue Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1">Murray Loew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07368">
                                    <div class="article-summary-box-inner">
                                        <span>Segmenting medical images accurately and reliably is important for disease
diagnosis and treatment. It is a challenging task because of the wide variety
of objects&#x27; sizes, shapes, and scanning modalities. Recently, many
convolutional neural networks (CNN) have been designed for segmentation tasks
and achieved great success. Few studies, however, have fully considered the
sizes of objects and thus most demonstrate poor performance on segmentation of
small objects segmentation. This can have significant impact on early detection
of disease. This paper proposes a Context Axial Reserve Attention Network
(CaraNet) to improve the segmentation performance on small objects compared
with recent state-of-the-art models. We test our CaraNet on brain tumor (BraTS
2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300 and
ETIS-LaribPolypDB) segmentation. Our CaraNet not only achieves the top-rank
mean Dice segmentation accuracy, but also shows a distinct advantage in
segmentation of small medical objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BN-NAS: Neural Architecture Search with Batch Normalization. (arXiv:2108.07375v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07375">
                                    <div class="article-summary-box-inner">
                                        <span>We present BN-NAS, neural architecture search with Batch Normalization
(BN-NAS), to accelerate neural architecture search (NAS). BN-NAS can
significantly reduce the time required by model training and evaluation in NAS.
Specifically, for fast evaluation, we propose a BN-based indicator for
predicting subnet performance at a very early training stage. The BN-based
indicator further facilitates us to improve the training efficiency by only
training the BN parameters during the supernet training. This is based on our
observation that training the whole supernet is not necessary while training
only BN parameters accelerates network convergence for network architecture
search. Extensive experiments show that our method can significantly shorten
the time of training supernet by more than 10 times and shorten the time of
evaluating subnets by more than 600,000 times without losing accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRB-GAN: A Dynamic ResBlock Generative Adversarial Network for Artistic Style Transfer. (arXiv:2108.07379v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenju Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Chengjiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruisheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07379">
                                    <div class="article-summary-box-inner">
                                        <span>The paper proposes a Dynamic ResBlock Generative Adversarial Network
(DRB-GAN) for artistic style transfer. The style code is modeled as the shared
parameters for Dynamic ResBlocks connecting both the style encoding network and
the style transfer network. In the style encoding network, a style class-aware
attention mechanism is used to attend the style feature representation for
generating the style codes. In the style transfer network, multiple Dynamic
ResBlocks are designed to integrate the style code and the extracted CNN
semantic feature and then feed into the spatial window Layer-Instance
Normalization (SW-LIN) decoder, which enables high-quality synthetic images
with artistic style transfer. Moreover, the style collection conditional
discriminator is designed to equip our DRB-GAN model with abilities for both
arbitrary style transfer and collection style transfer during the training
stage. No matter for arbitrary style transfer or collection style transfer,
extensive experiments strongly demonstrate that our proposed DRB-GAN
outperforms state-of-the-art methods and exhibits its superior performance in
terms of visual quality and efficiency. Our source code is available at
\color{magenta}{\url{https://github.com/xuwenju123/DRB-GAN}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextual Convolutional Neural Networks. (arXiv:2108.07387v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duta_I/0/1/0/all/0/1">Ionut Cosmin Duta</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgescu_M/0/1/0/all/0/1">Mariana Iuliana Georgescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07387">
                                    <div class="article-summary-box-inner">
                                        <span>We propose contextual convolution (CoConv) for visual recognition. CoConv is
a direct replacement of the standard convolution, which is the core component
of convolutional neural networks. CoConv is implicitly equipped with the
capability of incorporating contextual information while maintaining a similar
number of parameters and computational cost compared to the standard
convolution. CoConv is inspired by neuroscience studies indicating that (i)
neurons, even from the primary visual cortex (V1 area), are involved in
detection of contextual cues and that (ii) the activity of a visual neuron can
be influenced by the stimuli placed entirely outside of its theoretical
receptive field. On the one hand, we integrate CoConv in the widely-used
residual networks and show improved recognition performance over baselines on
the core tasks and benchmarks for visual recognition, namely image
classification on the ImageNet data set and object detection on the MS COCO
data set. On the other hand, we introduce CoConv in the generator of a
state-of-the-art Generative Adversarial Network, showing improved generative
results on CIFAR-10 and CelebA. Our code is available at
https://github.com/iduta/coconv.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering augmented Self-Supervised Learning: Anapplication to Land Cover Mapping. (arXiv:2108.07323v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1">Rahul Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaowei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chenxi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhenong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07323">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting large annotated datasets in Remote Sensing is often expensive and
thus can become a major obstacle for training advanced machine learning models.
Common techniques of addressing this issue, based on the underlying idea of
pre-training the Deep Neural Networks (DNN) on freely available large datasets,
cannot be used for Remote Sensing due to the unavailability of such large-scale
labeled datasets and the heterogeneity of data sources caused by the varying
spatial and spectral resolution of different sensors. Self-supervised learning
is an alternative approach that learns feature representation from unlabeled
images without using any human annotations. In this paper, we introduce a new
method for land cover mapping by using a clustering based pretext task for
self-supervised learning. We demonstrate the effectiveness of the method on two
societally relevant applications from the aspect of segmentation performance,
discriminative feature representation learning and the underlying cluster
structure. We also show the effectiveness of the active sampling using the
clusters obtained from our method in improving the mapping accuracy given a
limited budget of annotating.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scene Designer: a Unified Model for Scene Search and Synthesis from Sketch. (arXiv:2108.07353v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_L/0/1/0/all/0/1">Leo Sampaio Ferraz Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1">Moacir Ponti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07353">
                                    <div class="article-summary-box-inner">
                                        <span>Scene Designer is a novel method for searching and generating images using
free-hand sketches of scene compositions; i.e. drawings that describe both the
appearance and relative positions of objects. Our core contribution is a single
unified model to learn both a cross-modal search embedding for matching
sketched compositions to images, and an object embedding for layout synthesis.
We show that a graph neural network (GNN) followed by Transformer under our
novel contrastive learning setting is required to allow learning correlations
between object type, appearance and arrangement, driving a mask generation
module that synthesises coherent scene layouts, whilst also delivering state of
the art sketch based visual search of scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PnP-3D: A Plug-and-Play for 3D Point Clouds. (arXiv:2108.07378v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1">Shi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1">Saeed Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1">Nick Barnes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07378">
                                    <div class="article-summary-box-inner">
                                        <span>With the help of the deep learning paradigm, many point cloud networks have
been invented for visual analysis. However, there is great potential for
development of these networks since the given information of point cloud data
has not been fully exploited. To improve the effectiveness of existing networks
in analyzing point cloud data, we propose a plug-and-play module, PnP-3D,
aiming to refine the fundamental point cloud feature representations by
involving more local context and global bilinear response from explicit 3D
space and implicit feature space. To thoroughly evaluate our approach, we
conduct experiments on three standard point cloud analysis tasks, including
classification, semantic segmentation, and object detection, where we select
three state-of-the-art networks from each task for evaluation. Serving as a
plug-and-play module, PnP-3D can significantly boost the performances of
established networks. In addition to achieving state-of-the-art results on four
widely used point cloud benchmarks, we present comprehensive ablation studies
and visualizations to demonstrate our approach&#x27;s advantages. The code will be
available at https://github.com/ShiQiu0419/pnp-3d.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Generalization Prediction for Safety Critical Tasks in Novel Operating Domains. (arXiv:2108.07399v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+OBrien_M/0/1/0/all/0/1">Molly O&#x27;Brien</a>, <a href="http://arxiv.org/find/cs/1/au:+Medoff_M/0/1/0/all/0/1">Mike Medoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukowski_J/0/1/0/all/0/1">Julia Bukowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Hager_G/0/1/0/all/0/1">Greg Hager</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07399">
                                    <div class="article-summary-box-inner">
                                        <span>It is well known that Neural Network (network) performance often degrades
when a network is used in novel operating domains that differ from its training
and testing domains. This is a major limitation, as networks are being
integrated into safety critical, cyber-physical systems that must work in
unconstrained environments, e.g., perception for autonomous vehicles. Training
networks that generalize to novel operating domains and that extract robust
features is an active area of research, but previous work fails to predict what
the network performance will be in novel operating domains. We propose the task
Network Generalization Prediction: predicting the expected network performance
in novel operating domains. We describe the network performance in terms of an
interpretable Context Subspace, and we propose a methodology for selecting the
features of the Context Subspace that provide the most information about the
network performance. We identify the Context Subspace for a pretrained Faster
RCNN network performing pedestrian detection on the Berkeley Deep Drive (BDD)
Dataset, and demonstrate Network Generalization Prediction accuracy within 5%
or less of observed performance. We also demonstrate that the Context Subspace
from the BDD Dataset is informative for completely unseen datasets, JAAD and
Cityscapes, where predictions have a bias of 10% or less.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Dynamic Interpolation for Extremely Sparse Light Fields with Wide Baselines. (arXiv:2108.07408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mantang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07408">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we tackle the problem of dense light field (LF) reconstruction
from sparsely-sampled ones with wide baselines and propose a learnable model,
namely dynamic interpolation, to replace the commonly-used geometry warping
operation. Specifically, with the estimated geometric relation between input
views, we first construct a lightweight neural network to dynamically learn
weights for interpolating neighbouring pixels from input views to synthesize
each pixel of novel views independently. In contrast to the fixed and
content-independent weights employed in the geometry warping operation, the
learned interpolation weights implicitly incorporate the correspondences
between the source and novel views and adapt to different image content
information. Then, we recover the spatial correlation between the independently
synthesized pixels of each novel view by referring to that of input views using
a geometry-based spatial refinement module. We also constrain the angular
correlation between the novel views through a disparity-oriented LF structure
loss. Experimental results on LF datasets with wide baselines show that the
reconstructed LFs achieve much higher PSNR/SSIM and preserve the LF parallax
structure better than state-of-the-art methods. The source code is publicly
available at https://github.com/MantangGuo/DI4SLF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Match-Ignition: Plugging PageRank into Transformer for Long-form Text Matching. (arXiv:2101.06423v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06423">
                                    <div class="article-summary-box-inner">
                                        <span>Neural text matching models have been widely used in community question
answering, information retrieval, and dialogue. However, these models designed
for short texts cannot well address the long-form text matching problem,
because there are many contexts in long-form texts can not be directly aligned
with each other, and it is difficult for existing models to capture the key
matching signals from such noisy data. Besides, these models are
computationally expensive for simply use all textual data indiscriminately. To
tackle the effectiveness and efficiency problem, we propose a novel
hierarchical noise filtering model, namely Match-Ignition. The main idea is to
plug the well-known PageRank algorithm into the Transformer, to identify and
filter both sentence and word level noisy information in the matching process.
Noisy sentences are usually easy to detect because previous work has shown that
their similarity can be explicitly evaluated by the word overlapping, so we
directly use PageRank to filter such information based on a sentence similarity
graph. Unlike sentences, words rely on their contexts to express concrete
meanings, so we propose to jointly learn the filtering and matching process, to
well capture the critical word-level matching signals. Specifically, a word
graph is first built based on the attention scores in each self-attention block
of Transformer, and key words are then selected by applying PageRank on this
graph. In this way, noisy words will be filtered out layer by layer in the
matching process. Experimental results show that Match-Ignition outperforms
both SOTA short text matching models and recent long-form text matching models.
We also conduct detailed analysis to show that Match-Ignition efficiently
captures important sentences and words, to facilitate the long-form text
matching process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Self-Attentive Neural Networks for Click-Through Rate Prediction. (arXiv:2101.03654v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yichen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Feng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03654">
                                    <div class="article-summary-box-inner">
                                        <span>Click-Through Rate (CTR) prediction, whose aim is to predict the probability
of whether a user will click on an item, is an essential task for many online
applications. Due to the nature of data sparsity and high dimensionality of CTR
prediction, a key to making effective prediction is to model high-order feature
interaction. An efficient way to do this is to perform inner product of feature
embeddings with self-attentive neural networks. To better model complex feature
interaction, in this paper we propose a novel DisentanglEd Self-atTentIve
NEtwork (DESTINE) framework for CTR prediction that explicitly decouples the
computation of unary feature importance from pairwise interaction.
Specifically, the unary term models the general importance of one feature on
all other features, whereas the pairwise interaction term contributes to
learning the pure impact for each feature pair. We conduct extensive
experiments using two real-world benchmark datasets. The results show that
DESTINE not only maintains computational efficiency but achieves consistent
improvements over state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction. (arXiv:2008.01377v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heid_S/0/1/0/all/0/1">Stefan Heid</a>, <a href="http://arxiv.org/find/cs/1/au:+Wever_M/0/1/0/all/0/1">Marcel Wever</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01377">
                                    <div class="article-summary-box-inner">
                                        <span>Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis on the News to Improve Mental Health. (arXiv:2108.07706v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Saurav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayant_R/0/1/0/all/0/1">Rushil Jayant</a>, <a href="http://arxiv.org/find/cs/1/au:+Charagulla_N/0/1/0/all/0/1">Nihaar Charagulla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07706">
                                    <div class="article-summary-box-inner">
                                        <span>The popularization of the internet created a revitalized digital media. With
monetization driven by clicks, journalists have reprioritized their content for
the highly competitive atmosphere of online news. The resulting negativity bias
is harmful and can lead to anxiety and mood disturbance. We utilized a pipeline
of 4 sentiment analysis models trained on various datasets - using Sequential,
LSTM, BERT, and SVM models. When combined, the application, a mobile app,
solely displays uplifting and inspiring stories for users to read. Results have
been successful - 1,300 users rate the app at 4.9 stars, and 85% report
improved mental health by using it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MOI-Mixer: Improving MLP-Mixer with Multi Order Interactions in Sequential Recommendation. (arXiv:2108.07505v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hojoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_D/0/1/0/all/0/1">Dongyoon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Sunghwan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Changyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungryong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07505">
                                    <div class="article-summary-box-inner">
                                        <span>Successful sequential recommendation systems rely on accurately capturing the
user&#x27;s short-term and long-term interest. Although Transformer-based models
achieved state-of-the-art performance in the sequential recommendation task,
they generally require quadratic memory and time complexity to the sequence
length, making it difficult to extract the long-term interest of users. On the
other hand, Multi-Layer Perceptrons (MLP)-based models, renowned for their
linear memory and time complexity, have recently shown competitive results
compared to Transformer in various tasks. Given the availability of a massive
amount of the user&#x27;s behavior history, the linear memory and time complexity of
MLP-based models make them a promising alternative to explore in the sequential
recommendation task. To this end, we adopted MLP-based models in sequential
recommendation but consistently observed that MLP-based methods obtain lower
performance than those of Transformer despite their computational benefits.
From experiments, we observed that introducing explicit high-order interactions
to MLP layers mitigates such performance gap. In response, we propose the
Multi-Order Interaction (MOI) layer, which is capable of expressing an
arbitrary order of interactions within the inputs while maintaining the memory
and time complexity of the MLP layer. By replacing the MLP layer with the MOI
layer, our model was able to achieve comparable performance with
Transformer-based models while retaining the MLP-based models&#x27; computational
benefits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Powerful is Graph Convolution for Recommendation?. (arXiv:2108.07567v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yifei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yongji Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_C/0/1/0/all/0/1">Caihua Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Letaief_K/0/1/0/all/0/1">Khaled B. Letaief</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07567">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional networks (GCNs) have recently enabled a popular class of
algorithms for collaborative filtering (CF). Nevertheless, the theoretical
underpinnings of their empirical successes remain elusive. In this paper, we
endeavor to obtain a better understanding of GCN-based CF methods via the lens
of graph signal processing. By identifying the critical role of smoothness, a
key concept in graph signal processing, we develop a unified graph
convolution-based framework for CF. We prove that many existing CF methods are
special cases of this framework, including the neighborhood-based methods,
low-rank matrix factorization, linear auto-encoders, and LightGCN,
corresponding to different low-pass filters. Based on our framework, we then
present a simple and computationally efficient CF baseline, which we shall
refer to as Graph Filter based Collaborative Filtering (GF-CF). Given an
implicit feedback matrix, GF-CF can be obtained in a closed form instead of
expensive training with back-propagation. Experiments will show that GF-CF
achieves competitive or better performance against deep learning-based methods
on three well-known datasets, notably with a $70\%$ performance gain over
LightGCN on the Amazon-book dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Product Search Meets Collaborative Filtering: A Hierarchical Heterogeneous Graph Neural Network Approach. (arXiv:2108.07574v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xiangkun Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yangyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Liqiang Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhiyong Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07574">
                                    <div class="article-summary-box-inner">
                                        <span>Personalization lies at the core of boosting the product search system
performance. Prior studies mainly resorted to the semantic matching between
textual queries and user/product related documents, leaving the user
collaborative behaviors untapped. In fact, the collaborative filtering signals
between users intuitively offer a complementary information for the semantic
matching. To close the gap between collaborative filtering and product search,
we propose a Hierarchical Heterogeneous Graph Neural Network (HHGNN) approach
in this paper. Specifically, we organize HHGNN with a hierarchical graph
structure according to the three edge types. The sequence edge accounts for the
syntax formulation from word nodes to sentence nodes; the composition edge
aggregates the semantic features to the user and product nodes; and the
interaction edge on the top performs graph convolutional operation between user
and product nodes. At last, we integrate the higher-order neighboring
collaborative features and the semantic features for better representation
learning. We conduct extensive experiments on six Amazon review datasets. The
results show that our proposed method can outperform the state-of-the-art
baselines with a large margin. In addition, we empirically prove that
collaborative filtering and semantic matching are complementary to each other
in product search performance enhancement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Biased Subgroups in Ranking and Classification. (arXiv:2108.07450v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pastor_E/0/1/0/all/0/1">Eliana Pastor</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfaro_L/0/1/0/all/0/1">Luca de Alfaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Baralis_E/0/1/0/all/0/1">Elena Baralis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07450">
                                    <div class="article-summary-box-inner">
                                        <span>When analyzing the behavior of machine learning algorithms, it is important
to identify specific data subgroups for which the considered algorithm shows
different performance with respect to the entire dataset. The intervention of
domain experts is normally required to identify relevant attributes that define
these subgroups.

We introduce the notion of divergence to measure this performance difference
and we exploit it in the context of (i) classification models and (ii) ranking
applications to automatically detect data subgroups showing a significant
deviation in their behavior. Furthermore, we quantify the contribution of all
attributes in the data subgroup to the divergent behavior by means of Shapley
values, thus allowing the identification of the most impacting attributes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACM-CR: A Manually Annotated Test Collection for Citation Recommendation. (arXiv:2108.07571v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boudin_F/0/1/0/all/0/1">Florian Boudin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07571">
                                    <div class="article-summary-box-inner">
                                        <span>Citation recommendation is intended to assist researchers in the process of
searching for relevant papers to cite by recommending appropriate citations for
a given input text. Existing test collections for this task are noisy and
unreliable since they are built automatically from parsed PDF papers. In this
paper, we present our ongoing effort at creating a publicly available, manually
annotated test collection for citation recommendation. We also conduct a series
of experiments to evaluate the effectiveness of content-based baseline models
on the test collection, providing results for future work to improve upon. Our
test collection and code to replicate experiments are available at
https://github.com/boudinfl/acm-cr</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent Ethical Assessment of Text Classification Models: A Hate Speech Detection Case Study. (arXiv:2108.07627v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amitoj Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lihao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasekh_A/0/1/0/all/0/1">Amin Rasekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Golbin_I/0/1/0/all/0/1">Ilana Golbin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anand Rao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07627">
                                    <div class="article-summary-box-inner">
                                        <span>An independent ethical assessment of an artificial intelligence system is an
impartial examination of the system&#x27;s development, deployment, and use in
alignment with ethical values. System-level qualitative frameworks that
describe high-level requirements and component-level quantitative metrics that
measure individual ethical dimensions have been developed over the past few
years. However, there exists a gap between the two, which hinders the execution
of independent ethical assessments in practice. This study bridges this gap and
designs a holistic independent ethical assessment process for a text
classification model with a special focus on the task of hate speech detection.
The assessment is further augmented with protected attributes mining and
counterfactual-based analysis to enhance bias assessment. It covers assessments
of technical performance, data bias, embedding bias, classification bias, and
interpretability. The proposed process is demonstrated through an assessment of
a deep hate speech detection model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning with Echo State Networks. (arXiv:2105.07674v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cossu_A/0/1/0/all/0/1">Andrea Cossu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1">Davide Bacciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Carta_A/0/1/0/all/0/1">Antonio Carta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallicchio_C/0/1/0/all/0/1">Claudio Gallicchio</a>, <a href="http://arxiv.org/find/cs/1/au:+Lomonaco_V/0/1/0/all/0/1">Vincenzo Lomonaco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07674">
                                    <div class="article-summary-box-inner">
                                        <span>Continual Learning (CL) refers to a learning setup where data is non
stationary and the model has to learn without forgetting existing knowledge.
The study of CL for sequential patterns revolves around trained recurrent
networks. In this work, instead, we introduce CL in the context of Echo State
Networks (ESNs), where the recurrent component is kept fixed. We provide the
first evaluation of catastrophic forgetting in ESNs and we highlight the
benefits in using CL strategies which are not applicable to trained recurrent
models. Our results confirm the ESN as a promising model for CL and open to its
use in streaming scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who&#x27;s Waldo? Linking People Across Text and Images. (arXiv:2108.07253v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Claire Yuqing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1">Apoorv Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1">Yoav Artzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1">Noah Snavely</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1">Hadar Averbuch-Elor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07253">
                                    <div class="article-summary-box-inner">
                                        <span>We present a task and benchmark dataset for person-centric visual grounding,
the problem of linking between people named in a caption and people pictured in
an image. In contrast to prior work in visual grounding, which is predominantly
object-based, our new task masks out the names of people in captions in order
to encourage methods trained on such image-caption pairs to focus on contextual
cues (such as rich interactions between multiple people), rather than learning
associations between names and appearances. To facilitate this task, we
introduce a new dataset, Who&#x27;s Waldo, mined automatically from image-caption
data on Wikimedia Commons. We propose a Transformer-based method that
outperforms several strong baselines on this task, and are releasing our data
to the research community to spur work on contextual models that consider both
vision and language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Human-in-the-Loop Approach based on Explainability to Improve NTL Detection. (arXiv:2009.13437v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coma_Puig_B/0/1/0/all/0/1">Bernat Coma-Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmona_J/0/1/0/all/0/1">Josep Carmona</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13437">
                                    <div class="article-summary-box-inner">
                                        <span>Implementing systems based on Machine Learning to detect fraud and other
Non-Technical Losses (NTL) is challenging: the data available is biased, and
the algorithms currently used are black-boxes that cannot be either easily
trusted or understood by stakeholders. This work explains our human-in-the-loop
approach to mitigate these problems in a real system that uses a supervised
model to detect Non-Technical Losses (NTL) for an international utility company
from Spain. This approach exploits human knowledge (e.g. from the data
scientists or the company&#x27;s stakeholders) and the information provided by
explanatory methods to guide the system during the training process. This
simple, efficient method that can be easily implemented in other industrial
projects is tested in a real dataset and the results show that the derived
prediction model is better in terms of accuracy, interpretability, robustness
and flexibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Higgs Boson Classification: Brain-inspired BCPNN Learning with StreamBrain. (arXiv:2107.06676v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Svedin_M/0/1/0/all/0/1">Martin Svedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Podobas_A/0/1/0/all/0/1">Artur Podobas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1">Steven W. D. Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Markidis_S/0/1/0/all/0/1">Stefano Markidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06676">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most promising approaches for data analysis and exploration of
large data sets is Machine Learning techniques that are inspired by brain
models. Such methods use alternative learning rules potentially more
efficiently than established learning rules. In this work, we focus on the
potential of brain-inspired ML for exploiting High-Performance Computing (HPC)
resources to solve ML problems: we discuss the BCPNN and an HPC implementation,
called StreamBrain, its computational cost, suitability to HPC systems. As an
example, we use StreamBrain to analyze the Higgs Boson dataset from High Energy
Physics and discriminate between background and signal classes in collisions of
high-energy particle colliders. Overall, we reach up to 69.15% accuracy and
76.4% Area Under the Curve (AUC) performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Reinforcement Learning over MDPs. (arXiv:2108.02323v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Ke Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02323">
                                    <div class="article-summary-box-inner">
                                        <span>The past decade has seen the rapid development of Reinforcement Learning,
which acquires impressive performance with numerous training resources.
However, one of the greatest challenges in RL is generalization efficiency
(i.e., generalization performance in a unit time). This paper proposes a
framework of Active Reinforcement Learning (ARL) over MDPs to improve
generalization efficiency in a limited resource by instance selection. Given a
number of instances, the algorithm chooses out valuable instances as training
sets while training the policy, thereby costing fewer resources. Unlike
existing approaches, we attempt to actively select and use training data rather
than train on all the given data, thereby costing fewer resources. Furthermore,
we introduce a general instance evaluation metrics and selection mechanism into
the framework. Experiments results reveal that the proposed framework with
Proximal Policy Optimization as policy optimizer can effectively improve
generalization efficiency than unselect-ed and unbiased selected methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Navigation by Continuous-time Neural Networks. (arXiv:2106.08314v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vorbach_C/0/1/0/all/0/1">Charles Vorbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1">Ramin Hasani</a>, <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Alexander Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1">Mathias Lechner</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08314">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning enables high-fidelity, vision-based learning of policies
within rich, photorealistic environments. However, such techniques often rely
on traditional discrete-time neural models and face difficulties in
generalizing to domain shifts by failing to account for the causal
relationships between the agent and the environment. In this paper, we propose
a theoretical and experimental framework for learning causal representations
using continuous-time neural networks, specifically over their discrete-time
counterparts. We evaluate our method in the context of visual-control learning
of drones over a series of complex tasks, ranging from short- and long-term
navigation, to chasing static and dynamic objects through photorealistic
environments. Our results demonstrate that causal continuous-time deep models
can perform robust navigation tasks, where advanced recurrent models fail.
These models learn complex causal control representations directly from raw
visual inputs and scale to solve a variety of tasks using imitation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathdreamer: A World Model for Indoor Navigation. (arXiv:2105.08756v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1">Jing Yu Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1">Jason Baldridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_P/0/1/0/all/0/1">Peter Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08756">
                                    <div class="article-summary-box-inner">
                                        <span>People navigating in unfamiliar buildings take advantage of myriad visual,
spatial and semantic cues to efficiently achieve their navigation goals.
Towards equipping computational agents with similar capabilities, we introduce
Pathdreamer, a visual world model for agents navigating in novel indoor
environments. Given one or more previous visual observations, Pathdreamer
generates plausible high-resolution 360 visual observations (RGB, semantic
segmentation and depth) for viewpoints that have not been visited, in buildings
not seen during training. In regions of high uncertainty (e.g. predicting
around corners, imagining the contents of an unseen room), Pathdreamer can
predict diverse scenes, allowing an agent to sample multiple realistic outcomes
for a given trajectory. We demonstrate that Pathdreamer encodes useful and
accessible visual, spatial and semantic knowledge about human environments by
using it in the downstream task of Vision-and-Language Navigation (VLN).
Specifically, we show that planning ahead with Pathdreamer brings about half
the benefit of looking ahead at actual observations from unobserved parts of
the environment. We hope that Pathdreamer will help unlock model-based
approaches to challenging embodied navigation tasks such as navigating to
specified objects and VLN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. (arXiv:2103.14030v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ze Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yutong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yue Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yixuan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Stephen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14030">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new vision Transformer, called Swin Transformer, that
capably serves as a general-purpose backbone for computer vision. Challenges in
adapting Transformer from language to vision arise from differences between the
two domains, such as large variations in the scale of visual entities and the
high resolution of pixels in images compared to words in text. To address these
differences, we propose a hierarchical Transformer whose representation is
computed with \textbf{S}hifted \textbf{win}dows. The shifted windowing scheme
brings greater efficiency by limiting self-attention computation to
non-overlapping local windows while also allowing for cross-window connection.
This hierarchical architecture has the flexibility to model at various scales
and has linear computational complexity with respect to image size. These
qualities of Swin Transformer make it compatible with a broad range of vision
tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and
dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP
on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its
performance surpasses the previous state-of-the-art by a large margin of +2.7
box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the
potential of Transformer-based models as vision backbones. The hierarchical
design and the shifted window approach also prove beneficial for all-MLP
architectures. The code and models are publicly available
at~\url{https://github.com/microsoft/Swin-Transformer}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QuantumFed: A Federated Learning Framework for Collaborative Quantum Training. (arXiv:2106.09109v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1">Qi Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qun Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09109">
                                    <div class="article-summary-box-inner">
                                        <span>With the fast development of quantum computing and deep learning, quantum
neural networks have attracted great attention recently. By leveraging the
power of quantum computing, deep neural networks can potentially overcome
computational power limitations in classic machine learning. However, when
multiple quantum machines wish to train a global model using the local data on
each machine, it may be very difficult to copy the data into one machine and
train the model. Therefore, a collaborative quantum neural network framework is
necessary. In this article, we borrow the core idea of federated learning to
propose QuantumFed, a quantum federated learning framework to have multiple
quantum nodes with local quantum data train a mode together. Our experiments
show the feasibility and robustness of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Choice Set Confounding in Discrete Choice. (arXiv:2105.07959v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tomlinson_K/0/1/0/all/0/1">Kiran Tomlinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ugander_J/0/1/0/all/0/1">Johan Ugander</a>, <a href="http://arxiv.org/find/cs/1/au:+Benson_A/0/1/0/all/0/1">Austin R. Benson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07959">
                                    <div class="article-summary-box-inner">
                                        <span>Standard methods in preference learning involve estimating the parameters of
discrete choice models from data of selections (choices) made by individuals
from a discrete set of alternatives (the choice set). While there are many
models for individual preferences, existing learning methods overlook how
choice set assignment affects the data. Often, the choice set itself is
influenced by an individual&#x27;s preferences; for instance, a consumer choosing a
product from an online retailer is often presented with options from a
recommender system that depend on information about the consumer&#x27;s preferences.
Ignoring these assignment mechanisms can mislead choice models into making
biased estimates of preferences, a phenomenon that we call choice set
confounding; we demonstrate the presence of such confounding in widely-used
choice datasets.

To address this issue, we adapt methods from causal inference to the discrete
choice setting. We use covariates of the chooser for inverse probability
weighting and/or regression controls, accurately recovering individual
preferences in the presence of choice set confounding under certain
assumptions. When such covariates are unavailable or inadequate, we develop
methods that take advantage of structured choice set assignment to improve
prediction. We demonstrate the effectiveness of our methods on real-world
choice data, showing, for example, that accounting for choice set confounding
makes choices observed in hotel booking and commute transportation more
consistent with rational utility-maximization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model-Based Explainability Methods for Point Cloud NNs. (arXiv:2107.13459v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanxiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotthaus_H/0/1/0/all/0/1">Helena Kotthaus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13459">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of autonomous driving and robotics, point clouds are showing
their excellent real-time performance as raw data from most of the mainstream
3D sensors. Therefore, point cloud neural networks have become a popular
research direction in recent years. So far, however, there has been little
discussion about the explainability of deep neural networks for point clouds.
In this paper, we propose a point cloud-applicable explainability approach
based on local surrogate model-based method to show which components contribute
to the classification. Moreover, we propose quantitative fidelity validations
for generated explanations that enhance the persuasive power of explainability
and compare the plausibility of different existing point cloud-applicable
explainability methods. Our new explainability approach provides a fairly
accurate, more semantically coherent and widely applicable explanation for
point cloud classification tasks. Our code is available at
https://github.com/Explain3D/LIME-3D</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Convergent and Efficient Deep Q Network Algorithm. (arXiv:2106.15419v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhikang T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15419">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the empirical success of the deep Q network (DQN) reinforcement
learning algorithm and its variants, DQN is still not well understood and it
does not guarantee convergence. In this work, we show that DQN can diverge and
cease to operate in realistic settings. Although there exist gradient-based
convergent methods, we show that they actually have inherent problems in
learning behaviour and elucidate why they often fail in practice. To overcome
these problems, we propose a convergent DQN algorithm (C-DQN) by carefully
modifying DQN, and we show that the algorithm is convergent and can work with
large discount factors (0.9998). It learns robustly in difficult settings and
can learn several difficult games in the Atari 2600 benchmark where DQN fail,
within a moderate computational budget. Our codes have been publicly released
and can be used to reproduce our results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sensitivity analysis in differentially private machine learning using hybrid automatic differentiation. (arXiv:2107.04265v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_K/0/1/0/all/0/1">Kritika Prakash</a>, <a href="http://arxiv.org/find/cs/1/au:+Trask_A/0/1/0/all/0/1">Andrew Trask</a>, <a href="http://arxiv.org/find/cs/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/cs/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04265">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, formal methods of privacy protection such as differential
privacy (DP), capable of deployment to data-driven tasks such as machine
learning (ML), have emerged. Reconciling large-scale ML with the closed-form
reasoning required for the principled analysis of individual privacy loss
requires the introduction of new tools for automatic sensitivity analysis and
for tracking an individual&#x27;s data and their features through the flow of
computation. For this purpose, we introduce a novel \textit{hybrid} automatic
differentiation (AD) system which combines the efficiency of reverse-mode AD
with an ability to obtain a closed-form expression for any given quantity in
the computational graph. This enables modelling the sensitivity of arbitrary
differentiable function compositions, such as the training of neural networks
on private data. We demonstrate our approach by analysing the individual DP
guarantees of statistical database queries. Moreover, we investigate the
application of our technique to the training of DP neural networks. Our
approach can enable the principled reasoning about privacy loss in the setting
of data processing, and further the development of automatic sensitivity
analysis and privacy budgeting systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural ODE Processes. (arXiv:2103.12413v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Norcliffe_A/0/1/0/all/0/1">Alexander Norcliffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodnar_C/0/1/0/all/0/1">Cristian Bodnar</a>, <a href="http://arxiv.org/find/cs/1/au:+Day_B/0/1/0/all/0/1">Ben Day</a>, <a href="http://arxiv.org/find/cs/1/au:+Moss_J/0/1/0/all/0/1">Jacob Moss</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12413">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Ordinary Differential Equations (NODEs) use a neural network to model
the instantaneous rate of change in the state of a system. However, despite
their apparent suitability for dynamics-governed time-series, NODEs present a
few disadvantages. First, they are unable to adapt to incoming data points, a
fundamental requirement for real-time applications imposed by the natural
direction of time. Second, time series are often composed of a sparse set of
measurements that could be explained by many possible underlying dynamics.
NODEs do not capture this uncertainty. In contrast, Neural Processes (NPs) are
a family of models providing uncertainty estimation and fast data adaptation
but lack an explicit treatment of the flow of time. To address these problems,
we introduce Neural ODE Processes (NDPs), a new class of stochastic processes
determined by a distribution over Neural ODEs. By maintaining an adaptive
data-dependent distribution over the underlying ODE, we show that our model can
successfully capture the dynamics of low-dimensional systems from just a few
data points. At the same time, we demonstrate that NDPs scale up to challenging
high-dimensional time-series with unknown latent dynamics such as rotating
MNIST digits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data. (arXiv:2101.06069v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1">Gaurav Kumar Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saksham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Anirban Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06069">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained deep models hold their learnt knowledge in the form of model
parameters. These parameters act as &quot;memory&quot; for the trained models and help
them generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them &quot;Data
Impressions&quot;, which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating data-free Universal Adversarial
Perturbations (UAPs) with better fooling rates. Extensive experiments performed
on benchmark datasets demonstrate competitive performance achieved using data
impressions in absence of original training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Causal Graphical Prior Knowledge into Predictive Modeling via Simple Data Augmentation. (arXiv:2103.00136v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1">Takeshi Teshima</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00136">
                                    <div class="article-summary-box-inner">
                                        <span>Causal graphs (CGs) are compact representations of the knowledge of the data
generating processes behind the data distributions. When a CG is available,
e.g., from the domain knowledge, we can infer the conditional independence (CI)
relations that should hold in the data distribution. However, it is not
straightforward how to incorporate this knowledge into predictive modeling. In
this work, we propose a model-agnostic data augmentation method that allows us
to exploit the prior knowledge of the CI encoded in a CG for supervised machine
learning. We theoretically justify the proposed method by providing an excess
risk bound indicating that the proposed method suppresses overfitting by
reducing the apparent complexity of the predictor hypothesis class. Using
real-world data with CGs provided by domain experts, we experimentally show
that the proposed method is effective in improving the prediction accuracy,
especially in the small-data regime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term series forecasting with Query Selector -- efficient model of sparse attention. (arXiv:2107.08687v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klimek_J/0/1/0/all/0/1">Jacek Klimek</a>, <a href="http://arxiv.org/find/cs/1/au:+Klimek_J/0/1/0/all/0/1">Jakub Klimek</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraskiewicz_W/0/1/0/all/0/1">Witold Kraskiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Topolewski_M/0/1/0/all/0/1">Mateusz Topolewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08687">
                                    <div class="article-summary-box-inner">
                                        <span>Various modifications of TRANSFORMER were recently used to solve time-series
forecasting problem. We propose Query Selector - an efficient, deterministic
algorithm for sparse attention matrix. Experiments show it achieves
state-of-the art results on ETT, Helpdesk and BPI&#x27;12 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive analysis for scatterplot-based representations of dimensionality reduction. (arXiv:2101.12044v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+E%2E_W/0/1/0/all/0/1">Wilson E. Marc&#xed;lio-Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Eler_D/0/1/0/all/0/1">Danilo M. Eler</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_R/0/1/0/all/0/1">Rog&#xe9;rio E. Garcia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12044">
                                    <div class="article-summary-box-inner">
                                        <span>Cluster interpretation after dimensionality reduction (DR) is a ubiquitous
part of exploring multidimensional datasets. DR results are frequently
represented by scatterplots, where spatial proximity encodes similarity among
data samples. In the literature, techniques support the understanding of
scatterplots&#x27; organization by visualizing the importance of the features for
cluster definition with layout enrichment strategies. However, current
approaches usually focus on global information, hampering the analysis whenever
the focus is to understand the differences among clusters. Thus, this paper
introduces a methodology to visually explore DR results and interpret clusters&#x27;
formation based on contrastive analysis. We also introduce a bipartite graph to
visually interpret and explore the relationship between the statistical
variables employed to understand how the data features influence cluster
formation. Our approach is demonstrated through case studies, in which we
explore two document collections related to news articles and tweets about
COVID-19 symptoms. Finally, we evaluate our approach through quantitative
results to demonstrate its robustness to support multidimensional analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation. (arXiv:2103.10158v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1">Samuel G. M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10158">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic augmentation methods have recently become a crucial pillar for
strong model performance in vision tasks. While existing automatic augmentation
methods need to trade off simplicity, cost and performance, we present a most
simple baseline, TrivialAugment, that outperforms previous methods for almost
free. TrivialAugment is parameter-free and only applies a single augmentation
to each image. Thus, TrivialAugment&#x27;s effectiveness is very unexpected to us
and we performed very thorough experiments to study its performance. First, we
compare TrivialAugment to previous state-of-the-art methods in a variety of
image classification scenarios. Then, we perform multiple ablation studies with
different augmentation spaces, augmentation methods and setups to understand
the crucial requirements for its performance. Additionally, we provide a simple
interface to facilitate the widespread adoption of automatic augmentation
methods, as well as our full code base for reproducibility. Since our work
reveals a stagnation in many parts of automatic augmentation research, we end
with a short proposal of best practices for sustained future progress in
automatic augmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossy Compression for Lossless Prediction. (arXiv:2106.10800v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1">Yann Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloem_Reddy_B/0/1/0/all/0/1">Benjamin Bloem-Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1">Karen Ullrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1">Chris J. Maddison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10800">
                                    <div class="article-summary-box-inner">
                                        <span>Most data is automatically collected and only ever &quot;seen&quot; by algorithms. Yet,
data compressors preserve perceptual fidelity rather than just the information
needed by algorithms performing downstream tasks. In this paper, we
characterize the bit-rate required to ensure high performance on all predictive
tasks that are invariant under a set of transformations, such as data
augmentations. Based on our theory, we design unsupervised objectives for
training neural compressors. Using these objectives, we train a generic image
compressor that achieves substantial rate savings (more than $1000\times$ on
ImageNet) compared to JPEG on 8 datasets, without decreasing downstream
classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Generative Models of Textured 3D Meshes from Real-World Images. (arXiv:2103.15627v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1">Dario Pavllo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1">Thomas Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1">Aurelien Lucchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15627">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in differentiable rendering have sparked an interest in
learning generative models of textured 3D meshes from image collections. These
models natively disentangle pose and appearance, enable downstream applications
in computer graphics, and improve the ability of generative models to
understand the concept of image formation. Although there has been prior work
on learning such models from collections of 2D images, these approaches require
a delicate pose estimation step that exploits annotated keypoints, thereby
restricting their applicability to a few specific datasets. In this work, we
propose a GAN framework for generating textured triangle meshes without relying
on such annotations. We show that the performance of our approach is on par
with prior work that relies on ground-truth keypoints, and more importantly, we
demonstrate the generality of our method by setting new baselines on a larger
set of categories from ImageNet - for which keypoints are not available -
without any class-specific hyperparameter tuning. We release our code at
https://github.com/dariopavllo/textured-3d-gan</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal Inductive Matrix Completion. (arXiv:2004.01653v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ledent_A/0/1/0/all/0/1">Antoine Ledent</a>, <a href="http://arxiv.org/find/cs/1/au:+Alves_R/0/1/0/all/0/1">Rodrigo Alves</a>, <a href="http://arxiv.org/find/cs/1/au:+Kloft_M/0/1/0/all/0/1">Marius Kloft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01653">
                                    <div class="article-summary-box-inner">
                                        <span>We propose orthogonal inductive matrix completion (OMIC), an interpretable
approach to matrix completion based on a sum of multiple orthonormal side
information terms, together with nuclear-norm regularization. The approach
allows us to inject prior knowledge about the singular vectors of the ground
truth matrix. We optimize the approach by a provably converging algorithm,
which optimizes all components of the model simultaneously. We study the
generalization capabilities of our method in both the distribution-free setting
and in the case where the sampling distribution admits uniform marginals,
yielding learning guarantees that improve with the quality of the injected
knowledge in both cases. As particular cases of our framework, we present
models which can incorporate user and item biases or community information in a
joint and additive fashion. We analyse the performance of OMIC on several
synthetic and real datasets. On synthetic datasets with a sliding scale of user
bias relevance, we show that OMIC better adapts to different regimes than other
methods. On real-life datasets containing user/items recommendations and
relevant side information, we find that OMIC surpasses the state-of-the-art,
with the added benefit of greater interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Midwifery Learning and Forecasting: Predicting Content Demand with User-Generated Logs. (arXiv:2107.02480v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guitart_A/0/1/0/all/0/1">Anna Guitart</a>, <a href="http://arxiv.org/find/stat/1/au:+Rio_A/0/1/0/all/0/1">Ana Fern&#xe1;ndez del R&#xed;o</a>, <a href="http://arxiv.org/find/stat/1/au:+Perianez_A/0/1/0/all/0/1">&#xc1;frica Peri&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/stat/1/au:+Bellhouse_L/0/1/0/all/0/1">Lauren Bellhouse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02480">
                                    <div class="article-summary-box-inner">
                                        <span>Every day, 800 women and 6,700 newborns die from complications related to
pregnancy or childbirth. A well-trained midwife can prevent most of these
maternal and newborn deaths. Data science models together with logs generated
by users of online learning applications for midwives can help to improve their
learning competencies. The goal is to use these rich behavioral data to push
digital learning towards personalized content and to provide an adaptive
learning journey. In this work, we evaluate various forecasting methods to
determine the interest of future users on the different kind of contents
available in the app, broken down by profession and region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analogical and Relational Reasoning with Spiking Neural Networks. (arXiv:2010.06746v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Omari_R/0/1/0/all/0/1">Rollin Omari</a>, <a href="http://arxiv.org/find/cs/1/au:+McKay_R/0/1/0/all/0/1">R. I. McKay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06746">
                                    <div class="article-summary-box-inner">
                                        <span>Raven&#x27;s Progressive Matrices have been widely used for measuring abstract
reasoning and intelligence in humans. However for artificial learning systems,
abstract reasoning remains a challenging problem. In this paper we investigate
how neural networks augmented with biologically inspired spiking modules gain a
significant advantage in solving this problem. To illustrate this, we first
investigate the performance of our networks with supervised learning, then with
unsupervised learning. Experiments on the RAVEN dataset show that the overall
accuracy of our supervised networks surpass human-level performance, while our
unsupervised networks significantly outperform existing unsupervised methods.
Finally, our results from both supervised and unsupervised learning illustrate
that, unlike their non-augmented counterparts, networks with spiking modules
are able to extract and encode temporal features without any explicit
instruction, do not heavily rely on training data, and generalise more readily
to new problems. In summary, the results reported here indicate that artificial
neural networks with spiking modules are well suited to solving abstract
reasoning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization Through Hand-Eye Coordination: An Action Space for Learning Spatially-Invariant Visuomotor Control. (arXiv:2103.00375v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1">Ajay Mandlekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Danfei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00375">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation Learning (IL) is an effective framework to learn visuomotor skills
from offline demonstration data. However, IL methods often fail to generalize
to new scene configurations not covered by training data. On the other hand,
humans can manipulate objects in varying conditions. Key to such capability is
hand-eye coordination, a cognitive ability that enables humans to adaptively
direct their movements at task-relevant objects and be invariant to the
objects&#x27; absolute spatial location. In this work, we present a learnable action
space, Hand-eye Action Networks (HAN), that can approximate human&#x27;s hand-eye
coordination behaviors by learning from human teleoperated demonstrations.
Through a set of challenging multi-stage manipulation tasks, we show that a
visuomotor policy equipped with HAN is able to inherit the key spatial
invariance property of hand-eye coordination and achieve zero-shot
generalization to new scene configurations. Additional materials available at
https://sites.google.com/stanford.edu/han</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks. (arXiv:2007.05785v5 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Wei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhaofei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Masquelier_T/0/1/0/all/0/1">Timothee Masquelier</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tiejun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05785">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs) have attracted enormous research interest due
to temporal information processing capability, low power consumption, and high
biological plausibility. However, the formulation of efficient and
high-performance learning algorithms for SNNs is still challenging. Most
existing learning methods learn weights only, and require manual tuning of the
membrane-related parameters that determine the dynamics of a single spiking
neuron. These parameters are typically chosen to be the same for all neurons,
which limits the diversity of neurons and thus the expressiveness of the
resulting SNNs. In this paper, we take inspiration from the observation that
membrane-related parameters are different across brain regions, and propose a
training algorithm that is capable of learning not only the synaptic weights
but also the membrane time constants of SNNs. We show that incorporating
learnable membrane time constants can make the network less sensitive to
initial values and can speed up learning. In addition, we reevaluate the
pooling methods in SNNs and find that max-pooling will not lead to significant
information loss and have the advantage of low computation cost and binary
compatibility. We evaluate the proposed method for image classification tasks
on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and
neuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment
results show that the proposed method outperforms the state-of-the-art accuracy
on nearly all datasets, using fewer time-steps. Our codes are available at
https://github.com/fangwei123456/Parametric-Leaky-Integrate-and-Fire-Spiking-Neuron.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coping with Label Shift via Distributionally Robust Optimisation. (arXiv:2010.12230v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingzhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1">Andreas Veit</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1">Srinadh Bhojanapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1">Suvrit Sra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12230">
                                    <div class="article-summary-box-inner">
                                        <span>The label shift problem refers to the supervised learning setting where the
train and test label distributions do not match. Existing work addressing label
shift usually assumes access to an \emph{unlabelled} test sample. This sample
may be used to estimate the test label distribution, and to then train a
suitably re-weighted classifier. While approaches using this idea have proven
effective, their scope is limited as it is not always feasible to access the
target domain; further, they require repeated retraining if the model is to be
deployed in \emph{multiple} test environments. Can one instead learn a
\emph{single} classifier that is robust to arbitrary label shifts from a broad
family? In this paper, we answer this question by proposing a model that
minimises an objective based on distributionally robust optimisation (DRO). We
then design and analyse a gradient descent-proximal mirror ascent algorithm
tailored for large-scale problems to optimise the proposed objective. %, and
establish its convergence. Finally, through experiments on CIFAR-100 and
ImageNet, we show that our technique can significantly improve performance over
a number of baselines in settings where label shift is present.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Pitfalls of Model-Agnostic Interpretation Methods for Machine Learning Models. (arXiv:2007.04131v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Molnar_C/0/1/0/all/0/1">Christoph Molnar</a>, <a href="http://arxiv.org/find/stat/1/au:+Konig_G/0/1/0/all/0/1">Gunnar K&#xf6;nig</a>, <a href="http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1">Julia Herbinger</a>, <a href="http://arxiv.org/find/stat/1/au:+Freiesleben_T/0/1/0/all/0/1">Timo Freiesleben</a>, <a href="http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1">Susanne Dandl</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholbeck_C/0/1/0/all/0/1">Christian A. Scholbeck</a>, <a href="http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1">Giuseppe Casalicchio</a>, <a href="http://arxiv.org/find/stat/1/au:+Grosse_Wentrup_M/0/1/0/all/0/1">Moritz Grosse-Wentrup</a>, <a href="http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04131">
                                    <div class="article-summary-box-inner">
                                        <span>An increasing number of model-agnostic interpretation techniques for machine
learning (ML) models such as partial dependence plots (PDP), permutation
feature importance (PFI) and Shapley values provide insightful model
interpretations, but can lead to wrong conclusions if applied incorrectly. We
highlight many general pitfalls of ML model interpretation, such as using
interpretation techniques in the wrong context, interpreting models that do not
generalize well, ignoring feature dependencies, interactions, uncertainty
estimates and issues in high-dimensional settings, or making unjustified causal
interpretations, and illustrate them with examples. We focus on pitfalls for
global methods that describe the average model behavior, but many pitfalls also
apply to local methods that explain individual predictions. Our paper addresses
ML practitioners by raising awareness of pitfalls and identifying solutions for
correct model interpretation, but also addresses ML researchers by discussing
open issues for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching. (arXiv:2012.08950v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runzhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zetian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08950">
                                    <div class="article-summary-box-inner">
                                        <span>Graph matching (GM) has been a building block in many areas including
computer vision and pattern recognition. Despite the recent impressive
progress, existing deep GM methods often have difficulty in handling outliers
in both graphs, which are ubiquitous in practice. We propose a deep
reinforcement learning (RL) based approach RGM for weighted graph matching,
whose sequential node matching scheme naturally fits with the strategy for
selective inlier matching against outliers, and supports seed graph matching. A
revocable action scheme is devised to improve the agent&#x27;s flexibility against
the complex constrained matching task. Moreover, we propose a quadratic
approximation technique to regularize the affinity matrix, in the presence of
outliers. As such, the RL agent can finish inlier matching timely when the
objective score stop growing, for which otherwise an additional hyperparameter
i.e. the number of common inliers is needed to avoid matching outliers. In this
paper, we are focused on learning the back-end solver for the most general form
of GM: the Lawler&#x27;s QAP, whose input is the affinity matrix. Our approach can
also boost other solvers using the affinity input. Experimental results on both
synthetic and real-world datasets showcase its superior performance regarding
both matching accuracy and robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smart Choices and the Selection Monad. (arXiv:2007.08926v6 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abadi_M/0/1/0/all/0/1">Martin Abadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotkin_G/0/1/0/all/0/1">Gordon Plotkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08926">
                                    <div class="article-summary-box-inner">
                                        <span>Describing systems in terms of choices and their resulting costs and rewards
offers the promise of freeing algorithm designers and programmers from
specifying how those choices should be made; in implementations, the choices
can be realized by optimization techniques and, increasingly, by
machine-learning methods. We study this approach from a programming-language
perspective. We define two small languages that support decision-making
abstractions: one with choices and rewards, and the other additionally with
probabilities. We give both operational and denotational semantics.

In the case of the second language we consider three denotational semantics,
with varying degrees of correlation between possible program values and
expected rewards. The operational semantics combine the usual semantics of
standard constructs with optimization over spaces of possible execution
strategies. The denotational semantics, which are compositional, rely on the
selection monad, to handle choice, augmented with an auxiliary monad to handle
other effects, such as rewards or probability.

We establish adequacy theorems that the two semantics coincide in all cases.
We also prove full abstraction at base types, with varying notions of
observation in the probabilistic case corresponding to the various degrees of
correlation. We present axioms for choice combined with rewards and
probability, establishing completeness at base types for the case of rewards
without probability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatially Conditioned Graphs for Detecting Human-Object Interactions. (arXiv:2012.06060v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Frederic Z. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1">Dylan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06060">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of detecting human-object interactions in images using
graphical neural networks. Unlike conventional methods, where nodes send scaled
but otherwise identical messages to each of their neighbours, we propose to
condition messages between pairs of nodes on their spatial relationships,
resulting in different messages going to neighbours of the same node. To this
end, we explore various ways of applying spatial conditioning under a
multi-branch structure. Through extensive experimentation we demonstrate the
advantages of spatial conditioning for the computation of the adjacency
structure, messages and the refined graph features. In particular, we
empirically show that as the quality of the bounding boxes increases, their
coarse appearance features contribute relatively less to the disambiguation of
interactions compared to the spatial information. Our method achieves an mAP of
31.33% on HICO-DET and 54.2% on V-COCO, significantly outperforming
state-of-the-art on fine-tuned detections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Neural Architecture Search with Operation Embeddings. (arXiv:2105.04885v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatzianastasis_M/0/1/0/all/0/1">Michail Chatzianastasis</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasoulas_G/0/1/0/all/0/1">George Dasoulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Siolas_G/0/1/0/all/0/1">Georgios Siolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04885">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Architecture Search (NAS) has recently gained increased attention, as
a class of approaches that automatically searches in an input space of network
architectures. A crucial part of the NAS pipeline is the encoding of the
architecture that consists of the applied computational blocks, namely the
operations and the links between them. Most of the existing approaches either
fail to capture the structural properties of the architectures or use
hand-engineered vector to encode the operator information. In this paper, we
propose the replacement of fixed operator encoding with learnable
representations in the optimization process. This approach, which effectively
captures the relations of different operations, leads to smoother and more
accurate representations of the architectures and consequently to improved
performance of the end task. Our extensive evaluation in ENAS benchmark
demonstrates the effectiveness of the proposed operation embeddings to the
generation of highly accurate models, achieving state-of-the-art performance.
Finally, our method produces top-performing architectures that share similar
operation and graph patterns, highlighting a strong correlation between the
structural properties of the architecture and its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Speaker Verification Backend with Robust Performance across Conditions. (arXiv:2102.01760v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1">Luciana Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+McLaren_M/0/1/0/all/0/1">Mitchell McLaren</a>, <a href="http://arxiv.org/find/cs/1/au:+Brummer_N/0/1/0/all/0/1">Niko Brummer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01760">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address the problem of speaker verification in conditions
unseen or unknown during development. A standard method for speaker
verification consists of extracting speaker embeddings with a deep neural
network and processing them through a backend composed of probabilistic linear
discriminant analysis (PLDA) and global logistic regression score calibration.
This method is known to result in systems that work poorly on conditions
different from those used to train the calibration model. We propose to modify
the standard backend, introducing an adaptive calibrator that uses duration and
other automatically extracted side-information to adapt to the conditions of
the inputs. The backend is trained discriminatively to optimize binary
cross-entropy. When trained on a number of diverse datasets that are labeled
only with respect to speaker, the proposed backend consistently and, in some
cases, dramatically improves calibration, compared to the standard PLDA
approach, on a number of held-out datasets, some of which are markedly
different from the training data. Discrimination performance is also
consistently improved. We show that joint training of the PLDA and the adaptive
calibrator is essential -- the same benefits cannot be achieved when freezing
PLDA and fine-tuning the calibrator. To our knowledge, the results in this
paper are the first evidence in the literature that it is possible to develop a
speaker verification system with robust out-of-the-box performance on a large
variety of conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MVTN: Multi-View Transformation Network for 3D Shape Recognition. (arXiv:2011.13244v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamdi_A/0/1/0/all/0/1">Abdullah Hamdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Giancola_S/0/1/0/all/0/1">Silvio Giancola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13244">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view projection methods have demonstrated their ability to reach
state-of-the-art performance on 3D shape recognition. Those methods learn
different ways to aggregate information from multiple views. However, the
camera view-points for those views tend to be heuristically set and fixed for
all shapes. To circumvent the lack of dynamism of current multi-view methods,
we propose to learn those view-points. In particular, we introduce the
Multi-View Transformation Network (MVTN) that regresses optimal view-points for
3D shape recognition, building upon advances in differentiable rendering. As a
result, MVTN can be trained end-to-end along with any multi-view network for 3D
shape classification. We integrate MVTN in a novel adaptive multi-view pipeline
that can render either 3D meshes or point clouds. MVTN exhibits clear
performance gains in the tasks of 3D shape classification and 3D shape
retrieval without the need for extra training supervision. In these tasks, MVTN
achieves state-of-the-art performance on ModelNet40, ShapeNet Core55, and the
most recent and realistic ScanObjectNN dataset (up to 6% improvement).
Interestingly, we also show that MVTN can provide network robustness against
rotation and occlusion in the 3D domain. The code is available at
https://github.com/ajhamdi/MVTN .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just One Moment: Structural Vulnerability of Deep Action Recognition against One Frame Attack. (arXiv:2011.14585v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jaehui Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jun-Hyuk Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jun-Ho Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jong-Seok Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14585">
                                    <div class="article-summary-box-inner">
                                        <span>The video-based action recognition task has been extensively studied in
recent years. In this paper, we study the structural vulnerability of deep
learning-based action recognition models against the adversarial attack using
the one frame attack that adds an inconspicuous perturbation to only a single
frame of a given video clip. Our analysis shows that the models are highly
vulnerable against the one frame attack due to their structural properties.
Experiments demonstrate high fooling rates and inconspicuous characteristics of
the attack. Furthermore, we show that strong universal one frame perturbations
can be obtained under various scenarios. Our work raises the serious issue of
adversarial vulnerability of the state-of-the-art action recognition models in
various perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction. (arXiv:2008.01377v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heid_S/0/1/0/all/0/1">Stefan Heid</a>, <a href="http://arxiv.org/find/cs/1/au:+Wever_M/0/1/0/all/0/1">Marcel Wever</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01377">
                                    <div class="article-summary-box-inner">
                                        <span>Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Learning Guarantees for Compressive Clustering and Compressive Mixture Modeling. (arXiv:2004.08085v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1">R&#xe9;mi Gribonval</a> (PANAMA, DANTE), <a href="http://arxiv.org/find/cs/1/au:+Blanchard_G/0/1/0/all/0/1">Gilles Blanchard</a> (LMO), <a href="http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1">Nicolas Keriven</a> (GIPSA-GAIA), <a href="http://arxiv.org/find/cs/1/au:+Traonmilin_Y/0/1/0/all/0/1">Yann Traonmilin</a> (IMB)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08085">
                                    <div class="article-summary-box-inner">
                                        <span>We provide statistical learning guarantees for two unsupervised learning
tasks in the context of compressive statistical learning, a general framework
for resource-efficient large-scale learning that we introduced in a companion
paper.The principle of compressive statistical learning is to compress a
training collection, in one pass, into a low-dimensional sketch (a vector of
random empirical generalized moments) that captures the information relevant to
the considered learning task. We explicitly describe and analyze random feature
functions which empirical averages preserve the needed information for
compressive clustering and compressive Gaussian mixture modeling with fixed
known variance, and establish sufficient sketch sizes given the problem
dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing thermodynamic trajectories using evolutionary and gradient-based reinforcement learning. (arXiv:1903.08543v5 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beeler_C/0/1/0/all/0/1">Chris Beeler</a>, <a href="http://arxiv.org/find/cs/1/au:+Yahorau_U/0/1/0/all/0/1">Uladzimir Yahorau</a>, <a href="http://arxiv.org/find/cs/1/au:+Coles_R/0/1/0/all/0/1">Rory Coles</a>, <a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1">Kyle Mills</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitelam_S/0/1/0/all/0/1">Stephen Whitelam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1">Isaac Tamblyn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.08543">
                                    <div class="article-summary-box-inner">
                                        <span>Using a model heat engine, we show that neural network-based reinforcement
learning can identify thermodynamic trajectories of maximal efficiency. We
consider both gradient and gradient-free reinforcement learning. We use an
evolutionary learning algorithm to evolve a population of neural networks,
subject to a directive to maximize the efficiency of a trajectory composed of a
set of elementary thermodynamic processes; the resulting networks learn to
carry out the maximally-efficient Carnot, Stirling, or Otto cycles. When given
an additional irreversible process, this evolutionary scheme learns a
previously unknown thermodynamic cycle. Gradient-based reinforcement learning
is able to learn the Stirling cycle, whereas an evolutionary approach achieves
the optimal Carnot cycle. Our results show how the reinforcement learning
strategies developed for game playing can be applied to solve physical problems
conditioned upon path-extensive order parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Content-Based Deep Intrusion Detection System. (arXiv:2001.05009v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soltani_M/0/1/0/all/0/1">Mahdi Soltani</a>, <a href="http://arxiv.org/find/cs/1/au:+Siavoshani_M/0/1/0/all/0/1">Mahdi Jafari Siavoshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahangir_A/0/1/0/all/0/1">Amir Hossein Jahangir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.05009">
                                    <div class="article-summary-box-inner">
                                        <span>The growing number of Internet users and the prevalence of web applications
make it necessary to deal with very complex software and applications in the
network. This results in an increasing number of new vulnerabilities in the
systems, and leading to an increase in cyber threats and, in particular,
zero-day attacks. The cost of generating appropriate signatures for these
attacks is a potential motive for using machine learning-based methodologies.
Although there are many studies on using learning-based methods for attack
detection, they generally use extracted features and overlook raw contents.
This approach can lessen the performance of detection systems against
content-based attacks like SQL injection, Cross-site Scripting (XSS), and
various viruses.

In this work, we propose a framework, called deep intrusion detection (DID)
system, that uses the pure content of traffic flows in addition to traffic
metadata in the learning and detection phases of a passive DNN IDS. To this
end, we deploy and evaluate an offline IDS following the framework using LSTM
as a deep learning technique. Due to the inherent nature of deep learning, it
can process high dimensional data content and, accordingly, discover the
sophisticated relations between the auto extracted features of the traffic. To
evaluate the proposed DID system, we use the CIC-IDS2017 and CSE-CIC-IDS2018
datasets. The evaluation metrics, such as precision and recall, reach $0.992$
and $0.998$ on CIC-IDS2017, and $0.933$ and $0.923$ on CSE-CIC-IDS2018
respectively, which show the high performance of the proposed DID method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RandomRooms: Unsupervised Pre-training from Synthetic Shapes and Randomized Layouts for 3D Object Detection. (arXiv:2108.07794v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Benlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07794">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud understanding has made great progress in recent years.
However, one major bottleneck is the scarcity of annotated real datasets,
especially compared to 2D object detection tasks, since a large amount of labor
is involved in annotating the real scans of a scene. A promising solution to
this problem is to make better use of the synthetic dataset, which consists of
CAD object models, to boost the learning on real datasets. This can be achieved
by the pre-training and fine-tuning procedure. However, recent work on 3D
pre-training exhibits failure when transfer features learned on synthetic
objects to other real-world applications. In this work, we put forward a new
method called RandomRooms to accomplish this objective. In particular, we
propose to generate random layouts of a scene by making use of the objects in
the synthetic CAD dataset and learn the 3D scene representation by applying
object-level contrastive learning on two random scenes generated from the same
set of synthetic objects. The model pre-trained in this way can serve as a
better initialization when later fine-tuning on the 3D object detection task.
Empirically, we show consistent improvement in downstream 3D detection tasks on
several base models, especially when less training data are used, which
strongly demonstrates the effectiveness and generalization of our method.
Benefiting from the rich semantic knowledge and diverse objects from synthetic
data, our method establishes the new state-of-the-art on widely-used 3D
detection benchmarks ScanNetV2 and SUN RGB-D. We expect our attempt to provide
a new perspective for bridging object and scene-level 3D understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Recommendation for Structural Equation Model Discovery in Process Mining. (arXiv:2108.07795v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qafari_M/0/1/0/all/0/1">Mahnaz Sadat Qafari</a>, <a href="http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1">Wil van der Aalst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07795">
                                    <div class="article-summary-box-inner">
                                        <span>Process mining techniques can help organizations to improve their operational
processes. Organizations can benefit from process mining techniques in finding
and amending the root causes of performance or compliance problems. Considering
the volume of the data and the number of features captured by the information
system of today&#x27;s companies, the task of discovering the set of features that
should be considered in root cause analysis can be quite involving. In this
paper, we propose a method for finding the set of (aggregated) features with a
possible effect on the problem.

The root cause analysis task is usually done by applying a machine learning
technique to the data gathered from the information system supporting the
processes. To prevent mixing up correlation and causation, which may happen
because of interpreting the findings of machine learning techniques as causal,
we propose a method for discovering the structural equation model of the
process that can be used for root cause analysis. We have implemented the
proposed method as a plugin in ProM and we have evaluated it using two real and
synthetic event logs. These experiments show the validity and effectiveness of
the proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-aware Contrastive Regression for Action Quality Assessment. (arXiv:2108.07797v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xumin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07797">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing action quality is challenging due to the subtle differences between
videos and large variations in scores. Most existing approaches tackle this
problem by regressing a quality score from a single video, suffering a lot from
the large inter-video score variations. In this paper, we show that the
relations among videos can provide important clues for more accurate action
quality assessment during both training and inference. Specifically, we
reformulate the problem of action quality assessment as regressing the relative
scores with reference to another video that has shared attributes (e.g.,
category and difficulty), instead of learning unreferenced scores. Following
this formulation, we propose a new Contrastive Regression (CoRe) framework to
learn the relative scores by pair-wise comparison, which highlights the
differences between videos and guides the models to learn the key hints for
assessment. In order to further exploit the relative information between two
videos, we devise a group-aware regression tree to convert the conventional
score regression into two easier sub-problems: coarse-to-fine classification
and regression in small intervals. To demonstrate the effectiveness of CoRe, we
conduct extensive experiments on three mainstream AQA datasets including AQA-7,
MTL-AQA and JIGSAWS. Our approach outperforms previous methods by a large
margin and establishes new state-of-the-art on all three benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XtracTree: a Simple and Effective Method for Regulator Validation of Bagging Methods Used in Retail Banking. (arXiv:2004.02326v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Charlier_J/0/1/0/all/0/1">Jeremy Charlier</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarenkov_V/0/1/0/all/0/1">Vladimir Makarenkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.02326">
                                    <div class="article-summary-box-inner">
                                        <span>Bootstrap aggregation, known as bagging, is one of the most popular ensemble
methods used in machine learning (ML). An ensemble method is a ML method that
combines multiple hypotheses to form a single hypothesis used for prediction. A
bagging algorithm combines multiple classifiers modeled on different
sub-samples of the same data set to build one large classifier. Banks, and
their retail banking activities, are nowadays using the power of ML algorithms,
including decision trees and random forests, to optimize their processes.
However, banks have to comply with regulators and governance and, hence,
delivering effective ML solutions is a challenging task. It starts with the
bank&#x27;s validation and governance department, followed by the deployment of the
solution in a production environment up to the external validation of the
national financial regulator. Each proposed ML model has to be validated and
clear rules for every algorithm-based decision must be justified. In this
context, we propose XtracTree, an algorithm capable of efficiently converting
an ML bagging classifier, such as a random forest, into simple &quot;if-then&quot; rules
satisfying the requirements of model validation. We use a public loan data set
from Kaggle to illustrate the usefulness of our approach. Our experiments
demonstrate that using XtracTree, one can convert an ML model into a rule-based
algorithm, leading to easier model validation by national financial regulators
and the bank&#x27;s validation department. The proposed approach allowed our banking
institution to reduce up to 50% the time of delivery of our AI solutions to the
end-user.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The application of predictive analytics to identify at-risk students in health professions education. (arXiv:2108.07709v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Anshul Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Edwards_R/0/1/0/all/0/1">Roger Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_L/0/1/0/all/0/1">Lisa Walker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07709">
                                    <div class="article-summary-box-inner">
                                        <span>Introduction: When a learner fails to reach a milestone, educators often
wonder if there had been any warning signs that could have allowed them to
intervene sooner. Machine learning is used to predict which students are at
risk of failing a national certifying exam. Predictions are made well in
advance of the exam, such that educators can meaningfully intervene before
students take the exam.

Methods: Using already-collected, first-year student assessment data from
four cohorts in a Master of Physician Assistant Studies program, the authors
implement an &quot;adaptive minimum match&quot; version of the k-nearest neighbors
algorithm (AMMKNN), using changing numbers of neighbors to predict each
student&#x27;s future exam scores on the Physician Assistant National Certifying
Examination (PANCE). Leave-one-out cross validation (LOOCV) was used to
evaluate the practical capabilities of this model, before making predictions
for new students.

Results: The best predictive model has an accuracy of 93%, sensitivity of
69%, and specificity of 94%. It generates a predicted PANCE score for each
student, one year before they are scheduled to take the exam. Students can then
be prospectively categorized into groups that need extra support, optional
extra support, or no extra support. The educator then has one year to provide
the appropriate customized support to each type of student.

Conclusions: Predictive analytics can help health professions educators
allocate scarce time and resources across their students. Interprofessional
educators can use the included methods and code to generate predicted test
outcomes for students. The authors recommend that educators using this or
similar predictive methods act responsibly and transparently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImitAL: Learning Active Learning Strategies from Synthetic Data. (arXiv:2108.07670v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonsior_J/0/1/0/all/0/1">Julius Gonsior</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiele_M/0/1/0/all/0/1">Maik Thiele</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehner_W/0/1/0/all/0/1">Wolfgang Lehner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07670">
                                    <div class="article-summary-box-inner">
                                        <span>One of the biggest challenges that complicates applied supervised machine
learning is the need for huge amounts of labeled data. Active Learning (AL) is
a well-known standard method for efficiently obtaining labeled data by first
labeling the samples that contain the most information based on a query
strategy. Although many methods for query strategies have been proposed in the
past, no clear superior method that works well in general for all domains has
been found yet. Additionally, many strategies are computationally expensive
which further hinders the widespread use of AL for large-scale annotation
projects.

We, therefore, propose ImitAL, a novel query strategy, which encodes AL as a
learning-to-rank problem. For training the underlying neural network we chose
Imitation Learning. The required demonstrative expert experience for training
is generated from purely synthetic data.

To show the general and superior applicability of \ImitAL{}, we perform an
extensive evaluation comparing our strategy on 15 different datasets, from a
wide range of domains, with 10 different state-of-the-art query strategies. We
also show that our approach is more runtime performant than most other
strategies, especially on very large datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Should You Defend Your Classifier -- A Game-theoretical Analysis of Countermeasures against Adversarial Examples. (arXiv:2108.07602v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samsinger_M/0/1/0/all/0/1">Maximilian Samsinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Merkle_F/0/1/0/all/0/1">Florian Merkle</a>, <a href="http://arxiv.org/find/cs/1/au:+Schottle_P/0/1/0/all/0/1">Pascal Sch&#xf6;ttle</a>, <a href="http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1">Tomas Pevny</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07602">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial machine learning, i.e., increasing the robustness of machine
learning algorithms against so-called adversarial examples, is now an
established field. Yet, newly proposed methods are evaluated and compared under
unrealistic scenarios where costs for adversary and defender are not considered
and either all samples are attacked or no sample is attacked. We scrutinize
these assumptions and propose the advanced adversarial classification game,
which incorporates all relevant parameters of an adversary and a defender in
adversarial classification. Especially, we take into account economic factors
on both sides and the fact that all so far proposed countermeasures against
adversarial examples reduce accuracy on benign samples. Analyzing the scenario
in detail, where both players have two pure strategies, we identify all best
responses and conclude that in practical settings, the most influential factor
might be the maximum amount of adversarial examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MVCNet: Multiview Contrastive Network for Unsupervised Representation Learning for 3D CT Lesions. (arXiv:2108.07662v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_P/0/1/0/all/0/1">Penghua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_H/0/1/0/all/0/1">Huaiwei Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Gangming Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Chaowei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07662">
                                    <div class="article-summary-box-inner">
                                        <span>With the renaissance of deep learning, automatic diagnostic systems for
computed tomography (CT) have achieved many successful applications. However,
they are mostly attributed to careful expert annotations, which are often
scarce in practice. This drives our interest to the unsupervised representation
learning. Recent studies have shown that self-supervised learning is an
effective approach for learning representations, but most of them rely on the
empirical design of transformations and pretext tasks. To avoid the
subjectivity associated with these methods, we propose the MVCNet, a novel
unsupervised three dimensional (3D) representation learning method working in a
transformation-free manner. We view each 3D lesion from different orientations
to collect multiple two dimensional (2D) views. Then, an embedding function is
learned by minimizing a contrastive loss so that the 2D views of the same 3D
lesion are aggregated, and the 2D views of different lesions are separated. We
evaluate the representations by training a simple classification head upon the
embedding layer. Experimental results show that MVCNet achieves
state-of-the-art accuracies on the LIDC-IDRI (89.55%), LNDb (77.69%) and
TianChi (79.96%) datasets for unsupervised representation learning. When
fine-tuned on 10% of the labeled data, the accuracies are comparable to the
supervised learning model (89.46% vs. 85.03%, 73.85% vs. 73.44%, 83.56% vs.
83.34% on the three datasets, respectively), indicating the superiority of
MVCNet in learning representations with limited annotations. Code is released
at: https://github.com/penghuazhai/MVCNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Harnessing value from data science in business: ensuring explainability and fairness of solutions. (arXiv:2108.07714v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chomiak_K/0/1/0/all/0/1">Krzysztof Chomiak</a>, <a href="http://arxiv.org/find/cs/1/au:+Miktus_M/0/1/0/all/0/1">Micha&#x142; Miktus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07714">
                                    <div class="article-summary-box-inner">
                                        <span>The paper introduces concepts of fairness and explainability (XAI) in
artificial intelligence, oriented to solve a sophisticated business problems.
For fairness, the authors discuss the bias-inducing specifics, as well as
relevant mitigation methods, concluding with a set of recipes for introducing
fairness in data-driven organizations. Additionally, for XAI, the authors audit
specific algorithms paired with demonstrational business use-cases, discuss a
plethora of techniques of explanations quality quantification and provide an
overview of future research avenues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-parametric Bayesian Additive Regression Trees. (arXiv:2108.07636v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Prado_E/0/1/0/all/0/1">Estev&#xe3;o B. Prado</a>, <a href="http://arxiv.org/find/stat/1/au:+Parnell_A/0/1/0/all/0/1">Andrew C. Parnell</a>, <a href="http://arxiv.org/find/stat/1/au:+McJames_N/0/1/0/all/0/1">Nathan McJames</a>, <a href="http://arxiv.org/find/stat/1/au:+OShea_A/0/1/0/all/0/1">Ann O&#x27;Shea</a>, <a href="http://arxiv.org/find/stat/1/au:+Moral_R/0/1/0/all/0/1">Rafael A. Moral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07636">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new semi-parametric model based on Bayesian Additive Regression
Trees (BART). In our approach, the response variable is approximated by a
linear predictor and a BART model, where the first component is responsible for
estimating the main effects and BART accounts for the non-specified
interactions and non-linearities. The novelty in our approach lies in the way
we change tree generation moves in BART to deal with confounding between the
parametric and non-parametric components when they have covariates in common.
Through synthetic and real-world examples, we demonstrate that the performance
of the new semi-parametric BART is competitive when compared to regression
models and other tree-based methods. The implementation of the proposed method
is available at https://github.com/ebprado/SP-BART.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating harm in language models with conditional-likelihood filtration. (arXiv:2108.07790v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1">Helen Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Raterink_C/0/1/0/all/0/1">Cooper Raterink</a>, <a href="http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1">Jo&#xe3;o G.M. Ara&#xfa;jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_I/0/1/0/all/0/1">Ivan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Carol Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Morisot_A/0/1/0/all/0/1">Adrien Morisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Frosst_N/0/1/0/all/0/1">Nicholas Frosst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07790">
                                    <div class="article-summary-box-inner">
                                        <span>Language models trained on large-scale unfiltered datasets curated from the
open web acquire systemic biases, prejudices, and harmful views from their
training data. We present a methodology for programmatically identifying and
removing harmful text from web-scale datasets. A pretrained language model is
used to calculate the log-likelihood of researcher-written trigger phrases
conditioned on a specific document, which is used to identify and filter
documents from the dataset. We demonstrate that models trained on this filtered
dataset exhibit lower propensity to generate harmful text, with a marginal
decrease in performance on standard language modeling benchmarks compared to
unfiltered baselines. We provide a partial explanation for this performance gap
by surfacing examples of hate speech and other undesirable content from
standard language modeling benchmarks. Finally, we discuss the generalization
of this method and how trigger phrases which reflect specific values can be
used by researchers to build language models which are more closely aligned
with their values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGNet: Weighing Black Holes with Deep Learning. (arXiv:2108.07749v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Lin_J/0/1/0/all/0/1">Joshua Yao-Yu Lin</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Pandya_S/0/1/0/all/0/1">Sneh Pandya</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Pratap_D/0/1/0/all/0/1">Devanshi Pratap</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kind_M/0/1/0/all/0/1">Matias Carrasco Kind</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kindratenko_V/0/1/0/all/0/1">Volodymyr Kindratenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07749">
                                    <div class="article-summary-box-inner">
                                        <span>Supermassive black holes (SMBHs) are ubiquitously found at the centers of
most massive galaxies. Measuring SMBH mass is important for understanding the
origin and evolution of SMBHs. However, traditional methods require
spectroscopic data which is expensive to gather. We present an algorithm that
weighs SMBHs using quasar light time series, circumventing the need for
expensive spectra. We train, validate, and test neural networks that directly
learn from the Sloan Digital Sky Survey (SDSS) Stripe 82 light curves for a
sample of $38,939$ spectroscopically confirmed quasars to map out the nonlinear
encoding between SMBH mass and multi-color optical light curves. We find a
1$\sigma$ scatter of 0.37 dex between the predicted SMBH mass and the fiducial
virial mass estimate based on SDSS single-epoch spectra, which is comparable to
the systematic uncertainty in the virial mass estimate. Our results have direct
implications for more efficient applications with future observations from the
Vera C. Rubin Observatory. Our code, \textsf{AGNet}, is publicly available at

{\color{red} \url{https://github.com/snehjp2/AGNet}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPAN: Subgraph Prediction Attention Network for Dynamic Graphs. (arXiv:2108.07776v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chuanchang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yubo Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hai Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07776">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel model for predicting subgraphs in dynamic graphs,
an extension of traditional link prediction. This proposed end-to-end model
learns a mapping from the subgraph structures in the current snapshot to the
subgraph structures in the next snapshot directly, i.e., edge existence among
multiple nodes in the subgraph. A new mechanism named cross-attention with a
twin-tower module is designed to integrate node attribute information and
topology information collaboratively for learning subgraph evolution. We
compare our model with several state-of-the-art methods for subgraph prediction
and subgraph pattern prediction in multiple real-world homogeneous and
heterogeneous dynamic graphs, respectively. Experimental results demonstrate
that our model outperforms other models in these two tasks, with a gain
increase from 5.02% to 10.88%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Nonparametric Inference via Deep Neural Network. (arXiv:1902.01687v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruiqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukai_B/0/1/0/all/0/1">Ben Boukai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_Z/0/1/0/all/0/1">Zuofeng Shang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.01687">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network is a state-of-art method in modern science and
technology. Much statistical literature have been devoted to understanding its
performance in nonparametric estimation, whereas the results are suboptimal due
to a redundant logarithmic sacrifice. In this paper, we show that such
log-factors are not necessary. We derive upper bounds for the $L^2$ minimax
risk in nonparametric estimation. Sufficient conditions on network
architectures are provided such that the upper bounds become optimal (without
log-sacrifice). Our proof relies on an explicitly constructed network estimator
based on tensor product B-splines. We also derive asymptotic distributions for
the constructed network and a relating hypothesis testing procedure. The
testing procedure is further proven as minimax optimal under suitable network
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KCNet: An Insect-Inspired Single-Hidden-Layer Neural Network with Randomized Binary Weights for Prediction and Classification Tasks. (arXiv:2108.07554v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jinyung Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlic_T/0/1/0/all/0/1">Theodore P. Pavlic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07554">
                                    <div class="article-summary-box-inner">
                                        <span>Fruit flies are established model systems for studying olfactory learning as
they will readily learn to associate odors with both electric shock or sugar
rewards. The mechanisms of the insect brain apparently responsible for odor
learning form a relatively shallow neuronal architecture. Olfactory inputs are
received by the antennal lobe (AL) of the brain, which produces an encoding of
each odor mixture across ~50 sub-units known as glomeruli. Each of these
glomeruli then project its component of this feature vector to several of ~2000
so-called Kenyon Cells (KCs) in a region of the brain known as the mushroom
body (MB). Fly responses to odors are generated by small downstream neuropils
that decode the higher-order representation from the MB. Research has shown
that there is no recognizable pattern in the glomeruli--KC connections (and
thus the particular higher-order representations); they are akin to
fingerprints~-- even isogenic flies have different projections. Leveraging
insights from this architecture, we propose KCNet, a single-hidden-layer neural
network that contains sparse, randomized, binary weights between the input
layer and the hidden layer and analytically learned weights between the hidden
layer and the output layer. Furthermore, we also propose a dynamic optimization
algorithm that enables the KCNet to increase performance beyond its structural
limits by searching a more efficient set of inputs. For odorant-perception
tasks that predict perceptual properties of an odorant, we show that KCNet
outperforms existing data-driven approaches, such as XGBoost. For
image-classification tasks, KCNet achieves reasonable performance on benchmark
datasets (MNIST, Fashion-MNIST, and EMNIST) without any data-augmentation
methods or convolutional layers and shows particularly fast running time. Thus,
neural networks inspired by the insect brain can be both economical and perform
well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Program Synthesis with Large Language Models. (arXiv:2108.07732v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Odena_A/0/1/0/all/0/1">Augustus Odena</a>, <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosma_M/0/1/0/all/0/1">Maarten Bosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohan_D/0/1/0/all/0/1">David Dohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_E/0/1/0/all/0/1">Ellen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Carrie Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Terry_M/0/1/0/all/0/1">Michael Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1">Charles Sutton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07732">
                                    <div class="article-summary-box-inner">
                                        <span>This paper explores the limits of the current generation of large language
models for program synthesis in general purpose programming languages. We
evaluate a collection of such models (with between 244M and 137B parameters) on
two new benchmarks, MBPP and MathQA-Python, in both the few-shot and
fine-tuning regimes. Our benchmarks are designed to measure the ability of
these models to synthesize short Python programs from natural language
descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974
programming tasks, designed to be solvable by entry-level programmers. The
MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914
problems that evaluate the ability of the models to synthesize code from more
complex text. On both datasets, we find that synthesis performance scales
log-linearly with model size. Our largest models, even without finetuning on a
code dataset, can synthesize solutions to 59.6 percent of the problems from
MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a
held-out portion of the dataset improves performance by about 10 percentage
points across most model sizes. On the MathQA-Python dataset, the largest
fine-tuned model achieves 83.8 percent accuracy. Going further, we study the
model&#x27;s ability to engage in dialog about code, incorporating human feedback to
improve its solutions. We find that natural language feedback from a human
halves the error rate compared to the model&#x27;s initial prediction. Additionally,
we conduct an error analysis to shed light on where these models fall short and
what types of programs are most difficult to generate. Finally, we explore the
semantic grounding of these models by fine-tuning them to predict the results
of program execution. We find that even our best models are generally unable to
predict the output of a program given a specific input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting State Augmentation methods for Reinforcement Learning with Stochastic Delays. (arXiv:2108.07555v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nath_S/0/1/0/all/0/1">Somjit Nath</a>, <a href="http://arxiv.org/find/cs/1/au:+Baranwal_M/0/1/0/all/0/1">Mayank Baranwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Khadilkar_H/0/1/0/all/0/1">Harshad Khadilkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07555">
                                    <div class="article-summary-box-inner">
                                        <span>Several real-world scenarios, such as remote control and sensing, are
comprised of action and observation delays. The presence of delays degrades the
performance of reinforcement learning (RL) algorithms, often to such an extent
that algorithms fail to learn anything substantial. This paper formally
describes the notion of Markov Decision Processes (MDPs) with stochastic delays
and shows that delayed MDPs can be transformed into equivalent standard MDPs
(without delays) with significantly simplified cost structure. We employ this
equivalence to derive a model-free Delay-Resolved RL framework and show that
even a simple RL algorithm built upon this framework achieves near-optimal
rewards in environments with stochastic delays in actions and observations. The
delay-resolved deep Q-network (DRDQN) algorithm is bench-marked on a variety of
environments comprising of multi-step and stochastic delays and results in
better performance, both in terms of achieving near-optimal rewards and
minimizing the computational overhead thereof, with respect to the currently
established algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Placement of Public Electric Vehicle Charging Stations Using Deep Reinforcement Learning. (arXiv:2108.07772v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Petratos_A/0/1/0/all/0/1">Aidan Petratos</a>, <a href="http://arxiv.org/find/eess/1/au:+Ting_A/0/1/0/all/0/1">Allen Ting</a>, <a href="http://arxiv.org/find/eess/1/au:+Padmanabhan_S/0/1/0/all/0/1">Shankar Padmanabhan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_K/0/1/0/all/0/1">Kristina Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Hageman_D/0/1/0/all/0/1">Dylan Hageman</a>, <a href="http://arxiv.org/find/eess/1/au:+Pisel_J/0/1/0/all/0/1">Jesse R. Pisel</a>, <a href="http://arxiv.org/find/eess/1/au:+Pyrcz_M/0/1/0/all/0/1">Michael J. Pyrcz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07772">
                                    <div class="article-summary-box-inner">
                                        <span>The placement of charging stations in areas with developing charging
infrastructure is a critical component of the future success of electric
vehicles (EVs). In Albany County in New York, the expected rise in the EV
population requires additional charging stations to maintain a sufficient level
of efficiency across the charging infrastructure. A novel application of
Reinforcement Learning (RL) is able to find optimal locations for new charging
stations given the predicted charging demand and current charging locations.
The most important factors that influence charging demand prediction include
the conterminous traffic density, EV registrations, and proximity to certain
types of public buildings. The proposed RL framework can be refined and applied
to cities across the world to optimize charging station placement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct domain adaptation through reciprocal linear transformations. (arXiv:2108.07600v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alkhalifah_T/0/1/0/all/0/1">Tariq Alkhalifah</a>, <a href="http://arxiv.org/find/cs/1/au:+Ovcharenko_O/0/1/0/all/0/1">Oleg Ovcharenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07600">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a direct domain adaptation (DDA) approach to enrich the training
of supervised neural networks on synthetic data by features from real-world
data. The process involves a series of linear operations on the input features
to the NN model, whether they are from the source or target domains, as
follows: 1) A cross-correlation of the input data (i.e. images) with a randomly
picked sample pixel (or pixels) of all images from that domain or the mean of
all randomly picked sample pixel (or pixels) of all images. 2) The convolution
of the resulting data with the mean of the autocorrelated input images from the
other domain. In the training stage, as expected, the input images are from the
source domain, and the mean of auto-correlated images are evaluated from the
target domain. In the inference/application stage, the input images are from
the target domain, and the mean of auto-correlated images are evaluated from
the source domain. The proposed method only manipulates the data from the
source and target domains and does not explicitly interfere with the training
workflow and network architecture. An application that includes training a
convolutional neural network on the MNIST dataset and testing the network on
the MNIST-M dataset achieves a 70% accuracy on the test data. A principal
component analysis (PCA), as well as t-SNE, show that the input features from
the source and target domains, after the proposed direct transformations, share
similar properties along with the principal components as compared to the
original MNIST and MNIST-M input features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">O-HAS: Optical Hardware Accelerator Search for Boosting Both Acceleration Performance and Development Speed. (arXiv:2108.07538v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mengquan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhongzhi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yonggan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yingyan Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07538">
                                    <div class="article-summary-box-inner">
                                        <span>The recent breakthroughs and prohibitive complexities of Deep Neural Networks
(DNNs) have excited extensive interest in domain-specific DNN accelerators,
among which optical DNN accelerators are particularly promising thanks to their
unprecedented potential of achieving superior performance-per-watt. However,
the development of optical DNN accelerators is much slower than that of
electrical DNN accelerators. One key challenge is that while many techniques
have been developed to facilitate the development of electrical DNN
accelerators, techniques that support or expedite optical DNN accelerator
design remain much less explored, limiting both the achievable performance and
the innovation development of optical DNN accelerators. To this end, we develop
the first-of-its-kind framework dubbed O-HAS, which for the first time
demonstrates automated Optical Hardware Accelerator Search for boosting both
the acceleration efficiency and development speed of optical DNN accelerators.
Specifically, our O-HAS consists of two integrated enablers: (1) an O-Cost
Predictor, which can accurately yet efficiently predict an optical
accelerator&#x27;s energy and latency based on the DNN model parameters and the
optical accelerator design; and (2) an O-Search Engine, which can automatically
explore the large design space of optical DNN accelerators and identify the
optimal accelerators (i.e., the micro-architectures and
algorithm-to-accelerator mapping methods) in order to maximize the target
acceleration efficiency. Extensive experiments and ablation studies
consistently validate the effectiveness of both our O-Cost Predictor and
O-Search Engine as well as the excellent efficiency of O-HAS generated optical
accelerators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of Students performance with Artificial Neural Network using Demographic Traits. (arXiv:2108.07717v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kehinde_A/0/1/0/all/0/1">Adeniyi Jide Kehinde</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeniyi_A/0/1/0/all/0/1">Abidemi Emmanuel Adeniyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogundokun_R/0/1/0/all/0/1">Roseline Oluwaseun Ogundokun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Himanshu Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_S/0/1/0/all/0/1">Sanjay Misra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07717">
                                    <div class="article-summary-box-inner">
                                        <span>Many researchers have studied student academic performance in supervised and
unsupervised learning using numerous data mining techniques. Neural networks
often need a greater collection of observations to achieve enough predictive
ability. Due to the increase in the rate of poor graduates, it is necessary to
design a system that helps to reduce this menace as well as reduce the
incidence of students having to repeat due to poor performance or having to
drop out of school altogether in the middle of the pursuit of their career. It
is therefore necessary to study each one as well as their advantages and
disadvantages, so as to determine which is more efficient in and in what case
one should be preferred over the other. The study aims to develop a system to
predict student performance with Artificial Neutral Network using the student
demographic traits so as to assist the university in selecting candidates
(students) with a high prediction of success for admission using previous
academic records of students granted admissions which will eventually lead to
quality graduates of the institution. The model was developed based on certain
selected variables as the input. It achieved an accuracy of over 92.3 percent,
showing Artificial Neural Network potential effectiveness as a predictive tool
and a selection criterion for candidates seeking admission to a university.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incremental cluster validity index-guided online learning for performance and robustness to presentation order. (arXiv:2108.07743v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silva_L/0/1/0/all/0/1">Leonardo Enzo Brito da Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Rayapati_N/0/1/0/all/0/1">Nagasharath Rayapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Wunsch_D/0/1/0/all/0/1">Donald C. Wunsch II</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07743">
                                    <div class="article-summary-box-inner">
                                        <span>In streaming data applications incoming samples are processed and discarded,
therefore, intelligent decision-making is crucial for the performance of
lifelong learning systems. In addition, the order in which samples arrive may
heavily affect the performance of online (and offline) incremental learners.
The recently introduced incremental cluster validity indices (iCVIs) provide
valuable aid in addressing such class of problems. Their primary use-case has
been cluster quality monitoring; nonetheless, they have been very recently
integrated in a streaming clustering method to assist the clustering task
itself. In this context, the work presented here introduces the first adaptive
resonance theory (ART)-based model that uses iCVIs for unsupervised and
semi-supervised online learning. Moreover, it shows for the first time how to
use iCVIs to regulate ART vigilance via an iCVI-based match tracking mechanism.
The model achieves improved accuracy and robustness to ordering effects by
integrating an online iCVI framework as module B of a topological adaptive
resonance theory predictive mapping (TopoARTMAP) -- thereby being named
iCVI-TopoARTMAP -- and by employing iCVI-driven post-processing heuristics at
the end of each learning step. The online iCVI framework provides assignments
of input samples to clusters at each iteration in accordance to any of several
iCVIs. The iCVI-TopoARTMAP maintains useful properties shared by ARTMAP models,
such as stability, immunity to catastrophic forgetting, and the many-to-one
mapping capability via the map field module. The performance (unsupervised and
semi-supervised) and robustness to presentation order (unsupervised) of
iCVI-TopoARTMAP were evaluated via experiments with a synthetic data set and
deep embeddings of a real-world face image data set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Panoramic Learning with A Standardized Machine Learning Formalism. (arXiv:2108.07783v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric P. Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07783">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning (ML) is about computational methods that enable machines to
learn concepts from experiences. In handling a wide variety of experiences
ranging from data instances, knowledge, constraints, to rewards, adversaries,
and lifelong interplay in an ever-growing spectrum of tasks, contemporary ML/AI
research has resulted in a multitude of learning paradigms and methodologies.
Despite the continual progresses on all different fronts, the disparate
narrowly-focused methods also make standardized, composable, and reusable
development of learning solutions difficult, and make it costly if possible to
build AI agents that panoramically learn from all types of experiences. This
paper presents a standardized ML formalism, in particular a standard equation
of the learning objective, that offers a unifying understanding of diverse ML
algorithms, making them special cases due to different choices of modeling
components. The framework also provides guidance for mechanic design of new ML
solutions, and serves as a promising vehicle towards panoramic learning with
all experiences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Laws for Deep Learning. (arXiv:2108.07686v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenfeld_J/0/1/0/all/0/1">Jonathan S. Rosenfeld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07686">
                                    <div class="article-summary-box-inner">
                                        <span>Running faster will only get you so far -- it is generally advisable to first
understand where the roads lead, then get a car ...

The renaissance of machine learning (ML) and deep learning (DL) over the last
decade is accompanied by an unscalable computational cost, limiting its
advancement and weighing on the field in practice. In this thesis we take a
systematic approach to address the algorithmic and methodological limitations
at the root of these costs. We first demonstrate that DL training and pruning
are predictable and governed by scaling laws -- for state of the art models and
tasks, spanning image classification and language modeling, as well as for
state of the art model compression via iterative pruning. Predictability, via
the establishment of these scaling laws, provides the path for principled
design and trade-off reasoning, currently largely lacking in the field. We then
continue to analyze the sources of the scaling laws, offering an
approximation-theoretic view and showing through the exploration of a noiseless
realizable case that DL is in fact dominated by error sources very far from the
lower error limit. We conclude by building on the gained theoretical
understanding of the scaling laws&#x27; origins. We present a conjectural path to
eliminate one of the current dominant error sources -- through a data bandwidth
limiting hypothesis and the introduction of Nyquist learners -- which can, in
principle, reach the generalization error lower limit (e.g. 0 in the noiseless
case), at finite dataset size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coalesced Multi-Output Tsetlin Machines with Clause Sharing. (arXiv:2108.07594v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Glimsdal_S/0/1/0/all/0/1">Sondre Glimsdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1">Ole-Christoffer Granmo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07594">
                                    <div class="article-summary-box-inner">
                                        <span>Using finite-state machines to learn patterns, Tsetlin machines (TMs) have
obtained competitive accuracy and learning speed across several benchmarks,
with frugal memory- and energy footprint. A TM represents patterns as
conjunctive clauses in propositional logic (AND-rules), each clause voting for
or against a particular output. While efficient for single-output problems, one
needs a separate TM per output for multi-output problems. Employing multiple
TMs hinders pattern reuse because each TM then operates in a silo. In this
paper, we introduce clause sharing, merging multiple TMs into a single one.
Each clause is related to each output by using a weight. A positive weight
makes the clause vote for output $1$, while a negative weight makes the clause
vote for output $0$. The clauses thus coalesce to produce multiple outputs. The
resulting coalesced Tsetlin Machine (CoTM) simultaneously learns both the
weights and the composition of each clause by employing interacting Stochastic
Searching on the Line (SSL) and Tsetlin Automata (TA) teams. Our empirical
results on MNIST, Fashion-MNIST, and Kuzushiji-MNIST show that CoTM obtains
significantly higher accuracy than TM on $50$- to $1$K-clause configurations,
indicating an ability to repurpose clauses. E.g., accuracy goes from $71.99$%
to $89.66$% on Fashion-MNIST when employing $50$ clauses per class (22 Kb
memory). While TM and CoTM accuracy is similar when using more than $1$K
clauses per class, CoTM reaches peak accuracy $3\times$ faster on MNIST with
$8$K clauses. We further investigate robustness towards imbalanced training
data. Our evaluations on imbalanced versions of IMDb- and CIFAR10 data show
that CoTM is robust towards high degrees of class imbalance. Being able to
share clauses, we believe CoTM will enable new TM application domains that
involve multiple outputs, such as learning language models and auto-encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demonstrating REACT: a Real-time Educational AI-powered Classroom Tool. (arXiv:2108.07693v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1">Ajay Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gkountouna_O/0/1/0/all/0/1">Olga Gkountouna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07693">
                                    <div class="article-summary-box-inner">
                                        <span>We present a demonstration of REACT, a new Real-time Educational AI-powered
Classroom Tool that employs EDM techniques for supporting the decision-making
process of educators. REACT is a data-driven tool with a user-friendly
graphical interface. It analyzes students&#x27; performance data and provides
context-based alerts as well as recommendations to educators for course
planning. Furthermore, it incorporates model-agnostic explanations for bringing
explainability and interpretability in the process of decision making. This
paper demonstrates a use case scenario of our proposed tool using a real-world
dataset and presents the design of its architecture and user interface. This
demonstration focuses on the agglomerative clustering of students based on
their performance (i.e., incorrect responses and hints used) during an in-class
activity. This formation of clusters of students with similar strengths and
weaknesses may help educators to improve their course planning by identifying
at-risk students, forming study groups, or encouraging tutoring between
students of different strengths.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating smooth and sparse neural receptive fields with a flexible spline basis. (arXiv:2108.07537v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziwei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_Y/0/1/0/all/0/1">Yanli Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Oesterle_J/0/1/0/all/0/1">Jonathan Oesterle</a>, <a href="http://arxiv.org/find/cs/1/au:+Euler_T/0/1/0/all/0/1">Thomas Euler</a>, <a href="http://arxiv.org/find/cs/1/au:+Berens_P/0/1/0/all/0/1">Philipp Berens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07537">
                                    <div class="article-summary-box-inner">
                                        <span>Spatio-temporal receptive field (STRF) models are frequently used to
approximate the computation implemented by a sensory neuron. Typically, such
STRFs are assumed to be smooth and sparse. Current state-of-the-art approaches
for estimating STRFs based on empirical Bayes are often not computationally
efficient in high-dimensional settings, as encountered in sensory neuroscience.
Here we pursued an alternative approach and encode prior knowledge for
estimation of STRFs by choosing a set of basis functions with the desired
properties: natural cubic splines. Our method is computationally efficient and
can be easily applied to a wide range of existing models. We compared the
performance of spline-based methods to non-spline ones on simulated and
experimental data, showing that spline-based methods consistently outperform
the non-spline versions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Powerful is Graph Convolution for Recommendation?. (arXiv:2108.07567v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yifei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yongji Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_C/0/1/0/all/0/1">Caihua Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Letaief_K/0/1/0/all/0/1">Khaled B. Letaief</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07567">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional networks (GCNs) have recently enabled a popular class of
algorithms for collaborative filtering (CF). Nevertheless, the theoretical
underpinnings of their empirical successes remain elusive. In this paper, we
endeavor to obtain a better understanding of GCN-based CF methods via the lens
of graph signal processing. By identifying the critical role of smoothness, a
key concept in graph signal processing, we develop a unified graph
convolution-based framework for CF. We prove that many existing CF methods are
special cases of this framework, including the neighborhood-based methods,
low-rank matrix factorization, linear auto-encoders, and LightGCN,
corresponding to different low-pass filters. Based on our framework, we then
present a simple and computationally efficient CF baseline, which we shall
refer to as Graph Filter based Collaborative Filtering (GF-CF). Given an
implicit feedback matrix, GF-CF can be obtained in a closed form instead of
expensive training with back-propagation. Experiments will show that GF-CF
achieves competitive or better performance against deep learning-based methods
on three well-known datasets, notably with a $70\%$ performance gain over
LightGCN on the Amazon-book dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GCCAD: Graph Contrastive Coding for Anomaly Detection. (arXiv:2108.07516v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaokang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jian Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaibo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07516">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based anomaly detection has been widely used for detecting malicious
activities in real-world applications. Existing attempts to address this
problem have thus far focused on structural feature engineering or learning in
the binary classification regime. In this work, we propose to leverage graph
contrastive coding and present the supervised GCCAD model for contrasting
abnormal nodes with normal ones in terms of their distances to the global
context (e.g., the average of all nodes). To handle scenarios with scarce
labels, we further enable GCCAD as a self-supervised framework by designing a
graph corrupting strategy for generating synthetic node labels. To achieve the
contrastive objective, we design a graph neural network encoder that can infer
and further remove suspicious links during message passing, as well as learn
the global context of the input graph. We conduct extensive experiments on four
public datasets, demonstrating that 1) GCCAD significantly and consistently
outperforms various advanced baselines and 2) its self-supervised version
without fine-tuning can achieve comparable performance with its fully
supervised version.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Light-weight contextual spelling correction model for customizing transducer-based speech recognition systems. (arXiv:2108.07493v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07493">
                                    <div class="article-summary-box-inner">
                                        <span>It&#x27;s challenging to customize transducer-based automatic speech recognition
(ASR) system with context information which is dynamic and unavailable during
model training. In this work, we introduce a light-weight contextual spelling
correction model to correct context-related recognition errors in
transducer-based ASR systems. We incorporate the context information into the
spelling correction model with a shared context encoder and use a filtering
algorithm to handle large-size context lists. Experiments show that the model
improves baseline ASR model performance with about 50% relative word error rate
reduction, which also significantly outperforms the baseline method such as
contextual LM biasing. The model also shows excellent performance for
out-of-vocabulary terms not seen during training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RRLFSOR: An Efficient Self-Supervised Learning Strategy of Graph Convolutional Networks. (arXiv:2108.07481v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Feng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+V_A/0/1/0/all/0/1">Ajith Kumar V</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guanci Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qikui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiyun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Ansi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Makwana_D/0/1/0/all/0/1">Dhruv Makwana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07481">
                                    <div class="article-summary-box-inner">
                                        <span>To further improve the performance and the self-learning ability of GCNs, in
this paper, we propose an efficient self-supervised learning strategy of GCNs,
named randomly removed links with a fixed step at one region (RRLFSOR). In
addition, we also propose another self-supervised learning strategy of GCNs,
named randomly removing links with a fixed step at some blocks (RRLFSSB), to
solve the problem that adjacent nodes have no selected step. Experiments on
transductive link prediction tasks show that our strategies outperform the
baseline models consistently by up to 21.34% in terms of accuracy on three
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stability and Generalization for Randomized Coordinate Descent. (arXiv:2108.07414v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Puyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yunwen Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07414">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized coordinate descent (RCD) is a popular optimization algorithm with
wide applications in solving various machine learning problems, which motivates
a lot of theoretical analysis on its convergence behavior. As a comparison,
there is no work studying how the models trained by RCD would generalize to
test examples. In this paper, we initialize the generalization analysis of RCD
by leveraging the powerful tool of algorithmic stability. We establish argument
stability bounds of RCD for both convex and strongly convex objectives, from
which we develop optimal generalization bounds by showing how to early-stop the
algorithm to tradeoff the estimation and optimization. Our analysis shows that
RCD enjoys better stability as compared to stochastic gradient descent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MOI-Mixer: Improving MLP-Mixer with Multi Order Interactions in Sequential Recommendation. (arXiv:2108.07505v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hojoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_D/0/1/0/all/0/1">Dongyoon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Sunghwan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Changyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungryong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07505">
                                    <div class="article-summary-box-inner">
                                        <span>Successful sequential recommendation systems rely on accurately capturing the
user&#x27;s short-term and long-term interest. Although Transformer-based models
achieved state-of-the-art performance in the sequential recommendation task,
they generally require quadratic memory and time complexity to the sequence
length, making it difficult to extract the long-term interest of users. On the
other hand, Multi-Layer Perceptrons (MLP)-based models, renowned for their
linear memory and time complexity, have recently shown competitive results
compared to Transformer in various tasks. Given the availability of a massive
amount of the user&#x27;s behavior history, the linear memory and time complexity of
MLP-based models make them a promising alternative to explore in the sequential
recommendation task. To this end, we adopted MLP-based models in sequential
recommendation but consistently observed that MLP-based methods obtain lower
performance than those of Transformer despite their computational benefits.
From experiments, we observed that introducing explicit high-order interactions
to MLP layers mitigates such performance gap. In response, we propose the
Multi-Order Interaction (MOI) layer, which is capable of expressing an
arbitrary order of interactions within the inputs while maintaining the memory
and time complexity of the MLP layer. By replacing the MLP layer with the MOI
layer, our model was able to achieve comparable performance with
Transformer-based models while retaining the MLP-based models&#x27; computational
benefits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Uncertainty in Learning to Defer Algorithms for Safe Computer-Aided Diagnosis. (arXiv:2108.07392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jessie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_B/0/1/0/all/0/1">Blanca Gallego</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbieri_S/0/1/0/all/0/1">Sebastiano Barbieri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07392">
                                    <div class="article-summary-box-inner">
                                        <span>In this study we propose the Learning to Defer with Uncertainty (LDU)
algorithm, an approach which considers the model&#x27;s predictive uncertainty when
identifying the patient group to be evaluated by human experts. Our aim is to
ensure patient safety when ML models are deployed in healthcare settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model. (arXiv:2108.07467v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sitaula_C/0/1/0/all/0/1">Chiranjibi Sitaula</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jinyuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Priyadarshi_A/0/1/0/all/0/1">Archana Priyadarshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tracy_M/0/1/0/all/0/1">Mark Tracy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kavehei_O/0/1/0/all/0/1">Omid Kavehei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hinder_M/0/1/0/all/0/1">Murray Hinder</a>, <a href="http://arxiv.org/find/cs/1/au:+Withana_A/0/1/0/all/0/1">Anusha Withana</a>, <a href="http://arxiv.org/find/cs/1/au:+McEwan_A/0/1/0/all/0/1">Alistair McEwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzbanrad_F/0/1/0/all/0/1">Faezeh Marzbanrad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07467">
                                    <div class="article-summary-box-inner">
                                        <span>Abdominal auscultation is a convenient, safe and inexpensive method to assess
bowel conditions, which is essential in neonatal care. It helps early detection
of neonatal bowel dysfunctions and allows timely intervention. This paper
presents a neonatal bowel sound detection method to assist the auscultation.
Specifically, a Convolutional Neural Network (CNN) is proposed to classify
peristalsis and non-peristalsis sounds. The classification is then optimized
using a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is
validated on abdominal sounds from 49 newborn infants admitted to our tertiary
Neonatal Intensive Care Unit (NICU). The results show that the method can
effectively detect bowel sounds with accuracy and area under curve (AUC) score
being 89.81% and 83.96% respectively, outperforming 13 baseline methods.
Furthermore, the proposed Laplace HSMM refinement strategy is proven capable to
enhance other bowel sound detection models. The outcomes of this work have the
potential to facilitate future telehealth applications for neonatal care. The
source code of our work can be found at:
https://bitbucket.org/chirudeakin/neonatal-bowel-sound-classification/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning with Correlated Data: Taming the Tail for Age-Optimal Industrial IoT. (arXiv:2108.07504v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen-Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07504">
                                    <div class="article-summary-box-inner">
                                        <span>While information delivery in industrial Internet of things demands
reliability and latency guarantees, the freshness of the controller&#x27;s available
information, measured by the age of information (AoI), is paramount for
high-performing industrial automation. The problem in this work is cast as a
sensor&#x27;s transmit power minimization subject to the peak-AoI requirement and a
probabilistic constraint on queuing latency. We further characterize the tail
behavior of the latency by a generalized Pareto distribution (GPD) for solving
the power allocation problem through Lyapunov optimization. As each sensor
utilizes its own data to locally train the GPD model, we incorporate federated
learning and propose a local-model selection approach which accounts for
correlation among the sensor&#x27;s training data. Numerical results show the
tradeoff between the transmit power, peak AoI, and delay&#x27;s tail distribution.
Furthermore, we verify the superiority of the proposed correlation-aware
approach for selecting the local models in federated learning over an existing
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diagnosis of Acute Myeloid Leukaemia Using Machine Learning. (arXiv:2108.07396v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Angelakis_A/0/1/0/all/0/1">A. Angelakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Soulioti_I/0/1/0/all/0/1">I. Soulioti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07396">
                                    <div class="article-summary-box-inner">
                                        <span>We train a machine learning model on a dataset of 2177 individuals using as
features 26 probe sets and their age in order to classify if someone has acute
myeloid leukaemia or is healthy. The dataset is multicentric and consists of
data from 27 organisations, 25 cities, 15 countries and 4 continents. The
accuracy or our model is 99.94\% and its F1-score 0.9996. To the best of our
knowledge the performance of our model is the best one in the literature, as
regards the prediction of AML using similar or not data. Moreover, there has
not been any bibliographic reference associated with acute myeloid leukaemia
for the 26 probe sets we used as features in our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Compute Approximate Nash Equilibrium for Normal-form Games. (arXiv:2108.07472v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhijian Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiaotie Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07472">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a general meta learning approach to computing
approximate Nash equilibrium for finite $n$-player normal-form games. Unlike
existing solutions that approximate or learn a Nash equilibrium from scratch
for each of the games, our meta solver directly constructs a mapping from a
game utility matrix to a joint strategy profile. The mapping is parameterized
and learned in a self-supervised fashion by a proposed Nash equilibrium
approximation metric without ground truth data informing any Nash equilibrium.
As such, it can immediately predict the joint strategy profile that
approximates a Nash equilibrium for any unseen new game under the same game
distribution. Moreover, the meta-solver can be further fine-tuned and adaptive
to a new game if iteration updates are allowed. We theoretically prove that our
meta-solver is not affected by the non-smoothness of exact Nash equilibrium
solutions, and derive a sample complexity bound to demonstrate its
generalization ability across normal-form games. Experimental results
demonstrate its substantial approximation power against other strong baselines
in both adaptive and non-adaptive cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From the Greene--Wu Convolution to Gradient Estimation over Riemannian Manifolds. (arXiv:2108.07406v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Didong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07406">
                                    <div class="article-summary-box-inner">
                                        <span>Over a complete Riemannian manifold of finite dimension, Greene and Wu
introduced a convolution, known as Greene-Wu (GW) convolution. In this paper,
we introduce a reformulation of the GW convolution. Using our reformulation,
many properties of the GW convolution can be easily derived, including a new
formula for how the curvature of the space would affect the curvature of the
function through the GW convolution. Also enabled by our new reformulation, an
improved method for gradient estimation over Riemannian manifolds is
introduced. Theoretically, our gradient estimation method improves the order of
estimation error from $O \left( \left( n + 3 \right)^{3/2} \right)$ to $O
\left( n^{3/2} \right)$, where $n$ is the dimension of the manifold.
Empirically, our method outperforms the best existing method for gradient
estimation over Riemannian manifolds, as evidenced by thorough experimental
evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Secure and Practical Machine Learning via Secret Sharing and Random Permutation. (arXiv:2108.07463v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Fei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaochao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiaolin Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07463">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing demands for privacy protection, privacy-preserving
machine learning has been drawing much attention in both academia and industry.
However, most existing methods have their limitations in practical
applications. On the one hand, although most cryptographic methods are provable
secure, they bring heavy computation and communication. On the other hand, the
security of many relatively efficient private methods (e.g., federated learning
and split learning) is being questioned, since they are non-provable secure.
Inspired by previous work on privacy-preserving machine learning, we build a
privacy-preserving machine learning framework by combining random permutation
and arithmetic secret sharing via our compute-after-permutation technique.
Since our method reduces the cost for element-wise function computation, it is
more efficient than existing cryptographic methods. Moreover, by adopting
distance correlation as a metric for privacy leakage, we demonstrate that our
method is more secure than previous non-provable secure methods. Overall, our
proposal achieves a good balance between security and efficiency. Experimental
results show that our method not only is up to 6x faster and reduces up to 85%
network traffic compared with state-of-the-art cryptographic methods, but also
leaks less privacy during the training process compared with non-provable
secure methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Protein Using Large-scale Pretrain Language Model. (arXiv:2108.07435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yijia Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jiezhong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Chang-Yu Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07435">
                                    <div class="article-summary-box-inner">
                                        <span>Protein is linked to almost every life process. Therefore, analyzing the
biological structure and property of protein sequences is critical to the
exploration of life, as well as disease detection and drug discovery.
Traditional protein analysis methods tend to be labor-intensive and
time-consuming. The emergence of deep learning models makes modeling data
patterns in large quantities of data possible. Interdisciplinary researchers
have begun to leverage deep learning methods to model large biological
datasets, e.g. using long short-term memory and convolutional neural network
for protein sequence classification. After millions of years of evolution,
evolutionary information is encoded in protein sequences. Inspired by the
similarity between natural language and protein sequences, we use large-scale
language models to model evolutionary-scale protein sequences, encoding protein
biology information in representation. Significant improvements are observed in
both token-level and sequence-level tasks, demonstrating that our large-scale
model can accurately capture evolution information from pretraining on
evolutionary-scale individual sequences. Our code and model are available at
https://github.com/THUDM/ProteinLM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-Efficient Factorization Machines via Binarizing both Data and Model Coefficients. (arXiv:2108.07421v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1">Yu Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1">Liang Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07421">
                                    <div class="article-summary-box-inner">
                                        <span>Factorization Machines (FM), a general predictor that can efficiently model
feature interactions in linear time, was primarily proposed for collaborative
recommendation and have been broadly used for regression, classification and
ranking tasks. Subspace Encoding Factorization Machine (SEFM) has been proposed
recently to overcome the expressiveness limitation of Factorization Machines
(FM) by applying explicit nonlinear feature mapping for both individual
features and feature interactions through one-hot encoding to each input
feature. Despite the effectiveness of SEFM, it increases the memory cost of FM
by $b$ times, where $b$ is the number of bins when applying one-hot encoding on
each input feature. To reduce the memory cost of SEFM, we propose a new method
called Binarized FM which constraints the model parameters to be binary values
(i.e., 1 or $-1$). Then each parameter value can be efficiently stored in one
bit. Our proposed method can significantly reduce the memory cost of SEFM
model. In addition, we propose a new algorithm to effectively and efficiently
learn proposed FM with binary constraints using Straight Through Estimator
(STE) with Adaptive Gradient Descent (Adagrad). Finally, we evaluate the
performance of our proposed method on eight different classification datasets.
Our experimental results have demonstrated that our proposed method achieves
comparable accuracy with SEFM but with much less memory cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextual Convolutional Neural Networks. (arXiv:2108.07387v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duta_I/0/1/0/all/0/1">Ionut Cosmin Duta</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgescu_M/0/1/0/all/0/1">Mariana Iuliana Georgescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07387">
                                    <div class="article-summary-box-inner">
                                        <span>We propose contextual convolution (CoConv) for visual recognition. CoConv is
a direct replacement of the standard convolution, which is the core component
of convolutional neural networks. CoConv is implicitly equipped with the
capability of incorporating contextual information while maintaining a similar
number of parameters and computational cost compared to the standard
convolution. CoConv is inspired by neuroscience studies indicating that (i)
neurons, even from the primary visual cortex (V1 area), are involved in
detection of contextual cues and that (ii) the activity of a visual neuron can
be influenced by the stimuli placed entirely outside of its theoretical
receptive field. On the one hand, we integrate CoConv in the widely-used
residual networks and show improved recognition performance over baselines on
the core tasks and benchmarks for visual recognition, namely image
classification on the ImageNet data set and object detection on the MS COCO
data set. On the other hand, we introduce CoConv in the generator of a
state-of-the-art Generative Adversarial Network, showing improved generative
results on CIFAR-10 and CelebA. Our code is available at
https://github.com/iduta/coconv.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Biased Subgroups in Ranking and Classification. (arXiv:2108.07450v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pastor_E/0/1/0/all/0/1">Eliana Pastor</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfaro_L/0/1/0/all/0/1">Luca de Alfaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Baralis_E/0/1/0/all/0/1">Elena Baralis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07450">
                                    <div class="article-summary-box-inner">
                                        <span>When analyzing the behavior of machine learning algorithms, it is important
to identify specific data subgroups for which the considered algorithm shows
different performance with respect to the entire dataset. The intervention of
domain experts is normally required to identify relevant attributes that define
these subgroups.

We introduce the notion of divergence to measure this performance difference
and we exploit it in the context of (i) classification models and (ii) ranking
applications to automatically detect data subgroups showing a significant
deviation in their behavior. Furthermore, we quantify the contribution of all
attributes in the data subgroup to the divergent behavior by means of Shapley
values, thus allowing the identification of the most impacting attributes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating a Baseline Of Self Supervised Learning Towards Reducing Labeling Costs For Image Classification. (arXiv:2108.07464v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+AlQuabeh_H/0/1/0/all/0/1">Hilal AlQuabeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bawazeer_A/0/1/0/all/0/1">Ameera Bawazeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Alhashmi_A/0/1/0/all/0/1">Abdulateef Alhashmi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07464">
                                    <div class="article-summary-box-inner">
                                        <span>Data labeling in supervised learning is considered an expensive and
infeasible tool in some conditions. The self-supervised learning method is
proposed to tackle the learning effectiveness with fewer labeled data, however,
there is a lack of confidence in the size of labeled data needed to achieve
adequate results. This study aims to draw a baseline on the proportion of the
labeled data that models can appreciate to yield competent accuracy when
compared to training with additional labels. The study implements the
kaggle.com&#x27; cats-vs-dogs dataset, Mnist and Fashion-Mnist to investigate the
self-supervised learning task by implementing random rotations augmentation on
the original datasets. To reveal the true effectiveness of the pretext process
in self-supervised learning, the original dataset is divided into smaller
batches, and learning is repeated on each batch with and without the pretext
pre-training. Results show that the pretext process in the self-supervised
learning improves the accuracy around 15% in the downstream classification task
when compared to the plain supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aggregation Delayed Federated Learning. (arXiv:2108.07433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Ye Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1">Diego Klabjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yuan Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07433">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is a distributed machine learning paradigm where multiple
data owners (clients) collaboratively train one machine learning model while
keeping data on their own devices. The heterogeneity of client datasets is one
of the most important challenges of federated learning algorithms. Studies have
found performance reduction with standard federated algorithms, such as FedAvg,
on non-IID data. Many existing works on handling non-IID data adopt the same
aggregation framework as FedAvg and focus on improving model updates either on
the server side or on clients. In this work, we tackle this challenge in a
different view by introducing redistribution rounds that delay the aggregation.
We perform experiments on multiple tasks and show that the proposed framework
significantly improves the performance on non-IID data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Common Waveforms Including a Watchdog for Unknown Signals. (arXiv:2108.07339v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fredieu_C/0/1/0/all/0/1">C. Tanner Fredieu</a>, <a href="http://arxiv.org/find/eess/1/au:+Bui_J/0/1/0/all/0/1">Justin Bui</a>, <a href="http://arxiv.org/find/eess/1/au:+Martone_A/0/1/0/all/0/1">Anthony Martone</a>, <a href="http://arxiv.org/find/eess/1/au:+Marks_R/0/1/0/all/0/1">Robert J. Marks II</a>, <a href="http://arxiv.org/find/eess/1/au:+Baylis_C/0/1/0/all/0/1">Charles Baylis</a>, <a href="http://arxiv.org/find/eess/1/au:+Buehrer_R/0/1/0/all/0/1">R. Michael Buehrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07339">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we examine the use of a deep multi-layer perceptron model
architecture to classify received signal samples as coming from one of four
common waveforms, Single Carrier (SC), Single-Carrier Frequency Division
Multiple Access (SC-FDMA), Orthogonal Frequency Division Multiplexing (OFDM),
and Linear Frequency Modulation (LFM), used in communication and radar
networks. Synchronization of the signals is not needed as we assume there is an
unknown and uncompensated time and frequency offset. An autoencoder with a deep
CNN architecture is also examined to create a new fifth classification category
of an unknown waveform type. This is accomplished by calculating a minimum and
maximum threshold values from the root mean square error (RMSE) of the radar
and communication waveforms. The classifier and autoencoder work together to
monitor a spectrum area to identify the common waveforms inside the area of
operation along with detecting unknown waveforms. Results from testing showed
the classifier had 100\% classification rate above 0 dB with accuracy of 83.2\%
and 94.7\% at -10 dB and -5 dB, respectively, with signal impairments present.
Results for the anomaly detector showed 85.3\% accuracy at 0 dB with 100\% at
SNR greater than 0 dB with signal impairments present when using a high-value
Fast Fourier Transform (FFT) size. Accurate detection rates decline as
additional noise is introduced to the signals, with 78.1\% at -5 dB and 56.5\%
at -10 dB. However, these low rates seen can be potentially mitigated by using
even higher FFT sizes also shown in our results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An End-to-End Deep Learning Approach for Epileptic Seizure Prediction. (arXiv:2108.07453v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yankun Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1">Shiqi Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_H/0/1/0/all/0/1">Hemmings Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sawan_M/0/1/0/all/0/1">Mohamad Sawan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07453">
                                    <div class="article-summary-box-inner">
                                        <span>An accurate seizure prediction system enables early warnings before seizure
onset of epileptic patients. It is extremely important for drug-refractory
patients. Conventional seizure prediction works usually rely on features
extracted from Electroencephalography (EEG) recordings and classification
algorithms such as regression or support vector machine (SVM) to locate the
short time before seizure onset. However, such methods cannot achieve
high-accuracy prediction due to information loss of the hand-crafted features
and the limited classification ability of regression and SVM algorithms. We
propose an end-to-end deep learning solution using a convolutional neural
network (CNN) in this paper. One and two dimensional kernels are adopted in the
early- and late-stage convolution and max-pooling layers, respectively. The
proposed CNN model is evaluated on Kaggle intracranial and CHB-MIT scalp EEG
datasets. Overall sensitivity, false prediction rate, and area under receiver
operating characteristic curve reaches 93.5%, 0.063/h, 0.981 and 98.8%,
0.074/h, 0.988 on two datasets respectively. Comparison with state-of-the-art
works indicates that the proposed model achieves exceeding prediction
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BOBCAT: Bilevel Optimization-Based Computerized Adaptive Testing. (arXiv:2108.07386v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Aritra Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_A/0/1/0/all/0/1">Andrew Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07386">
                                    <div class="article-summary-box-inner">
                                        <span>Computerized adaptive testing (CAT) refers to a form of tests that are
personalized to every student/test taker. CAT methods adaptively select the
next most informative question/item for each student given their responses to
previous questions, effectively reducing test length. Existing CAT methods use
item response theory (IRT) models to relate student ability to their responses
to questions and static question selection algorithms designed to reduce the
ability estimation error as quickly as possible; therefore, these algorithms
cannot improve by learning from large-scale student response data. In this
paper, we propose BOBCAT, a Bilevel Optimization-Based framework for CAT to
directly learn a data-driven question selection algorithm from training data.
BOBCAT is agnostic to the underlying student response model and is
computationally efficient during the adaptive testing process. Through
extensive experiments on five real-world student response datasets, we show
that BOBCAT outperforms existing CAT methods (sometimes significantly) at
reducing test length.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">InfoGram and Admissible Machine Learning. (arXiv:2108.07380v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mukhopadhyay_S/0/1/0/all/0/1">Subhadeep Mukhopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07380">
                                    <div class="article-summary-box-inner">
                                        <span>We have entered a new era of machine learning (ML), where the most accurate
algorithm with superior predictive power may not even be deployable, unless it
is admissible under the regulatory constraints. This has led to great interest
in developing fair, transparent and trustworthy ML methods. The purpose of this
article is to introduce a new information-theoretic learning framework
(admissible machine learning) and algorithmic risk-management tools (InfoGram,
L-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf
ML methods to be regulatory compliant, while maintaining good prediction
accuracy. We have illustrated our approach using several real-data examples
from financial sectors, biomedical research, marketing campaigns, and the
criminal justice system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FARF: A Fair and Adaptive Random Forests Classifier. (arXiv:2108.07403v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bifet_A/0/1/0/all/0/1">Albert Bifet</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangliang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1">Jeremy C. Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Nejdl_W/0/1/0/all/0/1">Wolfgang Nejdl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07403">
                                    <div class="article-summary-box-inner">
                                        <span>As Artificial Intelligence (AI) is used in more applications, the need to
consider and mitigate biases from the learned models has followed. Most works
in developing fair learning algorithms focus on the offline setting. However,
in many real-world applications data comes in an online fashion and needs to be
processed on the fly. Moreover, in practical application, there is a trade-off
between accuracy and fairness that needs to be accounted for, but current
methods often have multiple hyperparameters with non-trivial interaction to
achieve fairness. In this paper, we propose a flexible ensemble algorithm for
fair decision-making in the more challenging context of evolving online
settings. This algorithm, called FARF (Fair and Adaptive Random Forests), is
based on using online component classifiers and updating them according to the
current distribution, that also accounts for fairness and a single
hyperparameters that alters fairness-accuracy balance. Experiments on
real-world discriminated data streams demonstrate the utility of FARF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Cluster via Same-Cluster Queries. (arXiv:2108.07383v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07383">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of learning to cluster data points using an oracle which
can answer same-cluster queries. Different from previous approaches, we do not
assume that the total number of clusters is known at the beginning and do not
require that the true clusters are consistent with a predefined objective
function such as the K-means. These relaxations are critical from the practical
perspective and, meanwhile, make the problem more challenging. We propose two
algorithms with provable theoretical guarantees and verify their effectiveness
via an extensive set of experiments on both synthetic and real-world data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Classification Using Group-Level Labels. (arXiv:2108.07330v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1">Guruprasad Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1">Rahul Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaowei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07330">
                                    <div class="article-summary-box-inner">
                                        <span>In many applications, finding adequate labeled data to train predictive
models is a major challenge. In this work, we propose methods to use
group-level binary labels as weak supervision to train instance-level binary
classification models. Aggregate labels are common in several domains where
annotating on a group-level might be cheaper or might be the only way to
provide annotated data without infringing on privacy. We model group-level
labels as Class Conditional Noisy (CCN) labels for individual instances and use
the noisy labels to regularize predictions of the model trained on the
strongly-labeled instances. Our experiments on real-world application of land
cover mapping shows the utility of the proposed method in leveraging
group-level labels, both in the presence and absence of class imbalance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthesizing Pareto-Optimal Interpretations for Black-Box Models. (arXiv:2108.07307v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Torfah_H/0/1/0/all/0/1">Hazem Torfah</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Shetal Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Supratik Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Akshay_S/0/1/0/all/0/1">S. Akshay</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1">Sanjit A. Seshia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07307">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new multi-objective optimization approach for synthesizing
interpretations that &quot;explain&quot; the behavior of black-box machine learning
models. Constructing human-understandable interpretations for black-box models
often requires balancing conflicting objectives. A simple interpretation may be
easier to understand for humans while being less precise in its predictions
vis-a-vis a complex interpretation. Existing methods for synthesizing
interpretations use a single objective function and are often optimized for a
single class of interpretations. In contrast, we provide a more general and
multi-objective synthesis framework that allows users to choose (1) the class
of syntactic templates from which an interpretation should be synthesized, and
(2) quantitative measures on both the correctness and explainability of an
interpretation. For a given black-box, our approach yields a set of
Pareto-optimal interpretations with respect to the correctness and
explainability measures. We show that the underlying multi-objective
optimization problem can be solved via a reduction to quantitative constraint
solving, such as weighted maximum satisfiability. To demonstrate the benefits
of our approach, we have applied it to synthesize interpretations for black-box
neural-network classifiers. Our experiments show that there often exists a rich
and varied set of choices for interpretations that are missed by existing
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IsoScore: Measuring the Uniformity of Vector Space Utilization. (arXiv:2108.07344v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rudman_W/0/1/0/all/0/1">William Rudman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillman_N/0/1/0/all/0/1">Nate Gillman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rayne_T/0/1/0/all/0/1">Taylor Rayne</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07344">
                                    <div class="article-summary-box-inner">
                                        <span>The recent success of distributed word representations has led to an
increased interest in analyzing the properties of their spatial distribution.
Current metrics suggest that contextualized word embedding models do not
uniformly utilize all dimensions when embedding tokens in vector space. Here we
argue that existing metrics are fragile and tend to obfuscate the true spatial
distribution of point clouds. To ameliorate this issue, we propose IsoScore: a
novel metric which quantifies the degree to which a point cloud uniformly
utilizes the ambient vector space. We demonstrate that IsoScore has several
desirable properties such as mean invariance and direct correspondence to the
number of dimensions used, which are properties that existing scores do not
possess. Furthermore, IsoScore is conceptually intuitive and computationally
efficient, making it well suited for analyzing the distribution of point clouds
in arbitrary vector spaces, not necessarily limited to those of word embeddings
alone. Additionally, we use IsoScore to demonstrate that a number of recent
conclusions in the NLP literature that have been derived using brittle metrics
of spatial distribution, such as average cosine similarity, may be incomplete
or altogether inaccurate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-tuning is Fine in Federated Learning. (arXiv:2108.07313v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Gary Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chadha_K/0/1/0/all/0/1">Karan Chadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchi_J/0/1/0/all/0/1">John Duchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07313">
                                    <div class="article-summary-box-inner">
                                        <span>We study the performance of federated learning algorithms and their variants
in an asymptotic framework. Our starting point is the formulation of federated
learning as a multi-criterion objective, where the goal is to minimize each
client&#x27;s loss using information from all of the clients. We propose a linear
regression model, where, for a given client, we theoretically compare the
performance of various algorithms in the high-dimensional asymptotic limit.
This asymptotic multi-criterion approach naturally models the high-dimensional,
many-device nature of federated learning and suggests that personalization is
central to federated learning. Our theory suggests that Fine-tuned Federated
Averaging (FTFA), i.e., Federated Averaging followed by local training, and the
ridge regularized variant Ridge-tuned Federated Averaging (RTFA) are
competitive with more sophisticated meta-learning and proximal-regularized
approaches. In addition to being conceptually simpler, FTFA and RTFA are
computationally more efficient than its competitors. We corroborate our
theoretical claims with extensive experiments on federated versions of the
EMNIST, CIFAR-100, Shakespeare, and Stack Overflow datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic optimization under time drift: iterate averaging, step decay, and high probability guarantees. (arXiv:2108.07356v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cutler_J/0/1/0/all/0/1">Joshua Cutler</a>, <a href="http://arxiv.org/find/math/1/au:+Drusvyatskiy_D/0/1/0/all/0/1">Dmitriy Drusvyatskiy</a>, <a href="http://arxiv.org/find/math/1/au:+Harchaoui_Z/0/1/0/all/0/1">Zaid Harchaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07356">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of minimizing a convex function that is evolving in
time according to unknown and possibly stochastic dynamics. Such problems
abound in the machine learning and signal processing literature, under the
names of concept drift and stochastic tracking. We provide novel non-asymptotic
convergence guarantees for stochastic algorithms with iterate averaging,
focusing on bounds valid both in expectation and with high probability.
Notably, we show that the tracking efficiency of the proximal stochastic
gradient method depends only logarithmically on the initialization quality,
when equipped with a step-decay schedule. The results moreover naturally extend
to settings where the dynamics depend jointly on time and on the decision
variable itself, as in the performative prediction framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterotic String Model Building with Monad Bundles and Reinforcement Learning. (arXiv:2108.07316v1 [hep-th])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-th/1/au:+Constantin_A/0/1/0/all/0/1">Andrei Constantin</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Harvey_T/0/1/0/all/0/1">Thomas R. Harvey</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Lukas_A/0/1/0/all/0/1">Andre Lukas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07316">
                                    <div class="article-summary-box-inner">
                                        <span>We use reinforcement learning as a means of constructing string
compactifications with prescribed properties. Specifically, we study heterotic
SO(10) GUT models on Calabi-Yau three-folds with monad bundles, in search of
phenomenologically promising examples. Due to the vast number of bundles and
the sparseness of viable choices, methods based on systematic scanning are not
suitable for this class of models. By focusing on two specific manifolds with
Picard numbers two and three, we show that reinforcement learning can be used
successfully to explore monad bundles. Training can be accomplished with
minimal computing resources and leads to highly efficient policy networks. They
produce phenomenologically promising states for nearly 100% of episodes and
within a small number of steps. In this way, hundreds of new candidate standard
models are found.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the factors driving the opioid epidemic using machine learning. (arXiv:2108.07301v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gavali_S/0/1/0/all/0/1">Sachin Gavali</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chuming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cowart_J/0/1/0/all/0/1">Julie Cowart</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shanshan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cathy Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_T/0/1/0/all/0/1">Tammy Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07301">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the US has experienced an opioid epidemic with an
unprecedented number of drugs overdose deaths. Research finds such overdose
deaths are linked to neighborhood-level traits, thus providing opportunity to
identify effective interventions. Typically, techniques such as Ordinary Least
Squares (OLS) or Maximum Likelihood Estimation (MLE) are used to document
neighborhood-level factors significant in explaining such adverse outcomes.
These techniques are, however, less equipped to ascertain non-linear
relationships between confounding factors. Hence, in this study we apply
machine learning based techniques to identify opioid risks of neighborhoods in
Delaware and explore the correlation of these factors using Shapley Additive
explanations (SHAP). We discovered that the factors related to neighborhoods
environment, followed by education and then crime, were highly correlated with
higher opioid risk. We also explored the change in these correlations over the
years to understand the changing dynamics of the epidemic. Furthermore, we
discovered that, as the epidemic has shifted from legal (i.e., prescription
opioids) to illegal (e.g.,heroin and fentanyl) drugs in recent years, the
correlation of environment, crime and health related variables with the opioid
risk has increased significantly while the correlation of economic and
socio-demographic variables has decreased. The correlation of education related
factors has been higher from the start and has increased slightly in recent
years suggesting a need for increased awareness about the opioid epidemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Emotion Recognition with Audio-visual Leader-follower Attentive Fusion. (arXiv:2107.01175v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the test (validation)
set of the Aff-Wild2 database, the achieved CCC is 0.463 (0.469) for valence
and 0.492 (0.649) for arousal, which significantly outperforms the baseline
method with the corresponding CCC of 0.200 (0.210) and 0.190 (0.230) for
valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-17">2021-08-17</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FUDGE: Controlled Text Generation With Future Discriminators. (arXiv:2104.05218v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05218">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Future Discriminators for Generation (FUDGE), a flexible and
modular method for controlled text generation. Given a pre-existing model G for
generating text from a distribution of interest, FUDGE enables conditioning on
a desired attribute a (for example, formality) while requiring access only to
G&#x27;s output logits. FUDGE learns an attribute predictor operating on a partial
sequence, and uses this predictor&#x27;s outputs to adjust G&#x27;s original
probabilities. We show that FUDGE models terms corresponding to a Bayesian
decomposition of the conditional distribution of G given attribute a. Moreover,
FUDGE can easily compose predictors for multiple desired attributes. We
evaluate FUDGE on three tasks -- couplet completion in poetry, topic control in
language generation, and formality change in machine translation -- and observe
gains in all three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noisy Channel Language Model Prompting for Few-Shot Text Classification. (arXiv:2108.04106v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1">Sewon Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Mike Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04106">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a noisy channel approach for language model prompting in
few-shot text classification. Instead of computing the likelihood of the label
given the input (referred as direct models), channel models compute the
conditional probability of the input given the label, and are thereby required
to explain every word in the input. We use channel models for recently proposed
few-shot learning methods with no or very limited updates to the language model
parameters, via either in-context demonstration or prompt tuning. Our
experiments show that, for both methods, channel models significantly
outperform their direct counterparts, which we attribute to their stability,
i.e., lower variance and higher worst-case accuracy. We also present extensive
ablations that provide recommendations for when to use channel prompt tuning
instead of other competitive models (e.g., direct head tuning): channel prompt
tuning is preferred when the number of training examples is small, labels in
the training data are imbalanced, or generalization to unseen labels is
required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clinical Relation Extraction Using Transformer-based Models. (arXiv:2107.08957v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zehao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08957">
                                    <div class="article-summary-box-inner">
                                        <span>The newly emerged transformer technology has a tremendous impact on NLP
research. In the general English domain, transformer-based models have achieved
state-of-the-art performances on various NLP benchmarks. In the clinical
domain, researchers also have investigated transformer models for clinical
applications. The goal of this study is to systematically explore three widely
used transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical
relation extraction and develop an open-source package with clinical
pre-trained transformer-based models to facilitate information extraction in
the clinical domain. We developed a series of clinical RE models based on three
transformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these
models using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2
challenges. We compared two classification strategies (binary vs. multi-class
classification) and investigated two approaches to generate candidate relations
in different experimental settings. In this study, we compared three
transformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We
demonstrated that the RoBERTa-clinical RE model achieved the best performance
on the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2
dataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our
results indicated that the binary classification strategy consistently
outperformed the multi-class classification strategy for clinical relation
extraction. Our methods and models are publicly available at
https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.
We believe this work will improve current practice on clinical relation
extraction and other related NLP tasks in the biomedical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task. (arXiv:2107.06959v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yun Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1">Hongyu Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1">Juan Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1">Holger Schwenk</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1">Naman Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06959">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we describe our end-to-end multilingual speech translation
system submitted to the IWSLT 2021 evaluation campaign on the Multilingual
Speech Translation shared task. Our system is built by leveraging transfer
learning across modalities, tasks and languages. First, we leverage
general-purpose multilingual modules pretrained with large amounts of
unlabelled and labelled data. We further enable knowledge transfer from the
text task to the speech task by training two tasks jointly. Finally, our
multilingual model is finetuned on speech translation task-specific data to
achieve the best translation results. Experimental results show our system
outperforms the reported systems, including both end-to-end and cascaded based
approaches, by a large margin.

In some translation directions, our speech translation results evaluated on
the public Multilingual TEDx test set are even comparable with the ones from a
strong text-to-text translation system, which uses the oracle speech
transcripts as input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition. (arXiv:2104.09106v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1">Mohammad Zeineldeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zuoyun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09106">
                                    <div class="article-summary-box-inner">
                                        <span>Subword units are commonly used for end-to-end automatic speech recognition
(ASR), while a fully acoustic-oriented subword modeling approach is somewhat
missing. We propose an acoustic data-driven subword modeling (ADSM) approach
that adapts the advantages of several text-based and acoustic-based subword
methods into one pipeline. With a fully acoustic-oriented label design and
learning process, ADSM produces acoustic-structured subword units and
acoustic-matched target sequence for further ASR training. The obtained ADSM
labels are evaluated with different end-to-end ASR approaches including CTC,
RNN-Transducer and attention models. Experiments on the LibriSpeech corpus show
that ADSM clearly outperforms both byte pair encoding (BPE) and
pronunciation-assisted subword modeling (PASM) in all cases. Detailed analysis
shows that ADSM achieves acoustically more logical word segmentation and more
balanced sequence length, and thus, is suitable for both time-synchronous and
label-synchronous models. We also briefly describe how to apply acoustic-based
subword regularization and unseen text segmentation using ADSM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM. (arXiv:2104.04473v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narayanan_D/0/1/0/all/0/1">Deepak Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Casper_J/0/1/0/all/0/1">Jared Casper</a>, <a href="http://arxiv.org/find/cs/1/au:+LeGresley_P/0/1/0/all/0/1">Patrick LeGresley</a>, <a href="http://arxiv.org/find/cs/1/au:+Patwary_M/0/1/0/all/0/1">Mostofa Patwary</a>, <a href="http://arxiv.org/find/cs/1/au:+Korthikanti_V/0/1/0/all/0/1">Vijay Anand Korthikanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainbrand_D/0/1/0/all/0/1">Dmitri Vainbrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashinkunti_P/0/1/0/all/0/1">Prethvi Kashinkunti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernauer_J/0/1/0/all/0/1">Julie Bernauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Phanishayee_A/0/1/0/all/0/1">Amar Phanishayee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1">Matei Zaharia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04473">
                                    <div class="article-summary-box-inner">
                                        <span>Large language models have led to state-of-the-art accuracies across a range
of tasks. However, training these models efficiently is challenging for two
reasons: a) GPU memory capacity is limited, making it impossible to fit large
models on even a multi-GPU server, and b) the number of compute operations
required to train these models can result in unrealistically long training
times. Consequently, new methods of model parallelism such as tensor and
pipeline parallelism have been proposed. Unfortunately, naive usage of these
methods leads to fundamental scaling issues at thousands of GPUs, e.g., due to
expensive cross-node communication or devices spending significant time waiting
on other devices to make progress.

In this paper, we show how different types of parallelism methods (tensor,
pipeline, and data parallelism) can be composed to scale to thousands of GPUs
and models with trillions of parameters. We survey techniques for pipeline
parallelism and propose a novel interleaved pipeline parallelism schedule that
can improve throughput by 10+% with memory footprint comparable to existing
approaches. We quantitatively study the trade-offs between tensor, pipeline,
and data parallelism, and provide intuition as to how to configure distributed
training of a large model. Our approach allows us to perform training
iterations on a model with 1 trillion parameters at 502 petaFLOP/s on 3072 GPUs
with achieved per-GPU throughput of 52% of theoretical peak. Our code is open
sourced at https://github.com/nvidia/megatron-lm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09261">
                                    <div class="article-summary-box-inner">
                                        <span>The existence of multiple datasets for sarcasm detection prompts us to apply
transfer learning to exploit their commonality. The adversarial neural transfer
(ANT) framework utilizes multiple loss terms that encourage the source-domain
and the target-domain feature distributions to be similar while optimizing for
domain-specific performance. However, these objectives may be in conflict,
which can lead to optimization difficulties and sometimes diminished transfer.
We propose a generalized latent optimization strategy that allows different
losses to accommodate each other and improves training dynamics. The proposed
method outperforms transfer learning and meta-learning baselines. In
particular, we achieve 10.02% absolute performance gain over the previous state
of the art on the iSarcasm dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MathBERT: A Pre-trained Language Model for General NLP Tasks in Mathematics Education. (arXiv:2106.07340v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jia Tracy Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamashita_M/0/1/0/all/0/1">Michiharu Yamashita</a>, <a href="http://arxiv.org/find/cs/1/au:+Prihar_E/0/1/0/all/0/1">Ethan Prihar</a>, <a href="http://arxiv.org/find/cs/1/au:+Heffernan_N/0/1/0/all/0/1">Neil Heffernan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xintao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Graff_B/0/1/0/all/0/1">Ben Graff</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dongwon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07340">
                                    <div class="article-summary-box-inner">
                                        <span>Since the introduction of the original BERT (i.e., BASE BERT), researchers
have developed various customized BERT models with improved performance for
specific domains and tasks by exploiting the benefits of {\em transfer
learning}. Due to the nature of mathematical texts, which often use domain
specific vocabulary along with equations and math symbols, we posit that the
development of a new BERT model for mathematics would be useful for many
mathematical downstream tasks. In this resource paper, we introduce our
multi-institutional effort (i.e., two learning platforms and three academic
institutions in the US) toward this need: MathBERT, a model created by
pre-training the BASE BERT model on a large mathematical corpus ranging from
pre-kindergarten (pre-k), to high-school, to college graduate level
mathematical content. In addition, we select three general NLP tasks that are
often used in mathematics education: prediction of knowledge component,
auto-grading open-ended Q\&amp;A, and knowledge tracing, to demonstrate the
superiority of MathBERT over BASE BERT. Our experiments show that MathBERT
outperforms prior best methods by 1.2-22\% and BASE BERT by 2-8\% on these
tasks. In addition, we build a mathematics specific vocabulary &#x60;mathVocab&#x27; to
train with MathBERT. We discover that MathBERT pre-trained with &#x60;mathVocab&#x27;
outperforms MathBERT trained with the BASE BERT vocabulary (i.e., &#x60;origVocab&#x27;).
MathBERT is currently being adopted at the participated leaning platforms:
Stride, Inc, a commercial educational resource provider, and ASSISTments.org, a
free online educational platform. We release MathBERT for public usage at:
https://github.com/tbs17/MathBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferability of Neural Network-based De-identification Systems. (arXiv:2102.08517v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kahyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobbins_N/0/1/0/all/0/1">Nicholas J. Dobbins</a>, <a href="http://arxiv.org/find/cs/1/au:+McInnes_B/0/1/0/all/0/1">Bridget McInnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1">Meliha Yetisgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1">&#xd6;zlem Uzuner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08517">
                                    <div class="article-summary-box-inner">
                                        <span>Methods and Materials: We investigated transferability of neural
network-based de-identification sys-tems with and without domain
generalization. We used two domain generalization approaches: a novel approach
Joint-Domain Learning (JDL) as developed in this paper, and a state-of-the-art
domain general-ization approach Common-Specific Decomposition (CSD) from the
literature. First, we measured trans-ferability from a single external source.
Second, we used two external sources and evaluated whether domain
generalization can improve transferability of de-identification models across
domains which rep-resent different note types from the same institution. Third,
using two external sources with in-domain training data, we studied whether
external source data are useful even in cases where sufficient in-domain
training data are available. Finally, we investigated transferability of the
de-identification mod-els across institutions. Results and Conclusions: We
found transferability from a single external source gave inconsistent re-sults.
Using additional external sources consistently yielded an F1-score of
approximately 80%, but domain generalization was not always helpful to improve
transferability. We also found that external sources were useful even in cases
where in-domain training data were available by reducing the amount of needed
in-domain training data or by improving performance. Transferability across
institutions was differed by note type and annotation label. External sources
from a different institution were also useful to further improve performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Effect of Domain and Diacritics in Yor\&#x60;ub\&#x27;a-English Neural Machine Translation. (arXiv:2103.08647v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1">David I. Adelani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiter_D/0/1/0/all/0/1">Dana Ruiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1">Jesujoba O. Alabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Adebonojo_D/0/1/0/all/0/1">Damilola Adebonojo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayeni_A/0/1/0/all/0/1">Adesina Ayeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeyemi_M/0/1/0/all/0/1">Mofe Adeyemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Awokoya_A/0/1/0/all/0/1">Ayodele Awokoya</a>, <a href="http://arxiv.org/find/cs/1/au:+Espana_Bonet_C/0/1/0/all/0/1">Cristina Espa&#xf1;a-Bonet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08647">
                                    <div class="article-summary-box-inner">
                                        <span>Massively multilingual machine translation (MT) has shown impressive
capabilities, including zero and few-shot translation between low-resource
language pairs. However, these models are often evaluated on high-resource
languages with the assumption that they generalize to low-resource ones. The
difficulty of evaluating MT models on low-resource pairs is often due to lack
of standardized evaluation datasets. In this paper, we present MENYO-20k, the
first multi-domain parallel corpus with a special focus on clean orthography
for Yor\&#x60;ub\&#x27;a--English with standardized train-test splits for benchmarking.
We provide several neural MT benchmarks and compare them to the performance of
popular pre-trained (massively multilingual) MT models both for the
heterogeneous test set and its subdomains. Since these pre-trained models use
huge amounts of data with uncertain quality, we also analyze the effect of
diacritics, a major characteristic of Yor\&#x60;ub\&#x27;a, in the training data. We
investigate how and when this training condition affects the final quality and
intelligibility of a translation. Our models outperform massively multilingual
models such as Google ($+8.7$ BLEU) and Facebook M2M ($+9.1$ BLEU) when
translating to Yor\&#x60;ub\&#x27;a, setting a high quality benchmark for future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">In Defense of Scene Graphs for Image Captioning. (arXiv:2102.04990v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Subarna Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bang Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_T/0/1/0/all/0/1">Tanaya Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Truong Q. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04990">
                                    <div class="article-summary-box-inner">
                                        <span>The mainstream image captioning models rely on Convolutional Neural Network
(CNN) image features to generate captions via recurrent models. Recently, image
scene graphs have been used to augment captioning models so as to leverage
their structural semantics, such as object entities, relationships and
attributes. Several studies have noted that the naive use of scene graphs from
a black-box scene graph generator harms image captioning performance and that
scene graph-based captioning models have to incur the overhead of explicit use
of image features to generate decent captions. Addressing these challenges, we
propose \textbf{SG2Caps}, a framework that utilizes only the scene graph labels
for competitive image captioning performance. The basic idea is to close the
semantic gap between the two scene graphs - one derived from the input image
and the other from its caption. In order to achieve this, we leverage the
spatial location of objects and the Human-Object-Interaction (HOI) labels as an
additional HOI graph. SG2Caps outperforms existing scene graph-only captioning
models by a large margin, indicating scene graphs as a promising representation
for image captioning. Direct utilization of scene graph labels avoids expensive
graph convolutions over high-dimensional CNN features resulting in 49% fewer
trainable parameters. Our code is available at:
https://github.com/Kien085/SG2Caps</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VLG-Net: Video-Language Graph Matching Network for Video Grounding. (arXiv:2011.10132v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soldan_M/0/1/0/all/0/1">Mattia Soldan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengmeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1">Sisi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1">Jesper Tegner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10132">
                                    <div class="article-summary-box-inner">
                                        <span>Grounding language queries in videos aims at identifying the time interval
(or moment) semantically relevant to a language query. The solution to this
challenging task demands understanding videos&#x27; and queries&#x27; semantic content
and the fine-grained reasoning about their multi-modal interactions. Our key
idea is to recast this challenge into an algorithmic graph matching problem.
Fueled by recent advances in Graph Neural Networks, we propose to leverage
Graph Convolutional Networks to model video and textual information as well as
their semantic alignment. To enable the mutual exchange of information across
the modalities, we design a novel Video-Language Graph Matching Network
(VLG-Net) to match video and query graphs. Core ingredients include
representation graphs built atop video snippets and query tokens separately and
used to model intra-modality relationships. A Graph Matching layer is adopted
for cross-modal context modeling and multi-modal fusion. Finally, moment
candidates are created using masked moment attention pooling by fusing the
moment&#x27;s enriched snippet features. We demonstrate superior performance over
state-of-the-art grounding methods on three widely used datasets for temporal
localization of moments in videos with language queries: ActivityNet-Captions,
TACoS, and DiDeMo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vocabulary Learning via Optimal Transport for Neural Machine Translation. (arXiv:2012.15671v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zaixiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15671">
                                    <div class="article-summary-box-inner">
                                        <span>The choice of token vocabulary affects the performance of machine
translation. This paper aims to figure out what is a good vocabulary and
whether one can find the optimal vocabulary without trial training. To answer
these questions, we first provide an alternative understanding of the role of
vocabulary from the perspective of information theory. Motivated by this, we
formulate the quest of vocabularization -- finding the best token dictionary
with a proper size -- as an optimal transport (OT) problem. We propose VOLT, a
simple and efficient solution without trial training. Empirical results show
that VOLT outperforms widely-used vocabularies in diverse scenarios, including
WMT-14 English-German and TED&#x27;s 52 translation directions. For example, VOLT
achieves almost 70% vocabulary size reduction and 0.5 BLEU gain on
English-German translation. Also, compared to BPE-search, VOLT reduces the
search time from 384 GPU hours to 30 GPU hours on English-German translation.
Codes are available at https://github.com/Jingjing-NLP/VOLT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lessons from Computational Modelling of Reference Production in Mandarin and English. (arXiv:2011.07398v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1">Kees van Deemter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07398">
                                    <div class="article-summary-box-inner">
                                        <span>Referring expression generation (REG) algorithms offer computational models
of the production of referring expressions. In earlier work, a corpus of
referring expressions (REs) in Mandarin was introduced. In the present paper,
we annotate this corpus, evaluate classic REG algorithms on it, and compare the
results with earlier results on the evaluation of REG for English referring
expressions. Next, we offer an in-depth analysis of the corpus, focusing on
issues that arise from the grammar of Mandarin. We discuss shortcomings of
previous REG evaluations that came to light during our investigation and we
highlight some surprising results. Perhaps most strikingly, we found a much
higher proportion of under-specified expressions than previous studies had
suggested, not just in Mandarin but in English as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Integrated Approach for Improving Brand Consistency of Web Content: Modeling, Analysis and Recommendation. (arXiv:2011.09754v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Soumyadeep Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sural_S/0/1/0/all/0/1">Shamik Sural</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhaya_N/0/1/0/all/0/1">Niyati Chhaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Natarajan_A/0/1/0/all/0/1">Anandhavelu Natarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1">Niloy Ganguly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09754">
                                    <div class="article-summary-box-inner">
                                        <span>A consumer-dependent (business-to-consumer) organization tends to present
itself as possessing a set of human qualities, which is termed as the brand
personality of the company. The perception is impressed upon the consumer
through the content, be it in the form of advertisement, blogs or magazines,
produced by the organization. A consistent brand will generate trust and retain
customers over time as they develop an affinity towards regularity and common
patterns. However, maintaining a consistent messaging tone for a brand has
become more challenging with the virtual explosion in the amount of content
which needs to be authored and pushed to the Internet to maintain an edge in
the era of digital marketing. To understand the depth of the problem, we
collect around 300K web page content from around 650 companies. We develop
trait-specific classification models by considering the linguistic features of
the content. The classifier automatically identifies the web articles which are
not consistent with the mission and vision of a company and further helps us to
discover the conditions under which the consistency cannot be maintained. To
address the brand inconsistency issue, we then develop a sentence ranking
system that outputs the top three sentences that need to be changed for making
a web article more consistent with the company&#x27;s brand personality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Streaming Approach For Efficient Batched Beam Search. (arXiv:2010.02164v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_V/0/1/0/all/0/1">Violet Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+DeNero_J/0/1/0/all/0/1">John DeNero</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02164">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient batching strategy for variable-length decoding on GPU
architectures. During decoding, when candidates terminate or are pruned
according to heuristics, our streaming approach periodically &quot;refills&quot; the
batch before proceeding with a selected subset of candidates. We apply our
method to variable-width beam search on a state-of-the-art machine translation
model. Our method decreases runtime by up to 71% compared to a fixed-width beam
search baseline and 17% compared to a variable-width baseline, while matching
baselines&#x27; BLEU. Finally, experiments show that our method can speed up
decoding in other domains, such as semantic and syntactic parsing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROSITA: Enhancing Vision-and-Language Semantic Alignments via Cross- and Intra-modal Knowledge Integration. (arXiv:2108.07073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yuhao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chunqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhongzhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07073">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-and-language pretraining (VLP) aims to learn generic multimodal
representations from massive image-text pairs. While various successful
attempts have been proposed, learning fine-grained semantic alignments between
image-text pairs plays a key role in their approaches. Nevertheless, most
existing VLP approaches have not fully utilized the intrinsic knowledge within
the image-text pairs, which limits the effectiveness of the learned alignments
and further restricts the performance of their models. To this end, we
introduce a new VLP method called ROSITA, which integrates the cross- and
intra-modal knowledge in a unified scene graph to enhance the semantic
alignments. Specifically, we introduce a novel structural knowledge masking
(SKM) strategy to use the scene graph structure as a priori to perform masked
language (region) modeling, which enhances the semantic alignments by
eliminating the interference information within and across modalities.
Extensive ablation studies and comprehensive analysis verifies the
effectiveness of ROSITA in semantic alignments. Pretrained with both in-domain
and out-of-domain datasets, ROSITA significantly outperforms existing
state-of-the-art VLP methods on three typical vision-and-language tasks over
six benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge-Based Construction of Confusion Matrices for Multi-Label Classification Algorithms using Semantic Similarity Measures. (arXiv:2011.00109v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turki_H/0/1/0/all/0/1">Houcemeddine Turki</a>, <a href="http://arxiv.org/find/cs/1/au:+Taieb_M/0/1/0/all/0/1">Mohamed Ali Hadj Taieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Aouicha_M/0/1/0/all/0/1">Mohamed Ben Aouicha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00109">
                                    <div class="article-summary-box-inner">
                                        <span>So far, multi-label classification algorithms have been evaluated using
statistical methods that do not consider the semantics of the considered
classes and that fully depend on abstract computations such as Bayesian
Reasoning. Currently, there are several attempts to develop ontology-based
methods for a better assessment of supervised classification algorithms. In
this research paper, we define a novel approach that aligns expected labels
with predicted labels in multi-label classification using ontology-driven
feature-based semantic similarity measures and we use it to develop a method
for creating precise confusion matrices for a more effective evaluation of
multi-label classification algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextual Mood Analysis with Knowledge Graph Representation for Hindi Song Lyrics in Devanagari Script. (arXiv:2108.06947v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Velankar_M/0/1/0/all/0/1">Makarand Velankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotian_R/0/1/0/all/0/1">Rachita Kotian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1">Parag Kulkarni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06947">
                                    <div class="article-summary-box-inner">
                                        <span>Lyrics play a significant role in conveying the song&#x27;s mood and are
information to understand and interpret music communication. Conventional
natural language processing approaches use translation of the Hindi text into
English for analysis. This approach is not suitable for lyrics as it is likely
to lose the inherent intended contextual meaning. Thus, the need was identified
to develop a system for Devanagari text analysis. The data set of 300 song
lyrics with equal distribution in five different moods is used for the
experimentation. The proposed system performs contextual mood analysis of Hindi
song lyrics in Devanagari text format. The contextual analysis is stored as a
knowledge base, updated using an incremental learning approach with new data.
Contextual knowledge graph with moods and associated important contextual terms
provides the graphical representation of the lyric data set used. The testing
results show 64% accuracy for the mood prediction. This work can be easily
extended to applications related to Hindi literary work such as summarization,
indexing, contextual retrieval, context-based classification and grouping of
documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Single Example Can Improve Zero-Shot Data Generation. (arXiv:2108.06991v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burnyshev_P/0/1/0/all/0/1">Pavel Burnyshev</a>, <a href="http://arxiv.org/find/cs/1/au:+Malykh_V/0/1/0/all/0/1">Valentin Malykh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bout_A/0/1/0/all/0/1">Andrey Bout</a>, <a href="http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1">Ekaterina Artemova</a>, <a href="http://arxiv.org/find/cs/1/au:+Piontkovskaya_I/0/1/0/all/0/1">Irina Piontkovskaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06991">
                                    <div class="article-summary-box-inner">
                                        <span>Sub-tasks of intent classification, such as robustness to distribution shift,
adaptation to specific user groups and personalization, out-of-domain
detection, require extensive and flexible datasets for experiments and
evaluation. As collecting such datasets is time- and labor-consuming, we
propose to use text generation methods to gather datasets. The generator should
be trained to generate utterances that belong to the given intent. We explore
two approaches to generating task-oriented utterances. In the zero-shot
approach, the model is trained to generate utterances from seen intents and is
further used to generate utterances for intents unseen during training. In the
one-shot approach, the model is presented with a single utterance from a test
intent. We perform a thorough automatic, and human evaluation of the dataset
generated utilizing two proposed approaches. Our results reveal that the
attributes of the generated data are close to original test sets, collected via
crowd-sourcing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label-Agnostic Sequence Labeling by Copying Nearest Neighbors. (arXiv:1906.04225v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1">Sam Wiseman</a>, <a href="http://arxiv.org/find/cs/1/au:+Stratos_K/0/1/0/all/0/1">Karl Stratos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.04225">
                                    <div class="article-summary-box-inner">
                                        <span>Retrieve-and-edit based approaches to structured prediction, where structures
associated with retrieved neighbors are edited to form new structures, have
recently attracted increased interest. However, much recent work merely
conditions on retrieved structures (e.g., in a sequence-to-sequence framework),
rather than explicitly manipulating them. We show we can perform accurate
sequence labeling by explicitly (and only) copying labels from retrieved
neighbors. Moreover, because this copying is label-agnostic, we can achieve
impressive performance in zero-shot sequence-labeling tasks. We additionally
consider a dynamic programming approach to sequence labeling in the presence of
retrieved neighbors, which allows for controlling the number of distinct
(copied) segments used to form a prediction, and leads to both more
interpretable and accurate predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Dat Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1">Stephen S. Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01777">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel interpretable deep neural network for text classification,
called ProtoryNet, based on a new concept of prototype trajectories. Motivated
by the prototype theory in modern linguistics, ProtoryNet makes a prediction by
finding the most similar prototype for each sentence in a text sequence and
feeding an RNN backbone with the proximity of each sentence to the
corresponding active prototype. The RNN backbone then captures the temporal
pattern of the prototypes, which we refer to as prototype trajectories.
Prototype trajectories enable intuitive and fine-grained interpretation of the
reasoning process of the RNN model, in resemblance to how humans analyze texts.
We also design a prototype pruning procedure to reduce the total number of
prototypes used by the model for better interpretability. Experiments on
multiple public data sets show that ProtoryNet is more accurate than the
baseline prototype-based deep neural net and reduces the performance gap
compared to state-of-the-art black-box models. In addition, after prototype
pruning, the resulting ProtoryNet models only need less than or around 20
prototypes for all datasets, which significantly benefits interpretability.
Furthermore, we report a survey result indicating that human users find
ProtoryNet more intuitive and easier to understand than other prototype-based
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning for Massively Parallel Translation of Constrained Text into Low Resource Languages. (arXiv:2108.07127v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alex Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07127">
                                    <div class="article-summary-box-inner">
                                        <span>We translate a closed text that is known in advance and available in many
languages into a new and severely low resource language. Most human translation
efforts adopt a portion-based approach to translate consecutive pages/chapters
in order, which may not suit machine translation. We compare the portion-based
approach that optimizes coherence of the text locally with the random sampling
approach that increases coverage of the text globally. Our results show that
the random sampling approach performs better. When training on a seed corpus of
~1,000 lines from the Bible and testing on the rest of the Bible (~30,000
lines), random sampling gives a performance gain of +11.0 BLEU using English as
a simulated low resource language, and +4.9 BLEU using Eastern Pokomchi, a
Mayan language. Furthermore, we compare three ways of updating machine
translation models with increasing amount of human post-edited data through
iterations. We find that adding newly post-edited data to training after
vocabulary update without self-supervision performs the best. We propose an
algorithm for human and machine to work together seamlessly to translate a
closed text into a severely low resource language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Effective Non-Autoregressive Model for Spoken Language Understanding. (arXiv:2108.07005v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Lizhi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1">Weijia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenmian Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07005">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken Language Understanding (SLU), a core component of the task-oriented
dialogue system, expects a shorter inference latency due to the impatience of
humans. Non-autoregressive SLU models clearly increase the inference speed but
suffer uncoordinated-slot problems caused by the lack of sequential dependency
information among each slot chunk. To gap this shortcoming, in this paper, we
propose a novel non-autoregressive SLU model named Layered-Refine Transformer,
which contains a Slot Label Generation (SLG) task and a Layered Refine
Mechanism (LRM). SLG is defined as generating the next slot label with the
token sequence and generated slot labels. With SLG, the non-autoregressive
model can efficiently obtain dependency information during training and spend
no extra time in inference. LRM predicts the preliminary SLU results from
Transformer&#x27;s middle states and utilizes them to guide the final prediction.
Experiments on two public datasets indicate that our model significantly
improves SLU performance (1.5\% on Overall accuracy) while substantially speed
up (more than 10 times) the inference process over the state-of-the-art
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Effective System for Multi-format Information Extraction. (arXiv:2108.06957v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yaduo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Longhui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1">Shujuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiaofeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1">Feiliang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06957">
                                    <div class="article-summary-box-inner">
                                        <span>The multi-format information extraction task in the 2021 Language and
Intelligence Challenge is designed to comprehensively evaluate information
extraction from different dimensions. It consists of an multiple slots relation
extraction subtask and two event extraction subtasks that extract events from
both sentence-level and document-level. Here we describe our system for this
multi-format information extraction competition task. Specifically, for the
relation extraction subtask, we convert it to a traditional triple extraction
task and design a voting based method that makes full use of existing models.
For the sentence-level event extraction subtask, we convert it to a NER task
and use a pointer labeling based method for extraction. Furthermore,
considering the annotated trigger information may be helpful for event
extraction, we design an auxiliary trigger recognition model and use the
multi-task learning mechanism to integrate the trigger features into the event
extraction model. For the document-level event extraction subtask, we design an
Encoder-Decoder based method and propose a Transformer-alike decoder.
Finally,our system ranks No.4 on the test set leader-board of this multi-format
information extraction task, and its F1 scores for the subtasks of relation
extraction, event extractions of sentence-level and document-level are 79.887%,
85.179%, and 70.828% respectively. The codes of our model are available at
{https://github.com/neukg/MultiIE}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoChart: A Dataset for Chart-to-Text Generation Task. (arXiv:2108.06897v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiawen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_J/0/1/0/all/0/1">Jinye Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1">Kenny Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06897">
                                    <div class="article-summary-box-inner">
                                        <span>The analytical description of charts is an exciting and important research
area with many applications in academia and industry. Yet, this challenging
task has received limited attention from the computational linguistics research
community. This paper proposes \textsf{AutoChart}, a large dataset for the
analytical description of charts, which aims to encourage more research into
this important area. Specifically, we offer a novel framework that generates
the charts and their analytical description automatically. We conducted
extensive human and machine evaluations on the generated charts and
descriptions and demonstrate that the generated texts are informative,
coherent, and relevant to the corresponding charts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MobIE: A German Dataset for Named Entity Recognition, Entity Linking and Relation Extraction in the Mobility Domain. (arXiv:2108.06955v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hennig_L/0/1/0/all/0/1">Leonhard Hennig</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_P/0/1/0/all/0/1">Phuc Tran Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabryszak_A/0/1/0/all/0/1">Aleksandra Gabryszak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06955">
                                    <div class="article-summary-box-inner">
                                        <span>We present MobIE, a German-language dataset, which is human-annotated with 20
coarse- and fine-grained entity types and entity linking information for
geographically linkable entities. The dataset consists of 3,232 social media
texts and traffic reports with 91K tokens, and contains 20.5K annotated
entities, 13.1K of which are linked to a knowledge base. A subset of the
dataset is human-annotated with seven mobility-related, n-ary relation types,
while the remaining documents are annotated using a weakly-supervised labeling
approach implemented with the Snorkel framework. To the best of our knowledge,
this is the first German-language dataset that combines annotations for NER, EL
and RE, and thus can be used for joint and multi-task learning of these
fundamental information extraction tasks. We make MobIE public at
https://github.com/dfki-nlp/mobie.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Filipino Disaster-Related Tweets Using Incremental and Density-Based Spatiotemporal Algorithm with Support Vector Machines for Needs Assessment 2. (arXiv:2108.06853v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barba_O/0/1/0/all/0/1">Ocean M. Barba</a>, <a href="http://arxiv.org/find/cs/1/au:+Calbay_F/0/1/0/all/0/1">Franz Arvin T. Calbay</a>, <a href="http://arxiv.org/find/cs/1/au:+Francisco_A/0/1/0/all/0/1">Angelica Jane S. Francisco</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1">Angel Luis D. Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponay_C/0/1/0/all/0/1">Charmaine S. Ponay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06853">
                                    <div class="article-summary-box-inner">
                                        <span>Social media has played a huge part on how people get informed and
communicate with one another. It has helped people express their needs due to
distress especially during disasters. Because posts made through it are
publicly accessible by default, Twitter is among the most helpful social media
sites in times of disaster. With this, the study aims to assess the needs
expressed during calamities by Filipinos on Twitter. Data were gathered and
classified as either disaster-related or unrelated with the use of Na\&quot;ive
Bayes classifier. After this, the disaster-related tweets were clustered per
disaster type using Incremental Clustering Algorithm, and then sub-clustered
based on the location and time of the tweet using Density-based Spatiotemporal
Clustering Algorithm. Lastly, using Support Vector Machines, the tweets were
classified according to the expressed need, such as shelter, rescue, relief,
cash, prayer, and others. After conducting the study, results showed that the
Incremental Clustering Algorithm and Density-Based Spatiotemporal Clustering
Algorithm were able to cluster the tweets with f-measure scores of 47.20% and
82.28% respectively. Also, the Na\&quot;ive Bayes and Support Vector Machines were
able to classify with an average f-measure score of 97% and an average accuracy
of 77.57% respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhoujun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Haoyu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiruo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaqi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jian-Guang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06712">
                                    <div class="article-summary-box-inner">
                                        <span>Tables are often created with hierarchies, but existing works on table
reasoning mainly focus on flat tables and neglect hierarchical tables.
Hierarchical tables challenge existing methods by hierarchical indexing, as
well as implicit relationships of calculation and semantics. This work presents
HiTab, a free and open dataset for the research community to study question
answering (QA) and natural language generation (NLG) over hierarchical tables.
HiTab is a cross-domain dataset constructed from a wealth of statistical
reports and Wikipedia pages, and has unique characteristics: (1) nearly all
tables are hierarchical, and (2) both target sentences for NLG and questions
for QA are revised from high-quality descriptions in statistical reports that
are meaningful and diverse. (3) HiTab provides fine-grained annotations on both
entity and quantity alignment. Targeting hierarchical structure, we devise a
novel hierarchy-aware logical form for symbolic reasoning over tables, which
shows high effectiveness. Then given annotations of entity and quantity
alignment, we propose partially supervised training, which helps models to
largely reduce spurious predictions in the QA task. In the NLG task, we find
that entity and quantity alignment also helps NLG models to generate better
results in a conditional generation setting. Experiment results of
state-of-the-art baselines suggest that this dataset presents a strong
challenge and a valuable benchmark for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning. (arXiv:2108.06743v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cunxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Boyuan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1">Yuchen Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06743">
                                    <div class="article-summary-box-inner">
                                        <span>To quantitatively and intuitively explore the generalization ability of
pre-trained language models (PLMs), we have designed several tasks of
arithmetic and logical reasoning. We both analyse how well PLMs generalize when
the test data is in the same distribution as the train data and when it is
different, for the latter analysis, we have also designed a cross-distribution
test set other than the in-distribution test set. We conduct experiments on one
of the most advanced and publicly released generative PLM - BART. Our research
finds that the PLMs can easily generalize when the distribution is the same,
however, it is still difficult for them to generalize out of the distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What can Neural Referential Form Selectors Learn?. (arXiv:2108.06806v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Same_F/0/1/0/all/0/1">Fahime Same</a>, <a href="http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1">Kees van Deemter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06806">
                                    <div class="article-summary-box-inner">
                                        <span>Despite achieving encouraging results, neural Referring Expression Generation
models are often thought to lack transparency. We probed neural Referential
Form Selection (RFS) models to find out to what extent the linguistic features
influencing the RE form are learnt and captured by state-of-the-art RFS models.
The results of 8 probing tasks show that all the defined features were learnt
to some extent. The probing tasks pertaining to referential status and
syntactic position exhibited the highest performance. The lowest performance
was achieved by the probing models designed to predict discourse structure
properties beyond the sentence level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maps Search Misspelling Detection Leveraging Domain-Augmented Contextual Representations. (arXiv:2108.06842v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yutong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06842">
                                    <div class="article-summary-box-inner">
                                        <span>Building an independent misspelling detector and serve it before correction
can bring multiple benefits to speller and other search components, which is
particularly true for the most commonly deployed noisy-channel based speller
systems. With rapid development of deep learning and substantial advancement in
contextual representation learning such as BERTology, building a decent
misspelling detector without having to rely on hand-crafted features associated
with noisy-channel architecture becomes more-than-ever accessible. However
BERTolgy models are trained with natural language corpus but Maps Search is
highly domain specific, would BERTology continue its success. In this paper we
design 4 stages of models for misspeling detection ranging from the most basic
LSTM to single-domain augmented fine-tuned BERT. We found for Maps Search in
our case, other advanced BERTology family model such as RoBERTa does not
necessarily outperform BERT, and a classic cross-domain fine-tuned full BERT
even underperforms a smaller single-domain fine-tuned BERT. We share more
findings through comprehensive modeling experiments and analysis, we also
briefly cover the data generation algorithm breakthrough.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants. (arXiv:2108.06633v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidharan_D/0/1/0/all/0/1">Deepak Muralidharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1">Joel Ruben Antony Moniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1">Stephen Pulman</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_M/0/1/0/all/0/1">Megan Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jingjing Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Jason Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Acero_A/0/1/0/all/0/1">Alex Acero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06633">
                                    <div class="article-summary-box-inner">
                                        <span>Named entity recognition (NER) is usually developed and tested on text from
well-written sources. However, in intelligent voice assistants, where NER is an
important component, input to NER may be noisy because of user or speech
recognition error. In applications, entity labels may change frequently, and
non-textual properties like topicality or popularity may be needed to choose
among alternatives.

We describe a NER system intended to address these problems. We test and
train this system on a proprietary user-derived dataset. We compare with a
baseline text-only NER system; the baseline enhanced with external gazetteers;
and the baseline enhanced with the search and indirect labelling techniques we
describe below. The final configuration gives around 6% reduction in NER error
rate. We also show that this technique improves related tasks, such as semantic
parsing, with an improvement of up to 5% in error rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complex Knowledge Base Question Answering: A Survey. (arXiv:2108.06688v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yunshi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1">Gaole He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jinhao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06688">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge base question answering (KBQA) aims to answer a question over a
knowledge base (KB). Early studies mainly focused on answering simple questions
over KBs and achieved great success. However, their performance on complex
questions is still far from satisfactory. Therefore, in recent years,
researchers propose a large number of novel methods, which looked into the
challenges of answering complex questions. In this survey, we review recent
advances on KBQA with the focus on solving complex questions, which usually
contain multiple subjects, express compound relations, or involve numerical
operations. In detail, we begin with introducing the complex KBQA task and
relevant background. Then, we describe benchmark datasets for complex KBQA task
and introduce the construction process of these datasets. Next, we present two
mainstream categories of methods for complex KBQA, namely semantic
parsing-based (SP-based) methods and information retrieval-based (IR-based)
methods. Specifically, we illustrate their procedures with flow designs and
discuss their major differences and similarities. After that, we summarize the
challenges that these two categories of methods encounter when answering
complex questions, and explicate advanced solutions and techniques used in
existing work. Finally, we conclude and discuss several promising directions
related to complex KBQA for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAPPHIRE: Approaches for Enhanced Concept-to-Text Generation. (arXiv:2108.06643v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Steven Y. Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_J/0/1/0/all/0/1">Jessica Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Narisetty_C/0/1/0/all/0/1">Chaitanya Narisetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06643">
                                    <div class="article-summary-box-inner">
                                        <span>We motivate and propose a suite of simple but effective improvements for
concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc
PHrase Infilling and REcombination. We demonstrate their effectiveness on
generative commonsense reasoning, a.k.a. the CommonGen task, through
experiments using both BART and T5 models. Through extensive automatic and
human evaluation, we show that SAPPHIRE noticeably improves model performance.
An in-depth qualitative analysis illustrates that SAPPHIRE effectively
addresses many issues of the baseline model generations, including lack of
commonsense, insufficient specificity, and poor fluency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Sample Named Entity Recognition for Security Vulnerability Reports by Fine-Tuning Pre-Trained Language Models. (arXiv:2108.06590v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guanqun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dineen_S/0/1/0/all/0/1">Shay Dineen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhipeng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xueqing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06590">
                                    <div class="article-summary-box-inner">
                                        <span>Public security vulnerability reports (e.g., CVE reports) play an important
role in the maintenance of computer and network systems. Security companies and
administrators rely on information from these reports to prioritize tasks on
developing and deploying patches to their customers. Since these reports are
unstructured texts, automatic information extraction (IE) can help scale up the
processing by converting the unstructured reports to structured forms, e.g.,
software names and versions and vulnerability types. Existing works on
automated IE for security vulnerability reports often rely on a large number of
labeled training samples. However, creating massive labeled training set is
both expensive and time consuming. In this work, for the first time, we propose
to investigate this problem where only a small number of labeled training
samples are available. In particular, we investigate the performance of
fine-tuning several state-of-the-art pre-trained language models on our small
training dataset. The results show that with pre-trained language models and
carefully tuned hyperparameters, we have reached or slightly outperformed the
state-of-the-art system on this task. Consistent with previous two-step process
of first fine-tuning on main category and then transfer learning to others as
in [7], if otherwise following our proposed approach, the number of required
labeled samples substantially decrease in both stages: 90% reduction in
fine-tuning from 5758 to 576,and 88.8% reduction in transfer learning with 64
labeled samples per category. Our experiments thus demonstrate the
effectiveness of few-sample learning on NER for security vulnerability report.
This result opens up multiple research opportunities for few-sample learning
for security vulnerability reports, which is discussed in the paper. Code:
https://github.com/guanqun-yang/FewVulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The SelectGen Challenge: Finding the Best Training Samples for Few-Shot Neural Text Generation. (arXiv:2108.06614v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xiaoyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_A/0/1/0/all/0/1">Alex Marin</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06614">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a shared task on training instance selection for few-shot neural
text generation. Large-scale pretrained language models have led to dramatic
improvements in few-shot text generation. Nonetheless, almost all previous work
simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. The study of the selection strategy can help us
to (1) make the most use of our annotation budget in downstream tasks and (2)
better benchmark few-shot text generative models. We welcome submissions that
present their selection strategies and the effects on the generation quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accurate, yet inconsistent? Consistency Analysis on Language Understanding Models. (arXiv:2108.06665v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jang_M/0/1/0/all/0/1">Myeongjun Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_D/0/1/0/all/0/1">Deuk Sin Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06665">
                                    <div class="article-summary-box-inner">
                                        <span>Consistency, which refers to the capability of generating the same
predictions for semantically similar contexts, is a highly desirable property
for a sound language understanding model. Although recent pretrained language
models (PLMs) deliver outstanding performance in various downstream tasks, they
should exhibit consistent behaviour provided the models truly understand
language. In this paper, we propose a simple framework named consistency
analysis on language understanding models (CALUM)} to evaluate the model&#x27;s
lower-bound consistency ability. Through experiments, we confirmed that current
PLMs are prone to generate inconsistent predictions even for semantically
identical inputs. We also observed that multi-task training with paraphrase
identification tasks is of benefit to improve consistency, increasing the
consistency by 13% on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Findings of the LoResMT 2021 Shared Task on COVID and Sign Language for Low-resource Languages. (arXiv:2108.06598v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ojha_A/0/1/0/all/0/1">Atul Kr. Ojha</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao-Hong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1">Katharina Kann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_J/0/1/0/all/0/1">John Ortega</a>, <a href="http://arxiv.org/find/cs/1/au:+Shatam_S/0/1/0/all/0/1">Sheetal Shatam</a>, <a href="http://arxiv.org/find/cs/1/au:+Fransen_T/0/1/0/all/0/1">Theodorus Fransen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06598">
                                    <div class="article-summary-box-inner">
                                        <span>We present the findings of the LoResMT 2021 shared task which focuses on
machine translation (MT) of COVID-19 data for both low-resource spoken and sign
languages. The organization of this task was conducted as part of the fourth
workshop on technologies for machine translation of low resource languages
(LoResMT). Parallel corpora is presented and publicly available which includes
the following directions: English$\leftrightarrow$Irish,
English$\leftrightarrow$Marathi, and Taiwanese Sign
language$\leftrightarrow$Traditional Chinese. Training data consists of 8112,
20933 and 128608 segments, respectively. There are additional monolingual data
sets for Marathi and English that consist of 21901 segments. The results
presented here are based on entries from a total of eight teams. Three teams
submitted systems for English$\leftrightarrow$Irish while five teams submitted
systems for English$\leftrightarrow$Marathi. Unfortunately, there were no
systems submissions for the Taiwanese Sign language$\leftrightarrow$Traditional
Chinese task. Maximum system performance was computed using BLEU and follow as
36.0 for English--Irish, 34.6 for Irish--English, 24.2 for English--Marathi,
and 31.3 for Marathi--English.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Entity Extraction Method Based on Machine Reading Comprehension. (arXiv:2108.06444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaobo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jiajun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1">Guangyu Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06444">
                                    <div class="article-summary-box-inner">
                                        <span>Entity extraction is a key technology for obtaining information from massive
texts in natural language processing. The further interaction between them does
not meet the standards of human reading comprehension, thus limiting the
understanding of the model, and also the omission or misjudgment of the answer
(ie the target entity) due to the reasoning question. An effective MRC-based
entity extraction model-MRC-I2DP, which uses the proposed gated
attention-attracting mechanism to adjust the restoration of each part of the
text pair, creating problems and thinking for multi-level interactive attention
calculations to increase the target entity It also uses the proposed 2D
probability coding module, TALU function and mask mechanism to strengthen the
detection of all possible targets of the target, thereby improving the
probability and accuracy of prediction. Experiments have proved that MRC-I2DP
represents an overall state-of-the-art model in 7 from the scientific and
public domains, achieving a performance improvement of 2.1% ~ 10.4% compared to
the model model in F1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Bias In Automatic Toxic Comment Detection: An Empirical Study. (arXiv:2108.06487v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ayush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratik Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06487">
                                    <div class="article-summary-box-inner">
                                        <span>With surge in online platforms, there has been an upsurge in the user
engagement on these platforms via comments and reactions. A large portion of
such textual comments are abusive, rude and offensive to the audience. With
machine learning systems in-place to check such comments coming onto platform,
biases present in the training data gets passed onto the classifier leading to
discrimination against a set of classes, religion and gender. In this work, we
evaluate different classifiers and feature to estimate the bias in these
classifiers along with their performance on downstream task of toxicity
classification. Results show that improvement in performance of automatic toxic
comment detection models is positively correlated to mitigating biases in these
models. In our work, LSTM with attention mechanism proved to be a better
modelling strategy than a CNN model. Further analysis shows that fasttext
embeddings is marginally preferable than glove embeddings on training models
for toxicity comment detection. Deeper analysis reveals the findings that such
automatic models are particularly biased to specific identity groups even
though the model has a high AUC score. Finally, in effort to mitigate bias in
toxicity detection models, a multi-task setup trained with auxiliary task of
toxicity sub-types proved to be useful leading to upto 0.26% (6% relative) gain
in AUC scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out-of-Core Surface Reconstruction via Global $TGV$ Minimization. (arXiv:2107.14790v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poliarnyi_N/0/1/0/all/0/1">Nikolai Poliarnyi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14790">
                                    <div class="article-summary-box-inner">
                                        <span>We present an out-of-core variational approach for surface reconstruction
from a set of aligned depth maps. Input depth maps are supposed to be
reconstructed from regular photos or/and can be a representation of terrestrial
LIDAR point clouds. Our approach is based on surface reconstruction via total
generalized variation minimization ($TGV$) because of its strong
visibility-based noise-filtering properties and GPU-friendliness. Our main
contribution is an out-of-core OpenCL-accelerated adaptation of this numerical
algorithm which can handle arbitrarily large real-world scenes with scale
diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and Accurate Low-Rank Tensor Completion Methods Based on QR Decomposition and $L_{2,1}$ Norm Minimization. (arXiv:2108.03002v3 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1">Hongbing Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1">Xinyi Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_H/0/1/0/all/0/1">Hongtao Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1">Yajing Li</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinlin Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03002">
                                    <div class="article-summary-box-inner">
                                        <span>More recently, an Approximate SVD Based on Qatar Riyal (QR) Decomposition
(CSVD-QR) method for matrix complete problem is presented, whose computational
complexity is $O(r^2(m+n))$, which is mainly due to that $r$ is far less than
$\min\{m,n\}$, where $r$ represents the largest number of singular values of
matrix $X$. What is particularly interesting is that after replacing the
nuclear norm with the $L_{2,1}$ norm proposed based on this decomposition, as
the upper bound of the nuclear norm, when the intermediate matrix $D$ in its
decomposition is close to the diagonal matrix, it will converge to the nuclear
norm, and is exactly equal, when the $D$ matrix is equal to the diagonal
matrix, to the nuclear norm, which ingeniously avoids the calculation of the
singular value of the matrix. To the best of our knowledge, there is no
literature to generalize and apply it to solve tensor complete problems.
Inspired by this, in this paper we propose a class of tensor minimization model
based on $L_{2,1}$ norm and CSVD-QR method for the tensor complete problem,
which is convex and therefore has a global minimum solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction. (arXiv:2108.00238v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Fang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sanping Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1">Wei Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00238">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding complex social interactions among agents is a key challenge for
trajectory prediction. Most existing methods consider the interactions between
pairwise traffic agents or in a local area, while the nature of interactions is
unlimited, involving an uncertain number of agents and non-local areas
simultaneously. Besides, they treat heterogeneous traffic agents the same,
namely those among agents of different categories, while neglecting people&#x27;s
diverse reaction patterns toward traffic agents in ifferent categories. To
address these problems, we propose a simple yet effective Unlimited
Neighborhood Interaction Network (UNIN), which predicts trajectories of
heterogeneous agents in multiple categories. Specifically, the proposed
unlimited neighborhood interaction module generates the fused-features of all
agents involved in an interaction simultaneously, which is adaptive to any
number of agents and any range of interaction area. Meanwhile, a hierarchical
graph attention module is proposed to obtain category-to-category interaction
and agent-to-agent interaction. Finally, parameters of a Gaussian Mixture Model
are estimated for generating the future trajectories. Extensive experimental
results on benchmark datasets demonstrate a significant performance improvement
of our method over the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Visual Engagement Signals for Representation Learning. (arXiv:2104.07767v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Menglin Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reiter_A/0/1/0/all/0/1">Austin Reiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1">Claire Cardie</a>, <a href="http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1">Serge Belongie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07767">
                                    <div class="article-summary-box-inner">
                                        <span>Visual engagement in social media platforms comprises interactions with photo
posts including comments, shares, and likes. In this paper, we leverage such
visual engagement clues as supervisory signals for representation learning.
However, learning from engagement signals is non-trivial as it is not clear how
to bridge the gap between low-level visual information and high-level social
interactions. We present VisE, a weakly supervised learning approach, which
maps social images to pseudo labels derived by clustered engagement signals. We
then study how models trained in this way benefit subjective downstream
computer vision tasks such as emotion recognition or political bias detection.
Through extensive studies, we empirically demonstrate the effectiveness of VisE
across a diverse set of classification tasks beyond the scope of conventional
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Adversarial Examples by Input Transformations, Defense Perturbations, and Voting. (arXiv:2101.11466v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nesti_F/0/1/0/all/0/1">Federico Nesti</a>, <a href="http://arxiv.org/find/cs/1/au:+Biondi_A/0/1/0/all/0/1">Alessandro Biondi</a>, <a href="http://arxiv.org/find/cs/1/au:+Buttazzo_G/0/1/0/all/0/1">Giorgio Buttazzo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11466">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few years, convolutional neural networks (CNNs) have proved to
reach super-human performance in visual recognition tasks. However, CNNs can
easily be fooled by adversarial examples, i.e., maliciously-crafted images that
force the networks to predict an incorrect output while being extremely similar
to those for which a correct output is predicted. Regular adversarial examples
are not robust to input image transformations, which can then be used to detect
whether an adversarial example is presented to the network. Nevertheless, it is
still possible to generate adversarial examples that are robust to such
transformations.

This paper extensively explores the detection of adversarial examples via
image transformations and proposes a novel methodology, called \textit{defense
perturbation}, to detect robust adversarial examples with the same input
transformations the adversarial examples are robust to. Such a \textit{defense
perturbation} is shown to be an effective counter-measure to robust adversarial
examples.

Furthermore, multi-network adversarial examples are introduced. This kind of
adversarial examples can be used to simultaneously fool multiple networks,
which is critical in systems that use network redundancy, such as those based
on architectures with majority voting over multiple CNNs. An extensive set of
experiments based on state-of-the-art CNNs trained on the Imagenet dataset is
finally reported.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal-Prototype Enhancing for Few-Shot Object Detection. (arXiv:2103.01077v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Aming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yahong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Linchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01077">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot object detection (FSOD) aims to strengthen the performance of novel
object detection with few labeled samples. To alleviate the constraint of few
samples, enhancing the generalization ability of learned features for novel
objects plays a key role. Thus, the feature learning process of FSOD should
focus more on intrinsical object characteristics, which are invariant under
different visual changes and therefore are helpful for feature generalization.
Unlike previous attempts of the meta-learning paradigm, in this paper, we
explore how to enhance object features with intrinsical characteristics that
are universal across different object categories. We propose a new prototype,
namely universal prototype, that is learned from all object categories. Besides
the advantage of characterizing invariant characteristics, the universal
prototypes alleviate the impact of unbalanced object categories. After
enhancing object features with the universal prototypes, we impose a
consistency loss to maximize the agreement between the enhanced features and
the original ones, which is beneficial for learning invariant object
characteristics. Thus, we develop a new framework of few-shot object detection
with universal prototypes ({FSOD}^{up}) that owns the merit of feature
generalization towards novel objects. Experimental results on PASCAL VOC and MS
COCO show the effectiveness of {FSOD}^{up}. Particularly, for the 1-shot case
of VOC Split2, {FSOD}^{up} outperforms the baseline by 6.8% in terms of mAP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text2Video: Text-driven Talking-head Video Synthesis with Personalized Phoneme-Pose Dictionary. (arXiv:2104.14631v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sibo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jiahong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Miao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangjun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14631">
                                    <div class="article-summary-box-inner">
                                        <span>With the advance of deep learning technology, automatic video generation from
audio or text has become an emerging and promising research topic. In this
paper, we present a novel approach to synthesize video from the text. The
method builds a phoneme-pose dictionary and trains a generative adversarial
network (GAN) to generate video from interpolated phoneme poses. Compared to
audio-driven video generation algorithms, our approach has a number of
advantages: 1) It only needs a fraction of the training data used by an
audio-driven approach; 2) It is more flexible and not subject to vulnerability
due to speaker variation; 3) It significantly reduces the preprocessing,
training and inference time. We perform extensive experiments to compare the
proposed method with state-of-the-art talking face generation methods on a
benchmark dataset and datasets of our own. The results demonstrate the
effectiveness and superiority of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Visual Understanding with Cognitive Attention Network. (arXiv:2108.02924v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xuejiao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_K/0/1/0/all/0/1">Kea Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1">Tyler Derr</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02924">
                                    <div class="article-summary-box-inner">
                                        <span>While image understanding on recognition-level has achieved remarkable
advancements, reliable visual scene understanding requires comprehensive image
understanding on recognition-level but also cognition-level, which calls for
exploiting the multi-source information as well as learning different levels of
understanding and extensive commonsense knowledge. In this paper, we propose a
novel Cognitive Attention Network (CAN) for visual commonsense reasoning to
achieve interpretable visual understanding. Specifically, we first introduce an
image-text fusion module to fuse information from images and text collectively.
Second, a novel inference module is designed to encode commonsense among image,
query and response. Extensive experiments on large-scale Visual Commonsense
Reasoning (VCR) benchmark dataset demonstrate the effectiveness of our
approach. The implementation is publicly available at
https://github.com/tanjatang/CAN</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Free-Form Deformation for 3D Face Reconstruction from In-The-Wild Images. (arXiv:2105.14857v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1">Harim Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_M/0/1/0/all/0/1">Myeong-Seok Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14857">
                                    <div class="article-summary-box-inner">
                                        <span>The 3D Morphable Model (3DMM), which is a Principal Component Analysis (PCA)
based statistical model that represents a 3D face using linear basis functions,
has shown promising results for reconstructing 3D faces from single-view
in-the-wild images. However, 3DMM has restricted representation power due to
the limited number of 3D scans and the global linear basis. To address the
limitations of 3DMM, we propose a straightforward learning-based method that
reconstructs a 3D face mesh through Free-Form Deformation (FFD) for the first
time. FFD is a geometric modeling method that embeds a reference mesh within a
parallelepiped grid and deforms the mesh by moving the sparse control points of
the grid. As FFD is based on mathematically defined basis functions, it has no
limitation in representation power. Thus, we can recover accurate 3D face
meshes by estimating appropriate deviation of control points as deformation
parameters. Although both 3DMM and FFD are parametric models, it is difficult
to predict the effect of the 3DMM parameters on the face shape, while the
deformation parameters of FFD are interpretable in terms of their effect on the
final shape of the mesh. This practical advantage of FFD allows the resulting
mesh and control points to serve as a good starting point for 3D face modeling,
in that ordinary users can fine-tune the mesh by using widely available 3D
software tools. Experiments on multiple datasets demonstrate how our method
successfully estimates the 3D face geometry and facial expressions from 2D face
images, achieving comparable performance to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition. (arXiv:2104.03841v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Massiceti_D/0/1/0/all/0/1">Daniela Massiceti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1">Luisa Zintgraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronskill_J/0/1/0/all/0/1">John Bronskill</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_L/0/1/0/all/0/1">Lida Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_M/0/1/0/all/0/1">Matthew Tobias Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Cutrell_E/0/1/0/all/0/1">Edward Cutrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1">Cecily Morrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_S/0/1/0/all/0/1">Simone Stumpf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03841">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition has made great advances in the last decade, but
predominately still relies on many high-quality training examples per object
category. In contrast, learning new objects from only a few examples could
enable many impactful applications from robotics to user personalization. Most
few-shot learning research, however, has been driven by benchmark datasets that
lack the high variation that these applications will face when deployed in the
real-world. To close this gap, we present the ORBIT dataset and benchmark,
grounded in the real-world application of teachable object recognizers for
people who are blind/low-vision. The dataset contains 3,822 videos of 486
objects recorded by people who are blind/low-vision on their mobile phones. The
benchmark reflects a realistic, highly challenging recognition problem,
providing a rich playground to drive research in robustness to few-shot,
high-variation conditions. We set the benchmark&#x27;s first state-of-the-art and
show there is massive scope for further innovation, holding the potential to
impact a broad range of real-world vision applications including tools for the
blind/low-vision community. We release the dataset at
https://doi.org/10.25383/city.14294597 and benchmark code at
https://github.com/microsoft/ORBIT-Dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score-Based Point Cloud Denoising. (arXiv:2107.10981v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shitong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10981">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds acquired from scanning devices are often perturbed by noise,
which affects downstream tasks such as surface reconstruction and analysis. The
distribution of a noisy point cloud can be viewed as the distribution of a set
of noise-free samples $p(x)$ convolved with some noise model $n$, leading to
$(p * n)(x)$ whose mode is the underlying clean surface. To denoise a noisy
point cloud, we propose to increase the log-likelihood of each point from $p *
n$ via gradient ascent -- iteratively updating each point&#x27;s position. Since $p
* n$ is unknown at test-time, and we only need the score (i.e., the gradient of
the log-probability function) to perform gradient ascent, we propose a neural
network architecture to estimate the score of $p * n$ given only noisy point
clouds as input. We derive objective functions for training the network and
develop a denoising algorithm leveraging on the estimated scores. Experiments
demonstrate that the proposed model outperforms state-of-the-art methods under
a variety of noise models, and shows the potential to be applied in other tasks
such as point cloud upsampling. The code is available at
\url{https://github.com/luost26/score-denoise}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Discriminative Representation Learning for Unsupervised Person Re-identification. (arXiv:2108.03439v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isobe_T/0/1/0/all/0/1">Takashi Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Lu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Yi Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03439">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of unsupervised domain adaptation for
person re-ID where annotations are available for the source domain but not for
target. Previous methods typically follow a two-stage optimization pipeline,
where the network is first pre-trained on source and then fine-tuned on target
with pseudo labels created by feature clustering. Such methods sustain two main
limitations. (1) The label noise may hinder the learning of discriminative
features for recognizing target classes. (2) The domain gap may hinder
knowledge transferring from source to target. We propose three types of
technical schemes to alleviate these issues. First, we propose a cluster-wise
contrastive learning algorithm (CCL) by iterative optimization of feature
learning and cluster refinery to learn noise-tolerant representations in the
unsupervised manner. Second, we adopt a progressive domain adaptation (PDA)
strategy to gradually mitigate the domain gap between source and target data.
Third, we propose Fourier augmentation (FA) for further maximizing the class
separability of re-ID models by imposing extra constraints in the Fourier
space. We observe that these proposed schemes are capable of facilitating the
learning of discriminative feature representations. Experiments demonstrate
that our method consistently achieves notable improvements over the
state-of-the-art unsupervised re-ID methods on multiple benchmarks, e.g.,
surpassing MMT largely by 8.1\%, 9.9\%, 11.4\% and 11.1\% mAP on the
Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT tasks,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Generating Transferable Targeted Perturbations. (arXiv:2103.14641v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1">Muzammal Naseer</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Shahbaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1">Fatih Porikli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14641">
                                    <div class="article-summary-box-inner">
                                        <span>While the untargeted black-box transferability of adversarial perturbations
has been extensively studied before, changing an unseen model&#x27;s decisions to a
specific &#x60;targeted&#x27; class remains a challenging feat. In this paper, we propose
a new generative approach for highly transferable targeted perturbations
(\ours). We note that the existing methods are less suitable for this task due
to their reliance on class-boundary information that changes from one model to
another, thus reducing transferability. In contrast, our approach matches the
perturbed image &#x60;distribution&#x27; with that of the target class, leading to high
targeted transferability rates. To this end, we propose a new objective
function that not only aligns the global distributions of source and target
images, but also matches the local neighbourhood structure between the two
domains. Based on the proposed objective, we train a generator function that
can adaptively synthesize perturbations specific to a given input. Our
generative approach is independent of the source or target domain labels, while
consistently performs well against state-of-the-art methods on a wide range of
attack settings. As an example, we achieve $32.63\%$ target transferability
from (an adversarially weak) VGG19$_{BN}$ to (a strong) WideResNet on ImageNet
val. set, which is 4$\times$ higher than the previous best generative attack
and 16$\times$ better than instance-specific iterative attack. Code is
available at: {\small\url{https://github.com/Muzammal-Naseer/TTP}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UAV-Human: A Large Benchmark for Human Behavior Understanding with Unmanned Aerial Vehicles. (arXiv:2104.00946v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianjiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1">Yun Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00946">
                                    <div class="article-summary-box-inner">
                                        <span>Human behavior understanding with unmanned aerial vehicles (UAVs) is of great
significance for a wide range of applications, which simultaneously brings an
urgent demand of large, challenging, and comprehensive benchmarks for the
development and evaluation of UAV-based models. However, existing benchmarks
have limitations in terms of the amount of captured data, types of data
modalities, categories of provided tasks, and diversities of subjects and
environments. Here we propose a new benchmark - UAVHuman - for human behavior
understanding with UAVs, which contains 67,428 multi-modal video sequences and
119 subjects for action recognition, 22,476 frames for pose estimation, 41,290
frames and 1,144 identities for person re-identification, and 22,263 frames for
attribute recognition. Our dataset was collected by a flying UAV in multiple
urban and rural districts in both daytime and nighttime over three months,
hence covering extensive diversities w.r.t subjects, backgrounds,
illuminations, weathers, occlusions, camera motions, and UAV flying attitudes.
Such a comprehensive and challenging benchmark shall be able to promote the
research of UAV-based human behavior understanding, including action
recognition, pose estimation, re-identification, and attribute recognition.
Furthermore, we propose a fisheye-based action recognition method that
mitigates the distortions in fisheye videos via learning unbounded
transformations guided by flat RGB videos. Experiments show the efficacy of our
method on the UAV-Human dataset. The project page:
https://github.com/SUTDCV/UAV-Human</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DualPoseNet: Category-level 6D Object Pose and Size Estimation Using Dual Pose Network with Refined Learning of Pose Consistency. (arXiv:2103.06526v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jiehong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zewei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhihao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songcen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanqing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06526">
                                    <div class="article-summary-box-inner">
                                        <span>Category-level 6D object pose and size estimation is to predict full pose
configurations of rotation, translation, and size for object instances observed
in single, arbitrary views of cluttered scenes. In this paper, we propose a new
method of Dual Pose Network with refined learning of pose consistency for this
task, shortened as DualPoseNet. DualPoseNet stacks two parallel pose decoders
on top of a shared pose encoder, where the implicit decoder predicts object
poses with a working mechanism different from that of the explicit one; they
thus impose complementary supervision on the training of pose encoder. We
construct the encoder based on spherical convolutions, and design a module of
Spherical Fusion wherein for a better embedding of pose-sensitive features from
the appearance and shape observations. Given no testing CAD models, it is the
novel introduction of the implicit decoder that enables the refined pose
prediction during testing, by enforcing the predicted pose consistency between
the two decoders using a self-adaptive loss term. Thorough experiments on
benchmarks of both category- and instance-level object pose datasets confirm
efficacy of our designs. DualPoseNet outperforms existing methods with a large
margin in the regime of high precision. Our code is released publicly at
https://github.com/Gorilla-Lab-SCUT/DualPoseNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards unconstrained joint hand-object reconstruction from RGB videos. (arXiv:2108.07044v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hasson_Y/0/1/0/all/0/1">Yana Hasson</a>, <a href="http://arxiv.org/find/cs/1/au:+Varol_G/0/1/0/all/0/1">G&#xfc;l Varol</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07044">
                                    <div class="article-summary-box-inner">
                                        <span>Our work aims to obtain 3D reconstruction of hands and manipulated objects
from monocular videos. Reconstructing hand-object manipulations holds a great
potential for robotics and learning from human demonstrations. The supervised
learning approach to this problem, however, requires 3D supervision and remains
limited to constrained laboratory settings and simulators for which 3D ground
truth is available. In this paper we first propose a learning-free fitting
approach for hand-object reconstruction which can seamlessly handle two-hand
object interactions. Our method relies on cues obtained with common methods for
object detection, hand pose estimation and instance segmentation. We
quantitatively evaluate our approach and show that it can be applied to
datasets with varying levels of difficulty for which training data is
unavailable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single Image Depth Prediction with Wavelet Decomposition. (arXiv:2106.02022v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramamonjisoa_M/0/1/0/all/0/1">Micha&#xeb;l Ramamonjisoa</a>, <a href="http://arxiv.org/find/cs/1/au:+Firman_M/0/1/0/all/0/1">Michael Firman</a>, <a href="http://arxiv.org/find/cs/1/au:+Watson_J/0/1/0/all/0/1">Jamie Watson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1">Vincent Lepetit</a>, <a href="http://arxiv.org/find/cs/1/au:+Turmukhambetov_D/0/1/0/all/0/1">Daniyar Turmukhambetov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02022">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for predicting accurate depths from monocular
images with high efficiency. This optimal efficiency is achieved by exploiting
wavelet decomposition, which is integrated in a fully differentiable
encoder-decoder architecture. We demonstrate that we can reconstruct
high-fidelity depth maps by predicting sparse wavelet coefficients. In contrast
with previous works, we show that wavelet coefficients can be learned without
direct supervision on coefficients. Instead we supervise only the final depth
image that is reconstructed through the inverse wavelet transform. We
additionally show that wavelet coefficients can be learned in fully
self-supervised scenarios, without access to ground-truth depth. Finally, we
apply our method to different state-of-the-art monocular depth estimation
models, in each case giving similar or better results compared to the original
model, while requiring less than half the multiply-adds in the decoder network.
Code at https://github.com/nianticlabs/wavelet-monodepth</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Frequency-aware Dynamic Network for Efficient Super-Resolution. (arXiv:2103.08357v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xie_W/0/1/0/all/0/1">Wenbin Xie</a>, <a href="http://arxiv.org/find/eess/1/au:+Song_D/0/1/0/all/0/1">Dehua Song</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Hui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08357">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning based methods, especially convolutional neural networks (CNNs)
have been successfully applied in the field of single image super-resolution
(SISR). To obtain better fidelity and visual quality, most of existing networks
are of heavy design with massive computation. However, the computation
resources of modern mobile devices are limited, which cannot easily support the
expensive cost. To this end, this paper explores a novel frequency-aware
dynamic network for dividing the input into multiple parts according to its
coefficients in the discrete cosine transform (DCT) domain. In practice, the
high-frequency part will be processed using expensive operations and the
lower-frequency part is assigned with cheap operations to relieve the
computation burden. Since pixels or image patches belong to low-frequency areas
contain relatively few textural details, this dynamic network will not affect
the quality of resulting super-resolution images. In addition, we embed
predictors into the proposed dynamic network to end-to-end fine-tune the
handcrafted frequency-aware masks. Extensive experiments conducted on benchmark
SISR models and datasets show that the frequency-aware dynamic network can be
employed for various SISR neural architectures to obtain the better tradeoff
between visual quality and computational complexity. For instance, we can
reduce the FLOPs of SR models by approximate 50% while preserving
state-of-the-art SISR performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints. (arXiv:2011.01354v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kenny Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pogue_A/0/1/0/all/0/1">Alexandra Pogue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_B/0/1/0/all/0/1">Brett T. Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Agha_mohammadi_A/0/1/0/all/0/1">Ali-akbar Agha-mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1">Ankur Mehta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01354">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular depth inference has gained tremendous attention from researchers in
recent years and remains as a promising replacement for expensive
time-of-flight sensors, but issues with scale acquisition and implementation
overhead still plague these systems. To this end, this work presents an
unsupervised learning framework that is able to predict at-scale depth maps and
egomotion, in addition to camera intrinsics, from a sequence of monocular
images via a single network. Our method incorporates both spatial and temporal
geometric constraints to resolve depth and pose scale factors, which are
enforced within the supervisory reconstruction loss functions at training time.
Only unlabeled stereo sequences are required for training the weights of our
single-network architecture, which reduces overall implementation overhead as
compared to previous methods. Our results demonstrate strong performance when
compared to the current state-of-the-art on multiple sequences of the KITTI
driving dataset and can provide faster training times with its reduced network
complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crop mapping from image time series: deep learning with multi-scale label hierarchies. (arXiv:2102.08820v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turkoglu_M/0/1/0/all/0/1">Mehmet Ozgur Turkoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+DAronco_S/0/1/0/all/0/1">Stefano D&#x27;Aronco</a>, <a href="http://arxiv.org/find/cs/1/au:+Perich_G/0/1/0/all/0/1">Gregor Perich</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebisch_F/0/1/0/all/0/1">Frank Liebisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Streit_C/0/1/0/all/0/1">Constantin Streit</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>, <a href="http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1">Jan Dirk Wegner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08820">
                                    <div class="article-summary-box-inner">
                                        <span>The aim of this paper is to map agricultural crops by classifying satellite
image time series. Domain experts in agriculture work with crop type labels
that are organised in a hierarchical tree structure, where coarse classes (like
orchards) are subdivided into finer ones (like apples, pears, vines, etc.). We
develop a crop classification method that exploits this expert knowledge and
significantly improves the mapping of rare crop types. The three-level label
hierarchy is encoded in a convolutional, recurrent neural network (convRNN),
such that for each pixel the model predicts three labels at different level of
granularity. This end-to-end trainable, hierarchical network architecture
allows the model to learn joint feature representations of rare classes (e.g.,
apples, pears) at a coarser level (e.g., orchard), thereby boosting
classification performance at the fine-grained level. Additionally, labelling
at different granularity also makes it possible to adjust the output according
to the classification scores; as coarser labels with high confidence are
sometimes more useful for agricultural practice than fine-grained but very
uncertain labels. We validate the proposed method on a new, large dataset that
we make public. ZueriCrop covers an area of 50 km x 48 km in the Swiss cantons
of Zurich and Thurgau with a total of 116&#x27;000 individual fields spanning 48
crop classes, and 28,000 (multi-temporal) image patches from Sentinel-2. We
compare our proposed hierarchical convRNN model with several baselines,
including methods designed for imbalanced class distributions. The hierarchical
approach performs superior by at least 9.9 percentage points in F1-score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields. (arXiv:2103.13415v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1">Jonathan T. Barron</a>, <a href="http://arxiv.org/find/cs/1/au:+Mildenhall_B/0/1/0/all/0/1">Ben Mildenhall</a>, <a href="http://arxiv.org/find/cs/1/au:+Tancik_M/0/1/0/all/0/1">Matthew Tancik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hedman_P/0/1/0/all/0/1">Peter Hedman</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Brualla_R/0/1/0/all/0/1">Ricardo Martin-Brualla</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_P/0/1/0/all/0/1">Pratul P. Srinivasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13415">
                                    <div class="article-summary-box-inner">
                                        <span>The rendering procedure used by neural radiance fields (NeRF) samples a scene
with a single ray per pixel and may therefore produce renderings that are
excessively blurred or aliased when training or testing images observe scene
content at different resolutions. The straightforward solution of supersampling
by rendering with multiple rays per pixel is impractical for NeRF, because
rendering each ray requires querying a multilayer perceptron hundreds of times.
Our solution, which we call &quot;mip-NeRF&quot; (a la &quot;mipmap&quot;), extends NeRF to
represent the scene at a continuously-valued scale. By efficiently rendering
anti-aliased conical frustums instead of rays, mip-NeRF reduces objectionable
aliasing artifacts and significantly improves NeRF&#x27;s ability to represent fine
details, while also being 7% faster than NeRF and half the size. Compared to
NeRF, mip-NeRF reduces average error rates by 17% on the dataset presented with
NeRF and by 60% on a challenging multiscale variant of that dataset that we
present. Mip-NeRF is also able to match the accuracy of a brute-force
supersampled NeRF on our multiscale dataset while being 22x faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Sensing of Urban Waterlogging. (arXiv:2103.05927v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Shi-Wei Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jyh-Horng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jo-Yu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_C/0/1/0/all/0/1">Chien-Hao Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Meng-Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fang-Pang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05927">
                                    <div class="article-summary-box-inner">
                                        <span>In the monsoon season, sudden flood events occur frequently in urban areas,
which hamper the social and economic activities and may threaten the
infrastructure and lives. The use of an efficient large-scale waterlogging
sensing and information system can provide valuable real-time disaster
information to facilitate disaster management and enhance awareness of the
general public to alleviate losses during and after flood disasters. Therefore,
in this study, a visual sensing approach driven by deep neural networks and
information and communication technology was developed to provide an end-to-end
mechanism to realize waterlogging sensing and event-location mapping. The use
of a deep sensing system in the monsoon season in Taiwan was demonstrated, and
waterlogging events were predicted on the island-wide scale. The system could
sense approximately 2379 vision sources through an internet of video things
framework and transmit the event-location information in 5 min. The proposed
approach can sense waterlogging events at a national scale and provide an
efficient and highly scalable alternative to conventional waterlogging sensing
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiaRet: A browser-based application for the grading of Diabetic Retinopathy with Integrated Gradients. (arXiv:2103.08501v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Patel_S/0/1/0/all/0/1">Shaswat Patel</a>, <a href="http://arxiv.org/find/eess/1/au:+Lohakare_M/0/1/0/all/0/1">Maithili Lohakare</a>, <a href="http://arxiv.org/find/eess/1/au:+Prajapati_S/0/1/0/all/0/1">Samyak Prajapati</a>, <a href="http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1">Shaanya Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Patel_N/0/1/0/all/0/1">Nancy Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08501">
                                    <div class="article-summary-box-inner">
                                        <span>Patients with long-standing diabetes often fall prey to Diabetic Retinopathy
(DR) resulting in changes in the retina of the human eye, which may lead to
loss of vision in extreme cases. The aim of this study is two-fold: (a) create
deep learning models that were trained to grade degraded retinal fundus images
and (b) to create a browser-based application that will aid in diagnostic
procedures by highlighting the key features of the fundus image. In this
research work, we have emulated the images plagued by distortions by degrading
the images based on multiple different combinations of Light Transmission
Disturbance, Image Blurring and insertion of Retinal Artifacts. InceptionV3,
ResNet-50 and InceptionResNetV2 were trained and used to classify retinal
fundus images based on their severity level and then further used in the
creation of a browser-based application, which implements the Integration
Gradient (IG) Attribution Mask on the input image and demonstrates the
predictions made by the model and the probability associated with each class.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global-local Enhancement Network for NMFs-aware Sign Language Recognition. (arXiv:2008.10428v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hezhen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_J/0/1/0/all/0/1">Junfu Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10428">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language recognition (SLR) is a challenging problem, involving complex
manual features, i.e., hand gestures, and fine-grained non-manual features
(NMFs), i.e., facial expression, mouth shapes, etc. Although manual features
are dominant, non-manual features also play an important role in the expression
of a sign word. Specifically, many sign words convey different meanings due to
non-manual features, even though they share the same hand gestures. This
ambiguity introduces great challenges in the recognition of sign words. To
tackle the above issue, we propose a simple yet effective architecture called
Global-local Enhancement Network (GLE-Net), including two mutually promoted
streams towards different crucial aspects of SLR. Of the two streams, one
captures the global contextual relationship, while the other stream captures
the discriminative fine-grained cues. Moreover, due to the lack of datasets
explicitly focusing on this kind of features, we introduce the first
non-manual-features-aware isolated Chinese sign language dataset~(NMFs-CSL)
with a total vocabulary size of 1,067 sign words in daily life. Extensive
experiments on NMFs-CSL and SLR500 datasets demonstrate the effectiveness of
our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Boundary Guided Adversarial Training. (arXiv:2011.11164v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jiequan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11164">
                                    <div class="article-summary-box-inner">
                                        <span>Previous adversarial training raises model robustness under the compromise of
accuracy on natural data. In this paper, we reduce natural accuracy
degradation. We use the model logits from one clean model to guide learning of
another one robust model, taking into consideration that logits from the well
trained clean model embed the most discriminative features of natural data,
{\it e.g.}, generalizable classifier boundary. Our solution is to constrain
logits from the robust model that takes adversarial examples as input and makes
it similar to those from the clean model fed with corresponding natural data.
It lets the robust model inherit the classifier boundary of the clean model.
Moreover, we observe such boundary guidance can not only preserve high natural
accuracy but also benefit model robustness, which gives new insights and
facilitates progress for the adversarial community. Finally, extensive
experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet testify to the
effectiveness of our method. We achieve new state-of-the-art robustness on
CIFAR-100 without additional real or synthetic data with auto-attack benchmark
\footnote{\url{https://github.com/fra31/auto-attack}}. Our code is available at
\url{https://github.com/dvlab-research/LBGAT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CrossNorm and SelfNorm for Generalization under Distribution Shifts. (arXiv:2102.02811v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiqiang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris Metaxas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02811">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional normalization techniques (e.g., Batch Normalization and Instance
Normalization) generally and simplistically assume that training and test data
follow the same distribution. As distribution shifts are inevitable in
real-world applications, well-trained models with previous normalization
methods can perform badly in new environments. Can we develop new normalization
methods to improve generalization robustness under distribution shifts? In this
paper, we answer the question by proposing CrossNorm and SelfNorm. CrossNorm
exchanges channel-wise mean and variance between feature maps to enlarge
training distribution, while SelfNorm uses attention to recalibrate the
statistics to bridge gaps between training and test distributions. CrossNorm
and SelfNorm can complement each other, though exploring different directions
in statistics usage. Extensive experiments on different fields (vision and
language), tasks (classification and segmentation), settings (supervised and
semi-supervised), and distribution shift types (synthetic and natural) show the
effectiveness. Code is available at
https://github.com/amazon-research/crossnorm-selfnorm</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RIN: Textured Human Model Recovery and Imitation with a Single Image. (arXiv:2011.12024v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ran_H/0/1/0/all/0/1">Haoxi Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangfu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Li Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12024">
                                    <div class="article-summary-box-inner">
                                        <span>Human imitation has become topical recently, driven by GAN&#x27;s ability to
disentangle human pose and body content. However, the latest methods hardly
focus on 3D information, and to avoid self-occlusion, a massive amount of input
images are needed. In this paper, we propose RIN, a novel volume-based
framework for reconstructing a textured 3D model from a single picture and
imitating a subject with the generated model. Specifically, to estimate most of
the human texture, we propose a U-Net-like front-to-back translation network.
With both front and back images input, the textured volume recovery module
allows us to color a volumetric human. A sequence of 3D poses then guides the
colored volume via Flowable Disentangle Networks as a volume-to-volume
translation task. To project volumes to a 2D plane during training, we design a
differentiable depth-aware renderer. Our experiments demonstrate that our
volume-based model is adequate for human imitation, and the back view can be
estimated reliably using our network. While prior works based on either 2D pose
or semantic map often fail for the unstable appearance of a human, our
framework can still produce concrete results, which are competitive to those
imagined from multi-view input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crop Classification under Varying Cloud Cover with Neural Ordinary Differential Equations. (arXiv:2012.02542v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Metzger_N/0/1/0/all/0/1">Nando Metzger</a>, <a href="http://arxiv.org/find/cs/1/au:+Turkoglu_M/0/1/0/all/0/1">Mehmet Ozgur Turkoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+DAronco_S/0/1/0/all/0/1">Stefano D&#x27;Aronco</a>, <a href="http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1">Jan Dirk Wegner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02542">
                                    <div class="article-summary-box-inner">
                                        <span>Optical satellite sensors cannot see the Earth&#x27;s surface through clouds.
Despite the periodic revisit cycle, image sequences acquired by Earth
observation satellites are therefore irregularly sampled in time.
State-of-the-art methods for crop classification (and other time series
analysis tasks) rely on techniques that implicitly assume regular temporal
spacing between observations, such as recurrent neural networks (RNNs). We
propose to use neural ordinary differential equations (NODEs) in combination
with RNNs to classify crop types in irregularly spaced image sequences. The
resulting ODE-RNN models consist of two steps: an update step, where a
recurrent unit assimilates new input data into the model&#x27;s hidden state; and a
prediction step, in which NODE propagates the hidden state until the next
observation arrives. The prediction step is based on a continuous
representation of the latent dynamics, which has several advantages. At the
conceptual level, it is a more natural way to describe the mechanisms that
govern the phenological cycle. From a practical point of view, it makes it
possible to sample the system state at arbitrary points in time, such that one
can integrate observations whenever they are available, and extrapolate beyond
the last observation. Our experiments show that ODE-RNN indeed improves
classification accuracy over common baselines such as LSTM, GRU, and temporal
convolution. The gains are most prominent in the challenging scenario where
only few observations are available (i.e., frequent cloud cover). Moreover, we
show that the ability to extrapolate translates to better classification
performance early in the season, which is important for forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Image Super-Resolution in Arbitrary Input-Output Band Settings. (arXiv:2103.10614v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhongyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1">Zia Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Salekin_A/0/1/0/all/0/1">Asif Salekin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1">Tauhidur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10614">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral image (HSI) with narrow spectral bands can capture rich
spectral information, but it sacrifices its spatial resolution in the process.
Many machine-learning-based HSI super-resolution (SR) algorithms have been
proposed recently. However, one of the fundamental limitations of these
approaches is that they are highly dependent on image and camera settings and
can only learn to map an input HSI with one specific setting to an output HSI
with another. However, different cameras capture images with different spectral
response functions and bands numbers due to the diversity of HSI cameras.
Consequently, the existing machine-learning-based approaches fail to learn to
super-resolve HSIs for a wide variety of input-output band settings. We propose
a single Meta-Learning-Based Super-Resolution (MLSR) model, which can take in
HSI images at an arbitrary number of input bands&#x27; peak wavelengths and generate
SR HSIs with an arbitrary number of output bands&#x27; peak wavelengths. We leverage
NTIRE2020 and ICVL datasets to train and validate the performance of the MLSR
model. The results show that the single proposed model can successfully
generate super-resolved HSI bands at arbitrary input-output band settings. The
results are better or at least comparable to baselines that are separately
trained on a specific input-output band setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lips Don&#x27;t Lie: A Generalisable and Robust Approach to Face Forgery Detection. (arXiv:2012.07657v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haliassos_A/0/1/0/all/0/1">Alexandros Haliassos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vougioukas_K/0/1/0/all/0/1">Konstantinos Vougioukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1">Stavros Petridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07657">
                                    <div class="article-summary-box-inner">
                                        <span>Although current deep learning-based face forgery detectors achieve
impressive performance in constrained scenarios, they are vulnerable to samples
created by unseen manipulation methods. Some recent works show improvements in
generalisation but rely on cues that are easily corrupted by common
post-processing operations such as compression. In this paper, we propose
LipForensics, a detection approach capable of both generalising to novel
manipulations and withstanding various distortions. LipForensics targets
high-level semantic irregularities in mouth movements, which are common in many
generated videos. It consists in first pretraining a spatio-temporal network to
perform visual speech recognition (lipreading), thus learning rich internal
representations related to natural mouth motion. A temporal network is
subsequently finetuned on fixed mouth embeddings of real and forged data in
order to detect fake videos based on mouth movements without overfitting to
low-level, manipulation-specific artefacts. Extensive experiments show that
this simple approach significantly surpasses the state-of-the-art in terms of
generalisation to unseen manipulations and robustness to perturbations, as well
as shed light on the factors responsible for its performance. Code is available
on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VLG-Net: Video-Language Graph Matching Network for Video Grounding. (arXiv:2011.10132v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soldan_M/0/1/0/all/0/1">Mattia Soldan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengmeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1">Sisi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1">Jesper Tegner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10132">
                                    <div class="article-summary-box-inner">
                                        <span>Grounding language queries in videos aims at identifying the time interval
(or moment) semantically relevant to a language query. The solution to this
challenging task demands understanding videos&#x27; and queries&#x27; semantic content
and the fine-grained reasoning about their multi-modal interactions. Our key
idea is to recast this challenge into an algorithmic graph matching problem.
Fueled by recent advances in Graph Neural Networks, we propose to leverage
Graph Convolutional Networks to model video and textual information as well as
their semantic alignment. To enable the mutual exchange of information across
the modalities, we design a novel Video-Language Graph Matching Network
(VLG-Net) to match video and query graphs. Core ingredients include
representation graphs built atop video snippets and query tokens separately and
used to model intra-modality relationships. A Graph Matching layer is adopted
for cross-modal context modeling and multi-modal fusion. Finally, moment
candidates are created using masked moment attention pooling by fusing the
moment&#x27;s enriched snippet features. We demonstrate superior performance over
state-of-the-art grounding methods on three widely used datasets for temporal
localization of moments in videos with language queries: ActivityNet-Captions,
TACoS, and DiDeMo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure-Aware Feature Generation for Zero-Shot Learning. (arXiv:2108.07032v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lianbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaoli Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinchao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07032">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-Shot Learning (ZSL) targets at recognizing unseen categories by
leveraging auxiliary information, such as attribute embedding. Despite the
encouraging results achieved, prior ZSL approaches focus on improving the
discriminant power of seen-class features, yet have largely overlooked the
geometric structure of the samples and the prototypes. The subsequent
attribute-based generative adversarial network (GAN), as a result, also
neglects the topological information in sample generation and further yields
inferior performances in classifying the visual features of unseen classes. In
this paper, we introduce a novel structure-aware feature generation scheme,
termed as SA-GAN, to explicitly account for the topological structure in
learning both the latent space and the generative networks. Specifically, we
introduce a constraint loss to preserve the initial geometric structure when
learning a discriminative latent space, and carry out our GAN training with
additional supervising signals from a structure-aware discriminator and a
reconstruction module. The former supervision distinguishes fake and real
samples based on their affinity to class prototypes, while the latter aims to
reconstruct the original feature space from the generated latent space. This
topology-preserving mechanism enables our method to significantly enhance the
generalization capability on unseen-classes and consequently improve the
classification performance. Experiments on four benchmarks demonstrate that the
proposed approach consistently outperforms the state of the art. Our code can
be found in the supplementary material and will also be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CFC-Net: A Critical Feature Capturing Network for Arbitrary-Oriented Object Detection in Remote Sensing Images. (arXiv:2101.06849v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1">Qi Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_L/0/1/0/all/0/1">Lingjuan Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhiqiang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yunpeng Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06849">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection in optical remote sensing images is an important and
challenging task. In recent years, the methods based on convolutional neural
networks have made good progress. However, due to the large variation in object
scale, aspect ratio, and arbitrary orientation, the detection performance is
difficult to be further improved. In this paper, we discuss the role of
discriminative features in object detection, and then propose a Critical
Feature Capturing Network (CFC-Net) to improve detection accuracy from three
aspects: building powerful feature representation, refining preset anchors, and
optimizing label assignment. Specifically, we first decouple the classification
and regression features, and then construct robust critical features adapted to
the respective tasks through the Polarization Attention Module (PAM). With the
extracted discriminative regression features, the Rotation Anchor Refinement
Module (R-ARM) performs localization refinement on preset horizontal anchors to
obtain superior rotation anchors. Next, the Dynamic Anchor Learning (DAL)
strategy is given to adaptively select high-quality anchors based on their
ability to capture critical features. The proposed framework creates more
powerful semantic representations for objects in remote sensing images and
achieves high-performance real-time object detection. Experimental results on
three remote sensing datasets including HRSC2016, DOTA, and UCAS-AOD show that
our method achieves superior detection performance compared with many
state-of-the-art approaches. Code and models are available at
https://github.com/ming71/CFC-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Regularizers for Attributional Robustness. (arXiv:2012.14395v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Anindya Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Anirban Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14395">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are the default choice of learning models for computer
vision tasks. Extensive work has been carried out in recent years on explaining
deep models for vision tasks such as classification. However, recent work has
shown that it is possible for these models to produce substantially different
attribution maps even when two very similar images are given to the network,
raising serious questions about trustworthiness. To address this issue, we
propose a robust attribution training strategy to improve attributional
robustness of deep neural networks. Our method carefully analyzes the
requirements for attributional robustness and introduces two new regularizers
that preserve a model&#x27;s attribution map during attacks. Our method surpasses
state-of-the-art attributional robustness methods by a margin of approximately
3% to 9% in terms of attribution robustness measures on several datasets
including MNIST, FMNIST, Flower and GTSRB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Dilation for Adversarial Robustness. (arXiv:2108.06885v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaohui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06885">
                                    <div class="article-summary-box-inner">
                                        <span>With the tremendous advances in the architecture and scale of convolutional
neural networks (CNNs) over the past few decades, they can easily reach or even
exceed the performance of humans in certain tasks. However, a recently
discovered shortcoming of CNNs is that they are vulnerable to adversarial
attacks. Although the adversarial robustness of CNNs can be improved by
adversarial training, there is a trade-off between standard accuracy and
adversarial robustness. From the neural architecture perspective, this paper
aims to improve the adversarial robustness of the backbone CNNs that have a
satisfactory accuracy. Under a minimal computational overhead, the introduction
of a dilation architecture is expected to be friendly with the standard
performance of the backbone CNN while pursuing adversarial robustness.
Theoretical analyses on the standard and adversarial error bounds naturally
motivate the proposed neural architecture dilation algorithm. Experimental
results on real-world datasets and benchmark neural networks demonstrate the
effectiveness of the proposed algorithm to balance the accuracy and adversarial
robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spot the conversation: speaker diarisation in the wild. (arXiv:2007.01216v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Joon Son Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Huh_J/0/1/0/all/0/1">Jaesung Huh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagrani_A/0/1/0/all/0/1">Arsha Nagrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Afouras_T/0/1/0/all/0/1">Triantafyllos Afouras</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01216">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of this paper is speaker diarisation of videos collected &#x27;in the
wild&#x27;. We make three key contributions. First, we propose an automatic
audio-visual diarisation method for YouTube videos. Our method consists of
active speaker detection using audio-visual methods and speaker verification
using self-enrolled speaker models. Second, we integrate our method into a
semi-automatic dataset creation pipeline which significantly reduces the number
of hours required to annotate videos with diarisation labels. Finally, we use
this pipeline to create a large-scale diarisation dataset called VoxConverse,
collected from &#x27;in the wild&#x27; videos, which we will release publicly to the
research community. Our dataset consists of overlapping speech, a large and
diverse speaker pool, and challenging background conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Breast Lesion Detection in Ultrafast DCE-MRI Using Deep Learning. (arXiv:2102.03932v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ayatollahi_F/0/1/0/all/0/1">Fazael Ayatollahi</a> (1 and 2), <a href="http://arxiv.org/find/eess/1/au:+Shokouhi_S/0/1/0/all/0/1">Shahriar B. Shokouhi</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Mann_R/0/1/0/all/0/1">Ritse M. Mann</a> (2), <a href="http://arxiv.org/find/eess/1/au:+Teuwen_J/0/1/0/all/0/1">Jonas Teuwen</a> (2 and 3) ((1) Electrical Engineering Department, Iran University of Science and Technology (IUST), Tehran, Iran, (2) Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, the Netherlands, (3) Department of Radiation Oncology, Netherlands Cancer Institute, Amsterdam, the Netherlands)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03932">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: We propose a deep learning-based computer-aided detection (CADe)
method to detect breast lesions in ultrafast DCE-MRI sequences. This method
uses both the three-dimensional spatial information and temporal information
obtained from the early-phase of the dynamic acquisition. Methods: The proposed
CADe method, based on a modified 3D RetinaNet model, operates on ultrafast T1
weighted sequences, which are preprocessed for motion compensation, temporal
normalization, and are cropped before passing into the model. The model is
optimized to enable the detection of relatively small breast lesions in a
screening setting, focusing on detection of lesions that are harder to
differentiate from confounding structures inside the breast. Results: The
method was developed based on a dataset consisting of 489 ultrafast MRI studies
obtained from 462 patients containing a total of 572 lesions (365 malignant,
207 benign) and achieved a detection rate, sensitivity, and detection rate of
benign lesions of 0.90 (0.876-0.934), 0.95 (0.934-0.980), and 0.81
(0.751-0.871) at 4 false positives per normal breast with 10-fold
cross-testing, respectively. Conclusions: The deep learning architecture used
for the proposed CADe application can efficiently detect benign and malignant
lesions on ultrafast DCE-MRI. Furthermore, utilizing the less visible hard-to
detect-lesions in training improves the learning process and, subsequently,
detection of malignant breast lesions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose and Shape Estimation from Single Polarization Images. (arXiv:2108.06834v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1">Shihao Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xinxin Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yiming Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1">Wei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Minglun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Li Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06834">
                                    <div class="article-summary-box-inner">
                                        <span>This paper focuses on a new problem of estimating human pose and shape from
single polarization images. Polarization camera is known to be able to capture
the polarization of reflected lights that preserves rich geometric cues of an
object surface. Inspired by the recent applications in surface normal
reconstruction from polarization images, in this paper, we attempt to estimate
human pose and shape from single polarization images by leveraging the
polarization-induced geometric cues. A dedicated two-stage pipeline is
proposed: given a single polarization image, stage one (Polar2Normal) focuses
on the fine detailed human body surface normal estimation; stage two
(Polar2Shape) then reconstructs clothed human shape from the polarization image
and the estimated surface normal. To empirically validate our approach, a
dedicated dataset (PHSPD) is constructed, consisting of over 500K frames with
accurate pose and shape annotations. Empirical evaluations on this real-world
dataset as well as a synthetic dataset, SURREAL, demonstrate the effectiveness
of our approach. It suggests polarization camera as a promising alternative to
the more conventional RGB camera for human pose and shape estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-shot Hyperspectral-Depth Imaging with Learned Diffractive Optics. (arXiv:2009.00463v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Baek_S/0/1/0/all/0/1">Seung-Hwan Baek</a>, <a href="http://arxiv.org/find/eess/1/au:+Ikoma_H/0/1/0/all/0/1">Hayato Ikoma</a>, <a href="http://arxiv.org/find/eess/1/au:+Jeon_D/0/1/0/all/0/1">Daniel S. Jeon</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yuqi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Heidrich_W/0/1/0/all/0/1">Wolfgang Heidrich</a>, <a href="http://arxiv.org/find/eess/1/au:+Wetzstein_G/0/1/0/all/0/1">Gordon Wetzstein</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_M/0/1/0/all/0/1">Min H. Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00463">
                                    <div class="article-summary-box-inner">
                                        <span>Imaging depth and spectrum have been extensively studied in isolation from
each other for decades. Recently, hyperspectral-depth (HS-D) imaging emerges to
capture both information simultaneously by combining two different imaging
systems; one for depth, the other for spectrum. While being accurate, this
combinational approach induces increased form factor, cost, capture time, and
alignment/registration problems. In this work, departing from the combinational
principle, we propose a compact single-shot monocular HS-D imaging method. Our
method uses a diffractive optical element (DOE), the point spread function of
which changes with respect to both depth and spectrum. This enables us to
reconstruct spectrum and depth from a single captured image. To this end, we
develop a differentiable simulator and a neural-network-based reconstruction
that are jointly optimized via automatic differentiation. To facilitate
learning the DOE, we present a first HS-D dataset by building a benchtop HS-D
imager that acquires high-quality ground truth. We evaluate our method with
synthetic and real experiments by building an experimental prototype and
achieve state-of-the-art HS-D imaging results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks. (arXiv:1911.11897v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11897">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art methods in image-to-image translation are capable of
learning a mapping from a source domain to a target domain with unpaired image
data. Though the existing methods have achieved promising results, they still
produce visual artifacts, being able to translate low-level information but not
high-level semantics of input images. One possible reason is that generators do
not have the ability to perceive the most discriminative parts between the
source and target domains, thus making the generated images low quality. In
this paper, we propose a new Attention-Guided Generative Adversarial Networks
(AttentionGAN) for the unpaired image-to-image translation task. AttentionGAN
can identify the most discriminative foreground objects and minimize the change
of the background. The attention-guided generators in AttentionGAN are able to
produce attention masks, and then fuse the generation output with the attention
masks to obtain high-quality target images. Accordingly, we also design a novel
attention-guided discriminator which only considers attended regions. Extensive
experiments are conducted on several generative tasks with eight public
datasets, demonstrating that the proposed method is effective to generate
sharper and more realistic images compared with existing competitive models.
The code is available at https://github.com/Ha0Tang/AttentionGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting. (arXiv:2007.03260v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xiaohan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_T/0/1/0/all/0/1">Tianxiang Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jianchao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jungong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuchen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guiguang Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03260">
                                    <div class="article-summary-box-inner">
                                        <span>We propose ResRep, a novel method for lossless channel pruning (a.k.a. filter
pruning), which slims down a CNN by reducing the width (number of output
channels) of convolutional layers. Inspired by the neurobiology research about
the independence of remembering and forgetting, we propose to re-parameterize a
CNN into the remembering parts and forgetting parts, where the former learn to
maintain the performance and the latter learn to prune. Via training with
regular SGD on the former but a novel update rule with penalty gradients on the
latter, we realize structured sparsity. Then we equivalently merge the
remembering and forgetting parts into the original architecture with narrower
layers. In this sense, ResRep can be viewed as a successful application of
Structural Re-parameterization. Such a methodology distinguishes ResRep from
the traditional learning-based pruning paradigm that applies a penalty on
parameters to produce sparsity, which may suppress the parameters essential for
the remembering. ResRep slims down a standard ResNet-50 with 76.15% accuracy on
ImageNet to a narrower one with only 45% FLOPs and no accuracy drop, which is
the first to achieve lossless pruning with such a high compression ratio. The
code and models are at https://github.com/DingXiaoH/ResRep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Computation-Efficient CNN System for High-Quality Brain Tumor Segmentation. (arXiv:2007.12066v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1">Yanming Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chunyan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12066">
                                    <div class="article-summary-box-inner">
                                        <span>The work presented in this paper is to propose a reliable high-quality system
of Convolutional Neural Network (CNN) for brain tumor segmentation with a low
computation requirement. The system consists of a CNN for the main processing
for the segmentation, a pre-CNN block for data reduction and post-CNN
refinement block. The unique CNN consists of 7 convolution layers involving
only 108 kernels and 20308 trainable parameters. It is custom-designed,
following the proposed paradigm of ASCNN (application specific CNN), to perform
mono-modality and cross-modality feature extraction, tumor localization and
pixel classification. Each layer fits the task assigned to it, by means of (i)
appropriate normalization applied to its input data, (ii) correct convolution
modes for the assigned task, and (iii) suitable nonlinear transformation to
optimize the convolution results. In this specific design context, the number
of kernels in each of the 7 layers is made to be just-sufficient for its task,
instead of exponentially growing over the layers, to increase information
density and to reduce randomness in the processing. The proposed activation
function Full-ReLU helps to halve the number of kernels in convolution layers
of high-pass filtering without degrading processing quality. A large number of
experiments with BRATS2018 dataset have been conducted to measure the
processing quality and reproducibility of the proposed system. The results
demonstrate that the system reproduces reliably almost the same output to the
same input after retraining. The mean dice scores for enhancing tumor, whole
tumor and tumor core are 77.2%, 89.2% and 76.3%, respectively. The simple
structure and reliable high processing quality of the proposed system will
facilitate its implementation and medical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient and Data Agnostic Image Classification Training Pipeline for Embedded Systems. (arXiv:2108.07049v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Prokofiev_K/0/1/0/all/0/1">Kirill Prokofiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sovrasov_V/0/1/0/all/0/1">Vladislav Sovrasov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07049">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays deep learning-based methods have achieved a remarkable progress at
the image classification task among a wide range of commonly used datasets
(ImageNet, CIFAR, SVHN, Caltech 101, SUN397, etc.). SOTA performance on each of
the mentioned datasets is obtained by careful tuning of the model architecture
and training tricks according to the properties of the target data. Although
this approach allows setting academic records, it is unrealistic that an
average data scientist would have enough resources to build a sophisticated
training pipeline for every image classification task he meets in practice.
This work is focusing on reviewing the latest augmentation and regularization
methods for the image classification and exploring ways to automatically choose
some of the most important hyperparameters: total number of epochs, initial
learning rate value and it&#x27;s schedule. Having a training procedure equipped
with a lightweight modern CNN architecture (like bileNetV3 or EfficientNet),
sufficient level of regularization and adaptive to data learning rate schedule,
we can achieve a reasonable performance on a variety of downstream image
classification tasks without manual tuning of parameters to each particular
task. Resulting models are computationally efficient and can be deployed to CPU
using the OpenVINO toolkit. Source code is available as a part of the OpenVINO
Training Extensions (https://github.com/openvinotoolkit/training_extensions).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Canonical View Representation for 3D Shape Recognition with Arbitrary Views. (arXiv:2108.07084v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yifei Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fudong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xing Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07084">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we focus on recognizing 3D shapes from arbitrary views, i.e.,
arbitrary numbers and positions of viewpoints. It is a challenging and
realistic setting for view-based 3D shape recognition. We propose a canonical
view representation to tackle this challenge. We first transform the original
features of arbitrary views to a fixed number of view features, dubbed
canonical view representation, by aligning the arbitrary view features to a set
of learnable reference view features using optimal transport. In this way, each
3D shape with arbitrary views is represented by a fixed number of canonical
view features, which are further aggregated to generate a rich and robust 3D
shape representation for shape recognition. We also propose a canonical view
feature separation constraint to enforce that the view features in canonical
view representation can be embedded into scattered points in a Euclidean space.
Experiments on the ModelNet40, ScanObjectNN, and RGBD datasets show that our
method achieves competitive results under the fixed viewpoint settings, and
significantly outperforms the applicable methods under the arbitrary view
setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Smooth Representation for Unsupervised Domain Adaptation. (arXiv:1905.10748v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_G/0/1/0/all/0/1">Guanyu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lianghua He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengchu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Alhumade_H/0/1/0/all/0/1">Hesham Alhumade</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Die Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10748">
                                    <div class="article-summary-box-inner">
                                        <span>Typical adversarial-training-based unsupervised domain adaptation methods are
vulnerable when the source and target datasets are highly-complex or exhibit a
large discrepancy between their data distributions. Recently, several
Lipschitz-constraint-based methods have been explored. The satisfaction of
Lipschitz continuity guarantees a remarkable performance on a target domain.
However, they lack a mathematical analysis of why a Lipschitz constraint is
beneficial to unsupervised domain adaptation and usually perform poorly on
large-scale datasets. In this paper, we take the principle of utilizing a
Lipschitz constraint further by discussing how it affects the error bound of
unsupervised domain adaptation. A connection between them is built and an
illustration of how Lipschitzness reduces the error bound is presented. A
\textbf{local smooth discrepancy} is defined to measure Lipschitzness of a
target distribution in a pointwise way. When constructing a deep end-to-end
model, to ensure the effectiveness and stability of unsupervised domain
adaptation, three critical factors are considered in our proposed optimization
strategy, i.e., the sample amount of a target domain, dimension and batchsize
of samples. Experimental results demonstrate that our model performs well on
several standard benchmarks. Our ablation study shows that the sample amount of
a target domain, the dimension and batchsize of samples indeed greatly impact
Lipschitz-constraint-based methods&#x27; ability to handle large-scale datasets.
Code is available at https://github.com/CuthbertCai/SRDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WikiChurches: A Fine-Grained Dataset of Architectural Styles with Real-World Challenges. (arXiv:2108.06959v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barz_B/0/1/0/all/0/1">Bj&#xf6;rn Barz</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06959">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel dataset for architectural style classification,
consisting of 9,485 images of church buildings. Both images and style labels
were sourced from Wikipedia. The dataset can serve as a benchmark for various
research fields, as it combines numerous real-world challenges: fine-grained
distinctions between classes based on subtle visual features, a comparatively
small sample size, a highly imbalanced class distribution, a high variance of
viewpoints, and a hierarchical organization of labels, where only some images
are labeled at the most precise level. In addition, we provide 631 bounding box
annotations of characteristic visual features for 139 churches from four major
categories. These annotations can, for example, be useful for research on
fine-grained classification, where additional expert knowledge about
distinctive object parts is often available. Images and annotations are
available at: https://doi.org/10.5281/zenodo.5166987</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08435">
                                    <div class="article-summary-box-inner">
                                        <span>Since the Lipschitz properties of convolutional neural networks (CNNs) are
widely considered to be related to adversarial robustness, we theoretically
characterize the $\ell_1$ norm and $\ell_\infty$ norm of 2D multi-channel
convolutional layers and provide efficient methods to compute the exact
$\ell_1$ norm and $\ell_\infty$ norm. Based on our theorem, we propose a novel
regularization method termed norm decay, which can effectively reduce the norms
of convolutional layers and fully-connected layers. Experiments show that
norm-regularization methods, including norm decay, weight decay, and singular
value clipping, can improve generalization of CNNs. However, they can slightly
hurt adversarial robustness. Observing this unexpected phenomenon, we compute
the norms of layers in the CNNs trained with three different adversarial
training frameworks and surprisingly find that adversarially robust CNNs have
comparable or even larger layer norms than their non-adversarially robust
counterparts. Furthermore, we prove that under a mild assumption, adversarially
robust classifiers can be achieved using neural networks, and an adversarially
robust neural network can have an arbitrarily large Lipschitz constant. For
this reason, enforcing small norms on CNN layers may be neither necessary nor
effective in achieving adversarial robustness. The code is available at
https://github.com/youweiliang/norm_robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-driven Colorization. (arXiv:2006.07587v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_M/0/1/0/all/0/1">Man M. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Raake_A/0/1/0/all/0/1">Alexander Raake</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jinjia Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07587">
                                    <div class="article-summary-box-inner">
                                        <span>Recent colorization works implicitly predict the semantic information while
learning to colorize black-and-white images. Consequently, the generated color
is easier to be overflowed, and the semantic faults are invisible. As a human
experience in colorization, our brains first detect and recognize the objects
in the photo, then imagine their plausible colors based on many similar objects
we have seen in real life, and finally colorize them, as described in the
teaser. In this study, we simulate that human-like action to let our network
first learn to understand the photo, then colorize it. Thus, our work can
provide plausible colors at a semantic level. Plus, the semantic information of
the learned model becomes understandable and able to interact. Additionally, we
also prove that Instance Normalization is also a missing ingredient for
colorization, then re-design the inference flow of U-Net to have two streams of
data, providing an appropriate way of normalizing the feature maps from the
black-and-white image and its semantic map. As a result, our network can
provide plausible colors competitive to the typical colorization works for
specific objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U-mesh: Human Correspondence Matching with Mesh Convolutional Networks. (arXiv:2108.06695v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Groisser_B/0/1/0/all/0/1">Benjamin Groisser</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_A/0/1/0/all/0/1">Alon Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimmel_R/0/1/0/all/0/1">Ron Kimmel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06695">
                                    <div class="article-summary-box-inner">
                                        <span>The proliferation of 3D scanning technology has driven a need for methods to
interpret geometric data, particularly for human subjects. In this paper we
propose an elegant fusion of regression (bottom-up) and generative (top-down)
methods to fit a parametric template model to raw scan meshes.

Our first major contribution is an intrinsic convolutional mesh U-net
architecture that predicts pointwise correspondence to a template surface.
Soft-correspondence is formulated as coordinates in a newly-constructed
Cartesian space. Modeling correspondence as Euclidean proximity enables
efficient optimization, both for network training and for the next step of the
algorithm.

Our second contribution is a generative optimization algorithm that uses the
U-net correspondence predictions to guide a parametric Iterative Closest Point
registration. By employing pre-trained human surface parametric models we
maximally leverage domain-specific prior knowledge.

The pairing of a mesh-convolutional network with generative model fitting
enables us to predict correspondence for real human surface scans including
occlusions, partialities, and varying genus (e.g. from self-contact). We
evaluate the proposed method on the FAUST correspondence challenge where we
achieve 20% (33%) improvement over state of the art methods for inter- (intra-)
subject correspondence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Sparse Coding Interpretation of Neural Networks and Theoretical Implications. (arXiv:2108.06622v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bowren_J/0/1/0/all/0/1">Joshua Bowren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06622">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks, specifically deep convolutional neural networks, have
achieved unprecedented performance in various computer vision tasks, but the
rationale for the computations and structures of successful neural networks is
not fully understood. Theories abound for the aptitude of convolutional neural
networks for image classification, but less is understood about why such models
would be capable of complex visual tasks such as inference and anomaly
identification. Here, we propose a sparse coding interpretation of neural
networks that have ReLU activation and of convolutional neural networks in
particular. In sparse coding, when the model&#x27;s basis functions are assumed to
be orthogonal, the optimal coefficients are given by the soft-threshold
function of the basis functions projected onto the input image. In a
non-negative variant of sparse coding, the soft-threshold function becomes a
ReLU. Here, we derive these solutions via sparse coding with orthogonal-assumed
basis functions, then we derive the convolutional neural network forward
transformation from a modified non-negative orthogonal sparse coding model with
an exponential prior parameter for each sparse coding coefficient. Next, we
derive a complete convolutional neural network without normalization and
pooling by adding logistic regression to a hierarchical sparse coding model.
Finally we motivate potentially more robust forward transformations by
maintaining sparse priors in convolutional neural networks as well performing a
stronger nonlinear transformation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Temporal Coherence for More General Video Face Forgery Detection. (arXiv:2108.06693v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yinglin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_F/0/1/0/all/0/1">Fang Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06693">
                                    <div class="article-summary-box-inner">
                                        <span>Although current face manipulation techniques achieve impressive performance
regarding quality and controllability, they are struggling to generate temporal
coherent face videos. In this work, we explore to take full advantage of the
temporal coherence for video face forgery detection. To achieve this, we
propose a novel end-to-end framework, which consists of two major stages. The
first stage is a fully temporal convolution network (FTCN). The key insight of
FTCN is to reduce the spatial convolution kernel size to 1, while maintaining
the temporal convolution kernel size unchanged. We surprisingly find this
special design can benefit the model for extracting the temporal features as
well as improve the generalization capability. The second stage is a Temporal
Transformer network, which aims to explore the long-term temporal coherence.
The proposed framework is general and flexible, which can be directly trained
from scratch without any pre-training models or external datasets. Extensive
experiments show that our framework outperforms existing methods and remains
effective when applied to detect new sorts of face forgery videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Open-World Object Proposals without Learning to Classify. (arXiv:2108.06753v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dahun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelova_A/0/1/0/all/0/1">Anelia Angelova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_W/0/1/0/all/0/1">Weicheng Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06753">
                                    <div class="article-summary-box-inner">
                                        <span>Object proposals have become an integral preprocessing steps of many vision
pipelines including object detection, weakly supervised detection, object
discovery, tracking, etc. Compared to the learning-free methods, learning-based
proposals have become popular recently due to the growing interest in object
detection. The common paradigm is to learn object proposals from data labeled
with a set of object regions and their corresponding categories. However, this
approach often struggles with novel objects in the open world that are absent
in the training set. In this paper, we identify that the problem is that the
binary classifiers in existing proposal methods tend to overfit to the training
categories. Therefore, we propose a classification-free Object Localization
Network (OLN) which estimates the objectness of each region purely by how well
the location and shape of a region overlap with any ground-truth object (e.g.,
centerness and IoU). This simple strategy learns generalizable objectness and
outperforms existing proposals on cross-category generalization on COCO, as
well as cross-dataset evaluation on RoboNet, Object365, and EpicKitchens.
Finally, we demonstrate the merit of OLN for long-tail object detection on
large vocabulary dataset, LVIS, where we notice clear improvement in rare and
common categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Foreground-Action Consistency Network for Weakly Supervised Temporal Action Localization. (arXiv:2108.06524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Linjiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06524">
                                    <div class="article-summary-box-inner">
                                        <span>As a challenging task of high-level video understanding, weakly supervised
temporal action localization has been attracting increasing attention. With
only video annotations, most existing methods seek to handle this task with a
localization-by-classification framework, which generally adopts a selector to
select snippets of high probabilities of actions or namely the foreground.
Nevertheless, the existing foreground selection strategies have a major
limitation of only considering the unilateral relation from foreground to
actions, which cannot guarantee the foreground-action consistency. In this
paper, we present a framework named FAC-Net based on the I3D backbone, on which
three branches are appended, named class-wise foreground classification branch,
class-agnostic attention branch and multiple instance learning branch. First,
our class-wise foreground classification branch regularizes the relation
between actions and foreground to maximize the foreground-background
separation. Besides, the class-agnostic attention branch and multiple instance
learning branch are adopted to regularize the foreground-action consistency and
help to learn a meaningful foreground classifier. Within each branch, we
introduce a hybrid attention mechanism, which calculates multiple attention
scores for each snippet, to focus on both discriminative and
less-discriminative snippets to capture the full action boundaries.
Experimental results on THUMOS14 and ActivityNet1.3 demonstrate the
state-of-the-art performance of our method. Our code is available at
https://github.com/LeonHLJ/FAC-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of Abnormal States in Videos of Ants Undergoing Social Phase Change. (arXiv:2009.08626v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_T/0/1/0/all/0/1">Taeyeong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyenson_B/0/1/0/all/0/1">Benjamin Pyenson</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebig_J/0/1/0/all/0/1">Juergen Liebig</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlic_T/0/1/0/all/0/1">Theodore P. Pavlic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08626">
                                    <div class="article-summary-box-inner">
                                        <span>Biology is both an important application area and a source of motivation for
development of advanced machine learning techniques. Although much attention
has been paid to large and complex data sets resulting from high-throughput
sequencing, advances in high-quality video recording technology have begun to
generate similarly rich data sets requiring sophisticated techniques from both
computer vision and time-series analysis. Moreover, just as studying gene
expression patterns in one organism can reveal general principles that apply to
other organisms, the study of complex social interactions in an experimentally
tractable model system, such as a laboratory ant colony, can provide general
principles about the dynamics of other social groups. Here, we focus on one
such example from the study of reproductive regulation in small laboratory
colonies of more than 50 Harpegnathos ants. These ants can be artificially
induced to begin a ~20 day process of hierarchy reformation. Although the
conclusion of this process is conspicuous to a human observer, it remains
unclear which behaviors during the transient period are contributing to the
process. To address this issue, we explore the potential application of
One-class Classification (OC) to the detection of abnormal states in ant
colonies for which behavioral data is only available for the normal societal
conditions during training. Specifically, we build upon the Deep Support Vector
Data Description (DSVDD) and introduce the Inner-Outlier Generator (IO-GEN)
that synthesizes fake &quot;inner outlier&quot; observations during training that are
near the center of the DSVDD data description. We show that IO-GEN increases
the reliability of the final OC classifier relative to other DSVDD baselines.
This method can be used to screen video frames for which additional human
observation is needed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Process of image super-resolution. (arXiv:1904.08396v8 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lablanche_S/0/1/0/all/0/1">Sebastien Lablanche</a>, <a href="http://arxiv.org/find/eess/1/au:+Lablanche_G/0/1/0/all/0/1">Gerard Lablanche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08396">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we explain a process of super-resolution reconstruction
allowing to increase the resolution of an image.The need for high-resolution
digital images exists in diverse domains, for example the medical and spatial
domains. The obtaining of high-resolution digital images can be made at the
time of the shooting, but it is often synonymic of important costs because of
the necessary material to avoid such costs, it is known how to use methods of
super-resolution reconstruction, consisting from one or several low resolution
images to obtain a high-resolution image. The american patent US 9208537
describes such an algorithm. A zone of one low-resolution image is isolated and
categorized according to the information contained in pixels forming the
borders of the zone. The category of it zone determines the type of
interpolation used to add pixels in aforementioned zone, to increase the
neatness of the images. It is also known how to reconstruct a low-resolution
image there high-resolution image by using a model of super-resolution
reconstruction whose learning is based on networks of neurons and on image or a
picture library. The demand of chinese patent CN 107563965 and the scientist
publication &quot;Pixel Recursive Super Resolution&quot;, R. Dahl, M. Norouzi, J. Shlens
propose such methods. The aim of this paper is to demonstrate that it is
possible to reconstruct coherent human faces from very degraded pixelated
images with a very fast algorithm, more faster than compressed sensing (CS),
easier to compute and without deep learning, so without important technology
resources, i.e. a large database of thousands training images (see
arXiv:2003.13063).

This technological breakthrough has been patented in 2018 with the demand of
French patent FR 1855485 (https://patents.google.com/patent/FR3082980A1, see
the HAL reference https://hal.archives-ouvertes.fr/hal-01875898v1).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search. (arXiv:1908.06022v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruijun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xudong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.06022">
                                    <div class="article-summary-box-inner">
                                        <span>To discover powerful yet compact models is an important goal of neural
architecture search. Previous two-stage one-shot approaches are limited by
search space with a fixed depth. It seems handy to include an additional skip
connection in the search space to make depths variable. However, it creates a
large range of perturbation during supernet training and it has difficulty
giving a confident ranking for subnetworks. In this paper, we discover that
skip connections bring about significant feature inconsistency compared with
other operations, which potentially degrades the supernet performance. Based on
this observation, we tackle the problem by imposing an equivariant learnable
stabilizer to homogenize such disparities. Experiments show that our proposed
stabilizer helps to improve the supernet&#x27;s convergence as well as ranking
performance. With an evolutionary search backend that incorporates the
stabilized supernet as an evaluator, we derive a family of state-of-the-art
architectures, the SCARLET series of several depths, especially SCARLET-A
obtains 76.9% top-1 accuracy on ImageNet. Code is available at
https://github.com/xiaomi-automl/ScarletNAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vehicle-counting with Automatic Region-of-Interest and Driving-Trajectory detection. (arXiv:2108.07135v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasu_M/0/1/0/all/0/1">Malolan Vasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abreu_N/0/1/0/all/0/1">Nelson Abreu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_R/0/1/0/all/0/1">Raysa V&#xe1;squez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_C/0/1/0/all/0/1">Christian L&#xf3;pez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07135">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicle counting systems can help with vehicle analysis and traffic incident
detection. Unfortunately, most existing methods require some level of human
input to identify the Region of interest (ROI), movements of interest, or to
establish a reference point or line to count vehicles from traffic cameras.
This work introduces a method to count vehicles from traffic videos that
automatically identifies the ROI for the camera, as well as the driving
trajectories of the vehicles. This makes the method feasible to use with
Pan-Tilt-Zoom cameras, which are frequently used in developing countries.
Preliminary results indicate that the proposed method achieves an average
intersection over the union of 57.05% for the ROI and a mean absolute error of
just 17.44% at counting vehicles of the traffic video cameras tested.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Self-Adaptive Hashing for Image Retrieval. (arXiv:2108.07094v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qinghong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaojun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Shangxuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yudong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07094">
                                    <div class="article-summary-box-inner">
                                        <span>Hashing technology has been widely used in image retrieval due to its
computational and storage efficiency. Recently, deep unsupervised hashing
methods have attracted increasing attention due to the high cost of human
annotations in the real world and the superiority of deep learning technology.
However, most deep unsupervised hashing methods usually pre-compute a
similarity matrix to model the pairwise relationship in the pre-trained feature
space. Then this similarity matrix would be used to guide hash learning, in
which most of the data pairs are treated equivalently. The above process is
confronted with the following defects: 1) The pre-computed similarity matrix is
inalterable and disconnected from the hash learning process, which cannot
explore the underlying semantic information. 2) The informative data pairs may
be buried by the large number of less-informative data pairs. To solve the
aforementioned problems, we propose a \textbf{Deep Self-Adaptive
Hashing~(DSAH)} model to adaptively capture the semantic information with two
special designs: \textbf{Adaptive Neighbor Discovery~(AND)} and
\textbf{Pairwise Information Content~(PIC)}. Firstly, we adopt the AND to
initially construct a neighborhood-based similarity matrix, and then refine
this initial similarity matrix with a novel update strategy to further
investigate the semantic structure behind the learned representation. Secondly,
we measure the priorities of data pairs with PIC and assign adaptive weights to
them, which is relies on the assumption that more dissimilar data pairs contain
more discriminative information for hash learning. Extensive experiments on
several benchmark datasets demonstrate that the above two technologies
facilitate the deep hashing model to achieve superior performance in a
self-adaptive manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Accuracy-Lossless Perturbation Method for Defending Privacy Attacks in Federated Learning. (arXiv:2002.09843v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Weijun Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jun Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaohu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Rongxing Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.09843">
                                    <div class="article-summary-box-inner">
                                        <span>Although federated learning improves privacy of training data by exchanging
local gradients or parameters rather than raw data, the adversary still can
leverage local gradients and parameters to obtain local training data by
launching reconstruction and membership inference attacks. To defend such
privacy attacks, many noises perturbation methods (like differential privacy or
CountSketch matrix) have been widely designed. However, the strong defence
ability and high learning accuracy of these schemes cannot be ensured at the
same time, which will impede the wide application of FL in practice (especially
for medical or financial institutions that require both high accuracy and
strong privacy guarantee). To overcome this issue, in this paper, we propose
\emph{an efficient model perturbation method for federated learning} to defend
reconstruction and membership inference attacks launched by curious clients. On
the one hand, similar to the differential privacy, our method also selects
random numbers as perturbed noises added to the global model parameters, and
thus it is very efficient and easy to be integrated in practice. Meanwhile, the
random selected noises are positive real numbers and the corresponding value
can be arbitrarily large, and thus the strong defence ability can be ensured.
On the other hand, unlike differential privacy or other perturbation methods
that cannot eliminate the added noises, our method allows the server to recover
the true gradients by eliminating the added noises. Therefore, our method does
not hinder learning accuracy at all.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Voxel-wise Cross-Volume Representation Learning for 3D Neuron Reconstruction. (arXiv:2108.06522v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jianhui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrzanowski_W/0/1/0/all/0/1">Wojciech Chrzanowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06522">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic 3D neuron reconstruction is critical for analysing the morphology
and functionality of neurons in brain circuit activities. However, the
performance of existing tracing algorithms is hinged by the low image quality.
Recently, a series of deep learning based segmentation methods have been
proposed to improve the quality of raw 3D optical image stacks by removing
noises and restoring neuronal structures from low-contrast background. Due to
the variety of neuron morphology and the lack of large neuron datasets, most of
current neuron segmentation models rely on introducing complex and
specially-designed submodules to a base architecture with the aim of encoding
better feature representations. Though successful, extra burden would be put on
computation during inference. Therefore, rather than modifying the base
network, we shift our focus to the dataset itself. The encoder-decoder backbone
used in most neuron segmentation models attends only intra-volume voxel points
to learn structural features of neurons but neglect the shared intrinsic
semantic features of voxels belonging to the same category among different
volumes, which is also important for expressive representation learning. Hence,
to better utilise the scarce dataset, we propose to explicitly exploit such
intrinsic features of voxels through a novel voxel-level cross-volume
representation learning paradigm on the basis of an encoder-decoder
segmentation model. Our method introduces no extra cost during inference.
Evaluated on 42 3D neuron images from BigNeuron project, our proposed method is
demonstrated to improve the learning ability of the original segmentation model
and further enhancing the reconstruction performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FrankMocap: A Monocular 3D Whole-Body Pose Estimation System via Regression and Integration. (arXiv:2108.06428v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiratori_T/0/1/0/all/0/1">Takaaki Shiratori</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_H/0/1/0/all/0/1">Hanbyul Joo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06428">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing monocular 3D pose estimation approaches only focus on a single
body part, neglecting the fact that the essential nuance of human motion is
conveyed through a concert of subtle movements of face, hands, and body. In
this paper, we present FrankMocap, a fast and accurate whole-body 3D pose
estimation system that can produce 3D face, hands, and body simultaneously from
in-the-wild monocular images. The core idea of FrankMocap is its modular
design: We first run 3D pose regression methods for face, hands, and body
independently, followed by composing the regression outputs via an integration
module. The separate regression modules allow us to take full advantage of
their state-of-the-art performances without compromising the original accuracy
and reliability in practice. We develop three different integration modules
that trade off between latency and accuracy. All of them are capable of
providing simple yet effective solutions to unify the separate outputs into
seamless whole-body pose estimation results. We quantitatively and
qualitatively demonstrate that our modularized system outperforms both the
optimization-based and end-to-end methods of estimating whole-body pose.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting to Unseen Vendor Domains for MRI Lesion Segmentation. (arXiv:2108.06434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mac_B/0/1/0/all/0/1">Brandon Mac</a>, <a href="http://arxiv.org/find/cs/1/au:+Moody_A/0/1/0/all/0/1">Alan R. Moody</a>, <a href="http://arxiv.org/find/cs/1/au:+Khademi_A/0/1/0/all/0/1">April Khademi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06434">
                                    <div class="article-summary-box-inner">
                                        <span>One of the key limitations in machine learning models is poor performance on
data that is out of the domain of the training distribution. This is especially
true for image analysis in magnetic resonance (MR) imaging, as variations in
hardware and software create non-standard intensities, contrasts, and noise
distributions across scanners. Recently, image translation models have been
proposed to augment data across domains to create synthetic data points. In
this paper, we investigate the application an unsupervised image translation
model to augment MR images from a source dataset to a target dataset.
Specifically, we want to evaluate how well these models can create synthetic
data points representative of the target dataset through image translation, and
to see if a segmentation model trained these synthetic data points would
approach the performance of a model trained directly on the target dataset. We
consider three configurations of augmentation between datasets consisting of
translation between images, between scanner vendors, and from labels to images.
It was found that the segmentation models trained on synthetic data from labels
to images configuration yielded the closest performance to the segmentation
model trained directly on the target dataset. The Dice coeffcient score per
each target vendor (GE, Siemens, Philips) for training on synthetic data was
0.63, 0.64, and 0.58, compared to training directly on target dataset was 0.65,
0.72, and 0.61.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio2Gestures: Generating Diverse Gestures from Speech Audio with Conditional Variational Autoencoders. (arXiv:2108.06720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1">Di Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_W/0/1/0/all/0/1">Wenjie Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_X/0/1/0/all/0/1">Xuefei Zhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenyu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06720">
                                    <div class="article-summary-box-inner">
                                        <span>Generating conversational gestures from speech audio is challenging due to
the inherent one-to-many mapping between audio and body motions. Conventional
CNNs/RNNs assume one-to-one mapping, and thus tend to predict the average of
all possible target motions, resulting in plain/boring motions during
inference. In order to overcome this problem, we propose a novel conditional
variational autoencoder (VAE) that explicitly models one-to-many
audio-to-motion mapping by splitting the cross-modal latent code into shared
code and motion-specific code. The shared code mainly models the strong
correlation between audio and motion (such as the synchronized audio and motion
beats), while the motion-specific code captures diverse motion information
independent of the audio. However, splitting the latent code into two parts
poses training difficulties for the VAE model. A mapping network facilitating
random sampling along with other techniques including relaxed motion loss,
bicycle constraint, and diversity loss are designed to better train the VAE.
Experiments on both 3D and 2D motion datasets verify that our method generates
more realistic and diverse motions than state-of-the-art methods,
quantitatively and qualitatively. Finally, we demonstrate that our method can
be readily used to generate motion sequences with user-specified motion clips
on the timeline. Code and more results are at
https://jingli513.github.io/audio2gestures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Dense-Sparse Learning for Efficient Liver and Tumor Segmentation. (arXiv:2108.06761v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Ziyuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zeyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zeng Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chow_P/0/1/0/all/0/1">Pierce KH Chow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06761">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate automatic liver and tumor segmentation plays a vital role in
treatment planning and disease monitoring. Recently, deep convolutional neural
network (DCNNs) has obtained tremendous success in 2D and 3D medical image
segmentation. However, 2D DCNNs cannot fully leverage the inter-slice
information, while 3D DCNNs are computationally expensive and memory intensive.
To address these issues, we first propose a novel dense-sparse training flow
from a data perspective, in which, densely adjacent slices and sparsely
adjacent slices are extracted as inputs for regularizing DCNNs, thereby
improving the model performance. Moreover, we design a 2.5D light-weight
nnU-Net from a network perspective, in which, depthwise separable convolutions
are adopted to improve the efficiency. Extensive experiments on the LiTS
dataset have demonstrated the superiority of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-granularity for knowledge distillation. (arXiv:2108.06681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_B/0/1/0/all/0/1">Baitan Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Ying Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06681">
                                    <div class="article-summary-box-inner">
                                        <span>Considering the fact that students have different abilities to understand the
knowledge imparted by teachers, a multi-granularity distillation mechanism is
proposed for transferring more understandable knowledge for student networks. A
multi-granularity self-analyzing module of the teacher network is designed,
which enables the student network to learn knowledge from different teaching
patterns. Furthermore, a stable excitation scheme is proposed for robust
supervision for the student training. The proposed distillation mechanism can
be embedded into different distillation frameworks, which are taken as
baselines. Experiments show the mechanism improves the accuracy by 0.58% on
average and by 1.08% in the best over the baselines, which makes its
performance superior to the state-of-the-arts. It is also exploited that the
student&#x27;s ability of fine-tuning and robustness to noisy inputs can be improved
via the proposed mechanism. The code is available at
https://github.com/shaoeric/multi-granularity-distillation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focusing on Persons: Colorizing Old Images Learning from Modern Historical Movies. (arXiv:2108.06515v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhonglan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Ke Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1">Dongqing Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingfan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Ziyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qilong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06515">
                                    <div class="article-summary-box-inner">
                                        <span>In industry, there exist plenty of scenarios where old gray photos need to be
automatically colored, such as video sites and archives. In this paper, we
present the HistoryNet focusing on historical person&#x27;s diverse high fidelity
clothing colorization based on fine grained semantic understanding and prior.
Colorization of historical persons is realistic and practical, however,
existing methods do not perform well in the regards. In this paper, a
HistoryNet including three parts, namely, classification, fine grained semantic
parsing and colorization, is proposed. Classification sub-module supplies
classifying of images according to the eras, nationalities and garment types;
Parsing sub-network supplies the semantic for person contours, clothing and
background in the image to achieve more accurate colorization of clothes and
persons and prevent color overflow. In the training process, we integrate
classification and semantic parsing features into the coloring generation
network to improve colorization. Through the design of classification and
parsing subnetwork, the accuracy of image colorization can be improved and the
boundary of each part of image can be more clearly. Moreover, we also propose a
novel Modern Historical Movies Dataset (MHMD) containing 1,353,166 images and
42 labels of eras, nationalities, and garment types for automatic colorization
from 147 historical movies or TV series made in modern time. Various
quantitative and qualitative comparisons demonstrate that our method
outperforms the state-of-the-art colorization methods, especially on military
uniforms, which has correct colors according to the historical literatures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Unsupervised Visual Representation Learning from Decentralized Data. (arXiv:2108.06492v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_X/0/1/0/all/0/1">Xin Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06492">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised representation learning has achieved outstanding performances
using centralized data available on the Internet. However, the increasing
awareness of privacy protection limits sharing of decentralized unlabeled image
data that grows explosively in multiple parties (e.g., mobile phones and
cameras). As such, a natural problem is how to leverage these data to learn
visual representations for downstream tasks while preserving data privacy. To
address this problem, we propose a novel federated unsupervised learning
framework, FedU. In this framework, each party trains models from unlabeled
data independently using contrastive learning with an online network and a
target network. Then, a central server aggregates trained models and updates
clients&#x27; models with the aggregated model. It preserves data privacy as each
party only has access to its raw data. Decentralized data among multiple
parties are normally non-independent and identically distributed (non-IID),
leading to performance degradation. To tackle this challenge, we propose two
simple but effective methods: 1) We design the communication protocol to upload
only the encoders of online networks for server aggregation and update them
with the aggregated encoder; 2) We introduce a new module to dynamically decide
how to update predictors based on the divergence caused by non-IID. The
predictor is the other component of the online network. Extensive experiments
and ablations demonstrate the effectiveness and significance of FedU. It
outperforms training with only one party by over 5% and other methods by over
14% in linear and semi-supervised evaluation on non-IID data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PICCOLO: Point Cloud-Centric Omnidirectional Localization. (arXiv:2108.06545v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1">Changwoon Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1">Hojun Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young Min Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06545">
                                    <div class="article-summary-box-inner">
                                        <span>We present PICCOLO, a simple and efficient algorithm for omnidirectional
localization. Given a colored point cloud and a 360 panorama image of a scene,
our objective is to recover the camera pose at which the panorama image is
taken. Our pipeline works in an off-the-shelf manner with a single image given
as a query and does not require any training of neural networks or collecting
ground-truth poses of images. Instead, we match each point cloud color to the
holistic view of the panorama image with gradient-descent optimization to find
the camera pose. Our loss function, called sampling loss, is point
cloud-centric, evaluated at the projected location of every point in the point
cloud. In contrast, conventional photometric loss is image-centric, comparing
colors at each pixel location. With a simple change in the compared entities,
sampling loss effectively overcomes the severe visual distortion of
omnidirectional images, and enjoys the global context of the 360 view to handle
challenging scenarios for visual localization. PICCOLO outperforms existing
omnidirectional localization algorithms in both accuracy and stability when
evaluated in various environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Algorithm Unrolling for Biomedical Imaging. (arXiv:2108.06637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuelong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bar_Shira_O/0/1/0/all/0/1">Or Bar-Shira</a>, <a href="http://arxiv.org/find/cs/1/au:+Monga_V/0/1/0/all/0/1">Vishal Monga</a>, <a href="http://arxiv.org/find/cs/1/au:+Eldar_Y/0/1/0/all/0/1">Yonina C. Eldar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06637">
                                    <div class="article-summary-box-inner">
                                        <span>In this chapter, we review biomedical applications and breakthroughs via
leveraging algorithm unrolling, an important technique that bridges between
traditional iterative algorithms and modern deep learning techniques. To
provide context, we start by tracing the origin of algorithm unrolling and
providing a comprehensive tutorial on how to unroll iterative algorithms into
deep networks. We then extensively cover algorithm unrolling in a wide variety
of biomedical imaging modalities and delve into several representative recent
works in detail. Indeed, there is a rich history of iterative algorithms for
biomedical image synthesis, which makes the field ripe for unrolling
techniques. In addition, we put algorithm unrolling into a broad perspective,
in order to understand why it is particularly effective and discuss recent
trends. Finally, we conclude the chapter by discussing open challenges, and
suggesting future research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal Graph with Meta Concepts for Video Captioning. (arXiv:2108.06458v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1">Steven C. H. Hoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06458">
                                    <div class="article-summary-box-inner">
                                        <span>Video captioning targets interpreting the complex visual contents as text
descriptions, which requires the model to fully understand video scenes
including objects and their interactions. Prevailing methods adopt
off-the-shelf object detection networks to give object proposals and use the
attention mechanism to model the relations between objects. They often miss
some undefined semantic concepts of the pretrained model and fail to identify
exact predicate relationships between objects. In this paper, we investigate an
open research task of generating text descriptions for the given videos, and
propose Cross-Modal Graph (CMG) with meta concepts for video captioning.
Specifically, to cover the useful semantic concepts in video captions, we
weakly learn the corresponding visual regions for text descriptions, where the
associated visual regions and textual words are named cross-modal meta
concepts. We further build meta concept graphs dynamically with the learned
cross-modal meta concepts. We also construct holistic video-level and local
frame-level video graphs with the predicted predicates to model video sequence
structures. We validate the efficacy of our proposed techniques with extensive
experiments and achieve state-of-the-art results on two public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1">Vinod Kumar Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sukhdeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anuj Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06663">
                                    <div class="article-summary-box-inner">
                                        <span>Handwritten character recognition (HCR) is a challenging learning problem in
pattern recognition, mainly due to similarity in structure of characters,
different handwriting styles, noisy datasets and a large variety of languages
and scripts. HCR problem is studied extensively for a few decades but there is
very limited research on script independent models. This is because of factors,
like, diversity of scripts, focus of the most of conventional research efforts
on handcrafted feature extraction techniques which are language/script specific
and are not always available, and unavailability of public datasets and codes
to reproduce the results. On the other hand, deep learning has witnessed huge
success in different areas of pattern recognition, including HCR, and provides
end-to-end learning, i.e., automated feature extraction and recognition. In
this paper, we have proposed a novel deep learning architecture which exploits
transfer learning and image-augmentation for end-to-end learning for script
independent handwritten character recognition, called HCR-Net. The network is
based on a novel transfer learning approach for HCR, where some of lower layers
of a pre-trained VGG16 network are utilised. Due to transfer learning and
image-augmentation, HCR-Net provides faster training, better performance and
better generalisations. The experimental results on publicly available datasets
of Bangla, Punjabi, Hindi, English, Swedish, Urdu, Farsi, Tibetan, Kannada,
Malayalam, Telugu, Marathi, Nepali and Arabic languages prove the efficacy of
HCR-Net and establishes several new benchmarks. For reproducibility of the
results and for the advancements of the HCR research, complete code is publicly
released at \href{https://github.com/jmdvinodjmd/HCR-Net}{GitHub}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOTR: Segmenting Objects with Transformers. (arXiv:2108.06747v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1">Ruohao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Dantong Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liao Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenbo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06747">
                                    <div class="article-summary-box-inner">
                                        <span>Most recent transformer-based models show impressive performance on vision
tasks, even better than Convolution Neural Networks (CNN). In this work, we
present a novel, flexible, and effective transformer-based model for
high-quality instance segmentation. The proposed method, Segmenting Objects
with TRansformers (SOTR), simplifies the segmentation pipeline, building on an
alternative CNN backbone appended with two parallel subtasks: (1) predicting
per-instance category via transformer and (2) dynamically generating
segmentation mask with the multi-level upsampling module. SOTR can effectively
extract lower-level feature representations and capture long-range context
dependencies by Feature Pyramid Network (FPN) and twin transformer,
respectively. Meanwhile, compared with the original transformer, the proposed
twin transformer is time- and resource-efficient since only a row and a column
attention are involved to encode pixels. Moreover, SOTR is easy to be
incorporated with various CNN backbones and transformer model variants to make
considerable improvements for the segmentation accuracy and training
convergence. Extensive experiments show that our SOTR performs well on the MS
COCO dataset and surpasses state-of-the-art instance segmentation approaches.
We hope our simple but strong framework could serve as a preferment baseline
for instance-level recognition. Our code is available at
https://github.com/easton-cau/SOTR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Automatically Diagnose Multiple Diseases in Pediatric Chest Radiographs Using Deep Convolutional Neural Networks. (arXiv:2108.06486v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Thanh T. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu H. Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thang V. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Tung T. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hieu T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Ha Q. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06486">
                                    <div class="article-summary-box-inner">
                                        <span>Chest radiograph (CXR) interpretation in pediatric patients is error-prone
and requires a high level of understanding of radiologic expertise. Recently,
deep convolutional neural networks (D-CNNs) have shown remarkable performance
in interpreting CXR in adults. However, there is a lack of evidence indicating
that D-CNNs can recognize accurately multiple lung pathologies from pediatric
CXR scans. In particular, the development of diagnostic models for the
detection of pediatric chest diseases faces significant challenges such as (i)
lack of physician-annotated datasets and (ii) class imbalance problems. In this
paper, we retrospectively collect a large dataset of 5,017 pediatric CXR scans,
for which each is manually labeled by an experienced radiologist for the
presence of 10 common pathologies. A D-CNN model is then trained on 3,550
annotated scans to classify multiple pediatric lung pathologies automatically.
To address the high-class imbalance issue, we propose to modify and apply
&quot;Distribution-Balanced loss&quot; for training D-CNNs which reshapes the standard
Binary-Cross Entropy loss (BCE) to efficiently learn harder samples by
down-weighting the loss assigned to the majority classes. On an independent
test set of 777 studies, the proposed approach yields an area under the
receiver operating characteristic (AUC) of 0.709 (95% CI, 0.690-0.729). The
sensitivity, specificity, and F1-score at the cutoff value are 0.722
(0.694-0.750), 0.579 (0.563-0.595), and 0.389 (0.373-0.405), respectively.
These results significantly outperform previous state-of-the-art methods on
most of the target diseases. Moreover, our ablation studies validate the
effectiveness of the proposed loss function compared to other standard losses,
e.g., BCE and Focal Loss, for this learning task. Overall, we demonstrate the
potential of D-CNNs in interpreting pediatric CXRs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CPNet: Cycle Prototype Network for Weakly-supervised 3D Renal Compartments Segmentation on CT Images. (arXiv:2108.06669v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Song Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuting He</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1">Youyong Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaomei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaobo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_P/0/1/0/all/0/1">Pengfei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dillenseger_J/0/1/0/all/0/1">Jean-Louis Dillenseger</a>, <a href="http://arxiv.org/find/cs/1/au:+Coatrieux_J/0/1/0/all/0/1">Jean-Louis Coatrieux</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guanyu Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06669">
                                    <div class="article-summary-box-inner">
                                        <span>Renal compartment segmentation on CT images targets on extracting the 3D
structure of renal compartments from abdominal CTA images and is of great
significance to the diagnosis and treatment for kidney diseases. However, due
to the unclear compartment boundary, thin compartment structure and large
anatomy variation of 3D kidney CT images, deep-learning based renal compartment
segmentation is a challenging task. We propose a novel weakly supervised
learning framework, Cycle Prototype Network, for 3D renal compartment
segmentation. It has three innovations: 1) A Cycle Prototype Learning (CPL) is
proposed to learn consistency for generalization. It learns from pseudo labels
through the forward process and learns consistency regularization through the
reverse process. The two processes make the model robust to noise and
label-efficient. 2) We propose a Bayes Weakly Supervised Module (BWSM) based on
cross-period prior knowledge. It learns prior knowledge from cross-period
unlabeled data and perform error correction automatically, thus generates
accurate pseudo labels. 3) We present a Fine Decoding Feature Extractor (FDFE)
for fine-grained feature extraction. It combines global morphology information
and local detail information to obtain feature maps with sharp detail, so the
model will achieve fine segmentation on thin structures. Our model achieves
Dice of 79.1% and 78.7% with only four labeled images, achieving a significant
improvement by about 20% than typical prototype model PANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DICOM Imaging Router: An Open Deep Learning Framework for Classification of Body Parts from DICOM X-ray Scans. (arXiv:2108.06490v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu H. Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_D/0/1/0/all/0/1">Dung V. Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Ha Q. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06490">
                                    <div class="article-summary-box-inner">
                                        <span>X-ray imaging in DICOM format is the most commonly used imaging modality in
clinical practice, resulting in vast, non-normalized databases. This leads to
an obstacle in deploying AI solutions for analyzing medical images, which often
requires identifying the right body part before feeding the image into a
specified AI model. This challenge raises the need for an automated and
efficient approach to classifying body parts from X-ray scans. Unfortunately,
to the best of our knowledge, there is no open tool or framework for this task
to date. To fill this lack, we introduce a DICOM Imaging Router that deploys
deep CNNs for categorizing unknown DICOM X-ray images into five anatomical
groups: abdominal, adult chest, pediatric chest, spine, and others. To this
end, a large-scale X-ray dataset consisting of 16,093 images has been collected
and manually classified. We then trained a set of state-of-the-art deep CNNs
using a training set of 11,263 images. These networks were then evaluated on an
independent test set of 2,419 images and showed superior performance in
classifying the body parts. Specifically, our best performing model achieved a
recall of 0.982 (95% CI, 0.977-0.988), a precision of 0.985 (95% CI,
0.975-0.989) and a F1-score of 0.981 (95% CI, 0.976-0.987), whilst requiring
less computation for inference (0.0295 second per image). Our external validity
on 1,000 X-ray images shows the robustness of the proposed approach across
hospitals. These remarkable performances indicate that deep CNNs can accurately
and effectively differentiate human body parts from X-ray scans, thereby
providing potential benefits for a wide range of applications in clinical
settings. The dataset, codes, and trained deep learning models from this study
will be made publicly available on our project website at https://vindr.ai/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning of Multi-view Facial Expressions. (arXiv:2108.06723v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Shuvendu Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06723">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expression recognition (FER) has emerged as an important component of
human-computer interaction systems. Despite recent advancements in FER,
performance often drops significantly for non-frontal facial images. We propose
Contrastive Learning of Multi-view facial Expressions (CL-MEx) to exploit
facial images captured simultaneously from different angles towards FER. CL-MEx
is a two-step training framework. In the first step, an encoder network is
pre-trained with the proposed self-supervised contrastive loss, where it learns
to generate view-invariant embeddings for different views of a subject. The
model is then fine-tuned with labeled data in a supervised setting. We
demonstrate the performance of the proposed method on two multi-view FER
datasets, KDEF and DDCF, where state-of-the-art performances are achieved.
Further experiments show the robustness of our method in dealing with
challenging angles and reduced amounts of labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GeoCLR: Georeference Contrastive Learning for Efficient Seafloor Image Interpretation. (arXiv:2108.06421v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamada_T/0/1/0/all/0/1">Takaki Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Prugel_Bennett_A/0/1/0/all/0/1">Adam Pr&#xfc;gel-Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_S/0/1/0/all/0/1">Stefan B. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Pizarro_O/0/1/0/all/0/1">Oscar Pizarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Thornton_B/0/1/0/all/0/1">Blair Thornton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06421">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes Georeference Contrastive Learning of visual
Representation (GeoCLR) for efficient training of deep-learning Convolutional
Neural Networks (CNNs). The method leverages georeference information by
generating a similar image pair using images taken of nearby locations, and
contrasting these with an image pair that is far apart. The underlying
assumption is that images gathered within a close distance are more likely to
have similar visual appearance, where this can be reasonably satisfied in
seafloor robotic imaging applications where image footprints are limited to
edge lengths of a few metres and are taken so that they overlap along a
vehicle&#x27;s trajectory, whereas seafloor substrates and habitats have patch sizes
that are far larger. A key advantage of this method is that it is
self-supervised and does not require any human input for CNN training. The
method is computationally efficient, where results can be generated between
dives during multi-day AUV missions using computational resources that would be
accessible during most oceanic field trials. We apply GeoCLR to habitat
classification on a dataset that consists of ~86k images gathered using an
Autonomous Underwater Vehicle (AUV). We demonstrate how the latent
representations generated by GeoCLR can be used to efficiently guide human
annotation efforts, where the semi-supervised framework improves classification
accuracy by an average of 11.8 % compared to state-of-the-art transfer learning
using the same CNN and equivalent number of human annotations for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Optimization in Edge-Cloud Continuum for Federated Unsupervised Person Re-identification. (arXiv:2108.06493v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06493">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (ReID) aims to re-identify a person from
non-overlapping camera views. Since person ReID data contains sensitive
personal information, researchers have adopted federated learning, an emerging
distributed training method, to mitigate the privacy leakage risks. However,
existing studies rely on data labels that are laborious and time-consuming to
obtain. We present FedUReID, a federated unsupervised person ReID system to
learn person ReID models without any labels while preserving privacy. FedUReID
enables in-situ model training on edges with unlabeled data. A cloud server
aggregates models from edges instead of centralizing raw data to preserve data
privacy. Moreover, to tackle the problem that edges vary in data volumes and
distributions, we personalize training in edges with joint optimization of
cloud and edge. Specifically, we propose personalized epoch to reassign
computation throughout training, personalized clustering to iteratively predict
suitable labels for unlabeled data, and personalized update to adapt the server
aggregated model to each edge. Extensive experiments on eight person ReID
datasets demonstrate that FedUReID not only achieves higher accuracy but also
reduces computation cost by 29%. Our FedUReID system with the joint
optimization will shed light on implementing federated learning to more
multimedia tasks without data labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Pseudo-Lidar needed for Monocular 3D Object detection?. (arXiv:2108.06417v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dennis Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambrus_R/0/1/0/all/0/1">Rares Ambrus</a>, <a href="http://arxiv.org/find/cs/1/au:+Guizilini_V/0/1/0/all/0/1">Vitor Guizilini</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06417">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress in 3D object detection from single images leverages monocular
depth estimation as a way to produce 3D pointclouds, turning cameras into
pseudo-lidar sensors. These two-stage detectors improve with the accuracy of
the intermediate depth estimation network, which can itself be improved without
manual labels via large-scale self-supervised learning. However, they tend to
suffer from overfitting more than end-to-end methods, are more complex, and the
gap with similar lidar-based detectors remains significant. In this work, we
propose an end-to-end, single stage, monocular 3D object detector, DD3D, that
can benefit from depth pre-training like pseudo-lidar methods, but without
their limitations. Our architecture is designed for effective information
transfer between depth estimation and 3D detection, allowing us to scale with
the amount of unlabeled pre-training data. Our method achieves state-of-the-art
results on two challenging benchmarks, with 16.34% and 9.28% AP for Cars and
Pedestrians (respectively) on the KITTI-3D benchmark, and 41.5% mAP on
NuScenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MMOCR: A Comprehensive Toolbox for Text Detection, Recognition and Understanding. (arXiv:2108.06543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1">Zhanghui Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hongbin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhizhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiaoyu Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsui Hin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Huaqiang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yiqin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wayne Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06543">
                                    <div class="article-summary-box-inner">
                                        <span>We present MMOCR-an open-source toolbox which provides a comprehensive
pipeline for text detection and recognition, as well as their downstream tasks
such as named entity recognition and key information extraction. MMOCR
implements 14 state-of-the-art algorithms, which is significantly more than all
the existing open-source OCR projects we are aware of to date. To facilitate
future research and industrial applications of text recognition-related
problems, we also provide a large number of trained models and detailed
benchmarks to give insights into the performance of text detection, recognition
and understanding. MMOCR is publicly released at
https://github.com/open-mmlab/mmocr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Disentanglement without Autoencoding: Pitfalls and Future Directions. (arXiv:2108.06613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burns_A/0/1/0/all/0/1">Andrea Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarna_A/0/1/0/all/0/1">Aaron Sarna</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_D/0/1/0/all/0/1">Dilip Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maschinot_A/0/1/0/all/0/1">Aaron Maschinot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06613">
                                    <div class="article-summary-box-inner">
                                        <span>Disentangled visual representations have largely been studied with generative
models such as Variational AutoEncoders (VAEs). While prior work has focused on
generative methods for disentangled representation learning, these approaches
do not scale to large datasets due to current limitations of generative models.
Instead, we explore regularization methods with contrastive learning, which
could result in disentangled representations that are powerful enough for large
scale datasets and downstream applications. However, we find that unsupervised
disentanglement is difficult to achieve due to optimization and initialization
sensitivity, with trade-offs in task performance. We evaluate disentanglement
with downstream tasks, analyze the benefits and disadvantages of each
regularization used, and discuss future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stacked Hourglass Network with a Multi-level Attention Mechanism: Where to Look for Intervertebral Disc Labeling. (arXiv:2108.06554v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azad_R/0/1/0/all/0/1">Reza Azad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouhier_L/0/1/0/all/0/1">Lucas Rouhier</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Adad_J/0/1/0/all/0/1">Julien Cohen-Adad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06554">
                                    <div class="article-summary-box-inner">
                                        <span>Labeling vertebral discs from MRI scans is important for the proper diagnosis
of spinal related diseases, including multiple sclerosis, amyotrophic lateral
sclerosis, degenerative cervical myelopathy and cancer. Automatic labeling of
the vertebral discs in MRI data is a difficult task because of the similarity
between discs and bone area, the variability in the geometry of the spine and
surrounding tissues across individuals, and the variability across scans
(manufacturers, pulse sequence, image contrast, resolution and artefacts). In
previous studies, vertebral disc labeling is often done after a disc detection
step and mostly fails when the localization algorithm misses discs or has false
positive detection. In this work, we aim to mitigate this problem by
reformulating the semantic vertebral disc labeling using the pose estimation
technique. To do so, we propose a stacked hourglass network with multi-level
attention mechanism to jointly learn intervertebral disc position and their
skeleton structure. The proposed deep learning model takes into account the
strength of semantic segmentation and pose estimation technique to handle the
missing area and false positive detection. To further improve the performance
of the proposed method, we propose a skeleton-based search space to reduce
false positive detection. The proposed method evaluated on spine generic public
multi-center dataset and demonstrated better performance comparing to previous
work, on both T1w and T2w contrasts. The method is implemented in ivadomed
(https://ivadomed.org).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ST3D++: Denoised Self-training for Unsupervised Domain Adaptation on 3D Object Detection. (arXiv:2108.06682v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shaoshuai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiaojuan Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06682">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a self-training method, named ST3D++, with a
holistic pseudo label denoising pipeline for unsupervised domain adaptation on
3D object detection. ST3D++ aims at reducing noise in pseudo label generation
as well as alleviating the negative impacts of noisy pseudo labels on model
training. First, ST3D++ pre-trains the 3D object detector on the labeled source
domain with random object scaling (ROS) which is designed to reduce target
domain pseudo label noise arising from object scale bias of the source domain.
Then, the detector is progressively improved through alternating between
generating pseudo labels and training the object detector with pseudo-labeled
target domain data. Here, we equip the pseudo label generation process with a
hybrid quality-aware triplet memory to improve the quality and stability of
generated pseudo labels. Meanwhile, in the model training stage, we propose a
source data assisted training strategy and a curriculum data augmentation
policy to effectively rectify noisy gradient directions and avoid model
over-fitting to noisy pseudo labeled data. These specific designs enable the
detector to be trained on meticulously refined pseudo labeled target data with
denoised training signals, and thus effectively facilitate adapting an object
detector to a target domain without requiring annotations. Finally, our method
is assessed on four 3D benchmark datasets (i.e., Waymo, KITTI, Lyft, and
nuScenes) for three common categories (i.e., car, pedestrian and bicycle).
ST3D++ achieves state-of-the-art performance on all evaluated settings,
outperforming the corresponding baseline by a large margin (e.g., 9.6% $\sim$
38.16% on Waymo $\rightarrow$ KITTI in terms of AP$_{\text{3D}}$), and even
surpasses the fully supervised oracle results on the KITTI 3D object detection
benchmark with target prior. Code will be available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DensePASS: Dense Panoramic Semantic Segmentation via Unsupervised Domain Adaptation with Attention-Augmented Context Exchange. (arXiv:2108.06383v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chaoxiang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roitberg_A/0/1/0/all/0/1">Alina Roitberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06383">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent vehicles clearly benefit from the expanded Field of View (FoV) of
the 360-degree sensors, but the vast majority of available semantic
segmentation training images are captured with pinhole cameras. In this work,
we look at this problem through the lens of domain adaptation and bring
panoramic semantic segmentation to a setting, where labelled training data
originates from a different distribution of conventional pinhole camera images.
First, we formalize the task of unsupervised domain adaptation for panoramic
semantic segmentation, where a network trained on labelled examples from the
source domain of pinhole camera data is deployed in a different target domain
of panoramic images, for which no labels are available. To validate this idea,
we collect and publicly release DensePASS - a novel densely annotated dataset
for panoramic segmentation under cross-domain conditions, specifically built to
study the Pinhole-to-Panoramic transfer and accompanied with pinhole camera
training examples obtained from Cityscapes. DensePASS covers both, labelled-
and unlabelled 360-degree images, with the labelled data comprising 19 classes
which explicitly fit the categories available in the source domain (i.e.
pinhole) data. To meet the challenge of domain shift, we leverage the current
progress of attention-based mechanisms and build a generic framework for
cross-domain panoramic semantic segmentation based on different variants of
attention-augmented domain adaptation modules. Our framework facilitates
information exchange at local- and global levels when learning the domain
correspondences and improves the domain adaptation performance of two standard
segmentation networks by 6.05% and 11.26% in Mean IoU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">In Defense of Scene Graphs for Image Captioning. (arXiv:2102.04990v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Subarna Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bang Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_T/0/1/0/all/0/1">Tanaya Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Truong Q. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04990">
                                    <div class="article-summary-box-inner">
                                        <span>The mainstream image captioning models rely on Convolutional Neural Network
(CNN) image features to generate captions via recurrent models. Recently, image
scene graphs have been used to augment captioning models so as to leverage
their structural semantics, such as object entities, relationships and
attributes. Several studies have noted that the naive use of scene graphs from
a black-box scene graph generator harms image captioning performance and that
scene graph-based captioning models have to incur the overhead of explicit use
of image features to generate decent captions. Addressing these challenges, we
propose \textbf{SG2Caps}, a framework that utilizes only the scene graph labels
for competitive image captioning performance. The basic idea is to close the
semantic gap between the two scene graphs - one derived from the input image
and the other from its caption. In order to achieve this, we leverage the
spatial location of objects and the Human-Object-Interaction (HOI) labels as an
additional HOI graph. SG2Caps outperforms existing scene graph-only captioning
models by a large margin, indicating scene graphs as a promising representation
for image captioning. Direct utilization of scene graph labels avoids expensive
graph convolutions over high-dimensional CNN features resulting in 49% fewer
trainable parameters. Our code is available at:
https://github.com/Kien085/SG2Caps</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image2Reverb: Cross-Modal Reverb Impulse Response Synthesis. (arXiv:2103.14201v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1">Nikhil Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mentch_J/0/1/0/all/0/1">Jeff Mentch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_J/0/1/0/all/0/1">Jerry Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Beveridge_M/0/1/0/all/0/1">Matthew Beveridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1">Iddo Drori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14201">
                                    <div class="article-summary-box-inner">
                                        <span>Measuring the acoustic characteristics of a space is often done by capturing
its impulse response (IR), a representation of how a full-range stimulus sound
excites it. This work generates an IR from a single image, which can then be
applied to other signals using convolution, simulating the reverberant
characteristics of the space shown in the image. Recording these IRs is both
time-intensive and expensive, and often infeasible for inaccessible locations.
We use an end-to-end neural network architecture to generate plausible audio
impulse responses from single images of acoustic environments. We evaluate our
method both by comparisons to ground truth data and by human expert evaluation.
We demonstrate our approach by generating plausible impulse responses from
diverse settings and formats including well known places, musical halls, rooms
in paintings, images from animations and computer games, synthetic environments
generated from text, panoramic images, and video conference backgrounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Broad Study on the Transferability of Visual Representations with Contrastive Learning. (arXiv:2103.13517v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Islam_A/0/1/0/all/0/1">Ashraful Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chun-Fu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1">Rameswar Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1">Leonid Karlinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Radke_R/0/1/0/all/0/1">Richard Radke</a>, <a href="http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1">Rogerio Feris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13517">
                                    <div class="article-summary-box-inner">
                                        <span>Tremendous progress has been made in visual representation learning, notably
with the recent success of self-supervised contrastive learning methods.
Supervised contrastive learning has also been shown to outperform its
cross-entropy counterparts by leveraging labels for choosing where to contrast.
However, there has been little work to explore the transfer capability of
contrastive learning to a different domain. In this paper, we conduct a
comprehensive study on the transferability of learned representations of
different contrastive approaches for linear evaluation, full-network transfer,
and few-shot recognition on 12 downstream datasets from different domains, and
object detection tasks on MSCOCO and VOC0712. The results show that the
contrastive approaches learn representations that are easily transferable to a
different downstream task. We further observe that the joint objective of
self-supervised contrastive loss with cross-entropy/supervised-contrastive loss
leads to better transferability of these models over their supervised
counterparts. Our analysis reveals that the representations learned from the
contrastive approaches contain more low/mid-level semantics than cross-entropy
models, which enables them to quickly adapt to a new task. Our codes and models
will be publicly available to facilitate future research on transferability of
visual representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weak Adaptation Learning -- Addressing Cross-domain Data Insufficiency with Weak Annotator. (arXiv:2102.07358v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shichao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lixu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07358">
                                    <div class="article-summary-box-inner">
                                        <span>Data quantity and quality are crucial factors for data-driven learning
methods. In some target problem domains, there are not many data samples
available, which could significantly hinder the learning process. While data
from similar domains may be leveraged to help through domain adaptation,
obtaining high-quality labeled data for those source domains themselves could
be difficult or costly. To address such challenges on data insufficiency for
classification problem in a target domain, we propose a weak adaptation
learning (WAL) approach that leverages unlabeled data from a similar source
domain, a low-cost weak annotator that produces labels based on task-specific
heuristics, labeling rules, or other methods (albeit with inaccuracy), and a
small amount of labeled data in the target domain. Our approach first conducts
a theoretical analysis on the error bound of the trained classifier with
respect to the data quantity and the performance of the weak annotator, and
then introduces a multi-stage weak adaptation learning method to learn an
accurate classifier by lowering the error bound. Our experiments demonstrate
the effectiveness of our approach in learning an accurate classifier with
limited labeled data in the target domain and unlabeled data in the source
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based Action Recognition. (arXiv:2105.01563v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_P/0/1/0/all/0/1">Pan Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+McKay_B/0/1/0/all/0/1">Bob McKay</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1">Saeed Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01563">
                                    <div class="article-summary-box-inner">
                                        <span>Skeleton sequences are lightweight and compact, thus are ideal candidates for
action recognition on edge devices. Recent skeleton-based action recognition
methods extract features from 3D joint coordinates as spatial-temporal cues,
using these representations in a graph neural network for feature fusion to
boost recognition performance. The use of first- and second-order features,
\ie{} joint and bone representations, has led to high accuracy. Nonetheless,
many models are still confused by actions that have similar motion
trajectories. To address these issues, we propose fusing third-order features
in the form of angular encoding into modern architectures to robustly capture
the relationships between joints and body parts. This simple fusion with
popular spatial-temporal graph neural networks achieves new state-of-the-art
accuracy in two large benchmarks, including NTU60 and NTU120, while employing
fewer parameters and reduced run time. Our source code is publicly available
at: https://github.com/ZhenyueQin/Angular-Skeleton-Encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poison Ink: Robust and Invisible Backdoor Attack. (arXiv:2108.02488v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1">Jing Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qidong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02488">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research shows deep neural networks are vulnerable to different types
of attacks, such as adversarial attack, data poisoning attack and backdoor
attack. Among them, backdoor attack is the most cunning one and can occur in
almost every stage of deep learning pipeline. Therefore, backdoor attack has
attracted lots of interests from both academia and industry. However, most
existing backdoor attack methods are either visible or fragile to some
effortless pre-processing such as common data transformations. To address these
limitations, we propose a robust and invisible backdoor attack called &quot;Poison
Ink&quot;. Concretely, we first leverage the image structures as target poisoning
areas, and fill them with poison ink (information) to generate the trigger
pattern. As the image structure can keep its semantic meaning during the data
transformation, such trigger pattern is inherently robust to data
transformations. Then we leverage a deep injection network to embed such
trigger pattern into the cover image to achieve stealthiness. Compared to
existing popular backdoor attack methods, Poison Ink outperforms both in
stealthiness and robustness. Through extensive experiments, we demonstrate
Poison Ink is not only general to different datasets and network architectures,
but also flexible for different attack scenarios. Besides, it also has very
strong resistance against many state-of-the-art defense techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks. (arXiv:2106.04026v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dae-Hyeok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dong-Kyun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Ji-Hoon Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04026">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-computer interface (BCI) is used for communication between humans and
devices by recognizing status and intention of humans. Communication between
humans and a drone using electroencephalogram (EEG) signals is one of the most
challenging issues in the BCI domain. In particular, the control of drone
swarms (the direction and formation) has more advantages compared to the
control of a drone. The visual imagery (VI) paradigm is that subjects visually
imagine specific objects or scenes. Reduction of the variability among EEG
signals of subjects is essential for practical BCI-based systems. In this
study, we proposed the subepoch-wise feature encoder (SEFE) to improve the
performances in the subject-independent tasks by using the VI dataset. This
study is the first attempt to demonstrate the possibility of generalization
among subjects in the VI-based BCI. We used the leave-one-subject-out
cross-validation for evaluating the performances. We obtained higher
performances when including our proposed module than excluding our proposed
module. The DeepConvNet with SEFE showed the highest performance of 0.72 among
six different decoding models. Hence, we demonstrated the feasibility of
decoding the VI dataset in the subject-independent task with robust
performances by using our proposed module.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mesh Graphormer. (arXiv:2104.00272v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kevin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00272">
                                    <div class="article-summary-box-inner">
                                        <span>We present a graph-convolution-reinforced transformer, named Mesh Graphormer,
for 3D human pose and mesh reconstruction from a single image. Recently both
transformers and graph convolutional neural networks (GCNNs) have shown
promising progress in human mesh reconstruction. Transformer-based approaches
are effective in modeling non-local interactions among 3D mesh vertices and
body joints, whereas GCNNs are good at exploiting neighborhood vertex
interactions based on a pre-specified mesh topology. In this paper, we study
how to combine graph convolutions and self-attentions in a transformer to model
both local and global interactions. Experimental results show that our proposed
method, Mesh Graphormer, significantly outperforms the previous
state-of-the-art methods on multiple benchmarks, including Human3.6M, 3DPW, and
FreiHAND datasets. Code and pre-trained models are available at
https://github.com/microsoft/MeshGraphormer</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A 3D CNN Network with BERT For Automatic COVID-19 Diagnosis From CT-Scan Images. (arXiv:2106.14403v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_W/0/1/0/all/0/1">Weijun Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jingfeng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14403">
                                    <div class="article-summary-box-inner">
                                        <span>We present an automatic COVID1-19 diagnosis framework from lung CT-scan slice
images. In this framework, the slice images of a CT-scan volume are first
proprocessed using segmentation techniques to filter out images of closed lung,
and to remove the useless background. Then a resampling method is used to
select one or multiple sets of a fixed number of slice images for training and
validation. A 3D CNN network with BERT is used to classify this set of selected
slice images. In this network, an embedding feature is also extracted. In cases
where there are more than one set of slice images in a volume, the features of
all sets are extracted and pooled into a global feature vector for the whole
CT-scan volume. A simple multiple-layer perceptron (MLP) network is used to
further classify the aggregated feature vector. The models are trained and
evaluated on the provided training and validation datasets. On the validation
dataset, the accuracy is 0.9278 and the F1 score is 0.9261.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Representation Factorization for Video-based Person Re-Identification. (arXiv:2107.11878v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aich_A/0/1/0/all/0/1">Abhishek Aich</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Meng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_S/0/1/0/all/0/1">Srikrishna Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Terrence Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1">Amit K. Roy-Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11878">
                                    <div class="article-summary-box-inner">
                                        <span>Despite much recent progress in video-based person re-identification (re-ID),
the current state-of-the-art still suffers from common real-world challenges
such as appearance similarity among various people, occlusions, and frame
misalignment. To alleviate these problems, we propose Spatio-Temporal
Representation Factorization (STRF), a flexible new computational unit that can
be used in conjunction with most existing 3D convolutional neural network
architectures for re-ID. The key innovations of STRF over prior work include
explicit pathways for learning discriminative temporal and spatial features,
with each component further factorized to capture complementary person-specific
appearance and motion information. Specifically, temporal factorization
comprises two branches, one each for static features (e.g., the color of
clothes) that do not change much over time, and dynamic features (e.g., walking
patterns) that change over time. Further, spatial factorization also comprises
two branches to learn both global (coarse segments) as well as local (finer
segments) appearance features, with the local features particularly useful in
cases of occlusion or spatial misalignment. These two factorization operations
taken together result in a modular architecture for our parameter-wise light
STRF unit that can be plugged in between any two 3D convolutional layers,
resulting in an end-to-end learning framework. We empirically show that STRF
improves performance of various existing baseline architectures while
demonstrating new state-of-the-art results using standard person re-ID
evaluation protocols on three benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset and System for Real-Time Gun Detection in Surveillance Video Using Deep Learning. (arXiv:2105.01058v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_D/0/1/0/all/0/1">Delong Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1">Weijun Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhifu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Qi Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingfeng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01058">
                                    <div class="article-summary-box-inner">
                                        <span>Gun violence is a severe problem in the world, particularly in the United
States. Deep learning methods have been studied to detect guns in surveillance
video cameras or smart IP cameras and to send a real-time alert to security
personals. One problem for the development of gun detection algorithms is the
lack of large public datasets. In this work, we first publish a dataset with
51K annotated gun images for gun detection and other 51K cropped gun chip
images for gun classification we collect from a few different sources. To our
knowledge, this is the largest dataset for the study of gun detection. This
dataset can be downloaded at www.linksprite.com/gun-detection-datasets. We
present a gun detection system using a smart IP camera as an embedded edge
device, and a cloud server as a manager for device, data, alert, and to further
reduce the false positive rate. We study to find solutions for gun detection in
an embedded device, and for gun classification on the edge device and the cloud
server. This edge/cloud framework makes the deployment of gun detection in the
real world possible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Open-World Uncertainty Modeling for Confidence Calibration. (arXiv:2107.12628v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yezhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12628">
                                    <div class="article-summary-box-inner">
                                        <span>Confidence calibration is of great importance to the reliability of decisions
made by machine learning systems. However, discriminative classifiers based on
deep neural networks are often criticized for producing overconfident
predictions that fail to reflect the true correctness likelihood of
classification accuracy. We argue that such an inability to model uncertainty
is mainly caused by the closed-world nature in softmax: a model trained by the
cross-entropy loss will be forced to classify input into one of $K$ pre-defined
categories with high probability. To address this problem, we for the first
time propose a novel $K$+1-way softmax formulation, which incorporates the
modeling of open-world uncertainty as the extra dimension. To unify the
learning of the original $K$-way classification task and the extra dimension
that models uncertainty, we propose a novel energy-based objective function,
and moreover, theoretically prove that optimizing such an objective essentially
forces the extra dimension to capture the marginal data distribution. Extensive
experiments show that our approach, Energy-based Open-World Softmax
(EOW-Softmax), is superior to existing state-of-the-art methods in improving
confidence calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Free Lunch for Few-shot Learning: Distribution Calibration. (arXiv:2101.06395v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06395">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from a limited number of samples is challenging since the learned
model can easily become overfitted based on the biased distribution formed by
only a few training examples. In this paper, we calibrate the distribution of
these few-sample classes by transferring statistics from the classes with
sufficient examples, then an adequate number of examples can be sampled from
the calibrated distribution to expand the inputs to the classifier. We assume
every dimension in the feature representation follows a Gaussian distribution
so that the mean and the variance of the distribution can borrow from that of
similar classes whose statistics are better estimated with an adequate number
of samples. Our method can be built on top of off-the-shelf pretrained feature
extractors and classification models without extra parameters. We show that a
simple logistic regression classifier trained using the features sampled from
our calibrated distribution can outperform the state-of-the-art accuracy on two
datasets (~5% improvement on miniImageNet compared to the next best). The
visualization of these generated features demonstrates that our calibrated
distribution is an accurate estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Meta-class Memory for Few-Shot Semantic Segmentation. (arXiv:2108.02958v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiangxi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+lin_G/0/1/0/all/0/1">Guosheng lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02958">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, the state-of-the-art methods treat few-shot semantic segmentation
task as a conditional foreground-background segmentation problem, assuming each
class is independent. In this paper, we introduce the concept of meta-class,
which is the meta information (e.g. certain middle-level features) shareable
among all classes. To explicitly learn meta-class representations in few-shot
segmentation task, we propose a novel Meta-class Memory based few-shot
segmentation method (MM-Net), where we introduce a set of learnable memory
embeddings to memorize the meta-class information during the base class
training and transfer to novel classes during the inference stage. Moreover,
for the $k$-shot scenario, we propose a novel image quality measurement module
to select images from the set of support images. A high-quality class prototype
could be obtained with the weighted sum of support image features based on the
quality measure. Experiments on both PASCAL-$5^i$ and COCO dataset shows that
our proposed method is able to achieve state-of-the-art results in both 1-shot
and 5-shot settings. Particularly, our proposed MM-Net achieves 37.5\% mIoU on
the COCO dataset in 1-shot setting, which is 5.1\% higher than the previous
state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gait Recognition via Effective Global-Local Feature Representation and Local Temporal Aggregation. (arXiv:2011.01461v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Beibei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shunli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01461">
                                    <div class="article-summary-box-inner">
                                        <span>Gait recognition is one of the most important biometric technologies and has
been applied in many fields. Recent gait recognition frameworks represent each
gait frame by descriptors extracted from either global appearances or local
regions of humans. However, the representations based on global information
often neglect the details of the gait frame, while local region based
descriptors cannot capture the relations among neighboring regions, thus
reducing their discriminativeness. In this paper, we propose a novel feature
extraction and fusion framework to achieve discriminative feature
representations for gait recognition. Towards this goal, we take advantage of
both global visual information and local region details and develop a Global
and Local Feature Extractor (GLFE). Specifically, our GLFE module is composed
of our newly designed multiple global and local convolutional layers (GLConv)
to ensemble global and local features in a principle manner. Furthermore, we
present a novel operation, namely Local Temporal Aggregation (LTA), to further
preserve the spatial information by reducing the temporal resolution to obtain
higher spatial resolution. With the help of our GLFE and LTA, our method
significantly improves the discriminativeness of our visual features, thus
improving the gait recognition performance. Extensive experiments demonstrate
that our proposed method outperforms state-of-the-art gait recognition methods
on two popular datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Knowledge by Mimicking Features. (arXiv:2011.01424v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guo-Hua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yifan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianxin Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01424">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation (KD) is a popular method to train efficient networks
(&quot;student&quot;) with the help of high-capacity networks (&quot;teacher&quot;). Traditional
methods use the teacher&#x27;s soft logits as extra supervision to train the student
network. In this paper, we argue that it is more advantageous to make the
student mimic the teacher&#x27;s features in the penultimate layer. Not only the
student can directly learn more effective information from the teacher feature,
feature mimicking can also be applied for teachers trained without a softmax
layer. Experiments show that it can achieve higher accuracy than traditional
KD. To further facilitate feature mimicking, we decompose a feature vector into
the magnitude and the direction. We argue that the teacher should give more
freedom to the student feature&#x27;s magnitude, and let the student pay more
attention on mimicking the feature direction. To meet this requirement, we
propose a loss term based on locality-sensitive hashing (LSH). With the help of
this new loss, our method indeed mimics feature directions more accurately,
relaxes constraints on feature magnitudes, and achieves state-of-the-art
distillation accuracy. We provide theoretical analyses of how LSH facilitates
feature direction mimicking, and further extend feature mimicking to
multi-label recognition and object detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GarmentNets: Category-Level Pose Estimation for Garments via Canonical Space Shape Completion. (arXiv:2104.05177v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_C/0/1/0/all/0/1">Cheng Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuran Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05177">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles the task of category-level pose estimation for garments.
With a near infinite degree of freedom, a garment&#x27;s full configuration (i.e.,
poses) is often described by the per-vertex 3D locations of its entire 3D
surface. However, garments are also commonly subject to extreme cases of
self-occlusion, especially when folded or crumpled, making it challenging to
perceive their full 3D surface. To address these challenges, we propose
GarmentNets, where the key idea is to formulate the deformable object pose
estimation problem as a shape completion task in the canonical space. This
canonical space is defined across garments instances within a category,
therefore, specifies the shared category-level pose. By mapping the observed
partial surface to the canonical space and completing it in this space, the
output representation describes the garment&#x27;s full configuration using a
complete 3D mesh with the per-vertex canonical coordinate label. To properly
handle the thin 3D structure presented on garments, we proposed a novel 3D
shape representation using the generalized winding number field. Experiments
demonstrate that GarmentNets is able to generalize to unseen garment instances
and achieve significantly better performance compared to alternative
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hacking VMAF and VMAF NEG: vulnerability to different preprocessing methods. (arXiv:2107.04510v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siniukov_M/0/1/0/all/0/1">Maksim Siniukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1">Anastasia Antsiferova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1">Dmitriy Kulikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1">Dmitriy Vatolin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04510">
                                    <div class="article-summary-box-inner">
                                        <span>Video-quality measurement plays a critical role in the development of
video-processing applications. In this paper, we show how video preprocessing
can artificially increase the popular quality metric VMAF and its
tuning-resistant version, VMAF NEG. We propose a pipeline that tunes
processing-algorithm parameters to increase VMAF by up to 218.8%. A subjective
comparison revealed that for most preprocessing methods, a video&#x27;s visual
quality drops or stays unchanged. We also show that some preprocessing methods
can increase VMAF NEG scores by up to 23.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wavelength-based Attributed Deep Neural Network for Underwater Image Restoration. (arXiv:2106.07910v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1">Prasen Kumar Sharma</a>, <a href="http://arxiv.org/find/eess/1/au:+Bisht_I/0/1/0/all/0/1">Ira Bisht</a>, <a href="http://arxiv.org/find/eess/1/au:+Sur_A/0/1/0/all/0/1">Arijit Sur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07910">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Underwater images, in general, suffer from low contrast and high
color distortions due to the non-uniform attenuation of the light as it
propagates through the water. In addition, the degree of attenuation varies
with the wavelength resulting in the asymmetric traversing of colors. Despite
the prolific works for underwater image restoration (UIR) using deep learning,
the above asymmetricity has not been addressed in the respective network
engineering.

Contributions: As the first novelty, this paper shows that attributing the
right receptive field size (context) based on the traversing range of the color
channel may lead to a substantial performance gain for the task of UIR.
Further, it is important to suppress the irrelevant multi-contextual features
and increase the representational power of the model. Therefore, as a second
novelty, we have incorporated an attentive skip mechanism to adaptively refine
the learned multi-contextual features. The proposed framework, called Deep
WaveNet, is optimized using the traditional pixel-wise and feature-based cost
functions. An extensive set of experiments have been carried out to show the
efficacy of the proposed scheme over existing best-published literature on
benchmark datasets. More importantly, we have demonstrated a comprehensive
validation of enhanced images across various high-level vision tasks, e.g.,
underwater image semantic segmentation, and diver&#x27;s 2D pose estimation. A
sample video to exhibit our real-world performance is available at
\url{https://tinyurl.com/yzcrup9n}. Also, we have open-sourced our framework at
\url{https://github.com/pksvision/Deep-WaveNet-UnderwaterImage-Restoration}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Consistency Regularized Mean Teacher for Semi-supervised 3D Left Atrium Segmentation. (arXiv:2105.10369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shumeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Ziyuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaixin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zeng Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10369">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has achieved promising segmentation performance on 3D left
atrium MR images. However, annotations for segmentation tasks are expensive,
costly and difficult to obtain. In this paper, we introduce a novel
hierarchical consistency regularized mean teacher framework for 3D left atrium
segmentation. In each iteration, the student model is optimized by multi-scale
deep supervision and hierarchical consistency regularization, concurrently.
Extensive experiments have shown that our method achieves competitive
performance as compared with full annotation, outperforming other
state-of-the-art semi-supervised segmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency. (arXiv:2108.06858v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golestaneh_S/0/1/0/all/0/1">S. Alireza Golestaneh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadsetan_S/0/1/0/all/0/1">Saba Dadsetan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris M. Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06858">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of No-Reference Image Quality Assessment (NR-IQA) is to estimate the
perceptual image quality in accordance with subjective evaluations, it is a
complex and unsolved problem due to the absence of the pristine reference
image. In this paper, we propose a novel model to address the NR-IQA task by
leveraging a hybrid approach that benefits from Convolutional Neural Networks
(CNNs) and self-attention mechanism in Transformers to extract both local and
non-local features from the input image. We capture local structure information
of the image via CNNs, then to circumvent the locality bias among the extracted
CNNs features and obtain a non-local representation of the image, we utilize
Transformers on the extracted features where we model them as a sequential
input to the Transformer model. Furthermore, to improve the monotonicity
correlation between the subjective and objective scores, we utilize the
relative distance information among the images within each batch and enforce
the relative ranking among them. Last but not least, we observe that the
performance of NR-IQA models degrades when we apply equivariant transformations
(e.g. horizontal flipping) to the inputs. Therefore, we propose a method that
leverages self-consistency as a source of self-supervision to improve the
robustness of NRIQA models. Specifically, we enforce self-consistency between
the outputs of our quality assessment model for each image and its
transformation (horizontally flipped) to utilize the rich self-supervisory
information and reduce the uncertainty of the model. To demonstrate the
effectiveness of our work, we evaluate it on seven standard IQA datasets (both
synthetic and authentic) and show that our model achieves state-of-the-art
results on various datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pixel Difference Networks for Efficient Edge Detection. (arXiv:2108.07009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1">Zhuo Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wenzhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zitong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dewen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1">Qing Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietikainen_M/0/1/0/all/0/1">Matti Pietik&#xe4;inen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07009">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep Convolutional Neural Networks (CNNs) can achieve human-level
performance in edge detection with the rich and abstract edge representation
capacities. However, the high performance of CNN based edge detection is
achieved with a large pretrained CNN backbone, which is memory and energy
consuming. In addition, it is surprising that the previous wisdom from the
traditional edge detectors, such as Canny, Sobel, and LBP are rarely
investigated in the rapid-developing deep learning era. To address these
issues, we propose a simple, lightweight yet effective architecture named Pixel
Difference Network (PiDiNet) for efficient edge detection. Extensive
experiments on BSDS500, NYUD, and Multicue are provided to demonstrate its
effectiveness, and its high training and inference efficiency. Surprisingly,
when training from scratch with only the BSDS500 and VOC datasets, PiDiNet can
surpass the recorded result of human perception (0.807 vs. 0.803 in ODS
F-measure) on the BSDS500 dataset with 100 FPS and less than 1M parameters. A
faster version of PiDiNet with less than 0.1M parameters can still achieve
comparable performance among state of the arts with 200 FPS. Results on the
NYUD and Multicue datasets show similar observations. The codes are available
at https://github.com/zhuoinoulu/pidinet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WideCaps: A Wide Attention based Capsule Network for Image Classification. (arXiv:2108.03627v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pawan_S/0/1/0/all/0/1">S J Pawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rishi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_H/0/1/0/all/0/1">Hemanth Sai Ram Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Vani_M/0/1/0/all/0/1">M Vani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_J/0/1/0/all/0/1">Jeny Rajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03627">
                                    <div class="article-summary-box-inner">
                                        <span>The capsule network is a distinct and promising segment of the neural network
family that drew attention due to its unique ability to maintain the
equivariance property by preserving the spatial relationship amongst the
features. The capsule network has attained unprecedented success over image
classification tasks with datasets such as MNIST and affNIST by encoding the
characteristic features into the capsules and building the parse-tree
structure. However, on the datasets involving complex foreground and background
regions such as CIFAR-10, the performance of the capsule network is sub-optimal
due to its naive data routing policy and incompetence towards extracting
complex features. This paper proposes a new design strategy for capsule network
architecture for efficiently dealing with complex images. The proposed method
incorporates wide bottleneck residual modules and the Squeeze and Excitation
attention blocks upheld by the modified FM routing algorithm to address the
defined problem. A wide bottleneck residual module facilitates extracting
complex features followed by the squeeze and excitation attention block to
enable channel-wise attention by suppressing the trivial features. This setup
allows channel inter-dependencies at almost no computational cost, thereby
enhancing the representation ability of capsules on complex images. We
extensively evaluate the performance of the proposed model on three publicly
available datasets, namely CIFAR-10, Fashion MNIST, and SVHN, to outperform the
top-5 performance on CIFAR-10 and Fashion MNIST with highly competitive
performance on the SVHN dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stereo Matching by Self-supervision of Multiscopic Vision. (arXiv:2104.04170v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weihao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yazhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bingkun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Siyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1">Ping Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Michael Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning for depth estimation possesses several advantages
over supervised learning. The benefits of no need for ground-truth depth,
online fine-tuning, and better generalization with unlimited data attract
researchers to seek self-supervised solutions. In this work, we propose a new
self-supervised framework for stereo matching utilizing multiple images
captured at aligned camera positions. A cross photometric loss, an
uncertainty-aware mutual-supervision loss, and a new smoothness loss are
introduced to optimize the network in learning disparity maps end-to-end
without ground-truth depth information. To train this framework, we build a new
multiscopic dataset consisting of synthetic images rendered by 3D engines and
real images captured by real cameras. After being trained with only the
synthetic images, our network can perform well in unseen outdoor scenes. Our
experiment shows that our model obtains better disparity maps than previous
unsupervised methods on the KITTI dataset and is comparable to supervised
methods when generalized to unseen data. Our source code and dataset are
available at https://sites.google.com/view/multiscopic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Transformer Pruning. (arXiv:2104.08500v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingjian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08500">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformer has achieved competitive performance on a variety of
computer vision applications. However, their storage, run-time memory, and
computational demands are hindering the deployment to mobile devices. Here we
present a vision transformer pruning approach, which identifies the impacts of
dimensions in each layer of transformer and then executes pruning accordingly.
By encouraging dimension-wise sparsity in the transformer, important dimensions
automatically emerge. A great number of dimensions with small importance scores
can be discarded to achieve a high pruning ratio without significantly
compromising accuracy. The pipeline for vision transformer pruning is as
follows: 1) training with sparsity regularization; 2) pruning dimensions of
linear projections; 3) fine-tuning. The reduced parameters and FLOPs ratios of
the proposed algorithm are well evaluated and analyzed on ImageNet dataset to
demonstrate the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HiFT: Hierarchical Feature Transformer for Aerial Tracking. (arXiv:2108.00202v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Ziang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Changhong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjie Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiming Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00202">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing Siamese-based tracking methods execute the classification and
regression of the target object based on the similarity maps. However, they
either employ a single map from the last convolutional layer which degrades the
localization accuracy in complex scenarios or separately use multiple maps for
decision making, introducing intractable computations for aerial mobile
platforms. Thus, in this work, we propose an efficient and effective
hierarchical feature transformer (HiFT) for aerial tracking. Hierarchical
similarity maps generated by multi-level convolutional layers are fed into the
feature transformer to achieve the interactive fusion of spatial (shallow
layers) and semantics cues (deep layers). Consequently, not only the global
contextual information can be raised, facilitating the target search, but also
our end-to-end architecture with the transformer can efficiently learn the
interdependencies among multi-level features, thereby discovering a
tracking-tailored feature space with strong discriminability. Comprehensive
evaluations on four aerial benchmarks have proven the effectiveness of HiFT.
Real-world tests on the aerial platform have strongly validated its
practicability with a real-time speed. Our code is available at
https://github.com/vision4robotics/HiFT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple Graph Learning for Scalable Multi-view Clustering. (arXiv:2106.15382v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tianyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Quanxue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15382">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based multi-view clustering has become an active topic due to the
efficiency in characterizing both the complex structure and relationship
between multimedia data. However, existing methods have the following
shortcomings: (1) They are inefficient or even fail for graph learning in large
scale due to the graph construction and eigen-decomposition. (2) They cannot
well exploit both the complementary information and spatial structure embedded
in graphs of different views. To well exploit complementary information and
tackle the scalability issue plaguing graph-based multi-view clustering, we
propose an efficient multiple graph learning model via a small number of anchor
points and tensor Schatten p-norm minimization. Specifically, we construct a
hidden and tractable large graph by anchor graph for each view and well exploit
complementary information embedded in anchor graphs of different views by
tensor Schatten p-norm regularizer. Finally, we develop an efficient algorithm,
which scales linearly with the data size, to solve our proposed model.
Extensive experimental results on several datasets indicate that our proposed
method outperforms some state-of-the-art multi-view clustering algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solo-learn: A Library of Self-supervised Methods for Visual Representation Learning. (arXiv:2108.01775v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_V/0/1/0/all/0/1">Victor G. Turrisi da Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Fini_E/0/1/0/all/0/1">Enrico Fini</a>, <a href="http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1">Moin Nabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1">Elisa Ricci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01775">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents solo-learn, a library of self-supervised methods for
visual representation learning. Implemented in Python, using Pytorch and
Pytorch lightning, the library fits both research and industry needs by
featuring distributed training pipelines with mixed-precision, faster data
loading via Nvidia DALI, online linear evaluation for better prototyping, and
many additional training tricks. Our goal is to provide an easy-to-use library
comprising a large amount of Self-supervised Learning (SSL) methods, that can
be easily extended and fine-tuned by the community. solo-learn opens up avenues
for exploiting large-budget SSL solutions on inexpensive smaller
infrastructures and seeks to democratize SSL by making it accessible to all.
The source code is available at https://github.com/vturrisi/solo-learn.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NPBDREG: A Non-parametric Bayesian Deep-Learning Based Approach for Diffeomorphic Brain MRI Registration. (arXiv:2108.06771v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khawaled_S/0/1/0/all/0/1">Samah Khawaled</a>, <a href="http://arxiv.org/find/cs/1/au:+Freiman_M/0/1/0/all/0/1">Moti Freiman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06771">
                                    <div class="article-summary-box-inner">
                                        <span>Quantification of uncertainty in deep-neural-networks (DNN) based image
registration algorithms plays an important role in the safe deployment of
real-world medical applications and research-oriented processing pipelines, and
in improving generalization capabilities. Currently available approaches for
uncertainty estimation, including the variational encoder-decoder architecture
and the inference-time dropout approach, require specific network architectures
and assume parametric distribution of the latent space which may result in
sub-optimal characterization of the posterior distribution for the predicted
deformation-fields. We introduce the NPBDREG, a fully non-parametric Bayesian
framework for unsupervised DNN-based deformable image registration by combining
an \texttt{Adam} optimizer with stochastic gradient Langevin dynamics (SGLD) to
characterize the true posterior distribution through posterior sampling. The
NPBDREG provides a principled non-parametric way to characterize the true
posterior distribution, thus providing improved uncertainty estimates and
confidence measures in a theoretically well-founded and computationally
efficient way. We demonstrated the added-value of NPBDREG, compared to the
baseline probabilistic \texttt{VoxelMorph} unsupervised model (PrVXM), on brain
MRI images registration using $390$ image pairs from four publicly available
databases: MGH10, CMUC12, ISBR18 and LPBA40. The NPBDREG shows a slight
improvement in the registration accuracy compared to PrVXM (Dice score of
$0.73$ vs. $0.68$, $p \ll 0.01$), a better generalization capability for data
corrupted by a mixed structure noise (e.g Dice score of $0.729$ vs. $0.686$ for
$\alpha&#x3D;0.2$) and last but foremost, a significantly better correlation of the
predicted uncertainty with out-of-distribution data ($r&gt;0.95$ vs. $r&lt;0.5$).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Augmentation for Scene Text Recognition. (arXiv:2108.06949v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Atienza_R/0/1/0/all/0/1">Rowel Atienza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06949">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text recognition (STR) is a challenging task in computer vision due to
the large number of possible text appearances in natural scenes. Most STR
models rely on synthetic datasets for training since there are no sufficiently
big and publicly available labelled real datasets. Since STR models are
evaluated using real data, the mismatch between training and testing data
distributions results into poor performance of models especially on challenging
text that are affected by noise, artifacts, geometry, structure, etc. In this
paper, we introduce STRAug which is made of 36 image augmentation functions
designed for STR. Each function mimics certain text image properties that can
be found in natural scenes, caused by camera sensors, or induced by signal
processing operations but poorly represented in the training dataset. When
applied to strong baseline models using RandAugment, STRAug significantly
increases the overall absolute accuracy of STR models across regular and
irregular test datasets by as much as 2.10% on Rosetta, 1.48% on R2AM, 1.30% on
CRNN, 1.35% on RARE, 1.06% on TRBA and 0.89% on GCRNN. The diversity and
simplicity of API provided by STRAug functions enable easy replication and
validation of existing data augmentation methods for STR. STRAug is available
at https://github.com/roatienza/straug.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Adaptive Monte Carlo Denoising and Super-Resolution. (arXiv:2108.06915v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xinyue Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haozhi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yujin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hongliang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jue Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06915">
                                    <div class="article-summary-box-inner">
                                        <span>The classic Monte Carlo path tracing can achieve high quality rendering at
the cost of heavy computation. Recent works make use of deep neural networks to
accelerate this process, by improving either low-resolution or fewer-sample
rendering with super-resolution or denoising neural networks in
post-processing. However, denoising and super-resolution have only been
considered separately in previous work. We show in this work that Monte Carlo
path tracing can be further accelerated by joint super-resolution and denoising
(SRD) in post-processing. This new type of joint filtering allows only a
low-resolution and fewer-sample (thus noisy) image to be rendered by path
tracing, which is then fed into a deep neural network to produce a
high-resolution and clean image. The main contribution of this work is a new
end-to-end network architecture, specifically designed for the SRD task. It
contains two cascaded stages with shared components. We discover that denoising
and super-resolution require very different receptive fields, a key insight
that leads to the introduction of deformable convolution into the network
design. Extensive experiments show that the proposed method outperforms
previous methods and their variants adopted for the SRD task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cascaded Zoom-In Network for Patterned Fabric Defect Detection. (arXiv:2108.06760v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06760">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, Deep Convolutional Neural Networks (DCNNs) are widely used in
fabric defect detection, which come with the cost of expensive training and
complex model parameters. With the observation that most fabrics are defect
free in practice, a two-step Cascaded Zoom-In Network (CZI-Net) is proposed for
patterned fabric defect detection. In the CZI-Net, the Aggregated HOG (A-HOG)
and SIFT features are used to instead of simple convolution filters for feature
extraction. Moreover, in order to extract more distinctive features, the
feature representation layer and full connection layer are included in the
CZI-Net. In practice, Most defect-free fabrics only involve in the first step
of our method and avoid a costive computation in the second step, which makes
very fast fabric detection. More importantly, we propose the
Locality-constrained Reconstruction Error (LCRE) in the first step and
Restrictive Locality-constrained Coding (RLC), Bag-of-Indexes (BoI) methods in
the second step. We also analyse the connections between different coding
methods and conclude that the index of visual words plays an essential role in
the coding methods. In conclusion, experiments based on real-world datasets are
implemented and demonstrate that our proposed method is not only
computationally simple but also with high detection accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">B-Splines. (arXiv:2108.06617v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_A/0/1/0/all/0/1">Arindam Chaudhuri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06617">
                                    <div class="article-summary-box-inner">
                                        <span>BSplines are one of the most promising curves in computer graphics. They are
blessed with some superior geometric properties which make them an ideal
candidate for several applications in computer aided design industry. In this
article, some basic properties of B-Spline curves are presented. Two
significant B-Spline properties viz convex hull property and repeated points
effects are discussed. The BSplines computation in computational devices is
also illustrated. An industry application based on image processing where
B-Spline curve reconstructs the 3D surfaces for CT image datasets of inner
organs further highlights the strength of these curves</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting a Joint Embedding Space for Generalized Zero-Shot Semantic Segmentation. (arXiv:2108.06536v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baek_D/0/1/0/all/0/1">Donghyeon Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Youngmin Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ham_B/0/1/0/all/0/1">Bumsub Ham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06536">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of generalized zero-shot semantic segmentation (GZS3)
predicting pixel-wise semantic labels for seen and unseen classes. Most GZS3
methods adopt a generative approach that synthesizes visual features of unseen
classes from corresponding semantic ones (e.g., word2vec) to train novel
classifiers for both seen and unseen classes. Although generative methods show
decent performance, they have two limitations: (1) the visual features are
biased towards seen classes; (2) the classifier should be retrained whenever
novel unseen classes appear. We propose a discriminative approach to address
these limitations in a unified framework. To this end, we leverage visual and
semantic encoders to learn a joint embedding space, where the semantic encoder
transforms semantic features to semantic prototypes that act as centers for
visual features of corresponding classes. Specifically, we introduce
boundary-aware regression (BAR) and semantic consistency (SC) losses to learn
discriminative features. Our approach to exploiting the joint embedding space,
together with BAR and SC terms, alleviates the seen bias problem. At test time,
we avoid the retraining process by exploiting semantic prototypes as a
nearest-neighbor (NN) classifier. To further alleviate the bias problem, we
also propose an inference technique, dubbed Apollonius calibration (AC), that
modulates the decision boundary of the NN classifier to the Apollonius circle
adaptively. Experimental results demonstrate the effectiveness of our
framework, achieving a new state of the art on standard benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Category and Domain Alignment: Category-Invariant Feature Enhancement for Adversarial Domain Adaptation. (arXiv:2108.06583v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkpen_D/0/1/0/all/0/1">Diana Inkpen</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Roby_A/0/1/0/all/0/1">Ahmed El-Roby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06583">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial domain adaptation has made impressive advances in transferring
knowledge from the source domain to the target domain by aligning feature
distributions of both domains. These methods focus on minimizing domain
divergence and regard the adaptability, which is measured as the expected error
of the ideal joint hypothesis on these two domains, as a small constant.
However, these approaches still face two issues: (1) Adversarial domain
alignment distorts the original feature distributions, deteriorating the
adaptability; (2) Transforming feature representations to be domain-invariant
needs to sacrifice domain-specific variations, resulting in weaker
discriminability. In order to alleviate these issues, we propose
category-invariant feature enhancement (CIFE), a general mechanism that
enhances the adversarial domain adaptation through optimizing the adaptability.
Specifically, the CIFE approach introduces category-invariant features to boost
the discriminability of domain-invariant features with preserving the
transferability. Experiments show that the CIFE could improve upon
representative adversarial domain adaptation methods to yield state-of-the-art
results on five benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-Aware Single Image Specular Highlight Removal. (arXiv:2108.06881v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_S/0/1/0/all/0/1">Shiyu Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaoqun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_W/0/1/0/all/0/1">Weize Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jingen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1">Dong-Ming Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06881">
                                    <div class="article-summary-box-inner">
                                        <span>Removing undesirable specular highlight from a single input image is of
crucial importance to many computer vision and graphics tasks. Existing methods
typically remove specular highlight for medical images and specific-object
images, however, they cannot handle the images with text. In addition, the
impact of specular highlight on text recognition is rarely studied by text
detection and recognition community. Therefore, in this paper, we first raise
and study the text-aware single image specular highlight removal problem. The
core goal is to improve the accuracy of text detection and recognition by
removing the highlight from text images. To tackle this challenging problem, we
first collect three high-quality datasets with fine-grained annotations, which
will be appropriately released to facilitate the relevant research. Then, we
design a novel two-stage network, which contains a highlight detection network
and a highlight removal network. The output of highlight detection network
provides additional information about highlight regions to guide the subsequent
highlight removal network. Moreover, we suggest a measurement set including the
end-to-end text detection and recognition evaluation and auxiliary visual
quality evaluation. Extensive experiments on our collected datasets demonstrate
the superior performance of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Continual Learning For Visual Food Classification. (arXiv:2108.06781v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jiangpeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fengqing Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06781">
                                    <div class="article-summary-box-inner">
                                        <span>Food image classification is challenging for real-world applications since
existing methods require static datasets for training and are not capable of
learning from sequentially available new food images. Online continual learning
aims to learn new classes from data stream by using each new data only once
without forgetting the previously learned knowledge. However, none of the
existing works target food image analysis, which is more difficult to learn
incrementally due to its high intra-class variation with the unbalanced and
unpredictable characteristics of future food class distribution. In this paper,
we address these issues by introducing (1) a novel clustering based exemplar
selection algorithm to store the most representative data belonging to each
learned food for knowledge replay, and (2) an effective online learning regime
using balanced training batch along with the knowledge distillation on
augmented exemplars to maintain the model performance on all learned classes.
Our method is evaluated on a challenging large scale food image database,
Food-1K, by varying the number of newly added food classes. Our results show
significant improvements compared with existing state-of-the-art online
continual learning methods, showing great potential to achieve lifelong
learning for food image classification in real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Occlusion-Aware Video Object Inpainting. (arXiv:2108.06765v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_L/0/1/0/all/0/1">Lei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Yu-Wing Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chi-Keung Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06765">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional video inpainting is neither object-oriented nor occlusion-aware,
making it liable to obvious artifacts when large occluded object regions are
inpainted. This paper presents occlusion-aware video object inpainting, which
recovers both the complete shape and appearance for occluded objects in videos
given their visible mask segmentation.

To facilitate this new research, we construct the first large-scale video
object inpainting benchmark YouTube-VOI to provide realistic occlusion
scenarios with both occluded and visible object masks available. Our technical
contribution VOIN jointly performs video object shape completion and occluded
texture generation. In particular, the shape completion module models
long-range object coherence while the flow completion module recovers accurate
flow with sharp motion boundary, for propagating temporally-consistent texture
to the same moving object across frames. For more realistic results, VOIN is
optimized using both T-PatchGAN and a new spatio-temporal attention-based
multi-class discriminator.

Finally, we compare VOIN and strong baselines on YouTube-VOI. Experimental
results clearly demonstrate the efficacy of our method including inpainting
complex and dynamic objects. VOIN degrades gracefully with inaccurate input
visible mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCIDA: Self-Correction Integrated Domain Adaptation from Single- to Multi-label Aerial Images. (arXiv:2108.06810v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tianze Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jianzhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1">Lichao Mou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yuansheng Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoxiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Z. Jane Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06810">
                                    <div class="article-summary-box-inner">
                                        <span>Most publicly available datasets for image classification are with single
labels, while images are inherently multi-labeled in our daily life. Such an
annotation gap makes many pre-trained single-label classification models fail
in practical scenarios. This annotation issue is more concerned for aerial
images: Aerial data collected from sensors naturally cover a relatively large
land area with multiple labels, while annotated aerial datasets, which are
publicly available (e.g., UCM, AID), are single-labeled. As manually annotating
multi-label aerial images would be time/labor-consuming, we propose a novel
self-correction integrated domain adaptation (SCIDA) method for automatic
multi-label learning. SCIDA is weakly supervised, i.e., automatically learning
the multi-label image classification model from using massive, publicly
available single-label images. To achieve this goal, we propose a novel
Label-Wise self-Correction (LWC) module to better explore underlying label
correlations. This module also makes the unsupervised domain adaptation (UDA)
from single- to multi-label data possible. For model training, the proposed
model only uses single-label information yet requires no prior knowledge of
multi-labeled data; and it predicts labels for multi-label aerial images. In
our experiments, trained with single-labeled MAI-AID-s and MAI-UCM-s datasets,
the proposed model is tested directly on our collected Multi-scene Aerial Image
(MAI) dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaCon: Adaptive Context-Aware Object Detection for Resource-Constrained Embedded Devices. (arXiv:2108.06850v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neseem_M/0/1/0/all/0/1">Marina Neseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Reda_S/0/1/0/all/0/1">Sherief Reda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06850">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks achieve state-of-the-art accuracy in object
detection tasks. However, they have large computational and energy requirements
that challenge their deployment on resource-constrained edge devices. Object
detection takes an image as an input, and identifies the existing object
classes as well as their locations in the image. In this paper, we leverage the
prior knowledge about the probabilities that different object categories can
occur jointly to increase the efficiency of object detection models. In
particular, our technique clusters the object categories based on their spatial
co-occurrence probability. We use those clusters to design an adaptive network.
During runtime, a branch controller decides which part(s) of the network to
execute based on the spatial context of the input frame. Our experiments using
COCO dataset show that our adaptive object detection model achieves up to 45%
reduction in the energy consumption, and up to 27% reduction in the latency,
with a small loss in the average precision (AP) of object detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular visual autonomous landing system for quadcopter drones using software in the loop. (arXiv:2108.06616v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saavedra_Ruiz_M/0/1/0/all/0/1">Miguel Saavedra-Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_Vargas_A/0/1/0/all/0/1">Ana Mario Pinto-Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_Cano_V/0/1/0/all/0/1">Victor Romero-Cano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06616">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous landing is a capability that is essential to achieve the full
potential of multi-rotor drones in many social and industrial applications. The
implementation and testing of this capability on physical platforms is risky
and resource-intensive; hence, in order to ensure both a sound design process
and a safe deployment, simulations are required before implementing a physical
prototype. This paper presents the development of a monocular visual system,
using a software-in-the-loop methodology, that autonomously and efficiently
lands a quadcopter drone on a predefined landing pad, thus reducing the risks
of the physical testing stage. In addition to ensuring that the autonomous
landing system as a whole fulfils the design requirements using a Gazebo-based
simulation, our approach provides a tool for safe parameter tuning and design
testing prior to physical implementation. Finally, the proposed monocular
vision-only approach to landing pad tracking made it possible to effectively
implement the system in an F450 quadcopter drone with the standard
computational capabilities of an Odroid XU4 embedded processor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refractive Geometry for Underwater Domes. (arXiv:2108.06575v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+She_M/0/1/0/all/0/1">Mengkun She</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakath_D/0/1/0/all/0/1">David Nakath</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yifan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Koser_K/0/1/0/all/0/1">Kevin K&#xf6;ser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06575">
                                    <div class="article-summary-box-inner">
                                        <span>Underwater cameras are typically placed behind glass windows to protect them
from the water. Spherical glass, a dome port, is well suited for high water
pressures at great depth, allows for a large field of view, and avoids
refraction if a pinhole camera is positioned exactly at the sphere&#x27;s center.
Adjusting a real lens perfectly to the dome center is a challenging task, both
in terms of how to actually guide the centering process (e.g. visual servoing)
and how to measure the alignment quality, but also, how to mechanically perform
the alignment. Consequently, such systems are prone to being decentered by some
offset, leading to challenging refraction patterns at the sphere that
invalidate the pinhole camera model. We show that the overall camera system
becomes an axial camera, even for thick domes as used for deep sea exploration
and provide a non-iterative way to compute the center of refraction without
requiring knowledge of exact air, glass or water properties. We also analyze
the refractive geometry at the sphere, looking at effects such as forward- vs.
backward decentering, iso-refraction curves and obtain a 6th-degree polynomial
equation for forward projection of 3D points in thin domes. We then propose a
pure underwater calibration procedure to estimate the decentering from multiple
images. This estimate can either be used during adjustment to guide the
mechanical position of the lens, or can be considered in photogrammetric
underwater applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dilated Inception U-Net (DIU-Net) for Brain Tumor Segmentation. (arXiv:2108.06772v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cahall_D/0/1/0/all/0/1">Daniel E. Cahall</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1">Ghulam Rasool</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouaynaya_N/0/1/0/all/0/1">Nidhal C. Bouaynaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathallah_Shaykh_H/0/1/0/all/0/1">Hassan M. Fathallah-Shaykh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06772">
                                    <div class="article-summary-box-inner">
                                        <span>Magnetic resonance imaging (MRI) is routinely used for brain tumor diagnosis,
treatment planning, and post-treatment surveillance. Recently, various models
based on deep neural networks have been proposed for the pixel-level
segmentation of tumors in brain MRIs. However, the structural variations,
spatial dissimilarities, and intensity inhomogeneity in MRIs make segmentation
a challenging task. We propose a new end-to-end brain tumor segmentation
architecture based on U-Net that integrates Inception modules and dilated
convolutions into its contracting and expanding paths. This allows us to
extract local structural as well as global contextual information. We performed
segmentation of glioma sub-regions, including tumor core, enhancing tumor, and
whole tumor using Brain Tumor Segmentation (BraTS) 2018 dataset. Our proposed
model performed significantly better than the state-of-the-art U-Net-based
model ($p&lt;0.05$) for tumor core and whole tumor segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Person Re-identification with Stochastic Training Strategy. (arXiv:2108.06938v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yutian Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06938">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised person re-identification (re-ID) has attracted increasing
research interests because of its scalability and possibility for real-world
applications. State-of-the-art unsupervised re-ID methods usually follow a
clustering-based strategy, which generates pseudo labels by clustering and
maintains a memory to store instance features and represent the centroid of the
clusters for contrastive learning. This approach suffers two problems. First,
the centroid generated by unsupervised learning may not be a perfect prototype.
Forcing images to get closer to the centroid emphasizes the result of
clustering, which could accumulate clustering errors during iterations. Second,
previous methods utilize features obtained at different training iterations to
represent one centroid, which is not consistent with the current training
sample, since the features are not directly comparable. To this end, we propose
an unsupervised re-ID approach with a stochastic learning strategy.
Specifically, we adopt a stochastic updated memory, where a random instance
from a cluster is used to update the cluster-level memory for contrastive
learning. In this way, the relationship between randomly selected pair of
images are learned to avoid the training bias caused by unreliable pseudo
labels. The stochastic memory is also always up-to-date for classifying to keep
the consistency. Besides, to relieve the issue of camera variance, a unified
distance matrix is proposed during clustering, where the distance bias from
different camera domain is reduced and the variances of identities is
emphasized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two Eyes Are Better Than One: Exploiting Binocular Correlation for Diabetic Retinopathy Severity Grading. (arXiv:2108.06763v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1">Peisheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Ziyuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zeng Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06763">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetic retinopathy (DR) is one of the most common eye conditions among
diabetic patients. However, vision loss occurs primarily in the late stages of
DR, and the symptoms of visual impairment, ranging from mild to severe, can
vary greatly, adding to the burden of diagnosis and treatment in clinical
practice. Deep learning methods based on retinal images have achieved
remarkable success in automatic DR grading, but most of them neglect that the
presence of diabetes usually affects both eyes, and ophthalmologists usually
compare both eyes concurrently for DR diagnosis, leaving correlations between
left and right eyes unexploited. In this study, simulating the diagnostic
process, we propose a two-stream binocular network to capture the subtle
correlations between left and right eyes, in which, paired images of eyes are
fed into two identical subnetworks separately during training. We design a
contrastive grading loss to learn binocular correlation for five-class DR
detection, which maximizes inter-class dissimilarity while minimizing the
intra-class difference. Experimental results on the EyePACS dataset show the
superiority of the proposed binocular model, outperforming monocular methods by
a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Soccer line mark segmentation with stochastic watershed transform. (arXiv:2108.06432v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berjon_D/0/1/0/all/0/1">Daniel Berj&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuevas_C/0/1/0/all/0/1">Carlos Cuevas</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_N/0/1/0/all/0/1">Narciso Garc&#xed;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06432">
                                    <div class="article-summary-box-inner">
                                        <span>Augmented reality applications are beginning to change the way sports are
broadcast, providing richer experiences and valuable insights to fans. The
first step of augmented reality systems is camera calibration, possibly based
on detecting the line markings of the field of play. Most existing proposals
for line detection rely on edge detection and Hough transform, but optical
distortion and extraneous edges cause inaccurate or spurious detections of line
markings. We propose a novel strategy to automatically and accurately segment
line markings based on a stochastic watershed transform that is robust to
optical distortions, since it makes no assumptions about line straightness, and
is unaffected by the presence of players or the ball in the field of play.
Firstly, the playing field as a whole is segmented completely eliminating the
stands and perimeter boards. Then the line markings are extracted.

The strategy has been tested on a new and public database composed by 60
annotated images from matches in five stadiums. The results obtained have
proven that the proposed segmentation algorithm allows successful and precise
detection of most line mark pixels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Fine-Grained Action Recognition via Bidirectional Attention and Contrastive Meta-Learning. (arXiv:2108.06647v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiahao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Annan Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06647">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained action recognition is attracting increasing attention due to the
emerging demand of specific action understanding in real-world applications,
whereas the data of rare fine-grained categories is very limited. Therefore, we
propose the few-shot fine-grained action recognition problem, aiming to
recognize novel fine-grained actions with only few samples given for each
class. Although progress has been made in coarse-grained actions, existing
few-shot recognition methods encounter two issues handling fine-grained
actions: the inability to capture subtle action details and the inadequacy in
learning from data with low inter-class variance. To tackle the first issue, a
human vision inspired bidirectional attention module (BAM) is proposed.
Combining top-down task-driven signals with bottom-up salient stimuli, BAM
captures subtle action details by accurately highlighting informative
spatio-temporal regions. To address the second issue, we introduce contrastive
meta-learning (CML). Compared with the widely adopted ProtoNet-based method,
CML generates more discriminative video representations for low inter-class
variance data, since it makes full use of potential contrastive pairs in each
training episode. Furthermore, to fairly compare different models, we establish
specific benchmark protocols on two large-scale fine-grained action recognition
datasets. Extensive experiments show that our method consistently achieves
state-of-the-art performance across evaluated tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPG: Unsupervised Domain Adaptation for 3D Object Detection via Semantic Point Generation. (arXiv:2108.06709v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiangeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1">Charles R. Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Anguelov_D/0/1/0/all/0/1">Dragomir Anguelov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06709">
                                    <div class="article-summary-box-inner">
                                        <span>In autonomous driving, a LiDAR-based object detector should perform reliably
at different geographic locations and under various weather conditions. While
recent 3D detection research focuses on improving performance within a single
domain, our study reveals that the performance of modern detectors can drop
drastically cross-domain. In this paper, we investigate unsupervised domain
adaptation (UDA) for LiDAR-based 3D object detection. On the Waymo Domain
Adaptation dataset, we identify the deteriorating point cloud quality as the
root cause of the performance drop. To address this issue, we present Semantic
Point Generation (SPG), a general approach to enhance the reliability of LiDAR
detectors against domain shifts. Specifically, SPG generates semantic points at
the predicted foreground regions and faithfully recovers missing parts of the
foreground objects, which are caused by phenomena such as occlusions, low
reflectance or weather interference. By merging the semantic points with the
original points, we obtain an augmented point cloud, which can be directly
consumed by modern LiDAR-based detectors. To validate the wide applicability of
SPG, we experiment with two representative detectors, PointPillars and PV-RCNN.
On the UDA task, SPG significantly improves both detectors across all object
categories of interest and at all difficulty levels. SPG can also benefit
object detection in the original domain. On the Waymo Open Dataset and KITTI,
SPG improves 3D detection results of these two methods across all categories.
Combined with PV-RCNN, SPG achieves state-of-the-art 3D detection results on
KITTI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deepfake Representation with Multilinear Regression. (arXiv:2108.06702v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilescu_M/0/1/0/all/0/1">M. Alex O. Vasilescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1">Evangelos E. Papalexakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06702">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural network architectures such as GANs, may be used to generate
synthetic instances to compensate for the lack of real data. However, they may
be employed to create media that may cause social, political or economical
upheaval. One emerging media is &quot;Deepfake&quot;.Techniques that can discriminate
between such media is indispensable. In this paper, we propose a modified
multilinear (tensor) method, a combination of linear and multilinear
regressions for representing fake and real data. We test our approach by
representing Deepfakes with our modified multilinear (tensor) approach and
perform SVM classification with encouraging results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds. (arXiv:2108.06455v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shan_J/0/1/0/all/0/1">Jiayao Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sifan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yubo Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06455">
                                    <div class="article-summary-box-inner">
                                        <span>3D single object tracking is a key issue for robotics. In this paper, we
propose a transformer module called Point-Track-Transformer (PTT) for point
cloud-based 3D single object tracking. PTT module contains three blocks for
feature embedding, position encoding, and self-attention feature computation.
Feature embedding aims to place features closer in the embedding space if they
have similar semantic information. Position encoding is used to encode
coordinates of point clouds into high dimension distinguishable features.
Self-attention generates refined attention features by computing attention
weights. Besides, we embed the PTT module into the open-source state-of-the-art
method P2B to construct PTT-Net. Experiments on the KITTI dataset reveal that
our PTT-Net surpasses the state-of-the-art by a noticeable margin (~10\%).
Additionally, PTT-Net could achieve real-time performance (~40FPS) on NVIDIA
1080Ti GPU. Our code is open-sourced for the robotics community at
https://github.com/shanjiayao/PTT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">My Eyes Are Up Here: Promoting Focus on Uncovered Regions in Masked Face Recognition. (arXiv:2108.00996v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neto_P/0/1/0/all/0/1">Pedro C. Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1">Fadi Boutros</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1">Jo&#xe3;o Ribeiro Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Saffari_M/0/1/0/all/0/1">Mohsen Saffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1">Naser Damer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sequeira_A/0/1/0/all/0/1">Ana F. Sequeira</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardoso_J/0/1/0/all/0/1">Jaime S. Cardoso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00996">
                                    <div class="article-summary-box-inner">
                                        <span>The recent Covid-19 pandemic and the fact that wearing masks in public is now
mandatory in several countries, created challenges in the use of face
recognition systems (FRS). In this work, we address the challenge of masked
face recognition (MFR) and focus on evaluating the verification performance in
FRS when verifying masked vs unmasked faces compared to verifying only unmasked
faces. We propose a methodology that combines the traditional triplet loss and
the mean squared error (MSE) intending to improve the robustness of an MFR
system in the masked-unmasked comparison mode. The results obtained by our
proposed method show improvements in a detailed step-wise ablation study. The
conducted study showed significant performance gains induced by our proposed
training paradigm and modified triplet loss on two evaluation databases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-embedded Unsupervised Spectral Reconstruction from Single RGB Images in the Wild. (arXiv:2108.06659v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhiyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Huanqiang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06659">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the problem of reconstructing hyperspectral (HS)
images from single RGB images captured by commercial cameras, \textbf{without}
using paired HS and RGB images during training. To tackle this challenge, we
propose a new lightweight and end-to-end learning-based framework.
Specifically, on the basis of the intrinsic imaging degradation model of RGB
images from HS images, we progressively spread the differences between input
RGB images and re-projected RGB images from recovered HS images via effective
unsupervised camera spectral response function estimation. To enable the
learning without paired ground-truth HS images as supervision, we adopt the
adversarial learning manner and boost it with a simple yet effective
$\mathcal{L}_1$ gradient clipping scheme. Besides, we embed the semantic
information of input RGB images to locally regularize the unsupervised
learning, which is expected to promote pixels with identical semantics to have
consistent spectral signatures. In addition to conducting quantitative
experiments over two widely-used datasets for HS image reconstruction from
synthetic RGB images, we also evaluate our method by applying recovered HS
images from real RGB images to HS-based visual tracking. Extensive results show
that our method significantly outperforms state-of-the-art unsupervised methods
and even exceeds the latest supervised method under some settings. The source
code is public available at
https://github.com/zbzhzhy/Unsupervised-Spectral-Reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Identification and Matching for Hand Hygiene Pose. (arXiv:2108.06537v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1">Rashmi Bakshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06537">
                                    <div class="article-summary-box-inner">
                                        <span>Three popular feature descriptors of computer vision such as SIFT, SURF, and
ORB compared and evaluated. The number of correct features extracted and
matched for the original hand hygiene pose-Rub hands palm to palm image and
rotated image. An accuracy score calculated based on the total number of
matches and the correct number of matches produced. The experiment demonstrated
that ORB algorithm outperforms by giving the high number of correct matches in
less amount of time. ORB feature detection technique applied over handwashing
video recordings for feature extraction and hand hygiene pose classification as
a future work. OpenCV utilized to apply the algorithms within python scripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TL-SDD: A Transfer Learning-Based Method for Surface Defect Detection with Few Samples. (arXiv:2108.06939v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jiahui Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Bin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sicong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guangzhi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yueqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiwen Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06939">
                                    <div class="article-summary-box-inner">
                                        <span>Surface defect detection plays an increasingly important role in
manufacturing industry to guarantee the product quality. Many deep learning
methods have been widely used in surface defect detection tasks, and have been
proven to perform well in defects classification and location. However, deep
learning-based detection methods often require plenty of data for training,
which fail to apply to the real industrial scenarios since the distribution of
defect categories is often imbalanced. In other words, common defect classes
have many samples but rare defect classes have extremely few samples, and it is
difficult for these methods to well detect rare defect classes. To solve the
imbalanced distribution problem, in this paper we propose TL-SDD: a novel
Transfer Learning-based method for Surface Defect Detection. First, we adopt a
two-phase training scheme to transfer the knowledge from common defect classes
to rare defect classes. Second, we propose a novel Metric-based Surface Defect
Detection (M-SDD) model. We design three modules for this model: (1) feature
extraction module: containing feature fusion which combines high-level semantic
information with low-level structural information. (2) feature reweighting
module: transforming examples to a reweighting vector that indicates the
importance of features. (3) distance metric module: learning a metric space in
which defects are classified by computing distances to representations of each
category. Finally, we validate the performance of our proposed method on a real
dataset including surface defects of aluminum profiles. Compared to the
baseline methods, the performance of our proposed method has improved by up to
11.98% for rare defect classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Temporal Anomaly Segmentation with Dynamic Time Warping. (arXiv:2108.06816v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dongha Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sehun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_H/0/1/0/all/0/1">Hyunjun Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06816">
                                    <div class="article-summary-box-inner">
                                        <span>Most recent studies on detecting and localizing temporal anomalies have
mainly employed deep neural networks to learn the normal patterns of temporal
data in an unsupervised manner. Unlike them, the goal of our work is to fully
utilize instance-level (or weak) anomaly labels, which only indicate whether
any anomalous events occurred or not in each instance of temporal data. In this
paper, we present WETAS, a novel framework that effectively identifies
anomalous temporal segments (i.e., consecutive time points) in an input
instance. WETAS learns discriminative features from the instance-level labels
so that it infers the sequential order of normal and anomalous segments within
each instance, which can be used as a rough segmentation mask. Based on the
dynamic time warping (DTW) alignment between the input instance and its
segmentation mask, WETAS obtains the result of temporal segmentation, and
simultaneously, it further enhances itself by using the mask as additional
supervision. Our experiments show that WETAS considerably outperforms other
baselines in terms of the localization of temporal anomalies, and also it
provides more informative results than point-level detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Real-World Prohibited Item Detection: A Large-Scale X-ray Benchmark. (arXiv:2108.07020v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boying Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Libo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Longyin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianglong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanjun Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07020">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic security inspection using computer vision technology is a
challenging task in real-world scenarios due to various factors, including
intra-class variance, class imbalance, and occlusion. Most of the previous
methods rarely solve the cases that the prohibited items are deliberately
hidden in messy objects due to the lack of large-scale datasets, restricted
their applications in real-world scenarios. Towards real-world prohibited item
detection, we collect a large-scale dataset, named as PIDray, which covers
various cases in real-world scenarios for prohibited item detection, especially
for deliberately hidden items. With an intensive amount of effort, our dataset
contains $12$ categories of prohibited items in $47,677$ X-ray images with
high-quality annotated segmentation masks and bounding boxes. To the best of
our knowledge, it is the largest prohibited items detection dataset to date.
Meanwhile, we design the selective dense attention network (SDANet) to
construct a strong baseline, which consists of the dense attention module and
the dependency refinement module. The dense attention module formed by the
spatial and channel-wise dense attentions, is designed to learn the
discriminative features to boost the performance. The dependency refinement
module is used to exploit the dependencies of multi-scale features. Extensive
experiments conducted on the collected PIDray dataset demonstrate that the
proposed method performs favorably against the state-of-the-art methods,
especially for detecting the deliberately hidden items.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised 3D Object Detection via Adaptive Pseudo-Labeling. (arXiv:2108.06649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hongyi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fengqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jinkun Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhijie Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhengyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06649">
                                    <div class="article-summary-box-inner">
                                        <span>3D object detection is an important task in computer vision. Most existing
methods require a large number of high-quality 3D annotations, which are
expensive to collect. Especially for outdoor scenes, the problem becomes more
severe due to the sparseness of the point cloud and the complexity of urban
scenes. Semi-supervised learning is a promising technique to mitigate the data
annotation issue. Inspired by this, we propose a novel semi-supervised
framework based on pseudo-labeling for outdoor 3D object detection tasks. We
design the Adaptive Class Confidence Selection module (ACCS) to generate
high-quality pseudo-labels. Besides, we propose Holistic Point Cloud
Augmentation (HPCA) for unlabeled data to improve robustness. Experiments on
the KITTI benchmark demonstrate the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on GAN Acceleration Using Memory Compression Technique. (arXiv:2108.06626v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tantawy_D/0/1/0/all/0/1">Dina Tantawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahran_M/0/1/0/all/0/1">Mohamed Zahran</a>, <a href="http://arxiv.org/find/cs/1/au:+Wassal_A/0/1/0/all/0/1">Amr Wassal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06626">
                                    <div class="article-summary-box-inner">
                                        <span>Since its invention, Generative adversarial networks (GANs) have shown
outstanding results in many applications. Generative Adversarial Networks are
powerful yet, resource-hungry deep-learning models. Their main difference from
ordinary deep learning models is the nature of their output. For example, GAN
output can be a whole image versus other models detecting objects or
classifying images. Thus, the architecture and numeric precision of the network
affect the quality and speed of the solution. Hence, accelerating GANs is
pivotal. Accelerating GANs can be classified into three main tracks: (1) Memory
compression, (2) Computation optimization, and (3) Data-flow optimization.
Because data transfer is the main source of energy usage, memory compression
leads to the most savings. Thus, in this paper, we survey memory compression
techniques for CNN-Based GANs. Additionally, the paper summarizes opportunities
and challenges in GANs acceleration and suggests open research problems to be
further investigated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for L3 Slice Localization in Sarcopenia Assessment. (arXiv:2107.12800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laousy_O/0/1/0/all/0/1">Othmane Laousy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12800">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcopenia is a medical condition characterized by a reduction in muscle mass
and function. A quantitative diagnosis technique consists of localizing the CT
slice passing through the middle of the third lumbar area (L3) and segmenting
muscles at this level. In this paper, we propose a deep reinforcement learning
method for accurate localization of the L3 CT slice. Our method trains a
reinforcement learning agent by incentivizing it to discover the right
position. Specifically, a Deep Q-Network is trained to find the best policy to
follow for this problem. Visualizing the training process shows that the agent
mimics the scrolling of an experienced radiologist. Extensive experiments
against other state-of-the-art deep learning based methods for L3 localization
prove the superiority of our technique which performs well even with a limited
amount of data and annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RDA: Robust Domain Adaptation via Fourier Adversarial Attacking. (arXiv:2106.02874v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02874">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) involves a supervised loss in a labeled
source domain and an unsupervised loss in an unlabeled target domain, which
often faces more severe overfitting (than classical supervised learning) as the
supervised source loss has clear domain gap and the unsupervised target loss is
often noisy due to the lack of annotations. This paper presents RDA, a robust
domain adaptation technique that introduces adversarial attacking to mitigate
overfitting in UDA. We achieve robust domain adaptation by a novel Fourier
adversarial attacking (FAA) method that allows large magnitude of perturbation
noises but has minimal modification of image semantics, the former is critical
to the effectiveness of its generated adversarial samples due to the existence
of &#x27;domain gaps&#x27;. Specifically, FAA decomposes images into multiple frequency
components (FCs) and generates adversarial samples by just perturbating certain
FCs that capture little semantic information. With FAA-generated samples, the
training can continue the &#x27;random walk&#x27; and drift into an area with a flat loss
landscape, leading to more robust domain adaptation. Extensive experiments over
multiple domain adaptation tasks show that RDA can work with different computer
vision tasks with superior performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reference Service Model for Federated Identity Management. (arXiv:2108.06701v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pohn_D/0/1/0/all/0/1">Daniela P&#xf6;hn</a>, <a href="http://arxiv.org/find/cs/1/au:+Hillmann_P/0/1/0/all/0/1">Peter Hillmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06701">
                                    <div class="article-summary-box-inner">
                                        <span>With the pandemic of COVID-19, people around the world increasingly work from
home. Each natural person typically has several digital identities with
different associated information. During the last years, various identity and
access management approaches have gained attraction, helping for example to
access other organization&#x27;s services within trust boundaries. The resulting
heterogeneity creates a high complexity to differentiate between these
approaches and scenarios as participating entity; combining them is even
harder. Last but not least, various actors have a different understanding or
perspective of the terms, like &#x27;service&#x27;, in this context. Our paper describes
a reference service with standard components in generic federated identity
management. This is utilized with modern Enterprise Architecture using the
framework ArchiMate. The proposed universal federated identity management
service model (FIMSM) is applied to describe various federated identity
management scenarios in a generic service-oriented way. The presented reference
design is approved in multiple aspects and is easily applicable in numerous
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Siamese Network for Identifying Bad Data in Medical Imaging Datasets. (arXiv:2108.07130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belton_N/0/1/0/all/0/1">Niamh Belton</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawlor_A/0/1/0/all/0/1">Aonghus Lawlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Curran_K/0/1/0/all/0/1">Kathleen M. Curran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07130">
                                    <div class="article-summary-box-inner">
                                        <span>Noisy data present in medical imaging datasets can often aid the development
of robust models that are equipped to handle real-world data. However, if the
bad data contains insufficient anatomical information, it can have a severe
negative effect on the model&#x27;s performance. We propose a novel methodology
using a semi-supervised Siamese network to identify bad data. This method
requires only a small pool of &#x27;reference&#x27; medical images to be reviewed by a
non-expert human to ensure the major anatomical structures are present in the
Field of View. The model trains on this reference set and identifies bad data
by using the Siamese network to compute the distance between the reference set
and all other medical images in the dataset. This methodology achieves an Area
Under the Curve (AUC) of 0.989 for identifying bad data. Code will be available
at https://git.io/JYFuV.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rundi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Changxi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09492">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models of 3D shapes have received a great deal of research
interest. Yet, almost all of them generate discrete shape representations, such
as voxels, point clouds, and polygon meshes. We present the first 3D generative
model for a drastically different shape representation --- describing a shape
as a sequence of computer-aided design (CAD) operations. Unlike meshes and
point clouds, CAD models encode the user creation process of 3D shapes, widely
used in numerous industrial and engineering design tasks. However, the
sequential and irregular structure of CAD operations poses significant
challenges for existing 3D generative models. Drawing an analogy between CAD
operations and natural language, we propose a CAD generative network based on
the Transformer. We demonstrate the performance of our model for both shape
autoencoding and random shape generation. To train our network, we create a new
CAD dataset consisting of 178,238 models and their CAD construction sequences.
We have made this dataset publicly available to promote future research on this
topic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disease-oriented image embedding with pseudo-scanner standardization for content-based image retrieval on 3D brain MRI. (arXiv:2108.06518v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arai_H/0/1/0/all/0/1">Hayato Arai</a>, <a href="http://arxiv.org/find/cs/1/au:+Onga_Y/0/1/0/all/0/1">Yuto Onga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikuta_K/0/1/0/all/0/1">Kumpei Ikuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chayama_Y/0/1/0/all/0/1">Yusuke Chayama</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oishi_K/0/1/0/all/0/1">Kenichi Oishi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06518">
                                    <div class="article-summary-box-inner">
                                        <span>To build a robust and practical content-based image retrieval (CBIR) system
that is applicable to a clinical brain MRI database, we propose a new framework
-- Disease-oriented image embedding with pseudo-scanner standardization
(DI-PSS) -- that consists of two core techniques, data harmonization and a
dimension reduction algorithm. Our DI-PSS uses skull stripping and
CycleGAN-based image transformations that map to a standard brain followed by
transformation into a brain image taken with a given reference scanner. Then,
our 3D convolutioinal autoencoders (3D-CAE) with deep metric learning acquires
a low-dimensional embedding that better reflects the characteristics of the
disease. The effectiveness of our proposed framework was tested on the
T1-weighted MRIs selected from the Alzheimer&#x27;s Disease Neuroimaging Initiative
and the Parkinson&#x27;s Progression Markers Initiative. We confirmed that our PSS
greatly reduced the variability of low-dimensional embeddings caused by
different scanner and datasets. Compared with the baseline condition, our PSS
reduced the variability in the distance from Alzheimer&#x27;s disease (AD) to
clinically normal (CN) and Parkinson disease (PD) cases by 15.8-22.6% and
18.0-29.9%, respectively. These properties allow DI-PSS to generate lower
dimensional representations that are more amenable to disease classification.
In AD and CN classification experiments based on spectral clustering, PSS
improved the average accuracy and macro-F1 by 6.2% and 10.7%, respectively.
Given the potential of the DI-PSS for harmonizing images scanned by MRI
scanners that were not used to scan the training data, we expect that the
DI-PSS is suitable for application to a large number of legacy MRIs scanned in
heterogeneous environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Study of Training Self-Supervised Vision Transformers. (arXiv:2104.02057v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinlei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Saining Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kaiming He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02057">
                                    <div class="article-summary-box-inner">
                                        <span>This paper does not describe a novel method. Instead, it studies a
straightforward, incremental, yet must-know baseline given the recent progress
in computer vision: self-supervised learning for Vision Transformers (ViT).
While the training recipes for standard convolutional networks have been highly
mature and robust, the recipes for ViT are yet to be built, especially in the
self-supervised scenarios where training becomes more challenging. In this
work, we go back to basics and investigate the effects of several fundamental
components for training self-supervised ViT. We observe that instability is a
major issue that degrades accuracy, and it can be hidden by apparently good
results. We reveal that these results are indeed partial failure, and they can
be improved when training is made more stable. We benchmark ViT results in MoCo
v3 and several other self-supervised frameworks, with ablations in various
aspects. We discuss the currently positive evidence as well as challenges and
open questions. We hope that this work will provide useful data points and
experience for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Change is Everywhere: Single-Temporal Supervised Object Change Detection in Remote Sensing Imagery. (arXiv:2108.07002v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhuo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_A/0/1/0/all/0/1">Ailong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangpei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yanfei Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07002">
                                    <div class="article-summary-box-inner">
                                        <span>For high spatial resolution (HSR) remote sensing images, bitemporal
supervised learning always dominates change detection using many pairwise
labeled bitemporal images. However, it is very expensive and time-consuming to
pairwise label large-scale bitemporal HSR remote sensing images. In this paper,
we propose single-temporal supervised learning (STAR) for change detection from
a new perspective of exploiting object changes in unpaired images as
supervisory signals. STAR enables us to train a high-accuracy change detector
only using \textbf{unpaired} labeled images and generalize to real-world
bitemporal images. To evaluate the effectiveness of STAR, we design a simple
yet effective change detector called ChangeStar, which can reuse any deep
semantic segmentation architecture by the ChangeMixin module. The comprehensive
experimental results show that ChangeStar outperforms the baseline with a large
margin under single-temporal supervision and achieves superior performance
under bitemporal supervision. Code is available at
https://github.com/Z-Zheng/ChangeStar</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FaPN: Feature-aligned Pyramid Network for Dense Image Prediction. (arXiv:2108.07058v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shihua/0/1/0/all/0/1">Shihua</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang/0/1/0/all/0/1">Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhichao/0/1/0/all/0/1">Zhichao</a>, Lu, Ran, <a href="http://arxiv.org/find/cs/1/au:+Cheng/0/1/0/all/0/1">Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng/0/1/0/all/0/1">Cheng</a>, He
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07058">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep neural networks have made remarkable
leap-forwards in dense image prediction. However, the issue of feature
alignment remains as neglected by most existing approaches for simplicity.
Direct pixel addition between upsampled and local features leads to feature
maps with misaligned contexts that, in turn, translate to mis-classifications
in prediction, especially on object boundaries. In this paper, we propose a
feature alignment module that learns transformation offsets of pixels to
contextually align upsampled higher-level features; and another feature
selection module to emphasize the lower-level features with rich spatial
details. We then integrate these two modules in a top-down pyramidal
architecture and present the Feature-aligned Pyramid Network (FaPN). Extensive
experimental evaluations on four dense prediction tasks and four datasets have
demonstrated the efficacy of FaPN, yielding an overall improvement of 1.2 - 2.6
points in AP / mIoU over FPN when paired with Faster / Mask R-CNN. In
particular, our FaPN achieves the state-of-the-art of 56.7% mIoU on ADE20K when
integrated within Mask-Former. The code is available from
https://github.com/EMI-Group/FaPN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1">Mahdi S. Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jia Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1">Andre Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jingxuan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1">Mathieu Tuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1">Konstantinos N. Plataniotis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06822">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Architecture Search (NAS) has shifted network design from using human
intuition to leveraging search algorithms guided by evaluation metrics. We
study channel size optimization in convolutional neural networks (CNN) and
identify the role it plays in model accuracy and complexity. Current channel
size selection methods are generally limited by discrete sample spaces while
suffering from manual iteration and simple heuristics. To solve this, we
introduce an efficient dynamic scaling algorithm -- CONet -- that automatically
optimizes channel sizes across network layers for a given CNN. Two metrics --
&#x60;&#x60;\textit{Rank}&quot; and &quot;\textit{Rank Average Slope}&quot; -- are introduced to
identify the information accumulated in training. The algorithm dynamically
scales channel sizes up or down over a fixed searching phase. We conduct
experiments on CIFAR10/100 and ImageNet datasets and show that CONet can find
efficient and accurate architectures searched in ResNet, DARTS, and DARTS+
spaces that outperform their baseline models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetric Bilateral Motion Estimation for Video Frame Interpolation. (arXiv:2108.06815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junheum Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chul Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Chang-Su Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06815">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel video frame interpolation algorithm based on asymmetric
bilateral motion estimation (ABME), which synthesizes an intermediate frame
between two input frames. First, we predict symmetric bilateral motion fields
to interpolate an anchor frame. Second, we estimate asymmetric bilateral
motions fields from the anchor frame to the input frames. Third, we use the
asymmetric fields to warp the input frames backward and reconstruct the
intermediate frame. Last, to refine the intermediate frame, we develop a new
synthesis network that generates a set of dynamic filters and a residual frame
using local and global information. Experimental results show that the proposed
algorithm achieves excellent performance on various datasets. The source codes
and pretrained models are available at https://github.com/JunHeum/ABME.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Attributions and Interactions of Adversarial Attacks. (arXiv:2108.06895v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuyun Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yufei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanshi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06895">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims to explain adversarial attacks in terms of how adversarial
perturbations contribute to the attacking task. We estimate attributions of
different image regions to the decrease of the attacking cost based on the
Shapley value. We define and quantify interactions among adversarial
perturbation pixels, and decompose the entire perturbation map into relatively
independent perturbation components. The decomposition of the perturbation map
shows that adversarially-trained DNNs have more perturbation components in the
foreground than normally-trained DNNs. Moreover, compared to the
normally-trained DNN, the adversarially-trained DNN have more components which
mainly decrease the score of the true category. Above analyses provide new
insights into the understanding of adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Informative Class Activation Maps. (arXiv:2106.10472v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10472">
                                    <div class="article-summary-box-inner">
                                        <span>We study how to evaluate the quantitative information content of a region
within an image for a particular label. To this end, we bridge class activation
maps with information theory. We develop an informative class activation map
(infoCAM). Given a classification task, infoCAM depict how to accumulate
information of partial regions to that of the entire image toward a label.
Thus, we can utilise infoCAM to locate the most informative features for a
label. When applied to an image classification task, infoCAM performs better
than the traditional classification map in the weakly supervised object
localisation task. We achieve state-of-the-art results on Tiny-ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct Estimation of Appearance Models for Segmentation. (arXiv:2102.11121v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neto_J/0/1/0/all/0/1">Jeova F. S. Rocha Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Felzenszwalb_P/0/1/0/all/0/1">Pedro Felzenszwalb</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_M/0/1/0/all/0/1">Marilyn Vazquez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11121">
                                    <div class="article-summary-box-inner">
                                        <span>Image segmentation algorithms often depend on appearance models that
characterize the distribution of pixel values in different image regions. We
describe a new approach for estimating appearance models directly from an
image, without explicit consideration of the pixels that make up each region.
Our approach is based on novel algebraic expressions that relate local image
statistics to the appearance of spatially coherent regions. We describe two
algorithms that can use the aforementioned algebraic expressions to estimate
appearance models directly from an image. The first algorithm solves a system
of linear and quadratic equations using a least squares formulation. The second
algorithm is a spectral method based on an eigenvector computation. We present
experimental results that demonstrate the proposed methods work well in
practice and lead to effective image segmentation algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HAA500: Human-Centric Atomic Action Dataset with Curated Videos. (arXiv:2009.05224v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jihoon Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Wuu_C/0/1/0/all/0/1">Cheng-hsin Wuu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hsuan-ru Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Yu-Wing Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chi-Keung Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05224">
                                    <div class="article-summary-box-inner">
                                        <span>We contribute HAA500, a manually annotated human-centric atomic action
dataset for action recognition on 500 classes with over 591K labeled frames. To
minimize ambiguities in action classification, HAA500 consists of highly
diversified classes of fine-grained atomic actions, where only consistent
actions fall under the same label, e.g., &quot;Baseball Pitching&quot; vs &quot;Free Throw in
Basketball&quot;. Thus HAA500 is different from existing atomic action datasets,
where coarse-grained atomic actions were labeled with coarse action-verbs such
as &quot;Throw&quot;. HAA500 has been carefully curated to capture the precise movement
of human figures with little class-irrelevant motions or spatio-temporal label
noises. The advantages of HAA500 are fourfold: 1) human-centric actions with a
high average of 69.7% detectable joints for the relevant human poses; 2) high
scalability since adding a new class can be done under 20-60 minutes; 3)
curated videos capturing essential elements of an atomic action without
irrelevant frames; 4) fine-grained atomic action classes. Our extensive
experiments including cross-data validation using datasets collected in the
wild demonstrate the clear benefits of human-centric and atomic characteristics
of HAA500, which enable training even a baseline deep learning model to improve
prediction by attending to atomic human poses. We detail the HAA500 dataset
statistics and collection methodology and compare quantitatively with existing
action recognition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantics Disentangling for Generalized Zero-Shot Learning. (arXiv:2101.07978v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yadan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07978">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized zero-shot learning (GZSL) aims to classify samples under the
assumption that some classes are not observable during training. To bridge the
gap between the seen and unseen classes, most GZSL methods attempt to associate
the visual features of seen classes with attributes or to generate unseen
samples directly. Nevertheless, the visual features used in the prior
approaches do not necessarily encode semantically related information that the
shared attributes refer to, which degrades the model generalization to unseen
classes. To address this issue, in this paper, we propose a novel semantics
disentangling framework for the generalized zero-shot learning task (SDGZSL),
where the visual features of unseen classes are firstly estimated by a
conditional VAE and then factorized into semantic-consistent and
semantic-unrelated latent vectors. In particular, a total correlation penalty
is applied to guarantee the independence between the two factorized
representations, and the semantic consistency of which is measured by the
derived relation network. Extensive experiments conducted on four GZSL
benchmark datasets have evidenced that the semantic-consistent features
disentangled by the proposed SDGZSL are more generalizable in tasks of
canonical and generalized zero-shot learning. Our source code is available at
https://github.com/uqzhichen/SDGZSL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Face Encryption by Generating Adversarial Identity Masks. (arXiv:2003.06814v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuefeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hui Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06814">
                                    <div class="article-summary-box-inner">
                                        <span>As billions of personal data being shared through social media and network,
the data privacy and security have drawn an increasing attention. Several
attempts have been made to alleviate the leakage of identity information from
face photos, with the aid of, e.g., image obfuscation techniques. However, most
of the present results are either perceptually unsatisfactory or ineffective
against face recognition systems. Our goal in this paper is to develop a
technique that can encrypt the personal photos such that they can protect users
from unauthorized face recognition systems but remain visually identical to the
original version for human beings. To achieve this, we propose a targeted
identity-protection iterative method (TIP-IM) to generate adversarial identity
masks which can be overlaid on facial images, such that the original identities
can be concealed without sacrificing the visual quality. Extensive experiments
demonstrate that TIP-IM provides 95\%+ protection success rate against various
state-of-the-art face recognition models under practical test scenarios.
Besides, we also show the practical and effective applicability of our method
on a commercial API service.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACNet: Mask-Aware Attention with Dynamic Context Enhancement for Robust Acne Detection. (arXiv:2105.14891v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Min_K/0/1/0/all/0/1">Kyungseo Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gun-Hee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14891">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided diagnosis has recently received attention for its advantage of
low cost and time efficiency. Although deep learning played a major role in the
recent success of acne detection, there are still several challenges such as
color shift by inconsistent illumination, variation in scales, and high density
distribution. To address these problems, we propose an acne detection network
which consists of three components, specifically: Composite Feature Refinement,
Dynamic Context Enhancement, and Mask-Aware Multi-Attention. First, Composite
Feature Refinement integrates semantic information and fine details to enrich
feature representation, which mitigates the adverse impact of imbalanced
illumination. Then, Dynamic Context Enhancement controls different receptive
fields of multi-scale features for context enhancement to handle scale
variation. Finally, Mask-Aware Multi-Attention detects densely arranged and
small acne by suppressing uninformative regions and highlighting probable acne
regions. Experiments are performed on acne image dataset ACNE04 and natural
image dataset PASCAL VOC 2007. We demonstrate how our method achieves the
state-of-the-art result on ACNE04 and competitive performance with previous
state-of-the-art methods on the PASCAL VOC 2007.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I3CL:Intra- and Inter-Instance Collaborative Learning for Arbitrary-shaped Scene Text Detection. (arXiv:2108.01343v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jian Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Juhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01343">
                                    <div class="article-summary-box-inner">
                                        <span>Existing methods for arbitrary-shaped text detection in natural scenes face
two critical issues, i.e., 1) fracture detections at the gaps in a text
instance; and 2) inaccurate detections of arbitrary-shaped text instances with
diverse background context. To address these issues, we propose a novel method
named Intra- and Inter-Instance Collaborative Learning (I3CL). Specifically, to
address the first issue, we design an effective convolutional module with
multiple receptive fields, which is able to collaboratively learn better
character and gap feature representations at local and long ranges inside a
text instance. To address the second issue, we devise an instance-based
transformer module to exploit the dependencies between different text instances
and a global context module to exploit the semantic context from the shared
background, which are able to collaboratively learn more discriminative text
feature representation. In this way, I3CL can effectively exploit the intra-
and inter-instance dependencies together in a unified end-to-end trainable
framework. Besides, to make full use of the unlabeled data, we design an
effective semi-supervised learning method to leverage the pseudo labels via an
ensemble strategy. Without bells and whistles, experimental results show that
the proposed I3CL sets new state-of-the-art results on three challenging public
benchmarks, i.e., an F-measure of 77.5% on ICDAR2019-ArT, 86.9% on Total-Text,
and 86.4% on CTW-1500. Notably, our I3CL with the ResNeSt-101 backbone ranked
1st place on the ICDAR2019-ArT leaderboard. The source code will be made
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Canonical Saliency Maps: Decoding Deep Face Models. (arXiv:2105.01386v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+John_T/0/1/0/all/0/1">Thrupthi Ann John</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1">C V Jawahar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01386">
                                    <div class="article-summary-box-inner">
                                        <span>As Deep Neural Network models for face processing tasks approach human-like
performance, their deployment in critical applications such as law enforcement
and access control has seen an upswing, where any failure may have far-reaching
consequences. We need methods to build trust in deployed systems by making
their working as transparent as possible. Existing visualization algorithms are
designed for object recognition and do not give insightful results when applied
to the face domain. In this work, we present &#x27;Canonical Saliency Maps&#x27;, a new
method that highlights relevant facial areas by projecting saliency maps onto a
canonical face model. We present two kinds of Canonical Saliency Maps:
image-level maps and model-level maps. Image-level maps highlight facial
features responsible for the decision made by a deep face model on a given
image, thus helping to understand how a DNN made a prediction on the image.
Model-level maps provide an understanding of what the entire DNN model focuses
on in each task and thus can be used to detect biases in the model. Our
qualitative and quantitative results show the usefulness of the proposed
canonical saliency maps, which can be used on any deep face model regardless of
the architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">10-mega pixel snapshot compressive imaging with a hybrid coded aperture. (arXiv:2106.15765v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihong Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_C/0/1/0/all/0/1">Chao Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_X/0/1/0/all/0/1">Xin Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Suo_J/0/1/0/all/0/1">Jinli Suo</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_Q/0/1/0/all/0/1">Qionghai Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15765">
                                    <div class="article-summary-box-inner">
                                        <span>High resolution images are widely used in our daily life, whereas high-speed
video capture is challenging due to the low frame rate of cameras working at
the high resolution mode. Digging deeper, the main bottleneck lies in the low
throughput of existing imaging systems. Towards this end, snapshot compressive
imaging (SCI) was proposed as a promising solution to improve the throughput of
imaging systems by compressive sampling and computational reconstruction.
During acquisition, multiple high-speed images are encoded and collapsed to a
single measurement. After this, algorithms are employed to retrieve the video
frames from the coded snapshot. Recently developed Plug-and-Play (PnP)
algorithms make it possible for SCI reconstruction in large-scale problems.
However, the lack of high-resolution encoding systems still precludes SCI&#x27;s
wide application. In this paper, we build a novel hybrid coded aperture
snapshot compressive imaging (HCA-SCI) system by incorporating a dynamic liquid
crystal on silicon and a high-resolution lithography mask. We further implement
a PnP reconstruction algorithm with cascaded denoisers for high quality
reconstruction. Based on the proposed HCA-SCI system and algorithm, we achieve
a 10-mega pixel SCI system to capture high-speed scenes, leading to a high
throughput of 4.6G voxels per second. Both simulation and real data experiments
verify the feasibility and performance of our proposed HCA-SCI scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrated Generalized Zero-Shot Learning for Fine-Grained Classification. (arXiv:2101.02141v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shermin_T/0/1/0/all/0/1">Tasfia Shermin</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1">Shyh Wei Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohel_F/0/1/0/all/0/1">Ferdous Sohel</a>, <a href="http://arxiv.org/find/cs/1/au:+Murshed_M/0/1/0/all/0/1">Manzur Murshed</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guojun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02141">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding learning (EL) and feature synthesizing (FS) are two of the popular
categories of fine-grained GZSL methods. EL or FS using global features cannot
discriminate fine details in the absence of local features. On the other hand,
EL or FS methods exploiting local features either neglect direct attribute
guidance or global information. Consequently, neither method performs well. In
this paper, we propose to explore global and direct attribute-supervised local
visual features for both EL and FS categories in an integrated manner for
fine-grained GZSL. The proposed integrated network has an EL sub-network and a
FS sub-network. Consequently, the proposed integrated network can be tested in
two ways. We propose a novel two-step dense attention mechanism to discover
attribute-guided local visual features. We introduce new mutual learning
between the sub-networks to exploit mutually beneficial information for
optimization. Moreover, we propose to compute source-target class similarity
based on mutual information and transfer-learn the target classes to reduce
bias towards the source domain during testing. We demonstrate that our proposed
method outperforms contemporary methods on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deeper or Wider Networks of Point Clouds with Self-attention?. (arXiv:2011.14285v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ran_H/0/1/0/all/0/1">Haoxi Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Li Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14285">
                                    <div class="article-summary-box-inner">
                                        <span>Prevalence of deeper networks driven by self-attention is in stark contrast
to underexplored point-based methods. In this paper, we propose groupwise
self-attention as the basic block to construct our network: SepNet. Our
proposed module can effectively capture both local and global dependencies.
This module computes the features of a group based on the summation of the
weighted features of any point within the group. For convenience, we generalize
groupwise operations to assemble this module. To further facilitate our
networks, we deepen and widen SepNet on the tasks of segmentation and
classification respectively, and verify its practicality. Specifically, SepNet
achieves state-of-the-art for the tasks of classification and segmentation on
most of the datasets. We show empirical evidence that SepNet can obtain extra
accuracy in classification or segmentation from increased width or depth,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D High-Fidelity Mask Face Presentation Attack Detection Challenge. (arXiv:2108.06968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Ajian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chenxu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zitong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1">Anyang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1">Zijian Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1">Jun Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1">Sergio Escalera</a>, <a href="http://arxiv.org/find/cs/1/au:+Escalante_H/0/1/0/all/0/1">Hugo Jair Escalante</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhen Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1">Guodong Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06968">
                                    <div class="article-summary-box-inner">
                                        <span>The threat of 3D masks to face recognition systems is increasingly serious
and has been widely concerned by researchers. To facilitate the study of the
algorithms, a large-scale High-Fidelity Mask dataset, namely CASIA-SURF
HiFiMask (briefly HiFiMask) has been collected. Specifically, it consists of a
total amount of 54, 600 videos which are recorded from 75 subjects with 225
realistic masks under 7 new kinds of sensors. Based on this dataset and
Protocol 3 which evaluates both the discrimination and generalization ability
of the algorithm under the open set scenarios, we organized a 3D High-Fidelity
Mask Face Presentation Attack Detection Challenge to boost the research of 3D
mask-based attack detection. It attracted 195 teams for the development phase
with a total of 18 teams qualifying for the final round. All the results were
verified and re-run by the organizing team, and the results were used for the
final ranking. This paper presents an overview of the challenge, including the
introduction of the dataset used, the definition of the protocol, the
calculation of the evaluation criteria, and the summary and publication of the
competition results. Finally, we focus on introducing and analyzing the top
ranking algorithms, the conclusion summary, and the research ideas for mask
attack detection provided by this competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpolation-Aware Padding for 3D Sparse Convolutional Neural Networks. (arXiv:2108.06925v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yu-Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng-Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06925">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse voxel-based 3D convolutional neural networks (CNNs) are widely used
for various 3D vision tasks. Sparse voxel-based 3D CNNs create sparse non-empty
voxels from the 3D input and perform 3D convolution operations on them only. We
propose a simple yet effective padding scheme --- interpolation-aware padding
to pad a few empty voxels adjacent to the non-empty voxels and involve them in
the 3D CNN computation so that all neighboring voxels exist when computing
point-wise features via the trilinear interpolation. For fine-grained 3D vision
tasks where point-wise features are essential, like semantic segmentation and
3D detection, our network achieves higher prediction accuracy than the existing
networks using the nearest neighbor interpolation or the normalized trilinear
interpolation with the zero-padding or the octree-padding scheme. Through
extensive comparisons on various 3D segmentation and detection tasks, we
demonstrate the superiority of 3D sparse CNNs with our padding scheme in
conjunction with feature interpolation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation. (arXiv:2003.06555v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaogang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hengshuang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06555">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is promising for improving robustness of deep neural
networks towards adversarial perturbations, especially on the classification
task. The effect of this type of training on semantic segmentation, contrarily,
just commences. We make the initial attempt to explore the defense strategy on
semantic segmentation by formulating a general adversarial training procedure
that can perform decently on both adversarial and clean samples. We propose a
dynamic divide-and-conquer adversarial training (DDC-AT) strategy to enhance
the defense effect, by setting additional branches in the target model during
training, and dealing with pixels with diverse properties towards adversarial
perturbation. Our dynamical division mechanism divides pixels into multiple
branches automatically. Note all these additional branches can be abandoned
during inference and thus leave no extra parameter and computation cost.
Extensive experiments with various segmentation models are conducted on PASCAL
VOC 2012 and Cityscapes datasets, in which DDC-AT yields satisfying performance
under both white- and black-box attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probeable DARTS with Application to Computational Pathology. (arXiv:2108.06859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Sheyang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1">Mahdi S. Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lina Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_S/0/1/0/all/0/1">Sonal Varma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rowsell_C/0/1/0/all/0/1">Corwyn Rowsell</a>, <a href="http://arxiv.org/find/cs/1/au:+Damaskinos_S/0/1/0/all/0/1">Savvas Damaskinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1">Konstantinos N. Plataniotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhou Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06859">
                                    <div class="article-summary-box-inner">
                                        <span>AI technology has made remarkable achievements in computational pathology
(CPath), especially with the help of deep neural networks. However, the network
performance is highly related to architecture design, which commonly requires
human experts with domain knowledge. In this paper, we combat this challenge
with the recent advance in neural architecture search (NAS) to find an optimal
network for CPath applications. In particular, we use differentiable
architecture search (DARTS) for its efficiency. We first adopt a probing metric
to show that the original DARTS lacks proper hyperparameter tuning on the CIFAR
dataset, and how the generalization issue can be addressed using an adaptive
optimization strategy. We then apply our searching framework on CPath
applications by searching for the optimum network architecture on a
histological tissue type dataset (ADP). Results show that the searched network
outperforms state-of-the-art networks in terms of prediction accuracy and
computation complexity. We further conduct extensive experiments to demonstrate
the transferability of the searched network to new CPath applications, the
robustness against downscaled inputs, as well as the reliability of
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intra-clip Aggregation for Video Person Re-identification. (arXiv:1905.01722v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isobe_T/0/1/0/all/0/1">Takashi Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jian Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yali Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.01722">
                                    <div class="article-summary-box-inner">
                                        <span>Video-based person re-identification has drawn massive attention in recent
years due to its extensive applications in video surveillance. While deep
learning-based methods have led to significant progress, these methods are
limited by ineffectively using complementary information, which is blamed on
necessary data augmentation in the training process. Data augmentation has been
widely used to mitigate the over-fitting trap and improve the ability of
network representation. However, the previous methods adopt image-based data
augmentation scheme to individually process the input frames, which corrupts
the complementary information between consecutive frames and causes performance
degradation. Extensive experiments on three benchmark datasets demonstrate that
our framework outperforms the most recent state-of-the-art methods. We also
perform cross-dataset validation to prove the generality of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers. (arXiv:2108.06932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1">Bo Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06932">
                                    <div class="article-summary-box-inner">
                                        <span>Most polyp segmentation methods use CNNs as their backbone, leading to two
key issues when exchanging information between the encoder and decoder: 1)
taking into account the differences in contribution between different-level
features; and 2) designing effective mechanism for fusing these features.
Different from existing CNN-based methods, we adopt a transformer encoder,
which learns more powerful and robust representations. In addition, considering
the image acquisition influence and elusive properties of polyps, we introduce
three novel modules, including a cascaded fusion module (CFM), a camouflage
identification module (CIM), a and similarity aggregation module (SAM). Among
these, the CFM is used to collect the semantic and location information of
polyps from high-level features, while the CIM is applied to capture polyp
information disguised in low-level features. With the help of the SAM, we
extend the pixel features of the polyp area with high-level semantic position
information to the entire polyp area, thereby effectively fusing cross-level
features. The proposed model, named \ourmodel, effectively suppresses noises in
the features and significantly improves their expressive capabilities.
Extensive experiments on five widely adopted datasets show that the proposed
model is more robust to various challenging situations (e.g., appearance
changes, small objects) than existing methods, and achieves the new
state-of-the-art performance. The proposed model is available at
https://github.com/DengPingFan/Polyp-PVT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distance-aware Quantization. (arXiv:2108.06983v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+kim_D/0/1/0/all/0/1">Dohyung kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junghyup Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ham_B/0/1/0/all/0/1">Bumsub Ham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06983">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of network quantization, that is, reducing bit-widths
of weights and/or activations to lighten network architectures. Quantization
methods use a rounding function to map full-precision values to the nearest
quantized ones, but this operation is not differentiable. There are mainly two
approaches to training quantized networks with gradient-based optimizers.
First, a straight-through estimator (STE) replaces the zero derivative of the
rounding with that of an identity function, which causes a gradient mismatch
problem. Second, soft quantizers approximate the rounding with continuous
functions at training time, and exploit the rounding for quantization at test
time. This alleviates the gradient mismatch, but causes a quantizer gap
problem. We alleviate both problems in a unified framework. To this end, we
introduce a novel quantizer, dubbed a distance-aware quantizer (DAQ), that
mainly consists of a distance-aware soft rounding (DASR) and a temperature
controller. To alleviate the gradient mismatch problem, DASR approximates the
discrete rounding with the kernel soft argmax, which is based on our insight
that the quantization can be formulated as a distance-based assignment problem
between full-precision values and quantized ones. The controller adjusts the
temperature parameter in DASR adaptively according to the input, addressing the
quantizer gap problem. Experimental results on standard benchmarks show that
DAQ outperforms the state of the art significantly for various bit-widths
without bells and whistles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CarveMix: A Simple Data Augmentation Method for Brain Lesion Segmentation. (arXiv:2108.06883v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chenghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_N/0/1/0/all/0/1">Ni Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiangzhu Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1">Xiaoliang Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yizhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1">Chuyang Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06883">
                                    <div class="article-summary-box-inner">
                                        <span>Brain lesion segmentation provides a valuable tool for clinical diagnosis,
and convolutional neural networks (CNNs) have achieved unprecedented success in
the task. Data augmentation is a widely used strategy that improves the
training of CNNs, and the design of the augmentation method for brain lesion
segmentation is still an open problem. In this work, we propose a simple data
augmentation approach, dubbed as CarveMix, for CNN-based brain lesion
segmentation. Like other &quot;mix&quot;-based methods, such as Mixup and CutMix,
CarveMix stochastically combines two existing labeled images to generate new
labeled samples. Yet, unlike these augmentation strategies based on image
combination, CarveMix is lesion-aware, where the combination is performed with
an attention on the lesions and a proper annotation is created for the
generated image. Specifically, from one labeled image we carve a region of
interest (ROI) according to the lesion location and geometry, and the size of
the ROI is sampled from a probability distribution. The carved ROI then
replaces the corresponding voxels in a second labeled image, and the annotation
of the second image is replaced accordingly as well. In this way, we generate
new labeled images for network training and the lesion information is
preserved. To evaluate the proposed method, experiments were performed on two
brain lesion datasets. The results show that our method improves the
segmentation accuracy compared with other simple data augmentation approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vector-Decomposed Disentanglement for Domain-Invariant Object Detection. (arXiv:2108.06685v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Aming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yahong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Linchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06685">
                                    <div class="article-summary-box-inner">
                                        <span>To improve the generalization of detectors, for domain adaptive object
detection (DAOD), recent advances mainly explore aligning feature-level
distributions between the source and single-target domain, which may neglect
the impact of domain-specific information existing in the aligned features.
Towards DAOD, it is important to extract domain-invariant object
representations. To this end, in this paper, we try to disentangle
domain-invariant representations from domain-specific representations. And we
propose a novel disentangled method based on vector decomposition. Firstly, an
extractor is devised to separate domain-invariant representations from the
input, which are used for extracting object proposals. Secondly,
domain-specific representations are introduced as the differences between the
input and domain-invariant representations. Through the difference operation,
the gap between the domain-specific and domain-invariant representations is
enlarged, which promotes domain-invariant representations to contain more
domain-irrelevant information. In the experiment, we separately evaluate our
method on the single- and compound-target case. For the single-target case,
experimental results of four domain-shift scenes show our method obtains a
significant performance gain over baseline methods. Moreover, for the
compound-target case (i.e., the target is a compound of two different domains
without domain labels), our method outperforms baseline methods by around 4%,
which demonstrates the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unravelling the Effect of Image Distortions for Biased Prediction of Pre-trained Face Recognition Models. (arXiv:2108.06581v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Majumdar_P/0/1/0/all/0/1">Puspita Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1">Surbhi Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Richa Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatsa_M/0/1/0/all/0/1">Mayank Vatsa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06581">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying and mitigating bias in deep learning algorithms has gained
significant popularity in the past few years due to its impact on the society.
Researchers argue that models trained on balanced datasets with good
representation provide equal and unbiased performance across subgroups.
However, \textit{can seemingly unbiased pre-trained model become biased when
input data undergoes certain distortions?} For the first time, we attempt to
answer this question in the context of face recognition. We provide a
systematic analysis to evaluate the performance of four state-of-the-art deep
face recognition models in the presence of image distortions across different
\textit{gender} and \textit{race} subgroups. We have observed that image
distortions have a relationship with the performance gap of the model across
different subgroups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finding Representative Interpretations on Convolutional Neural Networks. (arXiv:2108.06384v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lam_P/0/1/0/all/0/1">Peter Cho-Ho Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_L/0/1/0/all/0/1">Lingyang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Torgonskiy_M/0/1/0/all/0/1">Maxim Torgonskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lanjun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06384">
                                    <div class="article-summary-box-inner">
                                        <span>Interpreting the decision logic behind effective deep convolutional neural
networks (CNN) on images complements the success of deep learning models.
However, the existing methods can only interpret some specific decision logic
on individual or a small number of images. To facilitate human
understandability and generalization ability, it is important to develop
representative interpretations that interpret common decision logics of a CNN
on a large group of similar images, which reveal the common semantics data
contributes to many closely related predictions. In this paper, we develop a
novel unsupervised approach to produce a highly representative interpretation
for a large number of similar images. We formulate the problem of finding
representative interpretations as a co-clustering problem, and convert it into
a submodular cost submodular cover problem based on a sample of the linear
decision boundaries of a CNN. We also present a visualization and similarity
ranking method. Our extensive experiments demonstrate the excellent performance
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Marine Debris Dataset for Forward-Looking Sonar Semantic Segmentation. (arXiv:2108.06800v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1">Deepak Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Valdenegro_Toro_M/0/1/0/all/0/1">Matias Valdenegro-Toro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06800">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate detection and segmentation of marine debris is important for keeping
the water bodies clean. This paper presents a novel dataset for marine debris
segmentation collected using a Forward Looking Sonar (FLS). The dataset
consists of 1868 FLS images captured using ARIS Explorer 3000 sensor. The
objects used to produce this dataset contain typical house-hold marine debris
and distractor marine objects (tires, hooks, valves,etc), divided in 11 classes
plus a background class. Performance of state of the art semantic segmentation
architectures with a variety of encoders have been analyzed on this dataset and
presented as baseline results. Since the images are grayscale, no pretrained
weights have been used. Comparisons are made using Intersection over Union
(IoU). The best performing model is Unet with ResNet34 backbone at 0.7481 mIoU.
The dataset is available at
https://github.com/mvaldenegro/marine-debris-fls-datasets/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EventHPE: Event-based 3D Human Pose and Shape Estimation. (arXiv:2108.06819v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1">Shihao Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xinxin Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaoqin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shoushun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Minglun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Li Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06819">
                                    <div class="article-summary-box-inner">
                                        <span>Event camera is an emerging imaging sensor for capturing dynamics of moving
objects as events, which motivates our work in estimating 3D human pose and
shape from the event signals. Events, on the other hand, have their unique
challenges: rather than capturing static body postures, the event signals are
best at capturing local motions. This leads us to propose a two-stage deep
learning approach, called EventHPE. The first-stage, FlowNet, is trained by
unsupervised learning to infer optical flow from events. Both events and
optical flow are closely related to human body dynamics, which are fed as input
to the ShapeNet in the second stage, to estimate 3D human shapes. To mitigate
the discrepancy between image-based flow (optical flow) and shape-based flow
(vertices movement of human body shape), a novel flow coherence loss is
introduced by exploiting the fact that both flows are originated from the
identical human motion. An in-house event-based 3D human dataset is curated
that comes with 3D pose and shape annotations, which is by far the largest one
to our knowledge. Empirical evaluations on DHP19 dataset and our in-house
dataset demonstrate the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focus on the Positives: Self-Supervised Learning for Biodiversity Monitoring. (arXiv:2108.06435v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pantazis_O/0/1/0/all/0/1">Omiros Pantazis</a>, <a href="http://arxiv.org/find/cs/1/au:+Brostow_G/0/1/0/all/0/1">Gabriel Brostow</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_K/0/1/0/all/0/1">Kate Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1">Oisin Mac Aodha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06435">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of learning self-supervised representations from
unlabeled image collections. Unlike existing approaches that attempt to learn
useful features by maximizing similarity between augmented versions of each
input image or by speculatively picking negative samples, we instead also make
use of the natural variation that occurs in image collections that are captured
using static monitoring cameras. To achieve this, we exploit readily available
context data that encodes information such as the spatial and temporal
relationships between the input images. We are able to learn representations
that are surprisingly effective for downstream supervised classification, by
first identifying high probability positive pairs at training time, i.e. those
images that are likely to depict the same visual concept. For the critical task
of global biodiversity monitoring, this results in image features that can be
adapted to challenging visual species classification tasks with limited human
supervision. We present results on four different camera trap image
collections, across three different families of self-supervised learning
methods, and show that careful image selection at training time results in
superior performance compared to existing baselines such as conventional
self-supervised training and transfer learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Target Adversarial Frameworks for Domain Adaptation in Semantic Segmentation. (arXiv:2108.06962v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Antoine Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Tuan-Hung Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1">Patrick P&#xe9;rez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06962">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the task of unsupervised domain adaptation (UDA) for
semantic segmentation in presence of multiple target domains: The objective is
to train a single model that can handle all these domains at test time. Such a
multi-target adaptation is crucial for a variety of scenarios that real-world
autonomous systems must handle. It is a challenging setup since one faces not
only the domain gap between the labeled source set and the unlabeled target
set, but also the distribution shifts existing within the latter among the
different target domains. To this end, we introduce two adversarial frameworks:
(i) multi-discriminator, which explicitly aligns each target domain to its
counterparts, and (ii) multi-target knowledge transfer, which learns a
target-agnostic model thanks to a multi-teacher/single-student distillation
mechanism.The evaluation is done on four newly-proposed multi-target benchmarks
for UDA in semantic segmentation. In all tested scenarios, our approaches
consistently outperform baselines, setting competitive standards for the novel
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSH: A Self-Supervised Framework for Image Harmonization. (arXiv:2108.06805v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yifan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">He Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunkavalli_K/0/1/0/all/0/1">Kalyan Sunkavalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Simon Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirghodsi_S/0/1/0/all/0/1">Sohrab Amirghodsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1">Sarah Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06805">
                                    <div class="article-summary-box-inner">
                                        <span>Image harmonization aims to improve the quality of image compositing by
matching the &quot;appearance&quot; (\eg, color tone, brightness and contrast) between
foreground and background images. However, collecting large-scale annotated
datasets for this task requires complex professional retouching. Instead, we
propose a novel Self-Supervised Harmonization framework (SSH) that can be
trained using just &quot;free&quot; natural images without being edited. We reformulate
the image harmonization problem from a representation fusion perspective, which
separately processes the foreground and background examples, to address the
background occlusion issue. This framework design allows for a dual data
augmentation method, where diverse [foreground, background, pseudo GT] triplets
can be generated by cropping an image with perturbations using 3D color lookup
tables (LUTs). In addition, we build a real-world harmonization dataset as
carefully created by expert users, for evaluation and benchmarking purposes.
Our results show that the proposed self-supervised method outperforms previous
state-of-the-art methods in terms of reference metrics, visual quality, and
subject user study. Code and dataset are available at
\url{https://github.com/VITA-Group/SSHarmonization}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROSITA: Enhancing Vision-and-Language Semantic Alignments via Cross- and Intra-modal Knowledge Integration. (arXiv:2108.07073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yuhao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chunqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhongzhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07073">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-and-language pretraining (VLP) aims to learn generic multimodal
representations from massive image-text pairs. While various successful
attempts have been proposed, learning fine-grained semantic alignments between
image-text pairs plays a key role in their approaches. Nevertheless, most
existing VLP approaches have not fully utilized the intrinsic knowledge within
the image-text pairs, which limits the effectiveness of the learned alignments
and further restricts the performance of their models. To this end, we
introduce a new VLP method called ROSITA, which integrates the cross- and
intra-modal knowledge in a unified scene graph to enhance the semantic
alignments. Specifically, we introduce a novel structural knowledge masking
(SKM) strategy to use the scene graph structure as a priori to perform masked
language (region) modeling, which enhances the semantic alignments by
eliminating the interference information within and across modalities.
Extensive ablation studies and comprehensive analysis verifies the
effectiveness of ROSITA in semantic alignments. Pretrained with both in-domain
and out-of-domain datasets, ROSITA significantly outperforms existing
state-of-the-art VLP methods on three typical vision-and-language tasks over
six benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction. (arXiv:2108.06852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yongwei Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Chengjiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guiqing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06852">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose $\text{HF}^2$-VAD, a Hybrid framework that
integrates Flow reconstruction and Frame prediction seamlessly to handle Video
Anomaly Detection. Firstly, we design the network of ML-MemAE-SC (Multi-Level
Memory modules in an Autoencoder with Skip Connections) to memorize normal
patterns for optical flow reconstruction so that abnormal events can be
sensitively identified with larger flow reconstruction errors. More
importantly, conditioned on the reconstructed flows, we then employ a
Conditional Variational Autoencoder (CVAE), which captures the high correlation
between video frame and optical flow, to predict the next frame given several
previous frames. By CVAE, the quality of flow reconstruction essentially
influences that of frame prediction. Therefore, poorly reconstructed optical
flows of abnormal events further deteriorate the quality of the final predicted
future frame, making the anomalies more detectable. Experimental results
demonstrate the effectiveness of the proposed method. Code is available at
\href{https://github.com/LiUzHiAn/hf2vad}{https://github.com/LiUzHiAn/hf2vad}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-dimensional Assisted Generative Model for Color Image Restoration. (arXiv:2108.06460v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hong_K/0/1/0/all/0/1">Kai Hong</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1">Chunhua Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1">Cailian Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_M/0/1/0/all/0/1">Minghui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1">Yancheng Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuhao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1">Qiegen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06460">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents an unsupervised deep learning scheme that exploiting
high-dimensional assisted score-based generative model for color image
restoration tasks. Considering that the sample number and internal dimension in
score-based generative model have key influence on estimating the gradients of
data distribution, two different high-dimensional ways are proposed: The
channel-copy transformation increases the sample number and the pixel-scale
transformation decreases feasible space dimension. Subsequently, a set of
high-dimensional tensors represented by these transformations are used to train
the network through denoising score matching. Then, sampling is performed by
annealing Langevin dynamics and alternative data-consistency update.
Furthermore, to alleviate the difficulty of learning high-dimensional
representation, a progressive strategy is proposed to leverage the performance.
The proposed unsupervised learning and iterative restoration algo-rithm, which
involves a pre-trained generative network to obtain prior, has transparent and
clear interpretation compared to other data-driven approaches. Experimental
results on demosaicking and inpainting conveyed the remarkable performance and
diversity of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nowcasting-Nets: Deep Neural Network Structures for Precipitation Nowcasting Using IMERG. (arXiv:2108.06868v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ehsani_M/0/1/0/all/0/1">Mohammad Reza Ehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarei_A/0/1/0/all/0/1">Ariyan Zarei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Hoshin V. Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnard_K/0/1/0/all/0/1">Kobus Barnard</a>, <a href="http://arxiv.org/find/cs/1/au:+Behrangi_A/0/1/0/all/0/1">Ali Behrangi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06868">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate and timely estimation of precipitation is critical for issuing
hazard warnings (e.g., for flash floods or landslides). Current remotely sensed
precipitation products have a few hours of latency, associated with the
acquisition and processing of satellite data. By applying a robust nowcasting
system to these products, it is (in principle) possible to reduce this latency
and improve their applicability, value, and impact. However, the development of
such a system is complicated by the chaotic nature of the atmosphere, and the
consequent rapid changes that can occur in the structures of precipitation
systems In this work, we develop two approaches (hereafter referred to as
Nowcasting-Nets) that use Recurrent and Convolutional deep neural network
structures to address the challenge of precipitation nowcasting. A total of
five models are trained using Global Precipitation Measurement (GPM) Integrated
Multi-satellitE Retrievals for GPM (IMERG) precipitation data over the Eastern
Contiguous United States (CONUS) and then tested against independent data for
the Eastern and Western CONUS. The models were designed to provide forecasts
with a lead time of up to 1.5 hours and, by using a feedback loop approach, the
ability of the models to extend the forecast time to 4.5 hours was also
investigated. Model performance was compared against the Random Forest (RF) and
Linear Regression (LR) machine learning methods, and also against a persistence
benchmark (BM) that used the most recent observation as the forecast.
Independent IMERG observations were used as a reference, and experiments were
conducted to examine both overall statistics and case studies involving
specific precipitation events. Overall, the forecasts provided by the
Nowcasting-Net models are superior, with the Convolutional Nowcasting Network
with Residual Head (CNC-R) achieving 25%, 28%, and 46% improvement in the test
...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Action Segmentation with High-level Complex Activity Labels. (arXiv:2108.06706v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guodong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Angela Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06706">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past few years, the success in action recognition on short trimmed
videos has led more investigations towards the temporal segmentation of actions
in untrimmed long videos. Recently, supervised approaches have achieved
excellent performance in segmenting complex human actions in untrimmed videos.
However, besides action labels, such approaches also require the start and end
points of each action, which is expensive and tedious to collect.

In this paper, we aim to learn the action segments taking only the high-level
activity labels as input. Under the setting where no action-level supervision
is provided, Hungarian matching is often used to find the mapping between
segments and ground truth actions to evaluate the model and report the
performance. On the one hand, we show that with the high-level supervision, we
are able to generalize the Hungarian matching settings from the current video
and activity level to the global level. The extended global-level matching
allows for the shared actions across activities. On the other hand, we propose
a novel action discovery framework that automatically discovers constituent
actions in videos with the activity classification task. Specifically, we
define a finite number of prototypes to form a dual representation of a video
sequence. These collectively learned prototypes are considered discovered
actions. This classification setting endows our approach the capability of
discovering potentially shared actions across multiple complex activities.
Extensive experiments demonstrate that the discovered actions are helpful in
performing temporal action segmentation and activity recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Multi-Granularity Distillation for GAN Compression. (arXiv:2108.06908v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yuxi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xuefeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianchao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06908">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have witnessed prevailing success in
yielding outstanding images, however, they are burdensome to deploy on
resource-constrained devices due to ponderous computational costs and hulking
memory usage. Although recent efforts on compressing GANs have acquired
remarkable results, they still exist potential model redundancies and can be
further compressed. To solve this issue, we propose a novel online
multi-granularity distillation (OMGD) scheme to obtain lightweight GANs, which
contributes to generating high-fidelity images with low computational demands.
We offer the first attempt to popularize single-stage online distillation for
GAN-oriented compression, where the progressively promoted teacher generator
helps to refine the discriminator-free based student generator. Complementary
teacher generators and network layers provide comprehensive and
multi-granularity concepts to enhance visual fidelity from diverse dimensions.
Experimental results on four benchmark datasets demonstrate that OMGD successes
to compress 40x MACs and 82.5X parameters on Pix2Pix and CycleGAN, without loss
of image quality. It reveals that OMGD provides a feasible solution for the
deployment of real-time image translation on resource-constrained devices. Our
code and models are made public at: https://github.com/bytedance/OMGD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Transferable and Robust Adversarial Perturbation Generation from the Perspective of Network Hierarchy. (arXiv:2108.07033v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruikui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuanfang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruijie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07033">
                                    <div class="article-summary-box-inner">
                                        <span>The transferability and robustness of adversarial examples are two practical
yet important properties for black-box adversarial attacks. In this paper, we
explore effective mechanisms to boost both of them from the perspective of
network hierarchy, where a typical network can be hierarchically divided into
output stage, intermediate stage and input stage. Since over-specialization of
source model, we can hardly improve the transferability and robustness of the
adversarial perturbations in the output stage. Therefore, we focus on the
intermediate and input stages in this paper and propose a transferable and
robust adversarial perturbation generation (TRAP) method. Specifically, we
propose the dynamically guided mechanism to continuously calculate accurate
directional guidances for perturbation generation in the intermediate stage. In
the input stage, instead of the single-form transformation augmentations
adopted in the existing methods, we leverage multiform affine transformation
augmentations to further enrich the input diversity and boost the robustness
and transferability of the adversarial perturbations. Extensive experiments
demonstrate that our TRAP achieves impressive transferability and high
robustness against certain interferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Adversarially-Enhanced k-Nearest Neighbors. (arXiv:2108.06797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06797">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have theoretically and empirically shown that deep neural
networks (DNNs) have an inherent vulnerability to small perturbations. Applying
the Deep k-Nearest Neighbors (DkNN) classifier, we observe a dramatically
increasing robustness-accuracy trade-off as the layer goes deeper. In this
work, we propose a Deep Adversarially-Enhanced k-Nearest Neighbors (DAEkNN)
method which achieves higher robustness than DkNN and mitigates the
robustness-accuracy trade-off in deep layers through two key elements. First,
DAEkNN is based on an adversarially trained model. Second, DAEkNN makes
predictions by leveraging a weighted combination of benign and adversarial
training data. Empirically, we find that DAEkNN improves both the robustness
and the robustness-accuracy trade-off on MNIST and CIFAR-10 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Person Re-identification using Attribute-enhanced Features. (arXiv:2108.06946v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1">Tianrui Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Annan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_X/0/1/0/all/0/1">Xinyu Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06946">
                                    <div class="article-summary-box-inner">
                                        <span>Video-based person re-identification (Re-ID) which aims to associate people
across non-overlapping cameras using surveillance video is a challenging task.
Pedestrian attribute, such as gender, age and clothing characteristics contains
rich and supplementary information but is less explored in video person Re-ID.
In this work, we propose a novel network architecture named Attribute Salience
Assisted Network (ASA-Net) for attribute-assisted video person Re-ID, which
achieved considerable improvement to existing works by two methods.First, to
learn a better separation of the target from background, we propose to learn
the visual attention from middle-level attribute instead of high-level
identities. The proposed Attribute Salient Region Enhance (ASRE) module can
attend more accurately on the body of pedestrian. Second, we found that many
identity-irrelevant but object or subject-relevant factors like the view angle
and movement of the target pedestrian can greatly influence the two dimensional
appearance of a pedestrian. This problem can be mitigated by investigating both
identity-relevant and identity-irrelevant attributes via a novel triplet loss
which is referred as the Pose~\&amp;~Motion-Invariant (PMI) triplet loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flying Guide Dog: Walkable Path Discovery for the Visually Impaired Utilizing Drones and Transformer-based Semantic Segmentation. (arXiv:2108.07007v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Haobin Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xinyu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seibold_C/0/1/0/all/0/1">Constantin Seibold</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07007">
                                    <div class="article-summary-box-inner">
                                        <span>Lacking the ability to sense ambient environments effectively, blind and
visually impaired people (BVIP) face difficulty in walking outdoors, especially
in urban areas. Therefore, tools for assisting BVIP are of great importance. In
this paper, we propose a novel &quot;flying guide dog&quot; prototype for BVIP assistance
using drone and street view semantic segmentation. Based on the walkable areas
extracted from the segmentation prediction, the drone can adjust its movement
automatically and thus lead the user to walk along the walkable path. By
recognizing the color of pedestrian traffic lights, our prototype can help the
user to cross a street safely. Furthermore, we introduce a new dataset named
Pedestrian and Vehicle Traffic Lights (PVTL), which is dedicated to traffic
light recognition. The result of our user study in real-world scenarios shows
that our prototype is effective and easy to use, providing new insight into
BVIP assistance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning from an Artificial Radiograph-landmark Dataset for Registration of the Anatomic Skull Model to Dual Fluoroscopic X-ray Images. (arXiv:2108.06466v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chaochao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_T/0/1/0/all/0/1">Thomas Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guoan Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06466">
                                    <div class="article-summary-box-inner">
                                        <span>Registration of 3D anatomic structures to their 2D dual fluoroscopic X-ray
images is a widely used motion tracking technique. However, deep learning
implementation is often impeded by a paucity of medical images and ground
truths. In this study, we proposed a transfer learning strategy for 3D-to-2D
registration using deep neural networks trained from an artificial dataset.
Digitally reconstructed radiographs (DRRs) and radiographic skull landmarks
were automatically created from craniocervical CT data of a female subject.
They were used to train a residual network (ResNet) for landmark detection and
a cycle generative adversarial network (GAN) to eliminate the style difference
between DRRs and actual X-rays. Landmarks on the X-rays experiencing GAN style
translation were detected by the ResNet, and were used in triangulation
optimization for 3D-to-2D registration of the skull in actual dual-fluoroscope
images (with a non-orthogonal setup, point X-ray sources, image distortions,
and partially captured skull regions). The registration accuracy was evaluated
in multiple scenarios of craniocervical motions. In walking, learning-based
registration for the skull had angular/position errors of 3.9 +- 2.1 deg / 4.6
+- 2.2 mm. However, the accuracy was lower during functional neck activity, due
to overly small skull regions imaged on the dual fluoroscopic images at
end-range positions. The methodology to strategically augment artificial
training data can tackle the complicated skull registration scenario, and has
potentials to extend to widespread registration scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Multi-Modal Semantic Fusion on Unmanned Aerial Vehicles. (arXiv:2108.06608v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bultmann_S/0/1/0/all/0/1">Simon Bultmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Quenzel_J/0/1/0/all/0/1">Jan Quenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06608">
                                    <div class="article-summary-box-inner">
                                        <span>Unmanned aerial vehicles (UAVs) equipped with multiple complementary sensors
have tremendous potential for fast autonomous or remote-controlled semantic
scene analysis, e.g., for disaster examination. In this work, we propose a UAV
system for real-time semantic inference and fusion of multiple sensor
modalities. Semantic segmentation of LiDAR scans and RGB images, as well as
object detection on RGB and thermal images, run online onboard the UAV computer
using lightweight CNN architectures and embedded inference accelerators. We
follow a late fusion approach where semantic information from multiple
modalities augments 3D point clouds and image segmentation masks while also
generating an allocentric semantic map. Our system provides augmented semantic
images and point clouds with $\approx\,$9$\,$Hz. We evaluate the integrated
system in real-world experiments in an urban environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-Distillation Embedded Supervised Affinity Attention Model for Few-Shot Segmentation. (arXiv:2108.06600v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Binghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Shuchang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yifan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06600">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot semantic segmentation is a challenging task of predicting object
categories in pixel-wise with only few annotated samples. However, existing
approaches still face two main challenges. First, huge feature distinction
between support and query images causes knowledge transferring barrier, which
harms the segmentation performance. Second, few support samples cause
unrepresentative of support features, hardly to guide high-quality query
segmentation. To deal with the above two issues, we propose self-distillation
embedded supervised affinity attention model (SD-AANet) to improve the
performance of few-shot segmentation task. Specifically, the self-distillation
guided prototype module (SDPM) extracts intrinsic prototype by
self-distillation between support and query to capture representative features.
The supervised affinity attention module (SAAM) adopts support ground truth to
guide the production of high quality query attention map, which can learn
affinity information to focus on whole area of query target. Extensive
experiments prove that our SD-AANet significantly improves the performance
comparing with existing methods. Comprehensive ablation experiments and
visualization studies also show the significant effect of SDPM and SAAM for
few-shot segmentation task. On benchmark datasets, PASCAL-5i and COCO-20i, our
proposed SD-AANet both achieve state-of-the-art results. Our code will be
publicly available soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing Item Popularity Bias of Music Recommender Systems: Are Different Genders Equally Affected?. (arXiv:2108.06973v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lesota_O/0/1/0/all/0/1">Oleg Lesota</a>, <a href="http://arxiv.org/find/cs/1/au:+Melchiorre_A/0/1/0/all/0/1">Alessandro B. Melchiorre</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1">Navid Rekabsaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Brandl_S/0/1/0/all/0/1">Stefan Brandl</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowald_D/0/1/0/all/0/1">Dominik Kowald</a>, <a href="http://arxiv.org/find/cs/1/au:+Lex_E/0/1/0/all/0/1">Elisabeth Lex</a>, <a href="http://arxiv.org/find/cs/1/au:+Schedl_M/0/1/0/all/0/1">Markus Schedl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06973">
                                    <div class="article-summary-box-inner">
                                        <span>Several studies have identified discrepancies between the popularity of items
in user profiles and the corresponding recommendation lists. Such behavior,
which concerns a variety of recommendation algorithms, is referred to as
popularity bias. Existing work predominantly adopts simple statistical
measures, such as the difference of mean or median popularity, to quantify
popularity bias. Moreover, it does so irrespective of user characteristics
other than the inclination to popular content. In this work, in contrast, we
propose to investigate popularity differences (between the user profile and
recommendation list) in terms of median, a variety of statistical moments, as
well as similarity measures that consider the entire popularity distributions
(Kullback-Leibler divergence and Kendall&#x27;s tau rank-order correlation). This
results in a more detailed picture of the characteristics of popularity bias.
Furthermore, we investigate whether such algorithmic popularity bias affects
users of different genders in the same way. We focus on music recommendation
and conduct experiments on the recently released standardized LFM-2b dataset,
containing listening profiles of Last.fm users. We investigate the algorithmic
popularity bias of seven common recommendation algorithms (five collaborative
filtering and two baselines). Our experiments show that (1) the studied metrics
provide novel insights into popularity bias in comparison with only using
average differences, (2) algorithms less inclined towards popularity bias
amplification do not necessarily perform worse in terms of utility (NDCG), (3)
the majority of the investigated recommenders intensify the popularity bias of
the female users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Self-Adaptive Hashing for Image Retrieval. (arXiv:2108.07094v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qinghong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaojun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Shangxuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yudong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07094">
                                    <div class="article-summary-box-inner">
                                        <span>Hashing technology has been widely used in image retrieval due to its
computational and storage efficiency. Recently, deep unsupervised hashing
methods have attracted increasing attention due to the high cost of human
annotations in the real world and the superiority of deep learning technology.
However, most deep unsupervised hashing methods usually pre-compute a
similarity matrix to model the pairwise relationship in the pre-trained feature
space. Then this similarity matrix would be used to guide hash learning, in
which most of the data pairs are treated equivalently. The above process is
confronted with the following defects: 1) The pre-computed similarity matrix is
inalterable and disconnected from the hash learning process, which cannot
explore the underlying semantic information. 2) The informative data pairs may
be buried by the large number of less-informative data pairs. To solve the
aforementioned problems, we propose a \textbf{Deep Self-Adaptive
Hashing~(DSAH)} model to adaptively capture the semantic information with two
special designs: \textbf{Adaptive Neighbor Discovery~(AND)} and
\textbf{Pairwise Information Content~(PIC)}. Firstly, we adopt the AND to
initially construct a neighborhood-based similarity matrix, and then refine
this initial similarity matrix with a novel update strategy to further
investigate the semantic structure behind the learned representation. Secondly,
we measure the priorities of data pairs with PIC and assign adaptive weights to
them, which is relies on the assumption that more dissimilar data pairs contain
more discriminative information for hash learning. Extensive experiments on
several benchmark datasets demonstrate that the above two technologies
facilitate the deep hashing model to achieve superior performance in a
self-adaptive manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DGCN: Diversified Recommendation with Graph Convolutional Networks. (arXiv:2108.06952v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Depeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06952">
                                    <div class="article-summary-box-inner">
                                        <span>These years much effort has been devoted to improving the accuracy or
relevance of the recommendation system. Diversity, a crucial factor which
measures the dissimilarity among the recommended items, received rather little
scrutiny. Directly related to user satisfaction, diversification is usually
taken into consideration after generating the candidate items. However, this
decoupled design of diversification and candidate generation makes the whole
system suboptimal. In this paper, we aim at pushing the diversification to the
upstream candidate generation stage, with the help of Graph Convolutional
Networks (GCN). Although GCN based recommendation algorithms have shown great
power in modeling complex collaborative filtering effect to improve the
accuracy of recommendation, how diversity changes is ignored in those advanced
works. We propose to perform rebalanced neighbor discovering, category-boosted
negative sampling and adversarial learning on top of GCN. We conduct extensive
experiments on real-world datasets. Experimental results verify the
effectiveness of our proposed method on diversification. Further ablation
studies validate that our proposed method significantly alleviates the
accuracy-diversity dilemma.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deployment of a Free-Text Analytics Platform at a UK National Health Service Research Hospital: CogStack at University College London Hospitals. (arXiv:2108.06835v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noor_K/0/1/0/all/0/1">Kawsar Noor</a>, <a href="http://arxiv.org/find/cs/1/au:+Roguski_L/0/1/0/all/0/1">Lukasz Roguski</a>, <a href="http://arxiv.org/find/cs/1/au:+Handy_A/0/1/0/all/0/1">Alex Handy</a>, <a href="http://arxiv.org/find/cs/1/au:+Klapaukh_R/0/1/0/all/0/1">Roman Klapaukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Folarin_A/0/1/0/all/0/1">Amos Folarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Romao_L/0/1/0/all/0/1">Luis Romao</a>, <a href="http://arxiv.org/find/cs/1/au:+Matteson_J/0/1/0/all/0/1">Joshua Matteson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lea_N/0/1/0/all/0/1">Nathan Lea</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Leilei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1">Wai Keong Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Anoop Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1">Richard J Dobson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06835">
                                    <div class="article-summary-box-inner">
                                        <span>As more healthcare organisations transition to using electronic health record
(EHR) systems it is important for these organisations to maximise the secondary
use of their data to support service improvement and clinical research. These
organisations will find it challenging to have systems which can mine
information from the unstructured data fields in the record (clinical notes,
letters etc) and more practically have such systems interact with all of the
hospitals data systems (legacy and current). To tackle this problem at
University College London Hospitals, we have deployed an enhanced version of
the CogStack platform; an information retrieval platform with natural language
processing capabilities which we have configured to process the hospital&#x27;s
existing and legacy records. The platform has improved data ingestion
capabilities as well as better tools for natural language processing. To date
we have processed over 18 million records and the insights produced from
CogStack have informed a number of clinical research use cases at the
hospitals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward the Understanding of Deep Text Matching Models for Information Retrieval. (arXiv:2108.07081v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lijuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07081">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic text matching is a critical problem in information retrieval.
Recently, deep learning techniques have been widely used in this area and
obtained significant performance improvements. However, most models are black
boxes and it is hard to understand what happened in the matching process, due
to the poor interpretability of deep learning. This paper aims at tackling this
problem. The key idea is to test whether existing deep text matching methods
satisfy some fundamental heuristics in information retrieval. Specifically,
four heuristics are used in our study, i.e., term frequency constraint, term
discrimination constraint, length normalization constraints, and TF-length
constraint. Since deep matching models usually contain many parameters, it is
difficult to conduct a theoretical study for these complicated functions. In
this paper, We propose an empirical testing method. Specifically, We first
construct some queries and documents to make them satisfy the assumption in a
constraint, and then test to which extend a deep text matching model trained on
the original dataset satisfies the corresponding constraint. Besides, a famous
attribution based interpretation method, namely integrated gradient, is adopted
to conduct detailed analysis and guide for feasible improvement. Experimental
results on LETOR 4.0 and MS Marco show that all the investigated deep text
matching methods, both representation and interaction based methods, satisfy
the above constraints with high probabilities in statistics. We further extend
these constraints to the semantic settings, which are shown to be better
satisfied for all the deep text matching models. These empirical findings give
clear understandings on why deep text matching models usually perform well in
information retrieval. We believe the proposed evaluation methodology will be
useful for testing future deep text matching models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Event2Graph: Event-driven Bipartite Graph for Multivariate Time-series Anomaly Detection. (arXiv:2108.06783v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuhang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_M/0/1/0/all/0/1">Mengting Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yusan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06783">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling inter-dependencies between time-series is the key to achieve high
performance in anomaly detection for multivariate time-series data. The
de-facto solution to model the dependencies is to feed the data into a
recurrent neural network (RNN). However, the fully connected network structure
underneath the RNN (either GRU or LSTM) assumes a static and complete
dependency graph between time-series, which may not hold in many real-world
applications. To alleviate this assumption, we propose a dynamic bipartite
graph structure to encode the inter-dependencies between time-series. More
concretely, we model time series as one type of nodes, and the time series
segments (regarded as event) as another type of nodes, where the edge between
two types of nodes describe a temporal pattern occurred on a specific time
series at a certain time. Based on this design, relations between time series
can be explicitly modelled via dynamic connections to event nodes, and the
multivariate time-series anomaly detection problem can be formulated as a
self-supervised, edge stream prediction problem in dynamic graphs. We conducted
extensive experiments to demonstrate the effectiveness of the design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clinical Relation Extraction Using Transformer-based Models. (arXiv:2107.08957v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zehao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08957">
                                    <div class="article-summary-box-inner">
                                        <span>The newly emerged transformer technology has a tremendous impact on NLP
research. In the general English domain, transformer-based models have achieved
state-of-the-art performances on various NLP benchmarks. In the clinical
domain, researchers also have investigated transformer models for clinical
applications. The goal of this study is to systematically explore three widely
used transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical
relation extraction and develop an open-source package with clinical
pre-trained transformer-based models to facilitate information extraction in
the clinical domain. We developed a series of clinical RE models based on three
transformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these
models using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2
challenges. We compared two classification strategies (binary vs. multi-class
classification) and investigated two approaches to generate candidate relations
in different experimental settings. In this study, we compared three
transformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We
demonstrated that the RoBERTa-clinical RE model achieved the best performance
on the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2
dataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our
results indicated that the binary classification strategy consistently
outperformed the multi-class classification strategy for clinical relation
extraction. Our methods and models are publicly available at
https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.
We believe this work will improve current practice on clinical relation
extraction and other related NLP tasks in the biomedical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Representation Learning for Session-based Recommendation. (arXiv:2107.01516v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1">Sai Mitheran</a>, <a href="http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1">Abhinav Java</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1">Surya Kant Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1">Arshad Shaikh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01516">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation systems suggest relevant items to users by
modeling user behavior and preferences using short-term anonymous sessions.
Existing methods leverage Graph Neural Networks (GNNs) that propagate and
aggregate information from neighboring nodes i.e., local message passing. Such
graph-based architectures have representational limits, as a single sub-graph
is susceptible to overfit the sequential dependencies instead of accounting for
complex transitions between items in different sessions. We propose using a
Transformer in combination with a target attentive GNN, which allows richer
Representation Learning. Our experimental results and ablation show that our
proposed method is competitive with the existing methods on real-world
benchmark datasets, improving on graph-based hypotheses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-Time Sequential Recommendation with Temporal Graph Collaborative Transformer. (arXiv:2108.06625v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziwei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06625">
                                    <div class="article-summary-box-inner">
                                        <span>In order to model the evolution of user preference, we should learn user/item
embeddings based on time-ordered item purchasing sequences, which is defined as
Sequential Recommendation (SR) problem. Existing methods leverage sequential
patterns to model item transitions. However, most of them ignore crucial
temporal collaborative signals, which are latent in evolving user-item
interactions and coexist with sequential patterns. Therefore, we propose to
unify sequential patterns and temporal collaborative signals to improve the
quality of recommendation, which is rather challenging. Firstly, it is hard to
simultaneously encode sequential patterns and collaborative signals. Secondly,
it is non-trivial to express the temporal effects of collaborative signals.

Hence, we design a new framework Temporal Graph Sequential Recommender
(TGSRec) upon our defined continuous-time bi-partite graph. We propose a novel
Temporal Collaborative Trans-former (TCT) layer in TGSRec, which advances the
self-attention mechanism by adopting a novel collaborative attention. TCT layer
can simultaneously capture collaborative signals from both users and items, as
well as considering temporal dynamics inside sequential patterns. We propagate
the information learned fromTCTlayerover the temporal graph to unify sequential
patterns and temporal collaborative signals. Empirical results on five datasets
show that TGSRec significantly outperforms other baselines, in average up to
22.5% and 22.1%absolute improvements in Recall@10and MRR, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Scale-free Graphs for Knowledge-aware Recommendation. (arXiv:2108.06468v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yankai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Menglin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingxue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Ziqiao Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jian Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06468">
                                    <div class="article-summary-box-inner">
                                        <span>Aiming to alleviate data sparsity and cold-start problems of traditional
recommender systems, incorporating knowledge graphs (KGs) to supplement
auxiliary information has recently gained considerable attention. Via unifying
the KG with user-item interactions into a tripartite graph, recent works
explore the graph topologies to learn the low-dimensional representations of
users and items with rich semantics. However, these real-world tripartite
graphs are usually scale-free, the intrinsic hierarchical graph structures of
which are underemphasized in existing works, consequently, leading to
suboptimal recommendation performance.

To address this issue and provide more accurate recommendation, we propose a
knowledge-aware recommendation method with the hyperbolic geometry, namely
Lorentzian Knowledge-enhanced Graph convolutional networks for Recommendation
(LKGR). LKGR facilitates better modeling of scale-free tripartite graphs after
the data unification. Specifically, we employ different information propagation
strategies in the hyperbolic space to explicitly encode heterogeneous
information from historical interactions and KGs. Our proposed knowledge-aware
attention mechanism enables the model to automatically measure the information
contribution, producing the coherent information aggregation in the hyperbolic
space. Extensive experiments on three real-world benchmarks demonstrate that
LKGR outperforms state-of-the-art methods by 2.2-29.9% of Recall@20 on Top-K
recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhoujun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Haoyu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiruo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaqi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jian-Guang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06712">
                                    <div class="article-summary-box-inner">
                                        <span>Tables are often created with hierarchies, but existing works on table
reasoning mainly focus on flat tables and neglect hierarchical tables.
Hierarchical tables challenge existing methods by hierarchical indexing, as
well as implicit relationships of calculation and semantics. This work presents
HiTab, a free and open dataset for the research community to study question
answering (QA) and natural language generation (NLG) over hierarchical tables.
HiTab is a cross-domain dataset constructed from a wealth of statistical
reports and Wikipedia pages, and has unique characteristics: (1) nearly all
tables are hierarchical, and (2) both target sentences for NLG and questions
for QA are revised from high-quality descriptions in statistical reports that
are meaningful and diverse. (3) HiTab provides fine-grained annotations on both
entity and quantity alignment. Targeting hierarchical structure, we devise a
novel hierarchy-aware logical form for symbolic reasoning over tables, which
shows high effectiveness. Then given annotations of entity and quantity
alignment, we propose partially supervised training, which helps models to
largely reduce spurious predictions in the QA task. In the NLG task, we find
that entity and quantity alignment also helps NLG models to generate better
results in a conditional generation setting. Experiment results of
state-of-the-art baselines suggest that this dataset presents a strong
challenge and a valuable benchmark for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Self-supervised Sequential Recommendation with Robust Augmentation. (arXiv:2108.06479v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yongjun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06479">
                                    <div class="article-summary-box-inner">
                                        <span>Sequential Recommendationdescribes a set of techniques to model dynamic user
behavior in order to predict future interactions in sequential user data. At
their core, such approaches model transition probabilities between items in a
sequence, whether through Markov chains, recurrent networks, or more recently,
Transformers. However both old and new issues remain, including data-sparsity
and noisy data; such issues can impair the performance, especially in complex,
parameter-hungry models. In this paper, we investigate the application of
contrastive Self-Supervised Learning (SSL) to the sequential recommendation, as
a way to alleviate some of these issues. Contrastive SSL constructs
augmentations from unlabelled instances, where agreements among positive pairs
are maximized. It is challenging to devise a contrastive SSL framework for a
sequential recommendation, due to its discrete nature, correlations among
items, and skewness of length distributions. To this end, we propose a novel
framework, Contrastive Self-supervised Learning for sequential Recommendation
(CoSeRec). We introduce two informative augmentation operators leveraging item
correlations to create high-quality views for contrastive learning.
Experimental results on three real-world datasets demonstrate the effectiveness
of the proposed method on improving model performance and the robustness
against sparse and noisy data. Our implementation is available online at
\url{https://github.com/YChen1993/CoSeRec}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Enterprise Architecture Model Mining. (arXiv:2108.06696v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hillmann_P/0/1/0/all/0/1">Peter Hillmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Heiland_E/0/1/0/all/0/1">Erik Heiland</a>, <a href="http://arxiv.org/find/cs/1/au:+Karcher_A/0/1/0/all/0/1">Andreas Karcher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06696">
                                    <div class="article-summary-box-inner">
                                        <span>Metadata are like the steam engine of the 21st century, driving businesses
and offer multiple enhancements. Nevertheless, many companies are unaware that
these data can be used efficiently to improve their own operation. This is
where the Enterprise Architecture Framework comes in. It empowers an
organisation to get a clear view of their business, application, technical and
physical layer. This modelling approach is an established method for
organizations to take a deeper look into their structure and processes. The
development of such models requires a great deal of effort, is carried out
manually by interviewing stakeholders and requires continuous maintenance. Our
new approach enables the automated mining of Enterprise Architecture models.
The system uses common technologies to collect the metadata based on network
traffic, log files and other information in an organisation. Based on this, the
new approach generates EA models with the desired views points. Furthermore, a
rule and knowledge-based reasoning is used to obtain a holistic overview. This
offers a strategic decision support from business structure over process design
up to planning the appropriate support technology. Therefore, it forms the base
for organisations to act in an agile way. The modelling can be performed in
different modelling languages, including ArchiMate and the Nato Architecture
Framework (NAF). The designed approach is already evaluated on a small company
with multiple services and an infrastructure with several nodes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Objective Recommendations: A Tutorial. (arXiv:2108.06367v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+David/0/1/0/all/0/1">David</a> (Xuejun) <a href="http://arxiv.org/find/cs/1/au:+Wang/0/1/0/all/0/1">Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06367">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RecSys) have been well developed to assist user decision
making. Traditional RecSys usually optimize a single objective (e.g., rating
prediction errors or ranking quality) in the model. There is an emerging demand
in multi-objective optimization recently in RecSys, especially in the area of
multi-stakeholder and multi-task recommender systems. This article provides an
overview of multi-objective recommendations, followed by the discussions with
case studies. The document is considered as a supplementary material for our
tutorial on multi-objective recommendations at ACM SIGKDD 2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Feature Representations for Cricket Data Analysis using Deep Learning based Multi-Modal Fusion Model. (arXiv:2108.07139v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alaka_S/0/1/0/all/0/1">Souridas Alaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreekumar_R/0/1/0/all/0/1">Rishikesh Sreekumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalu_H/0/1/0/all/0/1">Hrithwik Shalu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07139">
                                    <div class="article-summary-box-inner">
                                        <span>Data analysis has become a necessity in the modern era of cricket. Everything
from effective team management to match win predictions use some form of
analytics. Meaningful data representations are necessary for efficient analysis
of data. In this study we investigate the use of adaptive (learnable)
embeddings to represent inter-related features (such as players, teams, etc).
The data used for this study is collected from a classical T20 tournament IPL
(Indian Premier League). To naturally facilitate the learning of meaningful
representations of features for accurate data analysis, we formulate a deep
representation learning framework which jointly learns a custom set of
embeddings (which represents our features of interest) through the minimization
of a contrastive loss. We base our objective on a set of classes obtained as a
result of hierarchical clustering on the overall run rate of an innings. It&#x27;s
been assessed that the framework ensures greater generality in the obtained
embeddings, on top of which a task based analysis of overall run rate
prediction was done to show the reliability of the framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Cyber Terrain in Reinforcement Learning for Penetration Testing. (arXiv:2108.07124v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gangupantulu_R/0/1/0/all/0/1">Rohit Gangupantulu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1">Tyler Cody</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_P/0/1/0/all/0/1">Paul Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1">Abdul Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenbeiser_L/0/1/0/all/0/1">Logan Eisenbeiser</a>, <a href="http://arxiv.org/find/cs/1/au:+Radke_D/0/1/0/all/0/1">Dan Radke</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_R/0/1/0/all/0/1">Ryan Clark</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07124">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) has been applied to attack graphs for penetration
testing, however, trained agents do not reflect reality because the attack
graphs lack operational nuances typically captured within the intelligence
preparation of the battlefield (IPB) that include notions of (cyber) terrain.
In particular, current practice constructs attack graphs exclusively using the
Common Vulnerability Scoring System (CVSS) and its components. We present
methods for constructing attack graphs using notions from IPB on cyber terrain
analysis of obstacles, avenues of approach, key terrain, observation and fields
of fire, and cover and concealment. We demonstrate our methods on an example
where firewalls are treated as obstacles and represented in (1) the reward
space and (2) the state dynamics. We show that terrain analysis can be used to
bring realism to attack graphs for RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Price of Incentivizing Exploration: A Characterization via Thompson Sampling and Sample Complexity. (arXiv:2002.00558v5 [cs.GT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00558">
                                    <div class="article-summary-box-inner">
                                        <span>We consider incentivized exploration: a version of multi-armed bandits where
the choice of arms is controlled by self-interested agents, and the algorithm
can only issue recommendations. The algorithm controls the flow of information,
and the information asymmetry can incentivize the agents to explore. Prior work
achieves optimal regret rates up to multiplicative factors that become
arbitrarily large depending on the Bayesian priors, and scale exponentially in
the number of arms. A more basic problem of sampling each arm once runs into
similar factors.

We focus on the price of incentives: the loss in performance, broadly
construed, incurred for the sake of incentive-compatibility. We prove that
Thompson Sampling, a standard bandit algorithm, is incentive-compatible if
initialized with sufficiently many data points. The performance loss due to
incentives is therefore limited to the initial rounds when these data points
are collected. The problem is largely reduced to that of sample complexity: how
many rounds are needed? We address this question, providing matching upper and
lower bounds and instantiating them in various corollaries. Typically, the
optimal sample complexity is polynomial in the number of arms and exponential
in the &quot;strength of beliefs&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intra-clip Aggregation for Video Person Re-identification. (arXiv:1905.01722v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isobe_T/0/1/0/all/0/1">Takashi Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jian Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yali Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.01722">
                                    <div class="article-summary-box-inner">
                                        <span>Video-based person re-identification has drawn massive attention in recent
years due to its extensive applications in video surveillance. While deep
learning-based methods have led to significant progress, these methods are
limited by ineffectively using complementary information, which is blamed on
necessary data augmentation in the training process. Data augmentation has been
widely used to mitigate the over-fitting trap and improve the ability of
network representation. However, the previous methods adopt image-based data
augmentation scheme to individually process the input frames, which corrupts
the complementary information between consecutive frames and causes performance
degradation. Extensive experiments on three benchmark datasets demonstrate that
our framework outperforms the most recent state-of-the-art methods. We also
perform cross-dataset validation to prove the generality of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Incremental Graph Convolution for Recommender System Retraining. (arXiv:2108.06889v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Sihao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongdong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06889">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world recommender system needs to be regularly retrained to keep with
the new data. In this work, we consider how to efficiently retrain graph
convolution network (GCN) based recommender models, which are state-of-the-art
techniques for collaborative recommendation. To pursue high efficiency, we set
the target as using only new data for model updating, meanwhile not sacrificing
the recommendation accuracy compared with full model retraining. This is
non-trivial to achieve, since the interaction data participates in both the
graph structure for model construction and the loss function for model
learning, whereas the old graph structure is not allowed to use in model
updating. Towards the goal, we propose a \textit{Causal Incremental Graph
Convolution} approach, which consists of two new operators named
\textit{Incremental Graph Convolution} (IGC) and \textit{Colliding Effect
Distillation} (CED) to estimate the output of full graph convolution. In
particular, we devise simple and effective modules for IGC to ingeniously
combine the old representations and the incremental graph and effectively fuse
the long-term and short-term preference signals. CED aims to avoid the
out-of-date issue of inactive nodes that are not in the incremental graph,
which connects the new data with inactive nodes through causal inference. In
particular, CED estimates the causal effect of new data on the representation
of inactive nodes through the control of their collider. Extensive experiments
on three real-world datasets demonstrate both accuracy gains and significant
speed-ups over the existing retraining mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maps Search Misspelling Detection Leveraging Domain-Augmented Contextual Representations. (arXiv:2108.06842v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yutong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06842">
                                    <div class="article-summary-box-inner">
                                        <span>Building an independent misspelling detector and serve it before correction
can bring multiple benefits to speller and other search components, which is
particularly true for the most commonly deployed noisy-channel based speller
systems. With rapid development of deep learning and substantial advancement in
contextual representation learning such as BERTology, building a decent
misspelling detector without having to rely on hand-crafted features associated
with noisy-channel architecture becomes more-than-ever accessible. However
BERTolgy models are trained with natural language corpus but Maps Search is
highly domain specific, would BERTology continue its success. In this paper we
design 4 stages of models for misspeling detection ranging from the most basic
LSTM to single-domain augmented fine-tuned BERT. We found for Maps Search in
our case, other advanced BERTology family model such as RoBERTa does not
necessarily outperform BERT, and a classic cross-domain fine-tuned full BERT
even underperforms a smaller single-domain fine-tuned BERT. We share more
findings through comprehensive modeling experiments and analysis, we also
briefly cover the data generation algorithm breakthrough.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting and improving deep-learning models with reality checks. (arXiv:2108.06847v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Singh_C/0/1/0/all/0/1">Chandan Singh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ha_W/0/1/0/all/0/1">Wooseok Ha</a>, <a href="http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1">Bin Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06847">
                                    <div class="article-summary-box-inner">
                                        <span>Recent deep-learning models have achieved impressive predictive performance
by learning complex functions of many variables, often at the cost of
interpretability. This chapter covers recent work aiming to interpret models by
attributing importance to features and feature groups for a single prediction.
Importantly, the proposed attributions assign importance to interactions
between features, in addition to features in isolation. These attributions are
shown to yield insights across real-world domains, including bio-imaging,
cosmology image and natural-language processing. We then show how these
attributions can be used to directly improve the generalization of a neural
network or to distill it into a simple model. Throughout the chapter, we
emphasize the use of reality checks to scrutinize the proposed interpretation
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Actor-Critic Algorithms. (arXiv:2108.01215v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuhua Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1">Lexing Ying</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01215">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a class of variational actor-critic algorithms based on a
variational formulation over both the value function and the policy. The
objective function of the variational formulation consists of two parts: one
for maximizing the value function and the other for minimizing the Bellman
residual. Besides the vanilla gradient descent with both the value function and
the policy updates, we propose two variants, the clipping method and the
flipping method, in order to speed up the convergence. We also prove that, when
the prefactor of the Bellman residual is sufficiently large, the fixed point of
the algorithm is close to the optimal policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FUDGE: Controlled Text Generation With Future Discriminators. (arXiv:2104.05218v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05218">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Future Discriminators for Generation (FUDGE), a flexible and
modular method for controlled text generation. Given a pre-existing model G for
generating text from a distribution of interest, FUDGE enables conditioning on
a desired attribute a (for example, formality) while requiring access only to
G&#x27;s output logits. FUDGE learns an attribute predictor operating on a partial
sequence, and uses this predictor&#x27;s outputs to adjust G&#x27;s original
probabilities. We show that FUDGE models terms corresponding to a Bayesian
decomposition of the conditional distribution of G given attribute a. Moreover,
FUDGE can easily compose predictors for multiple desired attributes. We
evaluate FUDGE on three tasks -- couplet completion in poetry, topic control in
language generation, and formality change in machine translation -- and observe
gains in all three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Hyperparameter Optimization under Multi-Source Covariate Shift. (arXiv:2006.10600v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nomura_M/0/1/0/all/0/1">Masahiro Nomura</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1">Yuta Saito</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10600">
                                    <div class="article-summary-box-inner">
                                        <span>A typical assumption in supervised machine learning is that the train
(source) and test (target) datasets follow completely the same distribution.
This assumption is, however, often violated in uncertain real-world
applications, which motivates the study of learning under covariate shift. In
this setting, the naive use of adaptive hyperparameter optimization methods
such as Bayesian optimization does not work as desired since it does not
address the distributional shift among different datasets. In this work, we
consider a novel hyperparameter optimization problem under the multi-source
covariate shift whose goal is to find the optimal hyperparameters for a target
task of interest using only unlabeled data in a target task and labeled data in
multiple source tasks. To conduct efficient hyperparameter optimization for the
target task, it is essential to estimate the target objective using only the
available information. To this end, we construct the variance reduced estimator
that unbiasedly approximates the target objective with a desirable variance
property. Building on the proposed estimator, we provide a general and
tractable hyperparameter optimization procedure, which works preferably in our
setting with a no-regret guarantee. The experiments demonstrate that the
proposed framework broadens the applications of automated hyperparameter
optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Continual Learning. (arXiv:2108.06552v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Boschini_M/0/1/0/all/0/1">Matteo Boschini</a>, <a href="http://arxiv.org/find/stat/1/au:+Buzzega_P/0/1/0/all/0/1">Pietro Buzzega</a>, <a href="http://arxiv.org/find/stat/1/au:+Bonicelli_L/0/1/0/all/0/1">Lorenzo Bonicelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Porrello_A/0/1/0/all/0/1">Angelo Porrello</a>, <a href="http://arxiv.org/find/stat/1/au:+Calderara_S/0/1/0/all/0/1">Simone Calderara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06552">
                                    <div class="article-summary-box-inner">
                                        <span>Continual Learning (CL) investigates how to train Deep Networks on a stream
of tasks without incurring catastrophic forgetting. CL settings proposed in the
literature assume that every incoming example is paired with ground-truth
annotations. However, this clashes with many real-world applications: gathering
labeled data, which is in itself tedious and expensive, becomes indeed
infeasible when data flow as a stream and must be consumed in real-time. This
work explores Weakly Supervised Continual Learning (WSCL): here, only a small
fraction of labeled input examples are shown to the learner. We assess how
current CL methods (e.g.: EWC, LwF, iCaRL, ER, GDumb, DER) perform in this
novel and challenging scenario, in which overfitting entangles forgetting.
Subsequently, we design two novel WSCL methods which exploit metric learning
and consistency regularization to leverage unsupervised data while learning. In
doing so, we show that not only our proposals exhibit higher flexibility when
supervised information is scarce, but also that less than 25% labels can be
enough to reach or even outperform SOTA methods trained under full supervision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Study of Training Self-Supervised Vision Transformers. (arXiv:2104.02057v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinlei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Saining Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kaiming He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02057">
                                    <div class="article-summary-box-inner">
                                        <span>This paper does not describe a novel method. Instead, it studies a
straightforward, incremental, yet must-know baseline given the recent progress
in computer vision: self-supervised learning for Vision Transformers (ViT).
While the training recipes for standard convolutional networks have been highly
mature and robust, the recipes for ViT are yet to be built, especially in the
self-supervised scenarios where training becomes more challenging. In this
work, we go back to basics and investigate the effects of several fundamental
components for training self-supervised ViT. We observe that instability is a
major issue that degrades accuracy, and it can be hidden by apparently good
results. We reveal that these results are indeed partial failure, and they can
be improved when training is made more stable. We benchmark ViT results in MoCo
v3 and several other self-supervised frameworks, with ablations in various
aspects. We discuss the currently positive evidence as well as challenges and
open questions. We hope that this work will provide useful data points and
experience for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical graph neural nets can capture long-range interactions. (arXiv:2107.07432v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rampasek_L/0/1/0/all/0/1">Ladislav Ramp&#xe1;&#x161;ek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1">Guy Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07432">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) based on message passing between neighboring
nodes are known to be insufficient for capturing long-range interactions in
graphs. In this project we study hierarchical message passing models that
leverage a multi-resolution representation of a given graph. This facilitates
learning of features that span large receptive fields without loss of local
information, an aspect not studied in preceding work on hierarchical GNNs. We
introduce Hierarchical Graph Net (HGNet), which for any two connected nodes
guarantees existence of message-passing paths of at most logarithmic length
w.r.t. the input graph size. Yet, under mild assumptions, its internal
hierarchy maintains asymptotic size equivalent to that of the input graph. We
observe that our HGNet outperforms conventional stacking of GCN layers
particularly in molecular property prediction benchmarks. Finally, we propose
two benchmarking tasks designed to elucidate capability of GNNs to leverage
long-range interactions in graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clinical Relation Extraction Using Transformer-based Models. (arXiv:2107.08957v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zehao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08957">
                                    <div class="article-summary-box-inner">
                                        <span>The newly emerged transformer technology has a tremendous impact on NLP
research. In the general English domain, transformer-based models have achieved
state-of-the-art performances on various NLP benchmarks. In the clinical
domain, researchers also have investigated transformer models for clinical
applications. The goal of this study is to systematically explore three widely
used transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical
relation extraction and develop an open-source package with clinical
pre-trained transformer-based models to facilitate information extraction in
the clinical domain. We developed a series of clinical RE models based on three
transformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these
models using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2
challenges. We compared two classification strategies (binary vs. multi-class
classification) and investigated two approaches to generate candidate relations
in different experimental settings. In this study, we compared three
transformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We
demonstrated that the RoBERTa-clinical RE model achieved the best performance
on the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2
dataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our
results indicated that the binary classification strategy consistently
outperformed the multi-class classification strategy for clinical relation
extraction. Our methods and models are publicly available at
https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.
We believe this work will improve current practice on clinical relation
extraction and other related NLP tasks in the biomedical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certifiable Machine Unlearning for Linear Models. (arXiv:2106.15093v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahadevan_A/0/1/0/all/0/1">Ananth Mahadevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1">Michael Mathioudakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15093">
                                    <div class="article-summary-box-inner">
                                        <span>Machine unlearning is the task of updating machine learning (ML) models after
a subset of the training data they were trained on is deleted. Methods for the
task are desired to combine effectiveness and efficiency, i.e., they should
effectively &quot;unlearn&quot; deleted data, but in a way that does not require
excessive computation effort (e.g., a full retraining) for a small amount of
deletions. Such a combination is typically achieved by tolerating some amount
of approximation in the unlearning. In addition, laws and regulations in the
spirit of &quot;the right to be forgotten&quot; have given rise to requirements for
certifiability, i.e., the ability to demonstrate that the deleted data has
indeed been unlearned by the ML model.

In this paper, we present an experimental study of the three state-of-the-art
approximate unlearning methods for linear models and demonstrate the trade-offs
between efficiency, effectiveness and certifiability offered by each method. In
implementing the study, we extend some of the existing works and describe a
common ML pipeline to compare and evaluate the unlearning methods on six
real-world datasets and a variety of settings. We provide insights into the
effect of the quantity and distribution of the deleted data on ML models and
the performance of each unlearning method in different settings. We also
propose a practical online strategy to determine when the accumulated error
from approximate unlearning is large enough to warrant a full retrain of the ML
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale Food Prices. (arXiv:2107.12770v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Menculini_L/0/1/0/all/0/1">Lorenzo Menculini</a>, <a href="http://arxiv.org/find/cs/1/au:+Marini_A/0/1/0/all/0/1">Andrea Marini</a>, <a href="http://arxiv.org/find/cs/1/au:+Proietti_M/0/1/0/all/0/1">Massimiliano Proietti</a>, <a href="http://arxiv.org/find/cs/1/au:+Garinei_A/0/1/0/all/0/1">Alberto Garinei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozza_A/0/1/0/all/0/1">Alessio Bozza</a>, <a href="http://arxiv.org/find/cs/1/au:+Moretti_C/0/1/0/all/0/1">Cecilia Moretti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marconi_M/0/1/0/all/0/1">Marcello Marconi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12770">
                                    <div class="article-summary-box-inner">
                                        <span>Setting sale prices correctly is of great importance for firms, and the study
and forecast of prices time series is therefore a relevant topic not only from
a data science perspective but also from an economic and applicative one. In
this paper we examine different techniques to forecast sale prices applied by
an Italian food wholesaler, as a step towards the automation of pricing tasks
usually taken care by human workforce. We consider ARIMA models and compare
them to Prophet, a scalable forecasting tool by Facebook based on a generalized
additive model, and to deep learning models exploiting Long Short--Term Memory
(LSTM) and Convolutional Neural Networks (CNNs). ARIMA models are frequently
used in econometric analyses, providing a good benchmark for the problem under
study. Our results indicate that ARIMA models and LSTM neural networks perform
similarly for the forecasting task under consideration, while the combination
of CNNs and LSTMs attains the best overall accuracy, but requires more time to
be tuned. On the contrary, Prophet is quick and easy to use, but considerably
less accurate.t overall accuracy, but requires more time to be tuned. On the
contrary, Prophet is quick and easy to use, but considerably less accurate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Open-World Uncertainty Modeling for Confidence Calibration. (arXiv:2107.12628v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yezhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12628">
                                    <div class="article-summary-box-inner">
                                        <span>Confidence calibration is of great importance to the reliability of decisions
made by machine learning systems. However, discriminative classifiers based on
deep neural networks are often criticized for producing overconfident
predictions that fail to reflect the true correctness likelihood of
classification accuracy. We argue that such an inability to model uncertainty
is mainly caused by the closed-world nature in softmax: a model trained by the
cross-entropy loss will be forced to classify input into one of $K$ pre-defined
categories with high probability. To address this problem, we for the first
time propose a novel $K$+1-way softmax formulation, which incorporates the
modeling of open-world uncertainty as the extra dimension. To unify the
learning of the original $K$-way classification task and the extra dimension
that models uncertainty, we propose a novel energy-based objective function,
and moreover, theoretically prove that optimizing such an objective essentially
forces the extra dimension to capture the marginal data distribution. Extensive
experiments show that our approach, Energy-based Open-World Softmax
(EOW-Softmax), is superior to existing state-of-the-art methods in improving
confidence calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Classifier as Mutual Information Evaluator. (arXiv:2106.10471v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10471">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-entropy loss with softmax output is a standard choice to train neural
network classifiers. We give a new view of neural network classifiers with
softmax and cross-entropy as mutual information evaluators. We show that when
the dataset is balanced, training a neural network with cross-entropy maximises
the mutual information between inputs and labels through a variational form of
mutual information. Thereby, we develop a new form of softmax that also
converts a classifier to a mutual information evaluator when the dataset is
imbalanced. Experimental results show that the new form leads to better
classification accuracy, in particular for imbalanced datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Loop-Invariant Synthesis via Reinforcement Learning. (arXiv:2107.09766v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsukada_T/0/1/0/all/0/1">Takeshi Tsukada</a>, <a href="http://arxiv.org/find/cs/1/au:+Unno_H/0/1/0/all/0/1">Hiroshi Unno</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekiyama_T/0/1/0/all/0/1">Taro Sekiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Suenaga_K/0/1/0/all/0/1">Kohei Suenaga</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09766">
                                    <div class="article-summary-box-inner">
                                        <span>Loop-invariant synthesis is the basis of every program verification
procedure. Due to its undecidability in general, a tool for invariant synthesis
necessarily uses heuristics. Despite the common belief that the design of
heuristics is vital for the effective performance of a verifier, little work
has been performed toward obtaining the optimal heuristics for each
invariant-synthesis tool. Instead, developers have hand-tuned the heuristics of
tools. This study demonstrates that we can effectively and automatically learn
a good heuristic via reinforcement learning for an invariant synthesizer PCSat.
Our experiment shows that PCSat combined with the heuristic learned by
reinforcement learning outperforms the state-of-the-art solvers for this task.
To the best of our knowledge, this is the first work that investigates learning
the heuristics of an invariant synthesis tool.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint AP Probing and Scheduling: A Contextual Bandit Approach. (arXiv:2108.03297v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianyi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Ding Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_P/0/1/0/all/0/1">Parth H. Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zizhan Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03297">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a set of APs with unknown data rates that cooperatively serve a
mobile client. The data rate of each link is i.i.d. sampled from a distribution
that is unknown a priori. In contrast to traditional link scheduling problems
under uncertainty, we assume that in each time step, the device can probe a
subset of links before deciding which one to use. We model this problem as a
contextual bandit problem with probing (CBwP) and present an efficient
algorithm. We further establish the regret of our algorithm for links with
Bernoulli data rates. Our CBwP model is a novel extension of the classic
contextual bandit model and can potentially be applied to a large class of
sequential decision-making problems that involve joint probing and play under
uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principal Components Bias in Deep Neural Networks. (arXiv:2105.05553v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hacohen_G/0/1/0/all/0/1">Guy Hacohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinshall_D/0/1/0/all/0/1">Daphna Weinshall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05553">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work suggests that convolutional neural networks of different
architectures learn to classify images in the same order. To understand this
phenomenon, we revisit the over-parametrized deep linear network model. Our
asymptotic analysis, assuming that the hidden layers are wide enough, reveals
that the convergence rate of this model&#x27;s parameters is exponentially faster
along directions corresponding to the larger principal components of the data,
at a rate governed by the singular values. We term this convergence pattern the
Principal Components bias (PC-bias). We show how the PC-bias streamlines the
order of learning of both linear and non-linear networks, more prominently at
earlier stages of learning. We then compare our results to the simplicity bias,
showing that both biases can be seen independently, and affect the order of
learning in different ways. Finally, we discuss how the PC-bias may explain
some benefits of early stopping and its connection to PCA, and why deep
networks converge more slowly when given random labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Reachability Knowledge into a Multi-Spatial Graph Convolution Based Seq2Seq Model for Traffic Forecasting. (arXiv:2107.01528v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jiexia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Furong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Juanjuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1">Kejiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chengzhong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01528">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate traffic state prediction is the foundation of transportation control
and guidance. It is very challenging due to the complex spatiotemporal
dependencies in traffic data. Existing works cannot perform well for multi-step
traffic prediction that involves long future time period. The spatiotemporal
information dilution becomes serve when the time gap between input step and
predicted step is large, especially when traffic data is not sufficient or
noisy. To address this issue, we propose a multi-spatial graph convolution
based Seq2Seq model. Our main novelties are three aspects: (1) We enrich the
spatiotemporal information of model inputs by fusing multi-view features (time,
location and traffic states) (2) We build multiple kinds of spatial
correlations based on both prior knowledge and data-driven knowledge to improve
model performance especially in insufficient or noisy data cases. (3) A
spatiotemporal attention mechanism based on reachability knowledge is novelly
designed to produce high-level features fed into decoder of Seq2Seq directly to
ease information dilution. Our model is evaluated on two real world traffic
datasets and achieves better performance than other competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple Graph Learning for Scalable Multi-view Clustering. (arXiv:2106.15382v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tianyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Quanxue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15382">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based multi-view clustering has become an active topic due to the
efficiency in characterizing both the complex structure and relationship
between multimedia data. However, existing methods have the following
shortcomings: (1) They are inefficient or even fail for graph learning in large
scale due to the graph construction and eigen-decomposition. (2) They cannot
well exploit both the complementary information and spatial structure embedded
in graphs of different views. To well exploit complementary information and
tackle the scalability issue plaguing graph-based multi-view clustering, we
propose an efficient multiple graph learning model via a small number of anchor
points and tensor Schatten p-norm minimization. Specifically, we construct a
hidden and tractable large graph by anchor graph for each view and well exploit
complementary information embedded in anchor graphs of different views by
tensor Schatten p-norm regularizer. Finally, we develop an efficient algorithm,
which scales linearly with the data size, to solve our proposed model.
Extensive experimental results on several datasets indicate that our proposed
method outperforms some state-of-the-art multi-view clustering algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Canonical Saliency Maps: Decoding Deep Face Models. (arXiv:2105.01386v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+John_T/0/1/0/all/0/1">Thrupthi Ann John</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1">C V Jawahar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01386">
                                    <div class="article-summary-box-inner">
                                        <span>As Deep Neural Network models for face processing tasks approach human-like
performance, their deployment in critical applications such as law enforcement
and access control has seen an upswing, where any failure may have far-reaching
consequences. We need methods to build trust in deployed systems by making
their working as transparent as possible. Existing visualization algorithms are
designed for object recognition and do not give insightful results when applied
to the face domain. In this work, we present &#x27;Canonical Saliency Maps&#x27;, a new
method that highlights relevant facial areas by projecting saliency maps onto a
canonical face model. We present two kinds of Canonical Saliency Maps:
image-level maps and model-level maps. Image-level maps highlight facial
features responsible for the decision made by a deep face model on a given
image, thus helping to understand how a DNN made a prediction on the image.
Model-level maps provide an understanding of what the entire DNN model focuses
on in each task and thus can be used to detect biases in the model. Our
qualitative and quantitative results show the usefulness of the proposed
canonical saliency maps, which can be used on any deep face model regardless of
the architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for L3 Slice Localization in Sarcopenia Assessment. (arXiv:2107.12800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laousy_O/0/1/0/all/0/1">Othmane Laousy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12800">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcopenia is a medical condition characterized by a reduction in muscle mass
and function. A quantitative diagnosis technique consists of localizing the CT
slice passing through the middle of the third lumbar area (L3) and segmenting
muscles at this level. In this paper, we propose a deep reinforcement learning
method for accurate localization of the L3 CT slice. Our method trains a
reinforcement learning agent by incentivizing it to discover the right
position. Specifically, a Deep Q-Network is trained to find the best policy to
follow for this problem. Visualizing the training process shows that the agent
mimics the scrolling of an experienced radiologist. Extensive experiments
against other state-of-the-art deep learning based methods for L3 localization
prove the superiority of our technique which performs well even with a limited
amount of data and annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Visual Engagement Signals for Representation Learning. (arXiv:2104.07767v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Menglin Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reiter_A/0/1/0/all/0/1">Austin Reiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1">Claire Cardie</a>, <a href="http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1">Serge Belongie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07767">
                                    <div class="article-summary-box-inner">
                                        <span>Visual engagement in social media platforms comprises interactions with photo
posts including comments, shares, and likes. In this paper, we leverage such
visual engagement clues as supervisory signals for representation learning.
However, learning from engagement signals is non-trivial as it is not clear how
to bridge the gap between low-level visual information and high-level social
interactions. We present VisE, a weakly supervised learning approach, which
maps social images to pseudo labels derived by clustered engagement signals. We
then study how models trained in this way benefit subjective downstream
computer vision tasks such as emotion recognition or political bias detection.
Through extensive studies, we empirically demonstrate the effectiveness of VisE
across a diverse set of classification tasks beyond the scope of conventional
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PIM-DRAM: Accelerating Machine Learning Workloads using Processing in Commodity DRAM. (arXiv:2105.03736v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Sourjya Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mustafa Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Anand Raghunathan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03736">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have transformed the field of machine learning
and are widely deployed in many applications involving image, video, speech and
natural language processing. The increasing compute demands of DNNs have been
widely addressed through Graphics Processing Units (GPUs) and specialized
accelerators. However, as model sizes grow, these von Neumann architectures
require very high memory bandwidth to keep the processing elements utilized as
a majority of the data resides in the main memory. Processing in memory has
been proposed as a promising solution for the memory wall bottleneck for ML
workloads. In this work, we propose a new DRAM-based processing-in-memory (PIM)
multiplication primitive coupled with intra-bank accumulation to accelerate
matrix vector operations in ML workloads. The proposed multiplication primitive
adds &lt; 1% area overhead and does not require any change in the DRAM
peripherals. Therefore, the proposed multiplication can be easily adopted in
commodity DRAM chips. Subsequently, we design a DRAM-based PIM architecture,
data mapping scheme and dataflow for executing DNNs within DRAM. System
evaluations performed on networks like AlexNet, VGG16 and ResNet18 show that
the proposed architecture, mapping, and data flow can provide up to 19.5x
speedup over an NVIDIA Titan Xp GPU highlighting the need to overcome the
memory bottleneck in future generations of DNN hardware.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Informative Class Activation Maps. (arXiv:2106.10472v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10472">
                                    <div class="article-summary-box-inner">
                                        <span>We study how to evaluate the quantitative information content of a region
within an image for a particular label. To this end, we bridge class activation
maps with information theory. We develop an informative class activation map
(infoCAM). Given a classification task, infoCAM depict how to accumulate
information of partial regions to that of the entire image toward a label.
Thus, we can utilise infoCAM to locate the most informative features for a
label. When applied to an image classification task, infoCAM performs better
than the traditional classification map in the weakly supervised object
localisation task. We achieve state-of-the-art results on Tiny-ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Selection of Informative Path Planning Strategies via Reinforcement Learning. (arXiv:2108.06618v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_T/0/1/0/all/0/1">Taeyeong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cielniak_G/0/1/0/all/0/1">Grzegorz Cielniak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06618">
                                    <div class="article-summary-box-inner">
                                        <span>In our previous work, we designed a systematic policy to prioritize sampling
locations to lead significant accuracy improvement in spatial interpolation by
using the prediction uncertainty of Gaussian Process Regression (GPR) as
&quot;attraction force&quot; to deployed robots in path planning. Although the
integration with Traveling Salesman Problem (TSP) solvers was also shown to
produce relatively short travel distance, we here hypothesise several factors
that could decrease the overall prediction precision as well because
sub-optimal locations may eventually be included in their paths. To address
this issue, in this paper, we first explore &quot;local planning&quot; approaches
adopting various spatial ranges within which next sampling locations are
prioritized to investigate their effects on the prediction performance as well
as incurred travel distance. Also, Reinforcement Learning (RL)-based high-level
controllers are trained to adaptively produce blended plans from a particular
set of local planners to inherit unique strengths from that selection depending
on latest prediction states. Our experiments on use cases of temperature
monitoring robots demonstrate that the dynamic mixtures of planners can not
only generate sophisticated, informative plans that a single planner could not
create alone but also ensure significantly reduced travel distances at no cost
of prediction reliability without any assist of additional modules for shortest
path calculation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and Accurate Low-Rank Tensor Completion Methods Based on QR Decomposition and $L_{2,1}$ Norm Minimization. (arXiv:2108.03002v3 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1">Hongbing Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1">Xinyi Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_H/0/1/0/all/0/1">Hongtao Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1">Yajing Li</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinlin Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03002">
                                    <div class="article-summary-box-inner">
                                        <span>More recently, an Approximate SVD Based on Qatar Riyal (QR) Decomposition
(CSVD-QR) method for matrix complete problem is presented, whose computational
complexity is $O(r^2(m+n))$, which is mainly due to that $r$ is far less than
$\min\{m,n\}$, where $r$ represents the largest number of singular values of
matrix $X$. What is particularly interesting is that after replacing the
nuclear norm with the $L_{2,1}$ norm proposed based on this decomposition, as
the upper bound of the nuclear norm, when the intermediate matrix $D$ in its
decomposition is close to the diagonal matrix, it will converge to the nuclear
norm, and is exactly equal, when the $D$ matrix is equal to the diagonal
matrix, to the nuclear norm, which ingeniously avoids the calculation of the
singular value of the matrix. To the best of our knowledge, there is no
literature to generalize and apply it to solve tensor complete problems.
Inspired by this, in this paper we propose a class of tensor minimization model
based on $L_{2,1}$ norm and CSVD-QR method for the tensor complete problem,
which is convex and therefore has a global minimum solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signal Processing on the Permutahedron: Tight Spectral Frames for Ranked Data Analysis. (arXiv:2103.04150v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yilin Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+DeJong_J/0/1/0/all/0/1">Jennifer DeJong</a>, <a href="http://arxiv.org/find/stat/1/au:+Halverson_T/0/1/0/all/0/1">Tom Halverson</a>, <a href="http://arxiv.org/find/stat/1/au:+Shuman_D/0/1/0/all/0/1">David I Shuman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04150">
                                    <div class="article-summary-box-inner">
                                        <span>Ranked data sets, where m judges/voters specify a preference ranking of n
objects/candidates, are increasingly prevalent in contexts such as political
elections, computer vision, recommender systems, and bioinformatics. The vote
counts for each ranking can be viewed as an n! data vector lying on the
permutahedron, which is a Cayley graph of the symmetric group with vertices
labeled by permutations and an edge when two permutations differ by an adjacent
transposition. Leveraging combinatorial representation theory and recent
progress in signal processing on graphs, we investigate a novel, scalable
transform method to interpret and exploit structure in ranked data. We
represent data on the permutahedron using an overcomplete dictionary of atoms,
each of which captures both smoothness information about the data (typically
the focus of spectral graph decomposition methods in graph signal processing)
and structural information about the data (typically the focus of symmetry
decomposition methods from representation theory). These atoms have a more
naturally interpretable structure than any known basis for signals on the
permutahedron, and they form a Parseval frame, ensuring beneficial numerical
properties such as energy preservation. We develop specialized algorithms and
open software that take advantage of the symmetry and structure of the
permutahedron to improve the scalability of the proposed method, making it more
applicable to the high-dimensional ranked data found in applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image2Reverb: Cross-Modal Reverb Impulse Response Synthesis. (arXiv:2103.14201v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1">Nikhil Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mentch_J/0/1/0/all/0/1">Jeff Mentch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_J/0/1/0/all/0/1">Jerry Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Beveridge_M/0/1/0/all/0/1">Matthew Beveridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1">Iddo Drori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14201">
                                    <div class="article-summary-box-inner">
                                        <span>Measuring the acoustic characteristics of a space is often done by capturing
its impulse response (IR), a representation of how a full-range stimulus sound
excites it. This work generates an IR from a single image, which can then be
applied to other signals using convolution, simulating the reverberant
characteristics of the space shown in the image. Recording these IRs is both
time-intensive and expensive, and often infeasible for inaccessible locations.
We use an end-to-end neural network architecture to generate plausible audio
impulse responses from single images of acoustic environments. We evaluate our
method both by comparisons to ground truth data and by human expert evaluation.
We demonstrate our approach by generating plausible impulse responses from
diverse settings and formats including well known places, musical halls, rooms
in paintings, images from animations and computer games, synthetic environments
generated from text, panoramic images, and video conference backgrounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferability of Neural Network-based De-identification Systems. (arXiv:2102.08517v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kahyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobbins_N/0/1/0/all/0/1">Nicholas J. Dobbins</a>, <a href="http://arxiv.org/find/cs/1/au:+McInnes_B/0/1/0/all/0/1">Bridget McInnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1">Meliha Yetisgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1">&#xd6;zlem Uzuner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08517">
                                    <div class="article-summary-box-inner">
                                        <span>Methods and Materials: We investigated transferability of neural
network-based de-identification sys-tems with and without domain
generalization. We used two domain generalization approaches: a novel approach
Joint-Domain Learning (JDL) as developed in this paper, and a state-of-the-art
domain general-ization approach Common-Specific Decomposition (CSD) from the
literature. First, we measured trans-ferability from a single external source.
Second, we used two external sources and evaluated whether domain
generalization can improve transferability of de-identification models across
domains which rep-resent different note types from the same institution. Third,
using two external sources with in-domain training data, we studied whether
external source data are useful even in cases where sufficient in-domain
training data are available. Finally, we investigated transferability of the
de-identification mod-els across institutions. Results and Conclusions: We
found transferability from a single external source gave inconsistent re-sults.
Using additional external sources consistently yielded an F1-score of
approximately 80%, but domain generalization was not always helpful to improve
transferability. We also found that external sources were useful even in cases
where in-domain training data were available by reducing the amount of needed
in-domain training data or by improving performance. Transferability across
institutions was differed by note type and annotation label. External sources
from a different institution were also useful to further improve performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low Dimensional Landscape Hypothesis is True: DNNs can be Trained in Tiny Subspaces. (arXiv:2103.11154v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1">Lei Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Q/0/1/0/all/0/1">Qinghua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yipeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11154">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) usually contain massive parameters, but there is
redundancy such that it is guessed that the DNNs could be trained in
low-dimensional subspaces. In this paper, we propose a Dynamic Linear
Dimensionality Reduction (DLDR) based on low-dimensional properties of the
training trajectory. The reduction is efficient, which is supported by
comprehensive experiments: optimization in 40 dimensional spaces can achieve
comparable performance as regular training over thousands or even millions of
parameters. Since there are only a few optimization variables, we develop a
quasi-Newton-based algorithm and also obtain robustness against label noises,
which are two follow-up experiments to show the advantages of finding
low-dimensional subspaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09261">
                                    <div class="article-summary-box-inner">
                                        <span>The existence of multiple datasets for sarcasm detection prompts us to apply
transfer learning to exploit their commonality. The adversarial neural transfer
(ANT) framework utilizes multiple loss terms that encourage the source-domain
and the target-domain feature distributions to be similar while optimizing for
domain-specific performance. However, these objectives may be in conflict,
which can lead to optimization difficulties and sometimes diminished transfer.
We propose a generalized latent optimization strategy that allows different
losses to accommodate each other and improves training dynamics. The proposed
method outperforms transfer learning and meta-learning baselines. In
particular, we achieve 10.02% absolute performance gain over the previous state
of the art on the iSarcasm dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private Federated Knowledge Graphs Embedding. (arXiv:2105.07615v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_V/0/1/0/all/0/1">Vincent Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianxin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07615">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge graph embedding plays an important role in knowledge
representation, reasoning, and data mining applications. However, for multiple
cross-domain knowledge graphs, state-of-the-art embedding models cannot make
full use of the data from different knowledge domains while preserving the
privacy of exchanged data. In addition, the centralized embedding model may not
scale to the extensive real-world knowledge graphs. Therefore, we propose a
novel decentralized scalable learning framework, \emph{Federated Knowledge
Graphs Embedding} (FKGE), where embeddings from different knowledge graphs can
be learnt in an asynchronous and peer-to-peer manner while being
privacy-preserving. FKGE exploits adversarial generation between pairs of
knowledge graphs to translate identical entities and relations of different
domains into near embedding spaces. In order to protect the privacy of the
training data, FKGE further implements a privacy-preserving neural network
structure to guarantee no raw data leakage. We conduct extensive experiments to
evaluate FKGE on 11 knowledge graphs, demonstrating a significant and
consistent improvement in model quality with at most 17.85\% and 7.90\%
increases in performance on triple classification and link prediction tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1">Vinod Kumar Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sukhdeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anuj Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06663">
                                    <div class="article-summary-box-inner">
                                        <span>Handwritten character recognition (HCR) is a challenging learning problem in
pattern recognition, mainly due to similarity in structure of characters,
different handwriting styles, noisy datasets and a large variety of languages
and scripts. HCR problem is studied extensively for a few decades but there is
very limited research on script independent models. This is because of factors,
like, diversity of scripts, focus of the most of conventional research efforts
on handcrafted feature extraction techniques which are language/script specific
and are not always available, and unavailability of public datasets and codes
to reproduce the results. On the other hand, deep learning has witnessed huge
success in different areas of pattern recognition, including HCR, and provides
end-to-end learning, i.e., automated feature extraction and recognition. In
this paper, we have proposed a novel deep learning architecture which exploits
transfer learning and image-augmentation for end-to-end learning for script
independent handwritten character recognition, called HCR-Net. The network is
based on a novel transfer learning approach for HCR, where some of lower layers
of a pre-trained VGG16 network are utilised. Due to transfer learning and
image-augmentation, HCR-Net provides faster training, better performance and
better generalisations. The experimental results on publicly available datasets
of Bangla, Punjabi, Hindi, English, Swedish, Urdu, Farsi, Tibetan, Kannada,
Malayalam, Telugu, Marathi, Nepali and Arabic languages prove the efficacy of
HCR-Net and establishes several new benchmarks. For reproducibility of the
results and for the advancements of the HCR research, complete code is publicly
released at \href{https://github.com/jmdvinodjmd/HCR-Net}{GitHub}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weak Adaptation Learning -- Addressing Cross-domain Data Insufficiency with Weak Annotator. (arXiv:2102.07358v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shichao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lixu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07358">
                                    <div class="article-summary-box-inner">
                                        <span>Data quantity and quality are crucial factors for data-driven learning
methods. In some target problem domains, there are not many data samples
available, which could significantly hinder the learning process. While data
from similar domains may be leveraged to help through domain adaptation,
obtaining high-quality labeled data for those source domains themselves could
be difficult or costly. To address such challenges on data insufficiency for
classification problem in a target domain, we propose a weak adaptation
learning (WAL) approach that leverages unlabeled data from a similar source
domain, a low-cost weak annotator that produces labels based on task-specific
heuristics, labeling rules, or other methods (albeit with inaccuracy), and a
small amount of labeled data in the target domain. Our approach first conducts
a theoretical analysis on the error bound of the trained classifier with
respect to the data quantity and the performance of the weak annotator, and
then introduces a multi-stage weak adaptation learning method to learn an
accurate classifier by lowering the error bound. Our experiments demonstrate
the effectiveness of our approach in learning an accurate classifier with
limited labeled data in the target domain and unlabeled data in the source
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Greedy Algorithm for Quantizing Neural Networks. (arXiv:2010.15979v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lybrand_E/0/1/0/all/0/1">Eric Lybrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1">Rayan Saab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15979">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new computationally efficient method for quantizing the weights
of pre- trained neural networks that is general enough to handle both
multi-layer perceptrons and convolutional neural networks. Our method
deterministically quantizes layers in an iterative fashion with no complicated
re-training required. Specifically, we quantize each neuron, or hidden unit,
using a greedy path-following algorithm. This simple algorithm is equivalent to
running a dynamical system, which we prove is stable for quantizing a
single-layer neural network (or, alternatively, for quantizing the first layer
of a multi-layer network) when the training data are Gaussian. We show that
under these assumptions, the quantization error decays with the width of the
layer, i.e., its level of over-parametrization. We provide numerical
experiments, on multi-layer networks, to illustrate the performance of our
methods on MNIST and CIFAR10 data, as well as for quantizing the VGG16 network
using ImageNet data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimising quantifier variance under prior probability shift. (arXiv:2107.08209v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tasche_D/0/1/0/all/0/1">Dirk Tasche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08209">
                                    <div class="article-summary-box-inner">
                                        <span>For the binary prevalence quantification problem under prior probability
shift, we determine the asymptotic variance of the maximum likelihood
estimator. We find that it is a function of the Brier score for the regression
of the class label against the features under the test data set distribution.
This observation suggests that optimising the accuracy of a base classifier on
the training data set helps to reduce the variance of the related quantifier on
the test data set. Therefore, we also point out training criteria for the base
classifier that imply optimisation of both of the Brier scores on the training
and the test data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Graph Convolutional Network Training with GPU-Oriented Data Communication Architecture. (arXiv:2103.03330v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1">Seung Won Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Sitao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hidayetoglu_M/0/1/0/all/0/1">Mert Hidayeto&#x11f;lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jinjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_E/0/1/0/all/0/1">Eiman Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Deming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwu_W/0/1/0/all/0/1">Wen-mei Hwu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03330">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Convolutional Networks (GCNs) are increasingly adopted in large-scale
graph-based recommender systems. Training GCN requires the minibatch generator
traversing graphs and sampling the sparsely located neighboring nodes to obtain
their features. Since real-world graphs often exceed the capacity of GPU
memory, current GCN training systems keep the feature table in host memory and
rely on the CPU to collect sparse features before sending them to the GPUs.
This approach, however, puts tremendous pressure on host memory bandwidth and
the CPU. This is because the CPU needs to (1) read sparse features from memory,
(2) write features into memory as a dense format, and (3) transfer the features
from memory to the GPUs. In this work, we propose a novel GPU-oriented data
communication approach for GCN training, where GPU threads directly access
sparse features in host memory through zero-copy accesses without much CPU
help. By removing the CPU gathering stage, our method significantly reduces the
consumption of the host resources and data access latency. We further present
two important techniques to achieve high host memory access efficiency by the
GPU: (1) automatic data access address alignment to maximize PCIe packet
efficiency, and (2) asynchronous zero-copy access and kernel execution to fully
overlap data transfer with training. We incorporate our method into PyTorch and
evaluate its effectiveness using several graphs with sizes up to 111 million
nodes and 1.6 billion edges. In a multi-GPU training setup, our method is
65-92% faster than the conventional data transfer method, and can even match
the performance of all-in-GPU-memory training for some graphs that fit in GPU
memory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blockchain-based Trustworthy Federated Learning Architecture. (arXiv:2108.06912v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Sin Kit Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qinghua Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Paik_H/0/1/0/all/0/1">Hye-Young Paik</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Liming Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06912">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an emerging privacy-preserving AI technique where
clients (i.e., organisations or devices) train models locally and formulate a
global model based on the local model updates without transferring local data
externally. However, federated learning systems struggle to achieve
trustworthiness and embody responsible AI principles. In particular, federated
learning systems face accountability and fairness challenges due to
multi-stakeholder involvement and heterogeneity in client data distribution. To
enhance the accountability and fairness of federated learning systems, we
present a blockchain-based trustworthy federated learning architecture. We
first design a smart contract-based data-model provenance registry to enable
accountability. Additionally, we propose a weighted fair data sampler algorithm
to enhance fairness in training data. We evaluate the proposed approach using a
COVID-19 X-ray detection use case. The evaluation results show that the
approach is feasible to enable accountability and improve fairness. The
proposed algorithm can achieve better performance than the default federated
learning setting in terms of the model&#x27;s generalisation and accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Unsupervised Visual Representation Learning from Decentralized Data. (arXiv:2108.06492v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_X/0/1/0/all/0/1">Xin Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06492">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised representation learning has achieved outstanding performances
using centralized data available on the Internet. However, the increasing
awareness of privacy protection limits sharing of decentralized unlabeled image
data that grows explosively in multiple parties (e.g., mobile phones and
cameras). As such, a natural problem is how to leverage these data to learn
visual representations for downstream tasks while preserving data privacy. To
address this problem, we propose a novel federated unsupervised learning
framework, FedU. In this framework, each party trains models from unlabeled
data independently using contrastive learning with an online network and a
target network. Then, a central server aggregates trained models and updates
clients&#x27; models with the aggregated model. It preserves data privacy as each
party only has access to its raw data. Decentralized data among multiple
parties are normally non-independent and identically distributed (non-IID),
leading to performance degradation. To tackle this challenge, we propose two
simple but effective methods: 1) We design the communication protocol to upload
only the encoders of online networks for server aggregation and update them
with the aggregated encoder; 2) We introduce a new module to dynamically decide
how to update predictors based on the divergence caused by non-IID. The
predictor is the other component of the online network. Extensive experiments
and ablations demonstrate the effectiveness and significance of FedU. It
outperforms training with only one party by over 5% and other methods by over
14% in linear and semi-supervised evaluation on non-IID data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reducing the Communication Cost of Federated Learning through Multistage Optimization. (arXiv:2108.06869v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_C/0/1/0/all/0/1">Charlie Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Thekumparampil_K/0/1/0/all/0/1">Kiran K. Thekumparampil</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanti_G/0/1/0/all/0/1">Giulia Fanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Sewoong Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06869">
                                    <div class="article-summary-box-inner">
                                        <span>A central question in federated learning (FL) is how to design optimization
algorithms that minimize the communication cost of training a model over
heterogeneous data distributed across many clients. A popular technique for
reducing communication is the use of local steps, where clients take multiple
optimization steps over local data before communicating with the server (e.g.,
FedAvg, SCAFFOLD). This contrasts with centralized methods, where clients take
one optimization step per communication round (e.g., Minibatch SGD). A recent
lower bound on the communication complexity of first-order methods shows that
centralized methods are optimal over highly-heterogeneous data, whereas local
methods are optimal over purely homogeneous data [Woodworth et al., 2020]. For
intermediate heterogeneity levels, no algorithm is known to match the lower
bound. In this paper, we propose a multistage optimization scheme that nearly
matches the lower bound across all heterogeneity levels. The idea is to first
run a local method up to a heterogeneity-induced error floor; next, we switch
to a centralized method for the remaining steps. Our analysis may help explain
empirically-successful stepsize decay methods in FL [Charles et al., 2020;
Reddi et al., 2020]. We demonstrate the scheme&#x27;s practical utility in image
classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Breast Lesion Detection in Ultrafast DCE-MRI Using Deep Learning. (arXiv:2102.03932v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ayatollahi_F/0/1/0/all/0/1">Fazael Ayatollahi</a> (1 and 2), <a href="http://arxiv.org/find/eess/1/au:+Shokouhi_S/0/1/0/all/0/1">Shahriar B. Shokouhi</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Mann_R/0/1/0/all/0/1">Ritse M. Mann</a> (2), <a href="http://arxiv.org/find/eess/1/au:+Teuwen_J/0/1/0/all/0/1">Jonas Teuwen</a> (2 and 3) ((1) Electrical Engineering Department, Iran University of Science and Technology (IUST), Tehran, Iran, (2) Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, the Netherlands, (3) Department of Radiation Oncology, Netherlands Cancer Institute, Amsterdam, the Netherlands)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03932">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: We propose a deep learning-based computer-aided detection (CADe)
method to detect breast lesions in ultrafast DCE-MRI sequences. This method
uses both the three-dimensional spatial information and temporal information
obtained from the early-phase of the dynamic acquisition. Methods: The proposed
CADe method, based on a modified 3D RetinaNet model, operates on ultrafast T1
weighted sequences, which are preprocessed for motion compensation, temporal
normalization, and are cropped before passing into the model. The model is
optimized to enable the detection of relatively small breast lesions in a
screening setting, focusing on detection of lesions that are harder to
differentiate from confounding structures inside the breast. Results: The
method was developed based on a dataset consisting of 489 ultrafast MRI studies
obtained from 462 patients containing a total of 572 lesions (365 malignant,
207 benign) and achieved a detection rate, sensitivity, and detection rate of
benign lesions of 0.90 (0.876-0.934), 0.95 (0.934-0.980), and 0.81
(0.751-0.871) at 4 false positives per normal breast with 10-fold
cross-testing, respectively. Conclusions: The deep learning architecture used
for the proposed CADe application can efficiently detect benign and malignant
lesions on ultrafast DCE-MRI. Furthermore, utilizing the less visible hard-to
detect-lesions in training improves the learning process and, subsequently,
detection of malignant breast lesions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ModelPS: An Interactive and Collaborative Platform for Editing Pre-trained Models at Scale. (arXiv:2105.08275v3 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huaizheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shanshan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yong Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08275">
                                    <div class="article-summary-box-inner">
                                        <span>AI engineering has emerged as a crucial discipline to democratize deep neural
network (DNN) models among software developers with a diverse background. In
particular, altering these DNN models in the deployment stage posits a
tremendous challenge. In this research, we propose and develop a low-code
solution, ModelPS (an acronym for &quot;Model Photoshop&quot;), to enable and empower
collaborative DNN model editing and intelligent model serving. The ModelPS
solution embodies two transformative features: 1) a user-friendly web interface
for a developer team to share and edit DNN models pictorially, in a low-code
fashion, and 2) a model genie engine in the backend to aid developers in
customizing model editing configurations for given deployment requirements or
constraints. Our case studies with a wide range of deep learning (DL) models
show that the system can tremendously reduce both development and communication
overheads with improved productivity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focus on the Positives: Self-Supervised Learning for Biodiversity Monitoring. (arXiv:2108.06435v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pantazis_O/0/1/0/all/0/1">Omiros Pantazis</a>, <a href="http://arxiv.org/find/cs/1/au:+Brostow_G/0/1/0/all/0/1">Gabriel Brostow</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_K/0/1/0/all/0/1">Kate Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1">Oisin Mac Aodha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06435">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of learning self-supervised representations from
unlabeled image collections. Unlike existing approaches that attempt to learn
useful features by maximizing similarity between augmented versions of each
input image or by speculatively picking negative samples, we instead also make
use of the natural variation that occurs in image collections that are captured
using static monitoring cameras. To achieve this, we exploit readily available
context data that encodes information such as the spatial and temporal
relationships between the input images. We are able to learn representations
that are surprisingly effective for downstream supervised classification, by
first identifying high probability positive pairs at training time, i.e. those
images that are likely to depict the same visual concept. For the critical task
of global biodiversity monitoring, this results in image features that can be
adapted to challenging visual species classification tasks with limited human
supervision. We present results on four different camera trap image
collections, across three different families of self-supervised learning
methods, and show that careful image selection at training time results in
superior performance compared to existing baselines such as conventional
self-supervised training and transfer learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants. (arXiv:2108.06633v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidharan_D/0/1/0/all/0/1">Deepak Muralidharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1">Joel Ruben Antony Moniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1">Stephen Pulman</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_M/0/1/0/all/0/1">Megan Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jingjing Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Jason Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Acero_A/0/1/0/all/0/1">Alex Acero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06633">
                                    <div class="article-summary-box-inner">
                                        <span>Named entity recognition (NER) is usually developed and tested on text from
well-written sources. However, in intelligent voice assistants, where NER is an
important component, input to NER may be noisy because of user or speech
recognition error. In applications, entity labels may change frequently, and
non-textual properties like topicality or popularity may be needed to choose
among alternatives.

We describe a NER system intended to address these problems. We test and
train this system on a proprietary user-derived dataset. We compare with a
baseline text-only NER system; the baseline enhanced with external gazetteers;
and the baseline enhanced with the search and indirect labelling techniques we
describe below. The final configuration gives around 6% reduction in NER error
rate. We also show that this technique improves related tasks, such as semantic
parsing, with an improvement of up to 5% in error rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying and Exploiting Structures for Reliable Deep Learning. (arXiv:2108.07083v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sanyal_A/0/1/0/all/0/1">Amartya Sanyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07083">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning research has recently witnessed an impressively fast-paced
progress in a wide range of tasks including computer vision, natural language
processing, and reinforcement learning. The extraordinary performance of these
systems often gives the impression that they can be used to revolutionise our
lives for the better. However, as recent works point out, these systems suffer
from several issues that make them unreliable for use in the real world,
including vulnerability to adversarial attacks (Szegedy et al. [248]), tendency
to memorise noise (Zhang et al. [292]), being over-confident on incorrect
predictions (miscalibration) (Guo et al. [99]), and unsuitability for handling
private data (Gilad-Bachrach et al. [88]). In this thesis, we look at each of
these issues in detail, investigate their causes, and propose computationally
cheap algorithms for mitigating them in practice. To do this, we identify
structures in deep neural networks that can be exploited to mitigate the above
causes of unreliability of deep learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Event2Graph: Event-driven Bipartite Graph for Multivariate Time-series Anomaly Detection. (arXiv:2108.06783v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuhang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_M/0/1/0/all/0/1">Mengting Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yusan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06783">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling inter-dependencies between time-series is the key to achieve high
performance in anomaly detection for multivariate time-series data. The
de-facto solution to model the dependencies is to feed the data into a
recurrent neural network (RNN). However, the fully connected network structure
underneath the RNN (either GRU or LSTM) assumes a static and complete
dependency graph between time-series, which may not hold in many real-world
applications. To alleviate this assumption, we propose a dynamic bipartite
graph structure to encode the inter-dependencies between time-series. More
concretely, we model time series as one type of nodes, and the time series
segments (regarded as event) as another type of nodes, where the edge between
two types of nodes describe a temporal pattern occurred on a specific time
series at a certain time. Based on this design, relations between time series
can be explicitly modelled via dynamic connections to event nodes, and the
multivariate time-series anomaly detection problem can be formulated as a
self-supervised, edge stream prediction problem in dynamic graphs. We conducted
extensive experiments to demonstrate the effectiveness of the design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08435">
                                    <div class="article-summary-box-inner">
                                        <span>Since the Lipschitz properties of convolutional neural networks (CNNs) are
widely considered to be related to adversarial robustness, we theoretically
characterize the $\ell_1$ norm and $\ell_\infty$ norm of 2D multi-channel
convolutional layers and provide efficient methods to compute the exact
$\ell_1$ norm and $\ell_\infty$ norm. Based on our theorem, we propose a novel
regularization method termed norm decay, which can effectively reduce the norms
of convolutional layers and fully-connected layers. Experiments show that
norm-regularization methods, including norm decay, weight decay, and singular
value clipping, can improve generalization of CNNs. However, they can slightly
hurt adversarial robustness. Observing this unexpected phenomenon, we compute
the norms of layers in the CNNs trained with three different adversarial
training frameworks and surprisingly find that adversarially robust CNNs have
comparable or even larger layer norms than their non-adversarially robust
counterparts. Furthermore, we prove that under a mild assumption, adversarially
robust classifiers can be achieved using neural networks, and an adversarially
robust neural network can have an arbitrarily large Lipschitz constant. For
this reason, enforcing small norms on CNN layers may be neither necessary nor
effective in achieving adversarial robustness. The code is available at
https://github.com/youweiliang/norm_robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guarantees on learning depth-2 neural networks under a data-poisoning attack. (arXiv:2005.01699v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karmakar_S/0/1/0/all/0/1">Sayar Karmakar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1">Anirbit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Muthukumar_R/0/1/0/all/0/1">Ramchandran Muthukumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01699">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we study the possibility of defending against &quot;data-poisoning&quot;
attacks while learning a neural net. We focus on the supervised learning setup
for a class of finite-sized depth-2 nets - which include the standard single
filter convolutional nets. For this setup we attempt to learn the true label
generating weights in the presence of a malicious oracle doing stochastic
bounded and additive adversarial distortions on the true labels being accessed
by the algorithm during training. For the non-gradient stochastic algorithm
that we instantiate we prove (worst case nearly optimal) trade-offs among the
magnitude of the adversarial attack, the accuracy, and the confidence achieved
by the proposed algorithm. Additionally, our algorithm uses mini-batching and
we keep track of how the mini-batch size affects the convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Streaming Approach For Efficient Batched Beam Search. (arXiv:2010.02164v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_V/0/1/0/all/0/1">Violet Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+DeNero_J/0/1/0/all/0/1">John DeNero</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02164">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient batching strategy for variable-length decoding on GPU
architectures. During decoding, when candidates terminate or are pruned
according to heuristics, our streaming approach periodically &quot;refills&quot; the
batch before proceeding with a selected subset of candidates. We apply our
method to variable-width beam search on a state-of-the-art machine translation
model. Our method decreases runtime by up to 71% compared to a fixed-width beam
search baseline and 17% compared to a variable-width baseline, while matching
baselines&#x27; BLEU. Finally, experiments show that our method can speed up
decoding in other domains, such as semantic and syntactic parsing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting. (arXiv:2007.03260v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xiaohan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_T/0/1/0/all/0/1">Tianxiang Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jianchao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jungong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuchen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guiguang Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03260">
                                    <div class="article-summary-box-inner">
                                        <span>We propose ResRep, a novel method for lossless channel pruning (a.k.a. filter
pruning), which slims down a CNN by reducing the width (number of output
channels) of convolutional layers. Inspired by the neurobiology research about
the independence of remembering and forgetting, we propose to re-parameterize a
CNN into the remembering parts and forgetting parts, where the former learn to
maintain the performance and the latter learn to prune. Via training with
regular SGD on the former but a novel update rule with penalty gradients on the
latter, we realize structured sparsity. Then we equivalently merge the
remembering and forgetting parts into the original architecture with narrower
layers. In this sense, ResRep can be viewed as a successful application of
Structural Re-parameterization. Such a methodology distinguishes ResRep from
the traditional learning-based pruning paradigm that applies a penalty on
parameters to produce sparsity, which may suppress the parameters essential for
the remembering. ResRep slims down a standard ResNet-50 with 76.15% accuracy on
ImageNet to a narrower one with only 45% FLOPs and no accuracy drop, which is
the first to achieve lossless pruning with such a high compression ratio. The
code and models are at https://github.com/DingXiaoH/ResRep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on GAN Acceleration Using Memory Compression Technique. (arXiv:2108.06626v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tantawy_D/0/1/0/all/0/1">Dina Tantawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahran_M/0/1/0/all/0/1">Mohamed Zahran</a>, <a href="http://arxiv.org/find/cs/1/au:+Wassal_A/0/1/0/all/0/1">Amr Wassal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06626">
                                    <div class="article-summary-box-inner">
                                        <span>Since its invention, Generative adversarial networks (GANs) have shown
outstanding results in many applications. Generative Adversarial Networks are
powerful yet, resource-hungry deep-learning models. Their main difference from
ordinary deep learning models is the nature of their output. For example, GAN
output can be a whole image versus other models detecting objects or
classifying images. Thus, the architecture and numeric precision of the network
affect the quality and speed of the solution. Hence, accelerating GANs is
pivotal. Accelerating GANs can be classified into three main tracks: (1) Memory
compression, (2) Computation optimization, and (3) Data-flow optimization.
Because data transfer is the main source of energy usage, memory compression
leads to the most savings. Thus, in this paper, we survey memory compression
techniques for CNN-Based GANs. Additionally, the paper summarizes opportunities
and challenges in GANs acceleration and suggests open research problems to be
further investigated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time. (arXiv:2108.06721v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasery_A/0/1/0/all/0/1">Anshul Nasery</a>, <a href="http://arxiv.org/find/cs/1/au:+Thakur_S/0/1/0/all/0/1">Soumyadeep Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Piratla_V/0/1/0/all/0/1">Vihari Piratla</a>, <a href="http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1">Abir De</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1">Sunita Sarawagi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06721">
                                    <div class="article-summary-box-inner">
                                        <span>In several real world applications, machine learning models are deployed to
make predictions on data whose distribution changes gradually along time,
leading to a drift between the train and test distributions. Such models are
often re-trained on new data periodically, and they hence need to generalize to
data not too far into the future. In this context, there is much prior work on
enhancing temporal generalization, e.g. continuous transportation of past data,
kernel smoothed time-sensitive parameters and more recently, adversarial
learning of time-invariant features. However, these methods share several
limitations, e.g, poor scalability, training instability, and dependence on
unlabeled data from the future. Responding to the above limitations, we propose
a simple method that starts with a model with time-sensitive parameters but
regularizes its temporal complexity using a Gradient Interpolation (GI) loss.
GI allows the decision boundary to change along time and can still prevent
overfitting to the limited training time snapshots by allowing task-specific
control over changes along time. We compare our method to existing baselines on
multiple real-world datasets, which show that GI outperforms more complicated
generative and adversarial approaches on the one hand, and simpler gradient
regularization methods on the other.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">First-order and second-order variants of the gradient descent in a unified framework. (arXiv:1810.08102v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pierrot_T/0/1/0/all/0/1">Thomas Pierrot</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrin_N/0/1/0/all/0/1">Nicolas Perrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigaud_O/0/1/0/all/0/1">Olivier Sigaud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1810.08102">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we provide an overview of first-order and second-order
variants of the gradient descent method that are commonly used in machine
learning. We propose a general framework in which 6 of these variants can be
interpreted as different instances of the same approach. They are the vanilla
gradient descent, the classical and generalized Gauss-Newton methods, the
natural gradient descent method, the gradient covariance matrix approach, and
Newton&#x27;s method. Besides interpreting these methods within a single framework,
we explain their specificities and show under which conditions some of them
coincide.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges for cognitive decoding using deep learning methods. (arXiv:2108.06896v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1">Armin W. Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1">Christopher R&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Poldrack_R/0/1/0/all/0/1">Russell A. Poldrack</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06896">
                                    <div class="article-summary-box-inner">
                                        <span>In cognitive decoding, researchers aim to characterize a brain region&#x27;s
representations by identifying the cognitive states (e.g., accepting/rejecting
a gamble) that can be identified from the region&#x27;s activity. Deep learning (DL)
methods are highly promising for cognitive decoding, with their unmatched
ability to learn versatile representations of complex data. Yet, their
widespread application in cognitive decoding is hindered by their general lack
of interpretability as well as difficulties in applying them to small datasets
and in ensuring their reproducibility and robustness. We propose to approach
these challenges by leveraging recent advances in explainable artificial
intelligence and transfer learning, while also providing specific
recommendations on how to improve the reproducibility and robustness of DL
modeling results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning of Multi-view Facial Expressions. (arXiv:2108.06723v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Shuvendu Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06723">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expression recognition (FER) has emerged as an important component of
human-computer interaction systems. Despite recent advancements in FER,
performance often drops significantly for non-frontal facial images. We propose
Contrastive Learning of Multi-view facial Expressions (CL-MEx) to exploit
facial images captured simultaneously from different angles towards FER. CL-MEx
is a two-step training framework. In the first step, an encoder network is
pre-trained with the proposed self-supervised contrastive loss, where it learns
to generate view-invariant embeddings for different views of a subject. The
model is then fine-tuned with labeled data in a supervised setting. We
demonstrate the performance of the proposed method on two multi-view FER
datasets, KDEF and DDCF, where state-of-the-art performances are achieved.
Further experiments show the robustness of our method in dealing with
challenging angles and reduced amounts of labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations. (arXiv:2108.06514v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piratla_V/0/1/0/all/0/1">Vihari Piratla</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_S/0/1/0/all/0/1">Soumen Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1">Sunita Sarawagi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06514">
                                    <div class="article-summary-box-inner">
                                        <span>Our goal is to evaluate the accuracy of a black-box classification model, not
as a single aggregate on a given test data distribution, but as a surface over
a large number of combinations of attributes characterizing multiple test data
distributions. Such attributed accuracy measures become important as machine
learning models get deployed as a service, where the training data distribution
is hidden from clients, and different clients may be interested in diverse
regions of the data distribution. We present Attributed Accuracy Assay (AAA)--a
Gaussian Process (GP)--based probabilistic estimator for such an accuracy
surface. Each attribute combination, called an &#x27;arm&#x27;, is associated with a Beta
density from which the service&#x27;s accuracy is sampled. We expect the GP to
smooth the parameters of the Beta density over related arms to mitigate
sparsity. We show that obvious application of GPs cannot address the challenge
of heteroscedastic uncertainty over a huge attribute space that is sparsely and
unevenly populated. In response, we present two enhancements: pooling sparse
observations, and regularizing the scale parameter of the Beta densities. After
introducing these innovations, we establish the effectiveness of AAA in terms
of both its estimation accuracy and exploration efficiency, through extensive
experiments and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting OODs as datapoints with High Uncertainty. (arXiv:2108.06380v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaur_R/0/1/0/all/0/1">Ramneet Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Susmit Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Anirban Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sangdon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolsky_O/0/1/0/all/0/1">Oleg Sokolsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06380">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are known to produce incorrect predictions with
very high confidence on out-of-distribution inputs (OODs). This limitation is
one of the key challenges in the adoption of DNNs in high-assurance systems
such as autonomous driving, air traffic management, and medical diagnosis. This
challenge has received significant attention recently, and several techniques
have been developed to detect inputs where the model&#x27;s prediction cannot be
trusted. These techniques detect OODs as datapoints with either high epistemic
uncertainty or high aleatoric uncertainty. We demonstrate the difference in the
detection ability of these techniques and propose an ensemble approach for
detection of OODs as datapoints with high uncertainty (epistemic or aleatoric).
We perform experiments on vision datasets with multiple DNN architectures,
achieving state-of-the-art results in most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple and optimal methods for stochastic variational inequalities, II: Markovian noise and policy evaluation in reinforcement learning. (arXiv:2011.08434v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kotsalis_G/0/1/0/all/0/1">Georgios Kotsalis</a>, <a href="http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1">Guanghui Lan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_T/0/1/0/all/0/1">Tianjiao Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08434">
                                    <div class="article-summary-box-inner">
                                        <span>The focus of this paper is on stochastic variational inequalities (VI) under
Markovian noise. A prominent application of our algorithmic developments is the
stochastic policy evaluation problem in reinforcement learning. Prior
investigations in the literature focused on temporal difference (TD) learning
by employing nonsmooth finite time analysis motivated by stochastic subgradient
descent leading to certain limitations. These encompass the requirement of
analyzing a modified TD algorithm that involves projection to an a-priori
defined Euclidean ball, achieving a non-optimal convergence rate and no clear
way of deriving the beneficial effects of parallel implementation. Our approach
remedies these shortcomings in the broader context of stochastic VIs and in
particular when it comes to stochastic policy evaluation. We developed a
variety of simple TD learning type algorithms motivated by its original version
that maintain its simplicity, while offering distinct advantages from a
non-asymptotic analysis point of view. We first provide an improved analysis of
the standard TD algorithm that can benefit from parallel implementation. Then
we present versions of a conditional TD algorithm (CTD), that involves periodic
updates of the stochastic iterates, which reduce the bias and therefore exhibit
improved iteration complexity. This brings us to the fast TD (FTD) algorithm
which combines elements of CTD and the stochastic operator extrapolation method
of the companion paper. For a novel index resetting policy FTD exhibits the
best known convergence rate. We also devised a robust version of the algorithm
that is particularly suitable for discounting factors close to 1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Local Kernels Formulation of Mutual Information with Application to Active Post-Seismic Building Damage Inference. (arXiv:2105.11492v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheibani_M/0/1/0/all/0/1">Mohamadreza Sheibani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_G/0/1/0/all/0/1">Ge Ou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11492">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance of training data is not guaranteed in various supervised
learning applications. One of these situations is the post-earthquake regional
damage assessment of buildings. Querying the damage label of each building
requires a thorough inspection by experts, and thus, is an expensive task. A
practical approach is to sample the most informative buildings in a sequential
learning scheme. Active learning methods recommend the most informative cases
that are able to maximally reduce the generalization error. The information
theoretic measure of mutual information (MI) is one of the most effective
criteria to evaluate the effectiveness of the samples in a pool-based sample
selection scenario. However, the computational complexity of the standard MI
algorithm prevents the utilization of this method on large datasets. A local
kernels strategy was proposed to reduce the computational costs, but the
adaptability of the kernels to the observed labels was not considered in the
original formulation of this strategy. In this article, an adaptive local
kernels methodology is developed that allows for the conformability of the
kernels to the observed output data while enhancing the computational
complexity of the standard MI algorithm. The proposed algorithm is developed to
work on a Gaussian process regression (GPR) framework, where the kernel
hyperparameters are updated after each label query using the maximum likelihood
estimation. In the sequential learning procedure, the updated hyperparameters
can be used in the MI kernel matrices to improve the sample suggestion
performance. The advantages are demonstrated on a simulation of the 2018
Anchorage, AK, earthquake. It is shown that while the proposed algorithm
enables GPR to reach acceptable performance with fewer training data, the
computational demands remain lower than the standard local kernels strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CrossNorm and SelfNorm for Generalization under Distribution Shifts. (arXiv:2102.02811v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiqiang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris Metaxas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02811">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional normalization techniques (e.g., Batch Normalization and Instance
Normalization) generally and simplistically assume that training and test data
follow the same distribution. As distribution shifts are inevitable in
real-world applications, well-trained models with previous normalization
methods can perform badly in new environments. Can we develop new normalization
methods to improve generalization robustness under distribution shifts? In this
paper, we answer the question by proposing CrossNorm and SelfNorm. CrossNorm
exchanges channel-wise mean and variance between feature maps to enlarge
training distribution, while SelfNorm uses attention to recalibrate the
statistics to bridge gaps between training and test distributions. CrossNorm
and SelfNorm can complement each other, though exploring different directions
in statistics usage. Extensive experiments on different fields (vision and
language), tasks (classification and segmentation), settings (supervised and
semi-supervised), and distribution shift types (synthetic and natural) show the
effectiveness. Code is available at
https://github.com/amazon-research/crossnorm-selfnorm</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inclusion of Domain-Knowledge into GNNs using Mode-Directed Inverse Entailment. (arXiv:2105.10709v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1">Tirtharaj Dash</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1">Ashwin Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Baskar_A/0/1/0/all/0/1">A Baskar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10709">
                                    <div class="article-summary-box-inner">
                                        <span>We present a general technique for constructing Graph Neural Networks (GNNs)
capable of using multi-relational domain knowledge. The technique is based on
mode-directed inverse entailment (MDIE) developed in Inductive Logic
Programming (ILP). Given a data instance $e$ and background knowledge $B$, MDIE
identifies a most-specific logical formula $\bot_B(e)$ that contains all the
relational information in $B$ that is related to $e$. We represent $\bot_B(e)$
by a &quot;bottom-graph&quot; that can be converted into a form suitable for GNN
implementations. This transformation allows a principled way of incorporating
generic background knowledge into GNNs: we use the term &#x60;BotGNN&#x27; for this form
of graph neural networks. For several GNN variants, using real-world datasets
with substantial background knowledge, we show that BotGNNs perform
significantly better than both GNNs without background knowledge and a recently
proposed simplified technique for including domain knowledge into GNNs. We also
provide experimental evidence comparing BotGNNs favourably to multi-layer
perceptrons (MLPs) that use features representing a &quot;propositionalised&quot; form of
the background knowledge; and BotGNNs to a standard ILP based on the use of
most-specific clauses. Taken together, these results point to BotGNNs as
capable of combining the computational efficacy of GNNs with the
representational versatility of ILP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information-Theoretic Generalization Bounds for Stochastic Gradient Descent. (arXiv:2102.00931v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1">Gergely Neu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dziugaite_G/0/1/0/all/0/1">Gintare Karolina Dziugaite</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghifam_M/0/1/0/all/0/1">Mahdi Haghifam</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1">Daniel M. Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00931">
                                    <div class="article-summary-box-inner">
                                        <span>We study the generalization properties of the popular stochastic optimization
method known as stochastic gradient descent (SGD) for optimizing general
non-convex loss functions. Our main contribution is providing upper bounds on
the generalization error that depend on local statistics of the stochastic
gradients evaluated along the path of iterates calculated by SGD. The key
factors our bounds depend on are the variance of the gradients (with respect to
the data distribution) and the local smoothness of the objective function along
the SGD path, and the sensitivity of the loss function to perturbations to the
final output. Our key technical tool is combining the information-theoretic
generalization bounds previously used for analyzing randomized variants of SGD
with a perturbation analysis of the iterates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Community Detection Approaches: From Statistical Modeling to Deep Learning. (arXiv:2101.01669v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Di Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhizhi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_P/0/1/0/all/0/1">Pengfei Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongxiao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jia Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weixiong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01669">
                                    <div class="article-summary-box-inner">
                                        <span>Community detection, a fundamental task for network analysis, aims to
partition a network into multiple sub-structures to help reveal their latent
functions. Community detection has been extensively studied in and broadly
applied to many real-world network problems. Classical approaches to community
detection typically utilize probabilistic graphical models and adopt a variety
of prior knowledge to infer community structures. As the problems that network
methods try to solve and the network data to be analyzed become increasingly
more sophisticated, new approaches have also been proposed and developed,
particularly those that utilize deep learning and convert networked data into
low dimensional representation. Despite all the recent advancement, there is
still a lack of insightful understanding of the theoretical and methodological
underpinning of community detection, which will be critically important for
future development of the area of network analysis. In this paper, we develop
and present a unified architecture of network community-finding methods to
characterize the state-of-the-art of the field of community detection.
Specifically, we provide a comprehensive review of the existing community
detection methods and introduce a new taxonomy that divides the existing
methods into two categories, namely probabilistic graphical model and deep
learning. We then discuss in detail the main idea behind each method in the two
categories. Furthermore, to promote future development of community detection,
we release several benchmark datasets from several problem domains and
highlight their applications to various network analysis tasks. We conclude
with discussions of the challenges of the field and suggestions of possible
directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks. (arXiv:1911.11897v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11897">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art methods in image-to-image translation are capable of
learning a mapping from a source domain to a target domain with unpaired image
data. Though the existing methods have achieved promising results, they still
produce visual artifacts, being able to translate low-level information but not
high-level semantics of input images. One possible reason is that generators do
not have the ability to perceive the most discriminative parts between the
source and target domains, thus making the generated images low quality. In
this paper, we propose a new Attention-Guided Generative Adversarial Networks
(AttentionGAN) for the unpaired image-to-image translation task. AttentionGAN
can identify the most discriminative foreground objects and minimize the change
of the background. The attention-guided generators in AttentionGAN are able to
produce attention masks, and then fuse the generation output with the attention
masks to obtain high-quality target images. Accordingly, we also design a novel
attention-guided discriminator which only considers attended regions. Extensive
experiments are conducted on several generative tasks with eight public
datasets, demonstrating that the proposed method is effective to generate
sharper and more realistic images compared with existing competitive models.
The code is available at https://github.com/Ha0Tang/AttentionGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Knowledge by Mimicking Features. (arXiv:2011.01424v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guo-Hua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yifan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianxin Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01424">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation (KD) is a popular method to train efficient networks
(&quot;student&quot;) with the help of high-capacity networks (&quot;teacher&quot;). Traditional
methods use the teacher&#x27;s soft logits as extra supervision to train the student
network. In this paper, we argue that it is more advantageous to make the
student mimic the teacher&#x27;s features in the penultimate layer. Not only the
student can directly learn more effective information from the teacher feature,
feature mimicking can also be applied for teachers trained without a softmax
layer. Experiments show that it can achieve higher accuracy than traditional
KD. To further facilitate feature mimicking, we decompose a feature vector into
the magnitude and the direction. We argue that the teacher should give more
freedom to the student feature&#x27;s magnitude, and let the student pay more
attention on mimicking the feature direction. To meet this requirement, we
propose a loss term based on locality-sensitive hashing (LSH). With the help of
this new loss, our method indeed mimics feature directions more accurately,
relaxes constraints on feature magnitudes, and achieves state-of-the-art
distillation accuracy. We provide theoretical analyses of how LSH facilitates
feature direction mimicking, and further extend feature mimicking to
multi-label recognition and object detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMITE: A Novel Polynomial Expansion for Analyzing Neural Network Nonlinearities. (arXiv:2007.06226v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sanchirico_M/0/1/0/all/0/1">Mauro J. Sanchirico III</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1">Xun Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Nataraj_C/0/1/0/all/0/1">C. Nataraj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06226">
                                    <div class="article-summary-box-inner">
                                        <span>Polynomial expansions are important in the analysis of neural network
nonlinearities. They have been applied thereto addressing well-known
difficulties in verification, explainability, and security. Existing approaches
span classical Taylor and Chebyshev methods, asymptotics, and many numerical
approaches. We find that while these individually have useful properties such
as exact error formulas, adjustable domain, and robustness to undefined
derivatives, there are no approaches that provide a consistent method yielding
an expansion with all these properties. To address this, we develop an
analytically modified integral transform expansion (AMITE), a novel expansion
via integral transforms modified using derived criteria for convergence. We
show the general expansion and then demonstrate application for two popular
activation functions, hyperbolic tangent and rectified linear units. Compared
with existing expansions (i.e., Chebyshev, Taylor, and numerical) employed to
this end, AMITE is the first to provide six previously mutually exclusive
desired expansion properties such as exact formulas for the coefficients and
exact expansion errors (Table II). We demonstrate the effectiveness of AMITE in
two case studies. First, a multivariate polynomial form is efficiently
extracted from a single hidden layer black-box MLP to facilitate equivalence
testing from noisy stimulus-response pairs. Second, a variety of FFNN
architectures having between 3 and 7 layers are range bounded using Taylor
models improved by the AMITE polynomials and error formulas. AMITE presents a
new dimension of expansion methods suitable for analysis/approximation of
nonlinearities in neural networks, opening new directions and opportunities for
the theoretical analysis and systematic testing of neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Face Encryption by Generating Adversarial Identity Masks. (arXiv:2003.06814v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuefeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hui Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06814">
                                    <div class="article-summary-box-inner">
                                        <span>As billions of personal data being shared through social media and network,
the data privacy and security have drawn an increasing attention. Several
attempts have been made to alleviate the leakage of identity information from
face photos, with the aid of, e.g., image obfuscation techniques. However, most
of the present results are either perceptually unsatisfactory or ineffective
against face recognition systems. Our goal in this paper is to develop a
technique that can encrypt the personal photos such that they can protect users
from unauthorized face recognition systems but remain visually identical to the
original version for human beings. To achieve this, we propose a targeted
identity-protection iterative method (TIP-IM) to generate adversarial identity
masks which can be overlaid on facial images, such that the original identities
can be concealed without sacrificing the visual quality. Extensive experiments
demonstrate that TIP-IM provides 95\%+ protection success rate against various
state-of-the-art face recognition models under practical test scenarios.
Besides, we also show the practical and effective applicability of our method
on a commercial API service.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1">Mahdi S. Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jia Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1">Andre Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jingxuan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1">Mathieu Tuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1">Konstantinos N. Plataniotis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06822">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Architecture Search (NAS) has shifted network design from using human
intuition to leveraging search algorithms guided by evaluation metrics. We
study channel size optimization in convolutional neural networks (CNN) and
identify the role it plays in model accuracy and complexity. Current channel
size selection methods are generally limited by discrete sample spaces while
suffering from manual iteration and simple heuristics. To solve this, we
introduce an efficient dynamic scaling algorithm -- CONet -- that automatically
optimizes channel sizes across network layers for a given CNN. Two metrics --
&#x60;&#x60;\textit{Rank}&quot; and &quot;\textit{Rank Average Slope}&quot; -- are introduced to
identify the information accumulated in training. The algorithm dynamically
scales channel sizes up or down over a fixed searching phase. We conduct
experiments on CIFAR10/100 and ImageNet datasets and show that CONet can find
efficient and accurate architectures searched in ResNet, DARTS, and DARTS+
spaces that outperform their baseline models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Deep Learning for Partial Differential Equation Parameter Discovery with Sparse and Noisy Data. (arXiv:2108.04085v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Bonneville_C/0/1/0/all/0/1">Christophe Bonneville</a>, <a href="http://arxiv.org/find/math/1/au:+Earls_C/0/1/0/all/0/1">Christopher J. Earls</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04085">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific machine learning has been successfully applied to inverse problems
and PDE discoveries in computational physics. One caveat of current methods
however is the need for large amounts of (clean) data in order to recover full
system responses or underlying physical models. Bayesian methods may be
particularly promising to overcome these challenges as they are naturally less
sensitive to sparse and noisy data. In this paper, we propose to use Bayesian
neural networks (BNN) in order to: 1) Recover the full system states from
measurement data (e.g. temperature, velocity field, etc.). We use Hamiltonian
Monte-Carlo to sample the posterior distribution of a deep and dense BNN, and
show that it is possible to accurately capture physics of varying complexity
without overfitting. 2) Recover the parameters in the underlying partial
differential equation (PDE) governing the physical system. Using the trained
BNN as a surrogate of the system response, we generate datasets of derivatives
potentially comprising the latent PDE of the observed system and perform a
Bayesian linear regression (BLR) between the successive derivatives in space
and time to recover the original PDE parameters. We take advantage of the
confidence intervals on the BNN outputs and introduce the spatial derivative
variance into the BLR likelihood to discard the influence of highly uncertain
surrogate data points, which allows for more accurate parameter discovery. We
demonstrate our approach on a handful of example applied to physics and
non-linear dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rundi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Changxi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09492">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models of 3D shapes have received a great deal of research
interest. Yet, almost all of them generate discrete shape representations, such
as voxels, point clouds, and polygon meshes. We present the first 3D generative
model for a drastically different shape representation --- describing a shape
as a sequence of computer-aided design (CAD) operations. Unlike meshes and
point clouds, CAD models encode the user creation process of 3D shapes, widely
used in numerous industrial and engineering design tasks. However, the
sequential and irregular structure of CAD operations poses significant
challenges for existing 3D generative models. Drawing an analogy between CAD
operations and natural language, we propose a CAD generative network based on
the Transformer. We demonstrate the performance of our model for both shape
autoencoding and random shape generation. To train our network, we create a new
CAD dataset consisting of 178,238 models and their CAD construction sequences.
We have made this dataset publicly available to promote future research on this
topic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neko: a Library for Exploring Neuromorphic Learning Rules. (arXiv:2105.00324v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zixuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wycoff_N/0/1/0/all/0/1">Nathan Wycoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Getty_N/0/1/0/all/0/1">Neil Getty</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1">Rick Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fangfang Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00324">
                                    <div class="article-summary-box-inner">
                                        <span>The field of neuromorphic computing is in a period of active exploration.
While many tools have been developed to simulate neuronal dynamics or convert
deep networks to spiking models, general software libraries for learning rules
remain underexplored. This is partly due to the diverse, challenging nature of
efforts to design new learning rules, which range from encoding methods to
gradient approximations, from population approaches that mimic the Bayesian
brain to constrained learning algorithms deployed on memristor crossbars. To
address this gap, we present Neko, a modular, extensible library with a focus
on aiding the design of new learning algorithms. We demonstrate the utility of
Neko in three exemplar cases: online local learning, probabilistic learning,
and analog on-device learning. Our results show that Neko can replicate the
state-of-the-art algorithms and, in one case, lead to significant
outperformance in accuracy and speed. Further, it offers tools including
gradient comparison that can help develop new algorithmic variants. Neko is an
open source Python library that supports PyTorch and TensorFlow backends.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Melodia_L/0/1/0/all/0/1">Luciano Melodia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenz_R/0/1/0/all/0/1">Richard Lenz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02493">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we use topological data analysis techniques to construct a
suitable neural network classifier for the task of learning sensor signals of
entire power plants according to their reference designation system. We use
representations of persistence diagrams to derive necessary preprocessing steps
and visualize the large amounts of data. We derive deep architectures with
one-dimensional convolutional layers combined with stacked long short-term
memories as residual networks suitable for processing the persistence features.
We combine three separate sub-networks, obtaining as input the time series
itself and a representation of the persistent homology for the zeroth and first
dimension. We give a mathematical derivation for most of the used
hyper-parameters. For validation, numerical experiments were performed with
sensor data from four power plants of the same construction type.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sleep Staging Based on Multi Scale Dual Attention Network. (arXiv:2107.08442v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huafeng Wang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chonggang Lu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhimin Hu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xiaodong Yuan</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingshu Zhang</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanquan Liu</a> (3) ((1) School of Information, North China University of Technology,(2) Department of Neurology, Kailuan General Hospital, Tangshan,(3) School of Intelligent Systems Engineering, Sun Yat-sen University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08442">
                                    <div class="article-summary-box-inner">
                                        <span>Sleep staging plays an important role on the diagnosis of sleep disorders. In
general, experts classify sleep stages manually based on polysomnography (PSG),
which is quite time-consuming. Meanwhile, the acquisition process of multiple
signals is much complex, which can affect the subject&#x27;s sleep. Therefore, the
use of single-channel electroencephalogram (EEG) for automatic sleep staging
has become a popular research topic. In the literature, a large number of sleep
staging methods based on single-channel EEG have been proposed with promising
results and achieve the preliminary automation of sleep staging. However, the
performance for most of these methods in the N1 stage do not satisfy the needs
of the diagnosis. In this paper, we propose a deep learning model multi scale
dual attention network(MSDAN) based on raw EEG, which utilizes multi-scale
convolution to extract features in different waveforms contained in the EEG
signal, connects channel attention and spatial attention mechanisms in series
to filter and highlight key information, and uses soft thresholding to remove
redundant information. Experiments were conducted using two datasets with
5-fold cross-validation and hold-out validation method. The final average
accuracy, overall accuracy, macro F1 score and Cohen&#x27;s Kappa coefficient of the
model reach 96.70%, 91.74%, 0.8231 and 0.8723 on the Sleep-EDF dataset, 96.14%,
90.35%, 0.7945 and 0.8284 on the Sleep-EDFx dataset. Significantly, our model
performed superiorly in the N1 stage, with F1 scores of 54.41% and 52.79% on
the two datasets respectively. The results show the superiority of our network
over the existing methods, reaching a new state-of-the-art. In particular, the
proposed method achieves excellent results in the N1 sleep stage compared to
other methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding. (arXiv:2104.13020v3 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1">Jose M. Pe&#xf1;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13020">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for assessing the sensitivity of the true causal effect
to unmeasured confounding. The method requires the analyst to set two intuitive
parameters. Otherwise, the method is assumption-free. The method returns an
interval that contains the true causal effect, and whose bounds are sharp, i.e.
attainable. We show experimentally that our bounds can be sharper than those
obtained by the method of Ding and VanderWeele (2016a) which, moreover,
requires to set one more parameter than our method. Finally, we extend our
method to bound the natural direct and indirect effects when there are measured
mediators and unmeasured exposure-outcome confounding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural-to-Tree Policy Distillation with Policy Improvement Criterion. (arXiv:2108.06898v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhao-Hua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06898">
                                    <div class="article-summary-box-inner">
                                        <span>While deep reinforcement learning has achieved promising results in
challenging decision-making tasks, the main bones of its success --- deep
neural networks are mostly black-boxes. A feasible way to gain insight into a
black-box model is to distill it into an interpretable model such as a decision
tree, which consists of if-then rules and is easy to grasp and be verified.
However, the traditional model distillation is usually a supervised learning
task under a stationary data distribution assumption, which is violated in
reinforcement learning. Therefore, a typical policy distillation that clones
model behaviors with even a small error could bring a data distribution shift,
resulting in an unsatisfied distilled policy model with low fidelity or low
performance. In this paper, we propose to address this issue by changing the
distillation objective from behavior cloning to maximizing an advantage
evaluation. The novel distillation objective maximizes an approximated
cumulative reward and focuses more on disastrous behaviors in critical states,
which controls the data shift effect. We evaluate our method on several Gym
tasks, a commercial fight game, and a self-driving car simulator. The empirical
results show that the proposed method can preserve a higher cumulative reward
than behavior cloning and learn a more consistent policy to the original one.
Moreover, by examining the extracted rules from the distilled decision trees,
we demonstrate that the proposed method delivers reasonable and robust
decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical forecasting with a top-down alignment of independent level forecasts. (arXiv:2103.08250v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Anderer_M/0/1/0/all/0/1">Matthias Anderer</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Feng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08250">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical forecasting with intermittent time series is a challenge in both
research and empirical studies. Vast research focuses on improving the accuracy
of each hierarchy, especially the intermittent time series at bottom levels. It
then reconciles forecasts at each hierarchy to further improve the overall
performance. In this paper, we present a hierarchical forecasting approach that
treats the bottom level forecasts as mutable to ensure higher forecasting
accuracy on the upper levels of the hierarchy. We employ a pure deep learning
forecasting approach N-BEATS for continuous time series on top levels and a
widely used tree-based algorithm LightGBM for the bottom level intermittent
time series. The hierarchical forecasting with alignment approach is a simple
yet effective variant of the bottom-up method, which accounts for biases that
are difficult to observe at the bottom level. It allows suboptimal forecasts at
the lower level to retain a higher overall performance. The approach in this
empirical study was developed by the first author during the M5 Forecasting
Accuracy competition, ranking second place. The approach is also business
orientated and could be beneficial for business strategic planning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unique sparse decomposition of low rank matrices. (arXiv:2106.07736v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jin_D/0/1/0/all/0/1">Dian Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Bing_X/0/1/0/all/0/1">Xin Bing</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1">Yuqian Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07736">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of finding the unique low dimensional decomposition of a given
matrix has been a fundamental and recurrent problem in many areas. In this
paper, we study the problem of seeking a unique decomposition of a low rank
matrix $Y\in \mathbb{R}^{p\times n}$ that admits a sparse representation.
Specifically, we consider $Y &#x3D; A X\in \mathbb{R}^{p\times n}$ where the matrix
$A\in \mathbb{R}^{p\times r}$ has full column rank, with $r &lt; \min\{n,p\}$, and
the matrix $X\in \mathbb{R}^{r\times n}$ is element-wise sparse. We prove that
this sparse decomposition of $Y$ can be uniquely identified, up to some
intrinsic signed permutation. Our approach relies on solving a nonconvex
optimization problem constrained over the unit sphere. Our geometric analysis
for the nonconvex optimization landscape shows that any {\em strict} local
solution is close to the ground truth solution, and can be recovered by a
simple data-driven initialization followed with any second order descent
algorithm. At last, we corroborate these theoretical results with numerical
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Democratic Source Coding: An Optimal Fixed-Length Quantization Scheme for Distributed Optimization Under Communication Constraints. (arXiv:2103.07578v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1">Rajarshi Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1">Mert Pilanci</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldsmith_A/0/1/0/all/0/1">Andrea J. Goldsmith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07578">
                                    <div class="article-summary-box-inner">
                                        <span>The communication cost of distributed optimization algorithms is a major
bottleneck in their scalability. This work considers a parameter-server setting
in which the worker is constrained to communicate information to the server
using only $R$ bits per dimension. We show that $\mathbf{democratic}$
$\mathbf{embeddings}$ from random matrix theory are significantly useful for
designing efficient and optimal vector quantizers that respect this bit budget.
The resulting polynomial complexity source coding schemes are used to design
distributed optimization algorithms with convergence rates matching the minimax
optimal lower bounds for (i) Smooth and Strongly-Convex objectives with access
to an Exact Gradient oracle, as well as (ii) General Convex and Non-Smooth
objectives with access to a Noisy Subgradient oracle. We further propose a
relaxation of this coding scheme which is nearly minimax optimal. Numerical
simulations validate our theoretical claims.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Teleportation. (arXiv:2012.01118v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Armenta_M/0/1/0/all/0/1">Marco Armenta</a>, <a href="http://arxiv.org/find/cs/1/au:+Judge_T/0/1/0/all/0/1">Thierry Judge</a>, <a href="http://arxiv.org/find/cs/1/au:+Painchaud_N/0/1/0/all/0/1">Nathan Painchaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Skandarani_Y/0/1/0/all/0/1">Youssef Skandarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemaire_C/0/1/0/all/0/1">Carl Lemaire</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_G/0/1/0/all/0/1">Gabriel Gibeau Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Spino_P/0/1/0/all/0/1">Philippe Spino</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01118">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore a process called neural teleportation, a
mathematical consequence of applying quiver representation theory to neural
networks. Neural teleportation &quot;teleports&quot; a network to a new position in the
weight space and preserves its function. This phenomenon comes directly from
the definitions of representation theory applied to neural networks and it
turns out to be a very simple operation that has remarkable properties. We shed
light on surprising and counter-intuitive consequences neural teleportation has
on the loss landscape. In particular, we show that teleportation can be used to
explore loss level curves, that it changes the local loss landscape, sharpens
global minima and boosts back-propagated gradients at any moment during the
learning process. Our results can be reproduced with the code available here:
https://github.com/vitalab/neuralteleportation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Computation-Efficient CNN System for High-Quality Brain Tumor Segmentation. (arXiv:2007.12066v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1">Yanming Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chunyan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12066">
                                    <div class="article-summary-box-inner">
                                        <span>The work presented in this paper is to propose a reliable high-quality system
of Convolutional Neural Network (CNN) for brain tumor segmentation with a low
computation requirement. The system consists of a CNN for the main processing
for the segmentation, a pre-CNN block for data reduction and post-CNN
refinement block. The unique CNN consists of 7 convolution layers involving
only 108 kernels and 20308 trainable parameters. It is custom-designed,
following the proposed paradigm of ASCNN (application specific CNN), to perform
mono-modality and cross-modality feature extraction, tumor localization and
pixel classification. Each layer fits the task assigned to it, by means of (i)
appropriate normalization applied to its input data, (ii) correct convolution
modes for the assigned task, and (iii) suitable nonlinear transformation to
optimize the convolution results. In this specific design context, the number
of kernels in each of the 7 layers is made to be just-sufficient for its task,
instead of exponentially growing over the layers, to increase information
density and to reduce randomness in the processing. The proposed activation
function Full-ReLU helps to halve the number of kernels in convolution layers
of high-pass filtering without degrading processing quality. A large number of
experiments with BRATS2018 dataset have been conducted to measure the
processing quality and reproducibility of the proposed system. The results
demonstrate that the system reproduces reliably almost the same output to the
same input after retraining. The mean dice scores for enhancing tumor, whole
tumor and tumor core are 77.2%, 89.2% and 76.3%, respectively. The simple
structure and reliable high processing quality of the proposed system will
facilitate its implementation and medical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Neural Network Reinforcement Learning for Autonomous Mobility-on-Demand Systems. (arXiv:2104.11434v2 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gammelli_D/0/1/0/all/0/1">Daniele Gammelli</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_K/0/1/0/all/0/1">Kaidi Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Harrison_J/0/1/0/all/0/1">James Harrison</a>, <a href="http://arxiv.org/find/eess/1/au:+Rodrigues_F/0/1/0/all/0/1">Filipe Rodrigues</a>, <a href="http://arxiv.org/find/eess/1/au:+Pereira_F/0/1/0/all/0/1">Francisco C. Pereira</a>, <a href="http://arxiv.org/find/eess/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11434">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous mobility-on-demand (AMoD) systems represent a rapidly developing
mode of transportation wherein travel requests are dynamically handled by a
coordinated fleet of robotic, self-driving vehicles. Given a graph
representation of the transportation network - one where, for example, nodes
represent areas of the city, and edges the connectivity between them - we argue
that the AMoD control problem is naturally cast as a node-wise decision-making
problem. In this paper, we propose a deep reinforcement learning framework to
control the rebalancing of AMoD systems through graph neural networks.
Crucially, we demonstrate that graph neural networks enable reinforcement
learning agents to recover behavior policies that are significantly more
transferable, generalizable, and scalable than policies learned through other
approaches. Empirically, we show how the learned policies exhibit promising
zero-shot transfer capabilities when faced with critical portability tasks such
as inter-city generalization, service area expansion, and adaptation to
potentially complex urban topologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastively Learning Visual Attention as Affordance Cues from Demonstrations for Robotic Grasping. (arXiv:2104.00878v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_Y/0/1/0/all/0/1">Yantian Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhambri_S/0/1/0/all/0/1">Siddhant Bhambri</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_L/0/1/0/all/0/1">Lin Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00878">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional works that learn grasping affordance from demonstrations need to
explicitly predict grasping configurations, such as gripper approaching angles
or grasping preshapes. Classic motion planners could then sample trajectories
by using such predicted configurations. In this work, our goal is instead to
fill the gap between affordance discovery and affordance-based policy learning
by integrating the two objectives in an end-to-end imitation learning framework
based on deep neural networks. From a psychological perspective, there is a
close association between attention and affordance. Therefore, with an
end-to-end neural network, we propose to learn affordance cues as visual
attention that serves as a useful indicating signal of how a demonstrator
accomplishes tasks, instead of explicitly modeling affordances. To achieve
this, we propose a contrastive learning framework that consists of a Siamese
encoder and a trajectory decoder. We further introduce a coupled triplet loss
to encourage the discovered affordance cues to be more affordance-relevant. Our
experimental results demonstrate that our model with the coupled triplet loss
achieves the highest grasping success rate in a simulated robot environment.
Our project website can be accessed at
https://sites.google.com/asu.edu/affordance-aware-imitation/project.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Set-to-Sequence Methods in Machine Learning: a Review. (arXiv:2103.09656v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jurewicz_M/0/1/0/all/0/1">Mateusz Jurewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Stromberg_Derczynski_L/0/1/0/all/0/1">Leon Str&#xf8;mberg-Derczynski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09656">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning on sets towards sequential output is an important and
ubiquitous task, with applications ranging from language modeling and
meta-learning to multi-agent strategy games and power grid optimization.
Combining elements of representation learning and structured prediction, its
two primary challenges include obtaining a meaningful, permutation invariant
set representation and subsequently utilizing this representation to output a
complex target permutation. This paper provides a comprehensive introduction to
the field as well as an overview of important machine learning methods tackling
both of these key challenges, with a detailed qualitative comparison of
selected model architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Achieving Fairness with a Simple Ridge Penalty. (arXiv:2105.13817v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scutari_M/0/1/0/all/0/1">Marco Scutari</a>, <a href="http://arxiv.org/find/cs/1/au:+Panero_F/0/1/0/all/0/1">Francesca Panero</a>, <a href="http://arxiv.org/find/cs/1/au:+Proissl_M/0/1/0/all/0/1">Manuel Proissl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13817">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present a general framework for estimating regression models
subject to a user-defined level of fairness. We enforce fairness as a model
selection step in which we choose the value of a ridge penalty to control the
effect of sensitive attributes. We then estimate the parameters of the model
conditional on the chosen penalty value. Our proposal is mathematically simple,
with a solution that is partly in closed form, and produces estimates of the
regression coefficients that are intuitive to interpret as a function of the
level of fairness. Furthermore, it is easily extended to generalised linear
models, kernelised regression models and other penalties; and it can
accommodate multiple definitions of fairness.

We compare our approach with the regression model from Komiyama et al.
(2018), which implements a provably-optimal linear regression model; and with
the fair models from Zafar et al. (2019). We evaluate these approaches
empirically on six different data sets, and we find that our proposal provides
better goodness of fit and better predictive accuracy for the same level of
fairness. In addition, we highlight a source of bias in the original
experimental evaluation in Komiyama et al. (2018).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction Analysis of Optical Tracker Parameters using Machine Learning Approaches for efficient Head Tracking. (arXiv:2108.06606v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kataria_A/0/1/0/all/0/1">Aman Kataria</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Smarajit Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Karar_V/0/1/0/all/0/1">Vinod Karar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06606">
                                    <div class="article-summary-box-inner">
                                        <span>A head tracker is a crucial part of the head mounted display systems, as it
tracks the head of the pilot in the plane/cockpit simulator. The operational
flaws of head trackers are also dependent on different environmental conditions
like different lighting conditions and stray light interference. In this
letter, an optical tracker has been employed to gather the 6-DoF data of head
movements under different environmental conditions. Also, the effect of
different environmental conditions and variation in distance between the
receiver and optical transmitter on the 6-DoF data was analyzed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-Sensitive Algorithms for Pure Exploration in Multinomial Logit Bandit. (arXiv:2012.01499v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karpov_N/0/1/0/all/0/1">Nikolai Karpov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01499">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by real-world applications such as fast fashion retailing and
online advertising, the Multinomial Logit Bandit (MNL-bandit) is a popular
model in online learning and operations research, and has attracted much
attention in the past decade. However, it is a bit surprising that pure
exploration, a basic problem in bandit theory, has not been well studied in
MNL-bandit so far. In this paper we give efficient algorithms for pure
exploration in MNL-bandit. Our algorithms achieve instance-sensitive pull
complexities. We also complement the upper bounds by an almost matching lower
bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline-Online Reinforcement Learning for Energy Pricing in Office Demand Response: Lowering Energy and Data Costs. (arXiv:2108.06594v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jang_D/0/1/0/all/0/1">Doseok Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Spangher_L/0/1/0/all/0/1">Lucas Spangher</a>, <a href="http://arxiv.org/find/cs/1/au:+Khattar_M/0/1/0/all/0/1">Manan Khattar</a>, <a href="http://arxiv.org/find/cs/1/au:+Agwan_U/0/1/0/all/0/1">Utkarsha Agwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadarajah_S/0/1/0/all/0/1">Selvaprabuh Nadarajah</a>, <a href="http://arxiv.org/find/cs/1/au:+Spanos_C/0/1/0/all/0/1">Costas Spanos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06594">
                                    <div class="article-summary-box-inner">
                                        <span>Our team is proposing to run a full-scale energy demand response experiment
in an office building. Although this is an exciting endeavor which will provide
value to the community, collecting training data for the reinforcement learning
agent is costly and will be limited. In this work, we examine how offline
training can be leveraged to minimize data costs (accelerate convergence) and
program implementation costs. We present two approaches to doing so:
pretraining our model to warm start the experiment with simulated tasks, and
using a planning model trained to simulate the real world&#x27;s rewards to the
agent. We present results that demonstrate the utility of offline reinforcement
learning to efficient price-setting in the energy demand response problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints. (arXiv:2011.01354v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kenny Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pogue_A/0/1/0/all/0/1">Alexandra Pogue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_B/0/1/0/all/0/1">Brett T. Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Agha_mohammadi_A/0/1/0/all/0/1">Ali-akbar Agha-mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1">Ankur Mehta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01354">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular depth inference has gained tremendous attention from researchers in
recent years and remains as a promising replacement for expensive
time-of-flight sensors, but issues with scale acquisition and implementation
overhead still plague these systems. To this end, this work presents an
unsupervised learning framework that is able to predict at-scale depth maps and
egomotion, in addition to camera intrinsics, from a sequence of monocular
images via a single network. Our method incorporates both spatial and temporal
geometric constraints to resolve depth and pose scale factors, which are
enforced within the supervisory reconstruction loss functions at training time.
Only unlabeled stereo sequences are required for training the weights of our
single-network architecture, which reduces overall implementation overhead as
compared to previous methods. Our results demonstrate strong performance when
compared to the current state-of-the-art on multiple sequences of the KITTI
driving dataset and can provide faster training times with its reduced network
complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GarmentNets: Category-Level Pose Estimation for Garments via Canonical Space Shape Completion. (arXiv:2104.05177v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_C/0/1/0/all/0/1">Cheng Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuran Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05177">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles the task of category-level pose estimation for garments.
With a near infinite degree of freedom, a garment&#x27;s full configuration (i.e.,
poses) is often described by the per-vertex 3D locations of its entire 3D
surface. However, garments are also commonly subject to extreme cases of
self-occlusion, especially when folded or crumpled, making it challenging to
perceive their full 3D surface. To address these challenges, we propose
GarmentNets, where the key idea is to formulate the deformable object pose
estimation problem as a shape completion task in the canonical space. This
canonical space is defined across garments instances within a category,
therefore, specifies the shared category-level pose. By mapping the observed
partial surface to the canonical space and completing it in this space, the
output representation describes the garment&#x27;s full configuration using a
complete 3D mesh with the per-vertex canonical coordinate label. To properly
handle the thin 3D structure presented on garments, we proposed a novel 3D
shape representation using the generalized winding number field. Experiments
demonstrate that GarmentNets is able to generalize to unseen garment instances
and achieve significantly better performance compared to alternative
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Free Lunch for Few-shot Learning: Distribution Calibration. (arXiv:2101.06395v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06395">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from a limited number of samples is challenging since the learned
model can easily become overfitted based on the biased distribution formed by
only a few training examples. In this paper, we calibrate the distribution of
these few-sample classes by transferring statistics from the classes with
sufficient examples, then an adequate number of examples can be sampled from
the calibrated distribution to expand the inputs to the classifier. We assume
every dimension in the feature representation follows a Gaussian distribution
so that the mean and the variance of the distribution can borrow from that of
similar classes whose statistics are better estimated with an adequate number
of samples. Our method can be built on top of off-the-shelf pretrained feature
extractors and classification models without extra parameters. We show that a
simple logistic regression classifier trained using the features sampled from
our calibrated distribution can outperform the state-of-the-art accuracy on two
datasets (~5% improvement on miniImageNet compared to the next best). The
visualization of these generated features demonstrates that our calibrated
distribution is an accurate estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analogical Proportions. (arXiv:2006.02854v7 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antic_C/0/1/0/all/0/1">Christian Anti&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02854">
                                    <div class="article-summary-box-inner">
                                        <span>Analogy-making is at the core of human and artificial intelligence and
creativity. This paper introduces from first principles an abstract algebraic
framework of analogical proportions of the form &#x60;$a$ is to $b$ what $c$ is to
$d$&#x27; in the general setting of universal algebra. This enables us to compare
mathematical objects possibly across different domains in a uniform way which
is crucial for AI-systems. The main idea is to define solutions to analogical
equations in terms of maximal sets of algebraic justifications, which amounts
to deriving abstract terms of concrete elements from a &#x60;known&#x27; source domain
which can then be instantiated in an &#x60;unknown&#x27; target domain to obtain
analogous elements. It turns out that our notion of analogical proportions has
appealing mathematical properties. We compare our framework with two recently
introduced frameworks of analogical proportions from the literature in the
concrete domains of sets and numbers, and we show that in each case we either
disagree with the notion from the literature justified by some counter-example
or we can show that our model yields strictly more solutions. As we construct
our model from first principles using only elementary concepts of universal
algebra, and since our model questions some basic properties of analogical
proportions presupposed in the literature, to convince the reader of the
plausibility of our model we show that it can be naturally embedded into
first-order logic via model-theoretic types, and prove that analogical
proportions are compatible with structure-preserving mappings from that
perspective. This provides strong evidence for its applicability. In a broader
sense, this paper is a first step towards a theory of analogical reasoning and
learning systems with potential applications to fundamental AI-problems like
commonsense reasoning and computational learning and creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amata: An Annealing Mechanism for Adversarial Training Acceleration. (arXiv:2012.08112v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1">Nanyang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qianxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiao-Yun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhanxing Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08112">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the empirical success in various domains, it has been revealed that
deep neural networks are vulnerable to maliciously perturbed input data that
much degrade their performance. This is known as adversarial attacks. To
counter adversarial attacks, adversarial training formulated as a form of
robust optimization has been demonstrated to be effective. However, conducting
adversarial training brings much computational overhead compared with standard
training. In order to reduce the computational cost, we propose an annealing
mechanism, Amata, to reduce the overhead associated with adversarial training.
The proposed Amata is provably convergent, well-motivated from the lens of
optimal control theory and can be combined with existing acceleration methods
to further enhance performance. It is demonstrated that on standard datasets,
Amata can achieve similar or better robustness with around 1/3 to 1/2 the
computational time compared with traditional methods. In addition, Amata can be
incorporated into other adversarial training acceleration algorithms (e.g.
YOPO, Free, Fast, and ATTA), which leads to further reduction in computational
time on large-scale problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows. (arXiv:2010.02068v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bo Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaddar_B/0/1/0/all/0/1">Bissan Ghaddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Nathwani_J/0/1/0/all/0/1">Jatin Nathwani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02068">
                                    <div class="article-summary-box-inner">
                                        <span>The past decade has seen a rapid penetration of electric vehicles (EV) in the
market, more and more logistics and transportation companies start to deploy
EVs for service provision. In order to model the operations of a commercial EV
fleet, we utilize the EV routing problem with time windows (EVRPTW). In this
research, we propose an end-to-end deep reinforcement learning framework to
solve the EVRPTW. In particular, we develop an attention model incorporating
the pointer network and a graph embedding technique to parameterize a
stochastic policy for solving the EVRPTW. The model is then trained using
policy gradient with rollout baseline. Our numerical studies show that the
proposed model is able to efficiently solve EVRPTW instances of large sizes
that are not solvable with any existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal and Efficient Algorithms for General Mixable Losses against Switching Oracles. (arXiv:2108.06411v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1">Kaan Gokcesu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1">Hakan Gokcesu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06411">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem of online learning, which has gained significant
attention in recent years due to its applicability in a wide range of fields
from machine learning to game theory. Specifically, we study the online
optimization of mixable loss functions in a dynamic environment. We introduce
online mixture schemes that asymptotically achieves the performance of the best
dynamic estimation sequence of the switching oracle with optimal regret
redundancies. The best dynamic estimation sequence that we compete against is
selected in hindsight with full observation of the loss functions and is
allowed to select different optimal estimations in different time intervals
(segments). We propose two mixtures in our work. Firstly, we propose a
tractable polynomial time complexity algorithm that can achieve the optimal
redundancy of the intractable brute force approach. Secondly, we propose an
efficient logarithmic time complexity algorithm that can achieve the optimal
redundancy up to a constant multiplicity gap. Our results are guaranteed to
hold in a strong deterministic sense in an individual sequence manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-Time Sequential Recommendation with Temporal Graph Collaborative Transformer. (arXiv:2108.06625v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziwei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06625">
                                    <div class="article-summary-box-inner">
                                        <span>In order to model the evolution of user preference, we should learn user/item
embeddings based on time-ordered item purchasing sequences, which is defined as
Sequential Recommendation (SR) problem. Existing methods leverage sequential
patterns to model item transitions. However, most of them ignore crucial
temporal collaborative signals, which are latent in evolving user-item
interactions and coexist with sequential patterns. Therefore, we propose to
unify sequential patterns and temporal collaborative signals to improve the
quality of recommendation, which is rather challenging. Firstly, it is hard to
simultaneously encode sequential patterns and collaborative signals. Secondly,
it is non-trivial to express the temporal effects of collaborative signals.

Hence, we design a new framework Temporal Graph Sequential Recommender
(TGSRec) upon our defined continuous-time bi-partite graph. We propose a novel
Temporal Collaborative Trans-former (TCT) layer in TGSRec, which advances the
self-attention mechanism by adopting a novel collaborative attention. TCT layer
can simultaneously capture collaborative signals from both users and items, as
well as considering temporal dynamics inside sequential patterns. We propagate
the information learned fromTCTlayerover the temporal graph to unify sequential
patterns and temporal collaborative signals. Empirical results on five datasets
show that TGSRec significantly outperforms other baselines, in average up to
22.5% and 22.1%absolute improvements in Recall@10and MRR, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Wider Neural Networks Really Help Adversarial Robustness?. (arXiv:2010.01279v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Boxi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinghui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Quanquan Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01279">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is a powerful type of defense against adversarial
examples. Previous empirical results suggest that adversarial training requires
wider networks for better performances. However, it remains elusive how neural
network width affects model robustness. In this paper, we carefully examine the
relationship between network width and model robustness. Specifically, we show
that the model robustness is closely related to the tradeoff between natural
accuracy and perturbation stability, which is controlled by the robust
regularization parameter $\lambda$. With the same $\lambda$, wider networks can
achieve better natural accuracy but worse perturbation stability, leading to a
potentially worse overall model robustness. To understand the origin of this
phenomenon, we further relate the perturbation stability with the network&#x27;s
local Lipschitzness. By leveraging recent results on neural tangent kernels, we
theoretically show that wider networks tend to have worse perturbation
stability. Our analyses suggest that: 1) the common strategy of first
fine-tuning $\lambda$ on small networks and then directly use it for wide model
training could lead to deteriorated model robustness; 2) one needs to properly
enlarge $\lambda$ to unleash the robustness potential of wider models fully.
Finally, we propose a new Width Adjusted Regularization (WAR) method that
adaptively enlarges $\lambda$ on wide models and significantly saves the tuning
time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Introduction to Quantum Reinforcement Learning: Theory and PennyLane-based Implementation. (arXiv:2108.06849v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwak_Y/0/1/0/all/0/1">Yunseok Kwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_W/0/1/0/all/0/1">Won Joon Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Soyi Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jong-Kook Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Joongheon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06849">
                                    <div class="article-summary-box-inner">
                                        <span>The emergence of quantum computing enables for researchers to apply quantum
circuit on many existing studies. Utilizing quantum circuit and quantum
differential programming, many research are conducted such as \textit{Quantum
Machine Learning} (QML). In particular, quantum reinforcement learning is a
good field to test the possibility of quantum machine learning, and a lot of
research is being done. This work will introduce the concept of quantum
reinforcement learning using a variational quantum circuit, and confirm its
possibility through implementation and experimentation. We will first present
the background knowledge and working principle of quantum reinforcement
learning, and then guide the implementation method using the PennyLane library.
We will also discuss the power and possibility of quantum reinforcement
learning from the experimental results obtained through this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding Theoretical Advantages of Complex-Reaction Networks. (arXiv:2108.06711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shao-Qun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1">Gao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06711">
                                    <div class="article-summary-box-inner">
                                        <span>Complex-valued neural networks have attracted increasing attention in recent
years, while it remains open on the advantages of complex-valued neural
networks in comparison with real-valued networks. This work takes one step on
this direction by introducing the \emph{complex-reaction network} with
fully-connected feed-forward architecture. We prove the universal approximation
property for complex-reaction networks, and show that a class of radial
functions can be approximated by a complex-reaction network using the
polynomial number of parameters, whereas real-valued networks need at least
exponential parameters to reach the same approximation level. For empirical
risk minimization, our theoretical result shows that the critical point set of
complex-reaction networks is a proper subset of that of real-valued networks,
which may show some insights on finding the optimal solutions more easily for
complex-reaction networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent State Inference in a Spatiotemporal Generative Model. (arXiv:2009.09823v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karlbauer_M/0/1/0/all/0/1">Matthias Karlbauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Menge_T/0/1/0/all/0/1">Tobias Menge</a>, <a href="http://arxiv.org/find/cs/1/au:+Otte_S/0/1/0/all/0/1">Sebastian Otte</a>, <a href="http://arxiv.org/find/cs/1/au:+Lensch_H/0/1/0/all/0/1">Hendrik P.A. Lensch</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholten_T/0/1/0/all/0/1">Thomas Scholten</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulfmeyer_V/0/1/0/all/0/1">Volker Wulfmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Butz_M/0/1/0/all/0/1">Martin V. Butz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09823">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge about the hidden factors that determine particular system dynamics
is crucial for both explaining them and pursuing goal-directed interventions.
Inferring these factors from time series data without supervision remains an
open challenge. Here, we focus on spatiotemporal processes, including wave
propagation and weather dynamics, for which we assume that universal causes
(e.g. physics) apply throughout space and time. A recently introduced
DIstributed SpatioTemporal graph Artificial Neural network Architecture
(DISTANA) is used and enhanced to learn such processes, requiring fewer
parameters and achieving significantly more accurate predictions compared to
temporal convolutional neural networks and other related approaches. We show
that DISTANA, when combined with a retrospective latent state inference
principle called active tuning, can reliably derive location-respective hidden
causal factors. In a current weather prediction benchmark, DISTANA infers our
planet&#x27;s land-sea mask solely by observing temperature dynamics and, meanwhile,
uses the self inferred information to improve its own future temperature
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Representation Learning for Session-based Recommendation. (arXiv:2107.01516v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1">Sai Mitheran</a>, <a href="http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1">Abhinav Java</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1">Surya Kant Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1">Arshad Shaikh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01516">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation systems suggest relevant items to users by
modeling user behavior and preferences using short-term anonymous sessions.
Existing methods leverage Graph Neural Networks (GNNs) that propagate and
aggregate information from neighboring nodes i.e., local message passing. Such
graph-based architectures have representational limits, as a single sub-graph
is susceptible to overfit the sequential dependencies instead of accounting for
complex transitions between items in different sessions. We propose using a
Transformer in combination with a target attentive GNN, which allows richer
Representation Learning. Our experimental results and ablation show that our
proposed method is competitive with the existing methods on real-world
benchmark datasets, improving on graph-based hypotheses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Waveform-Based Acoustic Models using Deep Variational Convolutional Neural Networks. (arXiv:1906.09526v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Oglic_D/0/1/0/all/0/1">Dino Oglic</a>, <a href="http://arxiv.org/find/stat/1/au:+Cvetkovic_Z/0/1/0/all/0/1">Zoran Cvetkovic</a>, <a href="http://arxiv.org/find/stat/1/au:+Sollich_P/0/1/0/all/0/1">Peter Sollich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.09526">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the potential of stochastic neural networks for learning
effective waveform-based acoustic models. The waveform-based setting, inherent
to fully end-to-end speech recognition systems, is motivated by several
comparative studies of automatic and human speech recognition that associate
standard non-adaptive feature extraction techniques with information loss which
can adversely affect robustness. Stochastic neural networks, on the other hand,
are a class of models capable of incorporating rich regularization mechanisms
into the learning process. We consider a deep convolutional neural network that
first decomposes speech into frequency sub-bands via an adaptive parametric
convolutional block where filters are specified by cosine modulations of
compactly supported windows. The network then employs standard non-parametric
1D convolutions to extract relevant spectro-temporal patterns while gradually
compressing the structured high dimensional representation generated by the
parametric block. We rely on a probabilistic parametrization of the proposed
neural architecture and learn the model using stochastic variational inference.
This requires evaluation of an analytically intractable integral defining the
Kullback-Leibler divergence term responsible for regularization, for which we
propose an effective approximation based on the Gauss-Hermite quadrature. Our
empirical results demonstrate a superior performance of the proposed approach
over comparable waveform-based baselines and indicate that it could lead to
robustness. Moreover, the approach outperforms a recently proposed deep
convolutional neural network for learning of robust acoustic models with
standard FBANK features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Safety Case for Hardware Fault Tolerance in Convolutional Neural Networks Using Activation Range Supervision. (arXiv:2108.07019v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geissler_F/0/1/0/all/0/1">Florian Geissler</a>, <a href="http://arxiv.org/find/cs/1/au:+Qutub_S/0/1/0/all/0/1">Syed Qutub</a>, <a href="http://arxiv.org/find/cs/1/au:+Roychowdhury_S/0/1/0/all/0/1">Sayanta Roychowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Asgari_A/0/1/0/all/0/1">Ali Asgari</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yang Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamasia_A/0/1/0/all/0/1">Akash Dhamasia</a>, <a href="http://arxiv.org/find/cs/1/au:+Graefe_R/0/1/0/all/0/1">Ralf Graefe</a>, <a href="http://arxiv.org/find/cs/1/au:+Pattabiraman_K/0/1/0/all/0/1">Karthik Pattabiraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulitsch_M/0/1/0/all/0/1">Michael Paulitsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07019">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have become an established part of
numerous safety-critical computer vision applications, including human robot
interactions and automated driving. Real-world implementations will need to
guarantee their robustness against hardware soft errors corrupting the
underlying platform memory. Based on the previously observed efficacy of
activation clipping techniques, we build a prototypical safety case for
classifier CNNs by demonstrating that range supervision represents a highly
reliable fault detector and mitigator with respect to relevant bit flips,
adopting an eight-exponent floating point data representation. We further
explore novel, non-uniform range restriction methods that effectively suppress
the probability of silent data corruptions and uncorrectable errors. As a
safety-relevant end-to-end use case, we showcase the benefit of our approach in
a vehicle classification scenario, using ResNet-50 and the traffic camera data
set MIOVision. The quantitative evidence provided in this work can be leveraged
to inspire further and possibly more complex CNN safety arguments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiMBNN: Matched and Balanced Causal Inference with Neural Networks. (arXiv:2004.13446v4 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sharma_A/0/1/0/all/0/1">Ankit Sharma</a>, <a href="http://arxiv.org/find/stat/1/au:+Gupta_G/0/1/0/all/0/1">Garima Gupta</a>, <a href="http://arxiv.org/find/stat/1/au:+Prasad_R/0/1/0/all/0/1">Ranjitha Prasad</a>, <a href="http://arxiv.org/find/stat/1/au:+Chatterjee_A/0/1/0/all/0/1">Arnab Chatterjee</a>, <a href="http://arxiv.org/find/stat/1/au:+Vig_L/0/1/0/all/0/1">Lovekesh Vig</a>, <a href="http://arxiv.org/find/stat/1/au:+Shroff_G/0/1/0/all/0/1">Gautam Shroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13446">
                                    <div class="article-summary-box-inner">
                                        <span>Causal inference (CI) in observational studies has received a lot of
attention in healthcare, education, ad attribution, policy evaluation, etc.
Confounding is a typical hazard, where the context affects both, the treatment
assignment and response. In a multiple treatment scenario, we propose the
neural network based MultiMBNN, where we overcome confounding by employing
generalized propensity score based matching, and learning balanced
representations. We benchmark the performance on synthetic and real-world
datasets using PEHE, and mean absolute percentage error over ATE as metrics.
MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and
Perfect Match (PM).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multistream Graph Attention Networks for Wind Speed Forecasting. (arXiv:2108.07063v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aykas_D/0/1/0/all/0/1">Dogan Aykas</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrkanoon_S/0/1/0/all/0/1">Siamak Mehrkanoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07063">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable and accurate wind speed prediction has significant impact in many
industrial sectors such as economic, business and management among others. This
paper presents a new model for wind speed prediction based on Graph Attention
Networks (GAT). In particular, the proposed model extends GAT architecture by
equipping it with a learnable adjacency matrix as well as incorporating a new
attention mechanism with the aim of obtaining attention scores per weather
variable. The output of the GAT based model is combined with the LSTM layer in
order to exploit both the spatial and temporal characteristics of the
multivariate multidimensional historical weather data. Real weather data
collected from several cities in Denmark and Netherlands are used to conduct
the experiments and evaluate the performance of the proposed model. We show
that in comparison to previous architectures used for wind speed prediction,
the proposed model is able to better learn the complex input-output
relationships of the weather data. Furthermore, thanks to the learned attention
weights, the model provides an additional insights on the most important
weather variables and cities for the studied prediction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PaDGAN: A Generative Adversarial Network for Performance Augmented Diverse Designs. (arXiv:2002.11304v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1">Faez Ahmed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11304">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models are proven to be a useful tool for automatic design
synthesis and design space exploration. When applied in engineering design,
existing generative models face three challenges: 1) generated designs lack
diversity and do not cover all areas of the design space, 2) it is difficult to
explicitly improve the overall performance or quality of generated designs, and
3) existing models generally do not generate novel designs, outside the domain
of the training data. In this paper, we simultaneously address these challenges
by proposing a new Determinantal Point Processes based loss function for
probabilistic modeling of diversity and quality. With this new loss function,
we develop a variant of the Generative Adversarial Network, named &quot;Performance
Augmented Diverse Generative Adversarial Network&quot; or PaDGAN, which can generate
novel high-quality designs with good coverage of the design space. Using three
synthetic examples and one real-world airfoil design example, we demonstrate
that PaDGAN can generate diverse and high-quality designs. In comparison to a
vanilla Generative Adversarial Network, on average, it generates samples with a
28% higher mean quality score with larger diversity and without the mode
collapse issue. Unlike typical generative models that usually generate new
designs by interpolating within the boundary of training data, we show that
PaDGAN expands the design space boundary outside the training data towards
high-quality regions. The proposed method is broadly applicable to many tasks
including design space exploration, design optimization, and creative solution
recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge-Based Construction of Confusion Matrices for Multi-Label Classification Algorithms using Semantic Similarity Measures. (arXiv:2011.00109v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turki_H/0/1/0/all/0/1">Houcemeddine Turki</a>, <a href="http://arxiv.org/find/cs/1/au:+Taieb_M/0/1/0/all/0/1">Mohamed Ali Hadj Taieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Aouicha_M/0/1/0/all/0/1">Mohamed Ben Aouicha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00109">
                                    <div class="article-summary-box-inner">
                                        <span>So far, multi-label classification algorithms have been evaluated using
statistical methods that do not consider the semantics of the considered
classes and that fully depend on abstract computations such as Bayesian
Reasoning. Currently, there are several attempts to develop ontology-based
methods for a better assessment of supervised classification algorithms. In
this research paper, we define a novel approach that aligns expected labels
with predicted labels in multi-label classification using ontology-driven
feature-based semantic similarity measures and we use it to develop a method
for creating precise confusion matrices for a more effective evaluation of
multi-label classification algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search. (arXiv:1908.06022v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruijun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xudong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.06022">
                                    <div class="article-summary-box-inner">
                                        <span>To discover powerful yet compact models is an important goal of neural
architecture search. Previous two-stage one-shot approaches are limited by
search space with a fixed depth. It seems handy to include an additional skip
connection in the search space to make depths variable. However, it creates a
large range of perturbation during supernet training and it has difficulty
giving a confident ranking for subnetworks. In this paper, we discover that
skip connections bring about significant feature inconsistency compared with
other operations, which potentially degrades the supernet performance. Based on
this observation, we tackle the problem by imposing an equivariant learnable
stabilizer to homogenize such disparities. Experiments show that our proposed
stabilizer helps to improve the supernet&#x27;s convergence as well as ranking
performance. With an evolutionary search backend that incorporates the
stabilized supernet as an evaluator, we derive a family of state-of-the-art
architectures, the SCARLET series of several depths, especially SCARLET-A
obtains 76.9% top-1 accuracy on ImageNet. Code is available at
https://github.com/xiaomi-automl/ScarletNAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-wise Split Gradient Boosting Trees for Multi-center Diabetes Prediction. (arXiv:2108.07107v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingcheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhiyun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiawei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jian Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Yanru Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jieli Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tiange Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1">Wei-Wei Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1">Yufang Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_G/0/1/0/all/0/1">Guang Ning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07107">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetes prediction is an important data science application in the social
healthcare domain. There exist two main challenges in the diabetes prediction
task: data heterogeneity since demographic and metabolic data are of different
types, data insufficiency since the number of diabetes cases in a single
medical center is usually limited. To tackle the above challenges, we employ
gradient boosting decision trees (GBDT) to handle data heterogeneity and
introduce multi-task learning (MTL) to solve data insufficiency. To this end,
Task-wise Split Gradient Boosting Trees (TSGB) is proposed for the multi-center
diabetes prediction task. Specifically, we firstly introduce task gain to
evaluate each task separately during tree construction, with a theoretical
analysis of GBDT&#x27;s learning objective. Secondly, we reveal a problem when
directly applying GBDT in MTL, i.e., the negative task gain problem. Finally,
we propose a novel split method for GBDT in MTL based on the task gain
statistics, named task-wise split, as an alternative to standard feature-wise
split to overcome the mentioned negative task gain problem. Extensive
experiments on a large-scale real-world diabetes dataset and a commonly used
benchmark dataset demonstrate TSGB achieves superior performance against
several state-of-the-art methods. Detailed case studies further support our
analysis of negative task gain problems and provide insightful findings. The
proposed TSGB method has been deployed as an online diabetes risk assessment
software for early diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vehicle-counting with Automatic Region-of-Interest and Driving-Trajectory detection. (arXiv:2108.07135v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasu_M/0/1/0/all/0/1">Malolan Vasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abreu_N/0/1/0/all/0/1">Nelson Abreu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_R/0/1/0/all/0/1">Raysa V&#xe1;squez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_C/0/1/0/all/0/1">Christian L&#xf3;pez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07135">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicle counting systems can help with vehicle analysis and traffic incident
detection. Unfortunately, most existing methods require some level of human
input to identify the Region of interest (ROI), movements of interest, or to
establish a reference point or line to count vehicles from traffic cameras.
This work introduces a method to count vehicles from traffic videos that
automatically identifies the ROI for the camera, as well as the driving
trajectories of the vehicles. This makes the method feasible to use with
Pan-Tilt-Zoom cameras, which are frequently used in developing countries.
Preliminary results indicate that the proposed method achieves an average
intersection over the union of 57.05% for the ROI and a mean absolute error of
just 17.44% at counting vehicles of the traffic video cameras tested.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile Application. (arXiv:2008.09264v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Wen Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Hung_K/0/1/0/all/0/1">Kuo-Hsuan Hung</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">You-Jin Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Kang_A/0/1/0/all/0/1">Alexander Chao-Fu Kang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lai_Y/0/1/0/all/0/1">Ya-Hsin Lai</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_K/0/1/0/all/0/1">Kai-Chun Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1">Sze-Wei Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Syu-Siang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09264">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a deep learning-based speech signal-processing
mobile application, CITISEN, which can perform three functions: speech
enhancement (SE), acoustic scene conversion (ASC), and model adaptation (MA).
For SE, CITISEN can effectively reduce noise components from speech signals and
accordingly enhance their clarity and intelligibility. For ASC, CITISEN can
convert the current background sound to a different background sound. Finally,
for MA, CITISEN can effectively adapt an SE model, with a few audio files, when
it encounters unknown speakers or noise types; the adapted SE model is used to
enhance the upcoming noisy utterances. Experimental results confirmed the
effectiveness of CITISEN in performing these three functions via objective
evaluation and subjective listening tests. The promising results reveal that
the developed CITISEN mobile application can potentially be used as a front-end
processor for various speech-related services such as voice communication,
assistive hearing devices, and virtual reality headsets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GC-TTS: Few-shot Speaker Adaptation with Geometric Constraints. (arXiv:2108.06890v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1">Ji-Hoon Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1">Sang-Hoon Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1">Ji-Hyun Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Jung_H/0/1/0/all/0/1">Hong-Gyu Jung</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06890">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot speaker adaptation is a specific Text-to-Speech (TTS) system that
aims to reproduce a novel speaker&#x27;s voice with a few training data. While
numerous attempts have been made to the few-shot speaker adaptation system,
there is still a gap in terms of speaker similarity to the target speaker
depending on the amount of data. To bridge the gap, we propose GC-TTS which
achieves high-quality speaker adaptation with significantly improved speaker
similarity. Specifically, we leverage two geometric constraints to learn
discriminative speaker representations. Here, a TTS model is pre-trained for
base speakers with a sufficient amount of data, and then fine-tuned for novel
speakers on a few minutes of data with two geometric constraints. Two geometric
constraints enable the model to extract discriminative speaker embeddings from
limited data, which leads to the synthesis of intelligible speech. We discuss
and verify the effectiveness of GC-TTS by comparing it with popular and
essential methods. The experimental results demonstrate that GC-TTS generates
high-quality speech from only a few minutes of training data, outperforming
standard techniques in terms of speaker similarity to the target speaker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-Efficient and Byzantine-Robust Distributed Learning with Error Feedback. (arXiv:1911.09721v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Avishek Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Maity_R/0/1/0/all/0/1">Raj Kumar Maity</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadhe_S/0/1/0/all/0/1">Swanand Kadhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1">Arya Mazumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.09721">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a communication-efficient distributed learning algorithm that is
robust against Byzantine worker machines. We propose and analyze a distributed
gradient-descent algorithm that performs a simple thresholding based on
gradient norms to mitigate Byzantine failures. We show the (statistical)
error-rate of our algorithm matches that of Yin et al.~\cite{dong}, which uses
more complicated schemes (coordinate-wise median, trimmed mean). Furthermore,
for communication efficiency, we consider a generic class of
$\delta$-approximate compressors from Karimireddi et al.~\cite{errorfeed} that
encompasses sign-based compressors and top-$k$ sparsification. Our algorithm
uses compressed gradients and gradient norms for aggregation and Byzantine
removal respectively. We establish the statistical error rate for non-convex
smooth loss functions. We show that, in certain range of the compression factor
$\delta$, the (order-wise) rate of convergence is not affected by the
compression operation. Moreover, we analyze the compressed gradient descent
algorithm with error feedback (proposed in \cite{errorfeed}) in a distributed
setting and in the presence of Byzantine worker machines. We show that
exploiting error feedback improves the statistical error rate. Finally, we
experimentally validate our results and show good performance in convergence
for convex (least-square regression) and non-convex (neural network training)
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A diffusion-map-based algorithm for gradient computation on manifolds and applications. (arXiv:2108.06988v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Alvaro Almeida Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Neto_A/0/1/0/all/0/1">Ant&#xf4;nio J. Silva Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Zubelli_J/0/1/0/all/0/1">Jorge P. Zubelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06988">
                                    <div class="article-summary-box-inner">
                                        <span>We recover the gradient of a given function defined on interior points of a
submanifold with boundary of the Euclidean space based on a (normally
distributed) random sample of function evaluations at points in the manifold.
This approach is based on the estimates of the Laplace-Beltrami operator
proposed in the theory of Diffusion-Maps. Analytical convergence results of the
resulting expansion are proved, and an efficient algorithm is proposed to deal
with non-convex optimization problems defined on Euclidean submanifolds. We
test and validate our methodology as a post-processing tool in Cryogenic
electron microscopy (Cryo-EM). We also apply the method to the classical sphere
packing problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicitly Regularized RL with Implicit Q-Values. (arXiv:2108.07041v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1">Nino Vieillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrychowicz_M/0/1/0/all/0/1">Marcin Andrychowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Raichuk_A/0/1/0/all/0/1">Anton Raichuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07041">
                                    <div class="article-summary-box-inner">
                                        <span>The $Q$-function is a central quantity in many Reinforcement Learning (RL)
algorithms for which RL agents behave following a (soft)-greedy policy w.r.t.
to $Q$. It is a powerful tool that allows action selection without a model of
the environment and even without explicitly modeling the policy. Yet, this
scheme can only be used in discrete action tasks, with small numbers of
actions, as the softmax cannot be computed exactly otherwise. Especially the
usage of function approximation, to deal with continuous action spaces in
modern actor-critic architectures, intrinsically prevents the exact computation
of a softmax. We propose to alleviate this issue by parametrizing the
$Q$-function implicitly, as the sum of a log-policy and of a value function. We
use the resulting parametrization to derive a practical off-policy deep RL
algorithm, suitable for large action spaces, and that enforces the softmax
relation between the policy and the $Q$-value. We provide a theoretical
analysis of our algorithm: from an Approximate Dynamic Programming perspective,
we show its equivalence to a regularized version of value iteration, accounting
for both entropy and Kullback-Leibler regularization, and that enjoys
beneficial error propagation results. We then evaluate our algorithm on classic
control tasks, where its results compete with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiseR: An end-to-end structure learning and deployment framework for causal graphical models. (arXiv:2108.07046v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maheshwari_S/0/1/0/all/0/1">Shubham Maheshwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pahwa_K/0/1/0/all/0/1">Khushbu Pahwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_T/0/1/0/all/0/1">Tavpritesh Sethi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07046">
                                    <div class="article-summary-box-inner">
                                        <span>Structure learning offers an expressive, versatile and explainable approach
to causal and mechanistic modeling of complex biological data. We present
wiseR, an open source application for learning, evaluating and deploying robust
causal graphical models using graph neural networks and Bayesian networks. We
demonstrate the utility of this application through application on for
biomarker discovery in a COVID-19 clinical dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Dat Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1">Stephen S. Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01777">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel interpretable deep neural network for text classification,
called ProtoryNet, based on a new concept of prototype trajectories. Motivated
by the prototype theory in modern linguistics, ProtoryNet makes a prediction by
finding the most similar prototype for each sentence in a text sequence and
feeding an RNN backbone with the proximity of each sentence to the
corresponding active prototype. The RNN backbone then captures the temporal
pattern of the prototypes, which we refer to as prototype trajectories.
Prototype trajectories enable intuitive and fine-grained interpretation of the
reasoning process of the RNN model, in resemblance to how humans analyze texts.
We also design a prototype pruning procedure to reduce the total number of
prototypes used by the model for better interpretability. Experiments on
multiple public data sets show that ProtoryNet is more accurate than the
baseline prototype-based deep neural net and reduces the performance gap
compared to state-of-the-art black-box models. In addition, after prototype
pruning, the resulting ProtoryNet models only need less than or around 20
prototypes for all datasets, which significantly benefits interpretability.
Furthermore, we report a survey result indicating that human users find
ProtoryNet more intuitive and easier to understand than other prototype-based
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HAA500: Human-Centric Atomic Action Dataset with Curated Videos. (arXiv:2009.05224v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jihoon Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Wuu_C/0/1/0/all/0/1">Cheng-hsin Wuu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hsuan-ru Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Yu-Wing Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chi-Keung Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05224">
                                    <div class="article-summary-box-inner">
                                        <span>We contribute HAA500, a manually annotated human-centric atomic action
dataset for action recognition on 500 classes with over 591K labeled frames. To
minimize ambiguities in action classification, HAA500 consists of highly
diversified classes of fine-grained atomic actions, where only consistent
actions fall under the same label, e.g., &quot;Baseball Pitching&quot; vs &quot;Free Throw in
Basketball&quot;. Thus HAA500 is different from existing atomic action datasets,
where coarse-grained atomic actions were labeled with coarse action-verbs such
as &quot;Throw&quot;. HAA500 has been carefully curated to capture the precise movement
of human figures with little class-irrelevant motions or spatio-temporal label
noises. The advantages of HAA500 are fourfold: 1) human-centric actions with a
high average of 69.7% detectable joints for the relevant human poses; 2) high
scalability since adding a new class can be done under 20-60 minutes; 3)
curated videos capturing essential elements of an atomic action without
irrelevant frames; 4) fine-grained atomic action classes. Our extensive
experiments including cross-data validation using datasets collected in the
wild demonstrate the clear benefits of human-centric and atomic characteristics
of HAA500, which enable training even a baseline deep learning model to improve
prediction by attending to atomic human poses. We detail the HAA500 dataset
statistics and collection methodology and compare quantitatively with existing
action recognition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A physics-informed variational DeepONet for predicting the crack path in brittle materials. (arXiv:2108.06905v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1">Somdatta Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1">Minglang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1">George Karniadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06905">
                                    <div class="article-summary-box-inner">
                                        <span>Failure trajectories, identifying the probable failure zones, and damage
statistics are some of the key quantities of relevance in brittle fracture
applications. High-fidelity numerical solvers that reliably estimate these
relevant quantities exist but they are computationally demanding requiring a
high resolution of the crack. Moreover, independent intensive simulations need
to be carried out even for a small change in domain parameters and/or material
properties. Therefore, fast and generalizable surrogate models are needed to
alleviate the computational burden but the discontinuous nature of fracture
mechanics presents a major challenge to developing such models. We propose a
physics-informed variational formulation of DeepONet (V-DeepONet) for brittle
fracture analysis. V-DeepONet is trained to map the initial configuration of
the defect to the relevant fields of interests (e.g., damage and displacement
fields). Once the network is trained, the entire global solution can be rapidly
obtained for any initial crack configuration and loading steps on that domain.
While the original DeepONet is solely data-driven, we take a different path to
train the V-DeepONet by imposing the governing equations in variational form
and we also use some labelled data. We demonstrate the effectiveness of
V-DeepOnet through two benchmarks of brittle fracture, and we verify its
accuracy using results from high-fidelity solvers. Encoding the physical laws
and also some data to train the network renders the surrogate model capable of
accurately performing both interpolation and extrapolation tasks, considering
that fracture modeling is very sensitive to fluctuations. The proposed hybrid
training of V-DeepONet is superior to state-of-the-art methods and can be
applied to a wide array of dynamical systems with complex responses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Molecular Design by Stochastic Iterative Target Augmentation. (arXiv:2002.04720v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wengong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Swanson_K/0/1/0/all/0/1">Kyle Swanson</a>, <a href="http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1">Regina Barzilay</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1">Tommi Jaakkola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04720">
                                    <div class="article-summary-box-inner">
                                        <span>Generative models in molecular design tend to be richly parameterized,
data-hungry neural models, as they must create complex structured objects as
outputs. Estimating such models from data may be challenging due to the lack of
sufficient training data. In this paper, we propose a surprisingly effective
self-training approach for iteratively creating additional molecular targets.
We first pre-train the generative model together with a simple property
predictor. The property predictor is then used as a likelihood model for
filtering candidate structures from the generative model. Additional targets
are iteratively produced and used in the course of stochastic EM iterations to
maximize the log-likelihood that the candidate structures are accepted. A
simple rejection (re-weighting) sampler suffices to draw posterior samples
since the generative model is already reasonable after pre-training. We
demonstrate significant gains over strong baselines for both unconditional and
conditional molecular design. In particular, our approach outperforms the
previous state-of-the-art in conditional molecular design by over 10% in
absolute gain. Finally, we show that our approach is useful in other domains as
well, such as program synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Predictive Monitoring under Partial Observabilit. (arXiv:2108.07134v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cairoli_F/0/1/0/all/0/1">Francesca Cairoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bortolussi_L/0/1/0/all/0/1">Luca Bortolussi</a>, <a href="http://arxiv.org/find/cs/1/au:+Paoletti_N/0/1/0/all/0/1">Nicola Paoletti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07134">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of predictive monitoring (PM), i.e., predicting at
runtime future violations of a system from the current state. We work under the
most realistic settings where only partial and noisy observations of the state
are available at runtime. Such settings directly affect the accuracy and
reliability of the reachability predictions, jeopardizing the safety of the
system. In this work, we present a learning-based method for PM that produces
accurate and reliable reachability predictions despite partial observability
(PO). We build on Neural Predictive Monitoring (NPM), a PM method that uses
deep neural networks for approximating hybrid systems reachability, and extend
it to the PO case. We propose and compare two solutions, an end-to-end
approach, which directly operates on the rough observations, and a two-step
approach, which introduces an intermediate state estimation step. Both
solutions rely on conformal prediction to provide 1) probabilistic guarantees
in the form of prediction regions and 2) sound estimates of predictive
uncertainty. We use the latter to identify unreliable (and likely erroneous)
predictions and to retrain and improve the monitors on these uncertain inputs
(i.e., active learning). Our method results in highly accurate reachability
predictions and error detection, as well as tight prediction regions with
guaranteed coverage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A complex network approach to time series analysis with application in diagnosis of neuromuscular disorders. (arXiv:2108.06920v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samiei_S/0/1/0/all/0/1">Samaneh Samiei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghadiri_N/0/1/0/all/0/1">Nasser Ghadiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Ansari_B/0/1/0/all/0/1">Behnaz Ansari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06920">
                                    <div class="article-summary-box-inner">
                                        <span>Electromyography (EMG) refers to a biomedical signal indicating neuromuscular
activity and muscle morphology. Experts accurately diagnose neuromuscular
disorders using this time series. Modern data analysis techniques have recently
led to introducing novel approaches for mapping time series data to graphs and
complex networks with applications in diverse fields, including medicine. The
resulting networks develop a completely different visual acuity that can be
used to complement physician findings of time series. This can lead to a more
enriched analysis, reduced error, more accurate diagnosis of the disease, and
increased accuracy and speed of the treatment process. The mapping process may
cause the loss of essential data from the time series and not retain all the
time series features. As a result, achieving an approach that can provide a
good representation of the time series while maintaining essential features is
crucial. This paper proposes a new approach to network development named
GraphTS to overcome the limited accuracy of existing methods through EMG time
series using the visibility graph method. For this purpose, EMG signals are
pre-processed and mapped to a complex network by a standard visibility graph
algorithm. The resulting networks can differentiate between healthy and patient
samples. In the next step, the properties of the developed networks are given
in the form of a feature matrix as input to classifiers after extracting
optimal features. Performance evaluation of the proposed approach with deep
neural network shows 99.30% accuracy for training data and 99.18% for test
data. Therefore, in addition to enriched network representation and covering
the features of time series for healthy, myopathy, and neuropathy EMG, the
proposed technique improves accuracy, precision, recall, and F-score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Siamese Network for Identifying Bad Data in Medical Imaging Datasets. (arXiv:2108.07130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belton_N/0/1/0/all/0/1">Niamh Belton</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawlor_A/0/1/0/all/0/1">Aonghus Lawlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Curran_K/0/1/0/all/0/1">Kathleen M. Curran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07130">
                                    <div class="article-summary-box-inner">
                                        <span>Noisy data present in medical imaging datasets can often aid the development
of robust models that are equipped to handle real-world data. However, if the
bad data contains insufficient anatomical information, it can have a severe
negative effect on the model&#x27;s performance. We propose a novel methodology
using a semi-supervised Siamese network to identify bad data. This method
requires only a small pool of &#x27;reference&#x27; medical images to be reviewed by a
non-expert human to ensure the major anatomical structures are present in the
Field of View. The model trains on this reference set and identifies bad data
by using the Siamese network to compute the distance between the reference set
and all other medical images in the dataset. This methodology achieves an Area
Under the Curve (AUC) of 0.989 for identifying bad data. Code will be available
at https://git.io/JYFuV.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting and interpreting faults in vulnerable power grids with machine learning. (arXiv:2108.07060v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eikeland_O/0/1/0/all/0/1">Odin Foldvik Eikeland</a>, <a href="http://arxiv.org/find/cs/1/au:+Holmstrand_I/0/1/0/all/0/1">Inga Sets&#xe5; Holmstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakkejord_S/0/1/0/all/0/1">Sigurd Bakkejord</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiesa_M/0/1/0/all/0/1">Matteo Chiesa</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1">Filippo Maria Bianchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07060">
                                    <div class="article-summary-box-inner">
                                        <span>Unscheduled power disturbances cause severe consequences both for customers
and grid operators. To defend against such events, it is necessary to identify
the causes of interruptions in the power distribution network. In this work, we
focus on the power grid of a Norwegian community in the Arctic that experiences
several faults whose sources are unknown. First, we construct a data set
consisting of relevant meteorological data and information about the current
power quality logged by power-quality meters. Then, we adopt machine-learning
techniques to predict the occurrence of faults. Experimental results show that
both linear and non-linear classifiers achieve good classification performance.
This indicates that the considered power-quality and weather variables explain
well the power disturbances. Interpreting the decision process of the
classifiers provides valuable insights to understand the main causes of
disturbances. Traditional features selection methods can only indicate which
are the variables that, on average, mostly explain the fault occurrences in the
dataset. Besides providing such a global interpretation, it is also important
to identify the specific set of variables that explain each individual fault.
To address this challenge, we adopt a recent technique to interpret the
decision process of a deep learning model, called Integrated Gradients. The
proposed approach allows to gain detailed insights on the occurrence of a
specific fault, which are valuable for the distribution system operators to
implement strategies to prevent and mitigate power disturbances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AIREX: Neural Network-based Approach for Air Quality Inference in Unmonitored Cities. (arXiv:2108.07120v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sasaki_Y/0/1/0/all/0/1">Yuya Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Harada_K/0/1/0/all/0/1">Kei Harada</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamasaki_S/0/1/0/all/0/1">Shohei Yamasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Onizuka_M/0/1/0/all/0/1">Makoto Onizuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07120">
                                    <div class="article-summary-box-inner">
                                        <span>Urban air pollution is a major environmental problem affecting human health
and quality of life. Monitoring stations have been established to continuously
obtain air quality information, but they do not cover all areas. Thus, there
are numerous methods for spatially fine-grained air quality inference. Since
existing methods aim to infer air quality of locations only in monitored
cities, they do not assume inferring air quality in unmonitored cities. In this
paper, we first study the air quality inference in unmonitored cities. To
accurately infer air quality in unmonitored cities, we propose a neural
network-based approach AIREX. The novelty of AIREX is employing a
mixture-of-experts approach, which is a machine learning technique based on the
divide-and-conquer principle, to learn correlations of air quality between
multiple cities. To further boost the performance, it employs attention
mechanisms to compute impacts of air quality inference from the monitored
cities to the locations in the unmonitored city. We show, through experiments
on a real-world air quality dataset, that AIREX achieves higher accuracy than
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of Abnormal States in Videos of Ants Undergoing Social Phase Change. (arXiv:2009.08626v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_T/0/1/0/all/0/1">Taeyeong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyenson_B/0/1/0/all/0/1">Benjamin Pyenson</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebig_J/0/1/0/all/0/1">Juergen Liebig</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlic_T/0/1/0/all/0/1">Theodore P. Pavlic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08626">
                                    <div class="article-summary-box-inner">
                                        <span>Biology is both an important application area and a source of motivation for
development of advanced machine learning techniques. Although much attention
has been paid to large and complex data sets resulting from high-throughput
sequencing, advances in high-quality video recording technology have begun to
generate similarly rich data sets requiring sophisticated techniques from both
computer vision and time-series analysis. Moreover, just as studying gene
expression patterns in one organism can reveal general principles that apply to
other organisms, the study of complex social interactions in an experimentally
tractable model system, such as a laboratory ant colony, can provide general
principles about the dynamics of other social groups. Here, we focus on one
such example from the study of reproductive regulation in small laboratory
colonies of more than 50 Harpegnathos ants. These ants can be artificially
induced to begin a ~20 day process of hierarchy reformation. Although the
conclusion of this process is conspicuous to a human observer, it remains
unclear which behaviors during the transient period are contributing to the
process. To address this issue, we explore the potential application of
One-class Classification (OC) to the detection of abnormal states in ant
colonies for which behavioral data is only available for the normal societal
conditions during training. Specifically, we build upon the Deep Support Vector
Data Description (DSVDD) and introduce the Inner-Outlier Generator (IO-GEN)
that synthesizes fake &quot;inner outlier&quot; observations during training that are
near the center of the DSVDD data description. We show that IO-GEN increases
the reliability of the final OC classifier relative to other DSVDD baselines.
This method can be used to screen video frames for which additional human
observation is needed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-Based Information Compression for Multi-Agent Communication Problems with Channel Rate Constraints. (arXiv:2005.14220v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mostaani_A/0/1/0/all/0/1">Arsham Mostaani</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Thang X. Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzinotas_S/0/1/0/all/0/1">Symeon Chatzinotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottersten_B/0/1/0/all/0/1">Bj&#xf6;rn Ottersten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.14220">
                                    <div class="article-summary-box-inner">
                                        <span>A collaborative task is assigned to a multiagent system (MAS) in which agents
are allowed to communicate. The MAS runs over an underlying Markov decision
process and its task is to maximize the averaged sum of discounted one-stage
rewards. Although knowing the global state of the environment is necessary for
the optimal action selection of the MAS, agents are limited to individual
observations. Inter-agent communication can tackle the issue of local
observability, however, the limited rate of inter-agent communication prevents
the agents from acquiring the precise global state information. To overcome
this challenge, agents need to communicate an abstract version of their
observations to each other such that the MAS compromises the minimum possible
sum of rewards. We show that this problem is equivalent to a form of
rate-distortion problem, which we call task-based information compression
(TBIC). We introduce state aggregation for information compression (SAIC) to
solve the TBIC problem. SAIC is shown to achieve near-optimal performance in
terms of the achieved sum of discounted rewards. The proposed algorithm is
applied to a rendezvous problem and its performance is compared with several
benchmarks. Numerical experiments confirm the superiority of the proposed
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MINE: Mutual Information Neural Estimation. (arXiv:1801.04062v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belghazi_M/0/1/0/all/0/1">Mohamed Ishmael Belghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Baratin_A/0/1/0/all/0/1">Aristide Baratin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1">Sai Rajeswar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1">Sherjil Ozair</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>, <a href="http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1">R Devon Hjelm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1801.04062">
                                    <div class="article-summary-box-inner">
                                        <span>We argue that the estimation of mutual information between high dimensional
continuous random variables can be achieved by gradient descent over neural
networks. We present a Mutual Information Neural Estimator (MINE) that is
linearly scalable in dimensionality as well as in sample size, trainable
through back-prop, and strongly consistent. We present a handful of
applications on which MINE can be used to minimize or maximize mutual
information. We apply MINE to improve adversarially trained generative models.
We also use MINE to implement Information Bottleneck, applying it to supervised
classification; our results demonstrate substantial improvement in flexibility
and performance in these settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Dilation for Adversarial Robustness. (arXiv:2108.06885v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaohui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06885">
                                    <div class="article-summary-box-inner">
                                        <span>With the tremendous advances in the architecture and scale of convolutional
neural networks (CNNs) over the past few decades, they can easily reach or even
exceed the performance of humans in certain tasks. However, a recently
discovered shortcoming of CNNs is that they are vulnerable to adversarial
attacks. Although the adversarial robustness of CNNs can be improved by
adversarial training, there is a trade-off between standard accuracy and
adversarial robustness. From the neural architecture perspective, this paper
aims to improve the adversarial robustness of the backbone CNNs that have a
satisfactory accuracy. Under a minimal computational overhead, the introduction
of a dilation architecture is expected to be friendly with the standard
performance of the backbone CNN while pursuing adversarial robustness.
Theoretical analyses on the standard and adversarial error bounds naturally
motivate the proposed neural architecture dilation algorithm. Experimental
results on real-world datasets and benchmark neural networks demonstrate the
effectiveness of the proposed algorithm to balance the accuracy and adversarial
robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Local Feature Aggregation on Graphs via Latent Fixed Data Structures. (arXiv:2108.07028v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rahmani_M/0/1/0/all/0/1">Mostafa Rahmani</a>, <a href="http://arxiv.org/find/stat/1/au:+Shafipour_R/0/1/0/all/0/1">Rasoul Shafipour</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1">Ping Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07028">
                                    <div class="article-summary-box-inner">
                                        <span>In contrast to image/text data whose order can be used to perform non-local
feature aggregation in a straightforward way using the pooling layers, graphs
lack the tensor representation and mostly the element-wise max/mean function is
utilized to aggregate the locally extracted feature vectors. In this paper, we
present a novel approach for global feature aggregation in Graph Neural
Networks (GNNs) which utilizes a Latent Fixed Data Structure (LFDS) to
aggregate the extracted feature vectors. The locally extracted feature vectors
are sorted/distributed on the LFDS and a latent neural network (CNN/GNN) is
utilized to perform feature aggregation on the LFDS. The proposed approach is
used to design several novel global feature aggregation methods based on the
choice of the LFDS. We introduce multiple LFDSs including loop, 3D tensor
(image), sequence, data driven graphs and an algorithm which sorts/distributes
the extracted local feature vectors on the LFDS. While the computational
complexity of the proposed methods are linear with the order of input graphs,
they achieve competitive or better results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Graph Vulnerability and Robustness using TIGER. (arXiv:2006.05648v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Freitas_S/0/1/0/all/0/1">Scott Freitas</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Diyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Srijan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1">Hanghang Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1">Duen Horng Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05648">
                                    <div class="article-summary-box-inner">
                                        <span>Network robustness plays a crucial role in our understanding of complex
interconnected systems such as transportation, communication, and computer
networks. While significant research has been conducted in the area of network
robustness, no comprehensive open-source toolbox currently exists to assist
researchers and practitioners in this important topic. This lack of available
tools hinders reproducibility and examination of existing work, development of
new research, and dissemination of new ideas. We contribute TIGER, an
open-sourced Python toolbox to address these challenges. TIGER contains 22
graph robustness measures with both original and fast approximate versions; 17
failure and attack strategies; 15 heuristic and optimization-based defense
techniques; and 4 simulation tools. By democratizing the tools required to
study network robustness, our goal is to assist researchers and practitioners
in analyzing their own networks; and facilitate the development of new research
in the field. TIGER has been integrated into the Nvidia Data Science Teaching
Kit available to educators across the world; and Georgia Tech&#x27;s Data and Visual
Analytics class with over 1,000 students. TIGER is open sourced at:
https://github.com/safreita1/TIGER</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-Sensitive Concept Drift Detector with Metric Learning. (arXiv:2108.06980v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellani_A/0/1/0/all/0/1">Andrea Castellani</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1">Sebastian Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1">Barbara Hammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06980">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting drifts in data is essential for machine learning applications, as
changes in the statistics of processed data typically has a profound influence
on the performance of trained models. Most of the available drift detection
methods require access to true labels during inference time. In a real-world
scenario, true labels usually available only during model training. In this
work, we propose a novel task-sensitive drift detection framework, which is
able to detect drifts without access to true labels during inference. It
utilizes metric learning of a constrained low-dimensional embedding
representation of the input data, which is best suited for the classification
task. It is able to detect real drift, where the drift affects the
classification performance, while it properly ignores virtual drift, where the
classification performance is not affected by the drift. In the proposed
framework, the actual method to detect a change in the statistics of incoming
data samples can be chosen freely. We also propose the two change detection
methods, which are based on the exponential moving average and a modified
$z$-score, respectively. We evaluate the performance of the proposed framework
with a novel metric, which accumulates the standard metrics of detection
accuracy, false positive rate and detection delay into one value. Experimental
evaluation on nine benchmarks datasets, with different types of drift,
demonstrates that the proposed framework can reliably detect drifts, and
outperforms state-of-the-art unsupervised drift detection approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Accuracy-Lossless Perturbation Method for Defending Privacy Attacks in Federated Learning. (arXiv:2002.09843v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Weijun Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jun Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaohu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Rongxing Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.09843">
                                    <div class="article-summary-box-inner">
                                        <span>Although federated learning improves privacy of training data by exchanging
local gradients or parameters rather than raw data, the adversary still can
leverage local gradients and parameters to obtain local training data by
launching reconstruction and membership inference attacks. To defend such
privacy attacks, many noises perturbation methods (like differential privacy or
CountSketch matrix) have been widely designed. However, the strong defence
ability and high learning accuracy of these schemes cannot be ensured at the
same time, which will impede the wide application of FL in practice (especially
for medical or financial institutions that require both high accuracy and
strong privacy guarantee). To overcome this issue, in this paper, we propose
\emph{an efficient model perturbation method for federated learning} to defend
reconstruction and membership inference attacks launched by curious clients. On
the one hand, similar to the differential privacy, our method also selects
random numbers as perturbed noises added to the global model parameters, and
thus it is very efficient and easy to be integrated in practice. Meanwhile, the
random selected noises are positive real numbers and the corresponding value
can be arbitrarily large, and thus the strong defence ability can be ensured.
On the other hand, unlike differential privacy or other perturbation methods
that cannot eliminate the added noises, our method allows the server to recover
the true gradients by eliminating the added noises. Therefore, our method does
not hinder learning accuracy at all.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aegis: A Trusted, Automatic and Accurate Verification Framework for Vertical Federated Learning. (arXiv:2108.06958v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cengguang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junxue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_D/0/1/0/all/0/1">Di Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06958">
                                    <div class="article-summary-box-inner">
                                        <span>Vertical federated learning (VFL) leverages various privacy-preserving
algorithms, e.g., homomorphic encryption or secret sharing based SecureBoost,
to ensure data privacy. However, these algorithms all require a semi-honest
secure definition, which raises concerns in real-world applications. In this
paper, we present Aegis, a trusted, automatic, and accurate verification
framework to verify the security of VFL jobs. Aegis is separated from local
parties to ensure the security of the framework. Furthermore, it automatically
adapts to evolving VFL algorithms by defining the VFL job as a finite state
machine to uniformly verify different algorithms and reproduce the entire job
to provide more accurate verification. We implement and evaluate Aegis with
different threat models on financial and medical datasets. Evaluation results
show that: 1) Aegis can detect 95% threat models, and 2) it provides
fine-grained verification results within 84% of the total VFL job time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Gaussian Process Modeling Applied to Economic Stochastic Model Predictive Control of Batch Processes. (arXiv:2108.06430v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bradford_E/0/1/0/all/0/1">E. Bradford</a>, <a href="http://arxiv.org/find/eess/1/au:+Imsland_L/0/1/0/all/0/1">L. Imsland</a>, <a href="http://arxiv.org/find/eess/1/au:+Reble_M/0/1/0/all/0/1">M. Reble</a>, <a href="http://arxiv.org/find/eess/1/au:+Rio_Chanona_E/0/1/0/all/0/1">E.A. del Rio-Chanona</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06430">
                                    <div class="article-summary-box-inner">
                                        <span>Nonlinear model predictive control (NMPC) is an efficient approach for the
control of nonlinear multivariable dynamic systems with constraints, which
however requires an accurate plant model. Plant models can often be determined
from first principles, parts of the model are however difficult to derive using
physical laws alone. In this paper a hybrid Gaussian process (GP) first
principles modeling scheme is proposed to overcome this issue, which exploits
GPs to model the parts of the dynamic system that are difficult to describe
using first principles. GPs not only give accurate predictions, but also
quantify the residual uncertainty of this model. It is vital to account for
this uncertainty in the control algorithm, to prevent constraint violations and
performance deterioration. Monte Carlo samples of the GPs are generated offline
to tighten constraints of the NMPC to ensure joint probabilistic constraint
satisfaction online. Advantages of our method include fast online evaluation
times, possibility to account for online learning alleviating conservativeness,
and exploiting the flexibility of GPs and the data efficiency of first
principle models. The algorithm is verified on a case study involving a
challenging semi-batch bioreactor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Attribute Reconstruction Attack in Federated Learning. (arXiv:2108.06910v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Lingjuan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06910">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) emerged as a promising learning paradigm to enable a
multitude of participants to construct a joint ML model without exposing their
private training data. Existing FL designs have been shown to exhibit
vulnerabilities which can be exploited by adversaries both within and outside
of the system to compromise data privacy. However, most current works conduct
attacks by leveraging gradients on a small batch of data, which is less
practical in FL. In this work, we consider a more practical and interesting
scenario in which participants share their epoch-averaged gradients (share
gradients after at least 1 epoch of local training) rather than per-example or
small batch-averaged gradients as in previous works. We perform the first
systematic evaluation of attribute reconstruction attack (ARA) launched by the
malicious server in the FL system, and empirically demonstrate that the shared
epoch-averaged local model gradients can reveal sensitive attributes of local
training data of any victim participant. To achieve this goal, we develop a
more effective and efficient gradient matching based method called cos-matching
to reconstruct the training data attributes. We evaluate our attacks on a
variety of real-world datasets, scenarios, assumptions. Our experiments show
that our proposed method achieves better attribute attack performance than most
existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IADA: Iterative Adversarial Data Augmentation Using Formal Verification and Expert Guidance. (arXiv:2108.06871v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruixuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changliu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06871">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks (NNs) are widely used for classification tasks for their
remarkable performance. However, the robustness and accuracy of NNs heavily
depend on the training data. In many applications, massive training data is
usually not available. To address the challenge, this paper proposes an
iterative adversarial data augmentation (IADA) framework to learn neural
network models from an insufficient amount of training data. The method uses
formal verification to identify the most &quot;confusing&quot; input samples, and
leverages human guidance to safely and iteratively augment the training data
with these samples. The proposed framework is applied to an artificial 2D
dataset, the MNIST dataset, and a human motion dataset. By applying IADA to
fully-connected NN classifiers, we show that our training method can improve
the robustness and accuracy of the learned model. By comparing to regular
supervised training, on the MNIST dataset, the average perturbation bound
improved 107.4%. The classification accuracy improved 1.77%, 3.76%, 10.85% on
the 2D dataset, the MNIST dataset, and the human motion dataset respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-Optimal No-Regret Learning in General Games. (arXiv:2108.06924v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1">Constantinos Daskalakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fishelson_M/0/1/0/all/0/1">Maxwell Fishelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1">Noah Golowich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06924">
                                    <div class="article-summary-box-inner">
                                        <span>We show that Optimistic Hedge -- a common variant of
multiplicative-weights-updates with recency bias -- attains ${\rm poly}(\log
T)$ regret in multi-player general-sum games. In particular, when every player
of the game uses Optimistic Hedge to iteratively update her strategy in
response to the history of play so far, then after $T$ rounds of interaction,
each player experiences total regret that is ${\rm poly}(\log T)$. Our bound
improves, exponentially, the $O({T}^{1/2})$ regret attainable by standard
no-regret learners in games, the $O(T^{1/4})$ regret attainable by no-regret
learners with recency bias (Syrgkanis et al., 2015), and the ${O}(T^{1/6})$
bound that was recently shown for Optimistic Hedge in the special case of
two-player games (Chen &amp; Pen, 2020). A corollary of our bound is that
Optimistic Hedge converges to coarse correlated equilibrium in general games at
a rate of $\tilde{O}\left(\frac 1T\right)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WikiChurches: A Fine-Grained Dataset of Architectural Styles with Real-World Challenges. (arXiv:2108.06959v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barz_B/0/1/0/all/0/1">Bj&#xf6;rn Barz</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06959">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel dataset for architectural style classification,
consisting of 9,485 images of church buildings. Both images and style labels
were sourced from Wikipedia. The dataset can serve as a benchmark for various
research fields, as it combines numerous real-world challenges: fine-grained
distinctions between classes based on subtle visual features, a comparatively
small sample size, a highly imbalanced class distribution, a high variance of
viewpoints, and a hierarchical organization of labels, where only some images
are labeled at the most precise level. In addition, we provide 631 bounding box
annotations of characteristic visual features for 139 churches from four major
categories. These annotations can, for example, be useful for research on
fine-grained classification, where additional expert knowledge about
distinctive object parts is often available. Images and annotations are
available at: https://doi.org/10.5281/zenodo.5166987</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time Delay Estimation of Traffic Congestion Propagation based on Transfer Entropy. (arXiv:2108.06717v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Oh_Y/0/1/0/all/0/1">YongKyung Oh</a>, <a href="http://arxiv.org/find/stat/1/au:+Kwak_J/0/1/0/all/0/1">JiIn Kwak</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1">JuYoung Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1">Sungil Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06717">
                                    <div class="article-summary-box-inner">
                                        <span>Considering how congestion will propagate in the near future, understanding
traffic congestion propagation has become crucial in GPS navigation systems for
providing users with a more accurate estimated time of arrival (ETA). However,
providing the exact ETA during congestion is a challenge owing to the complex
propagation process between roads and high uncertainty regarding the future
behavior of the process. Recent studies have focused on finding frequent
congestion propagation patterns and determining the propagation probabilities.
By contrast, this study proposes a novel time delay estimation method for
traffic congestion propagation between roads using lag-specific transfer
entropy (TE). Nonlinear normalization with a sliding window is used to
effectively reveal the causal relationship between the source and target time
series in calculating the TE. Moreover, Markov bootstrap techniques were
adopted to quantify the uncertainty in the time delay estimator. To the best of
our knowledge, the time delay estimation method presented in this article is
the first to determine the time delay between roads for any congestion
propagation pattern. The proposed method was validated using simulated data as
well as real user trajectory data obtained from a major GPS navigation system
applied in South Korea.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Attributions and Interactions of Adversarial Attacks. (arXiv:2108.06895v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuyun Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yufei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanshi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06895">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims to explain adversarial attacks in terms of how adversarial
perturbations contribute to the attacking task. We estimate attributions of
different image regions to the decrease of the attacking cost based on the
Shapley value. We define and quantify interactions among adversarial
perturbation pixels, and decompose the entire perturbation map into relatively
independent perturbation components. The decomposition of the perturbation map
shows that adversarially-trained DNNs have more perturbation components in the
foreground than normally-trained DNNs. Moreover, compared to the
normally-trained DNN, the adversarially-trained DNN have more components which
mainly decrease the score of the true category. Above analyses provide new
insights into the understanding of adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batched Thompson Sampling for Multi-Armed Bandits. (arXiv:2108.06812v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karpov_N/0/1/0/all/0/1">Nikolai Karpov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06812">
                                    <div class="article-summary-box-inner">
                                        <span>We study Thompson Sampling algorithms for stochastic multi-armed bandits in
the batched setting, in which we want to minimize the regret over a sequence of
arm pulls using a small number of policy changes (or, batches). We propose two
algorithms and demonstrate their effectiveness by experiments on both synthetic
and real datasets. We also analyze the proposed algorithms from the theoretical
aspect and obtain almost tight regret-batches tradeoffs for the two-arm case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Actor-Critic Policy with Optimized Training Datasets. (arXiv:2108.06911v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_C/0/1/0/all/0/1">Chayan Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Noman_N/0/1/0/all/0/1">Nasimul Noman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_M/0/1/0/all/0/1">Mohsen Zamani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06911">
                                    <div class="article-summary-box-inner">
                                        <span>Actor-critic (AC) algorithms are known for their efficacy and high
performance in solving reinforcement learning problems, but they also suffer
from low sampling efficiency. An AC based policy optimization process is
iterative and needs to frequently access the agent-environment system to
evaluate and update the policy by rolling out the policy, collecting rewards
and states (i.e. samples), and learning from them. It ultimately requires a
huge number of samples to learn an optimal policy. To improve sampling
efficiency, we propose a strategy to optimize the training dataset that
contains significantly less samples collected from the AC process. The dataset
optimization is made of a best episode only operation, a policy
parameter-fitness model, and a genetic algorithm module. The optimal policy
network trained by the optimized training dataset exhibits superior performance
compared to many contemporary AC algorithms in controlling autonomous dynamical
systems. Evaluation on standard benchmarks show that the method improves
sampling efficiency, ensures faster convergence to optima, and is more
data-efficient than its counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Dense-Sparse Learning for Efficient Liver and Tumor Segmentation. (arXiv:2108.06761v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Ziyuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zeyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zeng Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chow_P/0/1/0/all/0/1">Pierce KH Chow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06761">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate automatic liver and tumor segmentation plays a vital role in
treatment planning and disease monitoring. Recently, deep convolutional neural
network (DCNNs) has obtained tremendous success in 2D and 3D medical image
segmentation. However, 2D DCNNs cannot fully leverage the inter-slice
information, while 3D DCNNs are computationally expensive and memory intensive.
To address these issues, we first propose a novel dense-sparse training flow
from a data perspective, in which, densely adjacent slices and sparsely
adjacent slices are extracted as inputs for regularizing DCNNs, thereby
improving the model performance. Moreover, we design a 2.5D light-weight
nnU-Net from a network perspective, in which, depthwise separable convolutions
are adopted to improve the efficiency. Extensive experiments on the LiTS
dataset have demonstrated the superiority of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Filipino Disaster-Related Tweets Using Incremental and Density-Based Spatiotemporal Algorithm with Support Vector Machines for Needs Assessment 2. (arXiv:2108.06853v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barba_O/0/1/0/all/0/1">Ocean M. Barba</a>, <a href="http://arxiv.org/find/cs/1/au:+Calbay_F/0/1/0/all/0/1">Franz Arvin T. Calbay</a>, <a href="http://arxiv.org/find/cs/1/au:+Francisco_A/0/1/0/all/0/1">Angelica Jane S. Francisco</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1">Angel Luis D. Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponay_C/0/1/0/all/0/1">Charmaine S. Ponay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06853">
                                    <div class="article-summary-box-inner">
                                        <span>Social media has played a huge part on how people get informed and
communicate with one another. It has helped people express their needs due to
distress especially during disasters. Because posts made through it are
publicly accessible by default, Twitter is among the most helpful social media
sites in times of disaster. With this, the study aims to assess the needs
expressed during calamities by Filipinos on Twitter. Data were gathered and
classified as either disaster-related or unrelated with the use of Na\&quot;ive
Bayes classifier. After this, the disaster-related tweets were clustered per
disaster type using Incremental Clustering Algorithm, and then sub-clustered
based on the location and time of the tweet using Density-based Spatiotemporal
Clustering Algorithm. Lastly, using Support Vector Machines, the tweets were
classified according to the expressed need, such as shelter, rescue, relief,
cash, prayer, and others. After conducting the study, results showed that the
Incremental Clustering Algorithm and Density-Based Spatiotemporal Clustering
Algorithm were able to cluster the tweets with f-measure scores of 47.20% and
82.28% respectively. Also, the Na\&quot;ive Bayes and Support Vector Machines were
able to classify with an average f-measure score of 97% and an average accuracy
of 77.57% respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Interpretable Model Agnostic Explanations using Gaussian Processes. (arXiv:2108.06907v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saini_A/0/1/0/all/0/1">Aditya Saini</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_R/0/1/0/all/0/1">Ranjitha Prasad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06907">
                                    <div class="article-summary-box-inner">
                                        <span>Owing to tremendous performance improvements in data-intensive domains,
machine learning (ML) has garnered immense interest in the research community.
However, these ML models turn out to be black boxes, which are tough to
interpret, resulting in a direct decrease in productivity. Local Interpretable
Model-Agnostic Explanations (LIME) is a popular technique for explaining the
prediction of a single instance. Although LIME is simple and versatile, it
suffers from instability in the generated explanations. In this paper, we
propose a Gaussian Process (GP) based variation of locally interpretable
models. We employ a smart sampling strategy based on the acquisition functions
in Bayesian optimization. Further, we employ the automatic relevance
determination based covariance function in GP, with separate length-scale
parameters for each feature, where the reciprocal of lengthscale parameters
serve as feature explanations. We illustrate the performance of the proposed
technique on two real-world datasets, and demonstrate the superior stability of
the proposed technique. Furthermore, we demonstrate that the proposed technique
is able to generate faithful explanations using much fewer samples as compared
to LIME.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Proportionate Algorithms Exploit Sparsity?. (arXiv:2108.06846v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lima_M/0/1/0/all/0/1">Markus V. S. Lima</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaves_G/0/1/0/all/0/1">Gabriel S. Chaves</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferreira_T/0/1/0/all/0/1">Tadeu N. Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Diniz_P/0/1/0/all/0/1">Paulo S. R. Diniz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06846">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive filters exploiting sparsity have been a very active research field,
among which the algorithms that follow the &quot;proportional-update principle&quot;, the
so-called proportionate-type algorithms, are very popular. Indeed, there are
hundreds of works on proportionate-type algorithms and, therefore, their
advantages are widely known. This paper addresses the unexplored drawbacks and
limitations of using proportional updates and their practical impacts. Our
findings include the theoretical justification for the poor performance of
these algorithms in several sparse scenarios, and also when dealing with
non-stationary and compressible systems. Simulation results corroborating the
theory are presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Multi-Modal Learning of Editing Source Code. (arXiv:2108.06645v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Saikat Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1">Baishakhi Ray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06645">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Neural Machine Translator (NMT) has shown promise in
automatically editing source code. Typical NMT based code editor only considers
the code that needs to be changed as input and suggests developers with a
ranked list of patched code to choose from - where the correct one may not
always be at the top of the list. While NMT based code editing systems generate
a broad spectrum of plausible patches, the correct one depends on the
developers&#x27; requirement and often on the context where the patch is applied.
Thus, if developers provide some hints, using natural language, or providing
patch context, NMT models can benefit from them. As a proof of concept, in this
research, we leverage three modalities of information: edit location, edit code
context, commit messages (as a proxy of developers&#x27; hint in natural language)
to automatically generate edits with NMT models. To that end, we build MODIT, a
multi-modal NMT based code editing engine. With in-depth investigation and
analysis, we show that developers&#x27; hint as an input modality can narrow the
search space for patches and outperform state-of-the-art models to generate
correctly patched code in top-1 position.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation of Replay-based Approaches for Continual Learning. (arXiv:2108.06758v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagus_B/0/1/0/all/0/1">Benedikt Bagus</a>, <a href="http://arxiv.org/find/cs/1/au:+Gepperth_A/0/1/0/all/0/1">Alexander Gepperth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06758">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning (CL) is a major challenge of machine learning (ML) and
describes the ability to learn several tasks sequentially without catastrophic
forgetting (CF). Recent works indicate that CL is a complex topic, even more so
when real-world scenarios with multiple constraints are involved. Several
solution classes have been proposed, of which so-called replay-based approaches
seem very promising due to their simplicity and robustness. Such approaches
store a subset of past samples in a dedicated memory for later processing:
while this does not solve all problems, good results have been obtained. In
this article, we empirically investigate replay-based approaches of continual
learning and assess their potential for applications. Selected recent
approaches as well as own proposals are compared on a common set of benchmarks,
with a particular focus on assessing the performance of different sample
selection strategies. We find that the impact of sample selection increases
when a smaller number of samples is stored. Nevertheless, performance varies
strongly between different replay approaches. Surprisingly, we find that the
most naive rehearsal-based approaches that we propose here can outperform
recent state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAPPHIRE: Approaches for Enhanced Concept-to-Text Generation. (arXiv:2108.06643v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Steven Y. Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_J/0/1/0/all/0/1">Jessica Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Narisetty_C/0/1/0/all/0/1">Chaitanya Narisetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06643">
                                    <div class="article-summary-box-inner">
                                        <span>We motivate and propose a suite of simple but effective improvements for
concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc
PHrase Infilling and REcombination. We demonstrate their effectiveness on
generative commonsense reasoning, a.k.a. the CommonGen task, through
experiments using both BART and T5 models. Through extensive automatic and
human evaluation, we show that SAPPHIRE noticeably improves model performance.
An in-depth qualitative analysis illustrates that SAPPHIRE effectively
addresses many issues of the baseline model generations, including lack of
commonsense, insufficient specificity, and poor fluency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dilated Inception U-Net (DIU-Net) for Brain Tumor Segmentation. (arXiv:2108.06772v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cahall_D/0/1/0/all/0/1">Daniel E. Cahall</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1">Ghulam Rasool</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouaynaya_N/0/1/0/all/0/1">Nidhal C. Bouaynaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathallah_Shaykh_H/0/1/0/all/0/1">Hassan M. Fathallah-Shaykh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06772">
                                    <div class="article-summary-box-inner">
                                        <span>Magnetic resonance imaging (MRI) is routinely used for brain tumor diagnosis,
treatment planning, and post-treatment surveillance. Recently, various models
based on deep neural networks have been proposed for the pixel-level
segmentation of tumors in brain MRIs. However, the structural variations,
spatial dissimilarities, and intensity inhomogeneity in MRIs make segmentation
a challenging task. We propose a new end-to-end brain tumor segmentation
architecture based on U-Net that integrates Inception modules and dilated
convolutions into its contracting and expanding paths. This allows us to
extract local structural as well as global contextual information. We performed
segmentation of glioma sub-regions, including tumor core, enhancing tumor, and
whole tumor using Brain Tumor Segmentation (BraTS) 2018 dataset. Our proposed
model performed significantly better than the state-of-the-art U-Net-based
model ($p&lt;0.05$) for tumor core and whole tumor segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Adversarially-Enhanced k-Nearest Neighbors. (arXiv:2108.06797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06797">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have theoretically and empirically shown that deep neural
networks (DNNs) have an inherent vulnerability to small perturbations. Applying
the Deep k-Nearest Neighbors (DkNN) classifier, we observe a dramatically
increasing robustness-accuracy trade-off as the layer goes deeper. In this
work, we propose a Deep Adversarially-Enhanced k-Nearest Neighbors (DAEkNN)
method which achieves higher robustness than DkNN and mitigates the
robustness-accuracy trade-off in deep layers through two key elements. First,
DAEkNN is based on an adversarially trained model. Second, DAEkNN makes
predictions by leveraging a weighted combination of benign and adversarial
training data. Empirically, we find that DAEkNN improves both the robustness
and the robustness-accuracy trade-off on MNIST and CIFAR-10 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LinkTeller: Recovering Private Edges from Graph Neural Networks via Influence Analysis. (arXiv:2108.06504v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yunhui Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06504">
                                    <div class="article-summary-box-inner">
                                        <span>Graph structured data have enabled several successful applications such as
recommendation systems and traffic prediction, given the rich node features and
edges information. However, these high-dimensional features and high-order
adjacency information are usually heterogeneous and held by different data
holders in practice. Given such vertical data partition (e.g., one data holder
will only own either the node features or edge information), different data
holders have to develop efficient joint training protocols rather than directly
transfer data to each other due to privacy concerns. In this paper, we focus on
the edge privacy, and consider a training scenario where Bob with node features
will first send training node features to Alice who owns the adjacency
information. Alice will then train a graph neural network (GNN) with the joint
information and release an inference API. During inference, Bob is able to
provide test node features and query the API to obtain the predictions for test
nodes. Under this setting, we first propose a privacy attack LinkTeller via
influence analysis to infer the private edge information held by Alice via
designing adversarial queries for Bob. We then empirically show that LinkTeller
is able to recover a significant amount of private edges, outperforming
existing baselines. To further evaluate the privacy leakage, we adapt an
existing algorithm for differentially private graph convolutional network (DP
GCN) training and propose a new DP GCN mechanism LapGraph. We show that these
DP GCN mechanisms are not always resilient against LinkTeller empirically under
mild privacy guarantees ($\varepsilon&gt;5$). Our studies will shed light on
future research towards designing more resilient privacy-preserving GCN models;
in the meantime, provide an in-depth understanding of the tradeoff between GCN
model utility and robustness against potential privacy attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neuron Campaign for Initialization Guided by Information Bottleneck Theory. (arXiv:2108.06530v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Haitao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06530">
                                    <div class="article-summary-box-inner">
                                        <span>Initialization plays a critical role in the training of deep neural networks
(DNN). Existing initialization strategies mainly focus on stabilizing the
training process to mitigate gradient vanish/explosion problems. However, these
initialization methods are lacking in consideration about how to enhance
generalization ability. The Information Bottleneck (IB) theory is a well-known
understanding framework to provide an explanation about the generalization of
DNN. Guided by the insights provided by IB theory, we design two criteria for
better initializing DNN. And we further design a neuron campaign initialization
algorithm to efficiently select a good initialization for a neural network on a
given dataset. The experiments on MNIST dataset show that our method can lead
to a better generalization performance with faster convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective and Efficient Graph Learning for Multi-view Clustering. (arXiv:2108.06734v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Quanxue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06734">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the impressive clustering performance and efficiency in
characterizing both the relationship between data and cluster structure,
existing graph-based multi-view clustering methods still have the following
drawbacks. They suffer from the expensive time burden due to both the
construction of graphs and eigen-decomposition of Laplacian matrix, and fail to
explore the cluster structure of large-scale data. Moreover, they require a
post-processing to get the final clustering, resulting in suboptimal
performance. Furthermore, rank of the learned view-consensus graph cannot
approximate the target rank. In this paper, drawing the inspiration from the
bipartite graph, we propose an effective and efficient graph learning model for
multi-view clustering. Specifically, our method exploits the view-similar
between graphs of different views by the minimization of tensor Schatten
p-norm, which well characterizes both the spatial structure and complementary
information embedded in graphs of different views. We learn view-consensus
graph with adaptively weighted strategy and connectivity constraint such that
the connected components indicates clusters directly. Our proposed algorithm is
time-economical and obtains the stable results and scales well with the data
size. Extensive experimental results indicate that our method is superior to
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Evaluation and Temporal-Difference Learning in Continuous Time and Space: A Martingale Approach. (arXiv:2108.06655v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yanwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xun Yu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06655">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a unified framework to study policy evaluation (PE) and the
associated temporal difference (TD) methods for reinforcement learning in
continuous time and space. We show that PE is equivalent to maintaining the
martingale condition of a process. From this perspective, we find that the
mean--square TD error approximates the quadratic variation of the martingale
and thus is not a suitable objective for PE. We present two methods to use the
martingale characterization for designing PE algorithms. The first one
minimizes a &quot;martingale loss function&quot;, whose solution is proved to be the best
approximation of the true value function in the mean--square sense. This method
interprets the classical gradient Monte-Carlo algorithm. The second method is
based on a system of equations called the &quot;martingale orthogonality conditions&quot;
with &quot;test functions&quot;. Solving these equations in different ways recovers
various classical TD algorithms, such as TD($\lambda$), LSTD, and GTD.
Different choices of test functions determine in what sense the resulting
solutions approximate the true value function. Moreover, we prove that any
convergent time-discretized algorithm converges to its continuous-time
counterpart as the mesh size goes to zero. We demonstrate the theoretical
results and corresponding algorithms with numerical experiments and
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DQN Control Solution for KDD Cup 2021 City Brain Challenge. (arXiv:2108.06491v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yitian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kunlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kunjin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06491">
                                    <div class="article-summary-box-inner">
                                        <span>We took part in the city brain challenge competition and achieved the 8th
place. In this competition, the players are provided with a real-world
city-scale road network and its traffic demand derived from real traffic data.
The players are asked to coordinate the traffic signals with a self-designed
agent to maximize the number of vehicles served while maintaining an acceptable
delay. In this abstract paper, we present an overall analysis and our detailed
solution to this competition. Our approach is mainly based on the adaptation of
the deep Q-network (DQN) for real-time traffic signal control. From our
perspective, the major challenge of this competition is how to extend the
classical DQN framework to traffic signals control in real-world complex road
network and traffic flow situation. After trying and implementing several
classical reward functions, we finally chose to apply our newly-designed reward
in our agent. By applying our newly-proposed reward function and carefully
tuning the control scheme, an agent based on a single DQN model can rank among
the top 15 teams. We hope this paper could serve, to some extent, as a baseline
solution to traffic signal control of real-world road network and inspire
further attempts and researches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Data Clustering via Innovation Search. (arXiv:2108.06888v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_M/0/1/0/all/0/1">Mostafa Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Ping Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06888">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the subspace clustering problem in which data points
collected from high-dimensional ambient space lie in a union of linear
subspaces. Subspace clustering becomes challenging when the dimension of
intersection between subspaces is large and most of the self-representation
based methods are sensitive to the intersection between the span of clusters.
In sharp contrast to the self-representation based methods, a recently proposed
clustering method termed Innovation Pursuit, computed a set of optimal
directions (directions of innovation) to build the adjacency matrix. This paper
focuses on the Innovation Pursuit Algorithm to shed light on its impressive
performance when the subspaces are heavily intersected. It is shown that in
contrast to most of the existing methods which require the subspaces to be
sufficiently incoherent with each other, Innovation Pursuit only requires the
innovative components of the subspaces to be sufficiently incoherent with each
other. These new sufficient conditions allow the clusters to be strongly close
to each other. Motivated by the presented theoretical analysis, a simple yet
effective projection based technique is proposed which we show with both
numerical and theoretical results that it can boost the performance of
Innovation Pursuit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Bias In Automatic Toxic Comment Detection: An Empirical Study. (arXiv:2108.06487v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ayush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratik Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06487">
                                    <div class="article-summary-box-inner">
                                        <span>With surge in online platforms, there has been an upsurge in the user
engagement on these platforms via comments and reactions. A large portion of
such textual comments are abusive, rude and offensive to the audience. With
machine learning systems in-place to check such comments coming onto platform,
biases present in the training data gets passed onto the classifier leading to
discrimination against a set of classes, religion and gender. In this work, we
evaluate different classifiers and feature to estimate the bias in these
classifiers along with their performance on downstream task of toxicity
classification. Results show that improvement in performance of automatic toxic
comment detection models is positively correlated to mitigating biases in these
models. In our work, LSTM with attention mechanism proved to be a better
modelling strategy than a CNN model. Further analysis shows that fasttext
embeddings is marginally preferable than glove embeddings on training models
for toxicity comment detection. Deeper analysis reveals the findings that such
automatic models are particularly biased to specific identity groups even
though the model has a high AUC score. Finally, in effort to mitigate bias in
toxicity detection models, a multi-task setup trained with auxiliary task of
toxicity sub-types proved to be useful leading to upto 0.26% (6% relative) gain
in AUC scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classification and Topic Modeling. (arXiv:2108.06862v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hossen_M/0/1/0/all/0/1">Md Imran Hossen</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_A/0/1/0/all/0/1">Ashraful Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Anowar_F/0/1/0/all/0/1">Farzana Anowar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_E/0/1/0/all/0/1">Eshtiak Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mohammad Masudur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06862">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the variety of cyber-attacks or threats, the cybersecurity community
has been enhancing the traditional security control mechanisms to an advanced
level so that automated tools can encounter potential security threats. Very
recently a term, Cyber Threat Intelligence (CTI) has been represented as one of
the proactive and robust mechanisms because of its automated cybersecurity
threat prediction based on data. In general, CTI collects and analyses data
from various sources e.g. online security forums, social media where cyber
enthusiasts, analysts, even cybercriminals discuss cyber or computer security
related topics and discovers potential threats based on the analysis. As the
manual analysis of every such discussion i.e. posts on online platforms is
time-consuming, inefficient, and susceptible to errors, CTI as an automated
tool can perform uniquely to detect cyber threats. In this paper, our goal is
to identify and explore relevant CTI from hacker forums by using different
supervised and unsupervised learning techniques. To this end, we collect data
from a real hacker forum and constructed two datasets: a binary dataset and a
multi-class dataset. Our binary dataset contains two classes one containing
cybersecurity-relevant posts and another one containing posts that are not
related to security. This dataset is constructed using simple keyword search
technique. Using a similar approach, we further categorize posts from
security-relevant posts into five different threat categories. We then applied
several machine learning classifiers along with deep neural network-based
classifiers and use them on the datasets to compare their performances. We also
tested the classifiers on a leaked dataset with labels named nulled.io as our
ground truth. We further explore the datasets using unsupervised techniques
i.e. Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization
(NMF).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nowcasting-Nets: Deep Neural Network Structures for Precipitation Nowcasting Using IMERG. (arXiv:2108.06868v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ehsani_M/0/1/0/all/0/1">Mohammad Reza Ehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarei_A/0/1/0/all/0/1">Ariyan Zarei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Hoshin V. Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnard_K/0/1/0/all/0/1">Kobus Barnard</a>, <a href="http://arxiv.org/find/cs/1/au:+Behrangi_A/0/1/0/all/0/1">Ali Behrangi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06868">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate and timely estimation of precipitation is critical for issuing
hazard warnings (e.g., for flash floods or landslides). Current remotely sensed
precipitation products have a few hours of latency, associated with the
acquisition and processing of satellite data. By applying a robust nowcasting
system to these products, it is (in principle) possible to reduce this latency
and improve their applicability, value, and impact. However, the development of
such a system is complicated by the chaotic nature of the atmosphere, and the
consequent rapid changes that can occur in the structures of precipitation
systems In this work, we develop two approaches (hereafter referred to as
Nowcasting-Nets) that use Recurrent and Convolutional deep neural network
structures to address the challenge of precipitation nowcasting. A total of
five models are trained using Global Precipitation Measurement (GPM) Integrated
Multi-satellitE Retrievals for GPM (IMERG) precipitation data over the Eastern
Contiguous United States (CONUS) and then tested against independent data for
the Eastern and Western CONUS. The models were designed to provide forecasts
with a lead time of up to 1.5 hours and, by using a feedback loop approach, the
ability of the models to extend the forecast time to 4.5 hours was also
investigated. Model performance was compared against the Random Forest (RF) and
Linear Regression (LR) machine learning methods, and also against a persistence
benchmark (BM) that used the most recent observation as the forecast.
Independent IMERG observations were used as a reference, and experiments were
conducted to examine both overall statistics and case studies involving
specific precipitation events. Overall, the forecasts provided by the
Nowcasting-Net models are superior, with the Convolutional Nowcasting Network
with Residual Head (CNC-R) achieving 25%, 28%, and 46% improvement in the test
...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Approximation with Sparse Neural Networks and Applications. (arXiv:2108.06467v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1">Khay Boon Hong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06467">
                                    <div class="article-summary-box-inner">
                                        <span>We use deep sparsely connected neural networks to measure the complexity of a
function class in $L^2(\mathbb R^d)$ by restricting connectivity and memory
requirement for storing the neural networks. We also introduce representation
system - a countable collection of functions to guide neural networks, since
approximation theory with representation system has been well developed in
Mathematics. We then prove the fundamental bound theorem, implying a quantity
intrinsic to the function class itself can give information about the
approximation ability of neural networks and representation system. We also
provides a method for transferring existing theories about approximation by
representation systems to that of neural networks, greatly amplifying the
practical values of neural networks. Finally, we use neural networks to
approximate B-spline functions, which are used to generate the B-spline curves.
Then, we analyse the complexity of a class called $\beta$ cartoon-like
functions using rate-distortion theory and wedgelets construction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Microscopic Pandemic Simulator for Pandemic Prediction Using Scalable Million-Agent Reinforcement Learning. (arXiv:2108.06589v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhenggang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Kai Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Liting Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1">Wei Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changliu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06589">
                                    <div class="article-summary-box-inner">
                                        <span>Microscopic epidemic models are powerful tools for government policy makers
to predict and simulate epidemic outbreaks, which can capture the impact of
individual behaviors on the macroscopic phenomenon. However, existing models
only consider simple rule-based individual behaviors, limiting their
applicability. This paper proposes a deep-reinforcement-learning-powered
microscopic model named Microscopic Pandemic Simulator (MPS). By replacing
rule-based agents with rational agents whose behaviors are driven to maximize
rewards, the MPS provides a better approximation of real world dynamics. To
efficiently simulate with massive amounts of agents in MPS, we propose Scalable
Million-Agent DQN (SMADQN). The MPS allows us to efficiently evaluate the
impact of different government strategies. This paper first calibrates the MPS
against real-world data in Allegheny, US, then demonstratively evaluates two
government strategies: information disclosure and quarantine. The results
validate the effectiveness of the proposed method. As a broad impact, this
paper provides novel insights for the application of DRL in large scale
agent-based networks such as economic and social networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Disentanglement without Autoencoding: Pitfalls and Future Directions. (arXiv:2108.06613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burns_A/0/1/0/all/0/1">Andrea Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarna_A/0/1/0/all/0/1">Aaron Sarna</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_D/0/1/0/all/0/1">Dilip Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maschinot_A/0/1/0/all/0/1">Aaron Maschinot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06613">
                                    <div class="article-summary-box-inner">
                                        <span>Disentangled visual representations have largely been studied with generative
models such as Variational AutoEncoders (VAEs). While prior work has focused on
generative methods for disentangled representation learning, these approaches
do not scale to large datasets due to current limitations of generative models.
Instead, we explore regularization methods with contrastive learning, which
could result in disentangled representations that are powerful enough for large
scale datasets and downstream applications. However, we find that unsupervised
disentanglement is difficult to achieve due to optimization and initialization
sensitivity, with trade-offs in task performance. We evaluate disentanglement
with downstream tasks, analyze the benefits and disadvantages of each
regularization used, and discuss future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deepfake Representation with Multilinear Regression. (arXiv:2108.06702v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilescu_M/0/1/0/all/0/1">M. Alex O. Vasilescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1">Evangelos E. Papalexakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06702">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural network architectures such as GANs, may be used to generate
synthetic instances to compensate for the lack of real data. However, they may
be employed to create media that may cause social, political or economical
upheaval. One emerging media is &quot;Deepfake&quot;.Techniques that can discriminate
between such media is indispensable. In this paper, we propose a modified
multilinear (tensor) method, a combination of linear and multilinear
regressions for representing fake and real data. We test our approach by
representing Deepfakes with our modified multilinear (tensor) approach and
perform SVM classification with encouraging results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating the Relationship Between Dropout Regularization and Model Complexity in Neural Networks. (arXiv:2108.06628v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Christopher Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1">Jai Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Maiti_M/0/1/0/all/0/1">Milind Maiti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06628">
                                    <div class="article-summary-box-inner">
                                        <span>Dropout Regularization, serving to reduce variance, is nearly ubiquitous in
Deep Learning models. We explore the relationship between the dropout rate and
model complexity by training 2,000 neural networks configured with random
combinations of the dropout rate and the number of hidden units in each dense
layer, on each of the three data sets we selected. The generated figures, with
binary cross entropy loss and binary accuracy on the z-axis, question the
common assumption that adding depth to a dense layer while increasing the
dropout rate will certainly enhance performance. We also discover a complex
correlation between the two hyperparameters that we proceed to quantify by
building additional machine learning and Deep Learning models which predict the
optimal dropout rate given some hidden units in each dense layer. Linear
regression and polynomial logistic regression require the use of arbitrary
thresholds to select the cost data points included in the regression and to
assign the cost data points a binary classification, respectively. These
machine learning models have mediocre performance because their naive nature
prevented the modeling of complex decision boundaries. Turning to Deep Learning
models, we build neural networks that predict the optimal dropout rate given
the number of hidden units in each dense layer, the desired cost, and the
desired accuracy of the model. Though, this attempt encounters a mathematical
error that can be attributed to the failure of the vertical line test. The
ultimate Deep Learning model is a neural network whose decision boundary
represents the 2,000 previously generated data points. This final model leads
us to devise a promising method for tuning hyperparameters to minimize
computational expense yet maximize performance. The strategy can be applied to
any model hyperparameters, with the prospect of more efficient tuning in
industrial models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Temporal Anomaly Segmentation with Dynamic Time Warping. (arXiv:2108.06816v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dongha Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sehun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_H/0/1/0/all/0/1">Hyunjun Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06816">
                                    <div class="article-summary-box-inner">
                                        <span>Most recent studies on detecting and localizing temporal anomalies have
mainly employed deep neural networks to learn the normal patterns of temporal
data in an unsupervised manner. Unlike them, the goal of our work is to fully
utilize instance-level (or weak) anomaly labels, which only indicate whether
any anomalous events occurred or not in each instance of temporal data. In this
paper, we present WETAS, a novel framework that effectively identifies
anomalous temporal segments (i.e., consecutive time points) in an input
instance. WETAS learns discriminative features from the instance-level labels
so that it infers the sequential order of normal and anomalous segments within
each instance, which can be used as a rough segmentation mask. Based on the
dynamic time warping (DTW) alignment between the input instance and its
segmentation mask, WETAS obtains the result of temporal segmentation, and
simultaneously, it further enhances itself by using the mask as additional
supervision. Our experiments show that WETAS considerably outperforms other
baselines in terms of the localization of temporal anomalies, and also it
provides more informative results than point-level detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-dimensional Assisted Generative Model for Color Image Restoration. (arXiv:2108.06460v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hong_K/0/1/0/all/0/1">Kai Hong</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1">Chunhua Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1">Cailian Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_M/0/1/0/all/0/1">Minghui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1">Yancheng Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuhao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1">Qiegen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06460">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents an unsupervised deep learning scheme that exploiting
high-dimensional assisted score-based generative model for color image
restoration tasks. Considering that the sample number and internal dimension in
score-based generative model have key influence on estimating the gradients of
data distribution, two different high-dimensional ways are proposed: The
channel-copy transformation increases the sample number and the pixel-scale
transformation decreases feasible space dimension. Subsequently, a set of
high-dimensional tensors represented by these transformations are used to train
the network through denoising score matching. Then, sampling is performed by
annealing Langevin dynamics and alternative data-consistency update.
Furthermore, to alleviate the difficulty of learning high-dimensional
representation, a progressive strategy is proposed to leverage the performance.
The proposed unsupervised learning and iterative restoration algo-rithm, which
involves a pre-trained generative network to obtain prior, has transparent and
clear interpretation compared to other data-driven approaches. Experimental
results on demosaicking and inpainting conveyed the remarkable performance and
diversity of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equity-Directed Bootstrapping: Examples and Analysis. (arXiv:2108.06624v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bhat_H/0/1/0/all/0/1">Harish S. Bhat</a>, <a href="http://arxiv.org/find/stat/1/au:+Reeves_M/0/1/0/all/0/1">Majerle E. Reeves</a>, <a href="http://arxiv.org/find/stat/1/au:+Goldman_Mellor_S/0/1/0/all/0/1">Sidra Goldman-Mellor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06624">
                                    <div class="article-summary-box-inner">
                                        <span>When faced with severely imbalanced binary classification problems, we often
train models on bootstrapped data in which the number of instances of each
class occur in a more favorable ratio, e.g., one. We view algorithmic inequity
through the lens of imbalanced classification: in order to balance the
performance of a classifier across groups, we can bootstrap to achieve training
sets that are balanced with respect to both labels and group identity. For an
example problem with severe class imbalance---prediction of suicide death from
administrative patient records---we illustrate how an equity-directed bootstrap
can bring test set sensitivities and specificities much closer to satisfying
the equal odds criterion. In the context of na\&quot;ive Bayes and logistic
regression, we analyze the equity-directed bootstrap, demonstrating that it
works by bringing odds ratios close to one, and linking it to methods involving
intercept adjustment, thresholding, and weighting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topology-Guided Sampling for Fast and Accurate Community Detection. (arXiv:2108.06651v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wanye_F/0/1/0/all/0/1">Frank Wanye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleyzer_V/0/1/0/all/0/1">Vitaliy Gleyzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kao_E/0/1/0/all/0/1">Edward Kao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wu-chun Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06651">
                                    <div class="article-summary-box-inner">
                                        <span>Community detection is a well-studied problem with applications in domains
ranging from computer networking to bioinformatics. While there are many
algorithms that perform community detection, the more accurate and
statistically robust algorithms tend to be slow and hard to parallelize. One
way to speed up such algorithms is through data reduction. However, this
approach has not been thoroughly studied, and the quality of results obtained
with this approach varies with the graph it is applied to. In this manuscript,
we present an approach based on topology-guided sampling for accelerating
stochastic block partitioning - a community detection algorithm that works well
on graphs with complex and heterogeneous community structure. We also introduce
a degree-based thresholding scheme that improves the efficacy of our approach
at the expense of speedup. Finally, we perform a series of experiments on
synthetically generated graphs to determine how various graph parameters affect
the quality of results and speedup obtained with our approach, and we validate
our approach on real-world data. Our results show that our approach can lead to
a speedup of up to 15X over stochastic block partitioning without sampling
while maintaining result quality and can even lead to improvements of over 150%
in result quality in terms of F1 score on certain kinds of graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaGNN: A multi-modal latent representation meta-learner for GNNs based on AdaBoosting. (arXiv:2108.06452v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qinyi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yiou Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06452">
                                    <div class="article-summary-box-inner">
                                        <span>As a special field in deep learning, Graph Neural Networks (GNNs) focus on
extracting intrinsic network features and have drawn unprecedented popularity
in both academia and industry. Most of the state-of-the-art GNN models offer
expressive, robust, scalable and inductive solutions empowering social network
recommender systems with rich network features that are computationally
difficult to leverage with graph traversal based methods.

Most recent GNNs follow an encoder-decoder paradigm to encode high
dimensional heterogeneous information from a subgraph onto one low dimensional
embedding space. However, one single embedding space usually fails to capture
all aspects of graph signals. In this work, we propose boosting-based meta
learner for GNNs, which automatically learns multiple projections and the
corresponding embedding spaces that captures different aspects of the graph
signals. As a result, similarities between sub-graphs are quantified by
embedding proximity on multiple embedding spaces. AdaGNN performs exceptionally
well for applications with rich and diverse node neighborhood information.
Moreover, AdaGNN is compatible with any inductive GNNs for both node-level and
edge-level tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Scheduling of Isolated Microgrids Using Automated Reinforcement Learning-based Multi-period Forecasting. (arXiv:2108.06764v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_R/0/1/0/all/0/1">Ruinong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1">Zhen Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06764">
                                    <div class="article-summary-box-inner">
                                        <span>In order to reduce the negative impact of the uncertainty of load and
renewable energies outputs on microgrid operation, an optimal scheduling model
is proposed for isolated microgrids by using automated reinforcement
learning-based multi-period forecasting of renewable power generations and
loads. Firstly, a prioritized experience replay automated reinforcement
learning (PER-AutoRL) is designed to simplify the deployment of deep
reinforcement learning (DRL)-based forecasting model in a customized manner,
the single-step multi-period forecasting method based on PER-AutoRL is proposed
for the first time to address the error accumulation issue suffered by existing
multi-step forecasting methods, then the prediction values obtained by the
proposed forecasting method are revised via the error distribution to improve
the prediction accuracy; secondly, a scheduling model considering demand
response is constructed to minimize the total microgrid operating costs, where
the revised forecasting values are used as the dispatch basis, and a spinning
reserve chance constraint is set according to the error distribution; finally,
by transforming the original scheduling model into a readily solvable mixed
integer linear programming via the sequence operation theory (SOT), the
transformed model is solved by using CPLEX solver. The simulation results show
that compared with the traditional scheduling model without forecasting, this
approach manages to significantly reduce the system operating costs by
improving the prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Neural Network shifted-Proper Orthogonal Decomposition: a Machine Learning Approach for Non-linear Reduction of Hyperbolic Equations. (arXiv:2108.06558v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Papapicco_D/0/1/0/all/0/1">Davide Papapicco</a>, <a href="http://arxiv.org/find/math/1/au:+Demo_N/0/1/0/all/0/1">Nicola Demo</a>, <a href="http://arxiv.org/find/math/1/au:+Girfoglio_M/0/1/0/all/0/1">Michele Girfoglio</a>, <a href="http://arxiv.org/find/math/1/au:+Stabile_G/0/1/0/all/0/1">Giovanni Stabile</a>, <a href="http://arxiv.org/find/math/1/au:+Rozza_G/0/1/0/all/0/1">Gianluigi Rozza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06558">
                                    <div class="article-summary-box-inner">
                                        <span>Models with dominant advection always posed a difficult challenge for
projection-based reduced order modelling. Many methodologies that have recently
been proposed are based on the pre-processing of the full-order solutions to
accelerate the Kolmogorov N-width decay thereby obtaining smaller linear
subspaces with improved accuracy. These methods however must rely on the
knowledge of the characteristic speeds in phase space of the solution, limiting
their range of applicability to problems with explicit functional form for the
advection field. In this work we approach the problem of automatically
detecting the correct pre-processing transformation in a statistical learning
framework by implementing a deep-learning architecture. The purely data-driven
method allowed us to generalise the existing approaches of linear subspace
manipulation to non-linear hyperbolic problems with unknown advection fields.
The proposed algorithm has been validated against simple test cases to
benchmark its performances and later successfully applied to a multiphase
simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractional Transfer Learning for Deep Model-Based Reinforcement Learning. (arXiv:2108.06526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sasso_R/0/1/0/all/0/1">Remo Sasso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabatelli_M/0/1/0/all/0/1">Matthia Sabatelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiering_M/0/1/0/all/0/1">Marco A. Wiering</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06526">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is well known for requiring large amounts of data
in order for RL agents to learn to perform complex tasks. Recent progress in
model-based RL allows agents to be much more data-efficient, as it enables them
to learn behaviors of visual environments in imagination by leveraging an
internal World Model of the environment. Improved sample efficiency can also be
achieved by reusing knowledge from previously learned tasks, but transfer
learning is still a challenging topic in RL. Parameter-based transfer learning
is generally done using an all-or-nothing approach, where the network&#x27;s
parameters are either fully transferred or randomly initialized. In this work
we present a simple alternative approach: fractional transfer learning. The
idea is to transfer fractions of knowledge, opposed to discarding potentially
useful knowledge as is commonly done with random initialization. Using the
World Model-based Dreamer algorithm, we identify which type of components this
approach is applicable to, and perform experiments in a new multi-source
transfer learning setting. The results show that fractional transfer learning
often leads to substantially improved performance and faster learning compared
to learning from scratch and random initialization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Machine-Learning-Ready Dataset Prepared from the Solar and Heliospheric Observatory Mission. (arXiv:2108.06394v1 [astro-ph.SR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Shneider_C/0/1/0/all/0/1">Carl Shneider</a> (1), <a href="http://arxiv.org/find/astro-ph/1/au:+Hu_A/0/1/0/all/0/1">Andong Hu</a> (1), <a href="http://arxiv.org/find/astro-ph/1/au:+Tiwari_A/0/1/0/all/0/1">Ajay K. Tiwari</a> (1), <a href="http://arxiv.org/find/astro-ph/1/au:+Bobra_M/0/1/0/all/0/1">Monica G. Bobra</a> (2), <a href="http://arxiv.org/find/astro-ph/1/au:+Battams_K/0/1/0/all/0/1">Karl Battams</a> (5), <a href="http://arxiv.org/find/astro-ph/1/au:+Teunissen_J/0/1/0/all/0/1">Jannis Teunissen</a> (1), <a href="http://arxiv.org/find/astro-ph/1/au:+Camporeale_E/0/1/0/all/0/1">Enrico Camporeale</a> (3 and 4) ((1) Multiscale Dynamics Group, Center for Mathematics and Computer Science (CWI), Amsterdam, The Netherlands, (2) W.W. Hansen Experimental Physics Laboratory, Stanford University, Stanford, CA, USA, (3) CIRES, University of Colorado, Boulder, CO, USA, (4) NOAA, Space Weather Prediction Center, Boulder, CO, USA, (5) US Naval Research Laboratory, Washington DC, USA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06394">
                                    <div class="article-summary-box-inner">
                                        <span>We present a Python tool to generate a standard dataset from solar images
that allows for user-defined selection criteria and a range of pre-processing
steps. Our Python tool works with all image products from both the Solar and
Heliospheric Observatory (SoHO) and Solar Dynamics Observatory (SDO) missions.
We discuss a dataset produced from the SoHO mission&#x27;s multi-spectral images
which is free of missing or corrupt data as well as planetary transits in
coronagraph images, and is temporally synced making it ready for input to a
machine learning system. Machine-learning-ready images are a valuable resource
for the community because they can be used, for example, for forecasting space
weather parameters. We illustrate the use of this data with a 3-5 day-ahead
forecast of the north-south component of the interplanetary magnetic field
(IMF) observed at Lagrange point one (L1). For this use case, we apply a deep
convolutional neural network (CNN) to a subset of the full SoHO dataset and
compare with baseline results from a Gaussian Naive Bayes classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Regularization of Bregman Proximal Point Algorithm and Mirror Descent on Separable Data. (arXiv:2108.06808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_C/0/1/0/all/0/1">Caleb Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_E/0/1/0/all/0/1">Ethan X. Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06808">
                                    <div class="article-summary-box-inner">
                                        <span>Bregman proximal point algorithm (BPPA), as one of the centerpieces in the
optimization toolbox, has been witnessing emerging applications. With simple
and easy to implement update rule, the algorithm bears several compelling
intuitions for empirical successes, yet rigorous justifications are still
largely unexplored. We study the computational properties of BPPA through
classification tasks with separable data, and demonstrate provable algorithmic
regularization effects associated with BPPA. We show that BPPA attains
non-trivial margin, which closely depends on the condition number of the
distance generating function inducing the Bregman divergence. We further
demonstrate that the dependence on the condition number is tight for a class of
problems, thus showing the importance of divergence in affecting the quality of
the obtained solutions. In addition, we extend our findings to mirror descent
(MD), for which we establish similar connections between the margin and Bregman
divergence. We demonstrate through a concrete example, and show BPPA/MD
converges in direction to the maximal margin solution with respect to the
Mahalanobis distance. Our theoretical findings are among the first to
demonstrate the benign learning properties BPPA/MD, and also provide
corroborations for a careful choice of divergence in the algorithmic design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LayerPipe: Accelerating Deep Neural Network Training by Intra-Layer and Inter-Layer Gradient Pipelining and Multiprocessor Scheduling. (arXiv:2108.06629v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Unnikrishnan_N/0/1/0/all/0/1">Nanda K. Unnikrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Parhi_K/0/1/0/all/0/1">Keshab K. Parhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06629">
                                    <div class="article-summary-box-inner">
                                        <span>The time required for training the neural networks increases with size,
complexity, and depth. Training model parameters by backpropagation inherently
creates feedback loops. These loops hinder efficient pipelining and scheduling
of the tasks within the layer and between consecutive layers. Prior approaches,
such as PipeDream, have exploited the use of delayed gradient to achieve
inter-layer pipelining. However, these approaches treat the entire
backpropagation as a single task; this leads to an increase in computation time
and processor underutilization. This paper presents novel optimization
approaches where the gradient computations with respect to the weights and the
activation functions are considered independently; therefore, these can be
computed in parallel. This is referred to as intra-layer optimization.
Additionally, the gradient computation with respect to the activation function
is further divided into two parts and distributed to two consecutive layers.
This leads to balanced scheduling where the computation time of each layer is
the same. This is referred to as inter-layer optimization. The proposed system,
referred to as LayerPipe, reduces the number of clock cycles required for
training while maximizing processor utilization with minimal inter-processor
communication overhead. LayerPipe achieves an average speedup of 25% and
upwards of 80% with 7 to 9 processors with less communication overhead when
compared to PipeDream.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Sharpe predictor for fairness in machine learning. (arXiv:2108.06415v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Suyun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1">Luis Nunes Vicente</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06415">
                                    <div class="article-summary-box-inner">
                                        <span>In machine learning (ML) applications, unfair predictions may discriminate
against a minority group. Most existing approaches for fair machine learning
(FML) treat fairness as a constraint or a penalization term in the optimization
of a ML model, which does not lead to the discovery of the complete landscape
of the trade-offs among learning accuracy and fairness metrics, and does not
integrate fairness in a meaningful way.

Recently, we have introduced a new paradigm for FML based on Stochastic
Multi-Objective Optimization (SMOO), where accuracy and fairness metrics stand
as conflicting objectives to be optimized simultaneously. The entire trade-offs
range is defined as the Pareto front of the SMOO problem, which can then be
efficiently computed using stochastic-gradient type algorithms. SMOO also
allows defining and computing new meaningful predictors for FML, a novel one
being the Sharpe predictor that we introduce and explore in this paper, and
which gives the highest ratio of accuracy-to-unfairness. Inspired from SMOO in
finance, the Sharpe predictor for FML provides the highest prediction return
(accuracy) per unit of prediction risk (unfairness).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Geospatial Interpolation Networks. (arXiv:2108.06670v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_S/0/1/0/all/0/1">Sumit Kumar Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_J/0/1/0/all/0/1">Jeetu Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1">Aditya Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rishabh Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunturi_V/0/1/0/all/0/1">Venkata M. V. Gunturi</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_N/0/1/0/all/0/1">Narayanan C. Krishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06670">
                                    <div class="article-summary-box-inner">
                                        <span>Interpolation in Spatio-temporal data has applications in various domains
such as climate, transportation, and mining. Spatio-Temporal interpolation is
highly challenging due to the complex spatial and temporal relationships.
However, traditional techniques such as Kriging suffer from high running time
and poor performance on data that exhibit high variance across space and time
dimensions. To this end, we propose a novel deep neural network called as Deep
Geospatial Interpolation Network(DGIN), which incorporates both spatial and
temporal relationships and has significantly lower training time. DGIN consists
of three major components: Spatial Encoder to capture the spatial dependencies,
Sequential module to incorporate the temporal dynamics, and an Attention block
to learn the importance of the temporal neighborhood around the gap. We
evaluate DGIN on the MODIS reflectance dataset from two different regions. Our
experimental results indicate that DGIN has two advantages: (a) it outperforms
alternative approaches (has lower MSE with p-value &lt; 0.01) and, (b) it has
significantly low execution time than Kriging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stacked Hourglass Network with a Multi-level Attention Mechanism: Where to Look for Intervertebral Disc Labeling. (arXiv:2108.06554v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azad_R/0/1/0/all/0/1">Reza Azad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouhier_L/0/1/0/all/0/1">Lucas Rouhier</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Adad_J/0/1/0/all/0/1">Julien Cohen-Adad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06554">
                                    <div class="article-summary-box-inner">
                                        <span>Labeling vertebral discs from MRI scans is important for the proper diagnosis
of spinal related diseases, including multiple sclerosis, amyotrophic lateral
sclerosis, degenerative cervical myelopathy and cancer. Automatic labeling of
the vertebral discs in MRI data is a difficult task because of the similarity
between discs and bone area, the variability in the geometry of the spine and
surrounding tissues across individuals, and the variability across scans
(manufacturers, pulse sequence, image contrast, resolution and artefacts). In
previous studies, vertebral disc labeling is often done after a disc detection
step and mostly fails when the localization algorithm misses discs or has false
positive detection. In this work, we aim to mitigate this problem by
reformulating the semantic vertebral disc labeling using the pose estimation
technique. To do so, we propose a stacked hourglass network with multi-level
attention mechanism to jointly learn intervertebral disc position and their
skeleton structure. The proposed deep learning model takes into account the
strength of semantic segmentation and pose estimation technique to handle the
missing area and false positive detection. To further improve the performance
of the proposed method, we propose a skeleton-based search space to reduce
false positive detection. The proposed method evaluated on spine generic public
multi-center dataset and demonstrated better performance comparing to previous
work, on both T1w and T2w contrasts. The method is implemented in ivadomed
(https://ivadomed.org).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Optimization in Edge-Cloud Continuum for Federated Unsupervised Person Re-identification. (arXiv:2108.06493v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06493">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (ReID) aims to re-identify a person from
non-overlapping camera views. Since person ReID data contains sensitive
personal information, researchers have adopted federated learning, an emerging
distributed training method, to mitigate the privacy leakage risks. However,
existing studies rely on data labels that are laborious and time-consuming to
obtain. We present FedUReID, a federated unsupervised person ReID system to
learn person ReID models without any labels while preserving privacy. FedUReID
enables in-situ model training on edges with unlabeled data. A cloud server
aggregates models from edges instead of centralizing raw data to preserve data
privacy. Moreover, to tackle the problem that edges vary in data volumes and
distributions, we personalize training in edges with joint optimization of
cloud and edge. Specifically, we propose personalized epoch to reassign
computation throughout training, personalized clustering to iteratively predict
suitable labels for unlabeled data, and personalized update to adapt the server
aggregated model to each edge. Extensive experiments on eight person ReID
datasets demonstrate that FedUReID not only achieves higher accuracy but also
reduces computation cost by 29%. Our FedUReID system with the joint
optimization will shed light on implementing federated learning to more
multimedia tasks without data labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Federated Meta-Learning over Multi-Access Wireless Networks. (arXiv:2108.06453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1">Sheng Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Ju Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1">Jiang Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Deyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yaoxue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weihua Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06453">
                                    <div class="article-summary-box-inner">
                                        <span>Federated meta-learning (FML) has emerged as a promising paradigm to cope
with the data limitation and heterogeneity challenges in today&#x27;s edge learning
arena. However, its performance is often limited by slow convergence and
corresponding low communication efficiency. Besides, since the wireless
bandwidth and IoT devices&#x27; energy capacity are usually insufficient, it is
crucial to control the resource allocation and energy consumption when
deploying FML in realistic wireless networks. To overcome these challenges, in
this paper, we first rigorously analyze each device&#x27;s contribution to the
global loss reduction in each round and develop an FML algorithm (called NUFM)
with a non-uniform device selection scheme to accelerate the convergence. After
that, we formulate a resource allocation problem integrating NUFM in
multi-access wireless systems to jointly improve the convergence rate and
minimize the wall-clock time along with energy cost. By deconstructing the
original problem step by step, we devise a joint device selection and resource
allocation strategy (called URAL) to solve the problem and provide theoretical
guarantees. Further, we show that the computational complexity of NUFM can be
reduced from $O(d^2)$ to $O(d)$ (with $d$ being the model dimension) via
combining two first-order approximation techniques. Extensive simulation
results demonstrate the effectiveness and superiority of the proposed methods
by comparing with the existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Metadata-based Multi-Task Bandits with Bayesian Hierarchical Models. (arXiv:2108.06422v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_R/0/1/0/all/0/1">Runzhe Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_L/0/1/0/all/0/1">Lin Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06422">
                                    <div class="article-summary-box-inner">
                                        <span>How to explore efficiently is a central problem in multi-armed bandits. In
this paper, we introduce the metadata-based multi-task bandit problem, where
the agent needs to solve a large number of related multi-armed bandit tasks and
can leverage some task-specific features (i.e., metadata) to share knowledge
across tasks. As a general framework, we propose to capture task relations
through the lens of Bayesian hierarchical models, upon which a Thompson
sampling algorithm is designed to efficiently learn task relations, share
information, and minimize the cumulative regrets. Two concrete examples for
Gaussian bandits and Bernoulli bandits are carefully analyzed. The Bayes regret
for Gaussian bandits clearly demonstrates the benefits of information sharing
with our algorithm. The proposed method is further supported by extensive
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotic optimality and minimal complexity of classification by random projection. (arXiv:2108.06339v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boutin_M/0/1/0/all/0/1">Mireille Boutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Coupkova_E/0/1/0/all/0/1">Evzenie Coupkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06339">
                                    <div class="article-summary-box-inner">
                                        <span>The generalization error of a classifier is related to the complexity of the
set of functions among which the classifier is chosen. Roughly speaking, the
more complex the family, the greater the potential disparity between the
training error and the population error of the classifier. This principle is
embodied in layman&#x27;s terms by Occam&#x27;s razor principle, which suggests favoring
low-complexity hypotheses over complex ones. We study a family of
low-complexity classifiers consisting of thresholding the one-dimensional
feature obtained by projecting the data on a random line after embedding it
into a higher dimensional space parametrized by monomials of order up to k.
More specifically, the extended data is projected n-times and the best
classifier among those n (based on its performance on training data) is chosen.
We obtain a bound on the generalization error of these low-complexity
classifiers. The bound is less than that of any classifier with a non-trivial
VC dimension, and thus less than that of a linear classifier. We also show
that, given full knowledge of the class conditional densities, the error of the
classifiers would converge to the optimal (Bayes) error as k and n go to
infinity; if only a training dataset is given, we show that the classifiers
will perfectly classify all the training points as k and n go to infinity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Streaming of 360 Videos with Perfect, Imperfect, and Unknown FoV Viewing Probabilities in Wireless Networks. (arXiv:2107.09491v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Lingzhi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Ying Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunfei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09491">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates adaptive streaming of one or multiple tiled 360
videos from a multi-antenna base station (BS) to one or multiple single-antenna
users, respectively, in a multi-carrier wireless system. We aim to maximize the
video quality while keeping rebuffering time small via encoding rate adaptation
at each group of pictures (GOP) and transmission adaptation at each
(transmission) slot. To capture the impact of field-of-view (FoV) prediction,
we consider three cases of FoV viewing probability distributions, i.e.,
perfect, imperfect, and unknown FoV viewing probability distributions, and use
the average total utility, worst average total utility, and worst total utility
as the respective performance metrics. In the single-user scenario, we optimize
the encoding rates of the tiles, encoding rates of the FoVs, and transmission
beamforming vectors for all subcarriers to maximize the total utility in each
case. In the multi-user scenario, we adopt rate splitting with successive
decoding and optimize the encoding rates of the tiles, encoding rates of the
FoVs, rates of the common and private messages, and transmission beamforming
vectors for all subcarriers to maximize the total utility in each case. Then,
we separate the challenging optimization problem into multiple tractable
problems in each scenario. In the single-user scenario, we obtain a globally
optimal solution of each problem using transformation techniques and the
Karush-Kuhn-Tucker (KKT) conditions. In the multi-user scenario, we obtain a
KKT point of each problem using the concave-convex procedure (CCCP). Finally,
numerical results demonstrate that the proposed solutions achieve notable gains
over existing schemes in all three cases. To the best of our knowledge, this is
the first work revealing the impact of FoV prediction on the performance of
adaptive streaming of tiled 360 videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoChart: A Dataset for Chart-to-Text Generation Task. (arXiv:2108.06897v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiawen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_J/0/1/0/all/0/1">Jinye Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1">Kenny Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06897">
                                    <div class="article-summary-box-inner">
                                        <span>The analytical description of charts is an exciting and important research
area with many applications in academia and industry. Yet, this challenging
task has received limited attention from the computational linguistics research
community. This paper proposes \textsf{AutoChart}, a large dataset for the
analytical description of charts, which aims to encourage more research into
this important area. Specifically, we offer a novel framework that generates
the charts and their analytical description automatically. We conducted
extensive human and machine evaluations on the generated charts and
descriptions and demonstrate that the generated texts are informative,
coherent, and relevant to the corresponding charts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hacking VMAF and VMAF NEG: vulnerability to different preprocessing methods. (arXiv:2107.04510v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siniukov_M/0/1/0/all/0/1">Maksim Siniukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1">Anastasia Antsiferova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1">Dmitriy Kulikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1">Dmitriy Vatolin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04510">
                                    <div class="article-summary-box-inner">
                                        <span>Video-quality measurement plays a critical role in the development of
video-processing applications. In this paper, we show how video preprocessing
can artificially increase the popular quality metric VMAF and its
tuning-resistant version, VMAF NEG. We propose a pipeline that tunes
processing-algorithm parameters to increase VMAF by up to 218.8%. A subjective
comparison revealed that for most preprocessing methods, a video&#x27;s visual
quality drops or stays unchanged. We also show that some preprocessing methods
can increase VMAF NEG scores by up to 23.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focusing on Persons: Colorizing Old Images Learning from Modern Historical Movies. (arXiv:2108.06515v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhonglan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Ke Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1">Dongqing Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingfan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Ziyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qilong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06515">
                                    <div class="article-summary-box-inner">
                                        <span>In industry, there exist plenty of scenarios where old gray photos need to be
automatically colored, such as video sites and archives. In this paper, we
present the HistoryNet focusing on historical person&#x27;s diverse high fidelity
clothing colorization based on fine grained semantic understanding and prior.
Colorization of historical persons is realistic and practical, however,
existing methods do not perform well in the regards. In this paper, a
HistoryNet including three parts, namely, classification, fine grained semantic
parsing and colorization, is proposed. Classification sub-module supplies
classifying of images according to the eras, nationalities and garment types;
Parsing sub-network supplies the semantic for person contours, clothing and
background in the image to achieve more accurate colorization of clothes and
persons and prevent color overflow. In the training process, we integrate
classification and semantic parsing features into the coloring generation
network to improve colorization. Through the design of classification and
parsing subnetwork, the accuracy of image colorization can be improved and the
boundary of each part of image can be more clearly. Moreover, we also propose a
novel Modern Historical Movies Dataset (MHMD) containing 1,353,166 images and
42 labels of eras, nationalities, and garment types for automatic colorization
from 147 historical movies or TV series made in modern time. Various
quantitative and qualitative comparisons demonstrate that our method
outperforms the state-of-the-art colorization methods, especially on military
uniforms, which has correct colors according to the historical literatures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-16">2021-08-16</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diachronic Analysis of German Parliamentary Proceedings: Ideological Shifts through the Lens of Political Biases. (arXiv:2108.06295v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walter_T/0/1/0/all/0/1">Tobias Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirschner_C/0/1/0/all/0/1">Celina Kirschner</a>, <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponzetto_S/0/1/0/all/0/1">Simone Paolo Ponzetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06295">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze bias in historical corpora as encoded in diachronic distributional
semantic models by focusing on two specific forms of bias, namely a political
(i.e., anti-communism) and racist (i.e., antisemitism) one. For this, we use a
new corpus of German parliamentary proceedings, DeuPARL, spanning the period
1867--2020. We complement this analysis of historical biases in diachronic word
embeddings with a novel measure of bias on the basis of term co-occurrences and
graph-based label propagation. The results of our bias measurements align with
commonly perceived historical trends of antisemitic and anti-communist biases
in German politics in different time periods, thus indicating the viability of
analyzing historical bias trends using semantic spaces induced from historical
corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simplifying Paragraph-level Question Generation via Transformer Language Models. (arXiv:2005.01107v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lopez_L/0/1/0/all/0/1">Luis Enrico Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_D/0/1/0/all/0/1">Diane Kathryn Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1">Jan Christian Blaise Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Charibeth Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01107">
                                    <div class="article-summary-box-inner">
                                        <span>Question generation (QG) is a natural language generation task where a model
is trained to ask questions corresponding to some input text. Most recent
approaches frame QG as a sequence-to-sequence problem and rely on additional
features and mechanisms to increase performance; however, these often increase
model complexity, and can rely on auxiliary data unavailable in practical use.
A single Transformer-based unidirectional language model leveraging transfer
learning can be used to produce high quality questions while disposing of
additional task-specific complexity. Our QG model, finetuned from GPT-2 Small,
outperforms several paragraph-level QG baselines on the SQuAD dataset by 0.95
METEOR points. Human evaluators rated questions as easy to answer, relevant to
their context paragraph, and corresponding well to natural human speech. Also
introduced is a new set of baseline scores on the RACE dataset, which has not
previously been used for QG tasks. Further experimentation with varying model
capacities and datasets with non-identification type questions is recommended
in order to further verify the robustness of pretrained Transformer-based LMs
as question generators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Relationships Between Scientific Documents. (arXiv:2002.00317v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Kelvin Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1">Rik Koncel-Kedziorski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cachola_I/0/1/0/all/0/1">Isabel Cachola</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00317">
                                    <div class="article-summary-box-inner">
                                        <span>We address the task of explaining relationships between two scientific
documents using natural language text. This task requires modeling the complex
content of long technical documents, deducing a relationship between these
documents, and expressing the details of that relationship in text. In addition
to the theoretical interest of this task, successful solutions can help improve
researcher efficiency in search and review. In this paper we establish a
dataset of 622K examples from 154K documents. We pretrain a large language
model to serve as the foundation for autoregressive approaches to the task. We
explore the impact of taking different views on the two documents, including
the use of dense representations extracted with scientific IE systems. We
provide extensive automatic and human evaluations which show the promise of
such models, but make clear challenges for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning. (arXiv:2108.06332v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yanan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhilin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06332">
                                    <div class="article-summary-box-inner">
                                        <span>Most previous methods for text data augmentation are limited to simple tasks
and weak baselines. We explore data augmentation on hard tasks (i.e., few-shot
natural language understanding) and strong baselines (i.e., pretrained models
with over one billion parameters). Under this setting, we reproduced a large
number of previous augmentation methods and found that these methods bring
marginal gains at best and sometimes degrade the performance much. To address
this challenge, we propose a novel data augmentation method FlipDA that jointly
uses a generative model and a classifier to generate label-flipped data.
Central to the idea of FlipDA is the discovery that generating label-flipped
data is more crucial to the performance than generating label-preserved data.
Experiments show that FlipDA achieves a good tradeoff between effectiveness and
robustness---it substantially improves many tasks while not negatively
affecting the others.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spanish Language Models. (arXiv:2107.07253v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_Fandino_A/0/1/0/all/0/1">Asier Guti&#xe9;rrez-Fandi&#xf1;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Armengol_Estape_J/0/1/0/all/0/1">Jordi Armengol-Estap&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pamies_M/0/1/0/all/0/1">Marc P&#xe0;mies</a>, <a href="http://arxiv.org/find/cs/1/au:+Llop_Palao_J/0/1/0/all/0/1">Joan Llop-Palao</a>, <a href="http://arxiv.org/find/cs/1/au:+Silveira_Ocampo_J/0/1/0/all/0/1">Joaqu&#xed;n Silveira-Ocampo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carrino_C/0/1/0/all/0/1">Casimiro Pio Carrino</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Agirre_A/0/1/0/all/0/1">Aitor Gonzalez-Agirre</a>, <a href="http://arxiv.org/find/cs/1/au:+Armentano_Oller_C/0/1/0/all/0/1">Carme Armentano-Oller</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Penagos_C/0/1/0/all/0/1">Carlos Rodriguez-Penagos</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_M/0/1/0/all/0/1">Marta Villegas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07253">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the Spanish RoBERTa-base and RoBERTa-large models, as
well as the corresponding performance evaluations. Both models were pre-trained
using the largest Spanish corpus known to date, with a total of 570GB of clean
and deduplicated text processed for this work, compiled from the web crawlings
performed by the National Library of Spain from 2009 to 2019. We extended the
current evaluation datasets with an extractive Question Answering dataset and
our models outperform the existing Spanish models across tasks and settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models. (arXiv:2106.00245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00245">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from large-scale pre-training, we have witnessed significant
performance boost on the popular Visual Question Answering (VQA) task. Despite
rapid progress, it remains unclear whether these state-of-the-art (SOTA) models
are robust when encountering examples in the wild. To study this, we introduce
Adversarial VQA, a new large-scale VQA benchmark, collected iteratively via an
adversarial human-and-model-in-the-loop procedure. Through this new benchmark,
we discover several interesting findings. (i) Surprisingly, we find that during
dataset collection, non-expert annotators can easily attack SOTA VQA models
successfully. (ii) Both large-scale pre-trained models and adversarial training
methods achieve far worse performance on the new benchmark than over standard
VQA v2 dataset, revealing the fragility of these models while demonstrating the
effectiveness of our adversarial dataset. (iii) When used for data
augmentation, our dataset can effectively boost model performance on other
robust VQA benchmarks. We hope our Adversarial VQA dataset can shed new light
on robustness study in the community and serve as a valuable benchmark for
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting News Article Structure for Automatic Corpus Generation of Entailment Datasets. (arXiv:2010.11574v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1">Jan Christian Blaise Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Resabal_J/0/1/0/all/0/1">Jose Kristian Resabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">James Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1">Dan John Velasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Charibeth Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11574">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language Inference (NLI) benchmark datasets
for low-resource languages using published news articles. Through this, we
create and release NewsPH-NLI, the first sentence entailment benchmark dataset
in the low-resource Filipino language. Second, we produce new pretrained
transformers based on the ELECTRA technique to further alleviate the resource
scarcity in Filipino, benchmarking them on our dataset against other
commonly-used transfer learning techniques. Lastly, we perform analyses on
transfer learning techniques to shed light on their true performance when
operating in low-data domains through the use of degradation tests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Smart Chatbot Prototype for Patient Monitoring. (arXiv:2103.06816v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_H/0/1/0/all/0/1">Hannah Lei</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Weiqi Lu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ji_A/0/1/0/all/0/1">Alan Ji</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Bertram_E/0/1/0/all/0/1">Emmett Bertram</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Paul Gao</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Barman_A/0/1/0/all/0/1">Arko Barman</a> (1) ((1) Rice University, Houston, United States, (2) The University of Texas Health Science Center at Houston, United States)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06816">
                                    <div class="article-summary-box-inner">
                                        <span>Many COVID-19 patients developed prolonged symptoms after the infection,
including fatigue, delirium, and headache. The long-term health impact of these
conditions is still not clear. It is necessary to develop a way to follow up
with these patients for monitoring their health status to support timely
intervention and treatment. In the lack of sufficient human resources to follow
up with patients, we propose a novel smart chatbot solution backed with machine
learning to collect information (i.e., generating digital diary) in a
personalized manner. In this article, we describe the design framework and
components of our prototype.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset for Answering Time-Sensitive Questions. (arXiv:2108.06314v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06314">
                                    <div class="article-summary-box-inner">
                                        <span>Time is an important dimension in our physical world. Lots of facts can
evolve with respect to time. For example, the U.S. President might change every
four years. Therefore, it is important to consider the time dimension and
empower the existing QA models to reason over time. However, the existing QA
datasets contain rather few time-sensitive questions, hence not suitable for
diagnosing or benchmarking the model&#x27;s temporal reasoning capability. In order
to promote research in this direction, we propose to construct a time-sensitive
QA dataset. The dataset is constructed by 1) mining time-evolving facts from
WikiData and align them to their corresponding Wikipedia page, 2) employing
crowd workers to verify and calibrate these noisy facts, 3) generating
question-answer pairs based on the annotated time-sensitive facts. Our dataset
poses two novel challenges: 1) the model needs to understand both explicit and
implicit mention of time information in the long document, 2) the model needs
to perform temporal reasoning like comparison, addition, subtraction. We
evaluate different SoTA long-document QA systems like BigBird and FiD on our
dataset. The best-performing model FiD can only achieve 46\% accuracy, still
far behind the human performance of 87\%. We demonstrate that these models are
still lacking the ability to perform robust temporal understanding and
reasoning. Therefore, we believe that our dataset could serve as a benchmark to
empower future studies in temporal reasoning. The dataset and code are released
in~\url{https://github.com/wenhuchen/Time-Sensitive-QA}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MeetSum: Transforming Meeting Transcript Summarization using Transformers!. (arXiv:2108.06310v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadri_N/0/1/0/all/0/1">Nima Sadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bihan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06310">
                                    <div class="article-summary-box-inner">
                                        <span>Creating abstractive summaries from meeting transcripts has proven to be
challenging due to the limited amount of labeled data available for training
neural network models. Moreover, Transformer-based architectures have proven to
beat state-of-the-art models in summarizing news data. In this paper, we
utilize a Transformer-based Pointer Generator Network to generate abstract
summaries for meeting transcripts. This model uses 2 LSTMs as an encoder and a
decoder, a Pointer network which copies words from the inputted text, and a
Generator network to produce out-of-vocabulary words (hence making the summary
abstractive). Moreover, a coverage mechanism is used to avoid repetition of
words in the generated summary. First, we show that training the model on a
news summary dataset and using zero-shot learning to test it on the meeting
dataset proves to produce better results than training it on the AMI meeting
dataset. Second, we show that training this model first on out-of-domain data,
such as the CNN-Dailymail dataset, followed by a fine-tuning stage on the AMI
meeting dataset is able to improve the performance of the model significantly.
We test our model on a testing set from the AMI dataset and report the ROUGE-2
score of the generated summary to compare with previous literature. We also
report the Factual score of our summaries since it is a better benchmark for
abstractive summaries since the ROUGE-2 score is limited to measuring
word-overlaps. We show that our improved model is able to improve on previous
models by at least 5 ROUGE-2 scores, which is a substantial improvement. Also,
a qualitative analysis of the summaries generated by our model shows that these
summaries and human-readable and indeed capture most of the important
information from the transcripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Structured Dynamic Sparse Pre-Training of BERT. (arXiv:2108.06277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06277">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying algorithms for computational efficient unsupervised training of
large language models is an important and active area of research. In this
work, we develop and study a straightforward, dynamic always-sparse
pre-training approach for BERT language modeling task, which leverages periodic
compression steps based on magnitude pruning followed by random parameter
re-allocation. This approach enables us to achieve Pareto improvements in terms
of the number of floating-point operations (FLOPs) over statically sparse and
dense models across a broad spectrum of network sizes. Furthermore, we
demonstrate that training remains FLOP-efficient when using coarse-grained
block sparsity, making it particularly promising for efficient execution on
modern hardware accelerators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAIR: Framework for mining relationships between research articles, strategies, and regulations in the field of explainable artificial intelligence. (arXiv:2108.06216v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1">Stanis&#x142;aw Gizinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzba_M/0/1/0/all/0/1">Micha&#x142; Kuzba</a>, <a href="http://arxiv.org/find/cs/1/au:+Pielinski_B/0/1/0/all/0/1">Bartosz Pielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sienkiewicz_J/0/1/0/all/0/1">Julian Sienkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Laniewski_S/0/1/0/all/0/1">Stanis&#x142;aw &#x141;aniewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1">Przemys&#x142;aw Biecek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06216">
                                    <div class="article-summary-box-inner">
                                        <span>The growing number of AI applications, also for high-stake decisions,
increases the interest in Explainable and Interpretable Machine Learning
(XI-ML). This trend can be seen both in the increasing number of regulations
and strategies for developing trustworthy AI and the growing number of
scientific papers dedicated to this topic. To ensure the sustainable
development of AI, it is essential to understand the dynamics of the impact of
regulation on research papers as well as the impact of scientific discourse on
AI-related policies. This paper introduces a novel framework for joint analysis
of AI-related policy documents and eXplainable Artificial Intelligence (XAI)
research papers. The collected documents are enriched with metadata and
interconnections, using various NLP methods combined with a methodology
inspired by Institutional Grammar. Based on the information extracted from
collected documents, we showcase a series of analyses that help understand
interactions, similarities, and differences between documents at different
stages of institutionalization. To the best of our knowledge, this is the first
work to use automatic language analysis tools to understand the dynamics
between XI-ML methods and regulations. We believe that such a system
contributes to better cooperation between XAI researchers and AI policymakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1">Greyson Gerhard-Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1">Raviteja Anantha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1">Srinivas Chappidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1">Bj&#xf6;rn Hoffmeister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06329">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work building open-domain chatbots has demonstrated that increasing
model size improves performance. On the other hand, latency and connectivity
considerations dictate the move of digital assistants on the device. Giving a
digital assistant like Siri, Alexa, or Google Assistant the ability to discuss
just about anything leads to the need for reducing the chatbot model size such
that it fits on the user&#x27;s device. We demonstrate that low parameter models can
simultaneously retain their general knowledge conversational abilities while
improving in a specific domain. Additionally, we propose a generic framework
that accounts for variety in question types, tracks reference throughout
multi-turn conversations, and removes inconsistent and potentially toxic
responses. Our framework seamlessly transitions between chatting and performing
transactional tasks, which will ultimately make interactions with digital
assistants more human-like. We evaluate our framework on 1 internal and 4
public benchmark datasets using both automatic (Perplexity) and human (SSA -
Sensibleness and Specificity Average) evaluation metrics and establish
comparable performance while reducing model parameters by 90%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Single and Multiple Representations in Dense Passage Retrieval. (arXiv:2108.06279v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06279">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextualised language models has brought gains in search
effectiveness, not just when applied for re-ranking the output of classical
weighting models such as BM25, but also when used directly for passage indexing
and retrieval, a technique which is called dense retrieval. In the existing
literature in neural ranking, two dense retrieval families have become
apparent: single representation, where entire passages are represented by a
single embedding (usually BERT&#x27;s [CLS] token, as exemplified by the recent ANCE
approach), or multiple representations, where each token in a passage is
represented by its own embedding (as exemplified by the recent ColBERT
approach). These two families have not been directly compared. However, because
of the likely importance of dense retrieval moving forward, a clear
understanding of their advantages and disadvantages is paramount. To this end,
this paper contributes a direct study on their comparative effectiveness,
noting situations where each method under/over performs w.r.t. each other, and
w.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than
ColBERT in terms of response time and memory usage, multiple representations
are statistically more effective than the single representations for MAP and
MRR@10. We also show that multiple representations obtain better improvements
than single representations for queries that are the hardest for BM25, as well
as for definitional queries, and those with complex information needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aspect Sentiment Triplet Extraction Using Reinforcement Learning. (arXiv:2108.06107v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Samson Yu Bai Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_T/0/1/0/all/0/1">Tapas Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06107">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting triplets
of aspect terms, their associated sentiments, and the opinion terms that
provide evidence for the expressed sentiments. Previous approaches to ASTE
usually simultaneously extract all three components or first identify the
aspect and opinion terms, then pair them up to predict their sentiment
polarities. In this work, we present a novel paradigm, ASTE-RL, by regarding
the aspect and opinion terms as arguments of the expressed sentiment in a
hierarchical reinforcement learning (RL) framework. We first focus on
sentiments expressed in a sentence, then identify the target aspect and opinion
terms for that sentiment. This takes into account the mutual interactions among
the triplet&#x27;s components while improving exploration and sample efficiency.
Furthermore, this hierarchical RLsetup enables us to deal with multiple and
overlapping triplets. In our experiments, we evaluate our model on existing
datasets from laptop and restaurant domains and show that it achieves
state-of-the-art performance. The implementation of this work is publicly
available at https://github.com/declare-lab/ASTE-RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Answer Similarity for Evaluating Question Answering Models. (arXiv:2108.06130v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutsch_J/0/1/0/all/0/1">Julian Gutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietsch_M/0/1/0/all/0/1">Malte Pietsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06130">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of question answering models compares ground-truth annotations
with model predictions. However, as of today, this comparison is mostly
lexical-based and therefore misses out on answers that have no lexical overlap
but are still semantically similar, thus treating correct answers as false.
This underestimation of the true performance of models hinders user acceptance
in applications and complicates a fair comparison of different models.
Therefore, there is a need for an evaluation metric that is based on semantics
instead of pure string similarity. In this short paper, we present SAS, a
cross-encoder-based metric for the estimation of semantic answer similarity,
and compare it to seven existing metrics. To this end, we create an English and
a German three-way annotated evaluation dataset containing pairs of answers
along with human judgment of their semantic similarity, which we release along
with an implementation of the SAS metric and the experiments. We find that
semantic similarity metrics based on recent transformer models correlate much
better with human judgment than traditional lexical similarity metrics on our
two newly created datasets and one dataset from related work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Ruiyang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1">Shangwen Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Yingqi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">QiaoQiao She</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, dense passage retrieval has become a mainstream approach to finding
relevant information in various natural language processing tasks. A number of
studies have been devoted to improving the widely adopted dual-encoder
architecture. However, most of the previous studies only consider query-centric
similarity relation when learning the dual-encoder retriever. In order to
capture more comprehensive similarity relations, we propose a novel approach
that leverages both query-centric and PAssage-centric sImilarity Relations
(called PAIR) for dense passage retrieval. To implement our approach, we make
three major technical contributions by introducing formal formulations of the
two kinds of similarity relations, generating high-quality pseudo labeled data
via knowledge distillation, and designing an effective two-stage training
procedure that incorporates passage-centric similarity relation constraint.
Extensive experiments show that our approach significantly outperforms previous
state-of-the-art models on both MSMARCO and Natural Questions datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Graph Reasoning with Relational Directed Graph. (arXiv:2108.06040v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06040">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning on the knowledge graph (KG) aims to infer new facts from existing
ones. Methods based on the relational path in the literature have shown strong,
interpretable, and inductive reasoning ability. However, the paths are
naturally limited in capturing complex topology in KG. In this paper, we
introduce a novel relational structure, i.e., relational directed graph
(r-digraph), which is composed of overlapped relational paths, to capture the
KG&#x27;s structural information. Since the digraph exhibits more complex structure
than paths, constructing and learning on the r-digraph are challenging. Here,
we propose a variant of graph neural network, i.e., RED-GNN, to address the
above challenges by learning the RElational Digraph with a variant of GNN.
Specifically, RED-GNN recursively encodes multiple r-digraphs with shared edges
and selects the strongly correlated edges through query-dependent attention
weights. We demonstrate the significant gains on reasoning both KG with unseen
entities and incompletion KG benchmarks by the r-digraph, the efficiency of
RED-GNN, and the interpretable dependencies learned on the r-digraph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TPRM: A Topic-based Personalized Ranking Model for Web Search. (arXiv:2108.06014v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06014">
                                    <div class="article-summary-box-inner">
                                        <span>Ranking models have achieved promising results, but it remains challenging to
design personalized ranking systems to leverage user profiles and semantic
representations between queries and documents. In this paper, we propose a
topic-based personalized ranking model (TPRM) that integrates user topical
profile with pretrained contextualized term representations to tailor the
general document ranking list. Experiments on the real-world dataset
demonstrate that TPRM outperforms state-of-the-art ad-hoc ranking models and
personalized ranking models significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of the HASOC track at FIRE 2020: Hate Speech and Offensive Content Identification in Indo-European Languages. (arXiv:2108.05927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mandla_T/0/1/0/all/0/1">Thomas Mandla</a>, <a href="http://arxiv.org/find/cs/1/au:+Modha_S/0/1/0/all/0/1">Sandip Modha</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1">Amit Kumar Jaiswal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandini_D/0/1/0/all/0/1">Durgesh Nandini</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Daksh Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_P/0/1/0/all/0/1">Prasenjit Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_J/0/1/0/all/0/1">Johannes Sch&#xe4;fer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05927">
                                    <div class="article-summary-box-inner">
                                        <span>With the growth of social media, the spread of hate speech is also increasing
rapidly. Social media are widely used in many countries. Also Hate Speech is
spreading in these countries. This brings a need for multilingual Hate Speech
detection algorithms. Much research in this area is dedicated to English at the
moment. The HASOC track intends to provide a platform to develop and optimize
Hate Speech detection algorithms for Hindi, German and English. The dataset is
collected from a Twitter archive and pre-classified by a machine learning
system. HASOC has two sub-task for all three languages: task A is a binary
classification problem (Hate and Not Offensive) while task B is a fine-grained
classification problem for three classes (HATE) Hate speech, OFFENSIVE and
PROFANITY. Overall, 252 runs were submitted by 40 teams. The performance of the
best classification algorithms for task A are F1 measures of 0.51, 0.53 and
0.52 for English, Hindi, and German, respectively. For task B, the best
classification algorithms achieved F1 measures of 0.26, 0.33 and 0.29 for
English, Hindi, and German, respectively. This article presents the tasks and
the data development as well as the results. The best performing algorithms
were mainly variants of the transformer architecture BERT. However, also other
systems were applied with good success</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GQE-PRF: Generative Query Expansion with Pseudo-Relevance Feedback. (arXiv:2108.06010v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Meizhen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06010">
                                    <div class="article-summary-box-inner">
                                        <span>Query expansion with pseudo-relevance feedback (PRF) is a powerful approach
to enhance the effectiveness in information retrieval. Recently, with the rapid
advance of deep learning techniques, neural text generation has achieved
promising success in many natural language tasks. To leverage the strength of
text generation for information retrieval, in this article, we propose a novel
approach which effectively integrates text generation models into PRF-based
query expansion. In particular, our approach generates augmented query terms
via neural text generation models conditioned on both the initial query and
pseudo-relevance feedback. Moreover, in order to train the generative model, we
adopt the conditional generative adversarial nets (CGANs) and propose the
PRF-CGAN method in which both the generator and the discriminator are
conditioned on the pseudo-relevance feedback. We evaluate the performance of
our approach on information retrieval tasks using two benchmark datasets. The
experimental results show that our approach achieves comparable performance or
outperforms traditional query expansion methods on both the retrieval and
reranking tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate. (arXiv:2108.05921v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Rose Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertram Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1">Paul R&#xf6;ttger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05921">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting online hate is a complex task, and low-performing detection models
have harmful consequences when used for sensitive applications such as content
moderation. Emoji-based hate is a key emerging challenge for online hate
detection. We present HatemojiCheck, a test suite of 3,930 short-form
statements that allows us to evaluate how detection models perform on hateful
language expressed with emoji. Using the test suite, we expose weaknesses in
existing hate detection models. To address these weaknesses, we create the
HatemojiTrain dataset using an innovative human-and-model-in-the-loop approach.
Models trained on these 5,912 adversarial examples perform substantially better
at detecting emoji-based hate, while retaining strong performance on text-only
hate. Both HatemojiCheck and HatemojiTrain are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Lifespan Face Synthesis. (arXiv:2108.02874v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Sen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wentong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Michael Ying Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02874">
                                    <div class="article-summary-box-inner">
                                        <span>A lifespan face synthesis (LFS) model aims to generate a set of
photo-realistic face images of a person&#x27;s whole life, given only one snapshot
as reference. The generated face image given a target age code is expected to
be age-sensitive reflected by bio-plausible transformations of shape and
texture, while being identity preserving. This is extremely challenging because
the shape and texture characteristics of a face undergo separate and highly
nonlinear transformations w.r.t. age. Most recent LFS models are based on
generative adversarial networks (GANs) whereby age code conditional
transformations are applied to a latent face representation. They benefit
greatly from the recent advancements of GANs. However, without explicitly
disentangling their latent representations into the texture, shape and identity
factors, they are fundamentally limited in modeling the nonlinear age-related
transformation on texture and shape whilst preserving identity. In this work, a
novel LFS model is proposed to disentangle the key face characteristics
including shape, texture and identity so that the unique shape and texture age
transformations can be modeled effectively. This is achieved by extracting
shape, texture and identity features separately from an encoder. Critically,
two transformation modules, one conditional convolution based and the other
channel attention based, are designed for modeling the nonlinear shape and
texture feature transformations respectively. This is to accommodate their
rather distinct aging processes and ensure that our synthesized images are both
age-sensitive and identity preserving. Extensive experiments show that our LFS
model is clearly superior to the state-of-the-art alternatives. Codes and demo
are available on our project website:
\url{https://senhe.github.io/projects/iccv_2021_lifespan_face}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unifying Nonlocal Blocks for Neural Networks. (arXiv:2108.02451v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yanye Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02451">
                                    <div class="article-summary-box-inner">
                                        <span>The nonlocal-based blocks are designed for capturing long-range
spatial-temporal dependencies in computer vision tasks. Although having shown
excellent performance, they still lack the mechanism to encode the rich,
structured information among elements in an image or video. In this paper, to
theoretically analyze the property of these nonlocal-based blocks, we provide a
new perspective to interpret them, where we view them as a set of graph filters
generated on a fully-connected graph. Specifically, when choosing the Chebyshev
graph filter, a unified formulation can be derived for explaining and analyzing
the existing nonlocal-based blocks (e.g., nonlocal block, nonlocal stage,
double attention block). Furthermore, by concerning the property of spectral,
we propose an efficient and robust spectral nonlocal block, which can be more
robust and flexible to catch long-range dependencies when inserted into deep
neural networks than the existing nonlocal blocks. Experimental results
demonstrate the clear-cut improvements and practical applicabilities of our
method on image classification, action recognition, semantic segmentation, and
person re-identification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPACE: A Simulator for Physical Interactions and Causal Learning in 3D Environments. (arXiv:2108.06180v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jiafei Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Samson Yu Bai Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheston Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06180">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep learning, computer vision, and embodied AI have
given rise to synthetic causal reasoning video datasets. These datasets
facilitate the development of AI algorithms that can reason about physical
interactions between objects. However, datasets thus far have primarily focused
on elementary physical events such as rolling or falling. There is currently a
scarcity of datasets that focus on the physical interactions that humans
perform daily with objects in the real world. To address this scarcity, we
introduce SPACE: A Simulator for Physical Interactions and Causal Learning in
3D Environments. The SPACE simulator allows us to generate the SPACE dataset, a
synthetic video dataset in a 3D environment, to systematically evaluate
physics-based models on a range of physical causal reasoning tasks. Inspired by
daily object interactions, the SPACE dataset comprises videos depicting three
types of physical events: containment, stability and contact. These events make
up the vast majority of the basic physical interactions between objects. We
then further evaluate it with a state-of-the-art physics-based deep model and
show that the SPACE dataset improves the learning of intuitive physics with an
approach inspired by curriculum learning. Repository:
https://github.com/jiafei1224/SPACE</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness testing of AI systems: A case study for traffic sign recognition. (arXiv:2108.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berghoff_C/0/1/0/all/0/1">Christian Berghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielik_P/0/1/0/all/0/1">Pavol Bielik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neu_M/0/1/0/all/0/1">Matthias Neu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsankov_P/0/1/0/all/0/1">Petar Tsankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Twickel_A/0/1/0/all/0/1">Arndt von Twickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06159">
                                    <div class="article-summary-box-inner">
                                        <span>In the last years, AI systems, in particular neural networks, have seen a
tremendous increase in performance, and they are now used in a broad range of
applications. Unlike classical symbolic AI systems, neural networks are trained
using large data sets and their inner structure containing possibly billions of
parameters does not lend itself to human interpretation. As a consequence, it
is so far not feasible to provide broad guarantees for the correct behaviour of
neural networks during operation if they process input data that significantly
differ from those seen during training. However, many applications of AI
systems are security- or safety-critical, and hence require obtaining
statements on the robustness of the systems when facing unexpected events,
whether they occur naturally or are induced by an attacker in a targeted way.
As a step towards developing robust AI systems for such applications, this
paper presents how the robustness of AI systems can be practically examined and
which methods and metrics can be used to do so. The robustness testing
methodology is described and analysed for the example use case of traffic sign
recognition in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TokenPose: Learning Keypoint Tokens for Human Pose Estimation. (arXiv:2104.03516v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shoukui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wankou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03516">
                                    <div class="article-summary-box-inner">
                                        <span>Human pose estimation deeply relies on visual clues and anatomical
constraints between parts to locate keypoints. Most existing CNN-based methods
do well in visual representation, however, lacking in the ability to explicitly
learn the constraint relationships between keypoints. In this paper, we propose
a novel approach based on Token representation for human Pose
estimation~(TokenPose). In detail, each keypoint is explicitly embedded as a
token to simultaneously learn constraint relationships and appearance cues from
images. Extensive experiments show that the small and large TokenPose models
are on par with state-of-the-art CNN-based counterparts while being more
lightweight. Specifically, our TokenPose-S and TokenPose-L achieve $72.5$ AP
and $75.8$ AP on COCO validation dataset respectively, with significant
reduction in parameters ($\downarrow80.6\%$; $\downarrow$ $56.8\%$) and GFLOPs
($\downarrow$ $75.3\%$; $\downarrow$ $24.7\%$). Code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Interpretable Classification and Weakly-Supervised Segmentation of Histology Images via Max-Min Uncertainty. (arXiv:2011.07221v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belharbi_S/0/1/0/all/0/1">Soufiane Belharbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rony_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Rony</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+McCaffrey_L/0/1/0/all/0/1">Luke McCaffrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07221">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised learning (WSL) has recently triggered substantial interest
as it mitigates the lack of pixel-wise annotations.

Given global image labels, WSL methods yield pixel-level predictions
(segmentations), which enable to interpret class predictions. Despite their
recent success, mostly with natural images, such methods can face important
challenges when the foreground and background regions have similar visual cues,
yielding high false-positive rates in segmentations, as is the case in
challenging histology images. WSL training is commonly driven by standard
classification losses, which implicitly maximize model confidence, and locate
the discriminative regions linked to classification decisions. Therefore, they
lack mechanisms for modeling explicitly non-discriminative regions and reducing
false-positive rates. We propose novel regularization terms, which enable the
model to seek both non-discriminative and discriminative regions, while
discouraging unbalanced segmentations. We introduce high uncertainty as a
criterion to localize non-discriminative regions that do not affect classifier
decision, and describe it with original Kullback-Leibler (KL) divergence losses
evaluating the deviation of posterior predictions from the uniform
distribution. Our KL terms encourage high uncertainty of the model when the
latter inputs the latent non-discriminative regions. Our loss integrates: (i) a
cross-entropy seeking a foreground, where model confidence about class
prediction is high; (ii) a KL regularizer seeking a background, where model
uncertainty is high; and (iii) log-barrier terms discouraging unbalanced
segmentations. Comprehensive experiments and ablation studies over the public
GlaS colon cancer data and a Camelyon16 patch-based benchmark for breast cancer
show substantial improvements over state-of-the-art WSL methods, and confirm
the effect of our new regularizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VTGAN: Semi-supervised Retinal Image Synthesis and Disease Prediction using Vision Transformers. (arXiv:2104.06757v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamran_S/0/1/0/all/0/1">Sharif Amit Kamran</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_K/0/1/0/all/0/1">Khondker Fariha Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Tavakkoli_A/0/1/0/all/0/1">Alireza Tavakkoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerbrod_S/0/1/0/all/0/1">Stewart Lee Zuckerbrod</a>, <a href="http://arxiv.org/find/eess/1/au:+Baker_S/0/1/0/all/0/1">Salah A. Baker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06757">
                                    <div class="article-summary-box-inner">
                                        <span>In Fluorescein Angiography (FA), an exogenous dye is injected in the
bloodstream to image the vascular structure of the retina. The injected dye can
cause adverse reactions such as nausea, vomiting, anaphylactic shock, and even
death. In contrast, color fundus imaging is a non-invasive technique used for
photographing the retina but does not have sufficient fidelity for capturing
its vascular structure. The only non-invasive method for capturing retinal
vasculature is optical coherence tomography-angiography (OCTA). However, OCTA
equipment is quite expensive, and stable imaging is limited to small areas on
the retina. In this paper, we propose a novel conditional generative
adversarial network (GAN) capable of simultaneously synthesizing FA images from
fundus photographs while predicting retinal degeneration. The proposed system
has the benefit of addressing the problem of imaging retinal vasculature in a
non-invasive manner as well as predicting the existence of retinal
abnormalities. We use a semi-supervised approach to train our GAN using
multiple weighted losses on different modalities of data. Our experiments
validate that the proposed architecture exceeds recent state-of-the-art
generative networks for fundus-to-angiography synthesis. Moreover, our vision
transformer-based discriminators generalize quite well on out-of-distribution
data sets for retinal disease prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Path Learning for Domain Adaptation of Semantic Segmentation. (arXiv:2108.06337v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yiting Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_F/0/1/0/all/0/1">Fang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenqiang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06337">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation for semantic segmentation enables to alleviate the need for
large-scale pixel-wise annotations. Recently, self-supervised learning (SSL)
with a combination of image-to-image translation shows great effectiveness in
adaptive segmentation. The most common practice is to perform SSL along with
image translation to well align a single domain (the source or target).
However, in this single-domain paradigm, unavoidable visual inconsistency
raised by image translation may affect subsequent learning. In this paper,
based on the observation that domain adaptation frameworks performed in the
source and target domain are almost complementary in terms of image translation
and SSL, we propose a novel dual path learning (DPL) framework to alleviate
visual inconsistency. Concretely, DPL contains two complementary and
interactive single-domain adaptation pipelines aligned in source and target
domain respectively. The inference of DPL is extremely simple, only one
segmentation model in the target domain is employed. Novel technologies such as
dual path image translation and dual path adaptive segmentation are proposed to
make two paths promote each other in an interactive manner. Experiments on
GTA5$\rightarrow$Cityscapes and SYNTHIA$\rightarrow$Cityscapes scenarios
demonstrate the superiority of our DPL model over the state-of-the-art methods.
The code and models are available at: \url{https://github.com/royee182/DPL}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech. (arXiv:2106.14736v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonell_P/0/1/0/all/0/1">Patrik Jonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14736">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework for gesture generation, aiming to allow
data-driven approaches to produce more semantically rich gestures. Our approach
first predicts whether to gesture, followed by a prediction of the gesture
properties. Those properties are then used as conditioning for a modern
probabilistic gesture-generation model capable of high-quality output. This
empowers the approach to generate gestures that are both diverse and
representational. Follow-ups and more information can be found on the project
page: https://svito-zar.github.io/speech2properties2gestures/ .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models. (arXiv:2106.00245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00245">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from large-scale pre-training, we have witnessed significant
performance boost on the popular Visual Question Answering (VQA) task. Despite
rapid progress, it remains unclear whether these state-of-the-art (SOTA) models
are robust when encountering examples in the wild. To study this, we introduce
Adversarial VQA, a new large-scale VQA benchmark, collected iteratively via an
adversarial human-and-model-in-the-loop procedure. Through this new benchmark,
we discover several interesting findings. (i) Surprisingly, we find that during
dataset collection, non-expert annotators can easily attack SOTA VQA models
successfully. (ii) Both large-scale pre-trained models and adversarial training
methods achieve far worse performance on the new benchmark than over standard
VQA v2 dataset, revealing the fragility of these models while demonstrating the
effectiveness of our adversarial dataset. (iii) When used for data
augmentation, our dataset can effectively boost model performance on other
robust VQA benchmarks. We hope our Adversarial VQA dataset can shed new light
on robustness study in the community and serve as a valuable benchmark for
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuLF: Efficient Novel View Synthesis with Neural 4D Light Field. (arXiv:2105.07112v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Celong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Junsong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07112">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an efficient and robust deep learning solution for
novel view synthesis of complex scenes. In our approach, a 3D scene is
represented as a light field, i.e., a set of rays, each of which has a
corresponding color when reaching the image plane. For efficient novel view
rendering, we adopt a 4D parameterization of the light field, where each ray is
characterized by a 4D parameter. We then formulate the light field as a 4D
function that maps 4D coordinates to corresponding color values. We train a
deep fully connected network to optimize this implicit function and memorize
the 3D scene. Then, the scene-specific model is used to synthesize novel views.
Different from previous light field approaches which require dense view
sampling to reliably render novel views, our method can render novel views by
sampling rays and querying the color for each ray from the network directly,
thus enabling high-quality light field rendering with a sparser set of training
images. Our method achieves state-of-the-art novel view synthesis results while
maintaining an interactive frame rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild. (arXiv:2107.03465v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antoniadis_P/0/1/0/all/0/1">Panagiotis Antoniadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pikoulis_I/0/1/0/all/0/1">Ioannis Pikoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Filntisis_P/0/1/0/all/0/1">Panagiotis P. Filntisis</a>, <a href="http://arxiv.org/find/cs/1/au:+Maragos_P/0/1/0/all/0/1">Petros Maragos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03465">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we tackle the task of video-based audio-visual emotion
recognition, within the premises of the 2nd Workshop and Competition on
Affective Behavior Analysis in-the-wild (ABAW2). Poor illumination conditions,
head/body orientation and low image resolution constitute factors that can
potentially hinder performance in case of methodologies that solely rely on the
extraction and analysis of facial features. In order to alleviate this problem,
we leverage both bodily and contextual features, as part of a broader emotion
recognition framework. We choose to use a standard CNN-RNN cascade as the
backbone of our proposed model for sequence-to-sequence (seq2seq) learning.
Apart from learning through the RGB input modality, we construct an aural
stream which operates on sequences of extracted mel-spectrograms. Our extensive
experiments on the challenging and newly assembled Aff-Wild2 dataset verify the
validity of our intuitive multi-stream and multi-modal approach towards emotion
recognition in-the-wild. Emphasis is being laid on the the beneficial influence
of the human body and scene context, as aspects of the emotion recognition
process that have been left relatively unexplored up to this point. All the
code was implemented using PyTorch and is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FCOS3D: Fully Convolutional One-Stage Monocular 3D Object Detection. (arXiv:2104.10956v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinge Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10956">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular 3D object detection is an important task for autonomous driving
considering its advantage of low cost. It is much more challenging than
conventional 2D cases due to its inherent ill-posed property, which is mainly
reflected in the lack of depth information. Recent progress on 2D detection
offers opportunities to better solving this problem. However, it is non-trivial
to make a general adapted 2D detector work in this 3D task. In this paper, we
study this problem with a practice built on a fully convolutional single-stage
detector and propose a general framework FCOS3D. Specifically, we first
transform the commonly defined 7-DoF 3D targets to the image domain and
decouple them as 2D and 3D attributes. Then the objects are distributed to
different feature levels with consideration of their 2D scales and assigned
only according to the projected 3D-center for the training procedure.
Furthermore, the center-ness is redefined with a 2D Gaussian distribution based
on the 3D-center to fit the 3D target formulation. All of these make this
framework simple yet effective, getting rid of any 2D detection or 2D-3D
correspondence priors. Our solution achieves 1st place out of all the
vision-only methods in the nuScenes 3D detection challenge of NeurIPS 2020.
Code and models are released at https://github.com/open-mmlab/mmdetection3d.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectroscopic Approach to Correction and Visualisation of Bright-Field Light Transmission Microscopy Biological Data. (arXiv:1903.06519v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Platonova_G/0/1/0/all/0/1">Ganna Platonova</a>, <a href="http://arxiv.org/find/eess/1/au:+Stys_D/0/1/0/all/0/1">Dalibor Stys</a>, <a href="http://arxiv.org/find/eess/1/au:+Soucek_P/0/1/0/all/0/1">Pavel Soucek</a>, <a href="http://arxiv.org/find/eess/1/au:+Lonhus_K/0/1/0/all/0/1">Kirill Lonhus</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenta_J/0/1/0/all/0/1">Jan Valenta</a>, <a href="http://arxiv.org/find/eess/1/au:+Rychtarikova_R/0/1/0/all/0/1">Renata Rychtarikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.06519">
                                    <div class="article-summary-box-inner">
                                        <span>The most realistic information about the transparent sample such as a live
cell can be obtained only using bright-field light microscopy. At
high-intensity pulsing LED illumination, we captured a primary
12-bit-per-channel (bpc) response from an observed sample using a bright-field
microscope equipped with a high-resolution (4872x3248) image sensor. In order
to suppress data distortions originating from the light interactions with
elements in the optical path, poor sensor reproduction (geometrical defects of
the camera sensor and some peculiarities of sensor sensitivity), we propose a
spectroscopic approach for the correction of this uncompressed 12-bpc data by
simultaneous calibration of all parts of the experimental arrangement.
Moreover, the final intensities of the corrected images are proportional to the
photon fluxes detected by a camera sensor. It can be visualized in 8-bpc
intensity depth after the Least Information Loss compression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D point cloud segmentation using GIS. (arXiv:2108.06306v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao-Jung Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Krylov_V/0/1/0/all/0/1">Vladimir Krylov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahyot_R/0/1/0/all/0/1">Rozenn Dahyot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06306">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we propose an approach to perform semantic segmentation of 3D
point cloud data by importing the geographic information from a 2D GIS layer
(OpenStreetMap). The proposed automatic procedure identifies meaningful units
such as buildings and adjusts their locations to achieve best fit between the
GIS polygonal perimeters and the point cloud. Our processing pipeline is
presented and illustrated by segmenting point cloud data of Trinity College
Dublin (Ireland) campus constructed from optical imagery collected by a drone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEEA-Net: An Early Exit Evolutionary Neural Architecture Search. (arXiv:2108.06156v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Termritthikun_C/0/1/0/all/0/1">Chakkrit Termritthikun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamtsho_Y/0/1/0/all/0/1">Yeshi Jamtsho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ieamsaard_J/0/1/0/all/0/1">Jirarat Ieamsaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Muneesawang_P/0/1/0/all/0/1">Paisarn Muneesawang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Ivan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06156">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this research were to search for Convolutional Neural Network
(CNN) architectures, suitable for an on-device processor with limited computing
resources, performing at substantially lower Network Architecture Search (NAS)
costs. A new algorithm entitled an Early Exit Population Initialisation (EE-PI)
for Evolutionary Algorithm (EA) was developed to achieve both goals. The EE-PI
reduces the total number of parameters in the search process by filtering the
models with fewer parameters than the maximum threshold. It will look for a new
model to replace those models with parameters more than the threshold. Thereby,
reducing the number of parameters, memory usage for model storage and
processing time while maintaining the same performance or accuracy. The search
time was reduced to 0.52 GPU day. This is a huge and significant achievement
compared to the NAS of 4 GPU days achieved using NSGA-Net, 3,150 GPU days by
the AmoebaNet model, and the 2,000 GPU days by the NASNet model. As well, Early
Exit Evolutionary Algorithm networks (EEEA-Nets) yield network architectures
with minimal error and computational cost suitable for a given dataset as a
class of network algorithms. Using EEEA-Net on CIFAR-10, CIFAR-100, and
ImageNet datasets, our experiments showed that EEEA-Net achieved the lowest
error rate among state-of-the-art NAS models, with 2.46% for CIFAR-10, 15.02%
for CIFAR-100, and 23.8% for ImageNet dataset. Further, we implemented this
image recognition architecture for other tasks, such as object detection,
semantic segmentation, and keypoint detection tasks, and, in our experiments,
EEEA-Net-C2 outperformed MobileNet-V3 on all of these various tasks. (The
algorithm code is available at https://github.com/chakkritte/EEEA-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets, often with better accuracy and fewer
parameters. Our model eliminates the requirement for class token and positional
embeddings through a novel sequence pooling strategy and the use of
convolution/s. It is flexible in terms of model size, and can have as little as
0.28M parameters while achieving good results. Our model can reach 98.00%
accuracy when training from scratch on CIFAR-10, which is a significant
improvement over previous Transformer based models. It also outperforms many
modern CNN based approaches, such as ResNet, and even some recent NAS-based
approaches, such as Proxyless-NAS. Our simple and compact design democratizes
transformers by making them accessible to those with limited computing
resources and/or dealing with small datasets. Our method also works on larger
datasets, such as ImageNet (82.71% accuracy with 29% parameters of ViT), and
NLP tasks as well. Our code and pre-trained models are publicly available at
https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior Analysis. (arXiv:2107.04225v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shisen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_K/0/1/0/all/0/1">Kenji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04225">
                                    <div class="article-summary-box-inner">
                                        <span>Affective Behavior Analysis is an important part in human-computer
interaction. Existing multi-task affective behavior recognition methods suffer
from the problem of incomplete labeled datasets. To tackle this problem, this
paper presents a semi-supervised model with a mean teacher framework to
leverage additional unlabeled data. To be specific, a multi-task model is
proposed to learn three different kinds of facial affective representations
simultaneously. After that, the proposed model is assigned to be student and
teacher networks. When training with unlabeled data, the teacher network is
employed to predict pseudo labels for student network training, which allows it
to learn from unlabeled data. Experimental results showed that our proposed
method achieved much better performance than baseline model and ranked 4th in
both competition track 1 and track 2, and 6th in track 3, which verifies that
the proposed network can effectively learn from incomplete datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Zero-Shot Learning for Semantic Segmentation of 3D Point Cloud. (arXiv:2108.06230v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Michele_B/0/1/0/all/0/1">Bj&#xf6;rn Michele</a>, <a href="http://arxiv.org/find/cs/1/au:+Boulch_A/0/1/0/all/0/1">Alexandre Boulch</a>, <a href="http://arxiv.org/find/cs/1/au:+Puy_G/0/1/0/all/0/1">Gilles Puy</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlet_R/0/1/0/all/0/1">Renaud Marlet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06230">
                                    <div class="article-summary-box-inner">
                                        <span>While there has been a number of studies on Zero-Shot Learning (ZSL) for 2D
images, its application to 3D data is still recent and scarce, with just a few
methods limited to classification. We present the first generative approach for
both ZSL and Generalized ZSL (GZSL) on 3D data, that can handle both
classification and, for the first time, semantic segmentation. We show that it
reaches or outperforms the state of the art on ModelNet40 classification for
both inductive ZSL and inductive GZSL. For semantic segmentation, we created
three benchmarks for evaluating this new ZSL task, using S3DIS, ScanNet and
SemanticKITTI. Our experiments show that our method outperforms strong
baselines, which we additionally propose for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LSG-CPD: Coherent Point Drift with Local Surface Geometry for Point Cloud Registration. (arXiv:2103.15039v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weixiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongtao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chirikjian_G/0/1/0/all/0/1">Gregory Chirikjian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15039">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic point cloud registration methods are becoming more popular
because of their robustness. However, unlike point-to-plane variants of
iterative closest point (ICP) which incorporate local surface geometric
information such as surface normals, most probabilistic methods (e.g., coherent
point drift (CPD)) ignore such information and build Gaussian mixture models
(GMMs) with isotropic Gaussian covariances. This results in sphere-like GMM
components which only penalize the point-to-point distance between the two
point clouds. In this paper, we propose a novel method called CPD with Local
Surface Geometry (LSG-CPD) for rigid point cloud registration. Our method
adaptively adds different levels of point-to-plane penalization on top of the
point-to-point penalization based on the flatness of the local surface. This
results in GMM components with anisotropic covariances. We formulate point
cloud registration as a maximum likelihood estimation (MLE) problem and solve
it with the Expectation-Maximization (EM) algorithm. In the E step, we
demonstrate that the computation can be recast into simple matrix manipulations
and efficiently computed on a GPU. In the M step, we perform an unconstrained
optimization on a matrix Lie group to efficiently update the rigid
transformation of the registration. The proposed method outperforms
state-of-the-art algorithms in terms of accuracy and robustness on various
datasets captured with range scanners, RGBD cameras, and LiDARs. Also, it is
significantly faster than modern implementations of CPD. The source code is
available at https://github.com/ChirikjianLab/LSG-CPD.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Transferable Parameters for Unsupervised Domain Adaptation. (arXiv:2108.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhongyi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haoliang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) enables a learning machine to adapt from
a labeled source domain to an unlabeled domain under the distribution shift.
Thanks to the strong representation ability of deep neural networks, recent
remarkable achievements in UDA resort to learning domain-invariant features.
Intuitively, the hope is that a good feature representation, together with the
hypothesis learned from the source domain, can generalize well to the target
domain. However, the learning processes of domain-invariant features and source
hypothesis inevitably involve domain-specific information that would degrade
the generalizability of UDA models on the target domain. In this paper,
motivated by the lottery ticket hypothesis that only partial parameters are
essential for generalization, we find that only partial parameters are
essential for learning domain-invariant information and generalizing well in
UDA. Such parameters are termed transferable parameters. In contrast, the other
parameters tend to fit domain-specific details and often fail to generalize,
which we term as untransferable parameters. Driven by this insight, we propose
Transferable Parameter Learning (TransPar) to reduce the side effect brought by
domain-specific information in the learning process and thus enhance the
memorization of domain-invariant information. Specifically, according to the
distribution discrepancy degree, we divide all parameters into transferable and
untransferable ones in each training iteration. We then perform separate
updates rules for the two types of parameters. Extensive experiments on image
classification and regression tasks (keypoint detection) show that TransPar
outperforms prior arts by non-trivial margins. Moreover, experiments
demonstrate that TransPar can be integrated into the most popular deep UDA
networks and be easily extended to handle any data distribution shift
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Surface Function Networks for Clothed Human Bodies. (arXiv:2104.03978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burov_A/0/1/0/all/0/1">Andrei Burov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03978">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for temporal coherent reconstruction and tracking
of clothed humans. Given a monocular RGB-D sequence, we learn a person-specific
body model which is based on a dynamic surface function network. To this end,
we explicitly model the surface of the person using a multi-layer perceptron
(MLP) which is embedded into the canonical space of the SMPL body model. With
classical forward rendering, the represented surface can be rasterized using
the topology of a template mesh. For each surface point of the template mesh,
the MLP is evaluated to predict the actual surface location. To handle
pose-dependent deformations, the MLP is conditioned on the SMPL pose
parameters. We show that this surface representation as well as the pose
parameters can be learned in a self-supervised fashion using the principle of
analysis-by-synthesis and differentiable rasterization. As a result, we are
able to reconstruct a temporally coherent mesh sequence from the input data.
The underlying surface representation can be used to synthesize new animations
of the reconstructed person including pose-dependent deformations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards artificially intelligent recycling Improving image processing for waste classification. (arXiv:2108.06274v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youpeng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Grammenos_R/0/1/0/all/0/1">Ryan Grammenos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06274">
                                    <div class="article-summary-box-inner">
                                        <span>The ever-increasing amount of global refuse is overwhelming the waste and
recycling management industries. The need for smart systems for environmental
monitoring and the enhancement of recycling processes is thus greater than
ever. Amongst these efforts lies IBM&#x27;s Wastenet project which aims to improve
recycling by using artificial intelligence for waste classification. The work
reported in this paper builds on this project through the use of transfer
learning and data augmentation techniques to ameliorate classification
accuracy. Starting with a convolutional neural network (CNN), a systematic
approach is followed for selecting appropriate splitting ratios and for tuning
multiple training parameters including learning rate schedulers, layers
freezing, batch sizes and loss functions, in the context of the given scenario
which requires classification of waste into different recycling types. Results
are compared and contrasted using 10-fold cross validation and demonstrate that
the model developed achieves a 91.21% test accuracy. Subsequently, a range of
data augmentation techniques are then incorporated into this work including
flipping, rotation, shearing, zooming, and brightness control. Results show
that these augmentation techniques further improve the test accuracy of the
final model to 95.40%. Unlike other work reported in the field, this paper
provides full details regarding the training of the model. Furthermore, the
code for this work has been made open-source and we have demonstrated that the
model can perform successful real-time classification of recycling waste items
using a standard computer webcam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v10 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dai Quoc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer self-attention network has been extensively used in research
domains such as computer vision, image processing, and natural language
processing. The transformer, however, has not been actively used in graph
neural networks, where constructing an advanced aggregation function is
essential. To this end, we present an effective model, named UGformer, which --
by leveraging a transformer self-attention mechanism followed by a recurrent
transition -- induces an advanced aggregation function to learn graph
representations. Experimental results show that UGformer achieves
state-of-the-art accuracies on well-known benchmark datasets for graph
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Full-resolution quality assessment for pansharpening. (arXiv:2108.06144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scarpa_G/0/1/0/all/0/1">Giuseppe Scarpa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciotola_M/0/1/0/all/0/1">Matteo Ciotola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06144">
                                    <div class="article-summary-box-inner">
                                        <span>A reliable quality assessment procedure for pansharpening methods is of
critical importance for the development of the related solutions.
Unfortunately, the lack of ground-truths to be used as guidance for an
objective evaluation has pushed the community to resort to either
reference-based reduced-resolution indexes or to no-reference subjective
quality indexes that can be applied on full-resolution datasets. In particular,
the reference-based approach leverages on Wald&#x27;s protocol, a resolution
degradation process that allows one to synthesize data with related ground
truth. Both solutions, however, present critical shortcomings that we aim to
mitigate in this work by means of an alternative no-reference full-resolution
framework. On one side we introduce a protocol, namely the reprojection
protocol, which allows to handle the spectral fidelity problem. On the other
side, a new index of the spatial consistency between the pansharpened image and
the panchromatic band at full resolution is proposed. The experimental results
show the effectiveness of the proposed approach which is confirmed also by
visual inspection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry Uncertainty Projection Network for Monocular 3D Object Detection. (arXiv:2107.13774v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xinzhu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianzhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yating Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1">Qi Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13774">
                                    <div class="article-summary-box-inner">
                                        <span>Geometry Projection is a powerful depth estimation method in monocular 3D
object detection. It estimates depth dependent on heights, which introduces
mathematical priors into the deep model. But projection process also introduces
the error amplification problem, in which the error of the estimated height
will be amplified and reflected greatly at the output depth. This property
leads to uncontrollable depth inferences and also damages the training
efficiency. In this paper, we propose a Geometry Uncertainty Projection Network
(GUP Net) to tackle the error amplification problem at both inference and
training stages. Specifically, a GUP module is proposed to obtains the
geometry-guided uncertainty of the inferred depth, which not only provides high
reliable confidence for each depth but also benefits depth learning.
Furthermore, at the training stage, we propose a Hierarchical Task Learning
strategy to reduce the instability caused by error amplification. This learning
algorithm monitors the learning situation of each task by a proposed indicator
and adaptively assigns the proper loss weights for different tasks according to
their pre-tasks situation. Based on that, each task starts learning only when
its pre-tasks are learned well, which can significantly improve the stability
and efficiency of the training process. Extensive experiments demonstrate the
effectiveness of the proposed method. The overall model can infer more reliable
object depth than existing methods and outperforms the state-of-the-art
image-based monocular 3D detectors by 3.74% and 4.7% AP40 of the car and
pedestrian categories on the KITTI benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Inversion: A Survey. (arXiv:2101.05278v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Weihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yulun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yujiu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jing-Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05278">
                                    <div class="article-summary-box-inner">
                                        <span>GAN inversion aims to invert a given image back into the latent space of a
pretrained GAN model, for the image to be faithfully reconstructed from the
inverted code by the generator. As an emerging technique to bridge the real and
fake image domains, GAN inversion plays an essential role in enabling the
pretrained GAN models such as StyleGAN and BigGAN to be used for real image
editing applications. Meanwhile, GAN inversion also provides insights on the
interpretation of GAN&#x27;s latent space and how the realistic images can be
generated. In this paper, we provide an overview of GAN inversion with a focus
on its recent algorithms and applications. We cover important techniques of GAN
inversion and their applications to image restoration and image manipulation.
We further elaborate on some trends and challenges for future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IFR: Iterative Fusion Based Recognizer For Low Quality Scene Text Recognition. (arXiv:2108.06166v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shugong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_S/0/1/0/all/0/1">Shiyi Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yue Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06166">
                                    <div class="article-summary-box-inner">
                                        <span>Although recent works based on deep learning have made progress in improving
recognition accuracy on scene text recognition, how to handle low-quality text
images in end-to-end deep networks remains a research challenge. In this paper,
we propose an Iterative Fusion based Recognizer (IFR) for low quality scene
text recognition, taking advantage of refined text images input and robust
feature representation. IFR contains two branches which focus on scene text
recognition and low quality scene text image recovery respectively. We utilize
an iterative collaboration between two branches, which can effectively
alleviate the impact of low quality input. A feature fusion module is proposed
to strengthen the feature representation of the two branches, where the
features from the Recognizer are Fused with image Restoration branch, referred
to as RRF. Without changing the recognition network structure, extensive
quantitative and qualitative experimental results show that the proposed method
significantly outperforms the baseline methods in boosting the recognition
accuracy of benchmark datasets and low resolution images in TextZoom dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Interpretable Algorithm for Uveal Melanoma Subtyping from Whole Slide Cytology Images. (arXiv:2108.06246v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haomin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">T.Y. Alvin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_C/0/1/0/all/0/1">Catalina Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Correa_Z/0/1/0/all/0/1">Zelia Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06246">
                                    <div class="article-summary-box-inner">
                                        <span>Algorithmic decision support is rapidly becoming a staple of personalized
medicine, especially for high-stakes recommendations in which access to certain
information can drastically alter the course of treatment, and thus, patient
outcome; a prominent example is radiomics for cancer subtyping. Because in
these scenarios the stakes are high, it is desirable for decision systems to
not only provide recommendations but supply transparent reasoning in support
thereof. For learning-based systems, this can be achieved through an
interpretable design of the inference pipeline. Herein we describe an automated
yet interpretable system for uveal melanoma subtyping with digital cytology
images from fine needle aspiration biopsies. Our method embeds every
automatically segmented cell of a candidate cytology image as a point in a 2D
manifold defined by many representative slides, which enables reasoning about
the cell-level composition of the tissue sample, paving the way for
interpretable subtyping of the biopsy. Finally, a rule-based slide-level
classification algorithm is trained on the partitions of the circularly
distorted 2D manifold. This process results in a simple rule set that is
evaluated automatically but highly transparent for human verification. On our
in house cytology dataset of 88 uveal melanoma patients, the proposed method
achieves an accuracy of 87.5% that compares favorably to all competing
approaches, including deep &quot;black box&quot; models. The method comes with a user
interface to facilitate interaction with cell-level content, which may offer
additional insights for pathological assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional DETR for Fast Training Convergence. (arXiv:2108.06152v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Depu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaokang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zejia Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1">Gang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuhui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06152">
                                    <div class="article-summary-box-inner">
                                        <span>The recently-developed DETR approach applies the transformer encoder and
decoder architecture to object detection and achieves promising performance. In
this paper, we handle the critical issue, slow training convergence, and
present a conditional cross-attention mechanism for fast DETR training. Our
approach is motivated by that the cross-attention in DETR relies highly on the
content embeddings for localizing the four extremities and predicting the box,
which increases the need for high-quality content embeddings and thus the
training difficulty. Our approach, named conditional DETR, learns a conditional
spatial query from the decoder embedding for decoder multi-head
cross-attention. The benefit is that through the conditional spatial query,
each cross-attention head is able to attend to a band containing a distinct
region, e.g., one object extremity or a region inside the object box. This
narrows down the spatial range for localizing the distinct regions for object
classification and box regression, thus relaxing the dependence on the content
embeddings and easing the training. Empirical results show that conditional
DETR converges 6.7x faster for the backbones R50 and R101 and 10x faster for
stronger backbones DC5-R50 and DC5-R101. Code is available at
https://git.io/ConditionalDETR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimCVD: Simple Contrastive Voxel-Wise Representation Distillation for Semi-Supervised Medical Image Segmentation. (arXiv:2108.06227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruihan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1">Lawrence Staib</a>, <a href="http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1">James S. Duncan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06227">
                                    <div class="article-summary-box-inner">
                                        <span>Automated segmentation in medical image analysis is a challenging task that
requires a large amount of manually labeled data. However, most existing
learning-based approaches usually suffer from limited manually annotated
medical data, which poses a major practical problem for accurate and robust
medical image segmentation. In addition, most existing semi-supervised
approaches are usually not robust compared with the supervised counterparts,
and also lack explicit modeling of geometric structure and semantic
information, both of which limit the segmentation accuracy. In this work, we
present SimCVD, a simple contrastive distillation framework that significantly
advances state-of-the-art voxel-wise representation learning. We first describe
an unsupervised training strategy, which takes two views of an input volume and
predicts their signed distance maps of object boundaries in a contrastive
objective, with only two independent dropout as mask. This simple approach
works surprisingly well, performing on the same level as previous fully
supervised methods with much less labeled data. We hypothesize that dropout can
be viewed as a minimal form of data augmentation and makes the network robust
to representation collapse. Then, we propose to perform structural distillation
by distilling pair-wise similarities. We evaluate SimCVD on two popular
datasets: the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT
dataset. The results on the LA dataset demonstrate that, in two types of
labeled ratios (i.e., 20% and 10%), SimCVD achieves an average Dice score of
90.85% and 89.03% respectively, a 0.91% and 2.22% improvement compared to
previous best results. Our method can be trained in an end-to-end fashion,
showing the promise of utilizing SimCVD as a general framework for downstream
tasks, such as medical image synthesis and registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient Point Cloud Graph Neural Networks Through Architectural Simplification. (arXiv:2108.06317v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1">Shyam A. Tailor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_R/0/1/0/all/0/1">Ren&#xe9; de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Azevedo_T/0/1/0/all/0/1">Tiago Azevedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1">Matthew Mattina</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1">Partha Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06317">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years graph neural network (GNN)-based approaches have become a
popular strategy for processing point cloud data, regularly achieving
state-of-the-art performance on a variety of tasks. To date, the research
community has primarily focused on improving model expressiveness, with
secondary thought given to how to design models that can run efficiently on
resource constrained mobile devices including smartphones or mixed reality
headsets. In this work we make a step towards improving the efficiency of these
models by making the observation that these GNN models are heavily limited by
the representational power of their first, feature extracting, layer. We find
that it is possible to radically simplify these models so long as the feature
extraction layer is retained with minimal degradation to model performance;
further, we discover that it is possible to improve performance overall on
ModelNet40 and S3DIS by improving the design of the feature extractor. Our
approach reduces memory consumption by 20$\times$ and latency by up to
9.9$\times$ for graph layers in models such as DGCNN; overall, we achieve
speed-ups of up to 4.5$\times$ and peak memory reductions of 72.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based transformation of the H&amp;E stain into special stains. (arXiv:2008.08871v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Haan_K/0/1/0/all/0/1">Kevin de Haan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yijie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerman_J/0/1/0/all/0/1">Jonathan E. Zuckerman</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tairan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sisk_A/0/1/0/all/0/1">Anthony E. Sisk</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_M/0/1/0/all/0/1">Miguel F. P. Diaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Jen_K/0/1/0/all/0/1">Kuang-Yu Jen</a>, <a href="http://arxiv.org/find/eess/1/au:+Nobori_A/0/1/0/all/0/1">Alexander Nobori</a>, <a href="http://arxiv.org/find/eess/1/au:+Liou_S/0/1/0/all/0/1">Sofia Liou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Sarah Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Riahi_R/0/1/0/all/0/1">Rana Riahi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rivenson_Y/0/1/0/all/0/1">Yair Rivenson</a>, <a href="http://arxiv.org/find/eess/1/au:+Wallace_W/0/1/0/all/0/1">W. Dean Wallace</a>, <a href="http://arxiv.org/find/eess/1/au:+Ozcan_A/0/1/0/all/0/1">Aydogan Ozcan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08871">
                                    <div class="article-summary-box-inner">
                                        <span>Pathology is practiced by visual inspection of histochemically stained
slides. Most commonly, the hematoxylin and eosin (H&amp;E) stain is used in the
diagnostic workflow and it is the gold standard for cancer diagnosis. However,
in many cases, especially for non-neoplastic diseases, additional &quot;special
stains&quot; are used to provide different levels of contrast and color to tissue
components and allow pathologists to get a clearer diagnostic picture. In this
study, we demonstrate the utility of supervised learning-based computational
stain transformation from H&amp;E to different special stains (Masson&#x27;s Trichrome,
periodic acid-Schiff and Jones silver stain) using tissue sections from kidney
needle core biopsies. Based on evaluation by three renal pathologists, followed
by adjudication by a fourth renal pathologist, we show that the generation of
virtual special stains from existing H&amp;E images improves the diagnosis in
several non-neoplastic kidney diseases sampled from 58 unique subjects. A
second study performed by three pathologists found that the quality of the
special stains generated by the stain transformation network was statistically
equivalent to those generated through standard histochemical staining. As the
transformation of H&amp;E images into special stains can be achieved within 1 min
or less per patient core specimen slide, this stain-to-stain transformation
framework can improve the quality of the preliminary diagnosis when additional
special stains are needed, along with significant savings in time and cost,
reducing the burden on healthcare system and patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Robustness of Semantic Segmentation for Autonomous Driving against Real-World Adversarial Patch Attacks. (arXiv:2108.06179v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nesti_F/0/1/0/all/0/1">Federico Nesti</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossolini_G/0/1/0/all/0/1">Giulio Rossolini</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Saasha Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Biondi_A/0/1/0/all/0/1">Alessandro Biondi</a>, <a href="http://arxiv.org/find/cs/1/au:+Buttazzo_G/0/1/0/all/0/1">Giorgio Buttazzo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06179">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning and convolutional neural networks allow achieving impressive
performance in computer vision tasks, such as object detection and semantic
segmentation (SS). However, recent studies have shown evident weaknesses of
such models against adversarial perturbations. In a real-world scenario
instead, like autonomous driving, more attention should be devoted to
real-world adversarial examples (RWAEs), which are physical objects (e.g.,
billboards and printable patches) optimized to be adversarial to the entire
perception pipeline. This paper presents an in-depth evaluation of the
robustness of popular SS models by testing the effects of both digital and
real-world adversarial patches. These patches are crafted with powerful attacks
enriched with a novel loss function. Firstly, an investigation on the
Cityscapes dataset is conducted by extending the Expectation Over
Transformation (EOT) paradigm to cope with SS. Then, a novel attack
optimization, called scene-specific attack, is proposed. Such an attack
leverages the CARLA driving simulator to improve the transferability of the
proposed EOT-based attack to a real 3D environment. Finally, a printed physical
billboard containing an adversarial patch was tested in an outdoor driving
scenario to assess the feasibility of the studied attacks in the real world.
Exhaustive experiments revealed that the proposed attack formulations
outperform previous work to craft both digital and real-world adversarial
patches for SS. At the same time, the experimental results showed how these
attacks are notably less effective in the real world, hence questioning the
practical relevance of adversarial attacks to SS models for autonomous/assisted
driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DDNet: Dual-path Decoder Network for Occlusion Relationship Reasoning. (arXiv:1911.11582v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1">Lizhu Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11582">
                                    <div class="article-summary-box-inner">
                                        <span>Occlusion relationship reasoning based on convolution neural networks
consists of two subtasks: occlusion boundary extraction and occlusion
orientation inference. Due to the essential differences between the two
subtasks in the feature expression at the higher and lower stages, it is
challenging to carry on them simultaneously in one network. To address this
issue, we propose a novel Dual-path Decoder Network, which uniformly extracts
occlusion information at higher stages and separates into two paths to recover
boundary and occlusion orientation respectively in lower stages. Besides,
considering the restriction of occlusion orientation presentation to occlusion
orientation learning, we design a new orthogonal representation for occlusion
orientation and proposed the Orthogonal Orientation Regression loss which can
get rid of the unfitness between occlusion representation and learning and
further prompt the occlusion orientation learning. Finally, we apply a
multi-scale loss together with our proposed orientation regression loss to
guide the boundary and orientation path learning respectively. Experiments
demonstrate that our proposed method achieves state-of-the-art results on PIOD
and BSDS ownership datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Language Navigation with Random Environmental Mixup. (arXiv:2106.07876v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fengda Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiaojun Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yi-Dong Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07876">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-language Navigation (VLN) tasks require an agent to navigate
step-by-step while perceiving the visual observations and comprehending a
natural language instruction. Large data bias, which is caused by the disparity
ratio between the small data scale and large navigation space, makes the VLN
task challenging. Previous works have proposed various data augmentation
methods to reduce data bias. However, these works do not explicitly reduce the
data bias across different house scenes. Therefore, the agent would overfit to
the seen scenes and achieve poor navigation performance in the unseen scenes.
To tackle this problem, we propose the Random Environmental Mixup (REM) method,
which generates cross-connected house scenes as augmented data via mixuping
environment. Specifically, we first select key viewpoints according to the room
connection graph for each scene. Then, we cross-connect the key views of
different scenes to construct augmented scenes. Finally, we generate augmented
instruction-path pairs in the cross-connected scenes. The experimental results
on benchmark datasets demonstrate that our augmentation data via REM help the
agent reduce its performance gap between the seen and unseen environment and
improve the overall performance, making our model the best existing approach on
the standard VLN benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FIERY: Future Instance Prediction in Bird&#x27;s-Eye View from Surround Monocular Cameras. (arXiv:2104.10490v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1">Anthony Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Murez_Z/0/1/0/all/0/1">Zak Murez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_N/0/1/0/all/0/1">Nikhil Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudas_S/0/1/0/all/0/1">Sof&#xed;a Dudas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawke_J/0/1/0/all/0/1">Jeffrey Hawke</a>, <a href="http://arxiv.org/find/cs/1/au:+Badrinarayanan_V/0/1/0/all/0/1">Vijay Badrinarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cipolla_R/0/1/0/all/0/1">Roberto Cipolla</a>, <a href="http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1">Alex Kendall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10490">
                                    <div class="article-summary-box-inner">
                                        <span>Driving requires interacting with road agents and predicting their future
behaviour in order to navigate safely. We present FIERY: a probabilistic future
prediction model in bird&#x27;s-eye view from monocular cameras. Our model predicts
future instance segmentation and motion of dynamic agents that can be
transformed into non-parametric future trajectories. Our approach combines the
perception, sensor fusion and prediction components of a traditional autonomous
driving stack by estimating bird&#x27;s-eye-view prediction directly from surround
RGB monocular camera inputs. FIERY learns to model the inherent stochastic
nature of the future solely from camera driving data in an end-to-end manner,
without relying on HD maps, and predicts multimodal future trajectories. We
show that our model outperforms previous prediction baselines on the NuScenes
and Lyft datasets. The code and trained models are available at
https://github.com/wayveai/fiery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Random Walker Segmentation for Large Volumetric Biomedical Images. (arXiv:2103.09564v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drees_D/0/1/0/all/0/1">Dominik Drees</a>, <a href="http://arxiv.org/find/cs/1/au:+Eilers_F/0/1/0/all/0/1">Florian Eilers</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoyi Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09564">
                                    <div class="article-summary-box-inner">
                                        <span>The random walker method for image segmentation is a popular tool for
semi-automatic image segmentation, especially in the biomedical field. However,
its linear asymptotic run time and memory requirements make application to 3D
datasets of increasing sizes impractical. We propose a hierarchical framework
that, to the best of our knowledge, is the first attempt to overcome these
restrictions for the random walker algorithm and achieves sublinear run time
and constant memory complexity. The goal of this framework is -- rather than
improving the segmentation quality compared to the baseline method -- to make
interactive segmentation on out-of-core datasets possible. The method is
evaluated quantitavely on synthetic data and the CT-ORG dataset where the
expected improvements in algorithm run time while maintaining high segmentation
quality are confirmed. The incremental (i.e., interaction update) run time is
demonstrated to be in seconds on a standard PC even for volumes of hundreds of
Gigabytes in size. In a small case study the applicability to large real world
from current biomedical research is demonstrated. An implementation of the
presented method is publicly available in version 5.2 of the widely used volume
rendering and processing software Voreen (https://www.uni-muenster.de/Voreen/).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Continuity to Editability: Inverting GANs with Consecutive Images. (arXiv:2107.13812v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yangyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenpeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuemiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shengfeng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13812">
                                    <div class="article-summary-box-inner">
                                        <span>Existing GAN inversion methods are stuck in a paradox that the inverted codes
can either achieve high-fidelity reconstruction, or retain the editing
capability. Having only one of them clearly cannot realize real image editing.
In this paper, we resolve this paradox by introducing consecutive images (\eg,
video frames or the same person with different poses) into the inversion
process. The rationale behind our solution is that the continuity of
consecutive images leads to inherent editable directions. This inborn property
is used for two unique purposes: 1) regularizing the joint inversion process,
such that each of the inverted code is semantically accessible from one of the
other and fastened in a editable domain; 2) enforcing inter-image coherence,
such that the fidelity of each inverted code can be maximized with the
complement of other images. Extensive experiments demonstrate that our
alternative significantly outperforms state-of-the-art methods in terms of
reconstruction fidelity and editability on both the real image dataset and
synthesis dataset. Furthermore, our method provides the first support of
video-based GAN inversion, and an interesting application of unsupervised
semantic transfer from consecutive images. Source code can be found at:
\url{https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CNN-based Two-Stage Parking Slot Detection Using Region-Specific Multi-Scale Feature Extraction. (arXiv:2108.06185v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bui_Q/0/1/0/all/0/1">Quang Huy Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhr_J/0/1/0/all/0/1">Jae Kyu Suhr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06185">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous parking systems start with the detection of available parking
slots. Parking slot detection performance has been dramatically improved by
deep learning techniques. Deep learning-based object detection methods can be
categorized into one-stage and two-stage approaches. Although it is well-known
that the two-stage approach outperforms the one-stage approach in general
object detection, they have performed similarly in parking slot detection so
far. We consider this is because the two-stage approach has not yet been
adequately specialized for parking slot detection. Thus, this paper proposes a
highly specialized two-stage parking slot detector that uses region-specific
multi-scale feature extraction. In the first stage, the proposed method finds
the entrance of the parking slot as a region proposal by estimating its center,
length, and orientation. The second stage of this method designates specific
regions that most contain the desired information and extracts features from
them. That is, features for the location and orientation are separately
extracted from only the specific regions that most contain the locational and
orientational information. In addition, multi-resolution feature maps are
utilized to increase both positioning and classification accuracies. A
high-resolution feature map is used to extract detailed information (location
and orientation), while another low-resolution feature map is used to extract
semantic information (type and occupancy). In experiments, the proposed method
was quantitatively evaluated with two large-scale public parking slot detection
datasets and outperformed previous methods, including both one-stage and
two-stage approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MUSIQ: Multi-scale Image Quality Transformer. (arXiv:2108.05997v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1">Junjie Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Feng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05997">
                                    <div class="article-summary-box-inner">
                                        <span>Image quality assessment (IQA) is an important research topic for
understanding and improving visual experience. The current state-of-the-art IQA
methods are based on convolutional neural networks (CNNs). The performance of
CNN-based models is often compromised by the fixed shape constraint in batch
training. To accommodate this, the input images are usually resized and cropped
to a fixed shape, causing image quality degradation. To address this, we design
a multi-scale image quality Transformer (MUSIQ) to process native resolution
images with varying sizes and aspect ratios. With a multi-scale image
representation, our proposed method can capture image quality at different
granularities. Furthermore, a novel hash-based 2D spatial embedding and a scale
embedding is proposed to support the positional embedding in the multi-scale
representation. Experimental results verify that our method can achieve
state-of-the-art performance on multiple large scale IQA datasets such as
PaQ-2-PiQ, SPAQ and KonIQ-10k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANav: Group-wise Attention Network for Classifying Navigable Regions in Unstructured Outdoor Environments. (arXiv:2103.04233v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_T/0/1/0/all/0/1">Tianrui Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothandaraman_D/0/1/0/all/0/1">Divya Kothandaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Rohan Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sathyamoorthy_A/0/1/0/all/0/1">Adarsh Jagan Sathyamoorthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1">Dinesh Manocha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04233">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new learning-based method for identifying safe and navigable
regions in off-road terrains and unstructured environments from RGB images. Our
approach consists of classifying groups of terrains based on their navigability
levels using coarse-grained semantic segmentation. We propose a bottleneck
transformer-based deep neural network architecture that uses a novel group-wise
attention mechanism to distinguish between navigability levels of different
terrains. Our group-wise attention heads enable the network to explicitly focus
on the different groups and improve the accuracy. We show through extensive
evaluations on the RUGD and RELLIS-3D datasets that our learning algorithm
improves visual perception accuracy in off-road terrains for navigation. We
compare our approach with prior work on these datasets and achieve an
improvement over the state-of-the-art mIoU by 6.74-39.1% on RUGD and
3.82-10.64% on RELLIS-3D. In addition, we deploy our method on a Clearpath
Jackal robot. Our approach improves the performance of the navigation algorithm
in terms of average progress towards the goal by 54.73% and the false positives
in terms of forbidden region by 29.96%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting socially interacting groups using f-formation: A survey of taxonomy, methods, datasets, applications, challenges, and future research directions. (arXiv:2108.06181v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1">Hrishav Bakul Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Mg_T/0/1/0/all/0/1">Theint Haythi Mg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pramanick_P/0/1/0/all/0/1">Pradip Pramanick</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_C/0/1/0/all/0/1">Chayan Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06181">
                                    <div class="article-summary-box-inner">
                                        <span>Robots in our daily surroundings are increasing day by day. Their usability
and acceptability largely depend on their explicit and implicit interaction
capability with fellow human beings. As a result, social behavior is one of the
most sought-after qualities that a robot can possess. However, there is no
specific aspect and/or feature that defines socially acceptable behavior and it
largely depends on the situation, application, and society. In this article, we
investigate one such social behavior for collocated robots. Imagine a group of
people is interacting with each other and we want to join the group. We as
human beings do it in a socially acceptable manner, i.e., within the group, we
do position ourselves in such a way that we can participate in the group
activity without disturbing/obstructing anybody. To possess such a quality,
first, a robot needs to determine the formation of the group and then determine
a position for itself, which we humans do implicitly. The theory of f-formation
can be utilized for this purpose. As the types of formations can be very
diverse, detecting the social groups is not a trivial task. In this article, we
provide a comprehensive survey of the existing work on social interaction and
group detection using f-formation for robotics and other applications. We also
put forward a novel holistic survey framework combining all the possible
concerns and modules relevant to this problem. We define taxonomies based on
methods, camera views, datasets, detection capabilities and scale, evaluation
approaches, and application areas. We discuss certain open challenges and
limitations in current literature along with possible future research
directions based on this framework. In particular, we discuss the existing
methods/techniques and their relative merits and demerits, applications, and
provide a set of unsolved but relevant problems in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning vs XNOR-Net: A Comprehensive Study on Deep Learning for Audio Classification in Microcontrollers. (arXiv:2108.06128v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohaimenuzzaman_M/0/1/0/all/0/1">Md Mohaimenuzzaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_B/0/1/0/all/0/1">Bernd Meyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06128">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning has celebrated resounding successes in many application areas
of relevance to the Internet-of-Things, for example, computer vision and
machine listening. To fully harness the power of deep leaning for the IoT,
these technologies must ultimately be brought directly to the edge. The obvious
challenge is that deep learning techniques can only be implemented on strictly
resource-constrained edge devices if the models are radically downsized. This
task relies on different model compression techniques, such as network pruning,
quantization and the recent advancement of XNOR-Net. This paper examines the
suitability of these techniques for audio classification in microcontrollers.
We present an XNOR-Net for end-to-end raw audio classification and a
comprehensive empirical study comparing this approach with
pruning-and-quantization methods. We show that raw audio classification with
XNOR yields comparable performance to regular full precision networks for small
numbers of classes while reducing memory requirements 32-fold and computation
requirements 58-fold. However, as the number of classes increases
significantly, performance degrades and pruning-and-quantization based
compression techniques take over as the preferred technique being able to
satisfy the same space constraints but requiring about 8x more computation. We
show that these insights are consistent between raw audio classification and
image classification using standard benchmark sets.To the best of our
knowledge, this is the first study applying XNOR to end-to-end audio
classification and evaluating it in the context of alternative techniques. All
code is publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Benchmarking Analysis of Transfer Learning for Medical Image Analysis. (arXiv:2108.05930v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taher_M/0/1/0/all/0/1">Mohammad Reza Hosseinzadeh Taher</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghighi_F/0/1/0/all/0/1">Fatemeh Haghighi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ruibin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gotway_M/0/1/0/all/0/1">Michael B. Gotway</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jianming Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05930">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning from supervised ImageNet models has been frequently used in
medical image analysis. Yet, no large-scale evaluation has been conducted to
benchmark the efficacy of newly-developed pre-training techniques for medical
image analysis, leaving several important questions unanswered. As the first
step in this direction, we conduct a systematic study on the transferability of
models pre-trained on iNat2021, the most recent large-scale fine-grained
dataset, and 14 top self-supervised ImageNet models on 7 diverse medical tasks
in comparison with the supervised ImageNet model. Furthermore, we present a
practical approach to bridge the domain gap between natural and medical images
by continually (pre-)training supervised ImageNet models on medical images. Our
comprehensive evaluation yields new insights: (1) pre-trained models on
fine-grained data yield distinctive local representations that are more
suitable for medical segmentation tasks, (2) self-supervised ImageNet models
learn holistic features more effectively than supervised ImageNet models, and
(3) continual pre-training can bridge the domain gap between natural and
medical images. We hope that this large-scale open evaluation of transfer
learning can direct the future research of deep learning for medical imaging.
As open science, all codes and pre-trained models are available on our GitHub
page https://github.com/JLiangLab/BenchmarkTransferLearning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coupling Model-Driven and Data-Driven Methods for Remote Sensing Image Restoration and Fusion. (arXiv:2108.06073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huanfeng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Menghui Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chenxia Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1">Qiangqiang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangpei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06073">
                                    <div class="article-summary-box-inner">
                                        <span>In the fields of image restoration and image fusion, model-driven methods and
data-driven methods are the two representative frameworks. However, both
approaches have their respective advantages and disadvantages. The model-driven
methods consider the imaging mechanism, which is deterministic and
theoretically reasonable; however, they cannot easily model complicated
nonlinear problems. The data-driven methods have a stronger prior knowledge
learning capability for huge data, especially for nonlinear statistical
features; however, the interpretability of the networks is poor, and they are
over-dependent on training data. In this paper, we systematically investigate
the coupling of model-driven and data-driven methods, which has rarely been
considered in the remote sensing image restoration and fusion communities. We
are the first to summarize the coupling approaches into the following three
categories: 1) data-driven and model-driven cascading methods; 2) variational
models with embedded learning; and 3) model-constrained network learning
methods. The typical existing and potential coupling methods for remote sensing
image restoration and fusion are introduced with application examples. This
paper also gives some new insights into the potential future directions, in
terms of both methods and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedPara: Low-rank Hadamard Product Parameterization for Efficient Federated Learning. (arXiv:2108.06098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hyeon_Woo_N/0/1/0/all/0/1">Nam Hyeon-Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Bin_M/0/1/0/all/0/1">Moon Ye-Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1">Tae-Hyun Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06098">
                                    <div class="article-summary-box-inner">
                                        <span>To overcome the burdens on frequent model uploads and downloads during
federated learning (FL), we propose a communication-efficient
re-parameterization, FedPara. Our method re-parameterizes the model&#x27;s layers
using low-rank matrices or tensors followed by the Hadamard product. Different
from the conventional low-rank parameterization, our method is not limited to
low-rank constraints. Thereby, our FedPara has a larger capacity than the
low-rank one, even with the same number of parameters. It can achieve
comparable performance to the original models while requiring 2.8 to 10.1 times
lower communication costs than the original models, which is not achievable by
the traditional low-rank parameterization. Moreover, the efficiency can be
further improved by combining our method and other efficient FL techniques
because our method is compatible with others. We also extend our method to a
personalized FL application, pFedPara, which separates parameters into global
and local ones. We show that pFedPara outperforms competing personalized FL
methods with more than three times fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-imaging real-time detection and tracking of fast-moving objects. (arXiv:2108.06009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Fengming Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xuelei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tianhang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yiguang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06009">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time detection and tracking of fast-moving objects have achieved great
success in various fields. However, many existing methods, especially low-cost
ones, are difficult to achieve real-time and long-term object detection and
tracking. Here, a non-imaging strategy is proposed, including two stages, to
realize fast-moving object detection and tracking in real-time and for the long
term: 1) a contour-moments-based method is proposed to optimize the Hadamard
pattern sequence. And then reconstructing projection curves of the object based
on single-pixel imaging technology. The projection curve, which including the
object location information, is reconstructed directly with the measurements
collected by a single-pixel detector; 2) The fastest changing position in the
projection curve can be obtained by solving first-order gradients. A gradient
differential is used in two first-order gradients to calculate a differential
curve with the sudden change positions. Finally, we can obtain the boundary
information of the fast-moving object. We experimentally demonstrate that our
approach can achieve a temporal resolution of 105 frames per second at a 1.28%
sampling rate by using a 22,000 Hz digital micro-mirror device. The detection
and tracking algorithm of the proposed strategy is computationally efficient.
Compared with the state-of-the-art methods, our approach can make the sampling
rate lower. Additionally, the strategy acquires not more than 1MB of data for
each frame, which is capable of fast-moving object real-time and long-term
detection and tracking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point-Voxel Transformer: An Efficient Approach To 3D Deep Learning. (arXiv:2108.06076v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1">Haocheng Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xinyi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zizhao Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06076">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the sparsity and irregularity of the 3D data, approaches that directly
process points have become popular. Among all point-based models,
Transformer-based models have achieved state-of-the-art performance by fully
preserving point interrelation. However, most of them spend high percentage of
total time on sparse data accessing (e.g., Farthest Point Sampling (FPS) and
neighbor points query), which becomes the computation burden. Therefore, we
present a novel 3D Transformer, called Point-Voxel Transformer (PVT) that
leverages self-attention computation in points to gather global context
features, while performing multi-head self-attention (MSA) computation in
voxels to capture local information and reduce the irregular data access.
Additionally, to further reduce the cost of MSA computation, we design a cyclic
shifted boxing scheme which brings greater efficiency by limiting the MSA
computation to non-overlapping local boxes while also preserving cross-box
connection. Our method fully exploits the potentials of Transformer
architecture, paving the road to efficient and accurate recognition results.
Evaluated on classification and segmentation benchmarks, our PVT not only
achieves strong accuracy but outperforms previous state-of-the-art
Transformer-based models with 9x measured speedup on average. For 3D object
detection task, we replace the primitives in Frustrum PointNet with PVT layer
and achieve the improvement of 8.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Representative Labeling for Deep Semi-Supervised Learning. (arXiv:2108.06070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiaopeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Riquan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Litong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Huabin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wayne Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06070">
                                    <div class="article-summary-box-inner">
                                        <span>Deep semi-supervised learning (SSL) has experienced significant attention in
recent years, to leverage a huge amount of unlabeled data to improve the
performance of deep learning with limited labeled data. Pseudo-labeling is a
popular approach to expand the labeled dataset. However, whether there is a
more effective way of labeling remains an open problem. In this paper, we
propose to label only the most representative samples to expand the labeled
set. Representative samples, selected by indegree of corresponding nodes on a
directed k-nearest neighbor (kNN) graph, lie in the k-nearest neighborhood of
many other samples. We design a graph neural network (GNN) labeler to label
them in a progressive learning manner. Aided by the progressive GNN labeler,
our deep SSL approach outperforms state-of-the-art methods on several popular
SSL benchmarks including CIFAR-10, SVHN, and ILSVRC-2012. Notably, we achieve
72.1% top-1 accuracy, surpassing the previous best result by 3.3%, on the
challenging ImageNet benchmark with only $10\%$ labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning. (arXiv:2108.06017v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuefan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Shinjae Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibin Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yuewei Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06017">
                                    <div class="article-summary-box-inner">
                                        <span>While deep neural networks have shown impressive performance in many tasks,
they are fragile to carefully designed adversarial attacks. We propose a novel
adversarial training-based model by Attention Guided Knowledge Distillation and
Bi-directional Metric Learning (AGKD-BML). The attention knowledge is obtained
from a weight-fixed model trained on a clean dataset, referred to as a teacher
model, and transferred to a model that is under training on adversarial
examples (AEs), referred to as a student model. In this way, the student model
is able to focus on the correct region, as well as correcting the intermediate
features corrupted by AEs to eventually improve the model accuracy. Moreover,
to efficiently regularize the representation in feature space, we propose a
bidirectional metric learning. Specifically, given a clean image, it is first
attacked to its most confusing class to get the forward AE. A clean image in
the most confusing class is then randomly picked and attacked back to the
original class to get the backward AE. A triplet loss is then used to shorten
the representation distance between original image and its AE, while enlarge
that between the forward and backward AEs. We conduct extensive adversarial
robustness experiments on two widely used datasets with different attacks. Our
proposed AGKD-BML model consistently outperforms the state-of-the-art
approaches. The code of AGKD-BML will be available at:
https://github.com/hongw579/AGKD-BML.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-Temporal Semantic Reasoning for the Semantic Change Detection of HR Remote Sensing Images. (arXiv:2108.06103v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Lei Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Haitao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sicong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1">Lichao Mou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruzzone_L/0/1/0/all/0/1">Lorenzo Bruzzone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06103">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic change detection (SCD) extends the change detection (CD) task to
provide not only the change locations but also the detailed semantic categories
(before and after the observation intervals). This fine-grained change
information is more useful in land-cover/land-use (LC/LU) applications. Recent
studies indicate that the SCD can be modeled through a triple-branch
Convolutional Neural Network (CNN), which contains two temporal branches and a
change branch. However, in this architecture, the connections between the
temporal branches and the change branch are weak. To overcome these
limitations, we propose a novel CNN architecture for the SCD, where the
temporal features are re-used and are deeply merged in the temporal branch.
Furthermore, we elaborate on this architecture to model the bi-temporal
semantic correlations. The resulting Bi-temporal Semantic Reasoning Network
(Bi-SRNet) contains two types of semantic reasoning blocks to reason both
single-temporal and cross-temporal semantic correlations, as well as a novel
loss function to improve the semantic consistency of change detection results.
Experimental results on a benchmark dataset show that the proposed architecture
obtains significant accuracy improvements over the existing approaches, while
the added designs in the Bi-SRNet further improves the segmentation of both
semantic categories and the changed areas. The codes in this paper are
accessible at: https://github.com/ggsDing/Bi-SRNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted Physical-World Attention Attack on Deep Learning Models in Road Sign Recognition. (arXiv:2010.04331v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weifeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04331">
                                    <div class="article-summary-box-inner">
                                        <span>Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modal-Adaptive Gated Recoding Network for RGB-D Salient Object Detection. (arXiv:2108.06281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_F/0/1/0/all/0/1">Feng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jinchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xian Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qiu Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06281">
                                    <div class="article-summary-box-inner">
                                        <span>The multi-modal salient object detection model based on RGB-D information has
better robustness in the real world. However, it remains nontrivial to better
adaptively balance effective multi-modal information in the feature fusion
phase. In this letter, we propose a novel gated recoding network (GRNet) to
evaluate the information validity of the two modes, and balance their
influence. Our framework is divided into three phases: perception phase,
recoding mixing phase and feature integration phase. First, A perception
encoder is adopted to extract multi-level single-modal features, which lays the
foundation for multi-modal semantic comparative analysis. Then, a
modal-adaptive gate unit (MGU) is proposed to suppress the invalid information
and transfer the effective modal features to the recoding mixer and the hybrid
branch decoder. The recoding mixer is responsible for recoding and mixing the
balanced multi-modal information. Finally, the hybrid branch decoder completes
the multi-level feature integration under the guidance of an optional edge
guidance stream (OEGS). Experiments and analysis on eight popular benchmarks
verify that our framework performs favorably against 9 state-of-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective semantic segmentation in Cataract Surgery: What matters most?. (arXiv:2108.06119v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pissas_T/0/1/0/all/0/1">Theodoros Pissas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravasio_C/0/1/0/all/0/1">Claudio Ravasio</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1">Lyndon Da Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergeles_C/0/1/0/all/0/1">Christos Bergeles</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06119">
                                    <div class="article-summary-box-inner">
                                        <span>Our work proposes neural network design choices that set the state-of-the-art
on a challenging public benchmark on cataract surgery, CaDIS. Our methodology
achieves strong performance across three semantic segmentation tasks with
increasingly granular surgical tool class sets by effectively handling class
imbalance, an inherent challenge in any surgical video. We consider and
evaluate two conceptually simple data oversampling methods as well as different
loss functions. We show significant performance gains across network
architectures and tasks especially on the rarest tool classes, thereby
presenting an approach for achieving high performance when imbalanced granular
datasets are considered. Our code and trained models are available at
https://github.com/RViMLab/MICCAI2021_Cataract_semantic_segmentation and
qualitative results on unseen surgical video can be found at
https://youtu.be/twVIPUj1WZM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Captioning with Unseen Object Classes. (arXiv:2108.06165v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1">Berkan Demirel</a>, <a href="http://arxiv.org/find/cs/1/au:+Cinbis_R/0/1/0/all/0/1">Ramazan Gokberk Cinbis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06165">
                                    <div class="article-summary-box-inner">
                                        <span>Image caption generation is one of the most challenging problems at the
intersection of visual recognition and natural language modeling domains. In
this work, we propose and study a practically important variant of this problem
where test images may contain visual objects with no corresponding visual or
textual training examples. For this problem, we propose a detection-driven
approach based on a generalized zero-shot detection model and a template-based
sentence generation model. In order to improve the detection component, we
jointly define a class-to-class similarity based class representation and a
practical score calibration mechanism. We also propose a novel evaluation
metric that provides complimentary insights to the captioning outputs, by
separately handling the visual and non-visual components of the captions. Our
experiments show that the proposed zero-shot detection model obtains
state-of-the-art performance on the MS-COCO dataset and the zero-shot
captioning approach yields promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Track without Appearance: Learn Box and Tracklet Embedding with Local and Global Motion Patterns for Vehicle Tracking. (arXiv:2108.06029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gaoang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1">Renshu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zuozhu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06029">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicle tracking is an essential task in the multi-object tracking (MOT)
field. A distinct characteristic in vehicle tracking is that the trajectories
of vehicles are fairly smooth in both the world coordinate and the image
coordinate. Hence, models that capture motion consistencies are of high
necessity. However, tracking with the standalone motion-based trackers is quite
challenging because targets could get lost easily due to limited information,
detection error and occlusion. Leveraging appearance information to assist
object re-identification could resolve this challenge to some extent. However,
doing so requires extra computation while appearance information is sensitive
to occlusion as well. In this paper, we try to explore the significance of
motion patterns for vehicle tracking without appearance information. We propose
a novel approach that tackles the association issue for long-term tracking with
the exclusive fully-exploited motion information. We address the tracklet
embedding issue with the proposed reconstruct-to-embed strategy based on deep
graph convolutional neural networks (GCN). Comprehensive experiments on the
KITTI-car tracking dataset and UA-Detrac dataset show that the proposed method,
though without appearance information, could achieve competitive performance
with the state-of-the-art (SOTA) trackers. The source code will be available at
https://github.com/GaoangW/LGMTracker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue. (arXiv:2108.06024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Keke Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_D/0/1/0/all/0/1">Dingruibo Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Weilong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianpeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yawen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1">Zhaoquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhihong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06024">
                                    <div class="article-summary-box-inner">
                                        <span>Overconfident predictions on out-of-distribution (OOD) samples is a thorny
issue for deep neural networks. The key to resolve the OOD overconfidence issue
inherently is to build a subset of OOD samples and then suppress predictions on
them. This paper proposes the Chamfer OOD examples (CODEs), whose distribution
is close to that of in-distribution samples, and thus could be utilized to
alleviate the OOD overconfidence issue effectively by suppressing predictions
on them. To obtain CODEs, we first generate seed OOD examples via
slicing&amp;splicing operations on in-distribution samples from different
categories, and then feed them to the Chamfer generative adversarial network
for distribution transformation, without accessing to any extra data. Training
with suppressing predictions on CODEs is validated to alleviate the OOD
overconfidence issue largely without hurting classification accuracy, and
outperform the state-of-the-art methods. Besides, we demonstrate CODEs are
useful for improving OOD detection and classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation. (arXiv:2108.05988v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1">Ning Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05988">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to transfer the knowledge learnt
from a labeled source domain to an unlabeled target domain. Previous work is
mainly built upon convolutional neural networks (CNNs) to learn
domain-invariant representations. With the recent exponential increase in
applying Vision Transformer (ViT) to vision tasks, the capability of ViT in
adapting cross-domain knowledge, however, remains unexplored in the literature.
To fill this gap, this paper first comprehensively investigates the
transferability of ViT on a variety of domain adaptation tasks. Surprisingly,
ViT demonstrates superior transferability over its CNNs-based counterparts with
a large margin, while the performance can be further improved by incorporating
adversarial adaptation. Notwithstanding, directly using CNNs-based adaptation
strategies fails to take the advantage of ViT&#x27;s intrinsic merits (e.g.,
attention mechanism and sequential image representation) which play an
important role in knowledge transfer. To remedy this, we propose an unified
framework, namely Transferable Vision Transformer (TVT), to fully exploit the
transferability of ViT for domain adaptation. Specifically, we delicately
devise a novel and effective unit, which we term Transferability Adaption
Module (TAM). By injecting learned transferabilities into attention blocks, TAM
compels ViT focus on both transferable and discriminative features. Besides, we
leverage discriminative clustering to enhance feature diversity and separation
which are undermined during adversarial domain alignment. To verify its
versatility, we perform extensive studies of TVT on four benchmarks and the
experimental results demonstrate that TVT attains significant improvements
compared to existing state-of-the-art UDA methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Adversarial Framework for Optimizing Image Matting and Harmonization Simultaneously. (arXiv:2108.06087v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuqian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chunlei Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06087">
                                    <div class="article-summary-box-inner">
                                        <span>Image matting and image harmonization are two important tasks in image
composition. Image matting, aiming to achieve foreground boundary details, and
image harmonization, aiming to make the background compatible with the
foreground, are both promising yet challenging tasks. Previous works consider
optimizing these two tasks separately, which may lead to a sub-optimal
solution. We propose to optimize matting and harmonization simultaneously to
get better performance on both the two tasks and achieve more natural results.
We propose a new Generative Adversarial (GAN) framework which optimizing the
matting network and the harmonization network based on a self-attention
discriminator. The discriminator is required to distinguish the natural images
from different types of fake synthesis images. Extensive experiments on our
constructed dataset demonstrate the effectiveness of our proposed method. Our
dataset and dataset generating pipeline can be found in
\url{https://git.io/HaMaGAN}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SVC-onGoing: Signature Verification Competition. (arXiv:2108.06090v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1">Ruben Tolosana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1">Ruben Vera-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Garcia_C/0/1/0/all/0/1">Carlos Gonzalez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_Garcia_J/0/1/0/all/0/1">Javier Ortega-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_J/0/1/0/all/0/1">Juan Carlos Ruiz-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_Tapiador_S/0/1/0/all/0/1">Sergio Romero-Tapiador</a>, <a href="http://arxiv.org/find/cs/1/au:+Rengifo_S/0/1/0/all/0/1">Santiago Rengifo</a>, <a href="http://arxiv.org/find/cs/1/au:+Caruana_M/0/1/0/all/0/1">Miguel Caruana</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiajia Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1">Songxuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yecheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Galbally_J/0/1/0/all/0/1">Javier Galbally</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1">Moises Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_M/0/1/0/all/0/1">Miguel Angel Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Barrero_M/0/1/0/all/0/1">Marta Gomez-Barrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodashinsky_I/0/1/0/all/0/1">Ilya Hodashinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarin_K/0/1/0/all/0/1">Konstantin Sarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Slezkin_A/0/1/0/all/0/1">Artem Slezkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bardamova_M/0/1/0/all/0/1">Marina Bardamova</a>, <a href="http://arxiv.org/find/cs/1/au:+Svetlakov_M/0/1/0/all/0/1">Mikhail Svetlakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleem_M/0/1/0/all/0/1">Mohammad Saleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Szucs_C/0/1/0/all/0/1">Cintia Lia Szucs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovari_B/0/1/0/all/0/1">Bence Kovari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulsmeyer_F/0/1/0/all/0/1">Falk Pulsmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehbi_M/0/1/0/all/0/1">Mohamad Wehbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1">Dario Zanca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1">Sumaiya Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Sarthak Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jabin_S/0/1/0/all/0/1">Suraiya Jabin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06090">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents SVC-onGoing, an on-going competition for on-line
signature verification where researchers can easily benchmark their systems
against the state of the art in an open common platform using large-scale
public databases, such as DeepSignDB and SVC2021_EvalDB, and standard
experimental protocols. SVC-onGoing is based on the ICDAR 2021 Competition on
On-Line Signature Verification (SVC 2021), which has been extended to allow
participants anytime. The goal of SVC-onGoing is to evaluate the limits of
on-line signature verification systems on popular scenarios (office/mobile) and
writing inputs (stylus/finger) through large-scale public databases. Three
different tasks are considered in the competition, simulating realistic
scenarios as both random and skilled forgeries are simultaneously considered on
each task. The results obtained in SVC-onGoing prove the high potential of deep
learning methods in comparison with traditional methods. In particular, the
best signature verification system has obtained Equal Error Rate (EER) values
of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3). Future studies in the
field should be oriented to improve the performance of signature verification
systems on the challenging mobile scenarios of SVC-onGoing in which several
mobile devices and the finger are used during the signature acquisition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Disease Diagnosis via Deep Factorization Machine Models. (arXiv:2108.05916v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ronge_R/0/1/0/all/0/1">Raphael Ronge</a>, <a href="http://arxiv.org/find/cs/1/au:+Nho_K/0/1/0/all/0/1">Kwangsik Nho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Polsterl_S/0/1/0/all/0/1">Sebastian P&#xf6;lsterl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05916">
                                    <div class="article-summary-box-inner">
                                        <span>The current state-of-the-art deep neural networks (DNNs) for Alzheimer&#x27;s
Disease diagnosis use different biomarker combinations to classify patients,
but do not allow extracting knowledge about the interactions of biomarkers.
However, to improve our understanding of the disease, it is paramount to
extract such knowledge from the learned model. In this paper, we propose a Deep
Factorization Machine model that combines the ability of DNNs to learn complex
relationships and the ease of interpretability of a linear model. The proposed
model has three parts: (i) an embedding layer to deal with sparse categorical
data, (ii) a Factorization Machine to efficiently learn pairwise interactions,
and (iii) a DNN to implicitly model higher order interactions. In our
experiments on data from the Alzheimer&#x27;s Disease Neuroimaging Initiative, we
demonstrate that our proposed model classifies cognitive normal, mild cognitive
impaired, and demented patients more accurately than competing models. In
addition, we show that valuable knowledge about the interactions among
biomarkers can be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UMFA: A photorealistic style transfer method based on U-Net and multi-layer feature aggregation. (arXiv:2108.06113v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_D/0/1/0/all/0/1">D.Y. Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">X.J. Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">H. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kittler_J/0/1/0/all/0/1">J. Kittler</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">T.Y. Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06113">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a photorealistic style transfer network to
emphasize the natural effect of photorealistic image stylization. In general,
distortion of the image content and lacking of details are two typical issues
in the style transfer field. To this end, we design a novel framework employing
the U-Net structure to maintain the rich spatial clues, with a multi-layer
feature aggregation (MFA) method to simultaneously provide the details obtained
by the shallow layers in the stylization processing. In particular, an encoder
based on the dense block and a decoder form a symmetrical structure of U-Net
are jointly staked to realize an effective feature extraction and image
reconstruction. Besides, a transfer module based on MFA and &quot;adaptive instance
normalization&quot; (AdaIN) is inserted in the skip connection positions to achieve
the stylization. Accordingly, the stylized image possesses the texture of a
real photo and preserves rich content details without introducing any mask or
post-processing steps. The experimental results on public datasets demonstrate
that our method achieves a more faithful structural similarity with a lower
style loss, reflecting the effectiveness and merit of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Recommendation-cum-Reminder System. (arXiv:2108.06206v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Rohan Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_M/0/1/0/all/0/1">Maheep Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurya_C/0/1/0/all/0/1">Chandresh Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1">Shitala Prasad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06206">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent recommendation and reminder systems are the need of the
fast-pacing life. Current intelligent systems such as Siri, Google Assistant,
Microsoft Cortona, etc., have limited capability. For example, if you want to
wake up at 6 am because you have an upcoming trip, you have to set the alarm
manually. Besides, these systems do not recommend or remind what else to carry,
such as carrying an umbrella during a likely rain. The present work proposes a
system that takes an email as input and returns a recommendation-cumreminder
list. As a first step, we parse the emails, recognize the entities using named
entity recognition (NER). In the second step, information retrieval over the
web is done to identify nearby places, climatic conditions, etc. Imperative
sentences from the reviews of all places are extracted and passed to the object
extraction module. The main challenge lies in extracting the objects (items) of
interest from the review. To solve it, a modified Machine Reading
Comprehension-NER (MRC-NER) model is trained to tag objects of interest by
formulating annotation rules as a query. The objects so found are recommended
to the user one day in advance. The final reminder list of objects is pruned by
our proposed model for tracking objects kept during the &quot;packing activity.&quot;
Eventually, when the user leaves for the event/trip, an alert is sent
containing the reminding list items. Our approach achieves superior performance
compared to several baselines by as much as 30% on recall and 10% on precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Ruiyang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1">Shangwen Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Yingqi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">QiaoQiao She</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, dense passage retrieval has become a mainstream approach to finding
relevant information in various natural language processing tasks. A number of
studies have been devoted to improving the widely adopted dual-encoder
architecture. However, most of the previous studies only consider query-centric
similarity relation when learning the dual-encoder retriever. In order to
capture more comprehensive similarity relations, we propose a novel approach
that leverages both query-centric and PAssage-centric sImilarity Relations
(called PAIR) for dense passage retrieval. To implement our approach, we make
three major technical contributions by introducing formal formulations of the
two kinds of similarity relations, generating high-quality pseudo labeled data
via knowledge distillation, and designing an effective two-stage training
procedure that incorporates passage-centric similarity relation constraint.
Extensive experiments show that our approach significantly outperforms previous
state-of-the-art models on both MSMARCO and Natural Questions datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Music Performance Assessment with Contrastive Learning. (arXiv:2108.01711v1 [cs.SD] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1">Pavan Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerch_A/0/1/0/all/0/1">Alexander Lerch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Several automatic approaches for objective music performance assessment (MPA)
have been proposed in the past, however, existing systems are not yet capable
of reliably predicting ratings with the same accuracy as professional judges.
This study investigates contrastive learning as a potential method to improve
existing MPA systems. Contrastive learning is a widely used technique in
representation learning to learn a structured latent space capable of
separately clustering multiple classes. It has been shown to produce state of
the art results for image-based classification problems. We introduce a
weighted contrastive loss suitable for regression tasks applied to a
convolutional neural network and show that contrastive loss results in
performance gains in regression tasks for MPA. Our results show that
contrastive-based methods are able to match and exceed SoTA performance for MPA
regression tasks by creating better class clusters within the latent space of
the neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LT-OCF: Learnable-Time ODE-based Collaborative Filtering. (arXiv:2108.06208v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jeongwhan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06208">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is a long-standing problem of recommender
systems. Many novel methods have been proposed, ranging from classical matrix
factorization to recent graph convolutional network-based approaches. After
recent fierce debates, researchers started to focus on linear graph
convolutional networks (GCNs) with a layer combination, which show
state-of-the-art accuracy in many datasets. In this work, we extend them based
on neural ordinary differential equations (NODEs), because the linear GCN
concept can be interpreted as a differential equation, and present the method
of Learnable-Time ODE-based Collaborative Filtering (LT-OCF). The main novelty
in our method is that after redesigning linear GCNs on top of the NODE regime,
i) we learn the optimal architecture rather than relying on manually designed
ones, ii) we learn smooth ODE solutions that are considered suitable for CF,
and iii) we test with various ODE solvers that internally build a diverse set
of neural network connections. We also present a novel training method
specialized to our method. In our experiments with three benchmark datasets,
Gowalla, Yelp2018, and Amazon-Book, our method consistently shows better
accuracy than existing methods, e.g., a recall of 0.0411 by LightGCN vs. 0.0442
by LT-OCF and an NDCG of 0.0315 by LightGCN vs. 0.0341 by LT-OCF in
Amazon-Book. One more important discovery in our experiments that is worth
mentioning is that our best accuracy was achieved by dense connections rather
than linear connections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Single and Multiple Representations in Dense Passage Retrieval. (arXiv:2108.06279v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06279">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextualised language models has brought gains in search
effectiveness, not just when applied for re-ranking the output of classical
weighting models such as BM25, but also when used directly for passage indexing
and retrieval, a technique which is called dense retrieval. In the existing
literature in neural ranking, two dense retrieval families have become
apparent: single representation, where entire passages are represented by a
single embedding (usually BERT&#x27;s [CLS] token, as exemplified by the recent ANCE
approach), or multiple representations, where each token in a passage is
represented by its own embedding (as exemplified by the recent ColBERT
approach). These two families have not been directly compared. However, because
of the likely importance of dense retrieval moving forward, a clear
understanding of their advantages and disadvantages is paramount. To this end,
this paper contributes a direct study on their comparative effectiveness,
noting situations where each method under/over performs w.r.t. each other, and
w.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than
ColBERT in terms of response time and memory usage, multiple representations
are statistically more effective than the single representations for MAP and
MRR@10. We also show that multiple representations obtain better improvements
than single representations for queries that are the hardest for BM25, as well
as for definitional queries, and those with complex information needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Effectiveness of Reviews in E-commerce Top-N Recommendation. (arXiv:2106.09665v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhichao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Hansi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09665">
                                    <div class="article-summary-box-inner">
                                        <span>Modern E-commerce websites contain heterogeneous sources of information, such
as numerical ratings, textual reviews and images. These information can be
utilized to assist recommendation. Through textual reviews, a user explicitly
express her affinity towards the item. Previous researchers found that by using
the information extracted from these reviews, we can better profile the users&#x27;
explicit preferences as well as the item features, leading to the improvement
of recommendation performance. However, most of the previous algorithms were
only utilizing the review information for explicit-feedback problem i.e. rating
prediction, and when it comes to implicit-feedback ranking problem such as
top-N recommendation, the usage of review information has not been fully
explored. Seeing this gap, in this work, we investigate the effectiveness of
textual review information for top-N recommendation under E-commerce settings.
We adapt several SOTA review-based rating prediction models for top-N
recommendation tasks and compare them to existing top-N recommendation models
from both performance and efficiency. We find that models utilizing only review
information can not achieve better performances than vanilla implicit-feedback
matrix factorization method. When utilizing review information as a regularizer
or auxiliary information, the performance of implicit-feedback matrix
factorization method can be further improved. However, the optimal model
structure to utilize textual reviews for E-commerce top-N recommendation is yet
to be determined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recommending Insurance products by using Users&#x27; Sentiments. (arXiv:2108.06210v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parasrampuria_R/0/1/0/all/0/1">Rohan Parasrampuria</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Ayan Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Suchandra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dhrubasish Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06210">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s tech-savvy world every industry is trying to formulate methods for
recommending products by combining several techniques and algorithms to form a
pool that would bring forward the most enhanced models for making the
predictions. Building on these lines is our paper focused on the application of
sentiment analysis for recommendation in the insurance domain. We tried
building the following Machine Learning models namely, Logistic Regression,
Multinomial Naive Bayes, and the mighty Random Forest for analyzing the
polarity of a given feedback line given by a customer. Then we used this
polarity along with other attributes like Age, Gender, Locality, Income, and
the list of other products already purchased by our existing customers as input
for our recommendation model. Then we matched the polarity score along with the
user&#x27;s profiles and generated the list of insurance products to be recommended
in descending order. Despite our model&#x27;s simplicity and the lack of the key
data sets, the results seemed very logical and realistic. So, by developing the
model with more enhanced methods and with access to better and true data
gathered from an insurance industry may be the sector could be very well
benefitted from the amalgamation of sentiment analysis with a recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAIR: Framework for mining relationships between research articles, strategies, and regulations in the field of explainable artificial intelligence. (arXiv:2108.06216v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1">Stanis&#x142;aw Gizinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzba_M/0/1/0/all/0/1">Micha&#x142; Kuzba</a>, <a href="http://arxiv.org/find/cs/1/au:+Pielinski_B/0/1/0/all/0/1">Bartosz Pielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sienkiewicz_J/0/1/0/all/0/1">Julian Sienkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Laniewski_S/0/1/0/all/0/1">Stanis&#x142;aw &#x141;aniewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1">Przemys&#x142;aw Biecek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06216">
                                    <div class="article-summary-box-inner">
                                        <span>The growing number of AI applications, also for high-stake decisions,
increases the interest in Explainable and Interpretable Machine Learning
(XI-ML). This trend can be seen both in the increasing number of regulations
and strategies for developing trustworthy AI and the growing number of
scientific papers dedicated to this topic. To ensure the sustainable
development of AI, it is essential to understand the dynamics of the impact of
regulation on research papers as well as the impact of scientific discourse on
AI-related policies. This paper introduces a novel framework for joint analysis
of AI-related policy documents and eXplainable Artificial Intelligence (XAI)
research papers. The collected documents are enriched with metadata and
interconnections, using various NLP methods combined with a methodology
inspired by Institutional Grammar. Based on the information extracted from
collected documents, we showcase a series of analyses that help understand
interactions, similarities, and differences between documents at different
stages of institutionalization. To the best of our knowledge, this is the first
work to use automatic language analysis tools to understand the dynamics
between XI-ML methods and regulations. We believe that such a system
contributes to better cooperation between XAI researchers and AI policymakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMET: Convolutional Dimension Interaction for Collaborative Filtering. (arXiv:2007.14129v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xingzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee Keong Kwoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14129">
                                    <div class="article-summary-box-inner">
                                        <span>Latent factor models play a dominant role among recommendation techniques.
However, most of the existing latent factor models assume both historical
interactions and embedding dimensions are independent of each other, and thus
regrettably ignore the high-order interaction information among historical
interactions and embedding dimensions. In this paper, we propose a novel latent
factor model called COMET (COnvolutional diMEnsion inTeraction), which
simultaneously model the high-order interaction patterns among historical
interactions and embedding dimensions. To be specific, COMET stacks the
embeddings of historical interactions horizontally at first, which results in
two &quot;embedding maps&quot;. In this way, internal interactions and dimensional
interactions can be exploited by convolutional neural networks with kernels of
different sizes simultaneously. A fully-connected multi-layer perceptron is
then applied to obtain two interaction vectors. Lastly, the representations of
users and items are enriched by the learnt interaction vectors, which can
further be used to produce the final prediction. Extensive experiments and
ablation studies on various public implicit feedback datasets clearly
demonstrate the effectiveness and the rationality of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TPRM: A Topic-based Personalized Ranking Model for Web Search. (arXiv:2108.06014v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06014">
                                    <div class="article-summary-box-inner">
                                        <span>Ranking models have achieved promising results, but it remains challenging to
design personalized ranking systems to leverage user profiles and semantic
representations between queries and documents. In this paper, we propose a
topic-based personalized ranking model (TPRM) that integrates user topical
profile with pretrained contextualized term representations to tailor the
general document ranking list. Experiments on the real-world dataset
demonstrate that TPRM outperforms state-of-the-art ad-hoc ranking models and
personalized ranking models significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Answer Similarity for Evaluating Question Answering Models. (arXiv:2108.06130v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutsch_J/0/1/0/all/0/1">Julian Gutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietsch_M/0/1/0/all/0/1">Malte Pietsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06130">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of question answering models compares ground-truth annotations
with model predictions. However, as of today, this comparison is mostly
lexical-based and therefore misses out on answers that have no lexical overlap
but are still semantically similar, thus treating correct answers as false.
This underestimation of the true performance of models hinders user acceptance
in applications and complicates a fair comparison of different models.
Therefore, there is a need for an evaluation metric that is based on semantics
instead of pure string similarity. In this short paper, we present SAS, a
cross-encoder-based metric for the estimation of semantic answer similarity,
and compare it to seven existing metrics. To this end, we create an English and
a German three-way annotated evaluation dataset containing pairs of answers
along with human judgment of their semantic similarity, which we release along
with an implementation of the SAS metric and the experiments. We find that
semantic similarity metrics based on recent transformer models correlate much
better with human judgment than traditional lexical similarity metrics on our
two newly created datasets and one dataset from related work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GQE-PRF: Generative Query Expansion with Pseudo-Relevance Feedback. (arXiv:2108.06010v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Meizhen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06010">
                                    <div class="article-summary-box-inner">
                                        <span>Query expansion with pseudo-relevance feedback (PRF) is a powerful approach
to enhance the effectiveness in information retrieval. Recently, with the rapid
advance of deep learning techniques, neural text generation has achieved
promising success in many natural language tasks. To leverage the strength of
text generation for information retrieval, in this article, we propose a novel
approach which effectively integrates text generation models into PRF-based
query expansion. In particular, our approach generates augmented query terms
via neural text generation models conditioned on both the initial query and
pseudo-relevance feedback. Moreover, in order to train the generative model, we
adopt the conditional generative adversarial nets (CGANs) and propose the
PRF-CGAN method in which both the generator and the discriminator are
conditioned on the pseudo-relevance feedback. We evaluate the performance of
our approach on information retrieval tasks using two benchmark datasets. The
experimental results show that our approach achieves comparable performance or
outperforms traditional query expansion methods on both the retrieval and
reranking tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shift-invariant waveform learning on epileptic ECoG. (arXiv:2108.03177v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mendoza_Cardenas_C/0/1/0/all/0/1">Carlos H. Mendoza-Cardenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmeier_A/0/1/0/all/0/1">Austin J. Brockmeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03177">
                                    <div class="article-summary-box-inner">
                                        <span>Seizure detection algorithms must discriminate abnormal neuronal activity
associated with a seizure from normal neural activity in a variety of
conditions. Our approach is to seek spatiotemporal waveforms with distinct
morphology in electrocorticographic (ECoG) recordings of epileptic patients
that are indicative of a subsequent seizure (preictal) versus non-seizure
segments (interictal). To find these waveforms we apply a shift-invariant
k-means algorithm to segments of spatially filtered signals to learn codebooks
of prototypical waveforms. The frequency of the cluster labels from the
codebooks is then used to train a binary classifier that predicts the class
(preictal or interictal) of a test ECoG segment. We use the Matthews
correlation coefficient to evaluate the performance of the classifier and the
quality of the codebooks. We found that our method finds recurrent
non-sinusoidal waveforms that could be used to build interpretable features for
seizure prediction and that are also physiologically meaningful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient Point Cloud Graph Neural Networks Through Architectural Simplification. (arXiv:2108.06317v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1">Shyam A. Tailor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_R/0/1/0/all/0/1">Ren&#xe9; de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Azevedo_T/0/1/0/all/0/1">Tiago Azevedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1">Matthew Mattina</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1">Partha Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06317">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years graph neural network (GNN)-based approaches have become a
popular strategy for processing point cloud data, regularly achieving
state-of-the-art performance on a variety of tasks. To date, the research
community has primarily focused on improving model expressiveness, with
secondary thought given to how to design models that can run efficiently on
resource constrained mobile devices including smartphones or mixed reality
headsets. In this work we make a step towards improving the efficiency of these
models by making the observation that these GNN models are heavily limited by
the representational power of their first, feature extracting, layer. We find
that it is possible to radically simplify these models so long as the feature
extraction layer is retained with minimal degradation to model performance;
further, we discover that it is possible to improve performance overall on
ModelNet40 and S3DIS by improving the design of the feature extractor. Our
approach reduces memory consumption by 20$\times$ and latency by up to
9.9$\times$ for graph layers in models such as DGCNN; overall, we achieve
speed-ups of up to 4.5$\times$ and peak memory reductions of 72.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness testing of AI systems: A case study for traffic sign recognition. (arXiv:2108.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berghoff_C/0/1/0/all/0/1">Christian Berghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielik_P/0/1/0/all/0/1">Pavol Bielik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neu_M/0/1/0/all/0/1">Matthias Neu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsankov_P/0/1/0/all/0/1">Petar Tsankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Twickel_A/0/1/0/all/0/1">Arndt von Twickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06159">
                                    <div class="article-summary-box-inner">
                                        <span>In the last years, AI systems, in particular neural networks, have seen a
tremendous increase in performance, and they are now used in a broad range of
applications. Unlike classical symbolic AI systems, neural networks are trained
using large data sets and their inner structure containing possibly billions of
parameters does not lend itself to human interpretation. As a consequence, it
is so far not feasible to provide broad guarantees for the correct behaviour of
neural networks during operation if they process input data that significantly
differ from those seen during training. However, many applications of AI
systems are security- or safety-critical, and hence require obtaining
statements on the robustness of the systems when facing unexpected events,
whether they occur naturally or are induced by an attacker in a targeted way.
As a step towards developing robust AI systems for such applications, this
paper presents how the robustness of AI systems can be practically examined and
which methods and metrics can be used to do so. The robustness testing
methodology is described and analysed for the example use case of traffic sign
recognition in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Learning to Predict Engineering Technology Students&#x27; Success with Computer Aided Design. (arXiv:2108.05955v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1">Jasmine Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Perera_V/0/1/0/all/0/1">Viranga Perera</a>, <a href="http://arxiv.org/find/cs/1/au:+Magana_A/0/1/0/all/0/1">Alejandra J. Magana</a>, <a href="http://arxiv.org/find/cs/1/au:+Newell_B/0/1/0/all/0/1">Brittany Newell</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Kocsis_J/0/1/0/all/0/1">Jin Wei-Kocsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Seah_Y/0/1/0/all/0/1">Ying Ying Seah</a>, <a href="http://arxiv.org/find/cs/1/au:+Strimel_G/0/1/0/all/0/1">Greg J. Strimel</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Charles Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05955">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided design (CAD) programs are essential to engineering as they
allow for better designs through low-cost iterations. While CAD programs are
typically taught to undergraduate students as a job skill, such software can
also help students learn engineering concepts. A current limitation of CAD
programs (even those that are specifically designed for educational purposes)
is that they are not capable of providing automated real-time help to students.
To encourage CAD programs to build in assistance to students, we used data
generated from students using a free, open source CAD software called Aladdin
to demonstrate how student data combined with machine learning techniques can
predict how well a particular student will perform in a design task. We
challenged students to design a house that consumed zero net energy as part of
an introductory engineering technology undergraduate course. Using data from
128 students, along with the scikit-learn Python machine learning library, we
tested our models using both total counts of design actions and sequences of
design actions as inputs. We found that our models using early design sequence
actions are particularly valuable for prediction. Our logistic regression model
achieved a &gt;60% chance of predicting if a student would succeed in designing a
zero net energy house. Our results suggest that it would be feasible for
Aladdin to provide useful feedback to students when they are approximately
halfway through their design. Further improvements to these models could lead
to earlier predictions and thus provide students feedback sooner to enhance
their learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph2MDA: a multi-modal variational graph embedding model for predicting microbe-drug associations. (arXiv:2108.06338v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Deng_L/0/1/0/all/0/1">Lei Deng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_Y/0/1/0/all/0/1">Yibiao Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_X/0/1/0/all/0/1">Xuejun Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06338">
                                    <div class="article-summary-box-inner">
                                        <span>Accumulated clinical studies show that microbes living in humans interact
closely with human hosts, and get involved in modulating drug efficacy and drug
toxicity. Microbes have become novel targets for the development of
antibacterial agents. Therefore, screening of microbe-drug associations can
benefit greatly drug research and development. With the increase of microbial
genomic and pharmacological datasets, we are greatly motivated to develop an
effective computational method to identify new microbe-drug associations. In
this paper, we proposed a novel method, Graph2MDA, to predict microbe-drug
associations by using variational graph autoencoder (VGAE). We constructed
multi-modal attributed graphs based on multiple features of microbes and drugs,
such as molecular structures, microbe genetic sequences, and function
annotations. Taking as input the multi-modal attribute graphs, VGAE was trained
to learn the informative and interpretable latent representations of each node
and the whole graph, and then a deep neural network classifier was used to
predict microbe-drug associations. The hyperparameter analysis and model
ablation studies showed the sensitivity and robustness of our model. We
evaluated our method on three independent datasets and the experimental results
showed that our proposed method outperformed six existing state-of-the-art
methods. We also explored the meaningness of the learned latent representations
of drugs and found that the drugs show obvious clustering patterns that are
significantly consistent with drug ATC classification. Moreover, we conducted
case studies on two microbes and two drugs and found 75\%-95\% predicted
associations have been reported in PubMed literature. Our extensive performance
evaluations validated the effectiveness of our proposed method.\</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIND - Mainstream and Independent News Documents Corpus. (arXiv:2108.06249v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caled_D/0/1/0/all/0/1">Danielle Caled</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_P/0/1/0/all/0/1">Paula Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1">M&#xe1;rio J. Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06249">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents and characterizes MIND, a new Portuguese corpus comprised
of different types of articles collected from online mainstream and alternative
media sources, over a 10-month period. The articles in the corpus are organized
into five collections: facts, opinions, entertainment, satires, and conspiracy
theories. Throughout this paper, we explain how the data collection process was
conducted, and present a set of linguistic metrics that allow us to perform a
preliminary characterization of the texts included in the corpus. Also, we
deliver an analysis of the most frequent topics in the corpus, and discuss the
main differences and similarities among the collections considered. Finally, we
enumerate some tasks and applications that could benefit from this corpus, in
particular the ones (in)directly related to misinformation detection. Overall,
our contribution of a corpus and initial analysis are designed to support
future exploratory news studies, and provide a better insight into
misinformation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressive Sensing and Neural Networks from a Statistical Learning Perspective. (arXiv:2010.15658v4 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Behboodi_A/0/1/0/all/0/1">Arash Behboodi</a>, <a href="http://arxiv.org/find/math/1/au:+Rauhut_H/0/1/0/all/0/1">Holger Rauhut</a>, <a href="http://arxiv.org/find/math/1/au:+Schnoor_E/0/1/0/all/0/1">Ekkehard Schnoor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15658">
                                    <div class="article-summary-box-inner">
                                        <span>Various iterative reconstruction algorithms for inverse problems can be
unfolded as neural networks. Empirically, this approach has often led to
improved results, but theoretical guarantees are still scarce. While some
progress on generalization properties of neural networks have been made, great
challenges remain. In this chapter, we discuss and combine these topics to
present a generalization error analysis for a class of neural networks suitable
for sparse reconstruction from few linear measurements. The hypothesis class
considered is inspired by the classical iterative soft-thresholding algorithm
(ISTA). The neural networks in this class are obtained by unfolding iterations
of ISTA and learning some of the weights. Based on training samples, we aim at
learning the optimal network parameters via empirical risk minimization and
thereby the optimal network that reconstructs signals from their compressive
linear measurements. In particular, we may learn a sparsity basis that is
shared by all of the iterations/layers and thereby obtain a new approach for
dictionary learning. For this class of networks, we present a generalization
bound, which is based on bounding the Rademacher complexity of hypothesis
classes consisting of such deep networks via Dudley&#x27;s integral. Remarkably,
under realistic conditions, the generalization error scales only
logarithmically in the number of layers, and at most linear in number of
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Scalable Verification of Deep Reinforcement Learning. (arXiv:2105.11931v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1">Guy Amir</a>, <a href="http://arxiv.org/find/cs/1/au:+Schapira_M/0/1/0/all/0/1">Michael Schapira</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11931">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have gained significant popularity in recent
years, becoming the state of the art in a variety of domains. In particular,
deep reinforcement learning (DRL) has recently been employed to train DNNs that
realize control policies for various types of real-world systems. In this work,
we present the whiRL 2.0 tool, which implements a new approach for verifying
complex properties of interest for DRL systems. To demonstrate the benefits of
whiRL 2.0, we apply it to case studies from the communication networks domain
that have recently been used to motivate formal verification of DRL systems,
and which exhibit characteristics that are conducive for scalable verification.
We propose techniques for performing k-induction and semi-automated invariant
inference on such systems, and leverage these techniques for proving safety and
liveness properties that were previously impossible to verify due to the
scalability barriers of prior approaches. Furthermore, we show how our proposed
techniques provide insights into the inner workings and the generalizability of
DRL systems. whiRL 2.0 is publicly available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Models Improve Radiomics Reproducibility in Low Dose CTs: A Simulation Study. (arXiv:2104.15050v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chen_J/0/1/0/all/0/1">Junhua Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_C/0/1/0/all/0/1">Chong Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Traverso_A/0/1/0/all/0/1">Alberto Traverso</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhovannik_I/0/1/0/all/0/1">Ivan Zhovannik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dekker_A/0/1/0/all/0/1">Andre Dekker</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wee_L/0/1/0/all/0/1">Leonard Wee</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bermejo_I/0/1/0/all/0/1">Inigo Bermejo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15050">
                                    <div class="article-summary-box-inner">
                                        <span>Radiomics is an active area of research in medical image analysis, the low
reproducibility of radiomics has limited its applicability to clinical
practice. This issue is especially prominent when radiomic features are
calculated from noisy images, such as low dose computed tomography (CT) scans.
In this article, we investigate the possibility of improving the
reproducibility of radiomic features calculated on noisy CTs by using
generative models for denoising.One traditional denoising method - non-local
means - and two generative models - encoder-decoder networks (EDN) and
conditional generative adversarial networks (CGANs) - were selected as the test
models. We added noise to the sinograms of full dose CTs to mimic low dose CTs
with two different levels of noise: low-noise CT and high-noise CT. Models were
trained on high-noise CTs and used to denoise low-noise CTs without
re-training. We also test the performance of our model in real data, using
dataset of same-day repeat low dose CTs to assess the reproducibility of
radiomic features in denoised images. The EDN and the CGAN improved the
concordance correlation coefficients (CCC) of radiomic features for low-noise
images from 0.87 to 0.92 and for high-noise images from 0.68 to 0.92
respectively. Moreover, the EDN and the CGAN improved the test-retest
reliability of radiomic features (mean CCC increased from 0.89 to 0.94) based
on real low dose CTs. The results show that denoising using EDN and CGANs can
improve the reproducibility of radiomic features calculated on noisy CTs.
Moreover, images with different noise levels can be denoised to improve the
reproducibility using these models without re-training, as long as the noise
intensity is equal or lower than that in high-noise CTs. To the authors&#x27;
knowledge, this is the first effort to improve the reproducibility of radiomic
features calculated on low dose CT scans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedPara: Low-rank Hadamard Product Parameterization for Efficient Federated Learning. (arXiv:2108.06098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hyeon_Woo_N/0/1/0/all/0/1">Nam Hyeon-Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Bin_M/0/1/0/all/0/1">Moon Ye-Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1">Tae-Hyun Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06098">
                                    <div class="article-summary-box-inner">
                                        <span>To overcome the burdens on frequent model uploads and downloads during
federated learning (FL), we propose a communication-efficient
re-parameterization, FedPara. Our method re-parameterizes the model&#x27;s layers
using low-rank matrices or tensors followed by the Hadamard product. Different
from the conventional low-rank parameterization, our method is not limited to
low-rank constraints. Thereby, our FedPara has a larger capacity than the
low-rank one, even with the same number of parameters. It can achieve
comparable performance to the original models while requiring 2.8 to 10.1 times
lower communication costs than the original models, which is not achievable by
the traditional low-rank parameterization. Moreover, the efficiency can be
further improved by combining our method and other efficient FL techniques
because our method is compatible with others. We also extend our method to a
personalized FL application, pFedPara, which separates parameters into global
and local ones. We show that pFedPara outperforms competing personalized FL
methods with more than three times fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Split Learning. (arXiv:2108.06309v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Joongheon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghoon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Soyi Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Seehwan Yoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06309">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel split learning framework with multiple
end-systems in order to realize privacypreserving deep neural network
computation. In conventional split learning frameworks, deep neural network
computation is separated into multiple computing systems for hiding entire
network architectures. In our proposed framework, multiple computing
end-systems are sharing one centralized server in split learning computation,
where the multiple end-systems are with input and first hidden layers and the
centralized server is with the other hidden layers and output layer. This
framework, which is called as spatio-temporal split learning, is spatially
separated for gathering data from multiple end-systems and also temporally
separated due to the nature of split learning. Our performance evaluation
verifies that our proposed framework shows nearoptimal accuracy while
preserving data privacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted VAE: Variational and Targeted Learning for Causal Inference. (arXiv:2009.13472v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1">Matthew James Vowels</a>, <a href="http://arxiv.org/find/stat/1/au:+Camgoz_N/0/1/0/all/0/1">Necati Cihan Camgoz</a>, <a href="http://arxiv.org/find/stat/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13472">
                                    <div class="article-summary-box-inner">
                                        <span>Undertaking causal inference with observational data is incredibly useful
across a wide range of tasks including the development of medical treatments,
advertisements and marketing, and policy making. There are two significant
challenges associated with undertaking causal inference using observational
data: treatment assignment heterogeneity (i.e., differences between the treated
and untreated groups), and an absence of counterfactual data (i.e., not knowing
what would have happened if an individual who did get treatment, were instead
to have not been treated). We address these two challenges by combining
structured inference and targeted learning. In terms of structure, we factorize
the joint distribution into risk, confounding, instrumental, and miscellaneous
factors, and in terms of targeted learning, we apply a regularizer derived from
the influence curve in order to reduce residual bias. An ablation study is
undertaken, and an evaluation on benchmark datasets demonstrates that TVAE has
competitive and state of the art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEEA-Net: An Early Exit Evolutionary Neural Architecture Search. (arXiv:2108.06156v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Termritthikun_C/0/1/0/all/0/1">Chakkrit Termritthikun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamtsho_Y/0/1/0/all/0/1">Yeshi Jamtsho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ieamsaard_J/0/1/0/all/0/1">Jirarat Ieamsaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Muneesawang_P/0/1/0/all/0/1">Paisarn Muneesawang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Ivan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06156">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this research were to search for Convolutional Neural Network
(CNN) architectures, suitable for an on-device processor with limited computing
resources, performing at substantially lower Network Architecture Search (NAS)
costs. A new algorithm entitled an Early Exit Population Initialisation (EE-PI)
for Evolutionary Algorithm (EA) was developed to achieve both goals. The EE-PI
reduces the total number of parameters in the search process by filtering the
models with fewer parameters than the maximum threshold. It will look for a new
model to replace those models with parameters more than the threshold. Thereby,
reducing the number of parameters, memory usage for model storage and
processing time while maintaining the same performance or accuracy. The search
time was reduced to 0.52 GPU day. This is a huge and significant achievement
compared to the NAS of 4 GPU days achieved using NSGA-Net, 3,150 GPU days by
the AmoebaNet model, and the 2,000 GPU days by the NASNet model. As well, Early
Exit Evolutionary Algorithm networks (EEEA-Nets) yield network architectures
with minimal error and computational cost suitable for a given dataset as a
class of network algorithms. Using EEEA-Net on CIFAR-10, CIFAR-100, and
ImageNet datasets, our experiments showed that EEEA-Net achieved the lowest
error rate among state-of-the-art NAS models, with 2.46% for CIFAR-10, 15.02%
for CIFAR-100, and 23.8% for ImageNet dataset. Further, we implemented this
image recognition architecture for other tasks, such as object detection,
semantic segmentation, and keypoint detection tasks, and, in our experiments,
EEEA-Net-C2 outperformed MobileNet-V3 on all of these various tasks. (The
algorithm code is available at https://github.com/chakkritte/EEEA-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information-theoretic Perspective of Hierarchical Clustering. (arXiv:2108.06036v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yicheng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_B/0/1/0/all/0/1">Bingchen Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06036">
                                    <div class="article-summary-box-inner">
                                        <span>A combinatorial cost function for hierarchical clustering was introduced by
Dasgupta \cite{dasgupta2016cost}. It has been generalized by Cohen-Addad et al.
\cite{cohen2019hierarchical} to a general form named admissible function. In
this paper, we investigate hierarchical clustering from the
\emph{information-theoretic} perspective and formulate a new objective
function. We also establish the relationship between these two perspectives. In
algorithmic aspect, we get rid of the traditional top-down and bottom-up
frameworks, and propose a new one to stratify the \emph{sparsest} level of a
cluster tree recursively in guide with our objective function. For practical
use, our resulting cluster tree is not binary. Our algorithm called HCSE
outputs a $k$-level cluster tree by a novel and interpretable mechanism to
choose $k$ automatically without any hyper-parameter. Our experimental results
on synthetic datasets show that HCSE has a great advantage in finding the
intrinsic number of hierarchies, and the results on real datasets show that
HCSE also achieves competitive costs over the popular algorithms LOUVAIN and
HLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Overview of Machine Learning-aided Optical Performance Monitoring Techniques. (arXiv:2107.07338v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tizikara_D/0/1/0/all/0/1">Dativa K. Tizikara</a>, <a href="http://arxiv.org/find/cs/1/au:+Serugunda_J/0/1/0/all/0/1">Jonathan Serugunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Katumba_A/0/1/0/all/0/1">Andrew Katumba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07338">
                                    <div class="article-summary-box-inner">
                                        <span>Future communication systems are faced with increased demand for high
capacity, dynamic bandwidth, reliability and heterogeneous traffic. To meet
these requirements, networks have become more complex and thus require new
design methods and monitoring techniques, as they evolve towards becoming
autonomous. Machine learning has come to the forefront in recent years as a
promising technology to aid in this evolution. Optical fiber communications can
already provide the high capacity required for most applications, however,
there is a need for increased scalability and adaptability to changing user
demands and link conditions. Accurate performance monitoring is an integral
part of this transformation. In this paper we review optical performance
monitoring techniques where machine learning algorithms have been applied.
Moreover, since alot of OPM depends on knowledge of the signal type, we also
review work for modulation format recognition and bitrate identification. We
additionally briefly introduce a neuromorphic approach to OPM as an emerging
technique that has only recently been applied to this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Iterative Graph Self-Distillation. (arXiv:2010.12609v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric P. Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12609">
                                    <div class="article-summary-box-inner">
                                        <span>How to discriminatively vectorize graphs is a fundamental challenge that
attracts increasing attentions in recent years. Inspired by the recent success
of unsupervised contrastive learning, we aim to learn graph-level
representation in an unsupervised manner. Specifically, we propose a novel
unsupervised graph learning paradigm called Iterative Graph Self-Distillation
(IGSD) which iteratively performs the teacher-student distillation with graph
augmentations. Different from conventional knowledge distillation, IGSD
constructs the teacher with an exponential moving average of the student model
and distills the knowledge of itself. The intuition behind IGSD is to predict
the teacher network representation of the graph pairs under different augmented
views. As a natural extension, we also apply IGSD to semi-supervised scenarios
by jointly regularizing the network with both supervised and unsupervised
contrastive loss. Finally, we show that finetuning the IGSD-trained models with
self-training can further improve the graph representation power. Empirically,
we achieve significant and consistent performance gain on various graph
datasets in both unsupervised and semi-supervised settings, which well
validates the superiority of IGSD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast model-based clustering of partial records. (arXiv:2103.16336v5 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Goren_E/0/1/0/all/0/1">Emily M. Goren</a>, <a href="http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1">Ranjan Maitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16336">
                                    <div class="article-summary-box-inner">
                                        <span>Partially recorded data are frequently encountered in many applications and
usually clustered by first removing incomplete cases or features with missing
values, or by imputing missing values, followed by application of a clustering
algorithm to the resulting altered dataset. Here, we develop clustering
methodology through a model-based approach using the marginal density for the
observed values, assuming a finite mixture model of multivariate $t$
distributions. We compare our approximate algorithm to the corresponding full
expectation-maximization (EM) approach that considers the missing values in the
incomplete data set and makes a missing at random (MAR) assumption, as well as
case deletion and imputation methods. Since only the observed values are
utilized, our approach is computationally more efficient than imputation or
full EM. Simulation studies demonstrate that our approach has favorable
recovery of the true cluster partition compared to case deletion and imputation
under various missingness mechanisms, and is at least competitive with the full
EM approach, even when MAR assumptions are violated. Our methodology is
demonstrated on a problem of clustering gamma-ray bursts and is implemented at
https://github.com/emilygoren/MixtClust.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training. (arXiv:2108.06209v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yu-An Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Chung-Cheng Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">James Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Ruoming Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06209">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the success of masked language modeling~(MLM) in pre-training
natural language processing models, we propose w2v-BERT that explores MLM for
self-supervised speech representation learning. w2v-BERT is a framework that
combines contrastive learning and MLM, where the former trains the model to
discretize input continuous speech signals into a finite set of discriminative
speech tokens, and the latter trains the model to learn contextualized speech
representations via solving a masked prediction task consuming the discretized
tokens. In contrast to existing MLM-based speech pre-training frameworks such
as HuBERT, which relies on an iterative re-clustering and re-training process,
or vq-wav2vec, which concatenates two separately trained modules, w2v-BERT can
be optimized in an end-to-end fashion by solving the two self-supervised
tasks~(the contrastive task and MLM) simultaneously. Our experiments show that
w2v-BERT achieves competitive results compared to current state-of-the-art
pre-trained models on the LibriSpeech benchmarks when using the Libri-Light~60k
corpus as the unsupervised data. In particular, when compared to published
models such as conformer-based wav2vec~2.0 and HuBERT, our model shows~5\%
to~10\% relative WER reduction on the test-clean and test-other subsets. When
applied to the Google&#x27;s Voice Search traffic dataset, w2v-BERT outperforms our
internal conformer-based wav2vec~2.0 by more than~30\% relatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Structured Dynamic Sparse Pre-Training of BERT. (arXiv:2108.06277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06277">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying algorithms for computational efficient unsupervised training of
large language models is an important and active area of research. In this
work, we develop and study a straightforward, dynamic always-sparse
pre-training approach for BERT language modeling task, which leverages periodic
compression steps based on magnitude pruning followed by random parameter
re-allocation. This approach enables us to achieve Pareto improvements in terms
of the number of floating-point operations (FLOPs) over statically sparse and
dense models across a broad spectrum of network sizes. Furthermore, we
demonstrate that training remains FLOP-efficient when using coarse-grained
block sparsity, making it particularly promising for efficient execution on
modern hardware accelerators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principal Component Analysis Applied to Gradient Fields in Band Gap Optimization Problems for Metamaterials. (arXiv:2104.02588v6 [cs.CE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gnecco_G/0/1/0/all/0/1">Giorgio Gnecco</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacigalupo_A/0/1/0/all/0/1">Andrea Bacigalupo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fantoni_F/0/1/0/all/0/1">Francesca Fantoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Selvi_D/0/1/0/all/0/1">Daniela Selvi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02588">
                                    <div class="article-summary-box-inner">
                                        <span>A promising technique for the spectral design of acoustic metamaterials is
based on the formulation of suitable constrained nonlinear optimization
problems. Unfortunately, the straightforward application of classical
gradient-based iterative optimization algorithms to the numerical solution of
such problems is typically highly demanding, due to the complexity of the
underlying physical models. Nevertheless, supervised machine learning
techniques can reduce such a computational effort, e.g., by replacing the
original objective functions of such optimization problems with more-easily
computable approximations. In this framework, the present article describes the
application of a related unsupervised machine learning technique, namely,
principal component analysis, to approximate the gradient of the objective
function of a band gap optimization problem for an acoustic metamaterial, with
the aim of making the successive application of a gradient-based iterative
optimization algorithm faster. Numerical results show the effectiveness of the
proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets, often with better accuracy and fewer
parameters. Our model eliminates the requirement for class token and positional
embeddings through a novel sequence pooling strategy and the use of
convolution/s. It is flexible in terms of model size, and can have as little as
0.28M parameters while achieving good results. Our model can reach 98.00%
accuracy when training from scratch on CIFAR-10, which is a significant
improvement over previous Transformer based models. It also outperforms many
modern CNN based approaches, such as ResNet, and even some recent NAS-based
approaches, such as Proxyless-NAS. Our simple and compact design democratizes
transformers by making them accessible to those with limited computing
resources and/or dealing with small datasets. Our method also works on larger
datasets, such as ImageNet (82.71% accuracy with 29% parameters of ViT), and
NLP tasks as well. Our code and pre-trained models are publicly available at
https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-Based Value Functions. (arXiv:2006.09226v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faccio_F/0/1/0/all/0/1">Francesco Faccio</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirsch_L/0/1/0/all/0/1">Louis Kirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09226">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms
learn value functions of a single target policy. However, when value functions
are updated to track the learned policy, they forget potentially useful
information about old policies. We introduce a class of value functions called
Parameter-Based Value Functions (PBVFs) whose inputs include the policy
parameters. They can generalize across different policies. PBVFs can evaluate
the performance of any policy given a state, a state-action pair, or a
distribution over the RL agent&#x27;s initial states. First we show how PBVFs yield
novel off-policy policy gradient theorems. Then we derive off-policy
actor-critic algorithms based on PBVFs trained by Monte Carlo or Temporal
Difference methods. We show how learned PBVFs can zero-shot learn new policies
that outperform any policy seen during training. Finally our algorithms are
evaluated on a selection of discrete and continuous control tasks using shallow
policies and deep neural networks. Their performance is comparable to
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMDNet: Learning a Probabilistic Relaxation of Discrete Variables for Soft Detection with Low Complexity. (arXiv:2102.12756v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Beck_E/0/1/0/all/0/1">Edgar Beck</a>, <a href="http://arxiv.org/find/eess/1/au:+Bockelmann_C/0/1/0/all/0/1">Carsten Bockelmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Dekorsy_A/0/1/0/all/0/1">Armin Dekorsy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12756">
                                    <div class="article-summary-box-inner">
                                        <span>Following the great success of Machine Learning (ML), especially Deep Neural
Networks (DNNs), in many research domains in 2010s, several ML-based approaches
were proposed for detection in large inverse linear problems, e.g., massive
MIMO systems. The main motivation behind is that the complexity of Maximum
A-Posteriori (MAP) detection grows exponentially with system dimensions.
Instead of using DNNs, essentially being a black-box, we take a slightly
different approach and introduce a probabilistic Continuous relaxation of
disCrete variables to MAP detection. Enabling close approximation and
continuous optimization, we derive an iterative detection algorithm: Concrete
MAP Detection (CMD). Furthermore, extending CMD by the idea of deep unfolding
into CMDNet, we allow for (online) optimization of a small number of parameters
to different working points while limiting complexity. In contrast to recent
DNN-based approaches, we select the optimization criterion and output of CMDNet
based on information theory and are thus able to learn approximate
probabilities of the individual optimal detector. This is crucial for soft
decoding in today&#x27;s communication systems. Numerical simulation results in MIMO
systems reveal CMDNet to feature a promising accuracy complexity trade-off
compared to State of the Art. Notably, we demonstrate CMDNet&#x27;s soft outputs to
be reliable for decoders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning. (arXiv:2108.06266v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brunke_L/0/1/0/all/0/1">Lukas Brunke</a>, <a href="http://arxiv.org/find/cs/1/au:+Greeff_M/0/1/0/all/0/1">Melissa Greeff</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_A/0/1/0/all/0/1">Adam W. Hall</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhaocong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Siqi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Panerati_J/0/1/0/all/0/1">Jacopo Panerati</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoellig_A/0/1/0/all/0/1">Angela P. Schoellig</a> (University of Toronto Institute for Aerospace Studies, University of Toronto Robotics Institute, Vector Institute for Artificial Intelligence)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06266">
                                    <div class="article-summary-box-inner">
                                        <span>The last half-decade has seen a steep rise in the number of contributions on
safe learning methods for real-world robotic deployments from both the control
and reinforcement learning communities. This article provides a concise but
holistic review of the recent advances made in using machine learning to
achieve safe decision making under uncertainties, with a focus on unifying the
language and frameworks used in control theory and reinforcement learning
research. Our review includes: learning-based control approaches that safely
improve performance by learning the uncertain dynamics, reinforcement learning
approaches that encourage safety or robustness, and methods that can formally
certify the safety of a learned control policy. As data- and learning-based
robot control methods continue to gain traction, researchers must understand
when and how to best leverage them in real-world scenarios where safety is
imperative, such as when operating in close proximity to humans. We highlight
some of the open challenges that will drive the field of robot learning in the
coming years, and emphasize the need for realistic physics-based benchmarks to
facilitate fair comparisons between control and reinforcement learning
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Subspace Mixture Models for Interpretable Anomaly Detection. (arXiv:2108.06283v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Savkli_C/0/1/0/all/0/1">Cetin Savkli</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_C/0/1/0/all/0/1">Catherine Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06283">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new subspace-based method to construct probabilistic models for
high-dimensional data and highlight its use in anomaly detection. The approach
is based on a statistical estimation of probability density using densities of
random subspaces combined with geometric averaging. In selecting random
subspaces, equal representation of each attribute is used to ensure correct
statistical limits. Gaussian mixture models (GMMs) are used to create the
probability densities for each subspace with techniques included to mitigate
singularities allowing for the ability to handle both numerical and categorial
attributes. The number of components for each GMM is determined automatically
through Bayesian information criterion to prevent overfitting. The proposed
algorithm attains competitive AUC scores compared with prominent algorithms
against benchmark anomaly detection datasets with the added benefits of being
simple, scalable, and interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-shot Transfer Learning for Population Mapping. (arXiv:2108.06228v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_E/0/1/0/all/0/1">Erzhuo Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06228">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained population distribution data is of great importance for many
applications, e.g., urban planning, traffic scheduling, epidemic modeling, and
risk control. However, due to the limitations of data collection, including
infrastructure density, user privacy, and business security, such fine-grained
data is hard to collect and usually, only coarse-grained data is available.
Thus, obtaining fine-grained population distribution from coarse-grained
distribution becomes an important problem. To complete this task, existing
methods mainly rely on sufficient fine-grained ground truth for training, which
is not often available. This limits the applications of these methods and
brings the necessity to transfer knowledge from data-sufficient cities to
data-scarce cities.

In knowledge transfer scenario, we employ single reference fine-grained
ground truth in the target city as the ground truth to inform the large-scale
urban structure and support the knowledge transfer in the target city. By this
approach, we transform the fine-grained population mapping problem into a
one-shot transfer learning problem for population mapping task.

In this paper, we propose a one-shot transfer learning framework, PSRNet, to
transfer spatial-temporal knowledge across cities in fine-grained population
mapping task from the view of network structure, data, and optimization.
Experiments on real-life datasets of 4 cities demonstrate that PSRNet has
significant advantages over 8 baselines by reducing RMSE and MAE for more than
25%. Our code and datasets are released in Github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Operator Splitting View of Federated Learning. (arXiv:2108.05974v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malekmohammadi_S/0/1/0/all/0/1">Saber Malekmohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaloudegi_K/0/1/0/all/0/1">Kiarash Shaloudegi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zeou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaoliang Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05974">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past few years, the federated learning ($\texttt{FL}$) community has
witnessed a proliferation of new $\texttt{FL}$ algorithms. However, our
understating of the theory of $\texttt{FL}$ is still fragmented, and a
thorough, formal comparison of these algorithms remains elusive. Motivated by
this gap, we show that many of the existing $\texttt{FL}$ algorithms can be
understood from an operator splitting point of view. This unification allows us
to compare different algorithms with ease, to refine previous convergence
results and to uncover new algorithmic variants. In particular, our analysis
reveals the vital role played by the step size in $\texttt{FL}$ algorithms. The
unification also leads to a streamlined and economic way to accelerate
$\texttt{FL}$ algorithms, without incurring any communication overhead. We
perform numerical experiments on both convex and nonconvex models to validate
our findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarially Robust Low Dimensional Representations. (arXiv:1911.13268v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1">Pranjal Awasthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatziafratis_V/0/1/0/all/0/1">Vaggos Chatziafratis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijayaraghavan_A/0/1/0/all/0/1">Aravindan Vijayaraghavan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.13268">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning systems are vulnerable to small perturbations made to
inputs either at test time or at training time. This has received much recent
interest on the empirical front due to applications where reliability and
security are critical. However, theoretical understanding of algorithms that
are robust to adversarial perturbations is limited.

In this work we focus on Principal Component Analysis (PCA), a ubiquitous
algorithmic primitive in machine learning. We formulate a natural robust
variant of PCA where the goal is to find a low dimensional subspace to
represent the given data with minimum projection error, that is in addition
robust to small perturbations measured in $\ell_q$ norm (say $q&#x3D;\infty$).
Unlike PCA which is solvable in polynomial time, our formulation is
computationally intractable to optimize as it captures a variant of the
well-studied sparse PCA objective as a special case. We show the following
results:

-Polynomial time algorithm that is constant factor competitive in the
worst-case with respect to the best subspace, in terms of the projection error
and the robustness criterion.

-We show that our algorithmic techniques can also be made robust to
adversarial training-time perturbations, in addition to yielding
representations that are robust to adversarial perturbations at test time.
Specifically, we design algorithms for a strong notion of training-time
perturbations, where every point is adversarially perturbed up to a specified
amount.

-We illustrate the broad applicability of our algorithmic techniques in
addressing robustness to adversarial perturbations, both at training time and
test time. In particular, our adversarially robust PCA primitive leads to
computationally efficient and robust algorithms for both unsupervised and
supervised learning problems such as clustering and learning adversarially
robust classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Fairness-Aware Learning with Imbalanced Data Streams. (arXiv:2108.06231v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_V/0/1/0/all/0/1">Vasileios Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06231">
                                    <div class="article-summary-box-inner">
                                        <span>Data-driven learning algorithms are employed in many online applications, in
which data become available over time, like network monitoring, stock price
prediction, job applications, etc. The underlying data distribution might
evolve over time calling for model adaptation as new instances arrive and old
instances become obsolete. In such dynamic environments, the so-called data
streams, fairness-aware learning cannot be considered as a one-off requirement,
but rather it should comprise a continual requirement over the stream. Recent
fairness-aware stream classifiers ignore the problem of class imbalance, which
manifests in many real-life applications, and mitigate discrimination mainly
because they &quot;reject&quot; minority instances at large due to their inability to
effectively learn all classes.

In this work, we propose \ours, an online fairness-aware approach that
maintains a valid and fair classifier over the stream. \ours~is an online
boosting approach that changes the training distribution in an online fashion
by monitoring stream&#x27;s class imbalance and tweaks its decision boundary to
mitigate discriminatory outcomes over the stream. Experiments on 8 real-world
and 1 synthetic datasets from different domains with varying class imbalance
demonstrate the superiority of our method over state-of-the-art fairness-aware
stream approaches with a range (relative) increase [11.2\%-14.2\%] in balanced
accuracy, [22.6\%-31.8\%] in gmean, [42.5\%-49.6\%] in recall, [14.3\%-25.7\%]
in kappa and [89.4\%-96.6\%] in statistical parity (fairness).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recommending Insurance products by using Users&#x27; Sentiments. (arXiv:2108.06210v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parasrampuria_R/0/1/0/all/0/1">Rohan Parasrampuria</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Ayan Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Suchandra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dhrubasish Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06210">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s tech-savvy world every industry is trying to formulate methods for
recommending products by combining several techniques and algorithms to form a
pool that would bring forward the most enhanced models for making the
predictions. Building on these lines is our paper focused on the application of
sentiment analysis for recommendation in the insurance domain. We tried
building the following Machine Learning models namely, Logistic Regression,
Multinomial Naive Bayes, and the mighty Random Forest for analyzing the
polarity of a given feedback line given by a customer. Then we used this
polarity along with other attributes like Age, Gender, Locality, Income, and
the list of other products already purchased by our existing customers as input
for our recommendation model. Then we matched the polarity score along with the
user&#x27;s profiles and generated the list of insurance products to be recommended
in descending order. Despite our model&#x27;s simplicity and the lack of the key
data sets, the results seemed very logical and realistic. So, by developing the
model with more enhanced methods and with access to better and true data
gathered from an insurance industry may be the sector could be very well
benefitted from the amalgamation of sentiment analysis with a recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDE constraints on smooth hierarchical functions computed by neural networks. (arXiv:2005.08859v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Filom_K/0/1/0/all/0/1">Khashayar Filom</a>, <a href="http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1">Konrad Paul Kording</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhoodi_R/0/1/0/all/0/1">Roozbeh Farhoodi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08859">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are versatile tools for computation, having the ability to
approximate a broad range of functions. An important problem in the theory of
deep neural networks is expressivity; that is, we want to understand the
functions that are computable by a given network. We study real infinitely
differentiable (smooth) hierarchical functions implemented by feedforward
neural networks via composing simpler functions in two cases:

1) each constituent function of the composition has fewer inputs than the
resulting function;

2) constituent functions are in the more specific yet prevalent form of a
non-linear univariate function (e.g. tanh) applied to a linear multivariate
function.

We establish that in each of these regimes there exist non-trivial algebraic
partial differential equations (PDEs), which are satisfied by the computed
functions. These PDEs are purely in terms of the partial derivatives and are
dependent only on the topology of the network. For compositions of polynomial
functions, the algebraic PDEs yield non-trivial equations (of degrees dependent
only on the architecture) in the ambient polynomial space that are satisfied on
the associated functional varieties. Conversely, we conjecture that such PDE
constraints, once accompanied by appropriate non-singularity conditions and
perhaps certain inequalities involving partial derivatives, guarantee that the
smooth function under consideration can be represented by the network. The
conjecture is verified in numerous examples including the case of tree
architectures which are of neuroscientific interest. Our approach is a step
toward formulating an algebraic description of functional spaces associated
with specific neural networks, and may provide new, useful tools for
constructing neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural ODE to model and prognose thermoacoustic instability. (arXiv:2106.12758v2 [physics.flu-dyn] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Dhadphale_J/0/1/0/all/0/1">Jayesh Dhadphale</a>, <a href="http://arxiv.org/find/physics/1/au:+Unni_V/0/1/0/all/0/1">Vishnu R. Unni</a>, <a href="http://arxiv.org/find/physics/1/au:+Saha_A/0/1/0/all/0/1">Abhishek Saha</a>, <a href="http://arxiv.org/find/physics/1/au:+Sujith_R/0/1/0/all/0/1">R. I. Sujith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12758">
                                    <div class="article-summary-box-inner">
                                        <span>In reacting flow systems, thermoacoustic instability characterized by high
amplitude pressure fluctuations, is driven by a positive coupling between the
unsteady heat release rate and the acoustic field of the combustor. When the
underlying flow is turbulent, as a control parameter of the system is varied
and the system approach thermoacoustic instability, the acoustic pressure
oscillations synchronize with heat release rate oscillations. Consequently,
during the onset of thermoacoustic instability in turbulent combustors, the
system dynamics transition from chaotic oscillations to periodic oscillations
via a state of intermittency. Thermoacoustic systems are traditionally modeled
by coupling the model for the unsteady heat source and the acoustic subsystem,
each estimated independently. The response of the unsteady heat source, the
flame, to acoustic fluctuations are characterized by introducing external
unsteady forcing. This necessitates a powerful excitation module to obtain the
nonlinear response of the flame to acoustic perturbations. Instead of
characterizing individual subsystems, we introduce a neural ordinary
differential equation (neural ODE) framework to model the thermoacoustic system
as a whole. The neural ODE model for the thermoacoustic system uses time series
of the heat release rate and the pressure fluctuations, measured simultaneously
without introducing any external perturbations, to model their coupled
interaction. Further, we use the parameters of neural ODE to define an anomaly
measure that represents the proximity of system dynamics to limit cycle
oscillations and thus provide an early warning signal for the onset of
thermoacoustic instability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preparation of Many-body Ground States by Time Evolution with Variational Microscopic Magnetic Fields and Incomplete Interactions. (arXiv:2106.01779v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Lu_Y/0/1/0/all/0/1">Ying Lu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_Y/0/1/0/all/0/1">Yue-Min Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1">Peng-Fei Zhou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01779">
                                    <div class="article-summary-box-inner">
                                        <span>State preparation is of fundamental importance in quantum physics, which can
be realized by constructing the quantum circuit as a unitary that transforms
the initial state to the target, or implementing a quantum control protocol to
evolve to the target state with a designed Hamiltonian. In this work, we study
the latter on quantum many-body systems by the time evolution with fixed
couplings and variational magnetic fields. In specific, we consider to prepare
the ground states of the Hamiltonians containing certain interactions that are
missing in the Hamiltonians for the time evolution. An optimization method is
proposed to optimize the magnetic fields by &quot;fine-graining&quot; the discretization
of time, in order to gain high precision and stability. The back propagation
technique is utilized to obtain the gradients of the fields against the
logarithmic fidelity. Our method is tested on preparing the ground state of
Heisenberg chain with the time evolution by the XY and Ising interactions, and
its performance surpasses two baseline methods that use local and global
optimization strategies, respectively. Our work can be applied and generalized
to other quantum models such as those defined on higher dimensional lattices.
It enlightens to reduce the complexity of the required interactions for
implementing quantum control or other tasks in quantum information and
computation by means of optimizing the magnetic fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient active learning of sparse halfspaces with arbitrary bounded noise. (arXiv:2002.04840v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jie Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1">Pranjal Awasthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04840">
                                    <div class="article-summary-box-inner">
                                        <span>We study active learning of homogeneous $s$-sparse halfspaces in
$\mathbb{R}^d$ under the setting where the unlabeled data distribution is
isotropic log-concave and each label is flipped with probability at most $\eta$
for a parameter $\eta \in \big[0, \frac12\big)$, known as the bounded noise.
Even in the presence of mild label noise, i.e. $\eta$ is a small constant, this
is a challenging problem and only recently have label complexity bounds of the
form $\tilde{O}\big(s \cdot \mathrm{polylog}(d, \frac{1}{\epsilon})\big)$ been
established in [Zhang, 2018] for computationally efficient algorithms. In
contrast, under high levels of label noise, the label complexity bounds
achieved by computationally efficient algorithms are much worse: the best known
result of [Awasthi et al., 2016] provides a computationally efficient algorithm
with label complexity $\tilde{O}\big((\frac{s \ln
d}{\epsilon})^{2^{\mathrm{poly}(1/(1-2\eta))}} \big)$, which is label-efficient
only when the noise rate $\eta$ is a fixed constant. In this work, we
substantially improve on it by designing a polynomial time algorithm for active
learning of $s$-sparse halfspaces, with a label complexity of
$\tilde{O}\big(\frac{s}{(1-2\eta)^4} \mathrm{polylog} (d, \frac 1 \epsilon)
\big)$. This is the first efficient algorithm with label complexity polynomial
in $\frac{1}{1-2\eta}$ in this setting, which is label-efficient even for
$\eta$ arbitrarily close to $\frac12$. Our active learning algorithm and its
theoretical guarantees also immediately translate to new state-of-the-art label
and sample complexity results for full-dimensional active and passive halfspace
learning under arbitrary bounded noise. The key insight of our algorithm and
analysis is a new interpretation of online learning regret inequalities, which
may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech. (arXiv:2106.14736v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonell_P/0/1/0/all/0/1">Patrik Jonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14736">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework for gesture generation, aiming to allow
data-driven approaches to produce more semantically rich gestures. Our approach
first predicts whether to gesture, followed by a prediction of the gesture
properties. Those properties are then used as conditioning for a modern
probabilistic gesture-generation model capable of high-quality output. This
empowers the approach to generate gestures that are both diverse and
representational. Follow-ups and more information can be found on the project
page: https://svito-zar.github.io/speech2properties2gestures/ .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Music Performance Assessment with Contrastive Learning. (arXiv:2108.01711v1 [cs.SD] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1">Pavan Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerch_A/0/1/0/all/0/1">Alexander Lerch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Several automatic approaches for objective music performance assessment (MPA)
have been proposed in the past, however, existing systems are not yet capable
of reliably predicting ratings with the same accuracy as professional judges.
This study investigates contrastive learning as a potential method to improve
existing MPA systems. Contrastive learning is a widely used technique in
representation learning to learn a structured latent space capable of
separately clustering multiple classes. It has been shown to produce state of
the art results for image-based classification problems. We introduce a
weighted contrastive loss suitable for regression tasks applied to a
convolutional neural network and show that contrastive loss results in
performance gains in regression tasks for MPA. Our results show that
contrastive-based methods are able to match and exceed SoTA performance for MPA
regression tasks by creating better class clusters within the latent space of
the neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Jasmine: A New Active Learning Approach to Combat Cybercrime. (arXiv:2108.06238v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klein_J/0/1/0/all/0/1">Jan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhulai_S/0/1/0/all/0/1">Sandjai Bhulai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1">Mark Hoogendoorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_R/0/1/0/all/0/1">Rob van der Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06238">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past decade, the advent of cybercrime has accelarated the research
on cybersecurity. However, the deployment of intrusion detection methods falls
short. One of the reasons for this is the lack of realistic evaluation
datasets, which makes it a challenge to develop techniques and compare them.
This is caused by the large amounts of effort it takes for a cyber analyst to
classify network connections. This has raised the need for methods (i) that can
learn from small sets of labeled data, (ii) that can make predictions on large
sets of unlabeled data, and (iii) that request the label of only specially
selected unlabeled data instances. Hence, Active Learning (AL) methods are of
interest. These approaches choose speci?fic unlabeled instances by a query
function that are expected to improve overall classi?cation performance. The
resulting query observations are labeled by a human expert and added to the
labeled set.

In this paper, we propose a new hybrid AL method called Jasmine. Firstly, it
determines how suitable each observation is for querying, i.e., how likely it
is to enhance classi?cation. These properties are the uncertainty score and
anomaly score. Secondly, Jasmine introduces dynamic updating. This allows the
model to adjust the balance between querying uncertain, anomalous and randomly
selected observations. To this end, Jasmine is able to learn the best query
strategy during the labeling process. This is in contrast to the other AL
methods in cybersecurity that all have static, predetermined query functions.
We show that dynamic updating, and therefore Jasmine, is able to consistently
obtain good and more robust results than querying only uncertainties, only
anomalies or a ?fixed combination of the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven advice for interpreting local and global model predictions in bioinformatics problems. (arXiv:2108.06201v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Loecher_M/0/1/0/all/0/1">Markus Loecher</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06201">
                                    <div class="article-summary-box-inner">
                                        <span>Tree-based algorithms such as random forests and gradient boosted trees
continue to be among the most popular and powerful machine learning models used
across multiple disciplines. The conventional wisdom of estimating the impact
of a feature in tree based models is to measure the \textit{node-wise reduction
of a loss function}, which (i) yields only global importance measures and (ii)
is known to suffer from severe biases. Conditional feature contributions (CFCs)
provide \textit{local}, case-by-case explanations of a prediction by following
the decision path and attributing changes in the expected output of the model
to each feature along the path. However, Lundberg et al. pointed out a
potential bias of CFCs which depends on the distance from the root of a tree.
The by now immensely popular alternative, SHapley Additive exPlanation (SHAP)
values appear to mitigate this bias but are computationally much more
expensive. Here we contribute a thorough comparison of the explanations
computed by both methods on a set of 164 publicly available classification
problems in order to provide data-driven algorithm recommendations to current
researchers. For random forests, we find extremely high similarities and
correlations of both local and global SHAP values and CFC scores, leading to
very similar rankings and interpretations. Analogous conclusions hold for the
fidelity of using global feature importance scores as a proxy for the
predictive power associated with each feature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Recommendation-cum-Reminder System. (arXiv:2108.06206v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Rohan Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_M/0/1/0/all/0/1">Maheep Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurya_C/0/1/0/all/0/1">Chandresh Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1">Shitala Prasad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06206">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent recommendation and reminder systems are the need of the
fast-pacing life. Current intelligent systems such as Siri, Google Assistant,
Microsoft Cortona, etc., have limited capability. For example, if you want to
wake up at 6 am because you have an upcoming trip, you have to set the alarm
manually. Besides, these systems do not recommend or remind what else to carry,
such as carrying an umbrella during a likely rain. The present work proposes a
system that takes an email as input and returns a recommendation-cumreminder
list. As a first step, we parse the emails, recognize the entities using named
entity recognition (NER). In the second step, information retrieval over the
web is done to identify nearby places, climatic conditions, etc. Imperative
sentences from the reviews of all places are extracted and passed to the object
extraction module. The main challenge lies in extracting the objects (items) of
interest from the review. To solve it, a modified Machine Reading
Comprehension-NER (MRC-NER) model is trained to tag objects of interest by
formulating annotation rules as a query. The objects so found are recommended
to the user one day in advance. The final reminder list of objects is pruned by
our proposed model for tracking objects kept during the &quot;packing activity.&quot;
Eventually, when the user leaves for the event/trip, an alert is sent
containing the reminding list items. Our approach achieves superior performance
compared to several baselines by as much as 30% on recall and 10% on precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sherman_U/0/1/0/all/0/1">Uri Sherman</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03803">
                                    <div class="article-summary-box-inner">
                                        <span>We study a variant of online convex optimization where the player is
permitted to switch decisions at most $S$ times in expectation throughout $T$
rounds. Similar problems have been addressed in prior work for the discrete
decision set setting, and more recently in the continuous setting but only with
an adaptive adversary. In this work, we aim to fill the gap and present
computationally efficient algorithms in the more prevalent oblivious setting,
establishing a regret bound of $O(T/S)$ for general convex losses and
$\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic
i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches
with only a multiplicative $\log T$ factor overhead in its regret in both the
general and strongly convex settings. Finally, we complement our algorithms
with lower bounds that match our upper bounds in some of the cases we consider.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1">Greyson Gerhard-Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1">Raviteja Anantha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1">Srinivas Chappidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1">Bj&#xf6;rn Hoffmeister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06329">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work building open-domain chatbots has demonstrated that increasing
model size improves performance. On the other hand, latency and connectivity
considerations dictate the move of digital assistants on the device. Giving a
digital assistant like Siri, Alexa, or Google Assistant the ability to discuss
just about anything leads to the need for reducing the chatbot model size such
that it fits on the user&#x27;s device. We demonstrate that low parameter models can
simultaneously retain their general knowledge conversational abilities while
improving in a specific domain. Additionally, we propose a generic framework
that accounts for variety in question types, tracks reference throughout
multi-turn conversations, and removes inconsistent and potentially toxic
responses. Our framework seamlessly transitions between chatting and performing
transactional tasks, which will ultimately make interactions with digital
assistants more human-like. We evaluate our framework on 1 internal and 4
public benchmark datasets using both automatic (Perplexity) and human (SSA -
Sensibleness and Specificity Average) evaluation metrics and establish
comparable performance while reducing model parameters by 90%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted Physical-World Attention Attack on Deep Learning Models in Road Sign Recognition. (arXiv:2010.04331v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weifeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04331">
                                    <div class="article-summary-box-inner">
                                        <span>Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders. (arXiv:2107.12698v2 [gr-qc] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/gr-qc/1/au:+Moreno_E/0/1/0/all/0/1">Eric A. Moreno</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Vlimant_J/0/1/0/all/0/1">Jean-Roch Vlimant</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Spiropulu_M/0/1/0/all/0/1">Maria Spiropulu</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Borzyszkowski_B/0/1/0/all/0/1">Bartlomiej Borzyszkowski</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12698">
                                    <div class="article-summary-box-inner">
                                        <span>We present an application of anomaly detection techniques based on deep
recurrent autoencoders to the problem of detecting gravitational wave signals
in laser interferometers. Trained on noise data, this class of algorithms could
detect signals using an unsupervised strategy, i.e., without targeting a
specific kind of source. We develop a custom architecture to analyze the data
from two interferometers. We compare the obtained performance to that obtained
with other autoencoder architectures and with a convolutional classifier. The
unsupervised nature of the proposed strategy comes with a cost in terms of
accuracy, when compared to more traditional supervised techniques. On the other
hand, there is a qualitative gain in generalizing the experimental sensitivity
beyond the ensemble of pre-computed signal templates. The recurrent autoencoder
outperforms other autoencoders based on different architectures. The class of
recurrent autoencoders presented in this paper could complement the search
strategy employed for gravitational wave detection and extend the reach of the
ongoing detection campaigns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting socially interacting groups using f-formation: A survey of taxonomy, methods, datasets, applications, challenges, and future research directions. (arXiv:2108.06181v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1">Hrishav Bakul Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Mg_T/0/1/0/all/0/1">Theint Haythi Mg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pramanick_P/0/1/0/all/0/1">Pradip Pramanick</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_C/0/1/0/all/0/1">Chayan Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06181">
                                    <div class="article-summary-box-inner">
                                        <span>Robots in our daily surroundings are increasing day by day. Their usability
and acceptability largely depend on their explicit and implicit interaction
capability with fellow human beings. As a result, social behavior is one of the
most sought-after qualities that a robot can possess. However, there is no
specific aspect and/or feature that defines socially acceptable behavior and it
largely depends on the situation, application, and society. In this article, we
investigate one such social behavior for collocated robots. Imagine a group of
people is interacting with each other and we want to join the group. We as
human beings do it in a socially acceptable manner, i.e., within the group, we
do position ourselves in such a way that we can participate in the group
activity without disturbing/obstructing anybody. To possess such a quality,
first, a robot needs to determine the formation of the group and then determine
a position for itself, which we humans do implicitly. The theory of f-formation
can be utilized for this purpose. As the types of formations can be very
diverse, detecting the social groups is not a trivial task. In this article, we
provide a comprehensive survey of the existing work on social interaction and
group detection using f-formation for robotics and other applications. We also
put forward a novel holistic survey framework combining all the possible
concerns and modules relevant to this problem. We define taxonomies based on
methods, camera views, datasets, detection capabilities and scale, evaluation
approaches, and application areas. We discuss certain open challenges and
limitations in current literature along with possible future research
directions based on this framework. In particular, we discuss the existing
methods/techniques and their relative merits and demerits, applications, and
provide a set of unsolved but relevant problems in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based transformation of the H&amp;E stain into special stains. (arXiv:2008.08871v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Haan_K/0/1/0/all/0/1">Kevin de Haan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yijie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerman_J/0/1/0/all/0/1">Jonathan E. Zuckerman</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tairan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sisk_A/0/1/0/all/0/1">Anthony E. Sisk</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_M/0/1/0/all/0/1">Miguel F. P. Diaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Jen_K/0/1/0/all/0/1">Kuang-Yu Jen</a>, <a href="http://arxiv.org/find/eess/1/au:+Nobori_A/0/1/0/all/0/1">Alexander Nobori</a>, <a href="http://arxiv.org/find/eess/1/au:+Liou_S/0/1/0/all/0/1">Sofia Liou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Sarah Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Riahi_R/0/1/0/all/0/1">Rana Riahi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rivenson_Y/0/1/0/all/0/1">Yair Rivenson</a>, <a href="http://arxiv.org/find/eess/1/au:+Wallace_W/0/1/0/all/0/1">W. Dean Wallace</a>, <a href="http://arxiv.org/find/eess/1/au:+Ozcan_A/0/1/0/all/0/1">Aydogan Ozcan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08871">
                                    <div class="article-summary-box-inner">
                                        <span>Pathology is practiced by visual inspection of histochemically stained
slides. Most commonly, the hematoxylin and eosin (H&amp;E) stain is used in the
diagnostic workflow and it is the gold standard for cancer diagnosis. However,
in many cases, especially for non-neoplastic diseases, additional &quot;special
stains&quot; are used to provide different levels of contrast and color to tissue
components and allow pathologists to get a clearer diagnostic picture. In this
study, we demonstrate the utility of supervised learning-based computational
stain transformation from H&amp;E to different special stains (Masson&#x27;s Trichrome,
periodic acid-Schiff and Jones silver stain) using tissue sections from kidney
needle core biopsies. Based on evaluation by three renal pathologists, followed
by adjudication by a fourth renal pathologist, we show that the generation of
virtual special stains from existing H&amp;E images improves the diagnosis in
several non-neoplastic kidney diseases sampled from 58 unique subjects. A
second study performed by three pathologists found that the quality of the
special stains generated by the stain transformation network was statistically
equivalent to those generated through standard histochemical staining. As the
transformation of H&amp;E images into special stains can be achieved within 1 min
or less per patient core specimen slide, this stain-to-stain transformation
framework can improve the quality of the preliminary diagnosis when additional
special stains are needed, along with significant savings in time and cost,
reducing the burden on healthcare system and patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Ordinary Differential Equation Control of Dynamics on Graphs. (arXiv:2006.09773v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asikis_T/0/1/0/all/0/1">Thomas Asikis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottcher_L/0/1/0/all/0/1">Lucas B&#xf6;ttcher</a>, <a href="http://arxiv.org/find/cs/1/au:+Antulov_Fantulin_N/0/1/0/all/0/1">Nino Antulov-Fantulin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09773">
                                    <div class="article-summary-box-inner">
                                        <span>We study the ability of neural networks to steer or control trajectories of
continuous time non-linear dynamical systems on graphs, which we represent with
neural ordinary differential equations (neural ODEs). To do so, we introduce a
neural-ODE control (NODEC) framework and find that it can learn control signals
that drive graph dynamical systems into desired target states. While we use
loss functions that do not constrain the control energy, our results show that
NODEC produces low energy control signals. Finally, we showcase the performance
and versatility of NODEC by using it to control a system of more than one
thousand coupled, non-linear ODEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context Aware Object Geotagging. (arXiv:2108.06302v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao-Jung Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulicny_M/0/1/0/all/0/1">Matej Ulicny</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzke_M/0/1/0/all/0/1">Michael Manzke</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahyot_R/0/1/0/all/0/1">Rozenn Dahyot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06302">
                                    <div class="article-summary-box-inner">
                                        <span>Localization of street objects from images has gained a lot of attention in
recent years. We propose an approach to improve asset geolocation from street
view imagery by enhancing the quality of the metadata associated with the
images using Structure from Motion. The predicted object geolocation is further
refined by imposing contextual geographic information extracted from
OpenStreetMap. Our pipeline is validated experimentally against the state of
the art approaches for geotagging traffic lights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Transferable Parameters for Unsupervised Domain Adaptation. (arXiv:2108.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhongyi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haoliang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) enables a learning machine to adapt from
a labeled source domain to an unlabeled domain under the distribution shift.
Thanks to the strong representation ability of deep neural networks, recent
remarkable achievements in UDA resort to learning domain-invariant features.
Intuitively, the hope is that a good feature representation, together with the
hypothesis learned from the source domain, can generalize well to the target
domain. However, the learning processes of domain-invariant features and source
hypothesis inevitably involve domain-specific information that would degrade
the generalizability of UDA models on the target domain. In this paper,
motivated by the lottery ticket hypothesis that only partial parameters are
essential for generalization, we find that only partial parameters are
essential for learning domain-invariant information and generalizing well in
UDA. Such parameters are termed transferable parameters. In contrast, the other
parameters tend to fit domain-specific details and often fail to generalize,
which we term as untransferable parameters. Driven by this insight, we propose
Transferable Parameter Learning (TransPar) to reduce the side effect brought by
domain-specific information in the learning process and thus enhance the
memorization of domain-invariant information. Specifically, according to the
distribution discrepancy degree, we divide all parameters into transferable and
untransferable ones in each training iteration. We then perform separate
updates rules for the two types of parameters. Extensive experiments on image
classification and regression tasks (keypoint detection) show that TransPar
outperforms prior arts by non-trivial margins. Moreover, experiments
demonstrate that TransPar can be integrated into the most popular deep UDA
networks and be easily extended to handle any data distribution shift
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Disease Diagnosis via Deep Factorization Machine Models. (arXiv:2108.05916v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ronge_R/0/1/0/all/0/1">Raphael Ronge</a>, <a href="http://arxiv.org/find/cs/1/au:+Nho_K/0/1/0/all/0/1">Kwangsik Nho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Polsterl_S/0/1/0/all/0/1">Sebastian P&#xf6;lsterl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05916">
                                    <div class="article-summary-box-inner">
                                        <span>The current state-of-the-art deep neural networks (DNNs) for Alzheimer&#x27;s
Disease diagnosis use different biomarker combinations to classify patients,
but do not allow extracting knowledge about the interactions of biomarkers.
However, to improve our understanding of the disease, it is paramount to
extract such knowledge from the learned model. In this paper, we propose a Deep
Factorization Machine model that combines the ability of DNNs to learn complex
relationships and the ease of interpretability of a linear model. The proposed
model has three parts: (i) an embedding layer to deal with sparse categorical
data, (ii) a Factorization Machine to efficiently learn pairwise interactions,
and (iii) a DNN to implicitly model higher order interactions. In our
experiments on data from the Alzheimer&#x27;s Disease Neuroimaging Initiative, we
demonstrate that our proposed model classifies cognitive normal, mild cognitive
impaired, and demented patients more accurately than competing models. In
addition, we show that valuable knowledge about the interactions among
biomarkers can be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the gap between emotion and joint action. (arXiv:2108.06264v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bienkiewicz_M/0/1/0/all/0/1">M. M. N. Bie&#x144;kiewicz</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Smykovskyi_A/0/1/0/all/0/1">A. Smykovskyi</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Olugbade_T/0/1/0/all/0/1">T. Olugbade</a> (2), <a href="http://arxiv.org/find/q-bio/1/au:+Janaqi_S/0/1/0/all/0/1">S. Janaqi</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Camurri_A/0/1/0/all/0/1">A. Camurri</a> (3), <a href="http://arxiv.org/find/q-bio/1/au:+Bianchi_Berthouze_N/0/1/0/all/0/1">N. Bianchi-Berthouze</a> (2), <a href="http://arxiv.org/find/q-bio/1/au:+Bjorkman_M/0/1/0/all/0/1">M. Bj&#xf6;rkman</a> (4), <a href="http://arxiv.org/find/q-bio/1/au:+Bardy_B/0/1/0/all/0/1">B. G. Bardy</a> (1) ((1) EuroMov Digital Health in Motion Univ. Montpellier IMT Mines Ales France, (2) UCL, University College of London UK, (3) UNIGE InfoMus Casa Paganini Italy, (4) KTH Royal Institute of Technology Sweden)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06264">
                                    <div class="article-summary-box-inner">
                                        <span>Our daily human life is filled with a myriad of joint action moments, be it
children playing, adults working together (i.e., team sports), or strangers
navigating through a crowd. Joint action brings individuals (and embodiment of
their emotions) together, in space and in time. Yet little is known about how
individual emotions propagate through embodied presence in a group, and how
joint action changes individual emotion. In fact, the multi-agent component is
largely missing from neuroscience-based approaches to emotion, and reversely
joint action research has not found a way yet to include emotion as one of the
key parameters to model socio-motor interaction. In this review, we first
identify the gap and then stockpile evidence showing strong entanglement
between emotion and acting together from various branches of sciences. We
propose an integrative approach to bridge the gap, highlight five research
avenues to do so in behavioral neuroscience and digital sciences, and address
some of the key challenges in the area faced by modern societies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Room Classification on Floor Plan Graphs using Graph Neural Networks. (arXiv:2108.05947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paudel_A/0/1/0/all/0/1">Abhishek Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhakal_R/0/1/0/all/0/1">Roshan Dhakal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattarai_S/0/1/0/all/0/1">Sakshat Bhattarai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05947">
                                    <div class="article-summary-box-inner">
                                        <span>We present our approach to improve room classification task on floor plan
maps of buildings by representing floor plans as undirected graphs and
leveraging graph neural networks to predict the room categories. Rooms in the
floor plans are represented as nodes in the graph with edges representing their
adjacency in the map. We experiment with House-GAN dataset that consists of
floor plan maps in vector format and train multilayer perceptron and graph
neural networks. Our results show that graph neural networks, specifically
GraphSAGE and Topology Adaptive GCN were able to achieve accuracy of 80% and
81% respectively outperforming baseline multilayer perceptron by more than 15%
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CNN depth analysis with different channel inputs for Acoustic Scene Classification. (arXiv:1906.04591v4 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_Castanos_S/0/1/0/all/0/1">Sergi Perez-Castanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Naranjo_Alcazar_J/0/1/0/all/0/1">Javier Naranjo-Alcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuccarello_P/0/1/0/all/0/1">Pedro Zuccarello</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobos_M/0/1/0/all/0/1">Maximo Cobos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferri_F/0/1/0/all/0/1">Frances J. Ferri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.04591">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic scene classification (ASC) has been approached in the last years
using deep learning techniques such as convolutional neural networks or
recurrent neural networks. Many state-of-the-art solutions are based on image
classification frameworks and, as such, a 2D representation of the audio signal
is considered for training these networks. Finding the most suitable audio
representation is still a research area of interest. In this paper, different
log-Mel representations and combinations are analyzed. Experiments show that
the best results are obtained using the harmonic and percussive components plus
the difference between left and right stereo channels, (L-R). On the other
hand, it is a common strategy to ensemble different models in order to increase
the final accuracy. Even though averaging different model predictions is a
common choice, an exhaustive analysis of different ensemble techniques has not
been presented in ASC problems. In this paper, geometric and arithmetic mean
plus the Ordered Weighted Averaging (OWA) operator are studied as aggregation
operators for the output of the different models of the ensemble. Finally, the
work carried out in this paper is highly oriented towards real-time
implementations. In this context, as the number of applications for audio
classification on edge devices is increasing exponentially, we also analyze
different network depths and efficient solutions for aggregating ensemble
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimCVD: Simple Contrastive Voxel-Wise Representation Distillation for Semi-Supervised Medical Image Segmentation. (arXiv:2108.06227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruihan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1">Lawrence Staib</a>, <a href="http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1">James S. Duncan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06227">
                                    <div class="article-summary-box-inner">
                                        <span>Automated segmentation in medical image analysis is a challenging task that
requires a large amount of manually labeled data. However, most existing
learning-based approaches usually suffer from limited manually annotated
medical data, which poses a major practical problem for accurate and robust
medical image segmentation. In addition, most existing semi-supervised
approaches are usually not robust compared with the supervised counterparts,
and also lack explicit modeling of geometric structure and semantic
information, both of which limit the segmentation accuracy. In this work, we
present SimCVD, a simple contrastive distillation framework that significantly
advances state-of-the-art voxel-wise representation learning. We first describe
an unsupervised training strategy, which takes two views of an input volume and
predicts their signed distance maps of object boundaries in a contrastive
objective, with only two independent dropout as mask. This simple approach
works surprisingly well, performing on the same level as previous fully
supervised methods with much less labeled data. We hypothesize that dropout can
be viewed as a minimal form of data augmentation and makes the network robust
to representation collapse. Then, we propose to perform structural distillation
by distilling pair-wise similarities. We evaluate SimCVD on two popular
datasets: the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT
dataset. The results on the LA dataset demonstrate that, in two types of
labeled ratios (i.e., 20% and 10%), SimCVD achieves an average Dice score of
90.85% and 89.03% respectively, a 0.91% and 2.22% improvement compared to
previous best results. Our method can be trained in an end-to-end fashion,
showing the promise of utilizing SimCVD as a general framework for downstream
tasks, such as medical image synthesis and registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDM: Trustworthy Decision-Making via Interpretability Enhancement. (arXiv:2108.06080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1">Daoming Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fangkai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1">Hugh Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Wen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_L/0/1/0/all/0/1">Levent Yilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06080">
                                    <div class="article-summary-box-inner">
                                        <span>Human-robot interactive decision-making is increasingly becoming ubiquitous,
and trust is an influential factor in determining the reliance on autonomy.
However, it is not reasonable to trust systems that are beyond our
comprehension, and typical machine learning and data-driven decision-making are
black-box paradigms that impede interpretability. Therefore, it is critical to
establish computational trustworthy decision-making mechanisms enhanced by
interpretability-aware strategies. To this end, we propose a Trustworthy
Decision-Making (TDM) framework, which integrates symbolic planning into
sequential decision-making. The framework learns interpretable subtasks that
result in a complex, higher-level composite task that can be formally evaluated
using the proposed trust metric. TDM enables the subtask-level interpretability
by design and converges to an optimal symbolic plan from the learned subtasks.
Moreover, a TDM-based algorithm is introduced to demonstrate the unification of
symbolic planning with other sequential-decision making algorithms, reaping the
benefits of both. Experimental results validate the effectiveness of
trust-score-based planning while improving the interpretability of subtasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v10 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dai Quoc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer self-attention network has been extensively used in research
domains such as computer vision, image processing, and natural language
processing. The transformer, however, has not been actively used in graph
neural networks, where constructing an advanced aggregation function is
essential. To this end, we present an effective model, named UGformer, which --
by leveraging a transformer self-attention mechanism followed by a recurrent
transition -- induces an advanced aggregation function to learn graph
representations. Experimental results show that UGformer achieves
state-of-the-art accuracies on well-known benchmark datasets for graph
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster Kernel Interpolation for Gaussian Processes. (arXiv:2101.11751v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_M/0/1/0/all/0/1">Mohit Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheldon_D/0/1/0/all/0/1">Daniel Sheldon</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11751">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge in scaling Gaussian Process (GP) regression to massive
datasets is that exact inference requires computation with a dense n x n kernel
matrix, where n is the number of data points. Significant work focuses on
approximating the kernel matrix via interpolation using a smaller set of m
inducing points. Structured kernel interpolation (SKI) is among the most
scalable methods: by placing inducing points on a dense grid and using
structured matrix algebra, SKI achieves per-iteration time of O(n + m log m)
for approximate inference. This linear scaling in n enables inference for very
large data sets; however the cost is per-iteration, which remains a limitation
for extremely large n. We show that the SKI per-iteration time can be reduced
to O(m log m) after a single O(n) time precomputation step by reframing SKI as
solving a natural Bayesian linear regression problem with a fixed set of m
compact basis functions. With per-iteration complexity independent of the
dataset size n for a fixed grid, our method scales to truly massive data sets.
We demonstrate speedups in practice for a wide range of m and n and apply the
method to GP inference on a three-dimensional weather radar dataset with over
100 million points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Next Waves in Veridical Network Embedding. (arXiv:2007.05385v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ward_O/0/1/0/all/0/1">Owen G. Ward</a>, <a href="http://arxiv.org/find/stat/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Davison_A/0/1/0/all/0/1">Andrew Davison</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_T/0/1/0/all/0/1">Tian Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05385">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding nodes of a large network into a metric (e.g., Euclidean) space has
become an area of active research in statistical machine learning, which has
found applications in natural and social sciences. Generally, a representation
of a network object is learned in a Euclidean geometry and is then used for
subsequent tasks regarding the nodes and/or edges of the network, such as
community detection, node classification and link prediction. Network embedding
algorithms have been proposed in multiple disciplines, often with
domain-specific notations and details. In addition, different measures and
tools have been adopted to evaluate and compare the methods proposed under
different settings, often dependent of the downstream tasks. As a result, it is
challenging to study these algorithms in the literature systematically.
Motivated by the recently proposed Veridical Data Science (VDS) framework, we
propose a framework for network embedding algorithms and discuss how the
principles of predictability, computability and stability apply in this
context. The utilization of this framework in network embedding holds the
potential to motivate and point to new directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Structural Vulnerability in Graph Convolutional Networks. (arXiv:2108.06280v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jintang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qibiao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zibin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06280">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that Graph Convolutional Networks (GCNs) are
vulnerable to adversarial attacks on the graph structure. Although multiple
works have been proposed to improve their robustness against such structural
adversarial attacks, the reasons for the success of the attacks remain unclear.
In this work, we theoretically and empirically demonstrate that structural
adversarial examples can be attributed to the non-robust aggregation scheme
(i.e., the weighted mean) of GCNs. Specifically, our analysis takes advantage
of the breakdown point which can quantitatively measure the robustness of
aggregation schemes. The key insight is that weighted mean, as the basic design
of GCNs, has a low breakdown point and its output can be dramatically changed
by injecting a single edge. We show that adopting the aggregation scheme with a
high breakdown point (e.g., median or trimmed mean) could significantly enhance
the robustness of GCNs against structural attacks. Extensive experiments on
four real-world datasets demonstrate that such a simple but effective method
achieves the best robustness performance compared to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Interpretable Classification and Weakly-Supervised Segmentation of Histology Images via Max-Min Uncertainty. (arXiv:2011.07221v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belharbi_S/0/1/0/all/0/1">Soufiane Belharbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rony_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Rony</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+McCaffrey_L/0/1/0/all/0/1">Luke McCaffrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07221">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised learning (WSL) has recently triggered substantial interest
as it mitigates the lack of pixel-wise annotations.

Given global image labels, WSL methods yield pixel-level predictions
(segmentations), which enable to interpret class predictions. Despite their
recent success, mostly with natural images, such methods can face important
challenges when the foreground and background regions have similar visual cues,
yielding high false-positive rates in segmentations, as is the case in
challenging histology images. WSL training is commonly driven by standard
classification losses, which implicitly maximize model confidence, and locate
the discriminative regions linked to classification decisions. Therefore, they
lack mechanisms for modeling explicitly non-discriminative regions and reducing
false-positive rates. We propose novel regularization terms, which enable the
model to seek both non-discriminative and discriminative regions, while
discouraging unbalanced segmentations. We introduce high uncertainty as a
criterion to localize non-discriminative regions that do not affect classifier
decision, and describe it with original Kullback-Leibler (KL) divergence losses
evaluating the deviation of posterior predictions from the uniform
distribution. Our KL terms encourage high uncertainty of the model when the
latter inputs the latent non-discriminative regions. Our loss integrates: (i) a
cross-entropy seeking a foreground, where model confidence about class
prediction is high; (ii) a KL regularizer seeking a background, where model
uncertainty is high; and (iii) log-barrier terms discouraging unbalanced
segmentations. Comprehensive experiments and ablation studies over the public
GlaS colon cancer data and a Camelyon16 patch-based benchmark for breast cancer
show substantial improvements over state-of-the-art WSL methods, and confirm
the effect of our new regularizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Ridge Solution for the Incremental Broad Learning System on Added Nodes by Inverse Cholesky Factorization of a Partitioned Matrix. (arXiv:1911.04872v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hufei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chenghao Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04872">
                                    <div class="article-summary-box-inner">
                                        <span>To accelerate the existing Broad Learning System (BLS) for new added nodes in
[7], we extend the inverse Cholesky factorization in [10] to deduce an
efficient inverse Cholesky factorization for a Hermitian matrix partitioned
into 2 * 2 blocks, which is utilized to develop the proposed BLS algorithm 1.
The proposed BLS algorithm 1 compute the ridge solution (i.e, the output
weights) from the inverse Cholesky factor of the Hermitian matrix in the ridge
inverse, and update the inverse Cholesky factor efficiently. From the proposed
BLS algorithm 1, we deduce the proposed ridge inverse, which can be obtained
from the generalized inverse in [7] by just change one matrix in the equation
to compute the newly added sub-matrix. We also modify the proposed algorithm 1
into the proposed algorithm 2, which is equivalent to the existing BLS
algorithm [7] in terms of numerical computations. The proposed algorithms 1 and
2 can reduce the computational complexity, since usually the Hermitian matrix
in the ridge inverse is smaller than the ridge inverse. With respect to the
existing BLS algorithm, the proposed algorithms 1 and 2 usually require about
13 and 2 3 of complexities, respectively, while in numerical experiments they
achieve the speedups (in each additional training time) of 2.40 - 2.91 and 1.36
- 1.60, respectively. Numerical experiments also show that the proposed
algorithm 1 and the standard ridge solution always bear the same testing
accuracy, and usually so do the proposed algorithm 2 and the existing BLS
algorithm. The existing BLS assumes the ridge parameter lamda-&gt;0, since it is
based on the generalized inverse with the ridge regression approximation. When
the assumption of lamda-&gt; 0 is not satisfied, the standard ridge solution
obviously achieves a better testing accuracy than the existing BLS algorithm in
numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMET: Convolutional Dimension Interaction for Collaborative Filtering. (arXiv:2007.14129v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xingzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee Keong Kwoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14129">
                                    <div class="article-summary-box-inner">
                                        <span>Latent factor models play a dominant role among recommendation techniques.
However, most of the existing latent factor models assume both historical
interactions and embedding dimensions are independent of each other, and thus
regrettably ignore the high-order interaction information among historical
interactions and embedding dimensions. In this paper, we propose a novel latent
factor model called COMET (COnvolutional diMEnsion inTeraction), which
simultaneously model the high-order interaction patterns among historical
interactions and embedding dimensions. To be specific, COMET stacks the
embeddings of historical interactions horizontally at first, which results in
two &quot;embedding maps&quot;. In this way, internal interactions and dimensional
interactions can be exploited by convolutional neural networks with kernels of
different sizes simultaneously. A fully-connected multi-layer perceptron is
then applied to obtain two interaction vectors. Lastly, the representations of
users and items are enriched by the learnt interaction vectors, which can
further be used to produce the final prediction. Extensive experiments and
ablation studies on various public implicit feedback datasets clearly
demonstrate the effectiveness and the rationality of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Backprop: Stochastic Gradient Descent with Persistent Randomness. (arXiv:2108.06325v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dohare_S/0/1/0/all/0/1">Shibhansh Dohare</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">A. Rupam Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1">Richard S. Sutton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06325">
                                    <div class="article-summary-box-inner">
                                        <span>The Backprop algorithm for learning in neural networks utilizes two
mechanisms: first, stochastic gradient descent and second, initialization with
small random weights, where the latter is essential to the effectiveness of the
former. We show that in continual learning setups, Backprop performs well
initially, but over time its performance degrades. Stochastic gradient descent
alone is insufficient to learn continually; the initial randomness enables only
initial learning but not continual learning. To the best of our knowledge, ours
is the first result showing this degradation in Backprop&#x27;s ability to learn. To
address this issue, we propose an algorithm that continually injects random
features alongside gradient descent using a new generate-and-test process. We
call this the Continual Backprop algorithm. We show that, unlike Backprop,
Continual Backprop is able to continually adapt in both supervised and
reinforcement learning problems. We expect that as continual learning becomes
more common in future applications, a method like Continual Backprop will be
essential where the advantages of random initialization are present throughout
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Datasets for Studying Generalization from Easy to Hard Examples. (arXiv:2108.06011v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgnia_E/0/1/0/all/0/1">Eitan Borgnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Arpit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Emam_Z/0/1/0/all/0/1">Zeyad Emam</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06011">
                                    <div class="article-summary-box-inner">
                                        <span>We describe new datasets for studying generalization from easy to hard
examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Stage Graph Peeling Algorithm for Probabilistic Core Decomposition. (arXiv:2108.06094v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1">Xuekui Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Esfahani_F/0/1/0/all/0/1">Fatemeh Esfahani</a>, <a href="http://arxiv.org/find/stat/1/au:+Srinivasan_V/0/1/0/all/0/1">Venkatesh Srinivasan</a>, <a href="http://arxiv.org/find/stat/1/au:+Thomo_A/0/1/0/all/0/1">Alex Thomo</a>, <a href="http://arxiv.org/find/stat/1/au:+Xing_L/0/1/0/all/0/1">Li Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06094">
                                    <div class="article-summary-box-inner">
                                        <span>Mining dense subgraphs where vertices connect closely with each other is a
common task when analyzing graphs. A very popular notion in subgraph analysis
is core decomposition. Recently, Esfahani et al. presented a probabilistic core
decomposition algorithm based on graph peeling and Central Limit Theorem (CLT)
that is capable of handling very large graphs. Their proposed peeling algorithm
(PA) starts from the lowest degree vertices and recursively deletes these
vertices, assigning core numbers, and updating the degree of neighbour vertices
until it reached the maximum core. However, in many applications, particularly
in biology, more valuable information can be obtained from dense
sub-communities and we are not interested in small cores where vertices do not
interact much with others. To make the previous PA focus more on dense
subgraphs, we propose a multi-stage graph peeling algorithm (M-PA) that has a
two-stage data screening procedure added before the previous PA. After removing
vertices from the graph based on the user-defined thresholds, we can reduce the
graph complexity largely and without affecting the vertices in subgraphs that
we are interested in. We show that M-PA is more efficient than the previous PA
and with the properly set filtering threshold, can produce very similar if not
identical dense subgraphs to the previous PA (in terms of graph density and
clustering coefficient).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bayesian Approach to In-Game Win Probability in Soccer. (arXiv:1906.05029v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robberechts_P/0/1/0/all/0/1">Pieter Robberechts</a>, <a href="http://arxiv.org/find/cs/1/au:+Haaren_J/0/1/0/all/0/1">Jan Van Haaren</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jesse Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.05029">
                                    <div class="article-summary-box-inner">
                                        <span>In-game win probability models, which provide a sports team&#x27;s likelihood of
winning at each point in a game based on historical observations, are becoming
increasingly popular. In baseball, basketball and American football, they have
become important tools to enhance fan experience, to evaluate in-game
decision-making, and to inform coaching decisions. While equally relevant in
soccer, the adoption of these models is held back by technical challenges
arising from the low-scoring nature of the sport.

In this paper, we introduce an in-game win probability model for soccer that
addresses the shortcomings of existing models. First, we demonstrate that
in-game win probability models for other sports struggle to provide accurate
estimates for soccer, especially towards the end of a game. Second, we
introduce a novel Bayesian statistical framework that estimates running win,
tie and loss probabilities by leveraging a set of contextual game state
features. An empirical evaluation on eight seasons of data for the top-five
soccer leagues demonstrates that our framework provides well-calibrated
probabilities. Furthermore, two use cases show its ability to enhance fan
experience and to evaluate performance in crucial game situations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Positive-Unlabelled Learning via Markov Diffusion. (arXiv:2108.06158v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stolfi_P/0/1/0/all/0/1">Paola Stolfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mastropietro_A/0/1/0/all/0/1">Andrea Mastropietro</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasculli_G/0/1/0/all/0/1">Giuseppe Pasculli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tieri_P/0/1/0/all/0/1">Paolo Tieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Vergni_D/0/1/0/all/0/1">Davide Vergni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06158">
                                    <div class="article-summary-box-inner">
                                        <span>Positive-Unlabelled (PU) learning is the machine learning setting in which
only a set of positive instances are labelled, while the rest of the data set
is unlabelled. The unlabelled instances may be either unspecified positive
samples or true negative samples. Over the years, many solutions have been
proposed to deal with PU learning. Some techniques consider the unlabelled
samples as negative ones, reducing the problem to a binary classification with
a noisy negative set, while others aim to detect sets of possible negative
examples to later apply a supervised machine learning strategy (two-step
techniques). The approach proposed in this work falls in the latter category
and works in a semi-supervised fashion: motivated and inspired by previous
works, a Markov diffusion process with restart is used to assign pseudo-labels
to unlabelled instances. Afterward, a machine learning model, exploiting the
newly assigned classes, is trained. The principal aim of the algorithm is to
identify a set of instances which are likely to contain positive instances that
were originally unlabelled.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charts and atlases for nonlinear data-driven models of dynamics on manifolds. (arXiv:2108.05928v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Floryan_D/0/1/0/all/0/1">Daniel Floryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_M/0/1/0/all/0/1">Michael D. Graham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05928">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method for learning minimal-dimensional dynamical models from
high-dimensional time series data that lie on a low-dimensional manifold, as
arises for many processes. For an arbitrary manifold, there is no smooth global
coordinate representation, so following the formalism of differential topology
we represent the manifold as an atlas of charts. We first partition the data
into overlapping regions. Then undercomplete autoencoders are used to find
low-dimensional coordinate representations for each region. We then use the
data to learn dynamical models in each region, which together yield a global
low-dimensional dynamical model. We apply this method to examples ranging from
simple periodic dynamics to complex, nominally high-dimensional non-periodic
bursting dynamics of the Kuramoto-Sivashinsky equation. We demonstrate that it:
(1) can yield dynamical models of the lowest possible dimension, where previous
methods generally cannot; (2) exhibits computational benefits including
scalability, parallelizability, and adaptivity; and (3) separates state space
into regions of distinct behaviours.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MeetSum: Transforming Meeting Transcript Summarization using Transformers!. (arXiv:2108.06310v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadri_N/0/1/0/all/0/1">Nima Sadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bihan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06310">
                                    <div class="article-summary-box-inner">
                                        <span>Creating abstractive summaries from meeting transcripts has proven to be
challenging due to the limited amount of labeled data available for training
neural network models. Moreover, Transformer-based architectures have proven to
beat state-of-the-art models in summarizing news data. In this paper, we
utilize a Transformer-based Pointer Generator Network to generate abstract
summaries for meeting transcripts. This model uses 2 LSTMs as an encoder and a
decoder, a Pointer network which copies words from the inputted text, and a
Generator network to produce out-of-vocabulary words (hence making the summary
abstractive). Moreover, a coverage mechanism is used to avoid repetition of
words in the generated summary. First, we show that training the model on a
news summary dataset and using zero-shot learning to test it on the meeting
dataset proves to produce better results than training it on the AMI meeting
dataset. Second, we show that training this model first on out-of-domain data,
such as the CNN-Dailymail dataset, followed by a fine-tuning stage on the AMI
meeting dataset is able to improve the performance of the model significantly.
We test our model on a testing set from the AMI dataset and report the ROUGE-2
score of the generated summary to compare with previous literature. We also
report the Factual score of our summaries since it is a better benchmark for
abstractive summaries since the ROUGE-2 score is limited to measuring
word-overlaps. We show that our improved model is able to improve on previous
models by at least 5 ROUGE-2 scores, which is a substantial improvement. Also,
a qualitative analysis of the summaries generated by our model shows that these
summaries and human-readable and indeed capture most of the important
information from the transcripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Follow the Prophet: Accurate Online Conversion Rate Prediction in the Face of Delayed Feedback. (arXiv:2108.06167v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Feiyang Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1">Xiang Ao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Min Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Junwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dapeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qing He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06167">
                                    <div class="article-summary-box-inner">
                                        <span>The delayed feedback problem is one of the imperative challenges in online
advertising, which is caused by the highly diversified feedback delay of a
conversion varying from a few minutes to several days. It is hard to design an
appropriate online learning system under these non-identical delay for
different types of ads and users. In this paper, we propose to tackle the
delayed feedback problem in online advertising by &quot;Following the Prophet&quot; (FTP
for short). The key insight is that, if the feedback came instantly for all the
logged samples, we could get a model without delayed feedback, namely the
&quot;prophet&quot;. Although the prophet cannot be obtained during online learning, we
show that we could predict the prophet&#x27;s predictions by an aggregation policy
on top of a set of multi-task predictions, where each task captures the
feedback patterns of different periods. We propose the objective and
optimization approach for the policy, and use the logged data to imitate the
prophet. Extensive experiments on three real-world advertising datasets show
that our method outperforms the previous state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ST-PCNN: Spatio-Temporal Physics-Coupled Neural Networks for Dynamics Forecasting. (arXiv:2108.05940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">James Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Min Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Hanqi Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingquan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherubin_L/0/1/0/all/0/1">Laurent Ch&#xe9;rubin</a>, <a href="http://arxiv.org/find/cs/1/au:+VanZwieten_J/0/1/0/all/0/1">James VanZwieten</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yufei Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05940">
                                    <div class="article-summary-box-inner">
                                        <span>Ocean current, fluid mechanics, and many other spatio-temporal physical
dynamical systems are essential components of the universe. One key
characteristic of such systems is that certain physics laws -- represented as
ordinary/partial differential equations (ODEs/PDEs) -- largely dominate the
whole process, irrespective of time or location. Physics-informed learning has
recently emerged to learn physics for accurate prediction, but they often lack
a mechanism to leverage localized spatial and temporal correlation or rely on
hard-coded physics parameters. In this paper, we advocate a physics-coupled
neural network model to learn parameters governing the physics of the system,
and further couple the learned physics to assist the learning of recurring
dynamics. A spatio-temporal physics-coupled neural network (ST-PCNN) model is
proposed to achieve three goals: (1) learning the underlying physics
parameters, (2) transition of local information between spatio-temporal
regions, and (3) forecasting future values for the dynamical system. The
physics-coupled learning ensures that the proposed model can be tremendously
improved by using learned physics parameters, and can achieve good long-range
forecasting (e.g., more than 30-steps). Experiments, using simulated and
field-collected ocean current data, validate that ST-PCNN outperforms existing
physics-informed models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Q-Mixing Network for Multi-Agent Pathfinding in Partially Observable Grid Environments. (arXiv:2108.06148v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davydov_V/0/1/0/all/0/1">Vasilii Davydov</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrynnik_A/0/1/0/all/0/1">Alexey Skrynnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1">Konstantin Yakovlev</a>, <a href="http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1">Aleksandr I. Panov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06148">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider the problem of multi-agent navigation in partially
observable grid environments. This problem is challenging for centralized
planning approaches as they, typically, rely on the full knowledge of the
environment. We suggest utilizing the reinforcement learning approach when the
agents, first, learn the policies that map observations to actions and then
follow these policies to reach their goals. To tackle the challenge associated
with learning cooperative behavior, i.e. in many cases agents need to yield to
each other to accomplish a mission, we use a mixing Q-network that complements
learning individual policies. In the experimental evaluation, we show that such
approach leads to plausible results and scales well to large number of agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ergonomically Intelligent Physical Human-Robot Interaction: Postural Estimation, Assessment, and Optimization. (arXiv:2108.05971v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yazdani_A/0/1/0/all/0/1">Amir Yazdani</a>, <a href="http://arxiv.org/find/cs/1/au:+Novin_R/0/1/0/all/0/1">Roya Sabbagh Novin</a>, <a href="http://arxiv.org/find/cs/1/au:+Merryweather_A/0/1/0/all/0/1">Andrew Merryweather</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermans_T/0/1/0/all/0/1">Tucker Hermans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05971">
                                    <div class="article-summary-box-inner">
                                        <span>Ergonomics and human comfort are essential concerns in physical human-robot
interaction applications, and common practical methods either fail in
estimating the correct posture due to occlusion or suffer from less accurate
ergonomics models in their postural optimization methods. Instead, we propose a
novel framework for posture estimation, assessment, and optimization for
ergonomically intelligent physical human-robot interaction. We show that we can
estimate human posture solely from the trajectory of the interacting robot. We
propose DULA, a differentiable ergonomics model, and use it in gradient-free
postural optimization for physical human-robot interaction tasks such as
co-manipulation and teleoperation. We evaluate our framework through human and
simulation experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable3-BO: Big Data meets HPC - A scalable asynchronous parallel high-dimensional Bayesian optimization framework on supercomputers. (arXiv:2108.05969v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05969">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is a flexible and powerful framework that is
suitable for computationally expensive simulation-based applications and
guarantees statistical convergence to the global optimum. While remaining as
one of the most popular optimization methods, its capability is hindered by the
size of data, the dimensionality of the considered problem, and the nature of
sequential optimization. These scalability issues are intertwined with each
other and must be tackled simultaneously. In this work, we propose the
Scalable$^3$-BO framework, which employs sparse GP as the underlying surrogate
model to scope with Big Data and is equipped with a random embedding to
efficiently optimize high-dimensional problems with low effective
dimensionality. The Scalable$^3$-BO framework is further leveraged with
asynchronous parallelization feature, which fully exploits the computational
resource on HPC within a computational budget. As a result, the proposed
Scalable$^3$-BO framework is scalable in three independent perspectives: with
respect to data size, dimensionality, and computational resource on HPC. The
goal of this work is to push the frontiers of BO beyond its well-known
scalability issues and minimize the wall-clock waiting time for optimizing
high-dimensional computationally expensive applications. We demonstrate the
capability of Scalable$^3$-BO with 1 million data points, 10,000-dimensional
problems, with 20 concurrent workers in an HPC environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Network Approximation for Smooth Functions. (arXiv:2001.03040v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03040">
                                    <div class="article-summary-box-inner">
                                        <span>This paper establishes the optimal approximation error characterization of
deep rectified linear unit (ReLU) networks for smooth functions in terms of
both width and depth simultaneously. To that end, we first prove that
multivariate polynomials can be approximated by deep ReLU networks of width
$\mathcal{O}(N)$ and depth $\mathcal{O}(L)$ with an approximation error
$\mathcal{O}(N^{-L})$. Through local Taylor expansions and their deep ReLU
network approximations, we show that deep ReLU networks of width
$\mathcal{O}(N\ln N)$ and depth $\mathcal{O}(L\ln L)$ can approximate $f\in
C^s([0,1]^d)$ with a nearly optimal approximation error
$\mathcal{O}(\|f\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our estimate is
non-asymptotic in the sense that it is valid for arbitrary width and depth
specified by $N\in\mathbb{N}^+$ and $L\in\mathbb{N}^+$, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling extra-deep electromagnetic logs using a deep neural network. (arXiv:2005.08919v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Alyaev_S/0/1/0/all/0/1">Sergey Alyaev</a>, <a href="http://arxiv.org/find/eess/1/au:+Shahriari_M/0/1/0/all/0/1">Mostafa Shahriari</a>, <a href="http://arxiv.org/find/eess/1/au:+Pardo_D/0/1/0/all/0/1">David Pardo</a>, <a href="http://arxiv.org/find/eess/1/au:+Omella_A/0/1/0/all/0/1">Angel Javier Omella</a>, <a href="http://arxiv.org/find/eess/1/au:+Larsen_D/0/1/0/all/0/1">David Larsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jahani_N/0/1/0/all/0/1">Nazanin Jahani</a>, <a href="http://arxiv.org/find/eess/1/au:+Suter_E/0/1/0/all/0/1">Erich Suter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08919">
                                    <div class="article-summary-box-inner">
                                        <span>Modern geosteering is heavily dependent on real-time interpretation of deep
electromagnetic (EM) measurements. We present a methodology to construct a deep
neural network (DNN) model trained to reproduce a full set of extra-deep EM
logs consisting of 22 measurements per logging position. The model is trained
in a 1D layered environment consisting of up to seven layers with different
resistivity values. A commercial simulator provided by a tool vendor is used to
generate a training dataset. The dataset size is limited because the simulator
provided by the vendor is optimized for sequential execution. Therefore, we
design a training dataset that embraces the geological rules and geosteering
specifics supported by the forward model. We use this dataset to produce an EM
simulator based on a DNN without access to the proprietary information about
the EM tool configuration or the original simulator source code. Despite
employing a relatively small training set size, the resulting DNN forward model
is quite accurate for the considered examples: a multi-layer synthetic case and
a section of a published historical operation from the Goliat Field. The
observed average evaluation time of 0.15 ms per logging position makes it also
suitable for future use as part of evaluation-hungry statistical and/or
Monte-Carlo inversion algorithms within geosteering workflows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A reduced-order modeling framework for simulating signatures of faults in a bladed disk. (arXiv:2108.06265v1 [cs.CE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1">Divya Shyam Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Atul Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahapatra_D/0/1/0/all/0/1">D. Roy Mahapatra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06265">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reports a reduced-order modeling framework of bladed disks on a
rotating shaft to simulate the vibration signature of faults like cracks in
different components aiming towards simulated data-driven machine learning. We
have employed lumped and one-dimensional analytical models of the subcomponents
for better insight into the complex dynamic response. The framework seeks to
address some of the challenges encountered in analyzing and optimizing fault
detection and identification schemes for health monitoring of rotating
turbomachinery, including aero-engines. We model the bladed disks and shafts by
combining lumped elements and one-dimensional finite elements, leading to a
coupled system. The simulation results are in good agreement with previously
published data. We model the cracks in a blade analytically with their
effective reduced stiffness approximation. Multiple types of faults are
modeled, including cracks in the blades of single and two-stage bladed disks,
Fan Blade Off (FBO), and Foreign Object Damage (FOD). We have applied
aero-engine operational loading conditions to simulate realistic scenarios of
online health monitoring. The proposed reduced-order simulation framework will
have applications in probabilistic signal modeling, machine learning toward
fault signature identification, and parameter estimation with measured
vibration signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training. (arXiv:2108.06084v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Conglong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minjia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuxiong He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06084">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have demonstrated great success in training high-capacity
autoregressive language models (GPT, GPT-2, GPT-3) on a huge amount of
unlabeled text corpus for text generation. Despite showing great results, this
generates two training efficiency challenges. First, training large corpora can
be extremely timing consuming, and how to present training samples to the model
to improve the token-wise convergence speed remains a challenging and open
question. Second, many of these large models have to be trained with hundreds
or even thousands of processors using data-parallelism with a very large batch
size. Despite of its better compute efficiency, it has been observed that
large-batch training often runs into training instability issue or converges to
solutions with bad generalization performance. To overcome these two
challenges, we present a study of a curriculum learning based approach, which
helps improves the pre-training convergence speed of autoregressive models.
More importantly, we find that curriculum learning, as a regularization method,
exerts a gradient variance reduction effect and enables to train autoregressive
models with much larger batch sizes and learning rates without training
instability, further improving the training speed. Our evaluations demonstrate
that curriculum learning enables training GPT-2 models (with up to 1.5B
parameters) with 8x larger batch size and 4x larger learning rate, whereas the
baseline approach struggles with training divergence. To achieve the same
validation perplexity targets during pre-training, curriculum learning reduces
the required number of tokens and wall clock time by up to 59% and 54%,
respectively. To achieve the same or better zero-shot WikiText-103/LAMBADA
evaluation results at the end of pre-training, curriculum learning reduces the
required number of tokens and wall clock time by up to 13% and 61%,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LT-OCF: Learnable-Time ODE-based Collaborative Filtering. (arXiv:2108.06208v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jeongwhan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06208">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is a long-standing problem of recommender
systems. Many novel methods have been proposed, ranging from classical matrix
factorization to recent graph convolutional network-based approaches. After
recent fierce debates, researchers started to focus on linear graph
convolutional networks (GCNs) with a layer combination, which show
state-of-the-art accuracy in many datasets. In this work, we extend them based
on neural ordinary differential equations (NODEs), because the linear GCN
concept can be interpreted as a differential equation, and present the method
of Learnable-Time ODE-based Collaborative Filtering (LT-OCF). The main novelty
in our method is that after redesigning linear GCNs on top of the NODE regime,
i) we learn the optimal architecture rather than relying on manually designed
ones, ii) we learn smooth ODE solutions that are considered suitable for CF,
and iii) we test with various ODE solvers that internally build a diverse set
of neural network connections. We also present a novel training method
specialized to our method. In our experiments with three benchmark datasets,
Gowalla, Yelp2018, and Amazon-Book, our method consistently shows better
accuracy than existing methods, e.g., a recall of 0.0411 by LightGCN vs. 0.0442
by LT-OCF and an NDCG of 0.0315 by LightGCN vs. 0.0341 by LT-OCF in
Amazon-Book. One more important discovery in our experiments that is worth
mentioning is that our best accuracy was achieved by dense connections rather
than linear connections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Fairness Metrics: Roadblocks and Challenges for Ethical AI in Practice. (arXiv:2108.06217v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Storchan_V/0/1/0/all/0/1">Victor Storchan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurshan_E/0/1/0/all/0/1">Eren Kurshan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06217">
                                    <div class="article-summary-box-inner">
                                        <span>We review practical challenges in building and deploying ethical AI at the
scale of contemporary industrial and societal uses. Apart from the purely
technical concerns that are the usual focus of academic research, the
operational challenges of inconsistent regulatory pressures, conflicting
business goals, data quality issues, development processes, systems integration
practices, and the scale of deployment all conspire to create new ethical
risks. Such ethical concerns arising from these practical considerations are
not adequately addressed by existing research results. We argue that a holistic
consideration of ethics in the development and deployment of AI systems is
necessary for building ethical AI in practice, and exhort researchers to
consider the full operational contexts of AI systems when assessing ethical
risks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Quality Toolkit: Automatic assessment of data quality and remediation for machine learning datasets. (arXiv:2108.05935v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nitin Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_H/0/1/0/all/0/1">Hima Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Afzal_S/0/1/0/all/0/1">Shazia Afzal</a>, <a href="http://arxiv.org/find/cs/1/au:+Panwar_N/0/1/0/all/0/1">Naveen Panwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1">Ruhi Sharma Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttula_S/0/1/0/all/0/1">Shanmukha Guttula</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Abhinav Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagalapatti_L/0/1/0/all/0/1">Lokesh Nagalapatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1">Sameep Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hans_S/0/1/0/all/0/1">Sandeep Hans</a>, <a href="http://arxiv.org/find/cs/1/au:+Lohia_P/0/1/0/all/0/1">Pranay Lohia</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1">Aniya Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1">Diptikalyan Saha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05935">
                                    <div class="article-summary-box-inner">
                                        <span>The quality of training data has a huge impact on the efficiency, accuracy
and complexity of machine learning tasks. Various tools and techniques are
available that assess data quality with respect to general cleaning and
profiling checks. However these techniques are not applicable to detect data
issues in the context of machine learning tasks, like noisy labels, existence
of overlapping classes etc. We attempt to re-look at the data quality issues in
the context of building a machine learning pipeline and build a tool that can
detect, explain and remediate issues in the data, and systematically and
automatically capture all the changes applied to the data. We introduce the
Data Quality Toolkit for machine learning as a library of some key quality
metrics and relevant remediation techniques to analyze and enhance the
readiness of structured training datasets for machine learning projects. The
toolkit can reduce the turn-around times of data preparation pipelines and
streamline the data quality assessment process. Our toolkit is publicly
available via IBM API Hub [1] platform, any developer can assess the data
quality using the IBM&#x27;s Data Quality for AI apis [2]. Detailed tutorials are
also available on IBM Learning Path [3].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaze-Contingent Retinal Speckle Suppression for Perceptually-Matched Foveated Holographic Displays. (arXiv:2108.06192v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakravarthula_P/0/1/0/all/0/1">Praneeth Chakravarthula</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Okan Tursun</a>, <a href="http://arxiv.org/find/cs/1/au:+Didyk_P/0/1/0/all/0/1">Piotr Didyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuchs_H/0/1/0/all/0/1">Henry Fuchs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06192">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-generated holographic (CGH) displays show great potential and are
emerging as the next-generation displays for augmented and virtual reality, and
automotive heads-up displays. One of the critical problems harming the wide
adoption of such displays is the presence of speckle noise inherent to
holography, that compromises its quality by introducing perceptible artifacts.
Although speckle noise suppression has been an active research area, the
previous works have not considered the perceptual characteristics of the Human
Visual System (HVS), which receives the final displayed imagery. However, it is
well studied that the sensitivity of the HVS is not uniform across the visual
field, which has led to gaze-contingent rendering schemes for maximizing the
perceptual quality in various computer-generated imagery. Inspired by this, we
present the first method that reduces the &quot;perceived speckle noise&quot; by
integrating foveal and peripheral vision characteristics of the HVS, along with
the retinal point spread function, into the phase hologram computation.
Specifically, we introduce the anatomical and statistical retinal receptor
distribution into our computational hologram optimization, which places a
higher priority on reducing the perceived foveal speckle noise while being
adaptable to any individual&#x27;s optical aberration on the retina. Our method
demonstrates superior perceptual quality on our emulated holographic display.
Our evaluations with objective measurements and subjective studies demonstrate
a significant reduction of the human perceived noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-13">2021-08-13</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dissecting User-Perceived Latency of On-Device E2E Speech Recognition. (arXiv:2104.02207v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1">Yuan Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1">Rohit Prabhavalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1">Jay Mahadeokar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yangyang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiatong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chunyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1">Duc Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1">Ozlem Kalinli</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1">Christian Fuegen</a>, <a href="http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1">Michael L. Seltzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02207">
                                    <div class="article-summary-box-inner">
                                        <span>As speech-enabled devices such as smartphones and smart speakers become
increasingly ubiquitous, there is growing interest in building automatic speech
recognition (ASR) systems that can run directly on-device; end-to-end (E2E)
speech recognition models such as recurrent neural network transducers and
their variants have recently emerged as prime candidates for this task. Apart
from being accurate and compact, such systems need to decode speech with low
user-perceived latency (UPL), producing words as soon as they are spoken. This
work examines the impact of various techniques - model architectures, training
criteria, decoding hyperparameters, and endpointer parameters - on UPL. Our
analyses suggest that measures of model size (parameters, input chunk sizes),
or measures of computation (e.g., FLOPS, RTF) that reflect the model&#x27;s ability
to process input frames are not always strongly correlated with observed UPL.
Thus, conventional algorithmic latency measurements might be inadequate in
accurately capturing latency observed when models are deployed on embedded
devices. Instead, we find that factors affecting token emission latency, and
endpointing behavior have a larger impact on UPL. We achieve the best trade-off
between latency and word error rate when performing ASR jointly with
endpointing, while utilizing the recently proposed alignment regularization
mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word Alignment by Fine-tuning Embeddings on Parallel Corpora. (arXiv:2101.08231v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08231">
                                    <div class="article-summary-box-inner">
                                        <span>Word alignment over parallel corpora has a wide variety of applications,
including learning translation lexicons, cross-lingual transfer of language
processing tools, and automatic evaluation or analysis of translation outputs.
The great majority of past work on word alignment has worked by performing
unsupervised learning on parallel texts. Recently, however, other work has
demonstrated that pre-trained contextualized word embeddings derived from
multilingually trained language models (LMs) prove an attractive alternative,
achieving competitive results on the word alignment task even in the absence of
explicit training on parallel data. In this paper, we examine methods to marry
the two approaches: leveraging pre-trained LMs but fine-tuning them on parallel
text with objectives designed to improve alignment quality, and proposing
methods to effectively extract alignments from these fine-tuned models. We
perform experiments on five language pairs and demonstrate that our model can
consistently outperform previous state-of-the-art models of all varieties. In
addition, we demonstrate that we are able to train multilingual word aligners
that can obtain robust performance on different language pairs. Our aligner,
AWESOME (Aligning Word Embedding Spaces of Multilingual Encoders), with
pre-trained models is available at https://github.com/neulab/awesome-align</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Lexically Constrained Neural Machine Translation with Source-Conditioned Masked Span Prediction. (arXiv:2105.05498v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gyubok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seongjun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05498">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate terminology translation is crucial for ensuring the practicality and
reliability of neural machine translation (NMT) systems. To address this,
lexically constrained NMT explores various methods to ensure pre-specified
words and phrases appear in the translation output. However, in many cases,
those methods are studied on general domain corpora, where the terms are mostly
uni- and bi-grams (&gt;98%). In this paper, we instead tackle a more challenging
setup consisting of domain-specific corpora with much longer n-gram and highly
specialized terms. Inspired by the recent success of masked span prediction
models, we propose a simple and effective training strategy that achieves
consistent improvements on both terminology and sentence-level translation for
three domain-specific corpora in two language pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ambiguity Hierarchy of Regular Infinite Tree Languages. (arXiv:2009.02985v3 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rabinovich_A/0/1/0/all/0/1">Alexander Rabinovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiferet_D/0/1/0/all/0/1">Doron Tiferet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02985">
                                    <div class="article-summary-box-inner">
                                        <span>An automaton is unambiguous if for every input it has at most one accepting
computation. An automaton is k-ambiguous (for k &gt; 0) if for every input it has
at most k accepting computations. An automaton is boundedly ambiguous if it is
k-ambiguous for some $k \in \mathbb{N}$. An automaton is finitely
(respectively, countably) ambiguous if for every input it has at most finitely
(respectively, countably) many accepting computations.

The degree of ambiguity of a regular language is defined in a natural way. A
language is k-ambiguous (respectively, boundedly, finitely, countably
ambiguous) if it is accepted by a k-ambiguous (respectively, boundedly,
finitely, countably ambiguous) automaton. Over finite words every regular
language is accepted by a deterministic automaton. Over finite trees every
regular language is accepted by an unambiguous automaton. Over $\omega$-words
every regular language is accepted by an unambiguous B\&quot;uchi automaton and by a
deterministic parity automaton. Over infinite trees Carayol et al. showed that
there are ambiguous languages.

We show that over infinite trees there is a hierarchy of degrees of
ambiguity: For every k &gt; 1 there are k-ambiguous languages that are not k - 1
ambiguous; and there are finitely (respectively countably, uncountably)
ambiguous languages that are not boundedly (respectively finitely, countably)
ambiguous.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syntax Matters! Syntax-Controlled in Text Style Transfer. (arXiv:2108.05869v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiqiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu C. Aggarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05869">
                                    <div class="article-summary-box-inner">
                                        <span>Existing text style transfer (TST) methods rely on style classifiers to
disentangle the text&#x27;s content and style attributes for text style transfer.
While the style classifier plays a critical role in existing TST methods, there
is no known investigation on its effect on the TST methods. In this paper, we
conduct an empirical study on the limitations of the style classifiers used in
existing TST methods. We demonstrate that the existing style classifiers cannot
learn sentence syntax effectively and ultimately worsen existing TST models&#x27;
performance. To address this issue, we propose a novel Syntax-Aware
Controllable Generation (SACG) model, which includes a syntax-aware style
classifier that ensures learned style latent representations effectively
capture the syntax information for TST. Through extensive experiments on two
popular TST tasks, we show that our proposed method significantly outperforms
the state-of-the-art methods. Our case studies have also demonstrated SACG&#x27;s
ability to generate fluent target-style sentences that preserved the original
content.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cyclic Proof System for HFLN. (arXiv:2010.14891v3 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kori_M/0/1/0/all/0/1">Mayuko Kori</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsukada_T/0/1/0/all/0/1">Takeshi Tsukada</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_N/0/1/0/all/0/1">Naoki Kobayashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14891">
                                    <div class="article-summary-box-inner">
                                        <span>A cyclic proof system allows us to perform inductive reasoning without
explicit inductions. We propose a cyclic proof system for HFLN, which is a
higher-order predicate logic with natural numbers and alternating fixed-points.
Ours is the first cyclic proof system for a higher-order logic, to our
knowledge. Due to the presence of higher-order predicates and alternating
fixed-points, our cyclic proof system requires a more delicate global condition
on cyclic proofs than the original system of Brotherston and Simpson. We prove
the decidability of checking the global condition and soundness of this system,
and also prove a restricted form of standard completeness for an infinitary
variant of our cyclic proof system. A potential application of our cyclic proof
system is semi-automated verification of higher-order programs, based on
Kobayashi et al.&#x27;s recent work on reductions from program verification to HFLN
validity checking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Neural Information Fusion Architecture for Textual Network Embeddings. (arXiv:1908.11057v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qinliang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weijia Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.11057">
                                    <div class="article-summary-box-inner">
                                        <span>Textual network embeddings aim to learn a low-dimensional representation for
every node in the network so that both the structural and textual information
from the networks can be well preserved in the representations. Traditionally,
the structural and textual embeddings were learned by models that rarely take
the mutual influences between them into account. In this paper, a deep neural
architecture is proposed to effectively fuse the two kinds of informations into
one representation. The novelties of the proposed architecture are manifested
in the aspects of a newly defined objective function, the complementary
information fusion method for structural and textual features, and the mutual
gate mechanism for textual feature extraction. Experimental results show that
the proposed model outperforms the comparing methods on all three datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistent Dialogue Generation with Self-supervised Feature Learning. (arXiv:1903.05759v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1">Chris Brockett</a>, <a href="http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1">Michel Galley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1">Bill Dolan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.05759">
                                    <div class="article-summary-box-inner">
                                        <span>Generating responses that are consistent with the dialogue context is one of
the central challenges in building engaging conversational agents. We
demonstrate that neural conversation models can be geared towards generating
consistent responses by maintaining certain features related to topics and
personas throughout the conversation. Past work has required external
supervision that exploits features such as user identities that are often
unavailable. In our approach, topic and persona feature extractors are trained
using a contrastive training scheme that utilizes the natural structure of
dialogue data. We further adopt a feature disentangling loss which, paired with
controllable response generation techniques, allows us to promote or demote
certain learned topics and persona features. Evaluation results demonstrate the
model&#x27;s ability to capture meaningful topics and persona features. The
incorporation of the learned features brings significant improvement in terms
of the quality of generated responses on two dialogue datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining (second-order) graph-based and headed span-based projective dependency parsing. (arXiv:2108.05838v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Songlin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05838">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based methods are popular in dependency parsing for decades. Recently,
\citet{yang2021headed} propose a headed span-based method. Both of them score
all possible trees and globally find the highest-scoring tree. In this paper,
we combine these two kinds of methods, designing several dynamic programming
algorithms for joint inference. Experiments show the effectiveness of our
proposed methods\footnote{Our code is publicly available at
\url{https://github.com/sustcsonglin/span-based-dependency-parsing}.}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable pragmatic communication via self-supervision. (arXiv:2108.05799v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jennifer Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1">Roger Levy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaslavsky_N/0/1/0/all/0/1">Noga Zaslavsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05799">
                                    <div class="article-summary-box-inner">
                                        <span>Models of context-sensitive communication often use the Rational Speech Act
framework (RSA; Frank &amp; Goodman, 2012), which formulates listeners and speakers
in a cooperative reasoning process. However, the standard RSA formulation can
only be applied to small domains, and large-scale applications have relied on
imitating human behavior. Here, we propose a new approach to scalable
pragmatics, building upon recent theoretical results (Zaslavsky et al., 2020)
that characterize pragmatic reasoning in terms of general information-theoretic
principles. Specifically, we propose an architecture and learning process in
which agents acquire pragmatic policies via self-supervision instead of
imitating human data. This work suggests a new principled approach for
equipping artificial agents with pragmatic skills via self-supervision, which
is grounded both in pragmatic theory and in information theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting Semantics from Maintenance Records. (arXiv:2108.05454v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dixit_S/0/1/0/all/0/1">Sharad Dixit</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulwad_V/0/1/0/all/0/1">Varish Mulwad</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1">Abhinav Saxena</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05454">
                                    <div class="article-summary-box-inner">
                                        <span>Rapid progress in natural language processing has led to its utilization in a
variety of industrial and enterprise settings, including in its use for
information extraction, specifically named entity recognition and relation
extraction, from documents such as engineering manuals and field maintenance
reports. While named entity recognition is a well-studied problem, existing
state-of-the-art approaches require large labelled datasets which are hard to
acquire for sensitive data such as maintenance records. Further, industrial
domain experts tend to distrust results from black box machine learning models,
especially when the extracted information is used in downstream predictive
maintenance analytics. We overcome these challenges by developing three
approaches built on the foundation of domain expert knowledge captured in
dictionaries and ontologies. We develop a syntactic and semantic rules-based
approach and an approach leveraging a pre-trained language model, fine-tuned
for a question-answering task on top of our base dictionary lookup to extract
entities of interest from maintenance records. We also develop a preliminary
ontology to represent and capture the semantics of maintenance records. Our
evaluations on a real-world aviation maintenance records dataset show promising
results and help identify challenges specific to named entity recognition in
the context of noisy industrial data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1">Verna Dankers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1">Elia Bruni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1">Dieuwke Hupkes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05885">
                                    <div class="article-summary-box-inner">
                                        <span>Moving towards human-like linguistic performance is often argued to require
compositional generalisation. Whether neural networks exhibit this ability is
typically studied using artificial languages, for which the compositionality of
input fragments can be guaranteed and their meanings algebraically composed.
However, compositionality in natural language is vastly more complex than this
rigid, arithmetics-like version of compositionality, and as such artificial
compositionality tests do not allow us to draw conclusions about how neural
models deal with compositionality in more realistic scenarios. In this work, we
re-instantiate three compositionality tests from the literature and reformulate
them for neural machine translation (NMT). The results highlight two main
issues: the inconsistent behaviour of NMT models and their inability to
(correctly) modulate between local and global processing. Aside from an
empirical study, our work is a call to action: we should rethink the evaluation
of compositionality in neural networks of natural language, where composing
meaning is not as straightforward as doing the math.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">(Un)solving Morphological Inflection: Lemma Overlap Artificially Inflates Models&#x27; Performance. (arXiv:2108.05682v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goldman_O/0/1/0/all/0/1">Omer Goldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Guriel_D/0/1/0/all/0/1">David Guriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1">Reut Tsarfaty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05682">
                                    <div class="article-summary-box-inner">
                                        <span>In the domain of Morphology, Inflection is a fundamental and important task
that gained a lot of traction in recent years, mostly via SIGMORPHON&#x27;s
shared-tasks. With average accuracy above 0.9 over the scores of all languages,
the task is considered mostly solved using relatively generic neural
sequence-to-sequence models, even with little data provided. In this work, we
propose to re-evaluate morphological inflection models by employing harder
train-test splits that will challenge the generalization capacity of the
models. In particular, as opposed to the na\&quot;ive split-by-form, we propose a
split-by-lemma method to challenge the performance on existing benchmarks. Our
experiments with the three top-ranked systems on the SIGMORPHON&#x27;s 2020
shared-task show that the lemma-split presents an average drop of 30 percentage
points in macro-average for the 90 languages included. The effect is most
significant for low-resourced languages with a drop as high as 95 points, but
even high-resourced languages lose about 10 points on average. Our results
clearly show that generalizing inflection to unseen lemmas is far from being
solved, presenting a simple yet effective means to promote more sophisticated
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NoFake at CheckThat! 2021: Fake News Detection Using BERT. (arXiv:2108.05419v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sushma Kumari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05419">
                                    <div class="article-summary-box-inner">
                                        <span>Much research has been done for debunking and analysing fake news. Many
researchers study fake news detection in the last year, but many are limited to
social media data. Currently, multiples fact-checkers are publishing their
results in various formats. Also, multiple fact-checkers use different labels
for the fake news, making it difficult to make a generalisable classifier. With
the merge classes, the performance of the machine model can be enhanced. This
domain categorisation will help group the article, which will help save the
manual effort in assigning the claim verification. In this paper, we have
presented BERT based classification model to predict the domain and
classification. We have also used additional data from fact-checked articles.
We have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B
using the additional training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Optimal is Greedy Decoding for Extractive Question Answering?. (arXiv:2108.05857v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castel_O/0/1/0/all/0/1">Or Castel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1">Ori Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Efrat_A/0/1/0/all/0/1">Avia Efrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1">Omer Levy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05857">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-tuned language models use greedy decoding to answer reading
comprehension questions with relative success. However, this approach does not
ensure that the answer is a span in the given passage, nor does it guarantee
that it is the most probable one. Does greedy decoding actually perform worse
than an algorithm that does adhere to these properties? To study the
performance and optimality of greedy decoding, we present exact-extract, a
decoding algorithm that efficiently finds the most probable answer span in the
context. We compare the performance of T5 with both decoding algorithms on
zero-shot and few-shot extractive question answering. When no training examples
are available, exact-extract significantly outperforms greedy decoding.
However, greedy decoding quickly converges towards the performance of
exact-extract with the introduction of a few training examples, becoming more
extractive and increasingly likelier to generate the most probable span as the
training set grows. We also show that self-supervised training can bias the
model towards extractive behavior, increasing performance in the zero-shot
setting without resorting to annotated examples. Overall, our results suggest
that pretrained language models are so good at adapting to extractive question
answering, that it is often enough to fine-tune on a small training set for the
greedy algorithm to emulate the optimal decoding strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridger: Toward Bursting Scientific Filter Bubbles and Boosting Innovation via Novel Author Discovery. (arXiv:2108.05669v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portenoy_J/0/1/0/all/0/1">Jason Portenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radensky_M/0/1/0/all/0/1">Marissa Radensky</a>, <a href="http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1">Jevin West</a>, <a href="http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1">Eric Horvitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05669">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific silos can hinder innovation. These information &quot;filter bubbles&quot;
and the growing challenge of information overload limit awareness across the
literature, making it difficult to keep track of even narrow areas of interest,
let alone discover new ones. Algorithmic curation and recommendation, which
often prioritize relevance, can further reinforce these bubbles. In response,
we describe Bridger, a system for facilitating discovery of scholars and their
work, to explore design tradeoffs among relevant and novel recommendations. We
construct a faceted representation of authors using information extracted from
their papers and inferred personas. We explore approaches both for recommending
new content and for displaying it in a manner that helps researchers to
understand the work of authors who they are unfamiliar with. In studies with
computer science researchers, our approach substantially improves users&#x27;
abilities to do so. We develop an approach that locates commonalities and
contrasts between scientists---retrieving partially similar authors, rather
than aiming for strict similarity. We find this approach helps users discover
authors useful for generating novel research ideas of relevance to their work,
at a higher rate than a state-of-art neural model. Our analysis reveals that
Bridger connects authors who have different citation profiles, publish in
different venues, and are more distant in social co-authorship networks,
raising the prospect of bridging diverse communities and facilitating
discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Relevance Ranking under the Pre-training and Fine-tuning Paradigm. (arXiv:2108.05652v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Lin Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">XiuQiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05652">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pre-trained language models such as BERT have been applied to
document ranking for information retrieval, which first pre-train a general
language model on an unlabeled large corpus and then conduct ranking-specific
fine-tuning on expert-labeled relevance datasets. Ideally, an IR system would
model relevance from a user-system dualism: the user&#x27;s view and the system&#x27;s
view. User&#x27;s view judges the relevance based on the activities of &quot;real users&quot;
while the system&#x27;s view focuses on the relevance signals from the system side,
e.g., from the experts or algorithms, etc. Inspired by the user-system
relevance views and the success of pre-trained language models, in this paper
we propose a novel ranking framework called Pre-Rank that takes both user&#x27;s
view and system&#x27;s view into consideration, under the pre-training and
fine-tuning paradigm. Specifically, to model the user&#x27;s view of relevance,
Pre-Rank pre-trains the initial query-document representations based on
large-scale user activities data such as the click log. To model the system&#x27;s
view of relevance, Pre-Rank further fine-tunes the model on expert-labeled
relevance data. More importantly, the pre-trained representations, are
fine-tuned together with handcrafted learning-to-rank features under a wide and
deep network architecture. In this way, Pre-Rank can model the relevance by
incorporating the relevant knowledge and signals from both real search users
and the IR experts. To verify the effectiveness of Pre-Rank, we showed two
implementations by using BERT and SetRank as the underlying ranking model,
respectively. Experimental results base on three publicly available benchmarks
showed that in both of the implementations, Pre-Rank can respectively
outperform the underlying ranking models and achieved state-of-the-art
performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Diverse Descriptions from Semantic Graphs. (arXiv:2108.05659v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiuzhou Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_D/0/1/0/all/0/1">Daniel Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1">Trevor Cohn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05659">
                                    <div class="article-summary-box-inner">
                                        <span>Text generation from semantic graphs is traditionally performed with
deterministic methods, which generate a unique description given an input
graph. However, the generation problem admits a range of acceptable textual
outputs, exhibiting lexical, syntactic and semantic variation. To address this
disconnect, we present two main contributions. First, we propose a stochastic
graph-to-text model, incorporating a latent variable in an encoder-decoder
model, and its use in an ensemble. Second, to assess the diversity of the
generated sentences, we propose a new automatic evaluation metric which jointly
evaluates output diversity and quality in a multi-reference setting. We
evaluate the models on WebNLG datasets in English and Russian, and show an
ensemble of stochastic models produces diverse sets of generated sentences,
while retaining similar quality to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval. (arXiv:2108.05540v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Luyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1">Jamie Callan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05540">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research demonstrates the effectiveness of using fine-tuned language
models~(LM) for dense retrieval. However, dense retrievers are hard to train,
typically requiring heavily engineered fine-tuning pipelines to realize their
full potential. In this paper, we identify and address two underlying problems
of dense retrievers: i)~fragility to training data noise and ii)~requiring
large batches to robustly learn the embedding space. We use the recently
proposed Condenser pre-training architecture, which learns to condense
information into the dense vector through LM pre-training. On top of it, we
propose coCondenser, which adds an unsupervised corpus-level contrastive loss
to warm up the passage embedding space. Retrieval experiments on MS-MARCO,
Natural Question, and Trivia QA datasets show that coCondenser removes the need
for heavy data engineering such as augmentation, synthesis, or filtering, as
well as the need for large batch training. It shows comparable performance to
RocketQA, a state-of-the-art, heavily engineered system, using simple small
batch fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing. (arXiv:2108.05542v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalyan_K/0/1/0/all/0/1">Katikapalli Subramanyam Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajasekharan_A/0/1/0/all/0/1">Ajit Rajasekharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangeetha_S/0/1/0/all/0/1">Sivanesan Sangeetha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05542">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based pretrained language models (T-PTLMs) have achieved great
success in almost every NLP task. The evolution of these models started with
GPT and BERT. These models are built on the top of transformers,
self-supervised learning and transfer learning. Transformed-based PTLMs learn
universal language representations from large volumes of text data using
self-supervised learning and transfer this knowledge to downstream tasks. These
models provide good background knowledge to downstream tasks which avoids
training of downstream models from scratch. In this comprehensive survey paper,
we initially give a brief overview of self-supervised learning. Next, we
explain various core concepts like pretraining, pretraining methods,
pretraining tasks, embeddings and downstream adaptation methods. Next, we
present a new taxonomy of T-PTLMs and then give brief overview of various
benchmarks including both intrinsic and extrinsic. We present a summary of
various useful libraries to work with T-PTLMs. Finally, we highlight some of
the future research directions which will further improve these models. We
strongly believe that this comprehensive survey paper will serve as a good
reference to learn the core concepts as well as to stay updated with the recent
happenings in T-PTLMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kicktionary-LOME: A Domain-Specific Multilingual Frame Semantic Parsing Model for Football Language. (arXiv:2108.05575v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Minnema_G/0/1/0/all/0/1">Gosse Minnema</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05575">
                                    <div class="article-summary-box-inner">
                                        <span>This technical report introduces an adapted version of the LOME frame
semantic parsing model (Xia et al., EACL 2021) which is capable of
automatically annotating texts according to the &quot;Kicktionary&quot; domain-specific
framenet resource. Several methods for training a model even with limited
available training data are proposed. While there are some challenges for
evaluation related to the nature of the available annotations, preliminary
results are very promising, with the best model reaching F1-scores of 0.83
(frame prediction) and 0.81 (semantic role prediction).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generation Challenges: Results of the Accuracy Evaluation Shared Task. (arXiv:2108.05644v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomson_C/0/1/0/all/0/1">Craig Thomson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reiter_E/0/1/0/all/0/1">Ehud Reiter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05644">
                                    <div class="article-summary-box-inner">
                                        <span>The Shared Task on Evaluating Accuracy focused on techniques (both manual and
automatic) for evaluating the factual accuracy of texts produced by neural NLG
systems, in a sports-reporting domain. Four teams submitted evaluation
techniques for this task, using very different approaches and techniques. The
best-performing submissions did encouragingly well at this difficult task.
However, all automatic submissions struggled to detect factual errors which are
semantically or pragmatically complex (for example, based on incorrect
computation or inference).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethereum Data Structures. (arXiv:2108.05513v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jezek_K/0/1/0/all/0/1">Kamil Jezek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05513">
                                    <div class="article-summary-box-inner">
                                        <span>Ethereum platform operates with rich spectrum of data structures and hashing
and coding functions. The main source describing them is the Yellow paper,
complemented by a lot of informal blogs. These sources are somehow limited. In
particular, the Yellow paper does not ideally balance brevity and detail, in
some parts it is very detail, while too shallow elsewhere. The blogs on the
other hand are often too vague and in certain cases contain incorrect
information. As a solution, we provide this document, which summarises data
structures used in Ethereum. The goal is to provide sufficient detail while
keeping brevity. Sufficiently detailed formal view is enriched with examples to
extend on clarity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacks against Ranking Algorithms with Text Embeddings: a Case Study on Recruitment Algorithms. (arXiv:2108.05490v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samadi_A/0/1/0/all/0/1">Anahita Samadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1">Debapriya Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nilizadeh_S/0/1/0/all/0/1">Shirin Nilizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05490">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, some studies have shown that text classification tasks are
vulnerable to poisoning and evasion attacks. However, little work has
investigated attacks against decision making algorithms that use text
embeddings, and their output is a ranking. In this paper, we focus on ranking
algorithms for recruitment process, that employ text embeddings for ranking
applicants resumes when compared to a job description. We demonstrate both
white box and black box attacks that identify text items, that based on their
location in embedding space, have significant contribution in increasing the
similarity score between a resume and a job description. The adversary then
uses these text items to improve the ranking of their resume among others. We
tested recruitment algorithms that use the similarity scores obtained from
Universal Sentence Encoder (USE) and Term Frequency Inverse Document Frequency
(TF IDF) vectors. Our results show that in both adversarial settings, on
average the attacker is successful. We also found that attacks against TF IDF
is more successful compared to USE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes. (arXiv:2108.05615v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1">Dongki Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jaehoon Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yonghan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Deokhwa Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Changick Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1">Dinesh Manocha</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Donghwan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05615">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach for estimating depth from a monocular camera as
it moves through complex and crowded indoor environments, e.g., a department
store or a metro station. Our approach predicts absolute scale depth maps over
the entire scene consisting of a static background and multiple moving people,
by training on dynamic scenes. Since it is difficult to collect dense depth
maps from crowded indoor environments, we design our training framework without
requiring depths produced from depth sensing devices. Our network leverages RGB
images and sparse depth maps generated from traditional 3D reconstruction
methods to estimate dense depth maps. We use two constraints to handle depth
for non-rigidly moving people without tracking their motion explicitly. We
demonstrate that our approach offers consistent improvements over recent depth
estimation methods on the NAVERLABS dataset, which includes complex and crowded
scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep PET/CT fusion with Dempster-Shafer theory for lymphoma segmentation. (arXiv:2108.05422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Ling Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Denoeux_T/0/1/0/all/0/1">Thierry Denoeux</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonnelet_D/0/1/0/all/0/1">David Tonnelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Decazes_P/0/1/0/all/0/1">Pierre Decazes</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_S/0/1/0/all/0/1">Su Ruan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05422">
                                    <div class="article-summary-box-inner">
                                        <span>Lymphoma detection and segmentation from whole-body Positron Emission
Tomography/Computed Tomography (PET/CT) volumes are crucial for surgical
indication and radiotherapy. Designing automatic segmentation methods capable
of effectively exploiting the information from PET and CT as well as resolving
their uncertainty remain a challenge. In this paper, we propose an lymphoma
segmentation model using an UNet with an evidential PET/CT fusion layer.
Single-modality volumes are trained separately to get initial segmentation maps
and an evidential fusion layer is proposed to fuse the two pieces of evidence
using Dempster-Shafer theory (DST). Moreover, a multi-task loss function is
proposed: in addition to the use of the Dice loss for PET and CT segmentation,
a loss function based on the concordance between the two segmentation is added
to constrain the final segmentation. We evaluate our proposal on a database of
polycentric PET/CT volumes of patients treated for lymphoma, delineated by the
experts. Our method get accurate segmentation results with Dice score of 0.726,
without any user interaction. Quantitative results show that our method is
superior to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search From Task Similarity Measure. (arXiv:2103.00241v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1">Cat P. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltani_M/0/1/0/all/0/1">Mohammadreza Soltani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravier_R/0/1/0/all/0/1">Robert Ravier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00241">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a neural architecture search framework based on a
similarity measure between the baseline tasks and the incoming target task. We
first define the notion of task similarity based on the log-determinant of the
Fisher Information Matrices. Next, we compute the task similarity from each of
the baseline tasks to the incoming target task. By utilizing the relation
between a target and a set of learned baseline tasks, the search space of
architectures for the incoming target task can be significantly reduced, making
the discovery of the best candidates in the set of possible architectures
tractable and efficient, in terms of GPU days. This method eliminates the
requirement for training the networks from scratch for the incoming target task
as well as introducing the bias in the initialization of the search space from
the human domain. Experimental results with 8 classification tasks in MNIST and
CIFAR-10 datasets illustrate the efficacy of our proposed approach and its
competitiveness with other state-of-art methods in terms of the classification
performance, the number of parameters, and the search time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Image Semantic Segmentation. (arXiv:2107.13978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chang-Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Peng-Tao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_F/0/1/0/all/0/1">Feng Mao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13978">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation models trained on public datasets have achieved great
success in recent years. However, these models didn&#x27;t consider the
personalization issue of segmentation though it is important in practice. In
this paper, we address the problem of personalized image segmentation. The
objective is to generate more accurate segmentation results on unlabeled
personalized images by investigating the data&#x27;s personalized traits. To open up
future research in this area, we collect a large dataset containing various
users&#x27; personalized images called PIS (Personalized Image Semantic
Segmentation). We also survey some recent researches related to this problem
and report their performance on our dataset. Furthermore, by observing the
correlation among a user&#x27;s personalized images, we propose a baseline method
that incorporates the inter-image context when segmenting certain images.
Extensive experiments show that our method outperforms the existing methods on
the proposed dataset. The code and the PIS dataset will be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations. (arXiv:2108.05851v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zike Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuxin Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xuesong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1">Ping Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongbin Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05851">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances have enabled a single neural network to serve as an implicit
scene representation, establishing the mapping function between spatial
coordinates and scene properties. In this paper, we make a further step towards
continual learning of the implicit scene representation directly from
sequential observations, namely Continual Neural Mapping. The proposed problem
setting bridges the gap between batch-trained implicit neural representations
and commonly used streaming data in robotics and vision communities. We
introduce an experience replay approach to tackle an exemplary task of
continual neural mapping: approximating a continuous signed distance function
(SDF) from sequential depth images as a scene geometry representation. We show
for the first time that a single network can represent scene geometry over time
continually without catastrophic forgetting, while achieving promising
trade-offs between accuracy and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Oriented R-CNN for Object Detection. (arXiv:2108.05699v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xingxing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Gong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiabao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xiwen Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junwei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05699">
                                    <div class="article-summary-box-inner">
                                        <span>Current state-of-the-art two-stage detectors generate oriented proposals
through time-consuming schemes. This diminishes the detectors&#x27; speed, thereby
becoming the computational bottleneck in advanced oriented object detection
systems. This work proposes an effective and simple oriented object detection
framework, termed Oriented R-CNN, which is a general two-stage oriented
detector with promising accuracy and efficiency. To be specific, in the first
stage, we propose an oriented Region Proposal Network (oriented RPN) that
directly generates high-quality oriented proposals in a nearly cost-free
manner. The second stage is oriented R-CNN head for refining oriented Regions
of Interest (oriented RoIs) and recognizing them. Without tricks, oriented
R-CNN with ResNet50 achieves state-of-the-art detection accuracy on two
commonly-used datasets for oriented object detection including DOTA (75.87%
mAP) and HRSC2016 (96.50% mAP), while having a speed of 15.1 FPS with the image
size of 1024$\times$1024 on a single RTX 2080Ti. We hope our work could inspire
rethinking the design of oriented detectors and serve as a baseline for
oriented object detection. Code is available at
https://github.com/jbwang1997/OBBDetection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing the State of the Art: A Critical Look at Visual Representation Evaluation. (arXiv:1912.00215v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1">Cinjon Resnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zeping Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00215">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised research improved greatly over the past half decade, with
much of the growth being driven by objectives that are hard to quantitatively
compare. These techniques include colorization, cyclical consistency, and
noise-contrastive estimation from image patches. Consequently, the field has
settled on a handful of measurements that depend on linear probes to adjudicate
which approaches are the best. Our first contribution is to show that this test
is insufficient and that models which perform poorly (strongly) on linear
classification can perform strongly (weakly) on more involved tasks like
temporal activity localization. Our second contribution is to analyze the
capabilities of five different representations. And our third contribution is a
much needed new dataset for temporal activity localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiview Detection with Shadow Transformer (and View-Coherent Data Augmentation). (arXiv:2108.05888v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yunzhong Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05888">
                                    <div class="article-summary-box-inner">
                                        <span>Multiview detection incorporates multiple camera views to deal with
occlusions, and its central problem is multiview aggregation. Given feature map
projections from multiple views onto a common ground plane, the
state-of-the-art method addresses this problem via convolution, which applies
the same calculation regardless of object locations. However, such
translation-invariant behaviors might not be the best choice, as object
features undergo various projection distortions according to their positions
and cameras. In this paper, we propose a novel multiview detector, MVDeTr, that
adopts a newly introduced shadow transformer to aggregate multiview
information. Unlike convolutions, shadow transformer attends differently at
different positions and cameras to deal with various shadow-like distortions.
We propose an effective training scheme that includes a new view-coherent data
augmentation method, which applies random augmentations while maintaining
multiview consistency. On two multiview detection benchmarks, we report new
state-of-the-art accuracy with the proposed system. Code is available at
https://github.com/hou-yz/MVDeTr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascade Bagging for Accuracy Prediction with Few Training Samples. (arXiv:2108.05613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xubo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheyang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05613">
                                    <div class="article-summary-box-inner">
                                        <span>Accuracy predictor is trained to predict the validation accuracy of an
network from its architecture encoding. It can effectively assist in designing
networks and improving Neural Architecture Search(NAS) efficiency. However, a
high-performance predictor depends on adequate trainning samples, which
requires unaffordable computation overhead. To alleviate this problem, we
propose a novel framework to train an accuracy predictor under few training
samples. The framework consists ofdata augmentation methods and an ensemble
learning algorithm. The data augmentation methods calibrate weak labels and
inject noise to feature space. The ensemble learning algorithm, termed cascade
bagging, trains two-level models by sampling data and features. In the end, the
advantages of above methods are proved in the Performance Prediciton Track of
CVPR2021 1st Lightweight NAS Challenge. Our code is made public at:
https://github.com/dlongry/Solutionto-CVPR2021-NAS-Track2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TF-Blender: Temporal Feature Blender for Video Object Detection. (arXiv:2108.05821v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yiming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Liqi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhiwen Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dongfang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05821">
                                    <div class="article-summary-box-inner">
                                        <span>Video objection detection is a challenging task because isolated video frames
may encounter appearance deterioration, which introduces great confusion for
detection. One of the popular solutions is to exploit the temporal information
and enhance per-frame representation through aggregating features from
neighboring frames. Despite achieving improvements in detection, existing
methods focus on the selection of higher-level video frames for aggregation
rather than modeling lower-level temporal relations to increase the feature
representation. To address this limitation, we propose a novel solution named
TF-Blender,which includes three modules: 1) Temporal relation mod-els the
relations between the current frame and its neighboring frames to preserve
spatial information. 2). Feature adjustment enriches the representation of
every neigh-boring feature map; 3) Feature blender combines outputs from the
first two modules and produces stronger features for the later detection tasks.
For its simplicity, TF-Blender can be effortlessly plugged into any detection
network to improve detection behavior. Extensive evaluations on ImageNet VID
and YouTube-VIS benchmarks indicate the performance guarantees of using
TF-Blender on recent state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resetting the baseline: CT-based COVID-19 diagnosis with Deep Transfer Learning is not as accurate as widely thought. (arXiv:2108.05649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altaf_F/0/1/0/all/0/1">Fouzia Altaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Syed M.S. Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is gaining instant popularity in computer aided diagnosis of
COVID-19. Due to the high sensitivity of Computed Tomography (CT) to this
disease, CT-based COVID-19 detection with visual models is currently at the
forefront of medical imaging research. Outcomes published in this direction are
frequently claiming highly accurate detection under deep transfer learning.
This is leading medical technologists to believe that deep transfer learning is
the mainstream solution for the problem. However, our critical analysis of the
literature reveals an alarming performance disparity between different
published results. Hence, we conduct a systematic thorough investigation to
analyze the effectiveness of deep transfer learning for COVID-19 detection with
CT images. Exploring 14 state-of-the-art visual models with over 200 model
training sessions, we conclusively establish that the published literature is
frequently overestimating transfer learning performance for the problem, even
in the prestigious scientific sources. The roots of overestimation trace back
to inappropriate data curation. We also provide case studies that consider more
realistic scenarios, and establish transparent baselines for the problem. We
hope that our reproducible investigation will help in curbing hype-driven
claims for the critical problem of COVID-19 diagnosis, and pave the way for a
more transparent performance evaluation of techniques for CT-based COVID-19
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D-SiamRPN: An End-to-End Learning Method for Real-Time 3D Single Object Tracking Using Raw Point Cloud. (arXiv:2108.05630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sifan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yubo Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05630">
                                    <div class="article-summary-box-inner">
                                        <span>3D single object tracking is a key issue for autonomous following robot,
where the robot should robustly track and accurately localize the target for
efficient following. In this paper, we propose a 3D tracking method called
3D-SiamRPN Network to track a single target object by using raw 3D point cloud
data. The proposed network consists of two subnetworks. The first subnetwork is
feature embedding subnetwork which is used for point cloud feature extraction
and fusion. In this subnetwork, we first use PointNet++ to extract features of
point cloud from template and search branches. Then, to fuse the information of
features in the two branches and obtain their similarity, we propose two cross
correlation modules, named Pointcloud-wise and Point-wise respectively. The
second subnetwork is region proposal network(RPN), which is used to get the
final 3D bounding box of the target object based on the fusion feature from
cross correlation modules. In this subnetwork, we utilize the regression and
classification branches of a region proposal subnetwork to obtain proposals and
scores, thus get the final 3D bounding box of the target object. Experimental
results on KITTI dataset show that our method has a competitive performance in
both Success and Precision compared to the state-of-the-art methods, and could
run in real-time at 20.8 FPS. Additionally, experimental results on H3D dataset
demonstrate that our method also has good generalization ability and could
achieve good tracking performance in a new scene without re-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-aware Synthesis of High-resolution Diffusion from Structural Imaging. (arXiv:2108.04135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anctil_Robitaille_B/0/1/0/all/0/1">Benoit Anctil-Robitaille</a>, <a href="http://arxiv.org/find/cs/1/au:+Theberge_A/0/1/0/all/0/1">Antoine Th&#xe9;berge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1">Maxime Descoteaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Christian Desrosiers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombaert_H/0/1/0/all/0/1">Herv&#xe9; Lombaert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04135">
                                    <div class="article-summary-box-inner">
                                        <span>The physical and clinical constraints surrounding diffusion-weighted imaging
(DWI) often limit the spatial resolution of the produced images to voxels up to
8 times larger than those of T1w images. Thus, the detailed information
contained in T1w imagescould help in the synthesis of diffusion images in
higher resolution. However, the non-Euclidean nature of diffusion imaging
hinders current deep generative models from synthesizing physically plausible
images. In this work, we propose the first Riemannian network architecture for
the direct generation of diffusion tensors (DT) and diffusion orientation
distribution functions (dODFs) from high-resolution T1w images. Our integration
of the Log-Euclidean Metric into a learning objective guarantees, unlike
standard Euclidean networks, the mathematically-valid synthesis of diffusion.
Furthermore, our approach improves the fractional anisotropy mean squared error
(FA MSE) between the synthesized diffusion and the ground-truth by more than
23% and the cosine similarity between principal directions by almost 5% when
compared to our baselines. We validate our generated diffusion by comparing the
resulting tractograms to our expected real data. We observe similar fiber
bundles with streamlines having less than 3% difference in length, less than 1%
difference in volume, and a visually close shape. While our method is able to
generate high-resolution diffusion images from structural inputs in less than
15 seconds, we acknowledge and discuss the limits of diffusion inference solely
relying on T1w images. Our results nonetheless suggest a relationship between
the high-level geometry of the brain and the overall white matter architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Vision Transformer. (arXiv:2012.12556v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">An Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaohui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiman Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12556">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer, first applied to the field of natural language processing, is a
type of deep neural network mainly based on the self-attention mechanism.
Thanks to its strong representation capabilities, researchers are looking at
ways to apply transformer to computer vision tasks. In a variety of visual
benchmarks, transformer-based models perform similar to or better than other
types of networks such as convolutional and recurrent networks. Given its high
performance and less need for vision-specific inductive bias, transformer is
receiving more and more attention from the computer vision community. In this
paper, we review these vision transformer models by categorizing them in
different tasks and analyzing their advantages and disadvantages. The main
categories we explore include the backbone network, high/mid-level vision,
low-level vision, and video processing. We also include efficient transformer
methods for pushing transformer into real device-based applications.
Furthermore, we also take a brief look at the self-attention mechanism in
computer vision, as it is the base component in transformer. Toward the end of
this paper, we discuss the challenges and provide several further research
directions for vision transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction. (arXiv:2108.02110v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhao_M/0/1/0/all/0/1">Minyi Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1">Shuigeng Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02110">
                                    <div class="article-summary-box-inner">
                                        <span>A number of deep learning based algorithms have been proposed to recover
high-quality videos from low-quality compressed ones. Among them, some restore
the missing details of each frame via exploring the spatiotemporal information
of neighboring frames. However, these methods usually suffer from a narrow
temporal scope, thus may miss some useful details from some frames outside the
neighboring ones. In this paper, to boost artifact removal, on the one hand, we
propose a Recursive Fusion (RF) module to model the temporal dependency within
a long temporal range. Specifically, RF utilizes both the current reference
frames and the preceding hidden state to conduct better spatiotemporal
compensation. On the other hand, we design an efficient and effective
Deformable Spatiotemporal Attention (DSTA) module such that the model can pay
more effort on restoring the artifact-rich areas like the boundary area of a
moving object. Extensive experiments show that our method outperforms the
existing ones on the MFQE 2.0 dataset in terms of both fidelity and perceptual
effect. Code is available at https://github.com/zhaominyiz/RFDA-PyTorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification. (arXiv:2101.08467v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chaoyou Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yibo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Hailin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ran He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08467">
                                    <div class="article-summary-box-inner">
                                        <span>Visible-Infrared person re-identification (VI-ReID) aims to match
cross-modality pedestrian images, breaking through the limitation of
single-modality person ReID in dark environment. In order to mitigate the
impact of large modality discrepancy, existing works manually design various
two-stream architectures to separately learn modality-specific and
modality-sharable representations. Such a manual design routine, however,
highly depends on massive experiments and empirical practice, which is time
consuming and labor intensive. In this paper, we systematically study the
manually designed architectures, and identify that appropriately separating
Batch Normalization (BN) layers is the key to bring a great boost towards
cross-modality matching. Based on this observation, the essential objective is
to find the optimal separation scheme for each BN layer. To this end, we
propose a novel method, named Cross-Modality Neural Architecture Search
(CM-NAS). It consists of a BN-oriented search space in which the standard
optimization can be fulfilled subject to the cross-modality task. Equipped with
the searched architecture, our method outperforms state-of-the-art counterparts
in both two benchmarks, improving the Rank-1/mAP by 6.70%/6.13% on SYSU-MM01
and by 12.17%/11.23% on RegDB. Code is released at
https://github.com/JDAI-CV/CM-NAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Roll-off Points Variations: Exploring Useful Information in Feature Maps by Its Variations. (arXiv:2102.00369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yunkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yuyang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guozheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peiyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_W/0/1/0/all/0/1">Wenjing Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00369">
                                    <div class="article-summary-box-inner">
                                        <span>Useful information (UI) is an elusive concept in neural networks. A
quantitative measurement of UI is absent, despite the variations of UI can be
recognized by prior knowledge. The communication bandwidth of feature maps
decreases after downscaling operations, but UI flows smoothly after training
due to lower Nyquist frequency. Inspired by the low-Nyqusit-frequency nature of
UI, we propose the use of spectral roll-off points (SROPs) to estimate UI on
variations. The computation of an SROP is extended from a 1-D signal to a 2-D
image by the required rotation invariance in image classification tasks. SROP
statistics across feature maps are implemented as layer-wise useful information
estimates. We design sanity checks to explore SROP variations when UI
variations are produced by variations in model input, model architecture and
training stages. The variations of SROP is synchronizes with UI variations in
various randomized and sufficiently trained model structures. Therefore, SROP
variations is an accurate and convenient sign of UI variations, which promotes
the explainability of data representations with respect to frequency-domain
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Mitigation of Face Recognition Models Through Calibration. (arXiv:2106.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salvador_T/0/1/0/all/0/1">Tiago Salvador</a>, <a href="http://arxiv.org/find/cs/1/au:+Cairns_S/0/1/0/all/0/1">Stephanie Cairns</a>, <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marshall_N/0/1/0/all/0/1">Noah Marshall</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition models suffer from bias: for example, the probability of a
false positive (incorrect face match) strongly depends on sensitive attributes
like ethnicity. As a result, these models may disproportionately and negatively
impact minority groups when used in law enforcement. In this work, we introduce
the Bias Mitigation Calibration (BMC) method, which (i) increases model
accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated
probabilities, (iii) significantly reduces the gap in the false positive rates,
and (iv) does not require knowledge of the sensitive attribute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v11 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10762">
                                    <div class="article-summary-box-inner">
                                        <span>Random field and random cluster theory are used to describe certain
mathematical results concerning the probability distribution of image pixel
intensities characterized as generic $2D$ integer arrays. The size of the
smallest bounded region within an image is estimated for segmenting an image,
from which, the equilibrium distribution of intensities can be recovered. From
the estimated bounded regions, properties of the sub-optimal and equilibrium
distributions of intensities are derived, which leads to an image compression
methodology whereby only slightly more than half of all pixels are required for
a worst-case reconstruction of the original image. A custom deep belief network
and heuristic allows for the unsupervised segmentation, detection and
localization of objects in an image. An example illustrates the mathematical
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EV-VGCNN: A Voxel Graph CNN for Event-based Object Classification. (arXiv:2106.00216v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yongjian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huiying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Youfu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00216">
                                    <div class="article-summary-box-inner">
                                        <span>Event cameras report sparse intensity changes and hold noticeable advantages
of low power consumption, high dynamic range, and high response speed for
visual perception and understanding on portable devices. Event-based learning
methods have recently achieved massive success on object recognition by
integrating events into dense frame-based representations to apply traditional
2D learning algorithms. However, these approaches introduce much redundant
information during the sparse-to-dense conversion and necessitate models with
heavy-weight and large capacities, limiting the potential of event cameras on
real-life applications. To address the core problem of balancing accuracy and
model complexity for event-based classification models, we (1) construct graph
representations for event data to utilize their sparsity nature better and
design a lightweight end-to-end graph neural network (EV-VGCNN) for
classification; (2) use voxel-wise vertices rather than traditional point-wise
methods to incorporate the information from more points; (3) introduce a
multi-scale feature relational layer (MFRL) to extract semantic and motion cues
from each vertex adaptively concerning its distances to neighbors.
Comprehensive experiments show that our approach advances state-of-the-art
classification accuracy while achieving nearly 20 times parameter reduction
(merely 0.84M parameters).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation. (arXiv:2107.11264v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Sanghun Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungsoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gwak_D/0/1/0/all/0/1">Daehoon Gwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Sungha Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11264">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying unexpected objects on roads in semantic segmentation (e.g.,
identifying dogs on roads) is crucial in safety-critical applications. Existing
approaches use images of unexpected objects from external datasets or require
additional training (e.g., retraining segmentation networks or training an
extra network), which necessitate a non-trivial amount of labor intensity or
lengthy inference time. One possible alternative is to use prediction scores of
a pre-trained network such as the max logits (i.e., maximum values among
classes before the final softmax layer) for detecting such objects. However,
the distribution of max logits of each predicted class is significantly
different from each other, which degrades the performance of identifying
unexpected objects in urban-scene segmentation. To address this issue, we
propose a simple yet effective approach that standardizes the max logits in
order to align the different distributions and reflect the relative meanings of
max logits within each predicted class. Moreover, we consider the local regions
from two different perspectives based on the intuition that neighboring pixels
share similar semantic information. In contrast to previous approaches, our
method does not utilize any external datasets or require additional training,
which makes our method widely applicable to existing pre-trained segmentation
models. Such a straightforward approach achieves a new state-of-the-art
performance on the publicly available Fishyscapes Lost &amp; Found leaderboard with
a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransVG: End-to-End Visual Grounding with Transformers. (arXiv:2104.08541v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiajun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhengyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08541">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a neat yet effective transformer-based framework
for visual grounding, namely TransVG, to address the task of grounding a
language query to the corresponding region onto an image. The state-of-the-art
methods, including two-stage or one-stage ones, rely on a complex module with
manually-designed mechanisms to perform the query reasoning and multi-modal
fusion. However, the involvement of certain mechanisms in fusion module design,
such as query decomposition and image scene graph, makes the models easily
overfit to datasets with specific scenarios, and limits the plenitudinous
interaction between the visual-linguistic context. To avoid this caveat, we
propose to establish the multi-modal correspondence by leveraging transformers,
and empirically show that the complex fusion modules (\eg, modular attention
network, dynamic graph, and multi-modal tree) can be replaced by a simple stack
of transformer encoder layers with higher performance. Moreover, we
re-formulate the visual grounding as a direct coordinates regression problem
and avoid making predictions out of a set of candidates (\emph{i.e.}, region
proposals or anchor boxes). Extensive experiments are conducted on five widely
used datasets, and a series of state-of-the-art records are set by our TransVG.
We build the benchmark of transformer-based visual grounding framework and make
the code available at \url{https://github.com/djiajunustc/TransVG}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivAug: Plug-in Automated Data Augmentation with Explicit Diversity Maximization. (arXiv:2103.14545v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zirui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Haifeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Ting-Hsiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaixiong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14545">
                                    <div class="article-summary-box-inner">
                                        <span>Human-designed data augmentation strategies have been replaced by
automatically learned augmentation policy in the past two years. Specifically,
recent work has empirically shown that the superior performance of the
automated data augmentation methods stems from increasing the diversity of
augmented data \cite{autoaug, randaug}. However, two factors regarding the
diversity of augmented data are still missing: 1) the explicit definition (and
thus measurement) of diversity and 2) the quantifiable relationship between
diversity and its regularization effects. To bridge this gap, we propose a
diversity measure called Variance Diversity and theoretically show that the
regularization effect of data augmentation is promised by Variance Diversity.
We validate in experiments that the relative gain from automated data
augmentation in test accuracy is highly correlated to Variance Diversity. An
unsupervised sampling-based framework, \textbf{DivAug}, is designed to directly
maximize Variance Diversity and hence strengthen the regularization effect.
Without requiring a separate search process, the performance gain from DivAug
is comparable with the state-of-the-art method with better efficiency.
Moreover, under the semi-supervised setting, our framework can further improve
the performance of semi-supervised learning algorithms compared to RandAugment,
making it highly applicable to real-world problems, where labeled data is
scarce. The code is available at
\texttt{\url{https://github.com/warai-0toko/DivAug}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamical Pose Estimation. (arXiv:2103.06182v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Heng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Doran_C/0/1/0/all/0/1">Chris Doran</a>, <a href="http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1">Jean-Jacques Slotine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06182">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of aligning two sets of 3D geometric primitives given
known correspondences. Our first contribution is to show that this primitive
alignment framework unifies five perception problems including point cloud
registration, primitive (mesh) registration, category-level 3D registration,
absolution pose estimation (APE), and category-level APE. Our second
contribution is to propose DynAMical Pose estimation (DAMP), the first general
and practical algorithm to solve primitive alignment problem by simulating
rigid body dynamics arising from virtual springs and damping, where the springs
span the shortest distances between corresponding primitives. We evaluate DAMP
in simulated and real datasets across all five problems, and demonstrate (i)
DAMP always converges to the globally optimal solution in the first three
problems with 3D-3D correspondences; (ii) although DAMP sometimes converges to
suboptimal solutions in the last two problems with 2D-3D correspondences, using
a scheme for escaping local minima, DAMP always succeeds. Our third
contribution is to demystify the surprising empirical performance of DAMP and
formally prove a global convergence result in the case of point cloud
registration by charactering local stability of the equilibrium points of the
underlying dynamical system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MicroNet: Improving Image Recognition with Extremely Low FLOPs. (arXiv:2108.05894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1">Nuno Vasconcelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05894">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims at addressing the problem of substantial performance
degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet
classification). We found that two factors, sparse connectivity and dynamic
activation function, are effective to improve the accuracy. The former avoids
the significant reduction of network width, while the latter mitigates the
detriment of reduction in network depth. Technically, we propose
micro-factorized convolution, which factorizes a convolution matrix into low
rank matrices, to integrate sparse connectivity into convolution. We also
present a new dynamic activation function, named Dynamic Shift Max, to improve
the non-linearity via maxing out multiple dynamic fusions between an input
feature map and its circular channel shift. Building upon these two new
operators, we arrive at a family of networks, named MicroNet, that achieves
significant performance gains over the state of the art in the low FLOP regime.
For instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\% top-1
accuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\%. Source
code is at
\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Concentration for Domain Adaptation. (arXiv:2108.05720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Mixue Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fangrui Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chi Harold Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05720">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation (DA) paves the way for label annotation and dataset bias
issues by the knowledge transfer from a label-rich source domain to a related
but unlabeled target domain. A mainstream of DA methods is to align the feature
distributions of the two domains. However, the majority of them focus on the
entire image features where irrelevant semantic information, e.g., the messy
background, is inevitably embedded. Enforcing feature alignments in such case
will negatively influence the correct matching of objects and consequently lead
to the semantically negative transfer due to the confusion of irrelevant
semantics. To tackle this issue, we propose Semantic Concentration for Domain
Adaptation (SCDA), which encourages the model to concentrate on the most
principal features via the pair-wise adversarial alignment of prediction
distributions. Specifically, we train the classifier to class-wisely maximize
the prediction distribution divergence of each sample pair, which enables the
model to find the region with large differences among the same class of
samples. Meanwhile, the feature extractor attempts to minimize that
discrepancy, which suppresses the features of dissimilar regions among the same
class of samples and accentuates the features of principal parts. As a general
method, SCDA can be easily integrated into various DA methods as a regularizer
to further boost their performance. Extensive experiments on the cross-domain
benchmarks show the efficacy of SCDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">m-RevNet: Deep Reversible Neural Networks with Momentum. (arXiv:2108.05862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shang-Hua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05862">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the connections between deep residual networks and
first-order Ordinary Differential Equations (ODEs) have been disclosed. In this
work, we further bridge the deep neural architecture design with the
second-order ODEs and propose a novel reversible neural network, termed as
m-RevNet, that is characterized by inserting momentum update to residual
blocks. The reversible property allows us to perform backward pass without
access to activation values of the forward pass, greatly relieving the storage
burden during training. Furthermore, the theoretical foundation based on
second-order ODEs grants m-RevNet with stronger representational power than
vanilla residual networks, which potentially explains its performance gains.
For certain learning scenarios, we analytically and empirically reveal that our
m-RevNet succeeds while standard ResNet fails. Comprehensive experiments on
various image classification and semantic segmentation benchmarks demonstrate
the superiority of our m-RevNet over ResNet, concerning both memory efficiency
and recognition performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Test-time Augmentation for Content-based Image Retrieval. (arXiv:2002.01642v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Osman Tursun</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.01642">
                                    <div class="article-summary-box-inner">
                                        <span>Off-the-shelf convolutional neural network features achieve outstanding
results in many image retrieval tasks. However, their invariance to target data
is pre-defined by the network architecture and training data. Existing image
retrieval approaches require fine-tuning or modification of pre-trained
networks to adapt to variations unique to the target data. In contrast, our
method enhances the invariance of off-the-shelf features by aggregating
features extracted from images augmented at test-time, with augmentations
guided by a policy learned through reinforcement learning. The learned policy
assigns different magnitudes and weights to the selected transformations, which
are selected from a list of image transformations. Policies are evaluated using
a metric learning protocol to learn the optimal policy. The model converges
quickly and the cost of each policy iteration is minimal as we propose an
off-line caching technique to greatly reduce the computational cost of
extracting features from augmented images. Experimental results on large
trademark retrieval (METU trademark dataset) and landmark retrieval (ROxford5k
and RParis6k scene datasets) tasks show that the learned ensemble of
transformations is highly effective for improving performance, and is
practical, and transferable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Deep Metric Learning with Structural Matching. (arXiv:2108.05889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05889">
                                    <div class="article-summary-box-inner">
                                        <span>How do the neural networks distinguish two images? It is of critical
importance to understand the matching mechanism of deep models for developing
reliable intelligent systems for many risky visual applications such as
surveillance and access control. However, most existing deep metric learning
methods match the images by comparing feature vectors, which ignores the
spatial structure of images and thus lacks interpretability. In this paper, we
present a deep interpretable metric learning (DIML) method for more transparent
embedding learning. Unlike conventional metric learning methods based on
feature vector comparison, we propose a structural matching strategy that
explicitly aligns the spatial embeddings by computing an optimal matching flow
between feature maps of the two images. Our method enables deep models to learn
metrics in a more human-friendly way, where the similarity of two images can be
decomposed to several part-wise similarities and their contributions to the
overall similarity. Our method is model-agnostic, which can be applied to
off-the-shelf backbone networks and metric learning methods. We evaluate our
method on three major benchmarks of deep metric learning including CUB200-2011,
Cars196, and Stanford Online Products, and achieve substantial improvements
over popular metric learning methods with better interpretability. Code is
available at https://github.com/wl-zhao/DIML</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Visual Attribute Learning for Fashion Compatibility. (arXiv:2008.00348v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_K/0/1/0/all/0/1">Kuniaki Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Samarth Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1">Stan Sclaroff</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1">Bryan A Plummer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00348">
                                    <div class="article-summary-box-inner">
                                        <span>Many self-supervised learning (SSL) methods have been successful in learning
semantically meaningful visual representations by solving pretext tasks.
However, prior work in SSL focuses on tasks like object recognition or
detection, which aim to learn object shapes and assume that the features should
be invariant to concepts like colors and textures. Thus, these SSL methods
perform poorly on downstream tasks where these concepts provide critical
information. In this paper, we present an SSL framework that enables us to
learn color and texture-aware features without requiring any labels during
training. Our approach consists of three self-supervised tasks designed to
capture different concepts that are neglected in prior work that we can select
from depending on the needs of our downstream tasks. Our tasks include learning
to predict color histograms and discriminate shapeless local patches and
textures from each instance. We evaluate our approach on fashion compatibility
using Polyvore Outfits and In-Shop Clothing Retrieval using Deepfashion,
improving upon prior SSL methods by 9.5-16%, and even outperforming some
supervised approaches on Polyvore Outfits despite using no labels. We also show
that our approach can be used for transfer learning, demonstrating that we can
train on one dataset while achieving high performance on a different dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation. (arXiv:2010.05903v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_L/0/1/0/all/0/1">Liron Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection methods require high-quality features. In recent years, the
anomaly detection community has attempted to obtain better features using
advances in deep self-supervised feature learning. Surprisingly, a very
promising direction, using pretrained deep features, has been mostly
overlooked. In this paper, we first empirically establish the perhaps expected,
but unreported result, that combining pretrained features with simple anomaly
detection and segmentation methods convincingly outperforms, much more complex,
state-of-the-art methods.

In order to obtain further performance gains in anomaly detection, we adapt
pretrained features to the target distribution. Although transfer learning
methods are well established in multi-class classification problems, the
one-class classification (OCC) setting is not as well explored. It turns out
that naive adaptation methods, which typically work well in supervised
learning, often result in catastrophic collapse (feature deterioration) and
reduce performance in OCC settings. A popular OCC method, DeepSVDD, advocates
using specialized architectures, but this limits the adaptation performance
gain. We propose two methods for combating collapse: i) a variant of early
stopping that dynamically learns the stopping iteration ii) elastic
regularization inspired by continual learning. Our method, PANDA, outperforms
the state-of-the-art in the OCC, outlier exposure and anomaly segmentation
settings by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MT-ORL: Multi-Task Occlusion Relationship Learning. (arXiv:2108.05722v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+ZHANG_L/0/1/0/all/0/1">Lin ZHANG</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zijian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05722">
                                    <div class="article-summary-box-inner">
                                        <span>Retrieving occlusion relation among objects in a single image is challenging
due to sparsity of boundaries in image. We observe two key issues in existing
works: firstly, lack of an architecture which can exploit the limited amount of
coupling in the decoder stage between the two subtasks, namely occlusion
boundary extraction and occlusion orientation prediction, and secondly,
improper representation of occlusion orientation. In this paper, we propose a
novel architecture called Occlusion-shared and Path-separated Network (OPNet),
which solves the first issue by exploiting rich occlusion cues in shared
high-level features and structured spatial information in task-specific
low-level features. We then design a simple but effective orthogonal occlusion
representation (OOR) to tackle the second issue. Our method surpasses the
state-of-the-art methods by 6.1%/8.3% Boundary-AP and 6.5%/10% Orientation-AP
on standard PIOD/BSDS ownership datasets. Code is available at
https://github.com/fengpanhe/MT-ORL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Descent Algorithm for Nonsmooth Nonconvex Image Reconstruction. (arXiv:2007.11245v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunmei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongcheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaojing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingchao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11245">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a general learning based framework for solving nonsmooth and
nonconvex image reconstruction problems. We model the regularization function
as the composition of the $l_{2,1}$ norm and a smooth but nonconvex feature
mapping parametrized as a deep convolutional neural network. We develop a
provably convergent descent-type algorithm to solve the nonsmooth nonconvex
minimization problem by leveraging the Nesterov&#x27;s smoothing technique and the
idea of residual learning, and learn the network parameters such that the
outputs of the algorithm match the references in training data. Our method is
versatile as one can employ various modern network structures into the
regularization, and the resulting network inherits the guaranteed convergence
of the algorithm. We also show that the proposed network is parameter-efficient
and its performance compares favorably to the state-of-the-art methods in a
variety of image reconstruction problems in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Approach to Partial Observability in Games: Learning to Both Act and Observe. (arXiv:2108.05701v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gilmour_E/0/1/0/all/0/1">Elizabeth Gilmour</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotkin_N/0/1/0/all/0/1">Noah Plotkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Leslie Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05701">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is successful at learning to play games where the
entire environment is visible. However, RL approaches are challenged in complex
games like Starcraft II and in real-world environments where the entire
environment is not visible. In these more complex games with more limited
visual information, agents must choose where to look and how to optimally use
their limited visual information in order to succeed at the game. We verify
that with a relatively simple model the agent can learn where to look in
scenarios with a limited visual bandwidth. We develop a method for masking part
of the environment in Atari games to force the RL agent to learn both where to
look and how to play the game in order to study where the RL agent learns to
look. In addition, we develop a neural network architecture and method for
allowing the agent to choose where to look and what action to take in the Pong
game. Further, we analyze the strategies the agent learns to better understand
how the RL agent learns to play the game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Billion-Scale Pretraining with Vision Transformers for Multi-Task Visual Representations. (arXiv:2108.05887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beal_J/0/1/0/all/0/1">Josh Beal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao-Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dong Huk Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_A/0/1/0/all/0/1">Andrew Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kislyuk_D/0/1/0/all/0/1">Dmitry Kislyuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05887">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretraining of visual representations has led to state-of-the-art
performance on a range of benchmark computer vision tasks, yet the benefits of
these techniques at extreme scale in complex production systems has been
relatively unexplored. We consider the case of a popular visual discovery
product, where these representations are trained with multi-task learning, from
use-case specific visual understanding (e.g. skin tone classification) to
general representation learning for all visual content (e.g. embeddings for
retrieval). In this work, we describe how we (1) generate a dataset with over a
billion images via large weakly-supervised pretraining to improve the
performance of these visual representations, and (2) leverage Transformers to
replace the traditional convolutional backbone, with insights into both system
and performance improvements, especially at 1B+ image scale. To support this
backbone model, we detail a systematic approach to deriving weakly-supervised
image annotations from heterogenous text signals, demonstrating the benefits of
clustering techniques to handle the long-tail distribution of image labels.
Through a comprehensive study of offline and online evaluation, we show that
large-scale Transformer-based pretraining provides significant benefits to
industry computer vision applications. The model is deployed in a production
visual shopping system, with 36% improvement in top-1 relevance and 23%
improvement in click-through volume. We conduct extensive experiments to better
understand the empirical relationships between Transformer-based architectures,
dataset scale, and the performance of production vision systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-driven Graph Clustering Network. (arXiv:2108.05499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhihao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuheng Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05499">
                                    <div class="article-summary-box-inner">
                                        <span>The combination of the traditional convolutional network (i.e., an
auto-encoder) and the graph convolutional network has attracted much attention
in clustering, in which the auto-encoder extracts the node attribute feature
and the graph convolutional network captures the topological graph feature.
However, the existing works (i) lack a flexible combination mechanism to
adaptively fuse those two kinds of features for learning the discriminative
representation and (ii) overlook the multi-scale information embedded at
different layers for subsequent cluster assignment, leading to inferior
clustering results. To this end, we propose a novel deep clustering method
named Attention-driven Graph Clustering Network (AGCN). Specifically, AGCN
exploits a heterogeneity-wise fusion module to dynamically fuse the node
attribute feature and the topological graph feature. Moreover, AGCN develops a
scale-wise fusion module to adaptively aggregate the multi-scale features
embedded at different layers. Based on a unified optimization framework, AGCN
can jointly perform feature learning and cluster assignment in an unsupervised
fashion. Compared with the existing deep clustering methods, our method is more
flexible and effective since it comprehensively considers the numerous and
discriminative information embedded in the network and directly produces the
clustering results. Extensive quantitative and qualitative results on commonly
used benchmark datasets validate that our AGCN consistently outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Holistic Knowledge with Graph Neural Networks. (arXiv:2108.05507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yucheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Defang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Can Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1">Jiajun Bu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05507">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) aims at transferring knowledge from a larger
well-optimized teacher network to a smaller learnable student network.Existing
KD methods have mainly considered two types of knowledge, namely the individual
knowledge and the relational knowledge. However, these two types of knowledge
are usually modeled independently while the inherent correlations between them
are largely ignored. It is critical for sufficient student network learning to
integrate both individual knowledge and relational knowledge while reserving
their inherent correlation. In this paper, we propose to distill the novel
holistic knowledge based on an attributed graph constructed among instances.
The holistic knowledge is represented as a unified graph-based embedding by
aggregating individual knowledge from relational neighborhood samples with
graph neural networks, the student network is learned by distilling the
holistic knowledge in a contrastive manner. Extensive experiments and ablation
studies are conducted on benchmark datasets, the results demonstrate the
effectiveness of the proposed method. The code has been published in
https://github.com/wyc-ruiker/HKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yuzhe Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yueh-Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hanwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05877">
                                    <div class="article-summary-box-inner">
                                        <span>While we have made significant progress on understanding hand-object
interactions in computer vision, it is still very challenging for robots to
perform complex dexterous manipulation. In this paper, we propose a new
platform and pipeline, DexMV (Dex Manipulation from Videos), for imitation
learning to bridge the gap between computer vision and robot learning. We
design a platform with: (i) a simulation system for complex dexterous
manipulation tasks with a multi-finger robot hand and (ii) a computer vision
system to record large-scale demonstrations of a human hand conducting the same
tasks. In our new pipeline, we extract 3D hand and object poses from the
videos, and convert them to robot demonstrations via motion retargeting. We
then apply and compare multiple imitation learning algorithms with the
demonstrations. We show that the demonstrations can indeed improve robot
learning by a large margin and solve the complex tasks which reinforcement
learning alone cannot solve. Project page with video:
https://yzqin.github.io/dexmv/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">perf4sight: A toolflow to model CNN training performance on Edge GPUs. (arXiv:2108.05580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_A/0/1/0/all/0/1">Aditya Rajagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1">Christos-Savvas Bouganis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05580">
                                    <div class="article-summary-box-inner">
                                        <span>The increased memory and processing capabilities of today&#x27;s edge devices
create opportunities for greater edge intelligence. In the domain of vision,
the ability to adapt a Convolutional Neural Network&#x27;s (CNN) structure and
parameters to the input data distribution leads to systems with lower memory
footprint, latency and power consumption. However, due to the limited compute
resources and memory budget on edge devices, it is necessary for the system to
be able to predict the latency and memory footprint of the training process in
order to identify favourable training configurations of the network topology
and device combination for efficient network adaptation. This work proposes
perf4sight, an automated methodology for developing accurate models that
predict CNN training memory footprint and latency given a target device and
network. This enables rapid identification of network topologies that can be
retrained on the edge device with low resource consumption. With PyTorch as the
framework and NVIDIA Jetson TX2 as the target device, the developed models
predict training memory footprint and latency with 95% and 91% accuracy
respectively for a wide range of networks, opening the path towards efficient
network adaptation on edge GPUs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation. (arXiv:2108.05570v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shin_I/0/1/0/all/0/1">Inkyu Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sanghyun Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kwanyong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05570">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) for semantic segmentation has been
actively studied to mitigate the domain gap between label-rich source data and
unlabeled target data. Despite these efforts, UDA still has a long way to go to
reach the fully supervised performance. To this end, we propose a Labeling Only
if Required strategy, LabOR, where we introduce a human-in-the-loop approach to
adaptively give scarce labels to points that a UDA model is uncertain about. In
order to find the uncertain points, we generate an inconsistency mask using the
proposed adaptive pixel selector and we label these segment-based regions to
achieve near supervised performance with only a small fraction (about 2.2%)
ground truth points, which we call &quot;Segment based Pixel-Labeling (SPL)&quot;. To
further reduce the efforts of the human annotator, we also propose &quot;Point-based
Pixel-Labeling (PPL)&quot;, which finds the most representative points for labeling
within the generated inconsistency mask. This reduces efforts from 2.2% segment
label to 40 points label while minimizing performance degradation. Through
extensive experimentation, we show the advantages of this new framework for
domain adaptive semantic segmentation while minimizing human labor costs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision. (arXiv:2108.05863v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaoshi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1">Hadar Averbuch-Elor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1">Noah Snavely</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05863">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance and richness of Internet photos of landmarks and cities has led
to significant progress in 3D vision over the past two decades, including
automated 3D reconstructions of the world&#x27;s landmarks from tourist photos.
However, a major source of information available for these 3D-augmented
collections---namely language, e.g., from image captions---has been virtually
untapped. In this work, we present WikiScenes, a new, large-scale dataset of
landmark photo collections that contains descriptive text in the form of
captions and hierarchical category names. WikiScenes forms a new testbed for
multimodal reasoning involving images, text, and 3D geometry. We demonstrate
the utility of WikiScenes for learning semantic concepts over images and 3D
models. Our weakly-supervised framework connects images, 3D structure, and
semantics---utilizing the strong constraints provided by 3D geometry---to
associate semantic concepts to image pixels and 3D points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation. (arXiv:2011.06294v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhewei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1">Wen Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuchang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06294">
                                    <div class="article-summary-box-inner">
                                        <span>We propose RIFE, a Real-time Intermediate Flow Estimation algorithm for Video
Frame Interpolation (VFI). Many recent flow-based VFI methods first estimate
the bi-directional optical flows, then scale and reverse them to approximate
intermediate flows, leading to artifacts on motion boundaries. RIFE uses a
neural network named IFNet that can directly estimate the intermediate flows
from coarse-to-fine with much better speed. We design a privileged distillation
scheme for training intermediate flow model, which leads to a large performance
improvement. Experiments demonstrate that RIFE is flexible and can achieve
state-of-the-art performance on several public benchmarks. The code is
available at \url{https://github.com/hzwer/arXiv2020-RIFE}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Gaze Analysis: A Survey of DeepLearning based Approaches. (arXiv:2108.05479v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Shreya Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhall_A/0/1/0/all/0/1">Abhinav Dhall</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Knibbe_J/0/1/0/all/0/1">Jarrod Knibbe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1">Qiang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05479">
                                    <div class="article-summary-box-inner">
                                        <span>Eye gaze analysis is an important research problem in the field of computer
vision and Human-Computer Interaction (HCI). Even with significant progress in
the last few years, automatic gaze analysis still remains challenging due to
the individuality of eyes, eye-head interplay, occlusion, image quality, and
illumination conditions. There are several open questions including what are
the important cues to interpret gaze direction in an unconstrained environment
without prior knowledge and how to encode them in real-time. We review the
progress across a range of gaze analysis tasks and applications to shed light
on these fundamental questions; identify effective methods in gaze analysis and
provide possible future directions. We analyze recent gaze estimation and
segmentation methods, especially in the unsupervised and weakly supervised
domain, based on their advantages and reported evaluation metrics. Our analysis
shows that the development of a robust and generic gaze analysis method still
needs to address real-world challenges such as unconstrained setup and learning
with less supervision. We conclude by discussing future research directions for
designing a real-world gaze analysis system that can propagate to other domains
including computer vision, AR (Augmented Reality), VR (Virtual Reality), and
HCI (Human Computer Interaction).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Silhouette based View embeddings for Gait Recognition under Multiple Views. (arXiv:2108.05524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1">Tianrui Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_X/0/1/0/all/0/1">Xinyu Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Annan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05524">
                                    <div class="article-summary-box-inner">
                                        <span>Gait recognition under multiple views is an important computer vision and
pattern recognition task. In the emerging convolutional neural network based
approaches, the information of view angle is ignored to some extent. Instead of
direct view estimation and training view-specific recognition models, we
propose a compatible framework that can embed view information into existing
architectures of gait recognition. The embedding is simply achieved by a
selective projection layer. Experimental results on two large public datasets
show that the proposed framework is very effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Temporal Variational AutoEncoder for Action Video Prediction. (arXiv:2108.05658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaogang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05658">
                                    <div class="article-summary-box-inner">
                                        <span>To synthesize a realistic action sequence based on a single human image, it
is crucial to model both motion patterns and diversity in the action video.
This paper proposes an Action Conditional Temporal Variational AutoEncoder
(ACT-VAE) to improve motion prediction accuracy and capture movement diversity.
ACT-VAE predicts pose sequences for an action clips from a single input image.
It is implemented as a deep generative model that maintains temporal coherence
according to the action category with a novel temporal modeling on latent
space. Further, ACT-VAE is a general action sequence prediction framework. When
connected with a plug-and-play Pose-to-Image (P2I) network, ACT-VAE can
synthesize image sequences. Extensive experiments bear out our approach can
predict accurate pose and synthesize realistic image sequences, surpassing
state-of-the-art approaches. Compared to existing methods, ACT-VAE improves
model accuracy and preserves diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile-Former: Bridging MobileNet and Transformer. (arXiv:2108.05895v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05895">
                                    <div class="article-summary-box-inner">
                                        <span>We present Mobile-Former, a parallel design of MobileNet and Transformer with
a two-way bridge in between. This structure leverages the advantage of
MobileNet at local processing and transformer at global interaction. And the
bridge enables bidirectional fusion of local and global features. Different
with recent works on vision transformer, the transformer in Mobile-Former
contains very few tokens (e.g. less than 6 tokens) that are randomly
initialized, resulting in low computational cost. Combining with the proposed
light-weight cross attention to model the bridge, Mobile-Former is not only
computationally efficient, but also has more representation power,
outperforming MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet
classification. For instance, it achieves 77.9\% top-1 accuracy at 294M FLOPs,
gaining 1.3\% over MobileNetV3 but saving 17\% of computations. When
transferring to object detection, Mobile-Former outperforms MobileNetV3 by 8.6
AP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Camera Obscura: An Image Restoration Pipeline for Lensless Pinhole Photography. (arXiv:2108.05563v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rego_J/0/1/0/all/0/1">Joshua D. Rego</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huaijin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinwei Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasuriya_S/0/1/0/all/0/1">Suren Jayasuriya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05563">
                                    <div class="article-summary-box-inner">
                                        <span>The lensless pinhole camera is perhaps the earliest and simplest form of an
imaging system using only a pinhole-sized aperture in place of a lens. They can
capture an infinite depth-of-field and offer greater freedom from optical
distortion over their lens-based counterparts. However, the inherent
limitations of a pinhole system result in lower sharpness from blur caused by
optical diffraction and higher noise levels due to low light throughput of the
small aperture, requiring very long exposure times to capture well-exposed
images. In this paper, we explore an image restoration pipeline using deep
learning and domain-knowledge of the pinhole system to enhance the pinhole
image quality through a joint denoise and deblur approach. Our approach allows
for more practical exposure times for hand-held photography and provides higher
image quality, making it more suitable for daily photography compared to other
lensless cameras while keeping size and cost low. This opens up the potential
of pinhole cameras to be used in smaller devices, such as smartphones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preventing Catastrophic Forgetting and Distribution Mismatch in Knowledge Distillation via Synthetic Data. (arXiv:2108.05698v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Binici_K/0/1/0/all/0/1">Kuluhan Binici</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1">Nam Trung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1">Tulika Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Leman_K/0/1/0/all/0/1">Karianto Leman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05698">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing popularity of deep learning on edge devices, compressing
large neural networks to meet the hardware requirements of resource-constrained
devices became a significant research direction. Numerous compression
methodologies are currently being used to reduce the memory sizes and energy
consumption of neural networks. Knowledge distillation (KD) is among such
methodologies and it functions by using data samples to transfer the knowledge
captured by a large model (teacher) to a smaller one(student). However, due to
various reasons, the original training data might not be accessible at the
compression stage. Therefore, data-free model compression is an ongoing
research problem that has been addressed by various works. In this paper, we
point out that catastrophic forgetting is a problem that can potentially be
observed in existing data-free distillation methods. Moreover, the sample
generation strategies in some of these methods could result in a mismatch
between the synthetic and real data distributions. To prevent such problems, we
propose a data-free KD framework that maintains a dynamic collection of
generated samples over time. Additionally, we add the constraint of matching
the real data distribution in sample generation strategies that target maximum
information gain. Our experiments demonstrate that we can improve the accuracy
of the student models obtained via KD when compared with state-of-the-art
approaches on the SVHN, Fashion MNIST and CIFAR100 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Presenting an extensive lab- and field-image dataset of crops and weeds for computer vision tasks in agriculture. (arXiv:2108.05789v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_M/0/1/0/all/0/1">Michael A. Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen-Yi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidinosti_C/0/1/0/all/0/1">Christopher P. Bidinosti</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_C/0/1/0/all/0/1">Christopher J. Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Godee_C/0/1/0/all/0/1">Cara M. Godee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ajmani_M/0/1/0/all/0/1">Manisha Ajmani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05789">
                                    <div class="article-summary-box-inner">
                                        <span>We present two large datasets of labelled plant-images that are suited
towards the training of machine learning and computer vision models. The first
dataset encompasses as the day of writing over 1.2 million images of
indoor-grown crops and weeds common to the Canadian Prairies and many US
states. The second dataset consists of over 540,000 images of plants imaged in
farmland. All indoor plant images are labelled by species and we provide rich
etadata on the level of individual images. This comprehensive database allows
to filter the datasets under user-defined specifications such as for example
the crop-type or the age of the plant. Furthermore, the indoor dataset contains
images of plants taken from a wide variety of angles, including profile shots,
top-down shots, and angled perspectives. The images taken from plants in fields
are all from a top-down perspective and contain usually multiple plants per
image. For these images metadata is also available. In this paper we describe
both datasets&#x27; characteristics with respect to plant variety, plant age, and
number of images. We further introduce an open-access sample of the
indoor-dataset that contains 1,000 images of each species covered in our
dataset. These, in total 14,000 images, had been selected, such that they form
a representative sample with respect to plant age and ndividual plants per
species. This sample serves as a quick entry point for new users to the
dataset, allowing them to explore the data on a small scale and find the
parameters of data most useful for their application without having to deal
with hundreds of thousands of individual images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unconditional Scene Graph Generation. (arXiv:2108.05884v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sarthak Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamo_H/0/1/0/all/0/1">Helisa Dhamo</a>, <a href="http://arxiv.org/find/cs/1/au:+Farshad_A/0/1/0/all/0/1">Azade Farshad</a>, <a href="http://arxiv.org/find/cs/1/au:+Musatian_S/0/1/0/all/0/1">Sabrina Musatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05884">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent advancements in single-domain or single-object image
generation, it is still challenging to generate complex scenes containing
diverse, multiple objects and their interactions. Scene graphs, composed of
nodes as objects and directed-edges as relationships among objects, offer an
alternative representation of a scene that is more semantically grounded than
images. We hypothesize that a generative model for scene graphs might be able
to learn the underlying semantic structure of real-world scenes more
effectively than images, and hence, generate realistic novel scenes in the form
of scene graphs. In this work, we explore a new task for the unconditional
generation of semantic scene graphs. We develop a deep auto-regressive model
called SceneGraphGen which can directly learn the probability distribution over
labelled and directed graphs using a hierarchical recurrent architecture. The
model takes a seed object as input and generates a scene graph in a sequence of
steps, each step generating an object node, followed by a sequence of
relationship edges connecting to the previous nodes. We show that the scene
graphs generated by SceneGraphGen are diverse and follow the semantic patterns
of real-world scenes. Additionally, we demonstrate the application of the
generated graphs in image synthesis, anomaly detection and scene graph
completion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PixelSynth: Generating a 3D-Consistent Experience from a Single Image. (arXiv:2108.05892v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rockwell_C/0/1/0/all/0/1">Chris Rockwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Fouhey_D/0/1/0/all/0/1">David F. Fouhey</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_J/0/1/0/all/0/1">Justin Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05892">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in differentiable rendering and 3D reasoning have driven
exciting results in novel view synthesis from a single image. Despite realistic
results, methods are limited to relatively small view change. In order to
synthesize immersive scenes, models must also be able to extrapolate. We
present an approach that fuses 3D reasoning with autoregressive modeling to
outpaint large view changes in a 3D-consistent manner, enabling scene
synthesis. We demonstrate considerable improvement in single image large-angle
view synthesis results compared to a variety of methods and possible variants
across simulated and real datasets. In addition, we show increased 3D
consistency compared to alternative accumulation methods. Project website:
https://crockwell.github.io/pixelsynth/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniFaceGAN: A Unified Framework for Temporally Consistent Facial Video Editing. (arXiv:2108.05650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haozhi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05650">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has witnessed advances in facial image editing tasks
including face swapping and face reenactment. However, these methods are
confined to dealing with one specific task at a time. In addition, for video
facial editing, previous methods either simply apply transformations frame by
frame or utilize multiple frames in a concatenated or iterative fashion, which
leads to noticeable visual flickers. In this paper, we propose a unified
temporally consistent facial video editing framework termed UniFaceGAN. Based
on a 3D reconstruction model and a simple yet efficient dynamic training sample
selection mechanism, our framework is designed to handle face swapping and face
reenactment simultaneously. To enforce the temporal consistency, a novel 3D
temporal loss constraint is introduced based on the barycentric coordinate
interpolation. Besides, we propose a region-aware conditional normalization
layer to replace the traditional AdaIN or SPADE to synthesize more
context-harmonious results. Compared with the state-of-the-art facial image
editing methods, our framework generates video portraits that are more
photo-realistic and temporally smooth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards real-world navigation with deep differentiable planners. (arXiv:2108.05713v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishida_S/0/1/0/all/0/1">Shu Ishida</a>, <a href="http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1">Jo&#xe3;o F. Henriques</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05713">
                                    <div class="article-summary-box-inner">
                                        <span>We train embodied neural networks to plan and navigate unseen complex 3D
environments, emphasising real-world deployment. Rather than requiring prior
knowledge of the agent or environment, the planner learns to model the state
transitions and rewards. To avoid the potentially hazardous trial-and-error of
reinforcement learning, we focus on differentiable planners such as Value
Iteration Networks (VIN), which are trained offline from safe expert
demonstrations. Although they work well in small simulations, we address two
major limitations that hinder their deployment. First, we observed that current
differentiable planners struggle to plan long-term in environments with a high
branching complexity. While they should ideally learn to assign low rewards to
obstacles to avoid collisions, we posit that the constraints imposed on the
network are not strong enough to guarantee the network to learn sufficiently
large penalties for every possible collision. We thus impose a structural
constraint on the value iteration, which explicitly learns to model any
impossible actions. Secondly, we extend the model to work with a limited
perspective camera under translation and rotation, which is crucial for real
robot deployment. Many VIN-like planners assume a 360 degrees or overhead view
without rotation. In contrast, our method uses a memory-efficient lattice map
to aggregate CNN embeddings of partial observations, and models the rotational
dynamics explicitly using a 3D state-space grid (translation and rotation). Our
proposals significantly improve semantic navigation and exploration on several
2D and 3D environments, succeeding in settings that are otherwise challenging
for this class of methods. As far as we know, we are the first to successfully
perform differentiable planning on the difficult Active Vision Dataset,
consisting of real images captured from a robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds. (arXiv:2108.05836v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Runsong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zhen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tengping Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bisheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05836">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a neural network for robust normal estimation on point
clouds, named AdaFit, that can deal with point clouds with noise and density
variations. Existing works use a network to learn point-wise weights for
weighted least squares surface fitting to estimate the normals, which has
difficulty in finding accurate normals in complex regions or containing noisy
points. By analyzing the step of weighted least squares surface fitting, we
find that it is hard to determine the polynomial order of the fitting surface
and the fitting surface is sensitive to outliers. To address these problems, we
propose a simple yet effective solution that adds an additional offset
prediction to improve the quality of normal estimation. Furthermore, in order
to take advantage of points from different neighborhood sizes, a novel Cascaded
Scale Aggregation layer is proposed to help the network predict more accurate
point-wise offsets and weights. Extensive experiments demonstrate that AdaFit
achieves state-of-the-art performance on both the synthetic PCPNet dataset and
the real-word SceneNN dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVINS: Visual-Inertial SLAM for Centralized Collaboration. (arXiv:2108.05756v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmuck_P/0/1/0/all/0/1">Patrik Schmuck</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziegler_T/0/1/0/all/0/1">Thomas Ziegler</a>, <a href="http://arxiv.org/find/cs/1/au:+Karrer_M/0/1/0/all/0/1">Marco Karrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Perraudin_J/0/1/0/all/0/1">Jonathan Perraudin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chli_M/0/1/0/all/0/1">Margarita Chli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05756">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative SLAM enables a group of agents to simultaneously co-localize
and jointly map an environment, thus paving the way to wide-ranging
applications of multi-robot perception and multi-user AR experiences by
eliminating the need for external infrastructure or pre-built maps. This
article presents COVINS, a novel collaborative SLAM system, that enables
multi-agent, scalable SLAM in large environments and for large teams of more
than 10 agents. The paradigm here is that each agent runs visual-inertial
odomety independently onboard in order to ensure its autonomy, while sharing
map information with the COVINS server back-end running on a powerful local PC
or a remote cloud server. The server back-end establishes an accurate
collaborative global estimate from the contributed data, refining the joint
estimate by means of place recognition, global optimization and removal of
redundant data, in order to ensure an accurate, but also efficient SLAM
process. A thorough evaluation of COVINS reveals increased accuracy of the
collaborative SLAM estimates, as well as efficiency in both removing redundant
information and reducing the coordination overhead, and demonstrates successful
operation in a large-scale mission with 12 agents jointly performing SLAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Ranking Correlation of Supernet with Candidates Enhancement and Progressive Training. (arXiv:2108.05866v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xubo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheyang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05866">
                                    <div class="article-summary-box-inner">
                                        <span>One-shot neural architecture search (NAS) applies weight-sharing supernet to
reduce the unaffordable computation overhead of automated architecture
designing. However, the weight-sharing technique worsens the ranking
consistency of performance due to the interferences between different candidate
networks. To address this issue, we propose a candidates enhancement method and
progressive training pipeline to improve the ranking correlation of supernet.
Specifically, we carefully redesign the sub-networks in the supernet and map
the original supernet to a new one of high capacity. In addition, we gradually
add narrow branches of supernet to reduce the degree of weight sharing which
effectively alleviates the mutual interference between sub-networks. Finally,
our method ranks the 1st place in the Supernet Track of CVPR2021 1st
Lightweight NAS Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIDER: Single-Image Neural Optimization for Facial Geometric Detail Recovery. (arXiv:2108.05465v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatziagapi_A/0/1/0/all/0/1">Aggelina Chatziagapi</a>, <a href="http://arxiv.org/find/cs/1/au:+Athar_S/0/1/0/all/0/1">ShahRukh Athar</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1">Francesc Moreno-Noguer</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1">Dimitris Samaras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05465">
                                    <div class="article-summary-box-inner">
                                        <span>We present SIDER(Single-Image neural optimization for facial geometric DEtail
Recovery), a novel photometric optimization method that recovers detailed
facial geometry from a single image in an unsupervised manner. Inspired by
classical techniques of coarse-to-fine optimization and recent advances in
implicit neural representations of 3D shape, SIDER combines a geometry prior
based on statistical models and Signed Distance Functions (SDFs) to recover
facial details from single images. First, it estimates a coarse geometry using
a morphable model represented as an SDF. Next, it reconstructs facial geometry
details by optimizing a photometric loss with respect to the ground truth
image. In contrast to prior work, SIDER does not rely on any dataset priors and
does not require additional supervision from multiple views, lighting changes
or ground truth 3D shape. Extensive qualitative and quantitative evaluation
demonstrates that our method achieves state-of-the-art on facial geometric
detail recovery, using only a single in-the-wild image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DARTS for Inverse Problems: a Study on Hyperparameter Sensitivity. (arXiv:2108.05647v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1">Jovita Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05647">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) is a widely researched tool for
neural architecture search, due to its promising results for image
classification. The main benefit of DARTS is the effectiveness achieved through
the weight-sharing one-shot paradigm, which allows efficient architecture
search. In this work, we investigate DARTS in a systematic case study of
inverse problems, which allows us to analyze these potential benefits in a
controlled manner. Although we demonstrate that the success of DARTS can be
extended from image classification to reconstruction, our experiments yield
three fundamental difficulties in the evaluation of DARTS-based methods: First,
the results show a large variance in all test cases. Second, the final
performance is highly dependent on the hyperparameters of the optimizer. And
third, the performance of the weight-sharing architecture used during training
does not reflect the final performance of the found architecture well. Thus, we
conclude the necessity to 1) report the results of any DARTS-based methods from
several runs along with its underlying performance statistics, 2) show the
correlation of the training and final architecture performance, and 3)
carefully consider if the computational efficiency of DARTS outweighs the costs
of hyperparameter optimization and multiple runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation. (arXiv:2108.05773v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bangunharcana_A/0/1/0/all/0/1">Antyanta Bangunharcana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seokju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyung-Soo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohyun Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05773">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric deep learning approach towards stereo matching aggregates a cost
volume computed from input left and right images using 3D convolutions. Recent
works showed that utilization of extracted image features and a spatially
varying cost volume aggregation complements 3D convolutions. However, existing
methods with spatially varying operations are complex, cost considerable
computation time, and cause memory consumption to increase. In this work, we
construct Guided Cost volume Excitation (GCE) and show that simple channel
excitation of cost volume guided by image can improve performance considerably.
Moreover, we propose a novel method of using top-k selection prior to
soft-argmin disparity regression for computing the final disparity estimate.
Combining our novel contributions, we present an end-to-end network that we
call Correlate-and-Excite (CoEx). Extensive experiments of our model on the
SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate the effectiveness
and efficiency of our model and show that our model outperforms other
speed-based algorithms while also being competitive to other state-of-the-art
algorithms. Codes will be made available at https://github.com/antabangun/coex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Amended Gradient Descent for Efficient Spectral Reconstruction from Single RGB Images. (arXiv:2108.05547v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhiyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1">Sen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05547">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the problem of recovering hyperspectral (HS) images
from single RGB images. To tackle such a severely ill-posed problem, we propose
a physically-interpretable, compact, efficient, and end-to-end learning-based
framework, namely AGD-Net. Precisely, by taking advantage of the imaging
process, we first formulate the problem explicitly based on the classic
gradient descent algorithm. Then, we design a lightweight neural network with a
multi-stage architecture to mimic the formed amended gradient descent process,
in which efficient convolution and novel spectral zero-mean normalization are
proposed to effectively extract spatial-spectral features for regressing an
initialization, a basic gradient, and an incremental gradient. Besides, based
on the approximate low-rank property of HS images, we propose a novel rank loss
to promote the similarity between the global structures of reconstructed and
ground-truth HS images, which is optimized with our singular value weighting
strategy during training. Moreover, AGD-Net, a single network after one-time
training, is flexible to handle the reconstruction with various spectral
response functions. Extensive experiments over three commonly-used benchmark
datasets demonstrate that AGD-Net can improve the reconstruction quality by
more than 1.0 dB on average while saving 67$\times$ parameters and 32$\times$
FLOPs, compared with state-of-the-art methods. The code will be publicly
available at https://github.com/zbzhzhy/GD-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MISS GAN: A Multi-IlluStrator Style Generative Adversarial Network for image to illustration translation. (arXiv:2108.05693v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barzilay_N/0/1/0/all/0/1">Noa Barzilay</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalev_T/0/1/0/all/0/1">Tal Berkovitz Shalev</a>, <a href="http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05693">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised style transfer that supports diverse input styles using only one
trained generator is a challenging and interesting task in computer vision.
This paper proposes a Multi-IlluStrator Style Generative Adversarial Network
(MISS GAN) that is a multi-style framework for unsupervised
image-to-illustration translation, which can generate styled yet content
preserving images. The illustrations dataset is a challenging one since it is
comprised of illustrations of seven different illustrators, hence contains
diverse styles. Existing methods require to train several generators (as the
number of illustrators) to handle the different illustrators&#x27; styles, which
limits their practical usage, or require to train an image specific network,
which ignores the style information provided in other images of the
illustrator. MISS GAN is both input image specific and uses the information of
other images using only one trained model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Depth-Based Estimation of Object Articulation Models. (arXiv:2108.05875v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ajinkya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Giguere_S/0/1/0/all/0/1">Stephen Giguere</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1">Rudolf Lioutikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05875">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method that efficiently learns distributions over articulation
model parameters directly from depth images without the need to know
articulation model categories a priori. By contrast, existing methods that
learn articulation models from raw observations typically only predict point
estimates of the model parameters, which are insufficient to guarantee the safe
manipulation of articulated objects. Our core contributions include a novel
representation for distributions over rigid body transformations and
articulation model parameters based on screw theory, von Mises-Fisher
distributions, and Stiefel manifolds. Combining these concepts allows for an
efficient, mathematically sound representation that implicitly satisfies the
constraints that rigid body transformations and articulations must adhere to.
Leveraging this representation, we introduce a novel deep learning based
approach, DUST-net, that performs category-independent articulation model
estimation while also providing model uncertainties. We evaluate our approach
on several benchmarking datasets and real-world objects and compare its
performance with two current state-of-the-art methods. Our results demonstrate
that DUST-net can successfully learn distributions over articulation models for
novel objects across articulation model categories, which generate point
estimates with better accuracy than state-of-the-art methods and effectively
capture the uncertainty over predicted model parameters due to noisy inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Microlocal Reconstruction for Limited-Angle Tomography. (arXiv:2108.05732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andrade_Loarca_H/0/1/0/all/0/1">H&#xe9;ctor Andrade-Loarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1">Gitta Kutyniok</a>, <a href="http://arxiv.org/find/cs/1/au:+Oktem_O/0/1/0/all/0/1">Ozan &#xd6;ktem</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Philipp Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning-based algorithm to jointly solve a reconstruction
problem and a wavefront set extraction problem in tomographic imaging. The
algorithm is based on a recently developed digital wavefront set extractor as
well as the well-known microlocal canonical relation for the Radon transform.
We use the wavefront set information about x-ray data to improve the
reconstruction by requiring that the underlying neural networks simultaneously
extract the correct ground truth wavefront set and ground truth image. As a
necessary theoretical step, we identify the digital microlocal canonical
relations for deep convolutional residual neural networks. We find strong
numerical evidence for the effectiveness of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit Attenuating Weight Normalization. (arXiv:2108.05839v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aman Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanath_R/0/1/0/all/0/1">Rohan Ramanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1">Anika Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sirou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingzhou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Keerthi_S/0/1/0/all/0/1">S. Sathiya Keerthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05839">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized deep networks trained using gradient-based optimizers are
a popular choice for solving classification and ranking problems. Without
appropriately tuned $\ell_2$ regularization or weight decay, such networks have
the tendency to make output scores (logits) and network weights large, causing
training loss to become too small and the network to lose its adaptivity
(ability to move around) in the parameter space. Although regularization is
typically understood from an overfitting perspective, we highlight its role in
making the network more adaptive and enabling it to escape more easily from
weights that generalize poorly. To provide such a capability, we propose a
method called Logit Attenuating Weight Normalization (LAWN), that can be
stacked onto any gradient-based optimizer. LAWN controls the logits by
constraining the weight norms of layers in the final homogeneous sub-network.
Empirically, we show that the resulting LAWN variant of the optimizer makes a
deep network more adaptive to finding minimas with superior generalization
performance on large-scale image classification and recommender systems. While
LAWN is particularly impressive in improving Adam, it greatly improves all
optimizers when used with large batch sizes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Motion Prior for Weakly-Supervised Temporal Action Localization. (arXiv:2108.05607v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Can Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shou_M/0/1/0/all/0/1">Mike Zheng Shou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05607">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-Supervised Temporal Action Localization (WSTAL) aims to localize
actions in untrimmed videos with only video-level labels. Currently, most
state-of-the-art WSTAL methods follow a Multi-Instance Learning (MIL) pipeline:
producing snippet-level predictions first and then aggregating to the
video-level prediction. However, we argue that existing methods have overlooked
two important drawbacks: 1) inadequate use of motion information and 2) the
incompatibility of prevailing cross-entropy training loss. In this paper, we
analyze that the motion cues behind the optical flow features are complementary
informative. Inspired by this, we propose to build a context-dependent motion
prior, termed as motionness. Specifically, a motion graph is introduced to
model motionness based on the local motion carrier (e.g., optical flow). In
addition, to highlight more informative video snippets, a motion-guided loss is
proposed to modulate the network training conditioned on motionness scores.
Extensive ablation studies confirm that motionness efficaciously models
action-of-interest, and the motion-guided loss leads to more accurate results.
Besides, our motion-guided loss is a plug-and-play loss function and is
applicable with existing WSTAL methods. Without loss of generality, based on
the standard MIL pipeline, our method achieves new state-of-the-art performance
on three challenging benchmarks, including THUMOS&#x27;14, ActivityNet v1.2 and
v1.3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Visual Affordance Grounding from Demonstration Videos. (arXiv:2108.05675v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hongchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1">Wei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05675">
                                    <div class="article-summary-box-inner">
                                        <span>Visual affordance grounding aims to segment all possible interaction regions
between people and objects from an image/video, which is beneficial for many
applications, such as robot grasping and action recognition. However, existing
methods mainly rely on the appearance feature of the objects to segment each
region of the image, which face the following two problems: (i) there are
multiple possible regions in an object that people interact with; and (ii)
there are multiple possible human interactions in the same object region. To
address these problems, we propose a Hand-aided Affordance Grounding Network
(HAGNet) that leverages the aided clues provided by the position and action of
the hand in demonstration videos to eliminate the multiple possibilities and
better locate the interaction regions in the object. Specifically, HAG-Net has
a dual-branch structure to process the demonstration video and object image.
For the video branch, we introduce hand-aided attention to enhance the region
around the hand in each video frame and then use the LSTM network to aggregate
the action features. For the object branch, we introduce a semantic enhancement
module (SEM) to make the network focus on different parts of the object
according to the action classes and utilize a distillation loss to align the
output features of the object branch with that of the video branch and transfer
the knowledge in the video branch to the object branch. Quantitative and
qualitative evaluations on two challenging datasets show that our method has
achieved stateof-the-art results for affordance grounding. The source code will
be made available to the public.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Coordinate Transforms for Monocular 3D Object Detection. (arXiv:2108.05793v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Li Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiangyang Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05793">
                                    <div class="article-summary-box-inner">
                                        <span>Recognizing and localizing objects in the 3D space is a crucial ability for
an AI agent to perceive its surrounding environment. While significant progress
has been achieved with expensive LiDAR point clouds, it poses a great challenge
for 3D object detection given only a monocular image. While there exist
different alternatives for tackling this problem, it is found that they are
either equipped with heavy networks to fuse RGB and depth information or
empirically ineffective to process millions of pseudo-LiDAR points. With
in-depth examination, we realize that these limitations are rooted in
inaccurate object localization. In this paper, we propose a novel and
lightweight approach, dubbed Progressive Coordinate Transforms (PCT) to
facilitate learning coordinate representations. Specifically, a localization
boosting mechanism with confidence-aware loss is introduced to progressively
refine the localization prediction. In addition, semantic image repre-
sentation is also exploited to compensate for the usage of patch proposals.
Despite being lightweight and simple, our strategy leads to superior
improvements on the KITTI and Waymo Open Dataset monocular 3D detection
benchmarks. At the same time, our proposed PCT shows great generalization to
most coordinate- based 3D detection frameworks. The code is available at:
https://github.com/ amazon-research/progressive-coordinate-transforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robotic Testbed for Rendezvous and Optical Navigation: Multi-Source Calibration and Machine Learning Use Cases. (arXiv:2108.05529v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1">Tae Ha Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosse_J/0/1/0/all/0/1">Juergen Bosse</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmico_S/0/1/0/all/0/1">Simone D&#x27;Amico</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05529">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents the most recent advances of the Robotic Testbed for
Rendezvous and Optical Navigation (TRON) at Stanford University - the first
robotic testbed capable of validating machine learning algorithms for
spaceborne optical navigation. The TRON facility consists of two 6
degrees-of-freedom KUKA robot arms and a set of Vicon motion track cameras to
reconfigure an arbitrary relative pose between a camera and a target mockup
model. The facility includes multiple Earth albedo light boxes and a sun lamp
to recreate the high-fidelity spaceborne illumination conditions. After the
overview of the facility, this work details the multi-source calibration
procedure which enables the estimation of the relative pose between the object
and the camera with millimeter-level position and millidegree-level orientation
accuracies. Finally, a comparative analysis of the synthetic and TRON simulated
imageries is performed using a Convolutional Neural Network (CNN) pre-trained
on the synthetic images. The result shows a considerable gap in the CNN&#x27;s
performance, suggesting the TRON simulated images can be used to validate the
robustness of any machine learning algorithms trained on more easily accessible
synthetic imagery from computer graphics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities. (arXiv:2108.05779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eulig_E/0/1/0/all/0/1">Elias Eulig</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranrittichai_P/0/1/0/all/0/1">Piyapat Saranrittichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1">Chaithanya Kumar Mummadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambach_K/0/1/0/all/0/1">Kilian Rambach</a>, <a href="http://arxiv.org/find/cs/1/au:+Beluch_W/0/1/0/all/0/1">William Beluch</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiahan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_V/0/1/0/all/0/1">Volker Fischer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05779">
                                    <div class="article-summary-box-inner">
                                        <span>Common deep neural networks (DNNs) for image classification have been shown
to rely on shortcut opportunities (SO) in the form of predictive and
easy-to-represent visual factors. This is known as shortcut learning and leads
to impaired generalization. In this work, we show that common DNNs also suffer
from shortcut learning when predicting only basic visual object factors of
variation (FoV) such as shape, color, or texture. We argue that besides
shortcut opportunities, generalization opportunities (GO) are also an inherent
part of real-world vision data and arise from partial independence between
predicted classes and FoVs. We also argue that it is necessary for DNNs to
exploit GO to overcome shortcut learning. Our core contribution is to introduce
the Diagnostic Vision Benchmark suite DiagViB-6, which includes datasets and
metrics to study a network&#x27;s shortcut vulnerability and generalization
capability for six independent FoV. In particular, DiagViB-6 allows controlling
the type and degree of SO and GO in a dataset. We benchmark a wide range of
popular vision architectures and show that they can exploit GO only to a
limited extent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIODE: Dilatable Incremental Object Detection. (arXiv:2108.05627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Can Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Maksoud_S/0/1/0/all/0/1">Sam Maksoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovell_B/0/1/0/all/0/1">Brian C. Lovell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05627">
                                    <div class="article-summary-box-inner">
                                        <span>To accommodate rapid changes in the real world, the cognition system of
humans is capable of continually learning concepts. On the contrary,
conventional deep learning models lack this capability of preserving previously
learned knowledge. When a neural network is fine-tuned to learn new tasks, its
performance on previously trained tasks will significantly deteriorate. Many
recent works on incremental object detection tackle this problem by introducing
advanced regularization. Although these methods have shown promising results,
the benefits are often short-lived after the first incremental step. Under
multi-step incremental learning, the trade-off between old knowledge preserving
and new task learning becomes progressively more severe. Thus, the performance
of regularization-based incremental object detectors gradually decays for
subsequent learning steps. In this paper, we aim to alleviate this performance
decay on multi-step incremental detection tasks by proposing a dilatable
incremental object detector (DIODE). For the task-shared parameters, our method
adaptively penalizes the changes of important weights for previous tasks. At
the same time, the structure of the model is dilated or expanded by a limited
number of task-specific parameters to promote new task learning. Extensive
experiments on PASCAL VOC and COCO datasets demonstrate substantial
improvements over the state-of-the-art methods. Notably, compared with the
state-of-the-art methods, our method achieves up to 6.0% performance
improvement by increasing the number of parameters by just 1.2% for each newly
learned task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization. (arXiv:2108.05449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1">Haofu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05449">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms mine knowledge from the training data and thus would
likely inherit the dataset&#x27;s bias information. As a result, the obtained model
would generalize poorly and even mislead the decision process in real-life
applications. We propose to remove the bias information misused by the target
task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly
extracts target and bias features disentangled from the latent representation
generated by a feature extractor and then learns to discover and remove the
correlation between the target and bias features. The correlation measurement
plays a critical role in adversarial debiasing and is conducted by a
cross-sample neural mutual information estimator. Moreover, we propose joint
content and local structural representation learning to boost mutual
information estimation for better performance. We conduct thorough experiments
on publicly available datasets to validate the advantages of the proposed
method over state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Human Action Recognition Modelwith Flexible-interval Sampling and Normalization. (arXiv:2108.05633v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuke/0/1/0/all/0/1">Yuke</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang/0/1/0/all/0/1">Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05633">
                                    <div class="article-summary-box-inner">
                                        <span>Human action recognition is a well-known computer vision and pattern
recognition task of identifying which action a man is actually doing.
Extracting the keypoint information of a single human with both spatial and
temporal features of action sequences plays an essential role to accomplish the
task.In this paper, we propose a human action system for Red-Green-Blue(RGB)
input video with our own designed module. Based on the efficient Gated
Recurrent Unit(GRU) for spatio-temporal feature extraction, we add another
sampling module and normalization module to improve the performance of the
model in order to recognize the human actions. Furthermore, we build a novel
dataset with a similar background and discriminative actions for both human
keypoint prediction and behavior recognition. To get a better result, we
retrain the pose model with our new dataset to get better performance.
Experimental results demonstrate the effectiveness of the proposed model on our
own human behavior recognition dataset and some public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Medical Image Segmentation. (arXiv:2108.05476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_P/0/1/0/all/0/1">Pedro H. T. Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05476">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach for few-shot semantic segmentation
with sparse labeled images. We investigate the effectiveness of our method,
which is based on the Model-Agnostic Meta-Learning (MAML) algorithm, in the
medical scenario, where the use of sparse labeling and few-shot can alleviate
the cost of producing new annotated datasets. Our method uses sparse labels in
the meta-training and dense labels in the meta-test, thus making the model
learn to predict dense labels from sparse ones. We conducted experiments with
four Chest X-Ray datasets to evaluate two types of annotations (grid and
points). The results show that our method is the most suitable when the target
domain highly differs from source domains, achieving Jaccard scores comparable
to dense labels, using less than 2% of the pixels of an image with labels in
few-shot scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Semantic Segmentation for Off-road Unstructured Natural Environments. (arXiv:2108.05635v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Youngsaeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">David K. Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1">Hanseok Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05635">
                                    <div class="article-summary-box-inner">
                                        <span>With the availability of many datasets tailored for autonomous driving in
real-world urban scenes, semantic segmentation for urban driving scenes
achieves significant progress. However, semantic segmentation for off-road,
unstructured environments is not widely studied. Directly applying existing
segmentation networks often results in performance degradation as they cannot
overcome intrinsic problems in such environments, such as illumination changes.
In this paper, a built-in memory module for semantic segmentation is proposed
to overcome these problems. The memory module stores significant
representations of training images as memory items. In addition to the encoder
embedding like items together, the proposed memory module is specifically
designed to cluster together instances of the same class even when there are
significant variances in embedded features. Therefore, it makes segmentation
networks better deal with unexpected illumination changes. A triplet loss is
used in training to minimize redundancy in storing discriminative
representations of the memory module. The proposed memory module is general so
that it can be adopted in a variety of networks. We conduct experiments on the
Robot Unstructured Ground Driving (RUGD) dataset and RELLIS dataset, which are
collected from off-road, unstructured natural environments. Experimental
results show that the proposed memory module improves the performance of
existing segmentation networks and contributes to capturing unclear objects
over various off-road, unstructured natural scenes with equivalent
computational cost and network parameters. As the proposed method can be
integrated into compact networks, it presents a viable approach for
resource-limited small autonomous platforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iButter: Neural Interactive Bullet Time Generator for Human Free-viewpoint Rendering. (arXiv:2108.05577v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1">Pei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suo_X/0/1/0/all/0/1">Xin Suo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minye Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05577">
                                    <div class="article-summary-box-inner">
                                        <span>Generating &#x60;&#x60;bullet-time&#x27;&#x27; effects of human free-viewpoint videos is critical
for immersive visual effects and VR/AR experience. Recent neural advances still
lack the controllable and interactive bullet-time design ability for human
free-viewpoint rendering, especially under the real-time, dynamic and general
setting for our trajectory-aware task. To fill this gap, in this paper we
propose a neural interactive bullet-time generator (iButter) for
photo-realistic human free-viewpoint rendering from dense RGB streams, which
enables flexible and interactive design for human bullet-time visual effects.
Our iButter approach consists of a real-time preview and design stage as well
as a trajectory-aware refinement stage. During preview, we propose an
interactive bullet-time design approach by extending the NeRF rendering to a
real-time and dynamic setting and getting rid of the tedious per-scene
training. To this end, our bullet-time design stage utilizes a hybrid training
set, light-weight network design and an efficient silhouette-based sampling
strategy. During refinement, we introduce an efficient trajectory-aware scheme
within 20 minutes, which jointly encodes the spatial, temporal consistency and
semantic cues along the designed trajectory, achieving photo-realistic
bullet-time viewing experience of human activities. Extensive experiments
demonstrate the effectiveness of our approach for convenient interactive
bullet-time design and photo-realistic human free-viewpoint video generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal MRI Reconstruction with Spatial Alignment Network. (arXiv:2108.05603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xuan_K/0/1/0/all/0/1">Kai Xuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1">Lei Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaoqian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1">Dinggang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05603">
                                    <div class="article-summary-box-inner">
                                        <span>In clinical practice, magnetic resonance imaging (MRI) with multiple
contrasts is usually acquired in a single study to assess different properties
of the same region of interest in human body. The whole acquisition process can
be accelerated by having one or more modalities under-sampled in the k-space.
Recent researches demonstrate that, considering the redundancy between
different contrasts or modalities, a target MRI modality under-sampled in the
k-space can be better reconstructed with the helps from a fully-sampled
sequence (i.e., the reference modality). It implies that, in the same study of
the same subject, multiple sequences can be utilized together toward the
purpose of highly efficient multi-modal reconstruction. However, we find that
multi-modal reconstruction can be negatively affected by subtle spatial
misalignment between different sequences, which is actually common in clinical
practice. In this paper, we integrate the spatial alignment network with
reconstruction, to improve the quality of the reconstructed target modality.
Specifically, the spatial alignment network estimates the spatial misalignment
between the fully-sampled reference and the under-sampled target images, and
warps the reference image accordingly. Then, the aligned fully-sampled
reference image joins the under-sampled target image in the reconstruction
network, to produce the high-quality target image. Considering the contrast
difference between the target and the reference, we particularly design the
cross-modality-synthesis-based registration loss, in combination with the
reconstruction loss, to jointly train the spatial alignment network and the
reconstruction network. Our experiments on both clinical MRI and multi-coil
k-space raw data demonstrate the superiority and robustness of our spatial
alignment network. Code is publicly available at
https://github.com/woxuankai/SpatialAlignmentNetwork.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning for Irrigation Detection in Satellite Imagery. (arXiv:2108.05484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agastya_C/0/1/0/all/0/1">Chitra Agastya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghebremusse_S/0/1/0/all/0/1">Sirak Ghebremusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_I/0/1/0/all/0/1">Ian Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahabi_H/0/1/0/all/0/1">Hossein Vahabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Todeschini_A/0/1/0/all/0/1">Alberto Todeschini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05484">
                                    <div class="article-summary-box-inner">
                                        <span>Climate change has caused reductions in river runoffs and aquifer recharge
resulting in an increasingly unsustainable crop water demand from reduced
freshwater availability. Achieving food security while deploying water in a
sustainable manner will continue to be a major challenge necessitating careful
monitoring and tracking of agricultural water usage. Historically, monitoring
water usage has been a slow and expensive manual process with many
imperfections and abuses. Ma-chine learning and remote sensing developments
have increased the ability to automatically monitor irrigation patterns, but
existing techniques often require curated and labelled irrigation data, which
are expensive and time consuming to obtain and may not exist for impactful
areas such as developing countries. In this paper, we explore an end-to-end
real world application of irrigation detection with uncurated and unlabeled
satellite imagery. We apply state-of-the-art self-supervised deep learning
techniques to optical remote sensing data, and find that we are able to detect
irrigation with up to nine times better precision, 90% better recall and 40%
more generalization ability than the traditional supervised learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Voxel-level Importance Maps for Interpretable Brain Age Estimation. (arXiv:2108.05388v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bintsi_K/0/1/0/all/0/1">Kyriaki-Margarita Bintsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Baltatzis_V/0/1/0/all/0/1">Vasileios Baltatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammers_A/0/1/0/all/0/1">Alexander Hammers</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05388">
                                    <div class="article-summary-box-inner">
                                        <span>Brain aging, and more specifically the difference between the chronological
and the biological age of a person, may be a promising biomarker for
identifying neurodegenerative diseases. For this purpose accurate prediction is
important but the localisation of the areas that play a significant role in the
prediction is also crucial, in order to gain clinicians&#x27; trust and reassurance
about the performance of a prediction model. Most interpretability methods are
focused on classification tasks and cannot be directly transferred to
regression tasks. In this study, we focus on the task of brain age regression
from 3D brain Magnetic Resonance (MR) images using a Convolutional Neural
Network, termed prediction model. We interpret its predictions by extracting
importance maps, which discover the parts of the brain that are the most
important for brain age. In order to do so, we assume that voxels that are not
useful for the regression are resilient to noise addition. We implement a noise
model which aims to add as much noise as possible to the input without harming
the performance of the prediction model. We average the importance maps of the
subjects and end up with a population-based importance map, which displays the
regions of the brain that are influential for the task. We test our method on
13,750 3D brain MR images from the UK Biobank, and our findings are consistent
with the existing neuropathology literature, highlighting that the hippocampus
and the ventricles are the most relevant regions for brain aging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton. (arXiv:2108.05545v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wencan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Hyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jong Hwan Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05545">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing applications of 3D hand pose estimation in various
human-computer interaction applications, convolution neural networks (CNNs)
based estimation models have been actively explored. However, the existing
models require complex architectures or redundant computational resources to
trade with the acceptable accuracy. To tackle this limitation, this paper
proposes HandFoldingNet, an accurate and efficient hand pose estimator that
regresses the hand joint locations from the normalized 3D hand point cloud
input. The proposed model utilizes a folding-based decoder that folds a given
2D hand skeleton into the corresponding joint coordinates. For higher
estimation accuracy, folding is guided by multi-scale features, which include
both global and joint-wise local features. Experimental results show that the
proposed model outperforms the existing methods on three hand pose benchmark
datasets with the lowest model parameter requirement. Code is available at
https://github.com/cwc1260/HandFold.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Language Transformer and Query Generation for Referring Segmentation. (arXiv:2108.05565v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Henghui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suchen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xudong Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05565">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the challenging task of referring segmentation. The
query expression in referring segmentation typically indicates the target
object by describing its relationship with others. Therefore, to find the
target one among all instances in the image, the model must have a holistic
understanding of the whole image. To achieve this, we reformulate referring
segmentation as a direct attention problem: finding the region in the image
where the query language expression is most attended to. We introduce
transformer and multi-head attention to build a network with an encoder-decoder
attention mechanism architecture that &quot;queries&quot; the given image with the
language expression. Furthermore, we propose a Query Generation Module, which
produces multiple sets of queries with different attention weights that
represent the diversified comprehensions of the language expression from
different aspects. At the same time, to find the best way from these
diversified comprehensions based on visual clues, we further propose a Query
Balance Module to adaptively select the output features of these queries for a
better mask generation. Without bells and whistles, our approach is
light-weight and achieves new state-of-the-art performance consistently on
three referring segmentation datasets, RefCOCO, RefCOCO+, and G-Ref. Our code
is available at https://github.com/henghuiding/Vision-Language-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Pitfalls of Sample Selection: A Case Study on Lung Nodule Classification. (arXiv:2108.05386v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baltatzis_V/0/1/0/all/0/1">Vasileios Baltatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bintsi_K/0/1/0/all/0/1">Kyriaki-Margarita Bintsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Folgoc_L/0/1/0/all/0/1">Loic Le Folgoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzanera_O/0/1/0/all/0/1">Octavio E. Martinez Manzanera</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_S/0/1/0/all/0/1">Sam Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1">Arjun Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1">Sujal Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05386">
                                    <div class="article-summary-box-inner">
                                        <span>Using publicly available data to determine the performance of methodological
contributions is important as it facilitates reproducibility and allows
scrutiny of the published results. In lung nodule classification, for example,
many works report results on the publicly available LIDC dataset. In theory,
this should allow a direct comparison of the performance of proposed methods
and assess the impact of individual contributions. When analyzing seven recent
works, however, we find that each employs a different data selection process,
leading to largely varying total number of samples and ratios between benign
and malignant cases. As each subset will have different characteristics with
varying difficulty for classification, a direct comparison between the proposed
methods is thus not always possible, nor fair. We study the particular effect
of truthing when aggregating labels from multiple experts. We show that
specific choices can have severe impact on the data distribution where it may
be possible to achieve superior performance on one sample distribution but not
on another. While we show that we can further improve on the state-of-the-art
on one sample selection, we also find that on a more challenging sample
selection, on the same database, the more advanced models underperform with
respect to very simple baseline methods, highlighting that the selected data
distribution may play an even more important role than the model architecture.
This raises concerns about the validity of claimed methodological
contributions. We believe the community should be aware of these pitfalls and
make recommendations on how these can be avoided in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning. (arXiv:2108.05617v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junkai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Chaowei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weikai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1">Zhenhua Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaolin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1">Pengxu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05617">
                                    <div class="article-summary-box-inner">
                                        <span>Open-set semi-supervised learning (open-set SSL) investigates a challenging
but practical scenario where out-of-distribution (OOD) samples are contained in
the unlabeled data. While the mainstream technique seeks to completely filter
out the OOD samples for semi-supervised learning (SSL), we propose a novel
training mechanism that could effectively exploit the presence of OOD data for
enhanced feature learning while avoiding its adverse impact on the SSL. We
achieve this goal by first introducing a warm-up training that leverages all
the unlabeled data, including both the in-distribution (ID) and OOD samples.
Specifically, we perform a pretext task that enforces our feature extractor to
obtain a high-level semantic understanding of the training images, leading to
more discriminative features that can benefit the downstream tasks. Since the
OOD samples are inevitably detrimental to SSL, we propose a novel cross-modal
matching strategy to detect OOD samples. Instead of directly applying binary
classification, we train the network to predict whether the data sample is
matched to an assigned one-hot class label. The appeal of the proposed
cross-modal matching over binary classification is the ability to generate a
compatible feature space that aligns with the core classification task.
Extensive experiments show that our approach substantially lifts the
performance on open-set SSL and outperforms the state-of-the-art by a large
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patchwork: Concentric Zone-based Region-wise Ground Segmentation with Ground Likelihood Estimation Using a 3D LiDAR Sensor. (arXiv:2108.05560v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1">Hyungtae Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_M/0/1/0/all/0/1">Minho Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Myung_H/0/1/0/all/0/1">Hyun Myung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05560">
                                    <div class="article-summary-box-inner">
                                        <span>Ground segmentation is crucial for terrestrial mobile platforms to perform
navigation or neighboring object recognition. Unfortunately, the ground is not
flat, as it features steep slopes; bumpy roads; or objects, such as curbs,
flower beds, and so forth. To tackle the problem, this paper presents a novel
ground segmentation method called \textit{Patchwork}, which is robust for
addressing the under-segmentation problem and operates at more than 40 Hz. In
this paper, a point cloud is encoded into a Concentric Zone Model-based
representation to assign an appropriate density of cloud points among bins in a
way that is not computationally complex. This is followed by Region-wise Ground
Plane Fitting, which is performed to estimate the partial ground for each bin.
Finally, Ground Likelihood Estimation is introduced to dramatically reduce
false positives. As experimentally verified on SemanticKITTI and rough terrain
datasets, our proposed method yields promising performance compared with the
state-of-the-art methods, showing faster speed compared with existing plane
fitting--based methods. Code is available:
https://github.com/LimHyungTae/patchwork</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Trend Networks for Recommendations. (arXiv:2108.05552v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05552">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems aim to provide personalized services to users and are
playing an increasingly important role in our daily lives. The key of
recommender systems is to predict how likely users will interact with items
based on their historical online behaviors, e.g., clicks, add-to-cart,
purchases, etc. To exploit these user-item interactions, there are increasing
efforts on considering the user-item interactions as a user-item bipartite
graph and then performing information propagation in the graph via Graph Neural
Networks (GNNs). Given the power of GNNs in graph representation learning,
these GNN-based recommendation methods have remarkably boosted the
recommendation performance. Despite their success, most existing GNN-based
recommender systems overlook the existence of interactions caused by unreliable
behaviors (e.g., random/bait clicks) and uniformly treat all the interactions,
which can lead to sub-optimal and unstable performance. In this paper, we
investigate the drawbacks (e.g., non-adaptive propagation and non-robustness)
of existing GNN-based recommendation methods. To address these drawbacks, we
propose the Graph Trend Networks for recommendations (GTN) with principled
designs that can capture the adaptive reliability of the interactions.
Comprehensive experiments and ablation studies are presented to verify and
understand the effectiveness of the proposed framework. Our implementation and
datasets can be released after publication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Page-level Optimization of e-Commerce Item Recommendations. (arXiv:2108.05891v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1">Chieh Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1">Krutika Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changchen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kathy Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Platz_J/0/1/0/all/0/1">Justin Platz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilardi_A/0/1/0/all/0/1">Adam Ilardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhvanath_S/0/1/0/all/0/1">Sriganesh Madhvanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05891">
                                    <div class="article-summary-box-inner">
                                        <span>The item details page (IDP) is a web page on an e-commerce website that
provides information on a specific product or item listing. Just below the
details of the item on this page, the buyer can usually find recommendations
for other relevant items. These are typically in the form of a series of
modules or carousels, with each module containing a set of recommended items.
The selection and ordering of these item recommendation modules are intended to
increase discover-ability of relevant items and encourage greater user
engagement, while simultaneously showcasing diversity of inventory and
satisfying other business objectives. Item recommendation modules on the IDP
are often curated and statically configured for all customers, ignoring
opportunities for personalization. In this paper, we present a scalable
end-to-end production system to optimize the personalized selection and
ordering of item recommendation modules on the IDP in real-time by utilizing
deep neural networks. Through extensive offline experimentation and online A/B
testing, we show that our proposed system achieves significantly higher
click-through and conversion rates compared to other existing methods. In our
online A/B test, our framework improved click-through rate by 2.48% and
purchase-through rate by 7.34% over a static configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval. (arXiv:2108.05540v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Luyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1">Jamie Callan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05540">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research demonstrates the effectiveness of using fine-tuned language
models~(LM) for dense retrieval. However, dense retrievers are hard to train,
typically requiring heavily engineered fine-tuning pipelines to realize their
full potential. In this paper, we identify and address two underlying problems
of dense retrievers: i)~fragility to training data noise and ii)~requiring
large batches to robustly learn the embedding space. We use the recently
proposed Condenser pre-training architecture, which learns to condense
information into the dense vector through LM pre-training. On top of it, we
propose coCondenser, which adds an unsupervised corpus-level contrastive loss
to warm up the passage embedding space. Retrieval experiments on MS-MARCO,
Natural Question, and Trivia QA datasets show that coCondenser removes the need
for heavy data engineering such as augmentation, synthesis, or filtering, as
well as the need for large batch training. It shows comparable performance to
RocketQA, a state-of-the-art, heavily engineered system, using simple small
batch fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Sequential Slate Optimization. (arXiv:2108.05618v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Mingjian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Indrakanti_S/0/1/0/all/0/1">Saratchandra Indrakanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kannadasan_M/0/1/0/all/0/1">Manojkumar Rangasamy Kannadasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagherjeiran_A/0/1/0/all/0/1">Abraham Bagherjeiran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05618">
                                    <div class="article-summary-box-inner">
                                        <span>The top search results matching a user query that are displayed on the first
page are critical to the effectiveness and perception of a search system. A
search ranking system typically orders the results by independent
query-document scores to produce a slate of search results. However, such
unilateral scoring methods may fail to capture inter-document dependencies that
users are sensitive to, thus producing a sub-optimal slate. Further, in
practice, many real-world applications such as e-commerce search require
enforcing certain distributional criteria at the slate-level, due to business
objectives or long term user retention goals. Unilateral scoring of results
does not explicitly support optimizing for such objectives with respect to a
slate. Hence, solutions to the slate optimization problem must consider the
optimal selection and order of the documents, along with adherence to
slate-level distributional criteria. To that end, we propose a hybrid framework
extended from traditional slate optimization to solve the conditional slate
optimization problem. We introduce conditional sequential slate optimization
(CSSO), which jointly learns to optimize for traditional ranking metrics as
well as prescribed distribution criteria of documents within the slate. The
proposed method can be applied to practical real world problems such as
enforcing diversity in e-commerce search results, mitigating bias in top
results and personalization of results. Experiments on public datasets and
real-world data from e-commerce datasets show that CSSO outperforms popular
comparable ranking methods in terms of adherence to distributional criteria
while producing comparable or better relevance metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridger: Toward Bursting Scientific Filter Bubbles and Boosting Innovation via Novel Author Discovery. (arXiv:2108.05669v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portenoy_J/0/1/0/all/0/1">Jason Portenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radensky_M/0/1/0/all/0/1">Marissa Radensky</a>, <a href="http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1">Jevin West</a>, <a href="http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1">Eric Horvitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05669">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific silos can hinder innovation. These information &quot;filter bubbles&quot;
and the growing challenge of information overload limit awareness across the
literature, making it difficult to keep track of even narrow areas of interest,
let alone discover new ones. Algorithmic curation and recommendation, which
often prioritize relevance, can further reinforce these bubbles. In response,
we describe Bridger, a system for facilitating discovery of scholars and their
work, to explore design tradeoffs among relevant and novel recommendations. We
construct a faceted representation of authors using information extracted from
their papers and inferred personas. We explore approaches both for recommending
new content and for displaying it in a manner that helps researchers to
understand the work of authors who they are unfamiliar with. In studies with
computer science researchers, our approach substantially improves users&#x27;
abilities to do so. We develop an approach that locates commonalities and
contrasts between scientists---retrieving partially similar authors, rather
than aiming for strict similarity. We find this approach helps users discover
authors useful for generating novel research ideas of relevance to their work,
at a higher rate than a state-of-art neural model. Our analysis reveals that
Bridger connects authors who have different citation profiles, publish in
different venues, and are more distant in social co-authorship networks,
raising the prospect of bridging diverse communities and facilitating
discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locality Sensitive Hashing with Extended Differential Privacy. (arXiv:2010.09393v5 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_N/0/1/0/all/0/1">Natasha Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawamoto_Y/0/1/0/all/0/1">Yusuke Kawamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1">Takao Murakami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09393">
                                    <div class="article-summary-box-inner">
                                        <span>Extended differential privacy, a generalization of standard differential
privacy (DP) using a general metric, has been widely studied to provide
rigorous privacy guarantees while keeping high utility. However, existing works
on extended DP are limited to few metrics, such as the Euclidean metric.
Consequently, they have only a small number of applications, such as
location-based services and document processing. In this paper, we propose a
couple of mechanisms providing extended DP with a different metric: angular
distance (or cosine distance). Our mechanisms are based on locality sensitive
hashing (LSH), which can be applied to the angular distance and work well for
personal data in a high-dimensional space. We theoretically analyze the privacy
properties of our mechanisms, and prove extended DP for input data by taking
into account that LSH preserves the original metric only approximately. We
apply our mechanisms to friend matching based on high-dimensional personal data
with angular distance in the local model, and evaluate our mechanisms using two
real datasets. We show that LDP requires a very large privacy budget and that
RAPPOR does not work in this application. Then we show that our mechanisms
enable friend matching with high utility and rigorous privacy guarantees based
on extended DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Session-based Recommendation with Heterogeneous Graph Neural Network. (arXiv:2108.05641v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haiyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Senzhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1">Kaimin Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05641">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of the Session-Based Recommendation System is to predict the
user&#x27;s next click according to the previous session sequence. The current
studies generally learn user preferences according to the transitions of items
in the user&#x27;s session sequence. However, other effective information in the
session sequence, such as user profiles, are largely ignored which may lead to
the model unable to learn the user&#x27;s specific preferences. In this paper, we
propose a heterogeneous graph neural network-based session recommendation
method, named SR-HetGNN, which can learn session embeddings by heterogeneous
graph neural network (HetGNN), and capture the specific preferences of
anonymous users. Specifically, SR-HetGNN first constructs heterogeneous graphs
containing various types of nodes according to the session sequence, which can
capture the dependencies among items, users, and sessions. Second, HetGNN
captures the complex transitions between items and learns the item embeddings
containing user information. Finally, to consider the influence of users&#x27; long
and short-term preferences, local and global session embeddings are combined
with the attentional network to obtain the final session embedding. SR-HetGNN
is shown to be superior to the existing state-of-the-art session-based
recommendation methods through extensive experiments over two real large
datasets Diginetica and Tmall.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Analysis on Transparent Algorithmic Exploration in Recommender Systems. (arXiv:2108.00151v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kihwan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00151">
                                    <div class="article-summary-box-inner">
                                        <span>All learning algorithms for recommendations face inevitable and critical
trade-off between exploiting partial knowledge of a user&#x27;s preferences for
short-term satisfaction and exploring additional user preferences for long-term
coverage. Although exploration is indispensable for long success of a
recommender system, the exploration has been considered as the risk to decrease
user satisfaction. The reason for the risk is that items chosen for exploration
frequently mismatch with the user&#x27;s interests. To mitigate this risk,
recommender systems have mixed items chosen for exploration into a
recommendation list, disguising the items as recommendations to elicit feedback
on the items to discover the user&#x27;s additional tastes. This mix-in approach has
been widely used in many recommenders, but there is rare research, evaluating
the effectiveness of the mix-in approach or proposing a new approach for
eliciting user feedback without deceiving users. In this work, we aim to
propose a new approach for feedback elicitation without any deception and
compare our approach to the conventional mix-in approach for evaluation. To
this end, we designed a recommender interface that reveals which items are for
exploration and conducted a within-subject study with 94 MTurk workers. Our
results indicated that users left significantly more feedback on items chosen
for exploration with our interface. Besides, users evaluated that our new
interface is better than the conventional mix-in interface in terms of novelty,
diversity, transparency, trust, and satisfaction. Finally, path analysis show
that, in only our new interface, exploration caused to increase user-centric
evaluation metrics. Our work paves the way for how to design an interface,
which utilizes learning algorithm based on users&#x27; feedback signals, giving
better user experience and gathering more feedback data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Relevance Ranking under the Pre-training and Fine-tuning Paradigm. (arXiv:2108.05652v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Lin Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">XiuQiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05652">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pre-trained language models such as BERT have been applied to
document ranking for information retrieval, which first pre-train a general
language model on an unlabeled large corpus and then conduct ranking-specific
fine-tuning on expert-labeled relevance datasets. Ideally, an IR system would
model relevance from a user-system dualism: the user&#x27;s view and the system&#x27;s
view. User&#x27;s view judges the relevance based on the activities of &quot;real users&quot;
while the system&#x27;s view focuses on the relevance signals from the system side,
e.g., from the experts or algorithms, etc. Inspired by the user-system
relevance views and the success of pre-trained language models, in this paper
we propose a novel ranking framework called Pre-Rank that takes both user&#x27;s
view and system&#x27;s view into consideration, under the pre-training and
fine-tuning paradigm. Specifically, to model the user&#x27;s view of relevance,
Pre-Rank pre-trains the initial query-document representations based on
large-scale user activities data such as the click log. To model the system&#x27;s
view of relevance, Pre-Rank further fine-tunes the model on expert-labeled
relevance data. More importantly, the pre-trained representations, are
fine-tuned together with handcrafted learning-to-rank features under a wide and
deep network architecture. In this way, Pre-Rank can model the relevance by
incorporating the relevant knowledge and signals from both real search users
and the IR experts. To verify the effectiveness of Pre-Rank, we showed two
implementations by using BERT and SetRank as the underlying ranking model,
respectively. Experimental results base on three publicly available benchmarks
showed that in both of the implementations, Pre-Rank can respectively
outperform the underlying ranking models and achieved state-of-the-art
performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ontology drift is a challenge for explainable data governance. (arXiv:2108.05401v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05401">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the needs for explainable AI that arise from Standard No. 239
from the Basel Committee on Banking Standards (BCBS 239), which outlines 11
principles for effective risk data aggregation and risk reporting for financial
institutions. Of these, explainableAI is necessary for compliance in two key
aspects: data quality, and appropriate reporting for multiple stakeholders. We
describe the implementation challenges for one specific regulatory
requirement:that of having a complete data taxonomy that is appropriate for
firmwide use. The constantly evolving nature of financial ontologies
necessitate a continuous updating process to ensure ongoing compliance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Microlocal Reconstruction for Limited-Angle Tomography. (arXiv:2108.05732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andrade_Loarca_H/0/1/0/all/0/1">H&#xe9;ctor Andrade-Loarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1">Gitta Kutyniok</a>, <a href="http://arxiv.org/find/cs/1/au:+Oktem_O/0/1/0/all/0/1">Ozan &#xd6;ktem</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Philipp Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning-based algorithm to jointly solve a reconstruction
problem and a wavefront set extraction problem in tomographic imaging. The
algorithm is based on a recently developed digital wavefront set extractor as
well as the well-known microlocal canonical relation for the Radon transform.
We use the wavefront set information about x-ray data to improve the
reconstruction by requiring that the underlying neural networks simultaneously
extract the correct ground truth wavefront set and ground truth image. As a
necessary theoretical step, we identify the digital microlocal canonical
relations for deep convolutional residual neural networks. We find strong
numerical evidence for the effectiveness of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MicroNet: Improving Image Recognition with Extremely Low FLOPs. (arXiv:2108.05894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1">Nuno Vasconcelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05894">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims at addressing the problem of substantial performance
degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet
classification). We found that two factors, sparse connectivity and dynamic
activation function, are effective to improve the accuracy. The former avoids
the significant reduction of network width, while the latter mitigates the
detriment of reduction in network depth. Technically, we propose
micro-factorized convolution, which factorizes a convolution matrix into low
rank matrices, to integrate sparse connectivity into convolution. We also
present a new dynamic activation function, named Dynamic Shift Max, to improve
the non-linearity via maxing out multiple dynamic fusions between an input
feature map and its circular channel shift. Building upon these two new
operators, we arrive at a family of networks, named MicroNet, that achieves
significant performance gains over the state of the art in the low FLOP regime.
For instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\% top-1
accuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\%. Source
code is at
\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Lexically Constrained Neural Machine Translation with Source-Conditioned Masked Span Prediction. (arXiv:2105.05498v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gyubok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seongjun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05498">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate terminology translation is crucial for ensuring the practicality and
reliability of neural machine translation (NMT) systems. To address this,
lexically constrained NMT explores various methods to ensure pre-specified
words and phrases appear in the translation output. However, in many cases,
those methods are studied on general domain corpora, where the terms are mostly
uni- and bi-grams (&gt;98%). In this paper, we instead tackle a more challenging
setup consisting of domain-specific corpora with much longer n-gram and highly
specialized terms. Inspired by the recent success of masked span prediction
models, we propose a simple and effective training strategy that achieves
consistent improvements on both terminology and sentence-level translation for
three domain-specific corpora in two language pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Neural Information Fusion Architecture for Textual Network Embeddings. (arXiv:1908.11057v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qinliang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weijia Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.11057">
                                    <div class="article-summary-box-inner">
                                        <span>Textual network embeddings aim to learn a low-dimensional representation for
every node in the network so that both the structural and textual information
from the networks can be well preserved in the representations. Traditionally,
the structural and textual embeddings were learned by models that rarely take
the mutual influences between them into account. In this paper, a deep neural
architecture is proposed to effectively fuse the two kinds of informations into
one representation. The novelties of the proposed architecture are manifested
in the aspects of a newly defined objective function, the complementary
information fusion method for structural and textual features, and the mutual
gate mechanism for textual feature extraction. Experimental results show that
the proposed model outperforms the comparing methods on all three datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing the State of the Art: A Critical Look at Visual Representation Evaluation. (arXiv:1912.00215v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1">Cinjon Resnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zeping Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00215">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised research improved greatly over the past half decade, with
much of the growth being driven by objectives that are hard to quantitatively
compare. These techniques include colorization, cyclical consistency, and
noise-contrastive estimation from image patches. Consequently, the field has
settled on a handful of measurements that depend on linear probes to adjudicate
which approaches are the best. Our first contribution is to show that this test
is insufficient and that models which perform poorly (strongly) on linear
classification can perform strongly (weakly) on more involved tasks like
temporal activity localization. Our second contribution is to analyze the
capabilities of five different representations. And our third contribution is a
much needed new dataset for temporal activity localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeanML: A Design Pattern To Slash Avoidable Wastes in Machine Learning Projects. (arXiv:2107.08066v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samo_Y/0/1/0/all/0/1">Yves-Laurent Kom Samo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08066">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first application of the lean methodology to machine
learning projects. Similar to lean startups and lean manufacturing, we argue
that lean machine learning (LeanML) can drastically slash avoidable wastes in
commercial machine learning projects, reduce the business risk in investing in
machine learning capabilities and, in so doing, further democratize access to
machine learning. The lean design pattern we propose in this paper is based on
two realizations. First, it is possible to estimate the best performance one
may achieve when predicting an outcome $y \in \mathcal{Y}$ using a given set of
explanatory variables $x \in \mathcal{X}$, for a wide range of performance
metrics, and without training any predictive model. Second, doing so is
considerably easier, faster, and cheaper than learning the best predictive
model. We derive formulae expressing the best $R^2$, MSE, classification
accuracy, and log-likelihood per observation achievable when using $x$ to
predict $y$ as a function of the mutual information $I\left(y; x\right)$, and
possibly a measure of the variability of $y$ (e.g. its Shannon entropy in the
case of classification accuracy, and its variance in the case regression MSE).
We illustrate the efficacy of the LeanML design pattern on a wide range of
regression and classification problems, synthetic and real-life.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the &quot;Impossibility of Fairness&quot;: From Formal to Substantive Algorithmic Fairness. (arXiv:2107.04642v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Green_B/0/1/0/all/0/1">Ben Green</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04642">
                                    <div class="article-summary-box-inner">
                                        <span>In the face of compounding crises of social and economic inequality, many
have turned to algorithmic decision-making to achieve greater fairness in
society. As these efforts intensify, reasoning within the burgeoning field of
&quot;algorithmic fairness&quot; increasingly shapes how fairness manifests in practice.
This paper interrogates whether algorithmic fairness provides the appropriate
conceptual and practical tools for enhancing social equality. I argue that the
dominant, &quot;formal&quot; approach to algorithmic fairness is ill-equipped as a
framework for pursuing equality, as its narrow frame of analysis generates
restrictive approaches to reform. In light of these shortcomings, I propose an
alternative: a &quot;substantive&quot; approach to algorithmic fairness that centers
opposition to social hierarchies and provides a more expansive analysis of how
to address inequality. This substantive approach enables more fruitful
theorizing about the role of algorithms in combatting oppression. The
distinction between formal and substantive algorithmic fairness is exemplified
by each approach&#x27;s responses to the &quot;impossibility of fairness&quot; (an
incompatibility between mathematical definitions of algorithmic fairness).
While the formal approach requires us to accept the &quot;impossibility of fairness&quot;
as a harsh limit on efforts to enhance equality, the substantive approach
allows us to escape the &quot;impossibility of fairness&quot; by suggesting reforms that
are not subject to this false dilemma and that are better equipped to
ameliorate conditions of social oppression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Stochastic Block Model for Community Detection in Multiplex Networks. (arXiv:1904.05330v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Arash A. Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Paez_M/0/1/0/all/0/1">Marina S. Paez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lizhen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.05330">
                                    <div class="article-summary-box-inner">
                                        <span>Multiplex networks have become increasingly more prevalent in many fields,
and have emerged as a powerful tool for modeling the complexity of real
networks. There is a critical need for developing inference models for
multiplex networks that can take into account potential dependencies across
different layers, particularly when the aim is community detection. We add to a
limited literature by proposing a novel and efficient Bayesian model for
community detection in multiplex networks. A key feature of our approach is the
ability to model varying communities at different network layers. In contrast,
many existing models assume the same communities for all layers. Moreover, our
model automatically picks up the necessary number of communities at each layer
(as validated by real data examples). This is appealing, since deciding the
number of communities is a challenging aspect of community detection, and
especially so in the multiplex setting, if one allows the communities to change
across layers. Borrowing ideas from hierarchical Bayesian modeling, we use a
hierarchical Dirichlet prior to model community labels across layers, allowing
dependency in their structure. Given the community labels, a stochastic block
model (SBM) is assumed for each layer. We develop an efficient slice sampler
for sampling the posterior distribution of the community labels as well as the
link probabilities between communities. In doing so, we address some unique
challenges posed by coupling the complex likelihood of SBM with the
hierarchical nature of the prior on the labels. An extensive empirical
validation is performed on simulated and real data, demonstrating the superior
performance of the model over single-layer alternatives, as well as the ability
to uncover interesting structures in real networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation. (arXiv:2010.05903v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_L/0/1/0/all/0/1">Liron Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection methods require high-quality features. In recent years, the
anomaly detection community has attempted to obtain better features using
advances in deep self-supervised feature learning. Surprisingly, a very
promising direction, using pretrained deep features, has been mostly
overlooked. In this paper, we first empirically establish the perhaps expected,
but unreported result, that combining pretrained features with simple anomaly
detection and segmentation methods convincingly outperforms, much more complex,
state-of-the-art methods.

In order to obtain further performance gains in anomaly detection, we adapt
pretrained features to the target distribution. Although transfer learning
methods are well established in multi-class classification problems, the
one-class classification (OCC) setting is not as well explored. It turns out
that naive adaptation methods, which typically work well in supervised
learning, often result in catastrophic collapse (feature deterioration) and
reduce performance in OCC settings. A popular OCC method, DeepSVDD, advocates
using specialized architectures, but this limits the adaptation performance
gain. We propose two methods for combating collapse: i) a variant of early
stopping that dynamically learns the stopping iteration ii) elastic
regularization inspired by continual learning. Our method, PANDA, outperforms
the state-of-the-art in the OCC, outlier exposure and anomaly segmentation
settings by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Depth-Based Estimation of Object Articulation Models. (arXiv:2108.05875v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ajinkya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Giguere_S/0/1/0/all/0/1">Stephen Giguere</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1">Rudolf Lioutikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05875">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method that efficiently learns distributions over articulation
model parameters directly from depth images without the need to know
articulation model categories a priori. By contrast, existing methods that
learn articulation models from raw observations typically only predict point
estimates of the model parameters, which are insufficient to guarantee the safe
manipulation of articulated objects. Our core contributions include a novel
representation for distributions over rigid body transformations and
articulation model parameters based on screw theory, von Mises-Fisher
distributions, and Stiefel manifolds. Combining these concepts allows for an
efficient, mathematically sound representation that implicitly satisfies the
constraints that rigid body transformations and articulations must adhere to.
Leveraging this representation, we introduce a novel deep learning based
approach, DUST-net, that performs category-independent articulation model
estimation while also providing model uncertainties. We evaluate our approach
on several benchmarking datasets and real-world objects and compare its
performance with two current state-of-the-art methods. Our results demonstrate
that DUST-net can successfully learn distributions over articulation models for
novel objects across articulation model categories, which generate point
estimates with better accuracy than state-of-the-art methods and effectively
capture the uncertainty over predicted model parameters due to noisy inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation. (arXiv:2106.04096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04096">
                                    <div class="article-summary-box-inner">
                                        <span>Natural policy gradient (NPG) methods with function approximation achieve
impressive empirical success in reinforcement learning problems with large
state-action spaces. However, theoretical understanding of their convergence
behaviors remains limited in the function approximation setting. In this paper,
we perform a finite-time analysis of NPG with linear function approximation and
softmax parameterization, and prove for the first time that widely used entropy
regularization method, which encourages exploration, leads to linear
convergence rate. Under considerably weaker regularity conditions, we prove
that entropy-regularized Q-NPG variant with linear function approximation
achieves $\tilde{O}(1/T)$ convergence rate. We adopt a Lyapunov drift analysis
to prove the convergence results and explain the effectiveness of entropy
regularization in improving the convergence rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication Optimization in Large Scale Federated Learning using Autoencoder Compressed Weight Updates. (arXiv:2108.05670v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Srikanth Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandran_P/0/1/0/all/0/1">Pravin Chandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1">Raghavendra Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_A/0/1/0/all/0/1">Avinash Chakravarthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05670">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) solves many of this decade&#x27;s concerns regarding data
privacy and computation challenges. FL ensures no data leaves its source as the
model is trained at where the data resides. However, FL comes with its own set
of challenges. The communication of model weight updates in this distributed
environment comes with significant network bandwidth costs. In this context, we
propose a mechanism of compressing the weight updates using Autoencoders (AE),
which learn the data features of the weight updates and subsequently perform
compression. The encoder is set up on each of the nodes where the training is
performed while the decoder is set up on the node where the weights are
aggregated. This setup achieves compression through the encoder and recreates
the weights at the end of every communication round using the decoder. This
paper shows that the dynamic and orthogonal AE based weight compression
technique could serve as an advantageous alternative (or an add-on) in a large
scale FL, as it not only achieves compression ratios ranging from 500x to 1720x
and beyond, but can also be modified based on the accuracy requirements,
computational capacity, and other requirements of the given FL setup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation. (arXiv:2011.06294v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhewei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1">Wen Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuchang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06294">
                                    <div class="article-summary-box-inner">
                                        <span>We propose RIFE, a Real-time Intermediate Flow Estimation algorithm for Video
Frame Interpolation (VFI). Many recent flow-based VFI methods first estimate
the bi-directional optical flows, then scale and reverse them to approximate
intermediate flows, leading to artifacts on motion boundaries. RIFE uses a
neural network named IFNet that can directly estimate the intermediate flows
from coarse-to-fine with much better speed. We design a privileged distillation
scheme for training intermediate flow model, which leads to a large performance
improvement. Experiments demonstrate that RIFE is flexible and can achieve
state-of-the-art performance on several public benchmarks. The code is
available at \url{https://github.com/hzwer/arXiv2020-RIFE}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Analysis on Transparent Algorithmic Exploration in Recommender Systems. (arXiv:2108.00151v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kihwan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00151">
                                    <div class="article-summary-box-inner">
                                        <span>All learning algorithms for recommendations face inevitable and critical
trade-off between exploiting partial knowledge of a user&#x27;s preferences for
short-term satisfaction and exploring additional user preferences for long-term
coverage. Although exploration is indispensable for long success of a
recommender system, the exploration has been considered as the risk to decrease
user satisfaction. The reason for the risk is that items chosen for exploration
frequently mismatch with the user&#x27;s interests. To mitigate this risk,
recommender systems have mixed items chosen for exploration into a
recommendation list, disguising the items as recommendations to elicit feedback
on the items to discover the user&#x27;s additional tastes. This mix-in approach has
been widely used in many recommenders, but there is rare research, evaluating
the effectiveness of the mix-in approach or proposing a new approach for
eliciting user feedback without deceiving users. In this work, we aim to
propose a new approach for feedback elicitation without any deception and
compare our approach to the conventional mix-in approach for evaluation. To
this end, we designed a recommender interface that reveals which items are for
exploration and conducted a within-subject study with 94 MTurk workers. Our
results indicated that users left significantly more feedback on items chosen
for exploration with our interface. Besides, users evaluated that our new
interface is better than the conventional mix-in interface in terms of novelty,
diversity, transparency, trust, and satisfaction. Finally, path analysis show
that, in only our new interface, exploration caused to increase user-centric
evaluation metrics. Our work paves the way for how to design an interface,
which utilizes learning algorithm based on users&#x27; feedback signals, giving
better user experience and gathering more feedback data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Testing Autonomous Systems with Believed Equivalence Refinement. (arXiv:2103.04578v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Chih-Hong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rongjie Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04578">
                                    <div class="article-summary-box-inner">
                                        <span>Continuous engineering of autonomous driving functions commonly requires
deploying vehicles in road testing to obtain inputs that cause problematic
decisions. Although the discovery leads to producing an improved system, it
also challenges the foundation of testing using equivalence classes and the
associated relative test coverage criterion. In this paper, we propose believed
equivalence, where the establishment of an equivalence class is initially based
on expert belief and is subject to a set of available test cases having a
consistent valuation. Upon a newly encountered test case that breaks the
consistency, one may need to refine the established categorization in order to
split the originally believed equivalence into two. Finally, we focus on
modules implemented using deep neural networks where every category partitions
an input over the real domain. We present both analytical and lazy methods to
suggest the refinement. The concept is demonstrated in analyzing multiple
autonomous driving modules, indicating the potential of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal analysis of the predictability of hand-gesture properties. (arXiv:2108.05762v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05762">
                                    <div class="article-summary-box-inner">
                                        <span>Embodied conversational agents benefit from being able to accompany their
speech with gestures. Although many data-driven approaches to gesture
generation have been proposed in recent years, it is still unclear whether such
systems can consistently generate gestures that convey meaning. We investigate
which gesture properties (phase, category, and semantics) can be predicted from
speech text and/or audio using contemporary deep learning. In extensive
experiments, we show that gesture properties related to gesture meaning
(semantics and category) are predictable from text features (time-aligned BERT
embeddings) alone, but not from prosodic audio features, while rhythm-related
gesture properties (phase) on the other hand can be predicted from either
audio, text (with word-level timing information), or both. These results are
encouraging as they indicate that it is possible to equip an embodied agent
with content-wise meaningful co-speech gestures using a machine-learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning-Based Control via Bootstrapped Multiplicative Noise. (arXiv:2002.10069v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gravell_B/0/1/0/all/0/1">Benjamin Gravell</a>, <a href="http://arxiv.org/find/cs/1/au:+Summers_T/0/1/0/all/0/1">Tyler Summers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.10069">
                                    <div class="article-summary-box-inner">
                                        <span>Despite decades of research and recent progress in adaptive control and
reinforcement learning, there remains a fundamental lack of understanding in
designing controllers that provide robustness to inherent non-asymptotic
uncertainties arising from models estimated with finite, noisy data. We propose
a robust adaptive control algorithm that explicitly incorporates such
non-asymptotic uncertainties into the control design. The algorithm has three
components: (1) a least-squares nominal model estimator; (2) a bootstrap
resampling method that quantifies non-asymptotic variance of the nominal model
estimate; and (3) a non-conventional robust control design method using an
optimal linear quadratic regulator (LQR) with multiplicative noise. A key
advantage of the proposed approach is that the system identification and robust
control design procedures both use stochastic uncertainty representations, so
that the actual inherent statistical estimation uncertainty directly aligns
with the uncertainty the robust controller is being designed against. We show
through numerical experiments that the proposed robust adaptive controller can
significantly outperform the certainty equivalent controller on both expected
regret and measures of regret risk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Discretization for Adversarial Lipschitz Bandits. (arXiv:2006.12367v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1">Chara Podimata</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12367">
                                    <div class="article-summary-box-inner">
                                        <span>Lipschitz bandits is a prominent version of multi-armed bandits that studies
large, structured action spaces such as the [0,1] interval, where similar
actions are guaranteed to have similar rewards. A central theme here is the
adaptive discretization of the action space, which gradually &#x60;&#x60;zooms in&#x27;&#x27; on
the more promising regions thereof. The goal is to take advantage of &#x60;&#x60;nicer&#x27;&#x27;
problem instances, while retaining near-optimal worst-case performance. While
the stochastic version of the problem is well-understood, the general version
with adversarial rewards is not. We provide the first algorithm for adaptive
discretization in the adversarial version, and derive instance-dependent regret
bounds. In particular, we recover the worst-case optimal regret bound for the
adversarial version, and the instance-dependent regret bound for the stochastic
version. Further, an application of our algorithm to dynamic pricing (where a
seller repeatedly adjusts prices for a product) enjoys these regret bounds
without any smoothness assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reimagining an autonomous vehicle. (arXiv:2108.05805v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hawke_J/0/1/0/all/0/1">Jeffrey Hawke</a>, <a href="http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1">Haibo E</a>, <a href="http://arxiv.org/find/cs/1/au:+Badrinarayanan_V/0/1/0/all/0/1">Vijay Badrinarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1">Alex Kendall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05805">
                                    <div class="article-summary-box-inner">
                                        <span>The self driving challenge in 2021 is this century&#x27;s technological equivalent
of the space race, and is now entering the second major decade of development.
Solving the technology will create social change which parallels the invention
of the automobile itself. Today&#x27;s autonomous driving technology is laudable,
though rooted in decisions made a decade ago. We argue that a rethink is
required, reconsidering the autonomous vehicle (AV) problem in the light of the
body of knowledge that has been gained since the DARPA challenges which seeded
the industry. What does AV2.0 look like? We present an alternative vision: a
recipe for driving with machine learning, and grand challenges for research in
driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. (arXiv:2102.06387v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1">Peter Kairouz</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06387">
                                    <div class="article-summary-box-inner">
                                        <span>We consider training models on private data that are distributed across user
devices. To ensure privacy, we add on-device noise and use secure aggregation
so that only the noisy sum is revealed to the server. We present a
comprehensive end-to-end system, which appropriately discretizes the data and
adds discrete Gaussian noise before performing secure aggregation. We provide a
novel privacy analysis for sums of discrete Gaussians and carefully analyze the
effects of data quantization and modular summation arithmetic. Our theoretical
guarantees highlight the complex tension between communication, privacy, and
accuracy. Our extensive experimental results demonstrate that our solution is
essentially able to match the accuracy to central differential privacy with
less than 16 bits of precision per value.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning: A Field Experiment. (arXiv:1912.02572v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaxi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yidong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuming Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xingyu Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02572">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present an end-to-end framework for addressing the problem
of dynamic pricing (DP) on E-commerce platform using methods based on deep
reinforcement learning (DRL). By using four groups of different business data
to represent the states of each time period, we model the dynamic pricing
problem as a Markov Decision Process (MDP). Compared with the state-of-the-art
DRL-based dynamic pricing algorithms, our approaches make the following three
contributions. First, we extend the discrete set problem to the continuous
price set. Second, instead of using revenue as the reward function directly, we
define a new function named difference of revenue conversion rates (DRCR).
Third, the cold-start problem of MDP is tackled by pre-training and evaluation
using some carefully chosen historical sales data. Our approaches are evaluated
by both offline evaluation method using real dataset of Alibaba Inc., and
online field experiments starting from July 2018 with thousands of items,
lasting for months on Tmall.com. To our knowledge, there is no other DP field
experiment using DRL before. Field experiment results suggest that DRCR is a
more appropriate reward function than revenue, which is widely used by current
literature. Also, continuous price sets have better performance than discrete
sets and our approaches significantly outperformed the manual pricing by
operation experts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructing Multiclass Classifiers using Binary Classifiers Under Log-Loss. (arXiv:2102.08184v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Yishai_A/0/1/0/all/0/1">Assaf Ben-Yishai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordentlich_O/0/1/0/all/0/1">Or Ordentlich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08184">
                                    <div class="article-summary-box-inner">
                                        <span>The construction of multiclass classifiers from binary elements is studied in
this paper, and performance is quantified by the regret, defined with respect
to the Bayes optimal log-loss. We discuss two known methods. The first is one
vs. all (OVA), for which we prove that the multiclass regret is upper bounded
by the sum of binary regrets of the constituent classifiers. The second is
hierarchical classification, based on a binary tree. For this method we prove
that the multiclass regret is exactly a weighted sum of constituent binary
regrets where the weighing is determined by the tree structure.

We also introduce a leverage-hierarchical classification method, which
potentially yields smaller log-loss and regret. The advantages of these
classification methods are demonstrated by simulation on both synthetic and
real-life datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning and Slicing Neural Networks using Formal Verification. (arXiv:2105.13649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lahav_O/0/1/0/all/0/1">Ori Lahav</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) play an increasingly important role in various
computer systems. In order to create these networks, engineers typically
specify a desired topology, and then use an automated training algorithm to
select the network&#x27;s weights. While training algorithms have been studied
extensively and are well understood, the selection of topology remains a form
of art, and can often result in networks that are unnecessarily large - and
consequently are incompatible with end devices that have limited memory,
battery or computational power. Here, we propose to address this challenge by
harnessing recent advances in DNN verification. We present a framework and a
methodology for discovering redundancies in DNNs - i.e., for finding neurons
that are not needed, and can be removed in order to reduce the size of the DNN.
By using sound verification techniques, we can formally guarantee that our
simplified network is equivalent to the original, either completely, or up to a
prescribed tolerance. Further, we show how to combine our technique with
slicing, which results in a family of very small DNNs, which are together
equivalent to the original. Our approach can produce DNNs that are
significantly smaller than the original, rendering them suitable for deployment
on additional kinds of systems, and even more amenable to subsequent formal
verification. We provide a proof-of-concept implementation of our approach, and
use it to evaluate our techniques on several real-world DNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DANA: Dimension-Adaptive Neural Architecture for Multivariate Sensor Data. (arXiv:2008.02397v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1">Mohammad Malekzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Clegg_R/0/1/0/all/0/1">Richard G. Clegg</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1">Hamed Haddadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02397">
                                    <div class="article-summary-box-inner">
                                        <span>Motion sensors embedded in wearable and mobile devices allow for dynamic
selection of sensor streams and sampling rates, enabling several applications,
such as power management and data-sharing control. While deep neural networks
(DNNs) achieve competitive accuracy in sensor data classification, DNNs
generally process incoming data from a fixed set of sensors with a fixed
sampling rate, and changes in the dimensions of their inputs cause considerable
accuracy loss, unnecessary computations, or failure in operation. We introduce
a dimension-adaptive pooling (DAP) layer that makes DNNs flexible and more
robust to changes in sensor availability and in sampling rate. DAP operates on
convolutional filter maps of variable dimensions and produces an input of fixed
dimensions suitable for feedforward and recurrent layers. We also propose a
dimension-adaptive training (DAT) procedure for enabling DNNs that use DAP to
better generalize over the set of feasible data dimensions at inference time.
DAT comprises the random selection of dimensions during the forward passes and
optimization with accumulated gradients of several backward passes. Combining
DAP and DAT, we show how to transform non-adaptive DNNs into a
Dimension-Adaptive Neural Architecture (DANA), while keeping the same number of
parameters. Compared to existing approaches, our solution provides better
classification accuracy over the range of possible data dimensions at inference
time and does not require up-sampling or imputation, thus reducing unnecessary
computations. Experiments on seven datasets (four benchmark real-world datasets
for human activity recognition and three synthetic datasets) show that DANA
prevents significant losses in classification accuracy of the state-of-the-art
DNNs and, compared to baselines, it better captures correlated patterns in
sensor data under dynamic sensor availability and varying sampling rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ubiquitous Acoustic Sensing on Commodity IoT Devices: A Survey. (arXiv:1901.03450v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Rong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.03450">
                                    <div class="article-summary-box-inner">
                                        <span>With the proliferation of Internet-of-Things devices, acoustic sensing
attracts much attention in recent years. It exploits acoustic transceivers such
as microphones and speakers beyond their primary functions, namely recording
and playing, to enable novel applications and new user experiences. In this
paper, we present the first systematic survey of recent advances in active
acoustic sensing using commodity hardware with a frequency range below
24~\!kHz. We propose a general framework that categorizes main building blocks
of acoustic sensing systems. This framework encompasses three layers, i.e.,
physical layer, core technique layer, and application layer. The physical layer
includes basic hardware components, acoustic platforms as well as the air-borne
and structure-borne channel characteristics. The core technique layer
encompasses key mechanisms to generate acoustic signals (waveforms) and to
extract useful temporal, spatial and spectral information from received
signals. The application layer builds upon the functions offered by the core
techniques to realize different acoustic sensing applications. We highlight
unique challenges due to the limitations of physical devices and acoustic
channels and how they are mitigated or overcame by core processing techniques
and application-specific solutions. Finally, research opportunities and future
directions are discussed to spawn further in-depth investigation on acoustic
sensing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DDGC: Generative Deep Dexterous Grasping in Clutter. (arXiv:2103.04783v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lundell_J/0/1/0/all/0/1">Jens Lundell</a>, <a href="http://arxiv.org/find/cs/1/au:+Verdoja_F/0/1/0/all/0/1">Francesco Verdoja</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1">Ville Kyrki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04783">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in multi-fingered robotic grasping have enabled fast
6-Degrees-Of-Freedom (DOF) single object grasping. Multi-finger grasping in
cluttered scenes, on the other hand, remains mostly unexplored due to the added
difficulty of reasoning over obstacles which greatly increases the
computational time to generate high-quality collision-free grasps. In this work
we address such limitations by introducing DDGC, a fast generative multi-finger
grasp sampling method that can generate high quality grasps in cluttered scenes
from a single RGB-D image. DDGC is built as a network that encodes scene
information to produce coarse-to-fine collision-free grasp poses and
configurations. We experimentally benchmark DDGC against the
simulated-annealing planner in GraspIt! on 1200 simulated cluttered scenes and
7 real world scenes. The results show that DDGC outperforms the baseline on
synthesizing high-quality grasps and removing clutter while being 5 times
faster. This, in turn, opens up the door for using multi-finger grasps in
practical applications which has so far been limited due to the excessive
computation time needed by other methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Attention-based Communication-Efficient Federated Learning. (arXiv:2108.05765v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_K/0/1/0/all/0/1">Kai Fong Ernest Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q. S. Quek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05765">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) offers a solution to train a global machine learning
model while still maintaining data privacy, without needing access to data
stored locally at the clients. However, FL suffers performance degradation when
client data distribution is non-IID, and a longer training duration to combat
this degradation may not necessarily be feasible due to communication
limitations. To address this challenge, we propose a new adaptive training
algorithm $\texttt{AdaFL}$, which comprises two components: (i) an
attention-based client selection mechanism for a fairer training scheme among
the clients; and (ii) a dynamic fraction method to balance the trade-off
between performance stability and communication efficiency. Experimental
results show that our $\texttt{AdaFL}$ algorithm outperforms the usual
$\texttt{FedAvg}$ algorithm, and can be incorporated to further improve various
state-of-the-art FL algorithms, with respect to three aspects: model accuracy,
performance stability, and communication efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mean-Field Controls with Q-learning for Cooperative MARL: Convergence and Complexity Analysis. (arXiv:2002.04131v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Haotian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaoli Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Renyuan Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04131">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent reinforcement learning (MARL), despite its popularity and
empirical success, suffers from the curse of dimensionality. This paper builds
the mathematical framework to approximate cooperative MARL by a mean-field
control (MFC) approach, and shows that the approximation error is of
$\mathcal{O}(\frac{1}{\sqrt{N}})$. By establishing an appropriate form of the
dynamic programming principle for both the value function and the Q function,
it proposes a model-free kernel-based Q-learning algorithm (MFC-K-Q), which is
shown to have a linear convergence rate for the MFC problem, the first of its
kind in the MARL literature. It further establishes that the convergence rate
and the sample complexity of MFC-K-Q are independent of the number of agents
$N$, which provides an $\mathcal{O}(\frac{1}{\sqrt{N}})$ approximation to the
MARL problem with $N$ agents in the learning environment. Empirical studies for
the network traffic congestion problem demonstrate that MFC-K-Q outperforms
existing MARL algorithms when $N$ is large, for instance when $N&gt;50$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-aware Synthesis of High-resolution Diffusion from Structural Imaging. (arXiv:2108.04135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anctil_Robitaille_B/0/1/0/all/0/1">Benoit Anctil-Robitaille</a>, <a href="http://arxiv.org/find/cs/1/au:+Theberge_A/0/1/0/all/0/1">Antoine Th&#xe9;berge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1">Maxime Descoteaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Christian Desrosiers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombaert_H/0/1/0/all/0/1">Herv&#xe9; Lombaert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04135">
                                    <div class="article-summary-box-inner">
                                        <span>The physical and clinical constraints surrounding diffusion-weighted imaging
(DWI) often limit the spatial resolution of the produced images to voxels up to
8 times larger than those of T1w images. Thus, the detailed information
contained in T1w imagescould help in the synthesis of diffusion images in
higher resolution. However, the non-Euclidean nature of diffusion imaging
hinders current deep generative models from synthesizing physically plausible
images. In this work, we propose the first Riemannian network architecture for
the direct generation of diffusion tensors (DT) and diffusion orientation
distribution functions (dODFs) from high-resolution T1w images. Our integration
of the Log-Euclidean Metric into a learning objective guarantees, unlike
standard Euclidean networks, the mathematically-valid synthesis of diffusion.
Furthermore, our approach improves the fractional anisotropy mean squared error
(FA MSE) between the synthesized diffusion and the ground-truth by more than
23% and the cosine similarity between principal directions by almost 5% when
compared to our baselines. We validate our generated diffusion by comparing the
resulting tractograms to our expected real data. We observe similar fiber
bundles with streamlines having less than 3% difference in length, less than 1%
difference in volume, and a visually close shape. While our method is able to
generate high-resolution diffusion images from structural inputs in less than
15 seconds, we acknowledge and discuss the limits of diffusion inference solely
relying on T1w images. Our results nonetheless suggest a relationship between
the high-level geometry of the brain and the overall white matter architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal-difference learning with nonlinear function approximation: lazy training and mean field regimes. (arXiv:1905.10917v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agazzi_A/0/1/0/all/0/1">Andrea Agazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10917">
                                    <div class="article-summary-box-inner">
                                        <span>We discuss the approximation of the value function for infinite-horizon
discounted Markov Reward Processes (MRP) with nonlinear functions trained with
the Temporal-Difference (TD) learning algorithm. We first consider this problem
under a certain scaling of the approximating function, leading to a regime
called lazy training. In this regime, the parameters of the model vary only
slightly during the learning process, a feature that has recently been observed
in the training of neural networks, where the scaling we study arises
naturally, implicit in the initialization of their parameters. Both in the
under- and over-parametrized frameworks, we prove exponential convergence to
local, respectively global minimizers of the above algorithm in the lazy
training regime. We then compare this scaling of the parameters to the
mean-field regime, where the approximately linear behavior of the model is
lost. Under this alternative scaling we prove that all fixed points of the
dynamics in parameter space are global minimizers. We finally give examples of
our convergence results in the case of models that diverge if trained with
non-lazy TD learning, and in the case of neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speaker-invariant Affective Representation Learning via Adversarial Training. (arXiv:1911.01533v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Haoqi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_M/0/1/0/all/0/1">Ming Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Narayanan_S/0/1/0/all/0/1">Shrikanth Narayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Georgiou_P/0/1/0/all/0/1">Panayiotis Georgiou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01533">
                                    <div class="article-summary-box-inner">
                                        <span>Representation learning for speech emotion recognition is challenging due to
labeled data sparsity issue and lack of gold standard references. In addition,
there is much variability from input speech signals, human subjective
perception of the signals and emotion label ambiguity. In this paper, we
propose a machine learning framework to obtain speech emotion representations
by limiting the effect of speaker variability in the speech signals.
Specifically, we propose to disentangle the speaker characteristics from
emotion through an adversarial training network in order to better represent
emotion. Our method combines the gradient reversal technique with an entropy
loss function to remove such speaker information. Our approach is evaluated on
both IEMOCAP and CMU-MOSEI datasets. We show that our method improves speech
emotion classification and increases generalization to unseen speakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Compressed Records: Taking a Byte out of Deep Learning Data. (arXiv:1911.00472v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuchnik_M/0/1/0/all/0/1">Michael Kuchnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Amvrosiadis_G/0/1/0/all/0/1">George Amvrosiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1">Virginia Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.00472">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning accelerators efficiently train over vast and growing amounts of
data, placing a newfound burden on commodity networks and storage devices. A
common approach to conserve bandwidth involves resizing or compressing data
prior to training. We introduce Progressive Compressed Records (PCRs), a data
format that uses compression to reduce the overhead of fetching and
transporting data, effectively reducing the training time required to achieve a
target accuracy. PCRs deviate from previous storage formats by combining
progressive compression with an efficient storage layout to view a single
dataset at multiple fidelities---all without adding to the total dataset size.
We implement PCRs and evaluate them on a range of datasets, training tasks, and
hardware architectures. Our work shows that: (i) the amount of compression a
dataset can tolerate exceeds 50% of the original encoding for many DL training
tasks; (ii) it is possible to automatically and efficiently select appropriate
compression levels for a given task; and (iii) PCRs enable tasks to readily
access compressed data at runtime---utilizing as little as half the training
bandwidth and thus potentially doubling training speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing hierarchical multi-view MRI data with StaPLR: An application to Alzheimer&#x27;s disease classification. (arXiv:2108.05761v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Loon_W/0/1/0/all/0/1">Wouter van Loon</a>, <a href="http://arxiv.org/find/stat/1/au:+Vos_F/0/1/0/all/0/1">Frank de Vos</a>, <a href="http://arxiv.org/find/stat/1/au:+Fokkema_M/0/1/0/all/0/1">Marjolein Fokkema</a>, <a href="http://arxiv.org/find/stat/1/au:+Szabo_B/0/1/0/all/0/1">Botond Szabo</a>, <a href="http://arxiv.org/find/stat/1/au:+Koini_M/0/1/0/all/0/1">Marisa Koini</a>, <a href="http://arxiv.org/find/stat/1/au:+Schmidt_R/0/1/0/all/0/1">Reinhold Schmidt</a>, <a href="http://arxiv.org/find/stat/1/au:+Rooij_M/0/1/0/all/0/1">Mark de Rooij</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05761">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view data refers to a setting where features are divided into feature
sets, for example because they correspond to different sources. Stacked
penalized logistic regression (StaPLR) is a recently introduced method that can
be used for classification and automatically selecting the views that are most
important for prediction. We show how this method can easily be extended to a
setting where the data has a hierarchical multi-view structure. We apply StaPLR
to Alzheimer&#x27;s disease classification where different MRI measures have been
calculated from three scan types: structural MRI, diffusion-weighted MRI, and
resting-state fMRI. StaPLR can identify which scan types and which MRI measures
are most important for classification, and it outperforms elastic net
regression in classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Gradients Incorporating the Future. (arXiv:2108.02096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venuto_D/0/1/0/all/0/1">David Venuto</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_E/0/1/0/all/0/1">Elaine Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1">Ofir Nachum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02096">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning about the future -- understanding how decisions in the present time
affect outcomes in the future -- is one of the central challenges for
reinforcement learning (RL), especially in highly-stochastic or partially
observable environments. While predicting the future directly is hard, in this
work we introduce a method that allows an agent to &quot;look into the future&quot;
without explicitly predicting it. Namely, we propose to allow an agent, during
its training on past experience, to observe what \emph{actually} happened in
the future at that time, while enforcing an information bottleneck to avoid the
agent overly relying on this privileged information. This gives our agent the
opportunity to utilize rich and useful information about the future trajectory
dynamics in addition to the present. Our method, Policy Gradients Incorporating
the Future (PGIF), is easy to implement and versatile, being applicable to
virtually any policy gradient algorithm. We apply our proposed method to a
number of off-the-shelf RL algorithms and show that PGIF is able to achieve
higher reward faster in a variety of online and offline RL domains, as well as
sparse-reward and partially observable environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locality Sensitive Hashing with Extended Differential Privacy. (arXiv:2010.09393v5 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_N/0/1/0/all/0/1">Natasha Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawamoto_Y/0/1/0/all/0/1">Yusuke Kawamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1">Takao Murakami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09393">
                                    <div class="article-summary-box-inner">
                                        <span>Extended differential privacy, a generalization of standard differential
privacy (DP) using a general metric, has been widely studied to provide
rigorous privacy guarantees while keeping high utility. However, existing works
on extended DP are limited to few metrics, such as the Euclidean metric.
Consequently, they have only a small number of applications, such as
location-based services and document processing. In this paper, we propose a
couple of mechanisms providing extended DP with a different metric: angular
distance (or cosine distance). Our mechanisms are based on locality sensitive
hashing (LSH), which can be applied to the angular distance and work well for
personal data in a high-dimensional space. We theoretically analyze the privacy
properties of our mechanisms, and prove extended DP for input data by taking
into account that LSH preserves the original metric only approximately. We
apply our mechanisms to friend matching based on high-dimensional personal data
with angular distance in the local model, and evaluate our mechanisms using two
real datasets. We show that LDP requires a very large privacy budget and that
RAPPOR does not work in this application. Then we show that our mechanisms
enable friend matching with high utility and rigorous privacy guarantees based
on extended DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation. (arXiv:2108.05773v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bangunharcana_A/0/1/0/all/0/1">Antyanta Bangunharcana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seokju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyung-Soo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohyun Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05773">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric deep learning approach towards stereo matching aggregates a cost
volume computed from input left and right images using 3D convolutions. Recent
works showed that utilization of extracted image features and a spatially
varying cost volume aggregation complements 3D convolutions. However, existing
methods with spatially varying operations are complex, cost considerable
computation time, and cause memory consumption to increase. In this work, we
construct Guided Cost volume Excitation (GCE) and show that simple channel
excitation of cost volume guided by image can improve performance considerably.
Moreover, we propose a novel method of using top-k selection prior to
soft-argmin disparity regression for computing the final disparity estimate.
Combining our novel contributions, we present an end-to-end network that we
call Correlate-and-Excite (CoEx). Extensive experiments of our model on the
SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate the effectiveness
and efficiency of our model and show that our model outperforms other
speed-based algorithms while also being competitive to other state-of-the-art
algorithms. Codes will be made available at https://github.com/antabangun/coex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards real-world navigation with deep differentiable planners. (arXiv:2108.05713v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishida_S/0/1/0/all/0/1">Shu Ishida</a>, <a href="http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1">Jo&#xe3;o F. Henriques</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05713">
                                    <div class="article-summary-box-inner">
                                        <span>We train embodied neural networks to plan and navigate unseen complex 3D
environments, emphasising real-world deployment. Rather than requiring prior
knowledge of the agent or environment, the planner learns to model the state
transitions and rewards. To avoid the potentially hazardous trial-and-error of
reinforcement learning, we focus on differentiable planners such as Value
Iteration Networks (VIN), which are trained offline from safe expert
demonstrations. Although they work well in small simulations, we address two
major limitations that hinder their deployment. First, we observed that current
differentiable planners struggle to plan long-term in environments with a high
branching complexity. While they should ideally learn to assign low rewards to
obstacles to avoid collisions, we posit that the constraints imposed on the
network are not strong enough to guarantee the network to learn sufficiently
large penalties for every possible collision. We thus impose a structural
constraint on the value iteration, which explicitly learns to model any
impossible actions. Secondly, we extend the model to work with a limited
perspective camera under translation and rotation, which is crucial for real
robot deployment. Many VIN-like planners assume a 360 degrees or overhead view
without rotation. In contrast, our method uses a memory-efficient lattice map
to aggregate CNN embeddings of partial observations, and models the rotational
dynamics explicitly using a 3D state-space grid (translation and rotation). Our
proposals significantly improve semantic navigation and exploration on several
2D and 3D environments, succeeding in settings that are otherwise challenging
for this class of methods. As far as we know, we are the first to successfully
perform differentiable planning on the difficult Active Vision Dataset,
consisting of real images captured from a robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection using principles of human perception. (arXiv:2103.12323v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nassir_M/0/1/0/all/0/1">Mohammad Nassir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12323">
                                    <div class="article-summary-box-inner">
                                        <span>In the fields of statistics and unsupervised machine learning a fundamental
and well-studied problem is anomaly detection. Although anomalies are difficult
to define, many algorithms have been proposed. Underlying the approaches is the
nebulous understanding that anomalies are rare, unusual or inconsistent with
the majority of data. The present work gives a philosophical approach to
clearly define anomalies and to develop an algorithm for their efficient
detection with minimal user intervention. Inspired by the Gestalt School of
Psychology and the Helmholtz principle of human perception, the idea is to
assume anomalies are observations that are unexpected to occur with respect to
certain groupings made by the majority of the data. Thus, under appropriate
random variable modelling anomalies are directly found in a set of data under a
uniform and independent random assumption of the distribution of constituent
elements of the observations; anomalies correspond to those observations where
the expectation of occurrence of the elements in a given view is $&lt;1$. Starting
from fundamental principles of human perception an unsupervised anomaly
detection algorithm is developed that is simple, real-time and parameter-free.
Experiments suggest it as the prime choice for univariate data and it shows
promising performance on the detection of global anomalies in multivariate
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Mitigation of Face Recognition Models Through Calibration. (arXiv:2106.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salvador_T/0/1/0/all/0/1">Tiago Salvador</a>, <a href="http://arxiv.org/find/cs/1/au:+Cairns_S/0/1/0/all/0/1">Stephanie Cairns</a>, <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marshall_N/0/1/0/all/0/1">Noah Marshall</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition models suffer from bias: for example, the probability of a
false positive (incorrect face match) strongly depends on sensitive attributes
like ethnicity. As a result, these models may disproportionately and negatively
impact minority groups when used in law enforcement. In this work, we introduce
the Bias Mitigation Calibration (BMC) method, which (i) increases model
accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated
probabilities, (iii) significantly reduces the gap in the false positive rates,
and (iv) does not require knowledge of the sensitive attribute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Roll-off Points Variations: Exploring Useful Information in Feature Maps by Its Variations. (arXiv:2102.00369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yunkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yuyang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guozheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peiyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_W/0/1/0/all/0/1">Wenjing Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00369">
                                    <div class="article-summary-box-inner">
                                        <span>Useful information (UI) is an elusive concept in neural networks. A
quantitative measurement of UI is absent, despite the variations of UI can be
recognized by prior knowledge. The communication bandwidth of feature maps
decreases after downscaling operations, but UI flows smoothly after training
due to lower Nyquist frequency. Inspired by the low-Nyqusit-frequency nature of
UI, we propose the use of spectral roll-off points (SROPs) to estimate UI on
variations. The computation of an SROP is extended from a 1-D signal to a 2-D
image by the required rotation invariance in image classification tasks. SROP
statistics across feature maps are implemented as layer-wise useful information
estimates. We design sanity checks to explore SROP variations when UI
variations are produced by variations in model input, model architecture and
training stages. The variations of SROP is synchronizes with UI variations in
various randomized and sufficiently trained model structures. Therefore, SROP
variations is an accurate and convenient sign of UI variations, which promotes
the explainability of data representations with respect to frequency-domain
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is the brain macroscopically linear? A system identification of resting state dynamics. (arXiv:2012.12351v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Nozari_E/0/1/0/all/0/1">Erfan Nozari</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bertolero_M/0/1/0/all/0/1">Maxwell A. Bertolero</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Stiso_J/0/1/0/all/0/1">Jennifer Stiso</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Caciagli_L/0/1/0/all/0/1">Lorenzo Caciagli</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cornblath_E/0/1/0/all/0/1">Eli J. Cornblath</a>, <a href="http://arxiv.org/find/q-bio/1/au:+He_X/0/1/0/all/0/1">Xiaosong He</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mahadevan_A/0/1/0/all/0/1">Arun S. Mahadevan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pappas_G/0/1/0/all/0/1">George J. Pappas</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bassett_D/0/1/0/all/0/1">Dani Smith Bassett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12351">
                                    <div class="article-summary-box-inner">
                                        <span>A central challenge in the computational modeling of neural dynamics is the
trade-off between accuracy and simplicity. At the level of individual neurons,
nonlinear dynamics are both experimentally established and essential for
neuronal functioning. An implicit assumption has thus formed that an accurate
computational model of whole-brain dynamics must also be highly nonlinear,
whereas linear models may provide a first-order approximation. Here, we provide
a rigorous and data-driven investigation of this hypothesis at the level of
whole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential
dynamics by leveraging the theory of system identification. Using functional
MRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of
700 subjects in the Human Connectome Project (HCP) and 122 subjects from the
Restoring Active Memory (RAM) project using state-of-the-art linear and
nonlinear model families. We assess relative model fit using predictive power,
computational complexity, and the extent of residual dynamics unexplained by
the model. Contrary to our expectations, linear auto-regressive models achieve
the best measures across all three metrics, eliminating the trade-off between
accuracy and simplicity. To understand and explain this linearity, we highlight
four properties of macroscopic neurodynamics which can counteract or mask
microscopic nonlinear dynamics: averaging over space, averaging over time,
observation noise, and limited data samples. Whereas the latter two are
technological limitations and can improve in the future, the former two are
inherent to aggregated macroscopic brain activity. Our results, together with
the unparalleled interpretability of linear models, can greatly facilitate our
understanding of macroscopic neural dynamics and the principled design of
model-based interventions for the treatment of neuropsychiatric disorders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedXGBoost: Privacy-Preserving XGBoost for Federated Learning. (arXiv:2106.10662v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Nhan Khanh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quang Minh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fangzhou Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Quanwei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirche_S/0/1/0/all/0/1">Sandra Hirche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10662">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is the distributed machine learning framework that enables
collaborative training across multiple parties while ensuring data privacy.
Practical adaptation of XGBoost, the state-of-the-art tree boosting framework,
to federated learning remains limited due to high cost incurred by conventional
privacy-preserving methods. To address the problem, we propose two variants of
federated XGBoost with privacy guarantee: FedXGBoost-SMM and FedXGBoost-LDP.
Our first protocol FedXGBoost-SMM deploys enhanced secure matrix multiplication
method to preserve privacy with lossless accuracy and lower overhead than
encryption-based techniques. Developed independently, the second protocol
FedXGBoost-LDP is heuristically designed with noise perturbation for local
differential privacy, and empirically evaluated on real-world and synthetic
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1">Verna Dankers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1">Elia Bruni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1">Dieuwke Hupkes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05885">
                                    <div class="article-summary-box-inner">
                                        <span>Moving towards human-like linguistic performance is often argued to require
compositional generalisation. Whether neural networks exhibit this ability is
typically studied using artificial languages, for which the compositionality of
input fragments can be guaranteed and their meanings algebraically composed.
However, compositionality in natural language is vastly more complex than this
rigid, arithmetics-like version of compositionality, and as such artificial
compositionality tests do not allow us to draw conclusions about how neural
models deal with compositionality in more realistic scenarios. In this work, we
re-instantiate three compositionality tests from the literature and reformulate
them for neural machine translation (NMT). The results highlight two main
issues: the inconsistent behaviour of NMT models and their inability to
(correctly) modulate between local and global processing. Aside from an
empirical study, our work is a call to action: we should rethink the evaluation
of compositionality in neural networks of natural language, where composing
meaning is not as straightforward as doing the math.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantics-Native Communication with Contextual Reasoning. (arXiv:2108.05681v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_H/0/1/0/all/0/1">Hyowoon Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jihong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1">M&#xe9;rouane Debbah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05681">
                                    <div class="article-summary-box-inner">
                                        <span>Spurred by a huge interest in the post-Shannon communication, it has recently
been shown that leveraging semantics can significantly improve the
communication effectiveness across many tasks. In this article, inspired by
human communication, we propose a novel stochastic model of System 1
semantics-native communication (SNC) for generic tasks, where a speaker has an
intention of referring to an entity, extracts the semantics, and communicates
its symbolic representation to a target listener. To further reach its full
potential, we additionally infuse contextual reasoning into SNC such that the
speaker locally and iteratively self-communicates with a virtual agent built on
the physical listener&#x27;s unique way of coding its semantics, i.e., communication
context. The resultant System 2 SNC allows the speaker to extract the most
effective semantics for its listener. Leveraging the proposed stochastic model,
we show that the reliability of System 2 SNC increases with the number of
meaningful concepts, and derive the expected semantic representation (SR) bit
length which quantifies the extracted effective semantics. It is also shown
that System 2 SNC significantly reduces the SR length without compromising
communication reliability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile-Former: Bridging MobileNet and Transformer. (arXiv:2108.05895v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05895">
                                    <div class="article-summary-box-inner">
                                        <span>We present Mobile-Former, a parallel design of MobileNet and Transformer with
a two-way bridge in between. This structure leverages the advantage of
MobileNet at local processing and transformer at global interaction. And the
bridge enables bidirectional fusion of local and global features. Different
with recent works on vision transformer, the transformer in Mobile-Former
contains very few tokens (e.g. less than 6 tokens) that are randomly
initialized, resulting in low computational cost. Combining with the proposed
light-weight cross attention to model the bridge, Mobile-Former is not only
computationally efficient, but also has more representation power,
outperforming MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet
classification. For instance, it achieves 77.9\% top-1 accuracy at 294M FLOPs,
gaining 1.3\% over MobileNetV3 but saving 17\% of computations. When
transferring to object detection, Mobile-Former outperforms MobileNetV3 by 8.6
AP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Approach to Partial Observability in Games: Learning to Both Act and Observe. (arXiv:2108.05701v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gilmour_E/0/1/0/all/0/1">Elizabeth Gilmour</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotkin_N/0/1/0/all/0/1">Noah Plotkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Leslie Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05701">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is successful at learning to play games where the
entire environment is visible. However, RL approaches are challenged in complex
games like Starcraft II and in real-world environments where the entire
environment is not visible. In these more complex games with more limited
visual information, agents must choose where to look and how to optimally use
their limited visual information in order to succeed at the game. We verify
that with a relatively simple model the agent can learn where to look in
scenarios with a limited visual bandwidth. We develop a method for masking part
of the environment in Atari games to force the RL agent to learn both where to
look and how to play the game in order to study where the RL agent learns to
look. In addition, we develop a neural network architecture and method for
allowing the agent to choose where to look and what action to take in the Pong
game. Further, we analyze the strategies the agent learns to better understand
how the RL agent learns to play the game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Correlation Clustering with Asymmetric Classification Errors. (arXiv:2108.05697v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarov_J/0/1/0/all/0/1">Jafar Jafarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalhan_S/0/1/0/all/0/1">Sanchit Kalhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05697">
                                    <div class="article-summary-box-inner">
                                        <span>In the Correlation Clustering problem, we are given a complete weighted graph
$G$ with its edges labeled as &quot;similar&quot; and &quot;dissimilar&quot; by a noisy binary
classifier. For a clustering $\mathcal{C}$ of graph $G$, a similar edge is in
disagreement with $\mathcal{C}$, if its endpoints belong to distinct clusters;
and a dissimilar edge is in disagreement with $\mathcal{C}$ if its endpoints
belong to the same cluster. The disagreements vector, $\text{dis}$, is a vector
indexed by the vertices of $G$ such that the $v$-th coordinate $\text{dis}_v$
equals the weight of all disagreeing edges incident on $v$. The goal is to
produce a clustering that minimizes the $\ell_p$ norm of the disagreements
vector for $p\geq 1$. We study the $\ell_p$ objective in Correlation Clustering
under the following assumption: Every similar edge has weight in the range of
$[\alpha\mathbf{w},\mathbf{w}]$ and every dissimilar edge has weight at least
$\alpha\mathbf{w}$ (where $\alpha \leq 1$ and $\mathbf{w}&gt;0$ is a scaling
parameter). We give an
$O\left((\frac{1}{\alpha})^{\frac{1}{2}-\frac{1}{2p}}\cdot
\log\frac{1}{\alpha}\right)$ approximation algorithm for this problem.
Furthermore, we show an almost matching convex programming integrality gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Matured Dumb Teacher for Fine Generalization. (arXiv:2108.05776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1">HeeSeung Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kangil Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jong-Hun Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05776">
                                    <div class="article-summary-box-inner">
                                        <span>The flexibility of decision boundaries in neural networks that are unguided
by training data is a well-known problem typically resolved with generalization
methods. A surprising result from recent knowledge distillation (KD) literature
is that random, untrained, and equally structured teacher networks can also
vastly improve generalization performance. It raises the possibility of
existence of undiscovered assumptions useful for generalization on an uncertain
region. In this paper, we shed light on the assumptions by analyzing decision
boundaries and confidence distributions of both simple and KD-based
generalization methods. Assuming that a decision boundary exists to represent
the most general tendency of distinction on an input sample space (i.e., the
simplest hypothesis), we show the various limitations of methods when using the
hypothesis. To resolve these limitations, we propose matured dumb teacher based
KD, conservatively transferring the hypothesis for generalization of the
student without massive destruction of trained information. In practical
experiments on feed-forward and convolution neural networks for image
classification tasks on MNIST, CIFAR-10, and CIFAR-100 datasets, the proposed
method shows stable improvement to the best test performance in the grid search
of hyperparameters. The analysis and results imply that the proposed method can
provide finer generalization than existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Page-level Optimization of e-Commerce Item Recommendations. (arXiv:2108.05891v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1">Chieh Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1">Krutika Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changchen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kathy Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Platz_J/0/1/0/all/0/1">Justin Platz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilardi_A/0/1/0/all/0/1">Adam Ilardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhvanath_S/0/1/0/all/0/1">Sriganesh Madhvanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05891">
                                    <div class="article-summary-box-inner">
                                        <span>The item details page (IDP) is a web page on an e-commerce website that
provides information on a specific product or item listing. Just below the
details of the item on this page, the buyer can usually find recommendations
for other relevant items. These are typically in the form of a series of
modules or carousels, with each module containing a set of recommended items.
The selection and ordering of these item recommendation modules are intended to
increase discover-ability of relevant items and encourage greater user
engagement, while simultaneously showcasing diversity of inventory and
satisfying other business objectives. Item recommendation modules on the IDP
are often curated and statically configured for all customers, ignoring
opportunities for personalization. In this paper, we present a scalable
end-to-end production system to optimize the personalized selection and
ordering of item recommendation modules on the IDP in real-time by utilizing
deep neural networks. Through extensive offline experimentation and online A/B
testing, we show that our proposed system achieves significantly higher
click-through and conversion rates compared to other existing methods. In our
online A/B test, our framework improved click-through rate by 2.48% and
purchase-through rate by 7.34% over a static configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FreaAI: Automated extraction of data slices to test machine learning models. (arXiv:2108.05620v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ackerman_S/0/1/0/all/0/1">Samuel Ackerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_O/0/1/0/all/0/1">Orna Raz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmanovici_M/0/1/0/all/0/1">Marcel Zalmanovici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05620">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) solutions are prevalent. However, many challenges exist
in making these solutions business-grade. One major challenge is to ensure that
the ML solution provides its expected business value. In order to do that, one
has to bridge the gap between the way ML model performance is measured and the
solution requirements. In previous work (Barash et al, &quot;Bridging the gap...&quot;)
we demonstrated the effectiveness of utilizing feature models in bridging this
gap. Whereas ML performance metrics, such as the accuracy or F1-score of a
classifier, typically measure the average ML performance, feature models shed
light on explainable data slices that are too far from that average, and
therefore might indicate unsatisfied requirements. For example, the overall
accuracy of a bank text terms classifier may be very high, say $98\% \pm 2\%$,
yet it might perform poorly for terms that include short descriptions and
originate from commercial accounts. A business requirement, which may be
implicit in the training data, may be to perform well regardless of the type of
account and length of the description. Therefore, the under-performing data
slice that includes short descriptions and commercial accounts suggests
poorly-met requirements. In this paper we show the feasibility of automatically
extracting feature models that result in explainable data slices over which the
ML solution under-performs. Our novel technique, IBM FreaAI aka FreaAI,
extracts such slices from structured ML test data or any other labeled data. We
demonstrate that FreaAI can automatically produce explainable and
statistically-significant data slices over seven open datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real Negatives Matter: Continuous Training with Real Negatives for Delayed Feedback Modeling. (arXiv:2104.14121v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Siyu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1">Xiang-Rong Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Ying Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guorui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14121">
                                    <div class="article-summary-box-inner">
                                        <span>One of the difficulties of conversion rate (CVR) prediction is that the
conversions can delay and take place long after the clicks. The delayed
feedback poses a challenge: fresh data are beneficial to continuous training
but may not have complete label information at the time they are ingested into
the training pipeline. To balance model freshness and label certainty, previous
methods set a short waiting window or even do not wait for the conversion
signal. If conversion happens outside the waiting window, this sample will be
duplicated and ingested into the training pipeline with a positive label.
However, these methods have some issues. First, they assume the observed
feature distribution remains the same as the actual distribution. But this
assumption does not hold due to the ingestion of duplicated samples. Second,
the certainty of the conversion action only comes from the positives. But the
positives are scarce as conversions are sparse in commercial systems. These
issues induce bias during the modeling of delayed feedback. In this paper, we
propose DElayed FEedback modeling with Real negatives (DEFER) method to address
these issues. The proposed method ingests real negative samples into the
training pipeline. The ingestion of real negatives ensures the observed feature
distribution is equivalent to the actual distribution, thus reducing the bias.
The ingestion of real negatives also brings more certainty information of the
conversion. To correct the distribution shift, DEFER employs importance
sampling to weigh the loss function. Experimental results on industrial
datasets validate the superiority of DEFER. DEFER have been deployed in the
display advertising system of Alibaba, obtaining over 6.0% improvement on CVR
in several scenarios. The code and data in this paper are now open-sourced
{https://github.com/gusuperstar/defer.git}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Engineering with Regularity Structures. (arXiv:2108.05879v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chevyrev_I/0/1/0/all/0/1">Ilya Chevyrev</a>, <a href="http://arxiv.org/find/stat/1/au:+Gerasimovics_A/0/1/0/all/0/1">Andris Gerasimovics</a>, <a href="http://arxiv.org/find/stat/1/au:+Weber_H/0/1/0/all/0/1">Hendrik Weber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05879">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the use of models from the theory of regularity structure as
features in machine learning tasks. A model is a multi-linear function of a
space-time signal designed to well-approximate solutions to partial
differential equations (PDEs), even in low regularity regimes. Models can be
seen as natural multi-dimensional generalisations of signatures of paths; our
work therefore aims to extend the recent use of signatures in data science
beyond the context of time-ordered data. We provide a flexible definition of a
model feature vector associated to a space-time signal, along with two
algorithms which illustrate ways in which these features can be combined with
linear regression. We apply these algorithms in several numerical experiments
designed to learn solutions to PDEs with a given forcing and boundary data. Our
experiments include semi-linear parabolic and wave equations with forcing, and
Burgers&#x27; equation with no forcing. We find an advantage in favour of our
algorithms when compared to several alternative methods. Additionally, in the
experiment with Burgers&#x27; equation, we noticed stability in the prediction power
when noise is added to the observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Development of Risk-Free COVID-19 Screening Algorithm from Routine Blood Test using Ensemble Machine Learning. (arXiv:2108.05660v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raihan_M/0/1/0/all/0/1">Md. Mohsin Sarker Raihan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Md. Mohi Uddin Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Akter_L/0/1/0/all/0/1">Laboni Akter</a>, <a href="http://arxiv.org/find/cs/1/au:+Shams_A/0/1/0/all/0/1">Abdullah Bin Shams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05660">
                                    <div class="article-summary-box-inner">
                                        <span>The Reverse Transcription Polymerase Chain Reaction (RTPCR) test is the
silver bullet diagnostic test to discern COVID infection. Rapid antigen
detection is a screening test to identify COVID positive patients in little as
15 minutes, but has a lower sensitivity than the PCR tests. Besides having
multiple standardized test kits, many people are getting infected &amp; either
recovering or dying even before the test due to the shortage and cost of kits,
lack of indispensable specialists and labs, time-consuming result compared to
bulk population especially in developing and underdeveloped countries.
Intrigued by the parametric deviations in immunological &amp; hematological profile
of a COVID patient, this research work leveraged the concept of COVID-19
detection by proposing a risk-free and highly accurate Stacked Ensemble Machine
Learning model to identify a COVID patient from communally
available-widespread-cheap routine blood tests which gives a promising
accuracy, precision, recall &amp; F1-score of 100%. Analysis from R-curve also
shows the preciseness of the risk-free model to be implemented. The proposed
method has the potential for large scale ubiquitous low-cost screening
application. This can add an extra layer of protection in keeping the number of
infected cases to a minimum and control the pandemic by identifying
asymptomatic or pre-symptomatic people early.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PatrickStar: Parallel Training of Pre-trained Models via a Chunk-based Memory Management. (arXiv:2108.05818v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiarui Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shenggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05818">
                                    <div class="article-summary-box-inner">
                                        <span>The pre-trained model (PTM) is revolutionizing Artificial intelligence (AI)
technology. It learns a model with general language features on the vast text
and then fine-tunes the model using a task-specific dataset. Unfortunately, PTM
training requires prohibitively expensive computing devices, especially
fine-tuning, which is still a game for a small proportion of people in the AI
community. Enabling PTMs training on low-quality devices, PatrickStar now makes
PTM accessible to everyone.

PatrickStar reduces memory requirements of computing platforms by using the
CPU-GPU heterogeneous memory space to store model data, consisting of
parameters, gradients, and optimizer states. We observe that the GPU memory
available for model data changes regularly, in a tide-like pattern, decreasing
and increasing iteratively. However, the existing heterogeneous training works
do not take advantage of this pattern. Instead, they statically partition the
model data among CPU and GPU, leading to both memory waste and memory abuse. In
contrast, PatrickStar manages model data in chunks, which are dynamically
distributed in heterogeneous memory spaces. Chunks consist of stateful tensors
which run as finite state machines during training. Guided by the runtime
memory statistics collected in a warm-up iteration, chunks are orchestrated
efficiently in heterogeneous memory and generate lower CPU-GPU data
transmission volume. Symbiosis with the Zero Redundancy Optimizer, PatrickStar
scales to multiple GPUs using data parallelism, with the lowest communication
bandwidth requirements and more efficient bandwidth utilization. Experimental
results show PatrickStar trains a 12 billion parameters GPT model, 2x larger
than the STOA work, on an 8-V100 and 240GB CPU memory node, and is also more
efficient on the same model size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preventing Catastrophic Forgetting and Distribution Mismatch in Knowledge Distillation via Synthetic Data. (arXiv:2108.05698v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Binici_K/0/1/0/all/0/1">Kuluhan Binici</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1">Nam Trung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1">Tulika Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Leman_K/0/1/0/all/0/1">Karianto Leman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05698">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing popularity of deep learning on edge devices, compressing
large neural networks to meet the hardware requirements of resource-constrained
devices became a significant research direction. Numerous compression
methodologies are currently being used to reduce the memory sizes and energy
consumption of neural networks. Knowledge distillation (KD) is among such
methodologies and it functions by using data samples to transfer the knowledge
captured by a large model (teacher) to a smaller one(student). However, due to
various reasons, the original training data might not be accessible at the
compression stage. Therefore, data-free model compression is an ongoing
research problem that has been addressed by various works. In this paper, we
point out that catastrophic forgetting is a problem that can potentially be
observed in existing data-free distillation methods. Moreover, the sample
generation strategies in some of these methods could result in a mismatch
between the synthetic and real data distributions. To prevent such problems, we
propose a data-free KD framework that maintains a dynamic collection of
generated samples over time. Additionally, we add the constraint of matching
the real data distribution in sample generation strategies that target maximum
information gain. Our experiments demonstrate that we can improve the accuracy
of the student models obtained via KD when compared with state-of-the-art
approaches on the SVHN, Fashion MNIST and CIFAR100 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal scoring in Premier League with Poisson regression. (arXiv:2108.05796v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pham_C/0/1/0/all/0/1">Cuong Pham</a>, <a href="http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1">Tung Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05796">
                                    <div class="article-summary-box-inner">
                                        <span>Premier League is known as one of the most competitive football league in the
world, hence there are many goals are scored here every match. Which are the
factors that affect to the number of goal scored in each match? We use Poisson
regression to find out the relation between many factors as shots on target,
corners, red cards, to the goals home team can score in their match.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform. (arXiv:2108.05684v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Youxuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zongze Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shugong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05684">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, synthetic speech generated by advanced text-to-speech (TTS)
and voice conversion (VC) systems has caused great harms to automatic speaker
verification (ASV) systems, urging us to design a synthetic speech detection
system to protect ASV systems. In this paper, we propose a new speech
anti-spoofing model named ResWavegram-Resnet (RW-Resnet). The model contains
two parts, Conv1D Resblocks and backbone Resnet34. The Conv1D Resblock is based
on the Conv1D block with a residual connection. For the first part, we use the
raw waveform as input and feed it to the stacked Conv1D Resblocks to get the
ResWavegram. Compared with traditional methods, ResWavegram keeps all the
information from the audio signal and has a stronger ability in extracting
features. For the second part, the extracted features are fed to the backbone
Resnet34 for the spoofed or bonafide decision. The ASVspoof2019 logical access
(LA) corpus is used to evaluate our proposed RW-Resnet. Experimental results
show that the RW-Resnet achieves better performance than other state-of-the-art
anti-spoofing models, which illustrates its effectiveness in detecting
synthetic speech attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Deep Metric Learning with Structural Matching. (arXiv:2108.05889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05889">
                                    <div class="article-summary-box-inner">
                                        <span>How do the neural networks distinguish two images? It is of critical
importance to understand the matching mechanism of deep models for developing
reliable intelligent systems for many risky visual applications such as
surveillance and access control. However, most existing deep metric learning
methods match the images by comparing feature vectors, which ignores the
spatial structure of images and thus lacks interpretability. In this paper, we
present a deep interpretable metric learning (DIML) method for more transparent
embedding learning. Unlike conventional metric learning methods based on
feature vector comparison, we propose a structural matching strategy that
explicitly aligns the spatial embeddings by computing an optimal matching flow
between feature maps of the two images. Our method enables deep models to learn
metrics in a more human-friendly way, where the similarity of two images can be
decomposed to several part-wise similarities and their contributions to the
overall similarity. Our method is model-agnostic, which can be applied to
off-the-shelf backbone networks and metric learning methods. We evaluate our
method on three major benchmarks of deep metric learning including CUB200-2011,
Cars196, and Stanford Online Products, and achieve substantial improvements
over popular metric learning methods with better interpretability. Code is
available at https://github.com/wl-zhao/DIML</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Billion-Scale Pretraining with Vision Transformers for Multi-Task Visual Representations. (arXiv:2108.05887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beal_J/0/1/0/all/0/1">Josh Beal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao-Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dong Huk Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_A/0/1/0/all/0/1">Andrew Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kislyuk_D/0/1/0/all/0/1">Dmitry Kislyuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05887">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretraining of visual representations has led to state-of-the-art
performance on a range of benchmark computer vision tasks, yet the benefits of
these techniques at extreme scale in complex production systems has been
relatively unexplored. We consider the case of a popular visual discovery
product, where these representations are trained with multi-task learning, from
use-case specific visual understanding (e.g. skin tone classification) to
general representation learning for all visual content (e.g. embeddings for
retrieval). In this work, we describe how we (1) generate a dataset with over a
billion images via large weakly-supervised pretraining to improve the
performance of these visual representations, and (2) leverage Transformers to
replace the traditional convolutional backbone, with insights into both system
and performance improvements, especially at 1B+ image scale. To support this
backbone model, we detail a systematic approach to deriving weakly-supervised
image annotations from heterogenous text signals, demonstrating the benefits of
clustering techniques to handle the long-tail distribution of image labels.
Through a comprehensive study of offline and online evaluation, we show that
large-scale Transformer-based pretraining provides significant benefits to
industry computer vision applications. The model is deployed in a production
visual shopping system, with 36% improvement in top-1 relevance and 23%
improvement in click-through volume. We conduct extensive experiments to better
understand the empirical relationships between Transformer-based architectures,
dataset scale, and the performance of production vision systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate spectral clustering using both reference vectors and topology of the network generated by growing neural gas. (arXiv:2009.07101v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1">Kazuhisa Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07101">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral clustering (SC) is one of the most popular clustering methods and
often outperforms traditional clustering methods. SC uses the eigenvectors of a
Laplacian matrix calculated from a similarity matrix of a dataset. SC has
serious drawbacks: the significant increases in the time complexity derived
from the computation of eigenvectors and the memory space complexity to store
the similarity matrix. To address the issues, I develop a new approximate
spectral clustering using the network generated by growing neural gas (GNG),
called ASC with GNG in this study. ASC with GNG uses not only reference vectors
for vector quantization but also the topology of the network for extraction of
the topological relationship between data points in a dataset. ASC with GNG
calculates the similarity matrix from both the reference vectors and the
topology of the network generated by GNG. Using the network generated from a
dataset by GNG, ASC with GNG achieves to reduce the computational and space
complexities and improve clustering quality. In this study, I demonstrate that
ASC with GNG effectively reduces the computational time. Moreover, this study
shows that ASC with GNG provides equal to or better clustering performance than
SC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yuzhe Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yueh-Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hanwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05877">
                                    <div class="article-summary-box-inner">
                                        <span>While we have made significant progress on understanding hand-object
interactions in computer vision, it is still very challenging for robots to
perform complex dexterous manipulation. In this paper, we propose a new
platform and pipeline, DexMV (Dex Manipulation from Videos), for imitation
learning to bridge the gap between computer vision and robot learning. We
design a platform with: (i) a simulation system for complex dexterous
manipulation tasks with a multi-finger robot hand and (ii) a computer vision
system to record large-scale demonstrations of a human hand conducting the same
tasks. In our new pipeline, we extract 3D hand and object poses from the
videos, and convert them to robot demonstrations via motion retargeting. We
then apply and compare multiple imitation learning algorithms with the
demonstrations. We show that the demonstrations can indeed improve robot
learning by a large margin and solve the complex tasks which reinforcement
learning alone cannot solve. Project page with video:
https://yzqin.github.io/dexmv/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Nonconformity Functions and Difficulty of Datasets Impact the Efficiency of Conformal Classifiers. (arXiv:2108.05677v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aleksandrova_M/0/1/0/all/0/1">Marharyta Aleksandrova</a>, <a href="http://arxiv.org/find/cs/1/au:+Chertov_O/0/1/0/all/0/1">Oleg Chertov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05677">
                                    <div class="article-summary-box-inner">
                                        <span>The property of conformal predictors to guarantee the required accuracy rate
makes this framework attractive in various practical applications. However,
this property is achieved at a price of reduction in precision. In the case of
conformal classification, the systems can output multiple class labels instead
of one. It is also known from the literature, that the choice of nonconformity
function has a major impact on the efficiency of conformal classifiers.
Recently, it was shown that different model-agnostic nonconformity functions
result in conformal classifiers with different characteristics. For a Neural
Network-based conformal classifier, the inverse probability (or hinge loss)
allows minimizing the average number of predicted labels, and margin results in
a larger fraction of singleton predictions. In this work, we aim to further
extend this study. We perform an experimental evaluation using 8 different
classification algorithms and discuss when the previously observed relationship
holds or not. Additionally, we propose a successful method to combine the
properties of these two nonconformity functions. The experimental evaluation is
done using 11 real and 5 synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems. (arXiv:2108.05385v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yufei Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingquan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Min Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ali Muhamed Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Hanqi Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherubin_L/0/1/0/all/0/1">Laurent Cherubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05385">
                                    <div class="article-summary-box-inner">
                                        <span>Spatio-temporal forecasting is of great importance in a wide range of
dynamical systems applications from atmospheric science, to recent COVID-19
spread modeling. These applications rely on accurate predictions of
spatio-temporal structured data reflecting real-world phenomena. A stunning
characteristic is that the dynamical system is not only driven by some physics
laws but also impacted by the localized factor in spatial and temporal regions.
One of the major challenges is to infer the underlying causes, which generate
the perceived data stream and propagate the involved causal dynamics through
the distributed observing units. Another challenge is that the success of
machine learning based predictive models requires massive annotated data for
model training. However, the acquisition of high-quality annotated data is
objectively manual and tedious as it needs a considerable amount of human
intervention, making it infeasible in fields that require high levels of
expertise. To tackle these challenges, we advocate a spatio-temporal
physics-coupled neural networks (ST-PCNN) model to learn the underlying physics
of the dynamical system and further couple the learned physics to assist the
learning of the recurring dynamics. To deal with data-acquisition constraints,
an active learning mechanism with Kriging for actively acquiring the most
informative data is proposed for ST-PCNN training in a partially observable
environment. Our experiments on both synthetic and real-world datasets exhibit
that the proposed ST-PCNN with active learning converges to near optimal
accuracy with substantially fewer instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python. (arXiv:1909.02688v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1">Thomas L. Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tingshan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedigo_B/0/1/0/all/0/1">Benjamin D. Pedigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.02688">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Gaussian mixture modeling is a fundamental tool in clustering, as
well as discriminant analysis and semiparametric density estimation. However,
estimating the optimal model for any given number of components is an NP-hard
problem, and estimating the number of components is in some respects an even
harder problem. Findings: In R, a popular package called mclust addresses both
of these problems. However, Python has lacked such a package. We therefore
introduce AutoGMM, a Python algorithm for automatic Gaussian mixture modeling,
and its hierarchical version, HGMM. AutoGMM builds upon scikit-learn&#x27;s
AgglomerativeClustering and GaussianMixture classes, with certain modifications
to make the results more stable. Empirically, on several different
applications, AutoGMM performs approximately as well as mclust, and sometimes
better. Conclusions: AutoMM, a freely available Python package, enables
efficient Gaussian mixture modeling by automatically selecting the
initialization, number of clusters and covariance constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit Attenuating Weight Normalization. (arXiv:2108.05839v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aman Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanath_R/0/1/0/all/0/1">Rohan Ramanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1">Anika Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sirou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingzhou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Keerthi_S/0/1/0/all/0/1">S. Sathiya Keerthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05839">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized deep networks trained using gradient-based optimizers are
a popular choice for solving classification and ranking problems. Without
appropriately tuned $\ell_2$ regularization or weight decay, such networks have
the tendency to make output scores (logits) and network weights large, causing
training loss to become too small and the network to lose its adaptivity
(ability to move around) in the parameter space. Although regularization is
typically understood from an overfitting perspective, we highlight its role in
making the network more adaptive and enabling it to escape more easily from
weights that generalize poorly. To provide such a capability, we propose a
method called Logit Attenuating Weight Normalization (LAWN), that can be
stacked onto any gradient-based optimizer. LAWN controls the logits by
constraining the weight norms of layers in the final homogeneous sub-network.
Empirically, we show that the resulting LAWN variant of the optimizer makes a
deep network more adaptive to finding minimas with superior generalization
performance on large-scale image classification and recommender systems. While
LAWN is particularly impressive in improving Adam, it greatly improves all
optimizers when used with large batch sizes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A functional mirror ascent view of policy gradient methods with function approximation. (arXiv:2108.05828v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1">Sharan Vaswani</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1">Olivier Bachem</a>, <a href="http://arxiv.org/find/cs/1/au:+Totaro_S/0/1/0/all/0/1">Simone Totaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_R/0/1/0/all/0/1">Robert Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_M/0/1/0/all/0/1">Marlos C. Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05828">
                                    <div class="article-summary-box-inner">
                                        <span>We use functional mirror ascent to propose a general framework (referred to
as FMA-PG) for designing policy gradient methods. The functional perspective
distinguishes between a policy&#x27;s functional representation (what are its
sufficient statistics) and its parameterization (how are these statistics
represented) and naturally results in computationally efficient off-policy
updates. For simple policy parameterizations, the FMA-PG framework ensures that
the optimal policy is a fixed point of the updates. It also allows us to handle
complex policy parameterizations (e.g., neural networks) while guaranteeing
policy improvement. Our framework unifies several PG methods and opens the way
for designing sample-efficient variants of existing methods. Moreover, it
recovers important implementation heuristics (e.g., using forward vs reverse KL
divergence) in a principled way. With a softmax functional representation,
FMA-PG results in a variant of TRPO with additional desirable properties. It
also suggests an improved variant of PPO, whose robustness and efficiency we
empirically demonstrate on MuJoCo. Via experiments on simple reinforcement
learning problems, we evaluate algorithms instantiated by FMA-PG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlation Clustering with Asymmetric Classification Errors. (arXiv:2108.05696v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarov_J/0/1/0/all/0/1">Jafar Jafarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalhan_S/0/1/0/all/0/1">Sanchit Kalhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05696">
                                    <div class="article-summary-box-inner">
                                        <span>In the Correlation Clustering problem, we are given a weighted graph $G$ with
its edges labeled as &quot;similar&quot; or &quot;dissimilar&quot; by a binary classifier. The goal
is to produce a clustering that minimizes the weight of &quot;disagreements&quot;: the
sum of the weights of &quot;similar&quot; edges across clusters and &quot;dissimilar&quot; edges
within clusters. We study the correlation clustering problem under the
following assumption: Every &quot;similar&quot; edge $e$ has weight
$\mathbf{w}_e\in[\alpha \mathbf{w}, \mathbf{w}]$ and every &quot;dissimilar&quot; edge
$e$ has weight $\mathbf{w}_e\geq \alpha \mathbf{w}$ (where $\alpha\leq 1$ and
$\mathbf{w}&gt;0$ is a scaling parameter). We give a $(3 + 2 \log_e (1/\alpha))$
approximation algorithm for this problem. This assumption captures well the
scenario when classification errors are asymmetric. Additionally, we show an
asymptotically matching Linear Programming integrality gap of $\Omega(\log
1/\alpha)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Feedback. (arXiv:2108.05382v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaofei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1">Kourosh Hakhamaneshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1">Michael Laskin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05382">
                                    <div class="article-summary-box-inner">
                                        <span>A promising approach to solving challenging long-horizon tasks has been to
extract behavior priors (skills) by fitting generative models to large offline
datasets of demonstrations. However, such generative models inherit the biases
of the underlying data and result in poor and unusable skills when trained on
imperfect demonstration data. To better align skill extraction with human
intent we present Skill Preferences (SkiP), an algorithm that learns a model
over human preferences and uses it to extract human-aligned skills from offline
data. After extracting human-preferred skills, SkiP also utilizes human
feedback to solve down-stream tasks with RL. We show that SkiP enables a
simulated kitchen robot to solve complex multi-step manipulation tasks and
substantially outperforms prior leading RL algorithms with human preferences as
well as leading skill extraction algorithms without human preferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hybrid Learning Approach to Detecting Regime Switches in Financial Markets. (arXiv:2108.05801v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Akioyamen_P/0/1/0/all/0/1">Peter Akioyamen</a> (1), <a href="http://arxiv.org/find/q-fin/1/au:+Tang_Y/0/1/0/all/0/1">Yi Zhou Tang</a> (1), <a href="http://arxiv.org/find/q-fin/1/au:+Hussien_H/0/1/0/all/0/1">Hussien Hussien</a> (1) ((1) Western University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05801">
                                    <div class="article-summary-box-inner">
                                        <span>Financial markets are of much interest to researchers due to their dynamic
and stochastic nature. With their relations to world populations, global
economies and asset valuations, understanding, identifying and forecasting
trends and regimes are highly important. Attempts have been made to forecast
market trends by employing machine learning methodologies, while statistical
techniques have been the primary methods used in developing market regime
switching models used for trading and hedging. In this paper we present a novel
framework for the detection of regime switches within the US financial markets.
Principal component analysis is applied for dimensionality reduction and the
k-means algorithm is used as a clustering technique. Using a combination of
cluster analysis and classification, we identify regimes in financial markets
based on publicly available economic data. We display the efficacy of the
framework by constructing and assessing the performance of two trading
strategies based on detected regimes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">perf4sight: A toolflow to model CNN training performance on Edge GPUs. (arXiv:2108.05580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_A/0/1/0/all/0/1">Aditya Rajagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1">Christos-Savvas Bouganis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05580">
                                    <div class="article-summary-box-inner">
                                        <span>The increased memory and processing capabilities of today&#x27;s edge devices
create opportunities for greater edge intelligence. In the domain of vision,
the ability to adapt a Convolutional Neural Network&#x27;s (CNN) structure and
parameters to the input data distribution leads to systems with lower memory
footprint, latency and power consumption. However, due to the limited compute
resources and memory budget on edge devices, it is necessary for the system to
be able to predict the latency and memory footprint of the training process in
order to identify favourable training configurations of the network topology
and device combination for efficient network adaptation. This work proposes
perf4sight, an automated methodology for developing accurate models that
predict CNN training memory footprint and latency given a target device and
network. This enables rapid identification of network topologies that can be
retrained on the edge device with low resource consumption. With PyTorch as the
framework and NVIDIA Jetson TX2 as the target device, the developed models
predict training memory footprint and latency with 95% and 91% accuracy
respectively for a wide range of networks, opening the path towards efficient
network adaptation on edge GPUs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Medical Image Segmentation. (arXiv:2108.05476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_P/0/1/0/all/0/1">Pedro H. T. Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05476">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach for few-shot semantic segmentation
with sparse labeled images. We investigate the effectiveness of our method,
which is based on the Model-Agnostic Meta-Learning (MAML) algorithm, in the
medical scenario, where the use of sparse labeling and few-shot can alleviate
the cost of producing new annotated datasets. Our method uses sparse labels in
the meta-training and dense labels in the meta-test, thus making the model
learn to predict dense labels from sparse ones. We conducted experiments with
four Chest X-Ray datasets to evaluate two types of annotations (grid and
points). The results show that our method is the most suitable when the target
domain highly differs from source domains, achieving Jaccard scores comparable
to dense labels, using less than 2% of the pixels of an image with labels in
few-shot scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Critical Connectivity Radius for Randomly-Generated, High Dimensional Data Points. (arXiv:1602.03822v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1602.03822">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by a $2$-dimensional (unsupervised) image segmentation task whereby
local regions of pixels are clustered via edge detection methods, a more
general probabilistic mathematical framework is devised. Critical thresholds
are calculated that indicate strong correlation between randomly-generated,
high dimensional data points that have been projected into structures in a
partition of a bounded, $2$-dimensional area, of which, an image is a special
case. A neighbor concept for structures in the partition is defined and a
critical radius is uncovered. Measured from a central structure in localized
regions of the partition, the radius indicates strong, long and short range
correlation in the count of occupied structures. The size of a short interval
of radii is estimated upon which the transition from short-to-long range
correlation is virtually assured, which defines a demarcation of when an image
ceases to be &quot;interesting&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search From Task Similarity Measure. (arXiv:2103.00241v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1">Cat P. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltani_M/0/1/0/all/0/1">Mohammadreza Soltani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravier_R/0/1/0/all/0/1">Robert Ravier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00241">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a neural architecture search framework based on a
similarity measure between the baseline tasks and the incoming target task. We
first define the notion of task similarity based on the log-determinant of the
Fisher Information Matrices. Next, we compute the task similarity from each of
the baseline tasks to the incoming target task. By utilizing the relation
between a target and a set of learned baseline tasks, the search space of
architectures for the incoming target task can be significantly reduced, making
the discovery of the best candidates in the set of possible architectures
tractable and efficient, in terms of GPU days. This method eliminates the
requirement for training the networks from scratch for the incoming target task
as well as introducing the bias in the initialization of the search space from
the human domain. Experimental results with 8 classification tasks in MNIST and
CIFAR-10 datasets illustrate the efficacy of our proposed approach and its
competitiveness with other state-of-art methods in terms of the classification
performance, the number of parameters, and the search time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoder Fusion RNN: Context and Interaction Aware Decoders for Trajectory Prediction. (arXiv:2108.05814v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rella_E/0/1/0/all/0/1">Edoardo Mello Rella</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zaech_J/0/1/0/all/0/1">Jan-Nico Zaech</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Liniger_A/0/1/0/all/0/1">Alexander Liniger</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a> (1 and 2) ((1) Computer Vision Lab, ETH Z&#xfc;urich (2) PSI, KU Leuven)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05814">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the future behavior of all traffic agents in the vicinity is a
key task to achieve safe and reliable autonomous driving systems. It is a
challenging problem as agents adjust their behavior depending on their
intentions, the others&#x27; actions, and the road layout. In this paper, we propose
Decoder Fusion RNN (DF-RNN), a recurrent, attention-based approach for motion
forecasting. Our network is composed of a recurrent behavior encoder, an
inter-agent multi-headed attention module, and a context-aware decoder. We
design a map encoder that embeds polyline segments, combines them to create a
graph structure, and merges their relevant parts with the agents&#x27; embeddings.
We fuse the encoded map information with further inter-agent interactions only
inside the decoder and propose to use explicit training as a method to
effectively utilize the information available. We demonstrate the efficacy of
our method by testing it on the Argoverse motion forecasting dataset and show
its state-of-the-art performance on the public benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">m-RevNet: Deep Reversible Neural Networks with Momentum. (arXiv:2108.05862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shang-Hua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05862">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the connections between deep residual networks and
first-order Ordinary Differential Equations (ODEs) have been disclosed. In this
work, we further bridge the deep neural architecture design with the
second-order ODEs and propose a novel reversible neural network, termed as
m-RevNet, that is characterized by inserting momentum update to residual
blocks. The reversible property allows us to perform backward pass without
access to activation values of the forward pass, greatly relieving the storage
burden during training. Furthermore, the theoretical foundation based on
second-order ODEs grants m-RevNet with stronger representational power than
vanilla residual networks, which potentially explains its performance gains.
For certain learning scenarios, we analytically and empirically reveal that our
m-RevNet succeeds while standard ResNet fails. Comprehensive experiments on
various image classification and semantic segmentation benchmarks demonstrate
the superiority of our m-RevNet over ResNet, concerning both memory efficiency
and recognition performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MT-ORL: Multi-Task Occlusion Relationship Learning. (arXiv:2108.05722v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+ZHANG_L/0/1/0/all/0/1">Lin ZHANG</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zijian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05722">
                                    <div class="article-summary-box-inner">
                                        <span>Retrieving occlusion relation among objects in a single image is challenging
due to sparsity of boundaries in image. We observe two key issues in existing
works: firstly, lack of an architecture which can exploit the limited amount of
coupling in the decoder stage between the two subtasks, namely occlusion
boundary extraction and occlusion orientation prediction, and secondly,
improper representation of occlusion orientation. In this paper, we propose a
novel architecture called Occlusion-shared and Path-separated Network (OPNet),
which solves the first issue by exploiting rich occlusion cues in shared
high-level features and structured spatial information in task-specific
low-level features. We then design a simple but effective orthogonal occlusion
representation (OOR) to tackle the second issue. Our method surpasses the
state-of-the-art methods by 6.1%/8.3% Boundary-AP and 6.5%/10% Orientation-AP
on standard PIOD/BSDS ownership datasets. Code is available at
https://github.com/fengpanhe/MT-ORL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Engineering an Efficient Boolean Functional Synthesis Engine. (arXiv:2108.05717v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golia_P/0/1/0/all/0/1">Priyanka Golia</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1">Friedrich Slivovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhajit Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05717">
                                    <div class="article-summary-box-inner">
                                        <span>Given a Boolean specification between a set of inputs and outputs, the
problem of Boolean functional synthesis is to synthesise each output as a
function of inputs such that the specification is met. Although the past few
years have witnessed intense algorithmic development, accomplishing scalability
remains the holy grail. The state-of-the-art approach combines machine learning
and automated reasoning to efficiently synthesise Boolean functions. In this
paper, we propose four algorithmic improvements for a data-driven framework for
functional synthesis: using a dependency-driven multi-classifier to learn
candidate function, extracting uniquely defined functions by interpolation,
variables retention, and using lexicographic MaxSAT to repair candidates. We
implement these improvements in the state-of-the-art framework, called Manthan.
The proposed framework is called Manthan2. Manthan2 shows significantly
improved runtime performance compared to Manthan. In an extensive experimental
evaluation on 609 benchmarks, Manthan2 is able to synthesise a Boolean function
vector for 509 instances compared to 356 instances solved by Manthan--- an
increment of 153 instances over the state-of-the-art. To put this into
perspective, Manthan improved on the prior state-of-the-art by only 76
instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AffRankNet+: Ranking Affect Using Privileged Information. (arXiv:2108.05598v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makantasis_K/0/1/0/all/0/1">Konstantinos Makantasis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05598">
                                    <div class="article-summary-box-inner">
                                        <span>Many of the affect modelling tasks present an asymmetric distribution of
information between training and test time; additional information is given
about the training data, which is not available at test time. Learning under
this setting is called Learning Under Privileged Information (LUPI). At the
same time, due to the ordinal nature of affect annotations, formulating affect
modelling tasks as supervised learning ranking problems is gaining ground
within the Affective Computing research community. Motivated by the two facts
above, in this study, we introduce a ranking model that treats additional
information about the training data as privileged information to accurately
rank affect states. Our ranking model extends the well-known RankNet model to
the LUPI paradigm, hence its name AffRankNet+. To the best of our knowledge, it
is the first time that a ranking model based on neural networks exploits
privileged information. We evaluate the performance of the proposed model on
the public available Afew-VA dataset and compare it against the RankNet model,
which does not use privileged information. Experimental evaluation indicates
that the AffRankNet+ model can yield significantly better performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Sparse Regularization: The Impact of Depth and Early Stopping. (arXiv:2108.05574v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1">Jiangyuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1">Thanh V. Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Hegde_C/0/1/0/all/0/1">Chinmay Hegde</a>, <a href="http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1">Raymond K. W. Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05574">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the implicit bias of gradient descent for sparse
regression. We extend results on regression with quadratic parametrization,
which amounts to depth-2 diagonal linear networks, to more general depth-N
networks, under more realistic settings of noise and correlated designs. We
show that early stopping is crucial for gradient descent to converge to a
sparse model, a phenomenon that we call implicit sparse regularization. This
result is in sharp contrast to known results for noiseless and
uncorrelated-design cases. We characterize the impact of depth and early
stopping and show that for a general depth parameter N, gradient descent with
early stopping achieves minimax optimal sparse recovery with sufficiently small
initialization and step size. In particular, we show that increasing depth
enlarges the scale of working initialization and the early-stopping window,
which leads to more stable gradient paths for sparse recovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning Approach to Active Learning for Image Classification. (arXiv:2108.05595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Werner_T/0/1/0/all/0/1">Thorben Werner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05595">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning requires large amounts of labeled data to fit a model. Many
datasets are already publicly available, nevertheless forcing application
possibilities of machine learning to the domains of those public datasets. The
ever-growing penetration of machine learning algorithms in new application
areas requires solutions for the need for data in those new domains. This
thesis works on active learning as one possible solution to reduce the amount
of data that needs to be processed by hand, by processing only those datapoints
that specifically benefit the training of a strong model for the task. A newly
proposed framework for framing the active learning workflow as a reinforcement
learning problem is adapted for image classification and a series of three
experiments is conducted. Each experiment is evaluated and potential issues
with the approach are outlined. Each following experiment then proposes
improvements to the framework and evaluates their impact. After the last
experiment, a final conclusion is drawn, unfortunately rejecting this work&#x27;s
hypothesis and outlining that the proposed framework at the moment is not
capable of improving active learning for image classification with a trained
reinforcement learning agent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Hash Robustly, with Guarantees. (arXiv:2108.05433v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andoni_A/0/1/0/all/0/1">Alexandr Andoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Beaglehole_D/0/1/0/all/0/1">Daniel Beaglehole</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05433">
                                    <div class="article-summary-box-inner">
                                        <span>The indexing algorithms for the high-dimensional nearest neighbor search
(NNS) with the best worst-case guarantees are based on the randomized Locality
Sensitive Hashing (LSH), and its derivatives. In practice, many heuristic
approaches exist to &quot;learn&quot; the best indexing method in order to speed-up NNS,
crucially adapting to the structure of the given dataset.

Oftentimes, these heuristics outperform the LSH-based algorithms on real
datasets, but, almost always, come at the cost of losing the guarantees of
either correctness or robust performance on adversarial queries, or apply to
datasets with an assumed extra structure/model. In this paper, we design an NNS
algorithm for the Hamming space that has worst-case guarantees essentially
matching that of theoretical algorithms, while optimizing the hashing to the
structure of the dataset (think instance-optimal algorithms) for performance on
the minimum-performing query. We evaluate the algorithm&#x27;s ability to optimize
for a given dataset both theoretically and practically. On the theoretical
side, we exhibit a natural setting (dataset model) where our algorithm is much
better than the standard theoretical one. On the practical side, we run
experiments that show that our algorithm has a 1.8x and 2.1x better recall on
the worst-performing queries to the MNIST and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Sequential Slate Optimization. (arXiv:2108.05618v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Mingjian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Indrakanti_S/0/1/0/all/0/1">Saratchandra Indrakanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kannadasan_M/0/1/0/all/0/1">Manojkumar Rangasamy Kannadasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagherjeiran_A/0/1/0/all/0/1">Abraham Bagherjeiran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05618">
                                    <div class="article-summary-box-inner">
                                        <span>The top search results matching a user query that are displayed on the first
page are critical to the effectiveness and perception of a search system. A
search ranking system typically orders the results by independent
query-document scores to produce a slate of search results. However, such
unilateral scoring methods may fail to capture inter-document dependencies that
users are sensitive to, thus producing a sub-optimal slate. Further, in
practice, many real-world applications such as e-commerce search require
enforcing certain distributional criteria at the slate-level, due to business
objectives or long term user retention goals. Unilateral scoring of results
does not explicitly support optimizing for such objectives with respect to a
slate. Hence, solutions to the slate optimization problem must consider the
optimal selection and order of the documents, along with adherence to
slate-level distributional criteria. To that end, we propose a hybrid framework
extended from traditional slate optimization to solve the conditional slate
optimization problem. We introduce conditional sequential slate optimization
(CSSO), which jointly learns to optimize for traditional ranking metrics as
well as prescribed distribution criteria of documents within the slate. The
proposed method can be applied to practical real world problems such as
enforcing diversity in e-commerce search results, mitigating bias in top
results and personalization of results. Experiments on public datasets and
real-world data from e-commerce datasets show that CSSO outperforms popular
comparable ranking methods in terms of adherence to distributional criteria
while producing comparable or better relevance metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resetting the baseline: CT-based COVID-19 diagnosis with Deep Transfer Learning is not as accurate as widely thought. (arXiv:2108.05649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altaf_F/0/1/0/all/0/1">Fouzia Altaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Syed M.S. Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is gaining instant popularity in computer aided diagnosis of
COVID-19. Due to the high sensitivity of Computed Tomography (CT) to this
disease, CT-based COVID-19 detection with visual models is currently at the
forefront of medical imaging research. Outcomes published in this direction are
frequently claiming highly accurate detection under deep transfer learning.
This is leading medical technologists to believe that deep transfer learning is
the mainstream solution for the problem. However, our critical analysis of the
literature reveals an alarming performance disparity between different
published results. Hence, we conduct a systematic thorough investigation to
analyze the effectiveness of deep transfer learning for COVID-19 detection with
CT images. Exploring 14 state-of-the-art visual models with over 200 model
training sessions, we conclusively establish that the published literature is
frequently overestimating transfer learning performance for the problem, even
in the prestigious scientific sources. The roots of overestimation trace back
to inappropriate data curation. We also provide case studies that consider more
realistic scenarios, and establish transparent baselines for the problem. We
hope that our reproducible investigation will help in curbing hype-driven
claims for the critical problem of COVID-19 diagnosis, and pave the way for a
more transparent performance evaluation of techniques for CT-based COVID-19
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacks against Ranking Algorithms with Text Embeddings: a Case Study on Recruitment Algorithms. (arXiv:2108.05490v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samadi_A/0/1/0/all/0/1">Anahita Samadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1">Debapriya Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nilizadeh_S/0/1/0/all/0/1">Shirin Nilizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05490">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, some studies have shown that text classification tasks are
vulnerable to poisoning and evasion attacks. However, little work has
investigated attacks against decision making algorithms that use text
embeddings, and their output is a ranking. In this paper, we focus on ranking
algorithms for recruitment process, that employ text embeddings for ranking
applicants resumes when compared to a job description. We demonstrate both
white box and black box attacks that identify text items, that based on their
location in embedding space, have significant contribution in increasing the
similarity score between a resume and a job description. The adversary then
uses these text items to improve the ranking of their resume among others. We
tested recruitment algorithms that use the similarity scores obtained from
Universal Sentence Encoder (USE) and Term Frequency Inverse Document Frequency
(TF IDF) vectors. Our results show that in both adversarial settings, on
average the attacker is successful. We also found that attacks against TF IDF
is more successful compared to USE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DOI: Divergence-based Out-of-Distribution Indicators via Deep Generative Models. (arXiv:2108.05509v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_X/0/1/0/all/0/1">Xiaohui Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mingliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_D/0/1/0/all/0/1">Dan Pei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05509">
                                    <div class="article-summary-box-inner">
                                        <span>To ensure robust and reliable classification results, OoD
(out-of-distribution) indicators based on deep generative models are proposed
recently and are shown to work well on small datasets. In this paper, we
conduct the first large collection of benchmarks (containing 92 dataset pairs,
which is 1 order of magnitude larger than previous ones) for existing OoD
indicators and observe that none perform well. We thus advocate that a large
collection of benchmarks is mandatory for evaluating OoD indicators. We propose
a novel theoretical framework, DOI, for divergence-based Out-of-Distribution
indicators (instead of traditional likelihood-based) in deep generative models.
Following this framework, we further propose a simple and effective OoD
detection algorithm: Single-shot Fine-tune. It significantly outperforms past
works by 5~8 in AUROC, and its performance is close to optimal. In recent, the
likelihood criterion is shown to be ineffective in detecting OoD. Single-shot
Fine-tune proposes a novel fine-tune criterion to detect OoD, by whether the
likelihood of the testing sample is improved after fine-tuning a well-trained
model on it. Fine-tune criterion is a clear and easy-following criterion, which
will lead the OoD domain into a new stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DARTS for Inverse Problems: a Study on Hyperparameter Sensitivity. (arXiv:2108.05647v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1">Jovita Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05647">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) is a widely researched tool for
neural architecture search, due to its promising results for image
classification. The main benefit of DARTS is the effectiveness achieved through
the weight-sharing one-shot paradigm, which allows efficient architecture
search. In this work, we investigate DARTS in a systematic case study of
inverse problems, which allows us to analyze these potential benefits in a
controlled manner. Although we demonstrate that the success of DARTS can be
extended from image classification to reconstruction, our experiments yield
three fundamental difficulties in the evaluation of DARTS-based methods: First,
the results show a large variance in all test cases. Second, the final
performance is highly dependent on the hyperparameters of the optimizer. And
third, the performance of the weight-sharing architecture used during training
does not reflect the final performance of the found architecture well. Thus, we
conclude the necessity to 1) report the results of any DARTS-based methods from
several runs along with its underlying performance statistics, 2) show the
correlation of the training and final architecture performance, and 3)
carefully consider if the computational efficiency of DARTS outweighs the costs
of hyperparameter optimization and multiple runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On minimal representations of shallow ReLU networks. (arXiv:2108.05643v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dereich_S/0/1/0/all/0/1">S. Dereich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kassing_S/0/1/0/all/0/1">S. Kassing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05643">
                                    <div class="article-summary-box-inner">
                                        <span>The realization function of a shallow ReLU network is a continuous and
piecewise affine function $f:\mathbb R^d\to \mathbb R$, where the domain
$\mathbb R^{d}$ is partitioned by a set of $n$ hyperplanes into cells on which
$f$ is affine. We show that the minimal representation for $f$ uses either $n$,
$n+1$ or $n+2$ neurons and we characterize each of the three cases. In the
particular case, where the input layer is one-dimensional, minimal
representations always use at most $n+1$ neurons but in all higher dimensional
settings there are functions for which $n+2$ neurons are needed. Then we show
that the set of minimal networks representing $f$ forms a
$C^\infty$-submanifold $M$ and we derive the dimension and the number of
connected components of $M$. Additionally, we give a criterion for the
hyperplanes that guarantees that all continuous, piecewise affine functions are
realization functions of appropriate ReLU networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Local Planning with Linear Function Approximation. (arXiv:2108.05533v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1">Botao Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1">Yasin Abbasi-Yadkori</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazi%7Bc%7D_N/0/1/0/all/0/1">Nevena Lazi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesv%7Ba%7Dri_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05533">
                                    <div class="article-summary-box-inner">
                                        <span>We study query and computationally efficient planning algorithms with linear
function approximation and a simulator. We assume that the agent only has local
access to the simulator, meaning that the agent can only query the simulator at
states that have been visited before. This setting is more practical than many
prior works on reinforcement learning with a generative model. We propose an
algorithm named confident Monte Carlo least square policy iteration (Confident
MC-LSPI) for this setting. Under the assumption that the Q-functions of all
deterministic policies are linear in known features of the state-action pairs,
we show that our algorithm has polynomial query and computational complexities
in the dimension of the features, the effective planning horizon and the
targeted sub-optimality, while these complexities are independent of the size
of the state space. One technical contribution of our work is the introduction
of a novel proof technique that makes use of a virtual policy iteration
algorithm. We use this method to leverage existing results on
$\ell_\infty$-bounded approximate policy iteration to show that our algorithm
can learn the optimal policy for the given initial state even only with local
access to the simulator. We believe that this technique can be extended to
broader settings beyond this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ontology drift is a challenge for explainable data governance. (arXiv:2108.05401v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05401">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the needs for explainable AI that arise from Standard No. 239
from the Basel Committee on Banking Standards (BCBS 239), which outlines 11
principles for effective risk data aggregation and risk reporting for financial
institutions. Of these, explainableAI is necessary for compliance in two key
aspects: data quality, and appropriate reporting for multiple stakeholders. We
describe the implementation challenges for one specific regulatory
requirement:that of having a complete data taxonomy that is appropriate for
firmwide use. The constantly evolving nature of financial ontologies
necessitate a continuous updating process to ensure ongoing compliance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robotic Testbed for Rendezvous and Optical Navigation: Multi-Source Calibration and Machine Learning Use Cases. (arXiv:2108.05529v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1">Tae Ha Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosse_J/0/1/0/all/0/1">Juergen Bosse</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmico_S/0/1/0/all/0/1">Simone D&#x27;Amico</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05529">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents the most recent advances of the Robotic Testbed for
Rendezvous and Optical Navigation (TRON) at Stanford University - the first
robotic testbed capable of validating machine learning algorithms for
spaceborne optical navigation. The TRON facility consists of two 6
degrees-of-freedom KUKA robot arms and a set of Vicon motion track cameras to
reconfigure an arbitrary relative pose between a camera and a target mockup
model. The facility includes multiple Earth albedo light boxes and a sun lamp
to recreate the high-fidelity spaceborne illumination conditions. After the
overview of the facility, this work details the multi-source calibration
procedure which enables the estimation of the relative pose between the object
and the camera with millimeter-level position and millidegree-level orientation
accuracies. Finally, a comparative analysis of the synthetic and TRON simulated
imageries is performed using a Convolutional Neural Network (CNN) pre-trained
on the synthetic images. The result shows a considerable gap in the CNN&#x27;s
performance, suggesting the TRON simulated images can be used to validate the
robustness of any machine learning algorithms trained on more easily accessible
synthetic imagery from computer graphics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Contextual Appointment Scheduling Problem. (arXiv:2108.05531v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sadghiani_N/0/1/0/all/0/1">Nima Salehi Sadghiani</a>, <a href="http://arxiv.org/find/math/1/au:+Motiian_S/0/1/0/all/0/1">Saeid Motiian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05531">
                                    <div class="article-summary-box-inner">
                                        <span>This study is concerned with the determination of optimal appointment times
for a sequence of jobs with uncertain duration. We investigate the data-driven
Appointment Scheduling Problem (ASP) when one has $n$ observations of $p$
features (covariates) related to the jobs as well as historical data. We
formulate ASP as an Integrated Estimation and Optimization problem using a
task-based loss function. We justify the use of contexts by showing that not
including the them yields to inconsistent decisions, which translates to
sub-optimal appointments. We validate our approach through two numerical
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Trend Networks for Recommendations. (arXiv:2108.05552v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05552">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems aim to provide personalized services to users and are
playing an increasingly important role in our daily lives. The key of
recommender systems is to predict how likely users will interact with items
based on their historical online behaviors, e.g., clicks, add-to-cart,
purchases, etc. To exploit these user-item interactions, there are increasing
efforts on considering the user-item interactions as a user-item bipartite
graph and then performing information propagation in the graph via Graph Neural
Networks (GNNs). Given the power of GNNs in graph representation learning,
these GNN-based recommendation methods have remarkably boosted the
recommendation performance. Despite their success, most existing GNN-based
recommender systems overlook the existence of interactions caused by unreliable
behaviors (e.g., random/bait clicks) and uniformly treat all the interactions,
which can lead to sub-optimal and unstable performance. In this paper, we
investigate the drawbacks (e.g., non-adaptive propagation and non-robustness)
of existing GNN-based recommendation methods. To address these drawbacks, we
propose the Graph Trend Networks for recommendations (GTN) with principled
designs that can capture the adaptive reliability of the interactions.
Comprehensive experiments and ablation studies are presented to verify and
understand the effectiveness of the proposed framework. Our implementation and
datasets can be released after publication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization. (arXiv:2108.05449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1">Haofu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05449">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms mine knowledge from the training data and thus would
likely inherit the dataset&#x27;s bias information. As a result, the obtained model
would generalize poorly and even mislead the decision process in real-life
applications. We propose to remove the bias information misused by the target
task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly
extracts target and bias features disentangled from the latent representation
generated by a feature extractor and then learns to discover and remove the
correlation between the target and bias features. The correlation measurement
plays a critical role in adversarial debiasing and is conducted by a
cross-sample neural mutual information estimator. Moreover, we propose joint
content and local structural representation learning to boost mutual
information estimation for better performance. We conduct thorough experiments
on publicly available datasets to validate the advantages of the proposed
method over state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seven challenges for harmonizing explainability requirements. (arXiv:2108.05390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Storchan_V/0/1/0/all/0/1">Victor Storchan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05390">
                                    <div class="article-summary-box-inner">
                                        <span>Regulators have signalled an interest in adopting explainable AI(XAI)
techniques to handle the diverse needs for model governance, operational
servicing, and compliance in the financial services industry. In this short
overview, we review the recent technical literature in XAI and argue that based
on our current understanding of the field, the use of XAI techniques in
practice necessitate a highly contextualized approach considering the specific
needs of stakeholders for particular business applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Contract Theory based Incentive Mechanism for Federated Learning. (arXiv:2108.05568v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_M/0/1/0/all/0/1">Mengmeng Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zehui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_C/0/1/0/all/0/1">Cyril Leung</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05568">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) serves as a data privacy-preserved machine learning
paradigm, and realizes the collaborative model trained by distributed clients.
To accomplish an FL task, the task publisher needs to pay financial incentives
to the FL server and FL server offloads the task to the contributing FL
clients. It is challenging to design proper incentives for the FL clients due
to the fact that the task is privately trained by the clients. This paper aims
to propose a contract theory based FL task training model towards minimizing
incentive budget subject to clients being individually rational (IR) and
incentive compatible (IC) in each FL training round. We design a
two-dimensional contract model by formally defining two private types of
clients, namely data quality and computation effort. To effectively aggregate
the trained models, a contract-based aggregator is proposed. We analyze the
feasible and optimal contract solutions to the proposed contract model.
%Experimental results demonstrate that the proposed framework and contract
model can effective improve the generation accuracy of FL tasks. Experimental
results show that the generalization accuracy of the FL tasks can be improved
by the proposed incentive mechanism where contract-based aggregation is
applied.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seismic wave propagation and inversion with Neural Operators. (arXiv:2108.05421v1 [physics.geo-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Yang_Y/0/1/0/all/0/1">Yan Yang</a>, <a href="http://arxiv.org/find/physics/1/au:+Gao_A/0/1/0/all/0/1">Angela F. Gao</a>, <a href="http://arxiv.org/find/physics/1/au:+Castellanos_J/0/1/0/all/0/1">Jorge C. Castellanos</a>, <a href="http://arxiv.org/find/physics/1/au:+Ross_Z/0/1/0/all/0/1">Zachary E. Ross</a>, <a href="http://arxiv.org/find/physics/1/au:+Azizzadenesheli_K/0/1/0/all/0/1">Kamyar Azizzadenesheli</a>, <a href="http://arxiv.org/find/physics/1/au:+Clayton_R/0/1/0/all/0/1">Robert W. Clayton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05421">
                                    <div class="article-summary-box-inner">
                                        <span>Seismic wave propagation forms the basis for most aspects of seismological
research, yet solving the wave equation is a major computational burden that
inhibits the progress of research. This is exaspirated by the fact that new
simulations must be performed when the velocity structure or source location is
perturbed. Here, we explore a prototype framework for learning general
solutions using a recently developed machine learning paradigm called Neural
Operator. A trained Neural Operator can compute a solution in negligible time
for any velocity structure or source location. We develop a scheme to train
Neural Operators on an ensemble of simulations performed with random velocity
models and source locations. As Neural Operators are grid-free, it is possible
to evaluate solutions on higher resolution velocity models than trained on,
providing additional computational efficiency. We illustrate the method with
the 2D acoustic wave equation and demonstrate the method&#x27;s applicability to
seismic tomography, using reverse mode automatic differentiation to compute
gradients of the wavefield with respect to the velocity structure. The
developed procedure is nearly an order of magnitude faster than using
conventional numerical methods for full waveform inversion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gap-Dependent Unsupervised Exploration for Reinforcement Learning. (arXiv:2108.05439v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05439">
                                    <div class="article-summary-box-inner">
                                        <span>For the problem of task-agnostic reinforcement learning (RL), an agent first
collects samples from an unknown environment without the supervision of reward
signals, then is revealed with a reward and is asked to compute a corresponding
near-optimal policy. Existing approaches mainly concern the worst-case
scenarios, in which no structural information of the reward/transition-dynamics
is utilized. Therefore the best sample upper bound is
$\propto\widetilde{\mathcal{O}}(1/\epsilon^2)$, where $\epsilon&gt;0$ is the
target accuracy of the obtained policy, and can be overly pessimistic. To
tackle this issue, we provide an efficient algorithm that utilizes a gap
parameter, $\rho&gt;0$, to reduce the amount of exploration. In particular, for an
unknown finite-horizon Markov decision process, the algorithm takes only
$\widetilde{\mathcal{O}} (1/\epsilon \cdot (H^3SA / \rho + H^4 S^2 A) )$
episodes of exploration, and is able to obtain an $\epsilon$-optimal policy for
a post-revealed reward with sub-optimality gap at least $\rho$, where $S$ is
the number of states, $A$ is the number of actions, and $H$ is the length of
the horizon, obtaining a nearly \emph{quadratic saving} in terms of $\epsilon$.
We show that, information-theoretically, this bound is nearly tight for $\rho 1$. We further show that
$\propto\widetilde{\mathcal{O}}(1)$ sample bound is possible for $H&#x3D;1$ (i.e.,
multi-armed bandit) or with a sampling simulator, establishing a stark
separation between those settings and the RL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning for Irrigation Detection in Satellite Imagery. (arXiv:2108.05484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agastya_C/0/1/0/all/0/1">Chitra Agastya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghebremusse_S/0/1/0/all/0/1">Sirak Ghebremusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_I/0/1/0/all/0/1">Ian Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahabi_H/0/1/0/all/0/1">Hossein Vahabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Todeschini_A/0/1/0/all/0/1">Alberto Todeschini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05484">
                                    <div class="article-summary-box-inner">
                                        <span>Climate change has caused reductions in river runoffs and aquifer recharge
resulting in an increasingly unsustainable crop water demand from reduced
freshwater availability. Achieving food security while deploying water in a
sustainable manner will continue to be a major challenge necessitating careful
monitoring and tracking of agricultural water usage. Historically, monitoring
water usage has been a slow and expensive manual process with many
imperfections and abuses. Ma-chine learning and remote sensing developments
have increased the ability to automatically monitor irrigation patterns, but
existing techniques often require curated and labelled irrigation data, which
are expensive and time consuming to obtain and may not exist for impactful
areas such as developing countries. In this paper, we explore an end-to-end
real world application of irrigation detection with uncurated and unlabeled
satellite imagery. We apply state-of-the-art self-supervised deep learning
techniques to optical remote sensing data, and find that we are able to detect
irrigation with up to nine times better precision, 90% better recall and 40%
more generalization ability than the traditional supervised learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Agnostic Online Learning and Excellent Sets. (arXiv:2108.05569v1 [cs.DM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malliaris_M/0/1/0/all/0/1">Maryanthe Malliaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05569">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit a key idea from the interaction of model theory and combinatorics,
the existence of large &#x60;&#x60;indivisible&#x27;&#x27; sets, called &#x60;&#x60;$\epsilon$-excellent,&#x27;&#x27;
in $k$-edge stable graphs (equivalently, Littlestone classes). Translating to
the language of probability, we find a quite different existence proof for
$\epsilon$-excellent sets in Littlestone classes, using regret bounds in online
learning. This proof applies to any $\epsilon &lt; {1}/{2}$, compared to $&lt;
{1}/{2^{2^k}}$ or so in the original proof. We include a second proof using
closure properties and the VC theorem, with other advantages but weaker bounds.
As a simple corollary, the Littlestone dimension remains finite under some
natural modifications to the definition. A theme in these proofs is the
interaction of two abstract notions of majority, arising from measure, and from
rank or dimension; we prove that these densely often coincide and that this is
characteristic of Littlestone (stable) classes. The last section lists several
open problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Decision-Making for Food Inspections. (arXiv:2108.05523v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shubham Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_B/0/1/0/all/0/1">Bhuvni Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kash_I/0/1/0/all/0/1">Ian A. Kash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05523">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the application of predictive models by the Chicago Department of
Public Health to schedule restaurant inspections and prioritize the detection
of critical violations of the food code. Performing the first analysis from the
perspective of fairness to the population served by the restaurants, we find
that the model treats inspections unequally based on the sanitarian who
conducted the inspection and that in turn there are both geographic and
demographic disparities in the benefits of the model. We examine both
approaches to use the original model in a fairer way and ways to train the
model to achieve fairness and find more success with the former class of
approaches. The challenges from this application point to important directions
for future work around fairness with collective entities rather than
individuals, the use of critical violations as a proxy, and the disconnect
between fair classification and fairness in the dynamic scheduling system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal analysis of the predictability of hand-gesture properties. (arXiv:2108.05762v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05762">
                                    <div class="article-summary-box-inner">
                                        <span>Embodied conversational agents benefit from being able to accompany their
speech with gestures. Although many data-driven approaches to gesture
generation have been proposed in recent years, it is still unclear whether such
systems can consistently generate gestures that convey meaning. We investigate
which gesture properties (phase, category, and semantics) can be predicted from
speech text and/or audio using contemporary deep learning. In extensive
experiments, we show that gesture properties related to gesture meaning
(semantics and category) are predictable from text features (time-aligned BERT
embeddings) alone, but not from prosodic audio features, while rhythm-related
gesture properties (phase) on the other hand can be predicted from either
audio, text (with word-level timing information), or both. These results are
encouraging as they indicate that it is possible to equip an embodied agent
with content-wise meaningful co-speech gestures using a machine-learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-driven Graph Clustering Network. (arXiv:2108.05499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhihao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuheng Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05499">
                                    <div class="article-summary-box-inner">
                                        <span>The combination of the traditional convolutional network (i.e., an
auto-encoder) and the graph convolutional network has attracted much attention
in clustering, in which the auto-encoder extracts the node attribute feature
and the graph convolutional network captures the topological graph feature.
However, the existing works (i) lack a flexible combination mechanism to
adaptively fuse those two kinds of features for learning the discriminative
representation and (ii) overlook the multi-scale information embedded at
different layers for subsequent cluster assignment, leading to inferior
clustering results. To this end, we propose a novel deep clustering method
named Attention-driven Graph Clustering Network (AGCN). Specifically, AGCN
exploits a heterogeneity-wise fusion module to dynamically fuse the node
attribute feature and the topological graph feature. Moreover, AGCN develops a
scale-wise fusion module to adaptively aggregate the multi-scale features
embedded at different layers. Based on a unified optimization framework, AGCN
can jointly perform feature learning and cluster assignment in an unsupervised
fashion. Compared with the existing deep clustering methods, our method is more
flexible and effective since it comprehensively considers the numerous and
discriminative information embedded in the network and directly produces the
clustering results. Extensive quantitative and qualitative results on commonly
used benchmark datasets validate that our AGCN consistently outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intelligent computational model for the classification of Covid-19 with chest radiography compared to other respiratory diseases. (arXiv:2108.05536v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santos_P/0/1/0/all/0/1">Paula Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05536">
                                    <div class="article-summary-box-inner">
                                        <span>Lung X-ray images, if processed using statistical and computational methods,
can distinguish pneumonia from COVID-19. The present work shows that it is
possible to extract lung X-ray characteristics to improve the methods of
examining and diagnosing patients with suspected COVID-19, distinguishing them
from malaria, dengue, H1N1, tuberculosis, and Streptococcus pneumonia. More
precisely, an intelligent computational model was developed to process lung
X-ray images and classify whether the image is of a patient with COVID-19. The
images were processed and extracted their characteristics. These
characteristics were the input data for an unsupervised statistical learning
method, PCA, and clustering, which identified specific attributes of X-ray
images with Covid-19. The introduction of statistical models allowed a fast
algorithm, which used the X-means clustering method associated with the
Bayesian Information Criterion (CIB). The developed algorithm efficiently
distinguished each pulmonary pathology from X-ray images. The method exhibited
excellent sensitivity. The average recognition accuracy of COVID-19 was 0.93
and 0.051.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-08-19T01:35:03.932Z">2021-08-19T01:35:03.932Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>