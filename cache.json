{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.05589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinnuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>",
          "description": "Natural Language Generation (NLG) is a key component in a task-oriented\ndialogue system, which converts the structured meaning representation (MR) to\nthe natural language. For large-scale conversational systems, where it is\ncommon to have over hundreds of intents and thousands of slots, neither\ntemplate-based approaches nor model-based approaches are scalable. Recently,\nneural NLGs started leveraging transfer learning and showed promising results\nin few-shot settings. This paper proposes AUGNLG, a novel data augmentation\napproach that combines a self-trained neural retrieval model with a few-shot\nlearned NLU model, to automatically create MR-to-Text data from open-domain\ntexts. The proposed system mostly outperforms the state-of-the-art methods on\nthe FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm\nimproved results on the FewShotSGD data and provide comprehensive analysis\nresults on key components of our system. Our code and data are available at\nhttps://github.com/XinnuoXu/AugNLG.",
          "link": "http://arxiv.org/abs/2106.05589",
          "publishedOn": "2021-06-11T01:42:17.736Z",
          "wordCount": null,
          "title": "AUGNLG: Few-shot Natural Language Generation using Self-trained Data Augmentation. (arXiv:2106.05589v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seongbin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seongjin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>",
          "description": "End-to-end approaches open a new way for more accurate and efficient spoken\nlanguage understanding (SLU) systems by alleviating the drawbacks of\ntraditional pipeline systems. Previous works exploit textual information for an\nSLU model via pre-training with automatic speech recognition or fine-tuning\nwith knowledge distillation. To utilize textual information more effectively,\nthis work proposes a two-stage textual knowledge distillation method that\nmatches utterance-level representations and predicted logits of two modalities\nduring pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a\nspeech encoder because it captures general and rich features. Furthermore, we\nimprove the performance, especially in a low-resource scenario, with data\naugmentation methods by randomly masking spans of discrete audio tokens and\ncontextualized hidden representations. Consequently, we push the\nstate-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy\nin the full dataset setting and 99.5% in the 10% subset setting. Throughout the\nablation studies, we empirically verify that all used methods are crucial to\nthe final performance, providing the best practice for spoken language\nunderstanding. Code is available at https://github.com/clovaai/textual-kd-slu.",
          "link": "http://arxiv.org/abs/2010.13105",
          "publishedOn": "2021-06-11T01:42:17.722Z",
          "wordCount": null,
          "title": "Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1\">Sophia Althammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1\">Mark Buckley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "Domain-specific contextualized language models have demonstrated substantial\neffectiveness gains for domain-specific downstream tasks, like similarity\nmatching, entity recognition or information retrieval. However successfully\napplying such models in highly specific language domains requires domain\nadaptation of the pre-trained models. In this paper we propose the empirically\nmotivated Linguistically Informed Masking (LIM) method to focus\ndomain-adaptative pre-training on the linguistic patterns of patents, which use\na highly technical sublanguage. We quantify the relevant differences between\npatent, scientific and general-purpose language and demonstrate for two\ndifferent language models (BERT and SciBERT) that domain adaptation with LIM\nleads to systematically improved representations by evaluating the performance\nof the domain-adapted representations of patent language on two independent\ndownstream tasks, the IPC classification and similarity matching. We\ndemonstrate the impact of balancing the learning from different information\nsources during domain adaptation for the patent domain. We make the source code\nas well as the domain-adaptive pre-trained patent language models publicly\navailable at https://github.com/sophiaalthammer/patent-lim.",
          "link": "http://arxiv.org/abs/2106.05768",
          "publishedOn": "2021-06-11T01:42:17.721Z",
          "wordCount": null,
          "title": "Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1\">Ivan Chelombiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1\">Daniel Justus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1\">Douglas Orr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1\">Anastasia Dietrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1\">Frithjof Gressmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1\">Alexandros Koliousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Attention based language models have become a critical component in\nstate-of-the-art natural language processing systems. However, these models\nhave significant computational requirements, due to long training times, dense\noperations and large parameter count. In this work we demonstrate a set of\nmodifications to the structure of a Transformer layer, producing a more\nefficient architecture. First, we add a convolutional module to complement the\nself-attention module, decoupling the learning of local and global\ninteractions. Secondly, we rely on grouped transformations to reduce the\ncomputational cost of dense feed-forward layers and convolutions, while\npreserving the expressivity of the model. We apply the resulting architecture\nto language representation learning and demonstrate its superior performance\ncompared to BERT models of different scales. We further highlight its improved\nefficiency, both in terms of floating-point operations (FLOPs) and\ntime-to-train.",
          "link": "http://arxiv.org/abs/2106.05822",
          "publishedOn": "2021-06-11T01:42:17.681Z",
          "wordCount": null,
          "title": "GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>",
          "description": "Non-autoregressive translation (NAT) significantly accelerates the inference\nprocess via predicting the entire target sequence. However, recent studies show\nthat NAT is weak at learning high-mode of knowledge such as one-to-many\ntranslations. We argue that modes can be divided into various granularities\nwhich can be learned from easy to hard. In this study, we empirically show that\nNAT models are prone to learn fine-grained lower-mode knowledge, such as words\nand phrases, compared with sentences. Based on this observation, we propose\nprogressive multi-granularity training for NAT. More specifically, to make the\nmost of the training data, we break down the sentence-level examples into three\ntypes, i.e. words, phrases, sentences, and with the training goes, we\nprogressively increase the granularities. Experiments on Romanian-English,\nEnglish-German, Chinese-English, and Japanese-English demonstrate that our\napproach improves the phrase translation accuracy and model reordering ability,\ntherefore resulting in better translation quality against strong NAT baselines.\nAlso, we show that more deterministic fine-grained knowledge can further\nenhance performance.",
          "link": "http://arxiv.org/abs/2106.05546",
          "publishedOn": "2021-06-11T01:42:17.661Z",
          "wordCount": 590,
          "title": "Progressive Multi-Granularity Training for Non-Autoregressive Translation. (arXiv:2106.05546v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1\">Devendra Singh Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>",
          "description": "We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.",
          "link": "http://arxiv.org/abs/2106.05346",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1\">Keerthiram Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1\">Subhajit Chaudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1\">Kartik Talamadupula</a>",
          "description": "Text-based games (TBGs) have become a popular proving ground for the\ndemonstration of learning-based agents that make decisions in quasi real-world\nsettings. The crux of the problem for a reinforcement learning agent in such\nTBGs is identifying the objects in the world, and those objects' relations with\nthat world. While the recent use of text-based resources for increasing an\nagent's knowledge and improving its generalization have shown promise, we posit\nin this paper that there is much yet to be learned from visual representations\nof these same worlds. Specifically, we propose to retrieve images that\nrepresent specific instances of text observations from the world and train our\nagents on such images. This improves the agent's overall understanding of the\ngame 'scene' and objects' relationships to the world around them, and the\nvariety of visual representations on offer allow the agent to generate a better\ngeneralization of a relationship. We show that incorporating such images\nimproves the performance of agents in various TBG settings.",
          "link": "http://arxiv.org/abs/2106.05387",
          "publishedOn": "2021-06-11T01:42:17.618Z",
          "wordCount": null,
          "title": "Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aly_R/0/1/0/all/0/1\">Rami Aly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1\">Michael Schlichtkrull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodoulopoulos_C/0/1/0/all/0/1\">Christos Christodoulopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cocarascu_O/0/1/0/all/0/1\">Oana Cocarascu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Arpit Mittal</a>",
          "description": "Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.",
          "link": "http://arxiv.org/abs/2106.05707",
          "publishedOn": "2021-06-11T01:42:17.113Z",
          "wordCount": 614,
          "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information. (arXiv:2106.05707v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murauer_B/0/1/0/all/0/1\">Benjamin Murauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Specht_G/0/1/0/all/0/1\">G&#xfc;nther Specht</a>",
          "description": "Cross-language authorship attribution problems rely on either translation to\nenable the use of single-language features, or language-independent feature\nextraction methods. Until recently, the lack of datasets for this problem\nhindered the development of the latter, and single-language solutions were\nperformed on machine-translated corpora. In this paper, we present a novel\nlanguage-independent feature for authorship analysis based on dependency graphs\nand universal part of speech tags, called DT-grams (dependency tree grams),\nwhich are constructed by selecting specific sub-parts of the dependency graph\nof sentences. We evaluate DT-grams by performing cross-language authorship\nattribution on untranslated datasets of bilingual authors, showing that, on\naverage, they achieve a macro-averaged F1 score of 0.081 higher than previous\nmethods across five different language pairs. Additionally, by providing\nresults for a diverse set of features for comparison, we provide a baseline on\nthe previously undocumented task of untranslated cross-language authorship\nattribution.",
          "link": "http://arxiv.org/abs/2106.05677",
          "publishedOn": "2021-06-11T01:42:17.006Z",
          "wordCount": 577,
          "title": "DT-grams: Structured Dependency Grammar Stylometry for Cross-Language Authorship Attribution. (arXiv:2106.05677v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1\">Kenichi Kumatani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>",
          "description": "In this paper, we propose a unified pre-training approach called UniSpeech to\nlearn speech representations with both unlabeled and labeled data, in which\nsupervised phonetic CTC learning and phonetically-aware contrastive\nself-supervised learning are conducted in a multi-task learning manner. The\nresultant representations can capture information more correlated with phonetic\nstructures and improve the generalization across languages and domains. We\nevaluate the effectiveness of UniSpeech for cross-lingual representation\nlearning on public CommonVoice corpus. The results show that UniSpeech\noutperforms self-supervised pretraining and supervised transfer learning for\nspeech recognition by a maximum of 13.4% and 17.8% relative phone error rate\nreductions respectively (averaged over all testing languages). The\ntransferability of UniSpeech is also demonstrated on a domain-shift speech\nrecognition task, i.e., a relative word error rate reduction of 6% against the\nprevious approach.",
          "link": "http://arxiv.org/abs/2101.07597",
          "publishedOn": "2021-06-11T01:42:16.922Z",
          "wordCount": 618,
          "title": "UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhir_S/0/1/0/all/0/1\">Sohi Sudhir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Pushkar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1\">Helen Yannakoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>",
          "description": "On social media platforms, hateful and offensive language negatively impact\nthe mental well-being of users and the participation of people from diverse\nbackgrounds. Automatic methods to detect offensive language have largely relied\non datasets with categorical labels. However, comments can vary in their degree\nof offensiveness. We create the first dataset of English language Reddit\ncomments that has \\textit{fine-grained, real-valued scores} between -1\n(maximally supportive) and 1 (maximally offensive). The dataset was annotated\nusing \\emph{Best--Worst Scaling}, a form of comparative annotation that has\nbeen shown to alleviate known biases of using rating scales. We show that the\nmethod produces highly reliable offensiveness scores. Finally, we evaluate the\nability of widely-used neural models to predict offensiveness scores on this\nnew dataset.",
          "link": "http://arxiv.org/abs/2106.05664",
          "publishedOn": "2021-06-11T01:42:16.764Z",
          "wordCount": 561,
          "title": "Ruddit: Norms of Offensiveness for English Reddit Comments. (arXiv:2106.05664v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "Short textual descriptions of entities provide summaries of their key\nattributes and have been shown to be useful sources of background knowledge for\ntasks such as entity linking and question answering. However, generating entity\ndescriptions, especially for new and long-tail entities, can be challenging\nsince relevant information is often scattered across multiple sources with\nvaried content and style. We introduce DESCGEN: given mentions spread over\nmultiple documents, the goal is to generate an entity summary description.\nDESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each\npaired with nine evidence documents on average. The documents were collected\nusing a combination of entity linking and hyperlinks to the Wikipedia and\nFandom entity pages, which together provide high-quality distant supervision.\nThe resulting summaries are more abstractive than those found in existing\ndatasets and provide a better proxy for the challenge of describing new and\nemerging entities. We also propose a two-stage extract-then-generate baseline\nand show that there exists a large gap (19.9% in ROUGE-L) between\nstate-of-the-art models and human performance, suggesting that the data will\nsupport significant future work.",
          "link": "http://arxiv.org/abs/2106.05365",
          "publishedOn": "2021-06-11T01:42:16.695Z",
          "wordCount": 611,
          "title": "DESCGEN: A Distantly Supervised Datasetfor Generating Abstractive Entity Descriptions. (arXiv:2106.05365v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chacoma_A/0/1/0/all/0/1\">A. Chacoma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanette_D/0/1/0/all/0/1\">D. H. Zanette</a>",
          "description": "We analyze the frequency-rank relationship in sub-vocabularies corresponding\nto three different grammatical classes (nouns, verbs, and others) in a\ncollection of literary works in English, whose words have been automatically\ntagged according to their grammatical role. Comparing with a null hypothesis\nwhich assumes that words belonging to each class are uniformly distributed\nacross the frequency-ranked vocabulary of the whole work, we disclose\nstatistically significant differences between the three classes. This results\npoint to the fact that frequency-rank relationships may reflect linguistic\nfeatures associated with grammatical function.",
          "link": "http://arxiv.org/abs/2102.10992",
          "publishedOn": "2021-06-11T01:42:16.346Z",
          "wordCount": 536,
          "title": "Word frequency-rank relationship in tagged texts. (arXiv:2102.10992v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1\">Oleksandr Polozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>",
          "description": "We introduce a new type of programming challenge called programming puzzles,\nas an objective and comprehensive evaluation of program synthesis, and release\nan open-source dataset of Python Programming Puzzles (P3). Each puzzle is\ndefined by a short Python program $f$, and the goal is to find an input $x$\nwhich makes $f$ output \"True\". The puzzles are objective in that each one is\nspecified entirely by the source code of its verifier $f$, so evaluating $f(x)$\nis all that is needed to test a candidate solution $x$. They do not require an\nanswer key or input/output examples, nor do they depend on natural language\nunderstanding. The dataset is comprehensive in that it spans problems of a\nrange of difficulties and domains, ranging from trivial string manipulation\nproblems that are immediately obvious to human programmers (but not necessarily\nto AI), to classic programming puzzles (e.g., Towers of Hanoi), to\ninterview/competitive-programming problems (e.g., dynamic programming), to\nlongstanding open problems in algorithms and mathematics (e.g., factoring). The\nobjective nature of P3 readily supports self-supervised bootstrapping. We\ndevelop baseline enumerative program synthesis and GPT-3 solvers that are\ncapable of solving easy puzzles -- even without access to any reference\nsolutions -- by learning from their own past solutions. Based on a small user\nstudy, we find puzzle difficulty to correlate between human programmers and the\nbaseline AI solvers.",
          "link": "http://arxiv.org/abs/2106.05784",
          "publishedOn": "2021-06-11T01:42:16.254Z",
          "wordCount": 661,
          "title": "Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.02692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seanie Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "QA models based on pretrained language mod-els have achieved remarkable\nperformance onv arious benchmark datasets.However, QA models do not generalize\nwell to unseen data that falls outside the training distribution, due to\ndistributional shifts.Data augmentation(DA) techniques which drop/replace words\nhave shown to be effective in regularizing the model from overfitting to the\ntraining data.Yet, they may adversely affect the QA tasks since they incur\nsemantic changes that may lead to wrong answers for the QA task. To tackle this\nproblem, we propose a simple yet effective DA method based on a stochastic\nnoise generator, which learns to perturb the word embedding of the input\nquestions and context without changing their semantics. We validate the\nperformance of the QA models trained with our word embedding perturbation on a\nsingle source dataset, on five different target domains.The results show that\nour method significantly outperforms the baselineDA methods. Notably, the model\ntrained with ours outperforms the model trained with more than 240K\nartificially generated QA pairs.",
          "link": "http://arxiv.org/abs/2105.02692",
          "publishedOn": "2021-06-11T01:42:15.298Z",
          "wordCount": 621,
          "title": "Learning to Perturb Word Embeddings for Out-of-distribution QA. (arXiv:2105.02692v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shih-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.",
          "link": "http://arxiv.org/abs/2105.08399",
          "publishedOn": "2021-06-11T01:42:15.213Z",
          "wordCount": 630,
          "title": "Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yao-Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "The end-to-end architecture has made promising progress in speech translation\n(ST). However, the ST task is still challenging under low-resource conditions.\nMost ST models have shown unsatisfactory results, especially in the absence of\nword information from the source speech utterance. In this study, we survey\nmethods to improve ST performance without using source transcription, and\npropose a learning framework that utilizes a language-independent universal\nphone recognizer. The framework is based on an attention-based\nsequence-to-sequence model, where the encoder generates the phonetic embeddings\nand phone-aware acoustic representations, and the decoder controls the fusion\nof the two embedding streams to produce the target token sequence. In addition\nto investigating different fusion strategies, we explore the specific usage of\nbyte pair encoding (BPE), which compresses a phone sequence into a\nsyllable-like segmented sequence. Due to the conversion of symbols, a segmented\nsequence represents not only pronunciation but also language-dependent\ninformation lacking in phones. Experiments conducted on the Fisher\nSpanish-English and Taigi-Mandarin drama corpora show that our method\noutperforms the conformer-based baseline, and the performance is close to that\nof the existing best method using source transcription.",
          "link": "http://arxiv.org/abs/2105.00171",
          "publishedOn": "2021-06-11T01:42:15.185Z",
          "wordCount": 634,
          "title": "AlloST: Low-resource Speech Translation without Source Transcription. (arXiv:2105.00171v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanbin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Su Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>",
          "description": "This work aims to tackle the challenging heterogeneous graph encoding problem\nin the text-to-SQL task. Previous methods are typically node-centric and merely\nutilize different weight matrices to parameterize edge types, which 1) ignore\nthe rich semantics embedded in the topological structure of edges, and 2) fail\nto distinguish local and non-local relations for each node. To this end, we\npropose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying\nrelational features without constructing meta-paths. By virtue of the line\ngraph, messages propagate more efficiently through not only connections between\nnodes, but also the topology of directed edges. Furthermore, both local and\nnon-local relations are integrated distinctively during the graph iteration. We\nalso design an auxiliary task called graph pruning to improve the\ndiscriminative capability of the encoder. Our framework achieves\nstate-of-the-art results (62.8% with Glove, 72.0% with Electra) on the\ncross-domain text-to-SQL benchmark Spider at the time of writing.",
          "link": "http://arxiv.org/abs/2106.01093",
          "publishedOn": "2021-06-11T01:42:15.121Z",
          "wordCount": 626,
          "title": "LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. (arXiv:2106.01093v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulinskaite_J/0/1/0/all/0/1\">Jogil&#x117; Ulinskait&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pukelis_L/0/1/0/all/0/1\">Lukas Pukelis</a>",
          "description": "Abstract: In this paper we present an approach to develop a\ntext-classification model which would be able to identify populist content in\ntext. The developed BERT-based model is largely successful in identifying\npopulist content in text and produces only a negligible amount of False\nNegatives, which makes it well-suited as a content analysis automation tool,\nwhich shortlists potentially relevant content for human validation.",
          "link": "http://arxiv.org/abs/2106.03161",
          "publishedOn": "2021-06-11T01:42:14.310Z",
          "wordCount": 515,
          "title": "Identifying Populist Paragraphs in Text: A machine-learning approach. (arXiv:2106.03161v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04298",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1\">Christoph L&#xfc;scher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Acoustic modeling of raw waveform and learning feature extractors as part of\nthe neural network classifier has been the goal of many studies in the area of\nautomatic speech recognition (ASR). Recently, one line of research has focused\non frameworks that can be pre-trained on audio-only data in an unsupervised\nfashion and aim at improving downstream ASR tasks. In this work, we investigate\nthe usefulness of one of these front-end frameworks, namely wav2vec, for hybrid\nASR systems. In addition to deploying a pre-trained feature extractor, we\nexplore how to make use of an existing acoustic model (AM) trained on the same\ntask with different features as well. Another neural front-end which is only\ntrained together with the supervised ASR loss as well as traditional Gammatone\nfeatures are applied for comparison. Moreover, it is shown that the AM can be\nretrofitted with i-vectors for speaker adaptation. Finally, the described\nfeatures are combined in order to further advance the performance. With the\nfinal best system, we obtain a relative improvement of 4% and 6% over our\nprevious best model on the LibriSpeech test-clean and test-other sets.",
          "link": "http://arxiv.org/abs/2104.04298",
          "publishedOn": "2021-06-11T01:42:14.294Z",
          "wordCount": 648,
          "title": "Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1\">Benedikt Hilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which work well for large\ndatasets, but tend to overfit when applied in low resource scenarios. One\nsolution to tackle this issue is to generate synthetic data with a trained\ntext-to-speech system (TTS) if additional text is available. This was\nsuccessfully applied in many publications with AED systems. We present a novel\napproach of silence correction in the data pre-processing for TTS systems which\nincreases the robustness when training on corpora targeted for ASR\napplications. In this work we do not only show the successful application of\nsynthetic data for AED systems, but also test the same method on a highly\noptimized state-of-the-art Hybrid ASR system and a competitive monophone based\nsystem using connectionist-temporal-classification (CTC). We show that for the\nlater systems the addition of synthetic data only has a minor effect, but they\nstill outperform the AED systems by a large margin on LibriSpeech-100h. We\nachieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the\nclean/noisy test-sets, surpassing any previous state-of-the-art systems that do\nnot include unlabeled audio data.",
          "link": "http://arxiv.org/abs/2104.05379",
          "publishedOn": "2021-06-11T01:42:14.140Z",
          "wordCount": 657,
          "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1\">Baijun Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_N/0/1/0/all/0/1\">Nini Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_X/0/1/0/all/0/1\">Xiangyu Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangbin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>",
          "description": "Bilingual Lexicon Induction (BLI) aims to map words in one language to their\ntranslations in another, and is typically through learning linear projections\nto align monolingual word representation spaces. Two classes of word\nrepresentations have been explored for BLI: static word embeddings and\ncontextual representations, but there is no studies to combine both. In this\npaper, we propose a simple yet effective mechanism to combine the static word\nembeddings and the contextual representations to utilize the advantages of both\nparadigms. We test the combination mechanism on various language pairs under\nthe supervised and unsupervised BLI benchmark settings. Experiments show that\nour mechanism consistently improves performances over robust BLI baselines on\nall language pairs by averagely improving 3.2 points in the supervised setting,\nand 3.1 points in the unsupervised setting.",
          "link": "http://arxiv.org/abs/2106.03084",
          "publishedOn": "2021-06-11T01:42:14.129Z",
          "wordCount": 589,
          "title": "Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction. (arXiv:2106.03084v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evain_S/0/1/0/all/0/1\">Solene Evain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hang Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boito_M/0/1/0/all/0/1\">Marcely Zanon Boito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mdhaffar_S/0/1/0/all/0/1\">Salima Mdhaffar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alisamir_S/0/1/0/all/0/1\">Sina Alisamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1\">Ziyi Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomashenko_N/0/1/0/all/0/1\">Natalia Tomashenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinarelli_M/0/1/0/all/0/1\">Marco Dinarelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allauzen_A/0/1/0/all/0/1\">Alexandre Allauzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteve_Y/0/1/0/all/0/1\">Yannick Esteve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lecouteux_B/0/1/0/all/0/1\">Benjamin Lecouteux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portet_F/0/1/0/all/0/1\">Francois Portet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossato_S/0/1/0/all/0/1\">Solange Rossato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringeval_F/0/1/0/all/0/1\">Fabien Ringeval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1\">Didier Schwab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "Self-Supervised Learning (SSL) using huge unlabeled data has been\nsuccessfully explored for image and natural language processing. Recent works\nalso investigated SSL from speech. They were notably successful to improve\nperformance on downstream tasks such as automatic speech recognition (ASR).\nWhile these works suggest it is possible to reduce dependence on labeled data\nfor building efficient speech systems, their evaluation was mostly made on ASR\nand using multiple and heterogeneous experimental settings (most of them for\nEnglish). This questions the objective comparison of SSL approaches and the\nevaluation of their impact on building speech systems. In this paper, we\npropose LeBenchmark: a reproducible framework for assessing SSL from speech. It\nnot only includes ASR (high and low resource) tasks but also spoken language\nunderstanding, speech translation and emotion recognition. We also focus on\nspeech technologies in a language different than English: French. SSL models of\ndifferent sizes are trained from carefully sourced and documented datasets.\nExperiments show that SSL is beneficial for most but not all tasks which\nconfirms the need for exhaustive and reliable benchmarks to evaluate its real\nimpact. LeBenchmark is shared with the scientific community for reproducible\nresearch in SSL from speech.",
          "link": "http://arxiv.org/abs/2104.11462",
          "publishedOn": "2021-06-11T01:42:14.107Z",
          "wordCount": 706,
          "title": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech. (arXiv:2104.11462v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1\">Luong Luc Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_P/0/1/0/all/0/1\">Phuc Huynh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kim Thi-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tham Thi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_S/0/1/0/all/0/1\">Sieu Khai Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Luan Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1\">Tin Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>",
          "description": "In this paper, we present a process of building a social listening system\nbased on aspect-based sentiment analysis in Vietnamese from creating a dataset\nto building a real application. Firstly, we create UIT-ViSFD, a Vietnamese\nSmartphone Feedback Dataset as a new benchmark corpus built based on a strict\nannotation schemes for evaluating aspect-based sentiment analysis, consisting\nof 11,122 human-annotated comments for mobile e-commerce, which is freely\navailable for research purposes. We also present a proposed approach based on\nthe Bi-LSTM architecture with the fastText word embeddings for the Vietnamese\naspect based sentiment task. Our experiments show that our approach achieves\nthe best performances with the F1-score of 84.48% for the aspect task and\n63.06% for the sentiment task, which performs several conventional machine\nlearning and deep learning systems. Last but not least, we build SA2SL, a\nsocial listening system based on the best performance model on our dataset,\nwhich will inspire more social listening systems in future.",
          "link": "http://arxiv.org/abs/2105.15079",
          "publishedOn": "2021-06-11T01:42:14.079Z",
          "wordCount": 624,
          "title": "SA2SL: From Aspect-Based Sentiment Analysis to Social Listening System for Business Intelligence. (arXiv:2105.15079v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1\">Sajad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>",
          "description": "Training datasets for semantic parsing are typically small due to the higher\nexpertise required for annotation than most other NLP tasks. As a result,\nmodels for this application usually need additional prior knowledge to be built\ninto the architecture or algorithm. The increased dependency on human experts\nhinders automation and raises the development and maintenance costs in\npractice. This work investigates whether a generic transformer-based seq2seq\nmodel can achieve competitive performance with minimal code-generation-specific\ninductive bias design. By exploiting a relatively sizeable monolingual corpus\nof the target programming language, which is cheap to mine from the web, we\nachieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.\nBoth are SOTA to the best of our knowledge. This positive evidence highlights a\npotentially easier path toward building accurate semantic parsers in practice.",
          "link": "http://arxiv.org/abs/2101.00259",
          "publishedOn": "2021-06-11T01:42:14.063Z",
          "wordCount": 599,
          "title": "Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">John Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berlot_Attwell_I/0/1/0/all/0/1\">Ian Berlot-Attwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1\">Safwan Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudzicz_F/0/1/0/all/0/1\">Frank Rudzicz</a>",
          "description": "Clinical machine learning is increasingly multimodal, collected in both\nstructured tabular formats and unstructured forms such as freetext. We propose\na novel task of exploring fairness on a multimodal clinical dataset, adopting\nequalized odds for the downstream medical prediction tasks. To this end, we\ninvestigate a modality-agnostic fairness algorithm - equalized odds post\nprocessing - and compare it to a text-specific fairness algorithm: debiased\nclinical word embeddings. Despite the fact that debiased word embeddings do not\nexplicitly address equalized odds of protected groups, we show that a\ntext-specific approach to fairness may simultaneously achieve a good balance of\nperformance and classical notions of fairness. We hope that our paper inspires\nfuture contributions at the critical intersection of clinical NLP and fairness.\nThe full source code is available here:\nhttps://github.com/johntiger1/multimodal_fairness",
          "link": "http://arxiv.org/abs/2011.09625",
          "publishedOn": "2021-06-11T01:42:14.056Z",
          "wordCount": 625,
          "title": "Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal Clinical NLP. (arXiv:2011.09625v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chengqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "NeurST is an open-source toolkit for neural speech translation. The toolkit\nmainly focuses on end-to-end speech translation, which is easy to use, modify,\nand extend to advanced speech translation research and products. NeurST aims at\nfacilitating the speech translation research for NLP researchers and building\nreliable benchmarks for this field. It provides step-by-step recipes for\nfeature extraction, data preprocessing, distributed training, and evaluation.\nIn this paper, we will introduce the framework design of NeurST and show\nexperimental results for different benchmark datasets, which can be regarded as\nreliable baselines for future research. The toolkit is publicly available at\nhttps://github.com/bytedance/neurst/ and we will continuously update the\nperformance of NeurST with other counterparts and studies at\nhttps://st-benchmark.github.io/.",
          "link": "http://arxiv.org/abs/2012.10018",
          "publishedOn": "2021-06-11T01:42:14.035Z",
          "wordCount": 582,
          "title": "NeurST: Neural Speech Translation Toolkit. (arXiv:2012.10018v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The uniform information density (UID) hypothesis, which posits that speakers\nbehaving optimally tend to distribute information uniformly across a linguistic\nsignal, has gained traction in psycholinguistics as an explanation for certain\nsyntactic, morphological, and prosodic choices. In this work, we explore\nwhether the UID hypothesis can be operationalized as an inductive bias for\nstatistical language modeling. Specifically, we augment the canonical MLE\nobjective for training language models with a regularizer that encodes UID. In\nexperiments on ten languages spanning five language families, we find that\nusing UID regularization consistently improves perplexity in language models,\nhaving a larger effect when training data is limited. Moreover, via an analysis\nof generated sequences, we find that UID-regularized language models have other\ndesirable properties, e.g., they generate text that is more lexically diverse.\nOur results not only suggest that UID is a reasonable inductive bias for\nlanguage modeling, but also provide an alternative validation of the UID\nhypothesis using modern-day NLP tools.",
          "link": "http://arxiv.org/abs/2105.07144",
          "publishedOn": "2021-06-11T01:42:14.030Z",
          "wordCount": 623,
          "title": "A Cognitive Regularizer for Language Modeling. (arXiv:2105.07144v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1\">Tsz Kin Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohta_M/0/1/0/all/0/1\">Mayumi Ohta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schamoni_S/0/1/0/all/0/1\">Shigehiko Schamoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "We propose an on-the-fly data augmentation method for automatic speech\nrecognition (ASR) that uses alignment information to generate effective\ntraining samples. Our method, called Aligned Data Augmentation (ADA) for ASR,\nreplaces transcribed tokens and the speech representations in an aligned manner\nto generate previously unseen training pairs. The speech representations are\nsampled from an audio dictionary that has been extracted from the training\ncorpus and inject speaker variations into the training examples. The\ntranscribed tokens are either predicted by a language model such that the\naugmented data pairs are semantically close to the original data, or randomly\nsampled. Both strategies result in training pairs that improve robustness in\nASR training. Our experiments on a Seq-to-Seq architecture show that ADA can be\napplied on top of SpecAugment, and achieves about 9-23% and 4-15% relative\nimprovements in WER over SpecAugment alone on LibriSpeech 100h and LibriSpeech\n960h test datasets, respectively.",
          "link": "http://arxiv.org/abs/2104.01393",
          "publishedOn": "2021-06-11T01:42:14.014Z",
          "wordCount": 614,
          "title": "On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR. (arXiv:2104.01393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hussein_A/0/1/0/all/0/1\">Amir Hussein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Shammur Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahmed Ali</a>",
          "description": "In this paper, we present the Kanari/QCRI (KARI) system and the modeling\nstrategies used to participate in the Interspeech 2021 Code-switching (CS)\nchallenge for low-resource Indian languages. The subtask involved developing a\nspeech recognition system for two CS datasets: Hindi-English and\nBengali-English, collected in a real-life scenario. To tackle the CS\nchallenges, we use transfer learning for incorporating the publicly available\nmonolingual Hindi, Bengali, and English speech data. In this work, we study the\neffectiveness of two steps transfer learning protocol for low-resourced CS\ndata: monolingual pretraining, followed by fine-tuning. For acoustic modeling,\nwe develop an end-to-end convolution-augmented transformer (Conformer). We show\nthat selecting the percentage of each monolingual data affects model biases\ntowards using one language character set over the other in a CS scenario. The\nmodels pretrained on well-aligned and accurate monolingual data showed\nrobustness against misalignment between the segments and the transcription.\nFinally, we develop word-level n-gram language models (LM) to rescore ASR\nrecognition.",
          "link": "http://arxiv.org/abs/2106.05885",
          "publishedOn": "2021-06-11T01:42:13.987Z",
          "wordCount": 591,
          "title": "KARI: KAnari/QCRI's End-to-End systems for the INTERSPEECH 2021 Indian Languages Code-Switching Challenge. (arXiv:2106.05885v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:13.977Z",
          "wordCount": 659,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1\">Devaraja Adiga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1\">Rishabh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1\">Amrith Krishna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>",
          "description": "Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the\nvarious linguistic peculiarities present in the language. The Sanskrit language\nis lexically productive, undergoes euphonic assimilation of phones at the word\nboundaries and exhibits variations in spelling conventions and in\npronunciations. In this work, we propose the first large scale study of\nautomatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact\nof unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR\ndataset for Sanskrit, which faithfully captures several of the linguistic\ncharacteristics expressed by the language. We investigate the role of different\nacoustic model and language model units in ASR systems for Sanskrit. We also\npropose a new modelling unit, inspired by the syllable level unit selection,\nthat captures character sequences from one vowel in the word to the next vowel.\nWe also highlight the importance of choosing graphemic representations for\nSanskrit and show the impact of this choice on word error rates (WER). Finally,\nwe extend these insights from Sanskrit ASR for building ASR systems in two\nother Indic languages, Gujarati and Telugu. For both these languages, our\nexperimental results show that the use of phonetic based graphemic\nrepresentations in ASR results in performance improvements as compared to ASR\nsystems that use native scripts.",
          "link": "http://arxiv.org/abs/2106.05852",
          "publishedOn": "2021-06-11T01:42:13.967Z",
          "wordCount": 685,
          "title": "Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1\">Miguel Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with the text references.\nThis is different from human language processing, for which visual imaginations\noften improve comprehension. In this work, we propose ImaginE, an\nimagination-based automatic evaluation metric for natural language generation.\nWith the help of CLIP and DALL-E, two cross-modal models pre-trained on\nlarge-scale image-text pairs, we automatically generate an image as the\nembodied imagination for the text snippet and compute the imagination\nsimilarity using contextual embeddings. Experiments spanning several text\ngeneration tasks demonstrate that adding imagination with our ImaginE displays\ngreat potential in introducing multi-modal information into NLG evaluation, and\nimproves existing automatic metrics' correlations with human similarity\njudgments in many circumstances.",
          "link": "http://arxiv.org/abs/2106.05970",
          "publishedOn": "2021-06-11T01:42:13.873Z",
          "wordCount": 564,
          "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "Sarcasm is a sophisticated way of wrapping any immanent truth, mes-sage, or\neven mockery within a hilarious manner. The advent of communications using\nsocial networks has mass-produced new avenues of socialization. It can be\nfurther said that humor, irony, sarcasm, and wit are the four chariots of being\nsocially funny in the modern days. In this paper, we manually extract the\nsarcastic word distribution features of a benchmark pop culture sarcasm corpus,\ncontaining sarcastic dialogues and monologues. We generate input sequences\nformed of the weighted vectors from such words. We further propose an\namalgamation of four parallel deep long-short term networks (pLSTM), each with\ndistinctive activation classifier. These modules are primarily aimed at\nsuccessfully detecting sarcasm from the text corpus. Our proposed model for\ndetecting sarcasm peaks a training accuracy of 98.95% when trained with the\ndiscussed dataset. Consecutively, it obtains the highest of 98.31% overall\nvalidation accuracy on two handpicked Project Gutenberg English humor\nliterature among all the test cases. Our approach transcends previous\nstate-of-the-art works on several sarcasm corpora and results in a new gold\nstandard performance for sarcasm detection.",
          "link": "http://arxiv.org/abs/2106.05752",
          "publishedOn": "2021-06-11T01:42:13.844Z",
          "wordCount": 657,
          "title": "Parallel Deep Learning-Driven Sarcasm Detection from Pop Culture Text and English Humor Literature. (arXiv:2106.05752v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1\">Jeffrey P. Bigham</a>",
          "description": "Open-domain neural dialogue models have achieved high performance in response\nranking and evaluation tasks. These tasks are formulated as a binary\nclassification of responses given in a dialogue context, and models generally\nlearn to make predictions based on context-response content similarity.\nHowever, over-reliance on content similarity makes the models less sensitive to\nthe presence of inconsistencies, incorrect time expressions and other factors\nimportant for response appropriateness and coherence. We propose approaches for\nautomatically creating adversarial negative training data to help ranking and\nevaluation models learn features beyond content similarity. We propose\nmask-and-fill and keyword-guided approaches that generate negative examples for\ntraining more robust dialogue systems. These generated adversarial responses\nhave high content similarity with the contexts but are either incoherent,\ninappropriate or not fluent. Our approaches are fully data-driven and can be\neasily incorporated in existing models and datasets. Experiments on\nclassification, ranking and evaluation tasks across multiple datasets\ndemonstrate that our approaches outperform strong baselines in providing\ninformative negative examples for training dialogue systems.",
          "link": "http://arxiv.org/abs/2106.05894",
          "publishedOn": "2021-06-11T01:42:13.837Z",
          "wordCount": 600,
          "title": "Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation. (arXiv:2106.05894v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Recently, knowledge distillation (KD) has shown great success in BERT\ncompression. Instead of only learning from the teacher's soft label as in\nconventional KD, researchers find that the rich information contained in the\nhidden layers of BERT is conducive to the student's performance. To better\nexploit the hidden knowledge, a common practice is to force the student to\ndeeply mimic the teacher's hidden states of all the tokens in a layer-wise\nmanner. In this paper, however, we observe that although distilling the\nteacher's hidden state knowledge (HSK) is helpful, the performance gain\n(marginal utility) diminishes quickly as more HSK is distilled. To understand\nthis effect, we conduct a series of analysis. Specifically, we divide the HSK\nof BERT into three dimensions, namely depth, length and width. We first\ninvestigate a variety of strategies to extract crucial knowledge for each\nsingle dimension and then jointly compress the three dimensions. In this way,\nwe show that 1) the student's performance can be improved by extracting and\ndistilling the crucial HSK, and 2) using a tiny fraction of HSK can achieve the\nsame performance as extensive HSK distillation. Based on the second finding, we\nfurther propose an efficient KD paradigm to compress BERT, which does not\nrequire loading the teacher during the training of student. For two kinds of\nstudent models and computing devices, the proposed KD paradigm gives rise to\ntraining speedup of 2.7x ~ 3.4x.",
          "link": "http://arxiv.org/abs/2106.05691",
          "publishedOn": "2021-06-11T01:42:13.832Z",
          "wordCount": 674,
          "title": "Marginal Utility Diminishes: Exploring the Minimum Knowledge for BERT Knowledge Distillation. (arXiv:2106.05691v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yi-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kaizhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent work on speech self-supervised learning (speech SSL) demonstrated the\nbenefits of scale in learning rich and transferable representations for\nAutomatic Speech Recognition (ASR) with limited parallel data. It is then\nnatural to investigate the existence of sparse and transferrable subnetworks in\npre-trained speech SSL models that can achieve even better low-resource ASR\nperformance. However, directly applying widely adopted pruning methods such as\nthe Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost\nneeded. Moreover, contrary to what LTH predicts, the discovered subnetworks\nyield minimal performance gain compared to the original dense network. In this\nwork, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes\nsubnetworks for much better ASR performance, while only requiring a single\ndownstream finetuning run. PARP is inspired by our surprising observation that\nsubnetworks pruned for pre-training tasks only needed to be slightly adjusted\nto achieve a sizeable performance boost in downstream ASR tasks. Extensive\nexperiments on low-resource English and multi-lingual ASR show (1) sparse\nsubnetworks exist in pre-trained speech SSL, and (2) the computational\nadvantage and performance gain of PARP over baseline pruning methods. On the\n10min Librispeech split without LM decoding, PARP discovers subnetworks from\nwav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full\nmodel. We demonstrate PARP mitigates performance degradation in cross-lingual\nmask transfer, and investigate the possibility of discovering a single\nsubnetwork for 10 spoken languages in one run.",
          "link": "http://arxiv.org/abs/2106.05933",
          "publishedOn": "2021-06-11T01:42:13.814Z",
          "wordCount": 686,
          "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tengchao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilijevic_M/0/1/0/all/0/1\">Momcilo Vasilijevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "Video transcript summarization is a fundamental task for video understanding.\nConventional approaches for transcript summarization are usually built upon the\nsummarization data for written language such as news articles, while the domain\ndiscrepancy may degrade the model performance on spoken text. In this paper, we\npresent VT-SSum, a benchmark dataset with spoken language for video transcript\nsegmentation and summarization, which includes 125K transcript-summary pairs\nfrom 9,616 videos. VT-SSum takes advantage of the videos from VideoLectures.NET\nby leveraging the slides content as the weak supervision to generate the\nextractive summary for video transcripts. Experiments with a state-of-the-art\ndeep learning approach show that the model trained with VT-SSum brings a\nsignificant improvement on the AMI spoken text summarization benchmark. VT-SSum\nwill be publicly available to support the future research of video transcript\nsegmentation and summarization tasks.",
          "link": "http://arxiv.org/abs/2106.05606",
          "publishedOn": "2021-06-11T01:42:13.805Z",
          "wordCount": 569,
          "title": "VT-SSum: A Benchmark Dataset for Video Transcript Segmentation and Summarization. (arXiv:2106.05606v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dingmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wanwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1\">Li Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Yunzhe Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>",
          "description": "Most existing neural network based task-oriented dialogue systems follow\nencoder-decoder paradigm, where the decoder purely depends on the source texts\nto generate a sequence of words, usually suffering from instability and poor\nreadability. Inspired by the traditional template-based generation approaches,\nwe propose a template-guided hybrid pointer network for the knowledge-based\ntask-oriented dialogue system, which retrieves several potentially relevant\nanswers from a pre-constructed domain-specific conversational repository as\nguidance answers, and incorporates the guidance answers into both the encoding\nand decoding processes. Specifically, we design a memory pointer network model\nwith a gating mechanism to fully exploit the semantic correlation between the\nretrieved answers and the ground-truth response. We evaluate our model on four\nwidely used task-oriented datasets, including one simulated and three manually\ncreated datasets. The experimental results demonstrate that the proposed model\nachieves significantly better performance than the state-of-the-art methods\nover different automatic evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.05830",
          "publishedOn": "2021-06-11T01:42:13.790Z",
          "wordCount": 579,
          "title": "A Template-guided Hybrid Pointer Network for Knowledge-basedTask-oriented Dialogue Systems. (arXiv:2106.05830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:13.781Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baziotis_C/0/1/0/all/0/1\">Christos Baziotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddow_B/0/1/0/all/0/1\">Barry Haddow</a>",
          "description": "Unsupervised cross-lingual pretraining has achieved strong results in neural\nmachine translation (NMT), by drastically reducing the need for large parallel\ndata. Most approaches adapt masked-language modeling (MLM) to\nsequence-to-sequence architectures, by masking parts of the input and\nreconstructing them in the decoder. In this work, we systematically compare\nmasking with alternative objectives that produce inputs resembling real (full)\nsentences, by reordering and replacing words based on their context. We\npretrain models with different methods on English$\\leftrightarrow$German,\nEnglish$\\leftrightarrow$Nepali and English$\\leftrightarrow$Sinhala monolingual\ndata, and evaluate them on NMT. In (semi-) supervised NMT, varying the\npretraining objective leads to surprisingly small differences in the finetuned\nperformance, whereas unsupervised NMT is much more sensitive to it. To\nunderstand these results, we thoroughly study the pretrained models using a\nseries of probes and verify that they encode and use information in different\nways. We conclude that finetuning on parallel data is mostly sensitive to few\nproperties that are shared by most models, such as a strong decoder, in\ncontrast to unsupervised NMT that also requires models with strong\ncross-lingual abilities.",
          "link": "http://arxiv.org/abs/2106.05634",
          "publishedOn": "2021-06-11T01:42:13.758Z",
          "wordCount": 603,
          "title": "Exploring Unsupervised Pretraining Objectives for Machine Translation. (arXiv:2106.05634v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yaseen_U/0/1/0/all/0/1\">Usama Yaseen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1\">Stefan Langer</a>",
          "description": "This paper presents our findings from participating in the SMM4H Shared Task\n2021. We addressed Named Entity Recognition (NER) and Text Classification. To\naddress NER we explored BiLSTM-CRF with Stacked Heterogeneous Embeddings and\nlinguistic features. We investigated various machine learning algorithms\n(logistic regression, Support Vector Machine (SVM) and Neural Networks) to\naddress text classification. Our proposed approaches can be generalized to\ndifferent languages and we have shown its effectiveness for English and\nSpanish. Our text classification submissions (team:MIC-NLP) have achieved\ncompetitive performance with F1-score of $0.46$ and $0.90$ on ADE\nClassification (Task 1a) and Profession Classification (Task 7a) respectively.\nIn the case of NER, our submissions scored F1-score of $0.50$ and $0.82$ on ADE\nSpan Detection (Task 1b) and Profession Span detection (Task 7b) respectively.",
          "link": "http://arxiv.org/abs/2106.05823",
          "publishedOn": "2021-06-11T01:42:13.700Z",
          "wordCount": 560,
          "title": "Neural Text Classification and StackedHeterogeneous Embeddings for Named Entity Recognition in SMM4H 2021. (arXiv:2106.05823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuqi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>",
          "description": "Most previous studies integrate cognitive language processing signals (e.g.,\neye-tracking or EEG data) into neural models of natural language processing\n(NLP) just by directly concatenating word embeddings with cognitive features,\nignoring the gap between the two modalities (i.e., textual vs. cognitive) and\nnoise in cognitive features. In this paper, we propose a CogAlign approach to\nthese issues, which learns to align textual neural representations to cognitive\nfeatures. In CogAlign, we use a shared encoder equipped with a modality\ndiscriminator to alternatively encode textual and cognitive inputs to capture\ntheir differences and commonalities. Additionally, a text-aware attention\nmechanism is proposed to detect task-related information and to avoid using\nnoise in cognitive features. Experimental results on three NLP tasks, namely\nnamed entity recognition, sentiment analysis and relation extraction, show that\nCogAlign achieves significant improvements with multiple cognitive features\nover state-of-the-art models on public datasets. Moreover, our model is able to\ntransfer cognitive information to other datasets that do not have any cognitive\nprocessing signals.",
          "link": "http://arxiv.org/abs/2106.05544",
          "publishedOn": "2021-06-11T01:42:13.649Z",
          "wordCount": 592,
          "title": "CogAlign: Learning to Align Textual Neural Representations to Cognitive Language Processing Signals. (arXiv:2106.05544v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valles_Perez_I/0/1/0/all/0/1\">Iv&#xe1;n Vall&#xe9;s-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_J/0/1/0/all/0/1\">Julian Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beringer_G/0/1/0/all/0/1\">Grzegorz Beringer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barra_Chicote_R/0/1/0/all/0/1\">Roberto Barra-Chicote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>",
          "description": "Text-to-speech systems recently achieved almost indistinguishable quality\nfrom human speech. However, the prosody of those systems is generally flatter\nthan natural speech, producing samples with low expressiveness. Disentanglement\nof speaker id and prosody is crucial in text-to-speech systems to improve on\nnaturalness and produce more variable syntheses. This paper proposes a new\nneural text-to-speech model that approaches the disentanglement problem by\nconditioning a Tacotron2-like architecture on flow-normalized speaker\nembeddings, and by substituting the reference encoder with a new learned latent\ndistribution responsible for modeling the intra-sentence variability due to the\nprosody. By removing the reference encoder dependency, the speaker-leakage\nproblem typically happening in this kind of systems disappears, producing more\ndistinctive syntheses at inference time. The new model achieves significantly\nhigher prosody variance than the baseline in a set of quantitative prosody\nfeatures, as well as higher speaker distinctiveness, without decreasing the\nspeaker intelligibility. Finally, we observe that the normalized speaker\nembeddings enable much richer speaker interpolations, substantially improving\nthe distinctiveness of the new interpolated speakers.",
          "link": "http://arxiv.org/abs/2106.05762",
          "publishedOn": "2021-06-11T01:42:13.638Z",
          "wordCount": 617,
          "title": "Improving multi-speaker TTS prosody variance with a residual encoder and normalizing flows. (arXiv:2106.05762v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Binbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhendong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wenjing Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xin Lei</a>",
          "description": "The unified streaming and non-streaming two-pass (U2) end-to-end model for\nspeech recognition has shown great performance in terms of streaming\ncapability, accuracy, real-time factor (RTF), and latency. In this paper, we\npresent U2++, an enhanced version of U2 to further improve the accuracy. The\ncore idea of U2++ is to use the forward and the backward information of the\nlabeling sequences at the same time at training to learn richer information,\nand combine the forward and backward prediction at decoding to give more\naccurate recognition results. We also proposed a new data augmentation method\ncalled SpecSub to help the U2++ model to be more accurate and robust. Our\nexperiments show that, compared with U2, U2++ shows faster convergence at\ntraining, better robustness to the decoding method, as well as consistent 5\\% -\n8\\% word error rate reduction gain over U2. On the experiment of AISHELL-1, we\nachieve a 4.63\\% character error rate (CER) with a non-streaming setup and\n5.05\\% with a streaming setup with 320ms latency by U2++. To the best of our\nknowledge, 5.05\\% is the best-published streaming result on the AISHELL-1 test\nset.",
          "link": "http://arxiv.org/abs/2106.05642",
          "publishedOn": "2021-06-11T01:42:13.612Z",
          "wordCount": 626,
          "title": "U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition. (arXiv:2106.05642v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihye Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hye Jin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sungzoon Cho</a>",
          "description": "Increasing attention has been drawn to the sentiment analysis of financial\ndocuments. The most popular examples of such documents include analyst reports\nand economic news, the analysis of which is frequently used to capture the\ntrends in market sentiments. On the other hand, the significance of the role\nsentiment analysis plays in the financial domain has given rise to the efforts\nto construct a financial domain-specific sentiment lexicon. Sentiment lexicons\nlend a hand for solving various text mining tasks, such as unsupervised\nclassification of text data, while alleviating the arduous human labor required\nfor manual labeling. One of the challenges in the construction of an effective\nsentiment lexicon is that the semantic orientation of a word may change\ndepending on the context in which it appears. For instance, the word ``profit\"\nusually conveys positive sentiments; however, when the word is juxtaposed with\nanother word ``decrease,\" the sentiment associated with the phrase ``profit\ndecreases\" now becomes negative. Hence, the sentiment of a given word may shift\nas one begins to consider the context surrounding the word. In this paper, we\naddress this issue by incorporating context when building sentiment lexicon\nfrom a given corpus. Specifically, we construct a lexicon named Senti-DD for\nthe Sentiment lexicon composed of Direction-Dependent words, which expresses\neach term a pair of a directional word and a direction-dependent word.\nExperiment results show that higher classification performance is achieved with\nSenti-DD, proving the effectiveness of our method for automatically\nconstructing a context-aware sentiment lexicon in the financial domain.",
          "link": "http://arxiv.org/abs/2106.05723",
          "publishedOn": "2021-06-11T01:42:13.590Z",
          "wordCount": 685,
          "title": "Automatic Construction of Context-Aware Sentiment Lexicon in the Financial Domain Using Direction-Dependent Words. (arXiv:2106.05723v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nekvinda_T/0/1/0/all/0/1\">Tom&#xe1;&#x161; Nekvinda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>",
          "description": "The MultiWOZ dataset (Budzianowski et al.,2018) is frequently used for\nbenchmarking context-to-response abilities of task-oriented dialogue systems.\nIn this work, we identify inconsistencies in data preprocessing and reporting\nof three corpus-based metrics used on this dataset, i.e., BLEU score and Inform\n& Success rates. We point out a few problems of the MultiWOZ benchmark such as\nunsatisfactory preprocessing, insufficient or under-specified evaluation\nmetrics, or rigid database. We re-evaluate 7 end-to-end and 6 policy\noptimization models in as-fair-as-possible setups, and we show that their\nreported scores cannot be directly compared. To facilitate comparison of future\nsystems, we release our stand-alone standardized evaluation scripts. We also\ngive basic recommendations for corpus-based benchmarking in future works.",
          "link": "http://arxiv.org/abs/2106.05555",
          "publishedOn": "2021-06-11T01:42:13.581Z",
          "wordCount": 554,
          "title": "Shades of BLEU, Flavours of Success: The Case of MultiWOZ. (arXiv:2106.05555v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chousa_K/0/1/0/all/0/1\">Katsuki Chousa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morishita_M/0/1/0/all/0/1\">Makoto Morishita</a>",
          "description": "This paper describes our systems that were submitted to the restricted\ntranslation task at WAT 2021. In this task, the systems are required to output\ntranslated sentences that contain all given word constraints. Our system\ncombined input augmentation and constrained beam search algorithms. Through\nexperiments, we found that this combination significantly improves translation\naccuracy and can save inference time while containing all the constraints in\nthe output. For both En->Ja and Ja->En, our systems obtained the best\nevaluation performances in automatic evaluation.",
          "link": "http://arxiv.org/abs/2106.05450",
          "publishedOn": "2021-06-11T01:42:13.482Z",
          "wordCount": 526,
          "title": "Input Augmentation Improves Constrained Beam Search for Neural Machine Translation: NTT at WAT 2021. (arXiv:2106.05450v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Tyler A. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yifan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>",
          "description": "In this paper, we detail the relationship between convolutions and\nself-attention in natural language tasks. We show that relative position\nembeddings in self-attention layers are equivalent to recently-proposed dynamic\nlightweight convolutions, and we consider multiple new ways of integrating\nconvolutions into Transformer self-attention. Specifically, we propose\ncomposite attention, which unites previous relative position embedding methods\nunder a convolutional framework. We conduct experiments by training BERT with\ncomposite attention, finding that convolutions consistently improve performance\non multiple downstream tasks, replacing absolute position embeddings. To inform\nfuture work, we present results comparing lightweight convolutions, dynamic\nconvolutions, and depthwise-separable convolutions in language model\npre-training, considering multiple injection points for convolutions in\nself-attention layers.",
          "link": "http://arxiv.org/abs/2106.05505",
          "publishedOn": "2021-06-11T01:42:13.458Z",
          "wordCount": 547,
          "title": "Convolutions and Self-Attention: Re-interpreting Relative Positions in Pre-trained Language Models. (arXiv:2106.05505v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-11T01:42:13.432Z",
          "wordCount": 611,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinnuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1\">Verena Rieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1\">Ioannis Konstas</a>",
          "description": "We present AGGGEN (pronounced 'again'), a data-to-text model which\nre-introduces two explicit sentence planning stages into neural data-to-text\nsystems: input ordering and input aggregation. In contrast to previous work\nusing sentence planning, our model is still end-to-end: AGGGEN performs\nsentence planning at the same time as generating text by learning latent\nalignments (via semantic facts) between input representation and target text.\nExperiments on the WebNLG and E2E challenge data show that by using fact-based\nalignments our approach is more interpretable, expressive, robust to noise, and\neasier to control, while retaining the advantages of end-to-end systems in\nterms of fluency. Our code is available at https://github.com/XinnuoXu/AggGen.",
          "link": "http://arxiv.org/abs/2106.05580",
          "publishedOn": "2021-06-11T01:42:13.421Z",
          "wordCount": 543,
          "title": "AGGGEN: Ordering and Aggregating while Generating. (arXiv:2106.05580v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05299",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Correia_A/0/1/0/all/0/1\">A. D. Correia</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moortgat_M/0/1/0/all/0/1\">M. Moortgat</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Stoof_H/0/1/0/all/0/1\">H. T. C. Stoof</a>",
          "description": "Grover's algorithm, a well-know quantum search algorithm, allows one to find\nthe correct item in a database, with quadratic speedup. In this paper we adapt\nGrover's algorithm to the problem of finding a correct answer to a natural\nlanguage question in English, thus contributing to the growing field of Quantum\nNatural Language Processing. Using a grammar that can be interpreted as tensor\ncontractions, each word is represented as a quantum state that serves as input\nto the quantum circuit. We here introduce a quantum measurement to contract the\nrepresentations of words, resulting in the representation of larger text\nfragments. Using this framework, a representation for the question is found\nthat contains all the possible answers in equal quantum superposition, and\nallows for the building of an oracle that can detect a correct answer, being\nagnostic to the specific question. Furthermore, we show that our construction\ncan deal with certain types of ambiguous phrases by keeping the various\ndifferent meanings in quantum superposition.",
          "link": "http://arxiv.org/abs/2106.05299",
          "publishedOn": "2021-06-11T01:42:13.402Z",
          "wordCount": 593,
          "title": "Grover's Algorithm for Question Answering. (arXiv:2106.05299v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1\">Shashank Bujimalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1\">Mahesh Subedar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1\">Omesh Tickoo</a>",
          "description": "In this paper, we study the impact of motion blur, a common quality flaw in\nreal world images, on a state-of-the-art two-stage image captioning solution,\nand notice a degradation in solution performance as blur intensity increases.\nWe investigate techniques to improve the robustness of the solution to motion\nblur using training data augmentation at each or both stages of the solution,\ni.e., object detection and captioning, and observe improved results. In\nparticular, augmenting both the stages reduces the CIDEr-D degradation for high\nmotion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to\n6.8 on Vizwiz dataset.",
          "link": "http://arxiv.org/abs/2106.05437",
          "publishedOn": "2021-06-11T01:42:13.394Z",
          "wordCount": 539,
          "title": "Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Models that top leaderboards often perform unsatisfactorily when deployed in\nreal world applications; this has necessitated rigorous and expensive\npre-deployment model testing. A hitherto unexplored facet of model performance\nis: Are our leaderboards doing equitable evaluation? In this paper, we\nintroduce a task-agnostic method to probe leaderboards by weighting samples\nbased on their `difficulty' level. We find that leaderboards can be\nadversarially attacked and top performing models may not always be the best\nmodels. We subsequently propose alternate evaluation metrics. Our experiments\non 10 models show changes in model ranking and an overall reduction in\npreviously reported performance -- thus rectifying the overestimation of AI\nsystems' capabilities. Inspired by behavioral testing principles, we further\ndevelop a prototype of a visual analytics tool that enables leaderboard\nrevamping through customization, based on an end user's focus area. This helps\nusers analyze models' strengths and weaknesses, and guides them in the\nselection of a model best suited for their application scenario. In a user\nstudy, members of various commercial product development teams, covering 5\nfocus areas, find that our prototype reduces pre-deployment development and\ntesting effort by 41% on average.",
          "link": "http://arxiv.org/abs/2106.05532",
          "publishedOn": "2021-06-11T01:42:13.322Z",
          "wordCount": 632,
          "title": "How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1\">Rabeeh Karimi Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>",
          "description": "While large-scale pretrained language models have obtained impressive results\nwhen fine-tuned on a wide variety of tasks, they still often suffer from\noverfitting in low-resource scenarios. Since such models are general-purpose\nfeature extractors, many of these features are inevitably irrelevant for a\ngiven target task. We propose to use Variational Information Bottleneck (VIB)\nto suppress irrelevant features when fine-tuning on low-resource target tasks,\nand show that our method successfully reduces overfitting. Moreover, we show\nthat our VIB model finds sentence representations that are more robust to\nbiases in natural language inference datasets, and thereby obtains better\ngeneralization to out-of-domain datasets. Evaluation on seven low-resource\ndatasets in different tasks shows that our method significantly improves\ntransfer learning in low-resource scenarios, surpassing prior work. Moreover,\nit improves generalization on 13 out of 15 out-of-domain natural language\ninference benchmarks. Our code is publicly available in\nhttps://github.com/rabeehk/vibert.",
          "link": "http://arxiv.org/abs/2106.05469",
          "publishedOn": "2021-06-11T01:42:13.296Z",
          "wordCount": 572,
          "title": "Variational Information Bottleneck for Effective Low-Resource Fine-Tuning. (arXiv:2106.05469v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lingwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1\">Xiaoyong Huai</a>",
          "description": "Emotion Recognition in Conversations (ERC) has gained increasing attention\nfor developing empathetic machines. Recently, many approaches have been devoted\nto perceiving conversational context by deep learning models. However, these\napproaches are insufficient in understanding the context due to lacking the\nability to extract and integrate emotional clues. In this work, we propose\nnovel Contextual Reasoning Networks (DialogueCRN) to fully understand the\nconversational context from a cognitive perspective. Inspired by the Cognitive\nTheory of Emotion, we design multi-turn reasoning modules to extract and\nintegrate emotional clues. The reasoning module iteratively performs an\nintuitive retrieving process and a conscious reasoning process, which imitates\nhuman unique cognitive thinking. Extensive experiments on three public\nbenchmark datasets demonstrate the effectiveness and superiority of the\nproposed model.",
          "link": "http://arxiv.org/abs/2106.01978",
          "publishedOn": "2021-06-10T22:40:40.475Z",
          "wordCount": 575,
          "title": "DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations. (arXiv:2106.01978v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chin_N/0/1/0/all/0/1\">Ng Bee Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susanto_Y/0/1/0/all/0/1\">Yosephine Susanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>",
          "description": "MICE is a corpus of emotion words in four languages which is currently\nworking progress. There are two sections to this study, Part I: Emotion word\ncorpus and Part II: Emotion word survey. In Part 1, the method of how the\nemotion data is culled for each of the four languages will be described and\nvery preliminary data will be presented. In total, we identified 3,750 emotion\nexpressions in Malay, 6,657 in Indonesian, 3,347 in Mandarin Chinese and 8,683\nin English. We are currently evaluating and double checking the corpus and\ndoing further analysis on the distribution of these emotion expressions. Part\nII Emotion word survey involved an online language survey which collected\ninformation on how speakers assigned the emotion words into basic emotion\ncategories, the rating for valence and intensity as well as biographical\ninformation of all the respondents.",
          "link": "http://arxiv.org/abs/2106.04831",
          "publishedOn": "2021-06-10T01:56:49.602Z",
          "wordCount": 571,
          "title": "MICE: A Crosslinguistic Emotion Corpus in Malay, Indonesian, Chinese and English. (arXiv:2106.04831v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1811.00606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Most neural Information Retrieval (Neu-IR) models derive query-to-document\nranking scores based on term-level matching. Inspired by TileBars, a classical\nterm distribution visualization method, in this paper, we propose a novel\nNeu-IR model that handles query-to-document matching at the subtopic and higher\nlevels. Our system first splits the documents into topical segments,\n\"visualizes\" the matchings between the query and the segments, and then feeds\nan interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final\nranking scores. DeepTileBars models the relevance signals occurring at\ndifferent granularities in a document's topic hierarchy. It better captures the\ndiscourse structure of a document and thus the matching patterns. Although its\ndesign and implementation are light-weight, DeepTileBars outperforms other\nstate-of-the-art Neu-IR models on benchmark datasets including the Text\nREtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.",
          "link": "http://arxiv.org/abs/1811.00606",
          "publishedOn": "2021-06-10T01:56:49.544Z",
          "wordCount": 612,
          "title": "DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohiuddin_T/0/1/0/all/0/1\">Tasnim Mohiuddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "The success of Neural Machine Translation (NMT) largely depends on the\navailability of large bitext training corpora. Due to the lack of such large\ncorpora in low-resource language pairs, NMT systems often exhibit poor\nperformance. Extra relevant monolingual data often helps, but acquiring it\ncould be quite expensive, especially for low-resource languages. Moreover,\ndomain mismatch between bitext (train/test) and monolingual data might degrade\nthe performance. To alleviate such issues, we propose AUGVIC, a novel data\naugmentation framework for low-resource NMT which exploits the vicinal samples\nof the given bitext without using any extra monolingual data explicitly. It can\ndiversify the in-domain bitext data with finer level control. Through extensive\nexperiments on four low-resource language pairs comprising data from different\ndomains, we have shown that our method is comparable to the traditional\nback-translation that uses extra in-domain monolingual data. When we combine\nthe synthetic parallel data generated from AUGVIC with the ones from the extra\nmonolingual data, we achieve further improvements. We show that AUGVIC helps to\nattenuate the discrepancies between relevant and distant-domain monolingual\ndata in traditional back-translation. To understand the contributions of\ndifferent components of AUGVIC, we perform an in-depth framework analysis.",
          "link": "http://arxiv.org/abs/2106.05141",
          "publishedOn": "2021-06-10T01:56:49.511Z",
          "wordCount": 619,
          "title": "AUGVIC: Exploiting BiText Vicinity for Low-Resource NMT. (arXiv:2106.05141v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shuoran Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>",
          "description": "Graph convolutional network (GCN) has become popular in various natural\nlanguage processing (NLP) tasks with its superiority in long-term and\nnon-consecutive word interactions. However, existing single-hop graph reasoning\nin GCN may miss some important non-consecutive dependencies. In this study, we\ndefine the spectral graph convolutional network with the high-order dynamic\nChebyshev approximation (HDGCN), which augments the multi-hop graph reasoning\nby fusing messages aggregated from direct and long-term dependencies into one\nconvolutional layer. To alleviate the over-smoothing in high-order Chebyshev\napproximation, a multi-vote-based cross-attention (MVCAttn) with linear\ncomputation complexity is also proposed. The empirical results on four\ntransductive and inductive NLP tasks and the ablation study verify the efficacy\nof the proposed model. Our source code is available at\nhttps://github.com/MathIsAll/HDGCN-pytorch.",
          "link": "http://arxiv.org/abs/2106.05221",
          "publishedOn": "2021-06-10T01:56:49.460Z",
          "wordCount": 559,
          "title": "Multi-hop Graph Convolutional Network with High-order Chebyshev Approximation for Text Reasoning. (arXiv:2106.05221v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vries_W/0/1/0/all/0/1\">Wietse de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1\">Malvina Nissim</a>",
          "description": "Large generative language models have been very successful for English, but\nother languages lag behind, in part due to data and computational limitations.\nWe propose a method that may overcome these problems by adapting existing\npre-trained models to new languages. Specifically, we describe the adaptation\nof English GPT-2 to Italian and Dutch by retraining lexical embeddings without\ntuning the Transformer layers. As a result, we obtain lexical embeddings for\nItalian and Dutch that are aligned with the original English lexical\nembeddings. Additionally, we scale up complexity by transforming relearned\nlexical embeddings of GPT-2 small to the GPT-2 medium embedding space. This\nmethod minimises the amount of training and prevents losing information during\nadaptation that was learned by GPT-2. English GPT-2 models with relearned\nlexical embeddings can generate realistic sentences in Italian and Dutch.\nThough on average these sentences are still identifiable as artificial by\nhumans, they are assessed on par with sentences generated by a GPT-2 model\nfully trained from scratch.",
          "link": "http://arxiv.org/abs/2012.05628",
          "publishedOn": "2021-06-10T01:56:49.440Z",
          "wordCount": 642,
          "title": "As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages. (arXiv:2012.05628v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tamali Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>",
          "description": "Recent advances in Unsupervised Neural Machine Translation (UNMT) have\nminimized the gap between supervised and unsupervised machine translation\nperformance for closely related language pairs. However, the situation is very\ndifferent for distant language pairs. Lack of lexical overlap and low syntactic\nsimilarities such as between English and Indo-Aryan languages leads to poor\ntranslation quality in existing UNMT systems. In this paper, we show that\ninitializing the embedding layer of UNMT models with cross-lingual embeddings\nshows significant improvements in BLEU score over existing approaches with\nembeddings randomly initialized. Further, static embeddings (freezing the\nembedding layer weights) lead to better gains compared to updating the\nembedding layer weights during training (non-static). We experimented using\nMasked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT\napproaches for three distant language pairs. The proposed cross-lingual\nembedding initialization yields BLEU score improvement of as much as ten times\nover the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our\nanalysis shows the importance of cross-lingual embedding, comparisons between\napproaches, and the scope of improvements in these systems.",
          "link": "http://arxiv.org/abs/2106.04995",
          "publishedOn": "2021-06-10T01:56:49.332Z",
          "wordCount": 613,
          "title": "Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazoom_M/0/1/0/all/0/1\">Moshe Hazoom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_V/0/1/0/all/0/1\">Vibhor Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogin_B/0/1/0/all/0/1\">Ben Bogin</a>",
          "description": "Most available semantic parsing datasets, comprising of pairs of natural\nutterances and logical forms, were collected solely for the purpose of training\nand evaluation of natural language understanding systems. As a result, they do\nnot contain any of the richness and variety of natural-occurring utterances,\nwhere humans ask about data they need or are curious about. In this work, we\nrelease SEDE, a dataset with 12,023 pairs of utterances and SQL queries\ncollected from real usage on the Stack Exchange website. We show that these\npairs contain a variety of real-world challenges which were rarely reflected so\nfar in any other semantic parsing dataset, propose an evaluation metric based\non comparison of partial query clauses that is more suitable for real-world\nqueries, and conduct experiments with strong baselines, showing a large gap\nbetween the performance on SEDE compared to other common datasets.",
          "link": "http://arxiv.org/abs/2106.05006",
          "publishedOn": "2021-06-10T01:56:48.699Z",
          "wordCount": null,
          "title": "Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data. (arXiv:2106.05006v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>",
          "description": "End-to-end simultaneous speech translation (SST), which directly translates\nspeech in one language into text in another language in real-time, is useful in\nmany scenarios but has not been fully investigated. In this work, we propose\nRealTranS, an end-to-end model for SST. To bridge the modality gap between\nspeech and text, RealTranS gradually downsamples the input speech with\ninterleaved convolution and unidirectional Transformer layers for acoustic\nmodeling, and then maps speech features into text space with a\nweighted-shrinking operation and a semantic encoder. Besides, to improve the\nmodel performance in simultaneous scenarios, we propose a blank penalty to\nenhance the shrinking quality and a Wait-K-Stride-N strategy to allow local\nreranking during decoding. Experiments on public and widely-used datasets show\nthat RealTranS with the Wait-K-Stride-N strategy outperforms prior end-to-end\nmodels as well as cascaded models in diverse latency settings.",
          "link": "http://arxiv.org/abs/2106.04833",
          "publishedOn": "2021-06-10T01:56:48.084Z",
          "wordCount": 578,
          "title": "RealTranS: End-to-End Simultaneous Speech Translation with Convolutional Weighted-Shrinking Transformer. (arXiv:2106.04833v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pylkkonen_J/0/1/0/all/0/1\">Janne Pylkk&#xf6;nen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ukkonen_A/0/1/0/all/0/1\">Antti Ukkonen</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Kilpikoski_J/0/1/0/all/0/1\">Juho Kilpikoski</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tamminen_S/0/1/0/all/0/1\">Samu Tamminen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Heikinheimo_H/0/1/0/all/0/1\">Hannes Heikinheimo</a> (1) ((1) Speechly, (2) Department of Computer Science, University of Helsinki, Finland)",
          "description": "Adaption of end-to-end speech recognition systems to new tasks is known to be\nchallenging. A number of solutions have been proposed which apply external\nlanguage models with various fusion methods, possibly with a combination of\ntwo-pass decoding. Also TTS systems have been used to generate adaptation data\nfor the end-to-end models. In this paper we show that RNN-transducer models can\nbe effectively adapted to new domains using only small amounts of textual data.\nBy taking advantage of model's inherent structure, where the prediction network\nis interpreted as a language model, we can apply fast adaptation to the model.\nAdapting the model avoids the need for complicated decoding time fusions and\nexternal language models. Using appropriate regularization, the prediction\nnetwork can be adapted to new domains while still retaining good generalization\ncapabilities. We show with multiple ASR evaluation tasks how this method can\nprovide relative gains of 10-45% in target task WER. We also share insights how\nRNN-transducer prediction network performs as a language model.",
          "link": "http://arxiv.org/abs/2104.11127",
          "publishedOn": "2021-06-10T01:56:47.204Z",
          "wordCount": 656,
          "title": "Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network. (arXiv:2104.11127v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lingwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xuehai Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaodan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>",
          "description": "Document-level Sentiment Analysis (DSA) is more challenging due to vague\nsemantic links and complicate sentiment information. Recent works have been\ndevoted to leveraging text summarization and have achieved promising results.\nHowever, these summarization-based methods did not take full advantage of the\nsummary including ignoring the inherent interactions between the summary and\ndocument. As a result, they limited the representation to express major points\nin the document, which is highly indicative of the key sentiment. In this\npaper, we study how to effectively generate a discriminative representation\nwith explicit subject patterns and sentiment contexts for DSA. A Hierarchical\nInteraction Networks (HIN) is proposed to explore bidirectional interactions\nbetween the summary and document at multiple granularities and learn\nsubject-oriented document representations for sentiment classification.\nFurthermore, we design a Sentiment-based Rethinking mechanism (SR) by refining\nthe HIN with sentiment label information to learn a more sentiment-aware\ndocument representation. We extensively evaluate our proposed models on three\npublic datasets. The experimental results consistently demonstrate the\neffectiveness of our proposed models and show that HIN-SR outperforms various\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2007.08445",
          "publishedOn": "2021-06-10T01:56:46.022Z",
          "wordCount": 658,
          "title": "Hierarchical Interaction Networks with Rethinking Mechanism for Document-level Sentiment Analysis. (arXiv:2007.08445v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dao_M/0/1/0/all/0/1\">Mai Hoang Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thinh Hung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat Quoc Nguyen</a>",
          "description": "Intent detection and slot filling are important tasks in spoken and natural\nlanguage understanding. However, Vietnamese is a low-resource language in these\nresearch topics. In this paper, we present the first public intent detection\nand slot filling dataset for Vietnamese. In addition, we also propose a joint\nmodel for intent detection and slot filling, that extends the recent\nstate-of-the-art JointBERT+CRF model with an intent-slot attention layer to\nexplicitly incorporate intent context information into slot filling via \"soft\"\nintent label embedding. Experimental results on our Vietnamese dataset show\nthat our proposed model significantly outperforms JointBERT+CRF. We publicly\nrelease our dataset and the implementation of our model at:\nhttps://github.com/VinAIResearch/JointIDSF",
          "link": "http://arxiv.org/abs/2104.02021",
          "publishedOn": "2021-06-10T01:56:46.005Z",
          "wordCount": 579,
          "title": "Intent Detection and Slot Filling for Vietnamese. (arXiv:2104.02021v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To address these challenges, we\npropose the use of Deep Learning and Word Embeddings for identifying sixteen\nmorbidity types within textual descriptions of clinical records. For this\npurpose, we have used a Deep Learning model based on Bidirectional Long-Short\nTerm Memory (LSTM) layers which can exploit state-of-the-art vector\nrepresentations of data such as Word Embeddings. We have employed pre-trained\nWord Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained\non the target domain. Furthermore, we have compared the performances of the\ndeep learning approaches against the traditional tf-idf using Support Vector\nMachine and Multilayer perceptron (our baselines). From the obtained results it\nseems that the latter outperforms the combination of Deep Learning approaches\nusing any word embeddings. Our preliminary results indicate that there are\nspecific features that make the dataset biased in favour of traditional machine\nlearning approaches.",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-06-10T01:56:45.999Z",
          "wordCount": 711,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukagoshi_H/0/1/0/all/0/1\">Hayato Tsukagoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasano_R/0/1/0/all/0/1\">Ryohei Sasano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Koichi Takeda</a>",
          "description": "Sentence embedding methods using natural language inference (NLI) datasets\nhave been successfully applied to various tasks. However, these methods are\nonly available for limited languages due to relying heavily on the large NLI\ndatasets. In this paper, we propose DefSent, a sentence embedding method that\nuses definition sentences from a word dictionary, which performs comparably on\nunsupervised semantics textual similarity (STS) tasks and slightly better on\nSentEval tasks than conventional methods. Since dictionaries are available for\nmany languages, DefSent is more broadly applicable than methods using NLI\ndatasets without constructing additional datasets. We demonstrate that DefSent\nperforms comparably on unsupervised semantics textual similarity (STS) tasks\nand slightly better on SentEval tasks to the methods using large NLI datasets.\nOur code is publicly available at https://github.com/hpprc/defsent .",
          "link": "http://arxiv.org/abs/2105.04339",
          "publishedOn": "2021-06-10T01:56:45.987Z",
          "wordCount": 591,
          "title": "DefSent: Sentence Embeddings using Definition Sentences. (arXiv:2105.04339v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chun Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "The choice of token vocabulary affects the performance of machine\ntranslation. This paper aims to figure out what is a good vocabulary and\nwhether one can find the optimal vocabulary without trial training. To answer\nthese questions, we first provide an alternative understanding of the role of\nvocabulary from the perspective of information theory. Motivated by this, we\nformulate the quest of vocabularization -- finding the best token dictionary\nwith a proper size -- as an optimal transport (OT) problem.We We propose VOLT,\na simple and efficient solution without trial training. Empirical results show\nthat VOLT outperforms widely-used vocabularies in diverse scenarios, including\nWMT-14 English-German and TED's 52 translation directions. For example, VOLT\nachieves 70% vocabulary size reduction and 0.5 BLEU gain on English-German\ntranslation. Also, compared to BPE-search, VOLT reduces the search time from\n384 GPU hours to 30 GPU hours on English-German translation. Codes are\navailable at https://github.com/Jingjing-NLP/VOLT .",
          "link": "http://arxiv.org/abs/2012.15671",
          "publishedOn": "2021-06-10T01:56:45.981Z",
          "wordCount": 615,
          "title": "Vocabulary Learning via Optimal Transport for Machine Translation. (arXiv:2012.15671v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>",
          "description": "How can a text corpus stored in a customer relationship management (CRM)\ndatabase be used for data mining and segmentation? In order to answer this\nquestion we inherited the state of the art methods commonly used in natural\nlanguage processing (NLP) literature, such as word embeddings, and deep\nlearning literature, such as recurrent neural networks (RNN). We used the text\nnotes from a CRM system which are taken by customer representatives of an\ninternet ads consultancy agency between years 2009 and 2020. We trained word\nembeddings by using the corresponding text corpus and showed that these word\nembeddings can not only be used directly for data mining but also be used in\nRNN architectures, which are deep learning frameworks built with long short\nterm memory (LSTM) units, for more comprehensive segmentation objectives. The\nresults prove that structured text data in a CRM can be used to mine out very\nvaluable information and any CRM can be equipped with useful NLP features once\nthe problem definitions are properly built and the solution methods are\nconveniently implemented.",
          "link": "http://arxiv.org/abs/2106.05160",
          "publishedOn": "2021-06-10T01:56:45.974Z",
          "wordCount": 638,
          "title": "Case Studies on using Natural Language Processing Techniques in Customer Relationship Management Software. (arXiv:2106.05160v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Carolin Lawrence</a>",
          "description": "Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.",
          "link": "http://arxiv.org/abs/2011.02511",
          "publishedOn": "2021-06-10T01:56:45.944Z",
          "wordCount": 577,
          "title": "Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1\">Berrak Sisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>",
          "description": "Emotional voice conversion (EVC) aims to change the emotional state of an\nutterance while preserving the linguistic content and speaker identity. In this\npaper, we propose a novel 2-stage training strategy for sequence-to-sequence\nemotional voice conversion with a limited amount of emotional speech data. We\nnote that the proposed EVC framework leverages text-to-speech (TTS) as they\nshare a common goal that is to generate high-quality expressive voice. In stage\n1, we perform style initialization with a multi-speaker TTS corpus, to\ndisentangle speaking style and linguistic content. In stage 2, we perform\nemotion training with a limited amount of emotional speech data, to learn how\nto disentangle emotional style and linguistic information from the speech. The\nproposed framework can perform both spectrum and prosody conversion and\nachieves significant improvement over the state-of-the-art baselines in both\nobjective and subjective evaluation.",
          "link": "http://arxiv.org/abs/2103.16809",
          "publishedOn": "2021-06-10T01:56:45.912Z",
          "wordCount": 598,
          "title": "Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-stage Sequence-to-Sequence Training. (arXiv:2103.16809v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Katsuma Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1\">Soh Ohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1\">Kohei Nakajima</a>",
          "description": "Language is an outcome of our complex and dynamic human-interactions and the\ntechnique of natural language processing (NLP) is hence built on human\nlinguistic activities. Bidirectional Encoder Representations from Transformers\n(BERT) has recently gained its popularity by establishing the state-of-the-art\nscores in several NLP benchmarks. A Lite BERT (ALBERT) is literally\ncharacterized as a lightweight version of BERT, in which the number of BERT\nparameters is reduced by repeatedly applying the same neural network called\nTransformer's encoder layer. By pre-training the parameters with a massive\namount of natural language data, ALBERT can convert input sentences into\nversatile high-dimensional vectors potentially capable of solving multiple NLP\ntasks. In that sense, ALBERT can be regarded as a well-designed\nhigh-dimensional dynamical system whose operator is the Transformer's encoder,\nand essential structures of human language are thus expected to be encapsulated\nin its dynamics. In this study, we investigated the embedded properties of\nALBERT to reveal how NLP tasks are effectively solved by exploiting its\ndynamics. We thereby aimed to explore the nature of human language from the\ndynamical expressions of the NLP model. Our short-term analysis clarified that\nthe pre-trained model stably yields trajectories with higher dimensionality,\nwhich would enhance the expressive capacity required for NLP tasks. Also, our\nlong-term analysis revealed that ALBERT intrinsically shows transient chaos, a\ntypical nonlinear phenomenon showing chaotic dynamics only in its transient,\nand the pre-trained ALBERT model tends to produce the chaotic trajectory for a\nsignificantly longer time period compared to a randomly-initialized one. Our\nresults imply that local chaoticity would contribute to improving NLP\nperformance, uncovering a novel aspect in the role of chaotic dynamics in human\nlanguage behaviors.",
          "link": "http://arxiv.org/abs/2106.03181",
          "publishedOn": "2021-06-10T01:56:45.906Z",
          "wordCount": 731,
          "title": "Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_H/0/1/0/all/0/1\">Hrishikesh Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Many task-oriented dialogue systems use deep reinforcement learning (DRL) to\nlearn policies that respond to the user appropriately and complete the tasks\nsuccessfully. Training DRL agents with diverse dialogue trajectories prepare\nthem well for rare user requests and unseen situations. One effective\ndiversification method is to let the agent interact with a diverse set of\nlearned user models. However, trajectories created by these artificial user\nmodels may contain generation errors, which can quickly propagate into the\nagent's policy. It is thus important to control the quality of the\ndiversification and resist the noise. In this paper, we propose a novel\ndialogue diversification method for task-oriented dialogue systems trained in\nsimulators. Our method, Intermittent Short Extension Ensemble (I-SEE),\nconstrains the intensity to interact with an ensemble of diverse user models\nand effectively controls the quality of the diversification. Evaluations on the\nMultiwoz dataset show that I-SEE successfully boosts the performance of several\nstate-of-the-art DRL dialogue agents.",
          "link": "http://arxiv.org/abs/2106.00891",
          "publishedOn": "2021-06-10T01:56:45.889Z",
          "wordCount": 605,
          "title": "High-Quality Diversification for Task-Oriented Dialogue Systems. (arXiv:2106.00891v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chao Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>",
          "description": "End-to-end spoken language understanding (SLU) has recently attracted\nincreasing interest. Compared to the conventional tandem-based approach that\ncombines speech recognition and language understanding as separate modules, the\nnew approach extracts users' intentions directly from the speech signals,\nresulting in joint optimization and low latency. Such an approach, however, is\ntypically designed to process one intention at a time, which leads users to\ntake multiple rounds to fulfill their requirements while interacting with a\ndialogue system. In this paper, we propose a streaming end-to-end framework\nthat can process multiple intentions in an online and incremental way. The\nbackbone of our framework is a unidirectional RNN trained with the\nconnectionist temporal classification (CTC) criterion. By this design, an\nintention can be identified when sufficient evidence has been accumulated, and\nmultiple intentions can be identified sequentially. We evaluate our solution on\nthe Fluent Speech Commands (FSC) dataset and the intent detection accuracy is\nabout 97 % on all multi-intent settings. This result is comparable to the\nperformance of the state-of-the-art non-streaming models, but is achieved in an\nonline and incremental way. We also employ our model to a keyword spotting task\nusing the Google Speech Commands dataset and the results are also highly\npromising.",
          "link": "http://arxiv.org/abs/2105.10042",
          "publishedOn": "2021-06-10T01:56:45.884Z",
          "wordCount": 677,
          "title": "A Streaming End-to-End Framework For Spoken Language Understanding. (arXiv:2105.10042v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.",
          "link": "http://arxiv.org/abs/2012.14210",
          "publishedOn": "2021-06-10T01:56:45.826Z",
          "wordCount": 565,
          "title": "The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Thomas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krichene_S/0/1/0/all/0/1\">Syrine Krichene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1\">Julian Martin Eisenschlos</a>",
          "description": "Recent advances in open-domain QA have led to strong models based on dense\nretrieval, but only focused on retrieving textual passages. In this work, we\ntackle open-domain QA over tables for the first time, and show that retrieval\ncan be improved by a retriever designed to handle tabular context. We present\nan effective pre-training procedure for our retriever and improve retrieval\nquality with mined hard negatives. As relevant datasets are missing, we extract\na subset of Natural Questions (Kwiatkowski et al., 2019) into a Table QA\ndataset. We find that our retriever improves retrieval results from 72.0 to\n81.1 recall@10 and end-to-end QA results from 33.8 to 37.7 exact match, over a\nBERT based retriever.",
          "link": "http://arxiv.org/abs/2103.12011",
          "publishedOn": "2021-06-10T01:56:45.803Z",
          "wordCount": 577,
          "title": "Open Domain Question Answering over Tables via Dense Retrieval. (arXiv:2103.12011v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karita_S/0/1/0/all/0/1\">Shigeki Karita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubo_Y/0/1/0/all/0/1\">Yotaro Kubo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Adriaan Unico Bacchiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_L/0/1/0/all/0/1\">Llion Jones</a>",
          "description": "End-to-end (E2E) modeling is advantageous for automatic speech recognition\n(ASR) especially for Japanese since word-based tokenization of Japanese is not\ntrivial, and E2E modeling is able to model character sequences directly. This\npaper focuses on the latest E2E modeling techniques, and investigates their\nperformances on character-based Japanese ASR by conducting comparative\nexperiments. The results are analyzed and discussed in order to understand the\nrelative advantages of long short-term memory (LSTM), and Conformer models in\ncombination with connectionist temporal classification, transducer, and\nattention-based loss functions. Furthermore, the paper investigates on\neffectivity of the recent training techniques such as data augmentation\n(SpecAugment), variational noise injection, and exponential moving average. The\nbest configuration found in the paper achieved the state-of-the-art character\nerror rates of 4.1%, 3.2%, and 3.5% for Corpus of Spontaneous Japanese (CSJ)\neval1, eval2, and eval3 tasks, respectively. The system is also shown to be\ncomputationally efficient thanks to the efficiency of Conformer transducers.",
          "link": "http://arxiv.org/abs/2106.05111",
          "publishedOn": "2021-06-10T01:56:45.785Z",
          "wordCount": 607,
          "title": "A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition. (arXiv:2106.05111v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1\">Caglar Demir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1\">Axel-Cyrille Ngonga Ngomo</a>",
          "description": "In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.",
          "link": "http://arxiv.org/abs/2008.03130",
          "publishedOn": "2021-06-10T01:56:45.779Z",
          "wordCount": 587,
          "title": "Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mingzhu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moosavi_N/0/1/0/all/0/1\">Nafise Sadat Moosavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Coreference resolution is essential for natural language understanding and\nhas been long studied in NLP. In recent years, as the format of Question\nAnswering (QA) became a standard for machine reading comprehension (MRC), there\nhave been data collection efforts, e.g., Dasigi et al. (2019), that attempt to\nevaluate the ability of MRC models to reason about coreference. However, as we\nshow, coreference reasoning in MRC is a greater challenge than earlier thought;\nMRC datasets do not reflect the natural distribution and, consequently, the\nchallenges of coreference reasoning. Specifically, success on these datasets\ndoes not reflect a model's proficiency in coreference reasoning. We propose a\nmethodology for creating MRC datasets that better reflect the challenges of\ncoreference reasoning and use it to create a sample evaluation set. The results\non our dataset show that state-of-the-art models still struggle with these\nphenomena. Furthermore, we develop an effective way to use naturally occurring\ncoreference phenomena from existing coreference resolution datasets when\ntraining MRC models. This allows us to show an improvement in the coreference\nreasoning abilities of state-of-the-art models. The code and the resulting\ndataset are available at https://github.com/UKPLab/coref-reasoning-in-qa.",
          "link": "http://arxiv.org/abs/2012.15573",
          "publishedOn": "2021-06-10T01:56:45.772Z",
          "wordCount": 646,
          "title": "Coreference Reasoning in Machine Reading Comprehension. (arXiv:2012.15573v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1\">Rohit Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara Lee Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "Most existing video-and-language (VidL) research focuses on a single dataset,\nor multiple datasets of a single task. In reality, a truly useful VidL system\nis expected to be easily generalizable to diverse tasks, domains, and datasets.\nTo facilitate the evaluation of such systems, we introduce Video-And-Language\nUnderstanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets\nover 3 popular tasks: (i) text-to-video retrieval; (ii) video question\nanswering; and (iii) video captioning. VALUE benchmark aims to cover a broad\nrange of video genres, video lengths, data volumes, and task difficulty levels.\nRather than focusing on single-channel videos with visual information only,\nVALUE promotes models that leverage information from both video frames and\ntheir associated subtitles, as well as models that share knowledge across\nmultiple tasks. We evaluate various baseline methods with and without\nlarge-scale VidL pre-training, and systematically investigate the impact of\nvideo input channels, fusion methods, and different video representations. We\nalso study the transferability between tasks, and conduct multi-task learning\nunder different settings. The significant gap between our best model and human\nperformance calls for future study for advanced VidL models. VALUE is available\nat https://value-leaderboard.github.io/.",
          "link": "http://arxiv.org/abs/2106.04632",
          "publishedOn": "2021-06-10T01:56:45.767Z",
          "wordCount": 656,
          "title": "VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xinjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.",
          "link": "http://arxiv.org/abs/2106.05251",
          "publishedOn": "2021-06-10T01:56:45.755Z",
          "wordCount": 596,
          "title": "Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1\">Ananya Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1\">Martha Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "Recent advances in natural language processing (NLP) have the ability to\ntransform how classroom learning takes place. Combined with the increasing\nintegration of technology in today's classrooms, NLP systems leveraging\nquestion answering and dialog processing techniques can serve as private tutors\nor participants in classroom discussions to increase student engagement and\nlearning. To progress towards this goal, we use the classroom discourse\nframework of academically productive talk (APT) to learn strategies that make\nfor the best learning experience. In this paper, we introduce a new task,\ncalled future talk move prediction (FTMP): it consists of predicting the next\ntalk move -- an utterance strategy from APT -- given a conversation history\nwith its corresponding talk moves. We further introduce a neural network model\nfor this task, which outperforms multiple baselines by a large margin. Finally,\nwe compare our model's performance on FTMP to human performance and show\nseveral similarities between the two.",
          "link": "http://arxiv.org/abs/2106.05249",
          "publishedOn": "2021-06-10T01:56:45.738Z",
          "wordCount": 589,
          "title": "What Would a Teacher Do? Predicting Future Talk Moves. (arXiv:2106.05249v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "Zero-shot intent detection (ZSID) aims to deal with the continuously emerging\nintents without annotated training data. However, existing ZSID systems suffer\nfrom two limitations: 1) They are not good at modeling the relationship between\nseen and unseen intents. 2) They cannot effectively recognize unseen intents\nunder the generalized intent detection (GZSID) setting. A critical problem\nbehind these limitations is that the representations of unseen intents cannot\nbe learned in the training stage. To address this problem, we propose a novel\nframework that utilizes unseen class labels to learn Class-Transductive Intent\nRepresentations (CTIR). Specifically, we allow the model to predict unseen\nintents during training, with the corresponding label names serving as input\nutterances. On this basis, we introduce a multi-task learning objective, which\nencourages the model to learn the distinctions among intents, and a similarity\nscorer, which estimates the connections among intents more accurately. CTIR is\neasy to implement and can be integrated with existing methods. Experiments on\ntwo real-world datasets show that CTIR brings considerable improvement to the\nbaseline systems.",
          "link": "http://arxiv.org/abs/2012.01721",
          "publishedOn": "2021-06-10T01:56:45.732Z",
          "wordCount": 636,
          "title": "Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1\">Narjes Nikzad-Khasmakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1\">Meysam Asgari-Chenaghlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1\">Mohammad-Ali Balafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1\">Ali-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1\">Taymaz Rahkar-Farshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Majid Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1\">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1\">Elnaz Zafarani-Moattar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar-Khadivi</a>",
          "description": "Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n\nMethods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n\nResults: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n\nConclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.",
          "link": "http://arxiv.org/abs/2106.04939",
          "publishedOn": "2021-06-10T01:56:45.726Z",
          "wordCount": 685,
          "title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1\">Noam Wies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1\">Daniel Jannai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>",
          "description": "After their successful debut in natural language processing, Transformer\narchitectures are now becoming the de-facto standard in many domains. An\nobstacle for their deployment over new modalities is the architectural\nconfiguration: the optimal depth-to-width ratio has been shown to dramatically\nvary across data types (e.g., $10$x larger over images than over language). We\ntheoretically predict the existence of an embedding rank bottleneck that limits\nthe contribution of self-attention width to the Transformer expressivity. We\nthus directly tie the input vocabulary size and rank to the optimal\ndepth-to-width ratio, since a small vocabulary size or rank dictates an added\nadvantage of depth over width. We empirically demonstrate the existence of this\nbottleneck and its implications on the depth-to-width interplay of Transformer\narchitectures, linking the architecture variability across domains to the often\nglossed-over usage of different vocabulary sizes or embedding ranks in\ndifferent domains. As an additional benefit, our rank bottlenecking framework\nallows us to identify size redundancies of $25\\%-50\\%$ in leading NLP models\nsuch as ALBERT and T5.",
          "link": "http://arxiv.org/abs/2105.03928",
          "publishedOn": "2021-06-10T01:56:45.720Z",
          "wordCount": 632,
          "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujel_K/0/1/0/all/0/1\">Kamil Bujel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1\">Helen Yannakoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rei_M/0/1/0/all/0/1\">Marek Rei</a>",
          "description": "We investigate how sentence-level transformers can be modified into effective\nsequence labelers at the token level without any direct supervision. Existing\napproaches to zero-shot sequence labeling do not perform well when applied on\ntransformer-based architectures. As transformers contain multiple layers of\nmulti-head self-attention, information in the sentence gets distributed between\nmany tokens, negatively affecting zero-shot token-level performance. We find\nthat a soft attention module which explicitly encourages sharpness of attention\nweights can significantly outperform existing methods.",
          "link": "http://arxiv.org/abs/2103.14465",
          "publishedOn": "2021-06-10T01:56:45.713Z",
          "wordCount": 529,
          "title": "Zero-shot Sequence Labeling for Transformer-based Sentence Classifiers. (arXiv:2103.14465v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Demi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>",
          "description": "While task-specific finetuning of pretrained networks has led to significant\nempirical advances in NLP, the large size of networks makes finetuning\ndifficult to deploy in multi-task, memory-constrained settings. We propose diff\npruning as a simple approach to enable parameter-efficient transfer learning\nwithin the pretrain-finetune framework. This approach views finetuning as\nlearning a task-specific diff vector that is applied on top of the pretrained\nparameter vector, which remains fixed and is shared across different tasks. The\ndiff vector is adaptively pruned during training with a differentiable\napproximation to the L0-norm penalty to encourage sparsity. Diff pruning\nbecomes parameter-efficient as the number of tasks increases, as it requires\nstoring only the nonzero positions and weights of the diff vector for each\ntask, while the cost of storing the shared pretrained model remains constant.\nIt further does not require access to all tasks during training, which makes it\nattractive in settings where tasks arrive in stream or the set of tasks is\nunknown. We find that models finetuned with diff pruning can match the\nperformance of fully finetuned baselines on the GLUE benchmark while only\nmodifying 0.5% of the pretrained model's parameters per task.",
          "link": "http://arxiv.org/abs/2012.07463",
          "publishedOn": "2021-06-10T01:56:45.695Z",
          "wordCount": 647,
          "title": "Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yinpeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>",
          "description": "Recently, pre-training multilingual language models has shown great potential\nin learning multilingual representation, a crucial topic of natural language\nprocessing. Prior works generally use a single mixed attention (MA) module,\nfollowing TLM (Conneau and Lample, 2019), for attending to intra-lingual and\ncross-lingual contexts equivalently and simultaneously. In this paper, we\npropose a network named decomposed attention (DA) as a replacement of MA. The\nDA consists of an intra-lingual attention (IA) and a cross-lingual attention\n(CA), which model intralingual and cross-lingual supervisions respectively. In\naddition, we introduce a language-adaptive re-weighting strategy during\ntraining to further boost the model's performance. Experiments on various\ncross-lingual natural language understanding (NLU) tasks show that the proposed\narchitecture and learning strategy significantly improve the model's\ncross-lingual transferability.",
          "link": "http://arxiv.org/abs/2106.05166",
          "publishedOn": "2021-06-10T01:56:45.650Z",
          "wordCount": 553,
          "title": "Learning Multilingual Representation for Natural Language Understanding with Enhanced Cross-Lingual Supervision. (arXiv:2106.05166v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.08694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1\">Kaustubh D. Dhole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>",
          "description": "Question Generation (QG) is fundamentally a simple syntactic transformation;\nhowever, many aspects of semantics influence what questions are good to form.\nWe implement this observation by developing Syn-QG, a set of transparent\nsyntactic rules leveraging universal dependencies, shallow semantic parsing,\nlexical resources, and custom rules which transform declarative sentences into\nquestion-answer pairs. We utilize PropBank argument descriptions and VerbNet\nstate predicates to incorporate shallow semantic content, which helps generate\nquestions of a descriptive nature and produce inferential and semantically\nricher questions than existing systems. In order to improve syntactic fluency\nand eliminate grammatically incorrect questions, we employ back-translation\nover the output of these syntactic rules. A set of crowd-sourced evaluations\nshows that our system can generate a larger number of highly grammatical and\nrelevant questions than previous QG systems and that back-translation\ndrastically improves grammaticality at a slight cost of generating irrelevant\nquestions.",
          "link": "http://arxiv.org/abs/2004.08694",
          "publishedOn": "2021-06-10T01:56:45.642Z",
          "wordCount": 639,
          "title": "Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation. (arXiv:2004.08694v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1\">Sara Meftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1\">Nasredine Semmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1\">Youssef Tamaazousti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1\">Hassane Essafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1\">Fatiha Sadat</a>",
          "description": "Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.",
          "link": "http://arxiv.org/abs/2106.04935",
          "publishedOn": "2021-06-10T01:56:45.636Z",
          "wordCount": 657,
          "title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levy_S/0/1/0/all/0/1\">Sharon Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "The adoption of natural language generation (NLG) models can leave\nindividuals vulnerable to the generation of harmful information memorized by\nthe models, such as conspiracy theories. While previous studies examine\nconspiracy theories in the context of social media, they have not evaluated\ntheir presence in the new space of generative language models. In this work, we\ninvestigate the capability of language models to generate conspiracy theory\ntext. Specifically, we aim to answer: can we test pretrained generative\nlanguage models for the memorization and elicitation of conspiracy theories\nwithout access to the model's training data? We highlight the difficulties of\nthis task and discuss it in the context of memorization, generalization, and\nhallucination. Utilizing a new dataset consisting of conspiracy theory topics\nand machine-generated conspiracy theories helps us discover that many\nconspiracy theories are deeply rooted in the pretrained language models. Our\nexperiments demonstrate a relationship between model parameters such as size\nand temperature and their propensity to generate conspiracy theory text. These\nresults indicate the need for a more thorough review of NLG applications before\nrelease and an in-depth discussion of the drawbacks of memorization in\ngenerative language models.",
          "link": "http://arxiv.org/abs/2101.00379",
          "publishedOn": "2021-06-10T01:56:45.630Z",
          "wordCount": 660,
          "title": "Investigating Memorization of Conspiracy Theories in Text Generation. (arXiv:2101.00379v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose mRASP2, a\ntraining method to obtain a single unified multilingual translation model.\nmRASP2 is empowered by two techniques: a) a contrastive learning scheme to\nclose the gap among representations of different languages, and b) data\naugmentation on both multiple parallel and monolingual data to further align\ntoken representations. For English-centric directions, mRASP2 outperforms\nexisting best unified model and achieves competitive or even better performance\nthan the pre-trained and fine-tuned model mBART on tens of WMT's translation\ndirections. For non-English directions, mRASP2 achieves an improvement of\naverage 10+ BLEU compared with the multilingual Transformer baseline. Code,\ndata and trained models are available at https://github.com/PANXiao1994/mRASP2.",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-06-10T01:56:45.612Z",
          "wordCount": 627,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1\">Muhammad Bilal Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1\">Michele Donini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">C&#xe9;dric Archambeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sanjiv Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1\">Krishnaram Kenthapadi</a>",
          "description": "With the ever-increasing complexity of neural language models, practitioners\nhave turned to methods for understanding the predictions of these models. One\nof the most well-adopted approaches for model interpretability is feature-based\ninterpretability, i.e., ranking the features in terms of their impact on model\npredictions. Several prior studies have focused on assessing the fidelity of\nfeature-based interpretability methods, i.e., measuring the impact of dropping\nthe top-ranked features on the model output. However, relatively little work\nhas been conducted on quantifying the robustness of interpretations. In this\nwork, we assess the robustness of interpretations of neural text classifiers,\nspecifically, those based on pretrained Transformer encoders, using two\nrandomization tests. The first compares the interpretations of two models that\nare identical except for their initializations. The second measures whether the\ninterpretations differ between a model with trained parameters and a model with\nrandom parameters. Both tests show surprising deviations from expected\nbehavior, raising questions about the extent of insights that practitioners may\ndraw from interpretations.",
          "link": "http://arxiv.org/abs/2106.04631",
          "publishedOn": "2021-06-10T01:56:45.596Z",
          "wordCount": 608,
          "title": "On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1\">Hillel Taub-Tabib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "Domain experts often need to extract structured information from large\ncorpora. We advocate for a search paradigm called ``extractive search'', in\nwhich a search query is enriched with capture-slots, to allow for such rapid\nextraction. Such an extractive search system can be built around syntactic\nstructures, resulting in high-precision, low-recall results. We show how the\nrecall can be improved using neural retrieval and alignment. The goals of this\npaper are to concisely introduce the extractive-search paradigm; and to\ndemonstrate a prototype neural retrieval system for extractive search and its\nbenefits and potential. Our prototype is available at\n\\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is\navailable at \\url{https://vimeo.com/559586687}.",
          "link": "http://arxiv.org/abs/2106.04612",
          "publishedOn": "2021-06-10T01:56:45.590Z",
          "wordCount": 535,
          "title": "Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1\">Michel Pl&#xfc;ss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1\">Lukas Neukom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1\">Christian Scheller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1\">Manfred Vogel</a>",
          "description": "We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss\nGerman speech to Standard German text corpus. This first version of the corpus\nis based on publicly available data of the Bernese cantonal parliament and\nconsists of 293 hours of data. It was created using a novel forced sentence\nalignment procedure and an alignment quality estimator, which can be used to\ntrade off corpus size and quality. We trained Automatic Speech Recognition\n(ASR) models as baselines on different subsets of the data and achieved a Word\nError Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The\ncorpus is freely available for download.",
          "link": "http://arxiv.org/abs/2010.02810",
          "publishedOn": "2021-06-10T01:56:45.584Z",
          "wordCount": 581,
          "title": "Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Houfeng Wang</a>",
          "description": "In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the\nonline inference efficiency of the Transformer for instantaneous Grammatical\nError Correction (GEC). SAD optimizes the online inference efficiency for GEC\nby two innovations: 1) it aggressively decodes as many tokens as possible in\nparallel instead of always decoding only one token in each step to improve\ncomputational parallelism; 2) it uses a shallow decoder instead of the\nconventional Transformer architecture with balanced encoder-decoder depth to\nreduce the computational cost during inference. Experiments in both English and\nChinese GEC benchmarks show that aggressive decoding could yield the same\npredictions as greedy decoding but with a significant speedup for online\ninference. Its combination with the shallow decoder could offer an even higher\nonline inference speedup over the powerful Transformer baseline without quality\nloss. Not only does our approach allow a single model to achieve the\nstate-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14\nand 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference\nspeedup over the Transformer-big model, but also it is easily adapted to other\nlanguages. Our code is available at\nhttps://github.com/AutoTemp/Shallow-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2106.04970",
          "publishedOn": "2021-06-10T01:56:45.577Z",
          "wordCount": 627,
          "title": "Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Cunxiao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.",
          "link": "http://arxiv.org/abs/2106.05093",
          "publishedOn": "2021-06-10T01:56:45.570Z",
          "wordCount": 590,
          "title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on\ndialog systems and found that improvement on individual components (e.g., NLU,\npolicy) in prior work may not necessarily bring benefit to pipeline systems in\nsystem-wise evaluation. To improve the system-wise performance, in this paper,\nwe propose new joint system-wise optimization techniques for the pipeline\ndialog system. First, we propose a new data augmentation approach which\nautomates the labeling process for NLU training. Second, we propose a novel\nstochastic policy parameterization with Poisson distribution that enables\nbetter exploration and offers a principled way to compute policy gradient.\nThird, we propose a reward bonus to help policy explore successful dialogs. Our\napproaches outperform the competitive pipeline systems from Takanobu et al.\n(2020) by big margins of 12% success rate in automatic system-wise evaluation\nand of 16% success rate in human evaluation on the standard multi-domain\nbenchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art\nend-to-end trained model from DSTC9.",
          "link": "http://arxiv.org/abs/2106.04835",
          "publishedOn": "2021-06-10T01:56:45.553Z",
          "wordCount": 594,
          "title": "Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1\">D. Emre Ta&#x15f;ar</a>",
          "description": "In this study, we aim to find a method to auto-tag sentences specific to a\ndomain. Our training data comprises short conversational sentences extracted\nfrom chat conversations between company's customer representatives and web site\nvisitors. We manually tagged approximately 14 thousand visitor inputs into ten\nbasic categories, which will later be used in a transformer-based language\nmodel with attention mechanisms for the ultimate goal of developing a chatbot\napplication that can produce meaningful dialogue. We considered three different\nstate-of-the-art models and reported their auto-tagging capabilities. We\nachieved the best performance with the bidirectional encoder representation\nfrom transformers (BERT) model. Implementation of the models used in these\nexperiments can be cloned from our GitHub repository and tested for similar\nauto-tagging problems without much effort.",
          "link": "http://arxiv.org/abs/2106.04959",
          "publishedOn": "2021-06-10T01:56:45.531Z",
          "wordCount": 554,
          "title": "Auto-tagging of Short Conversational Sentences using Natural Language Processing Methods. (arXiv:2106.04959v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yitao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhe Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>",
          "description": "Abstract Meaning Representation (AMR) is a rooted, labeled, acyclic graph\nrepresenting the semantics of natural language. As previous works show,\nalthough AMR is designed for English at first, it can also represent semantics\nin other languages. However, they find that concepts in their predicted AMR\ngraphs are less specific. We argue that the misprediction of concepts is due to\nthe high relevance between English tokens and AMR concepts. In this work, we\nintroduce bilingual input, namely the translated texts as well as non-English\ntexts, in order to enable the model to predict more accurate concepts. Besides,\nwe also introduce an auxiliary task, requiring the decoder to predict the\nEnglish sequences at the same time. The auxiliary task can help the decoder\nunderstand what exactly the corresponding English tokens are. Our proposed\ncross-lingual AMR parser surpasses previous state-of-the-art parser by 10.6\npoints on Smatch F1 score. The ablation study also demonstrates the efficacy of\nour proposed modules.",
          "link": "http://arxiv.org/abs/2106.04814",
          "publishedOn": "2021-06-10T01:56:45.525Z",
          "wordCount": 588,
          "title": "Making Better Use of Bilingual Information for Cross-Lingual AMR Parsing. (arXiv:2106.04814v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurfali_M/0/1/0/all/0/1\">Murathan Kurfal&#x131;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostling_R/0/1/0/all/0/1\">Robert &#xd6;stling</a>",
          "description": "Pre-trained multilingual language models have become an important building\nblock in multilingual natural language processing. In the present paper, we\ninvestigate a range of such models to find out how well they transfer\ndiscourse-level knowledge across languages. This is done with a systematic\nevaluation on a broader set of discourse-level tasks than has been previously\nbeen assembled. We find that the XLM-RoBERTa family of models consistently show\nthe best performance, by simultaneously being good monolingual models and\ndegrading relatively little in a zero-shot setting. Our results also indicate\nthat model distillation may hurt the ability of cross-lingual transfer of\nsentence representations, while language dissimilarity at most has a modest\neffect. We hope that our test suite, covering 5 tasks with a total of 22\nlanguages in 10 distinct families, will serve as a useful evaluation platform\nfor multilingual performance at and beyond the sentence level.",
          "link": "http://arxiv.org/abs/2106.04832",
          "publishedOn": "2021-06-10T01:56:45.505Z",
          "wordCount": 569,
          "title": "Probing Multilingual Language Models for Discourse. (arXiv:2106.04832v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Feifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1\">Haolan Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>",
          "description": "Most of the recent work on personality detection from online posts adopts\nmultifarious deep neural networks to represent the posts and builds predictive\nmodels in a data-driven manner, without the exploitation of psycholinguistic\nknowledge that may unveil the connections between one's language usage and his\npsychological traits. In this paper, we propose a psycholinguistic\nknowledge-based tripartite graph network, TrigNet, which consists of a\ntripartite graph network and a BERT-based graph initializer. The graph network\ninjects structural psycholinguistic knowledge from LIWC, a computerized\ninstrument for psycholinguistic analysis, by constructing a heterogeneous\ntripartite graph. The graph initializer is employed to provide initial\nembeddings for the graph nodes. To reduce the computational cost in graph\nlearning, we further propose a novel flow graph attention network (GAT) that\nonly transmits messages between neighboring parties in the tripartite graph.\nBenefiting from the tripartite graph, TrigNet can aggregate post information\nfrom a psychological perspective, which is a novel way of exploiting domain\nknowledge. Extensive experiments on two datasets show that TrigNet outperforms\nthe existing state-of-art model by 3.47 and 2.10 points in average F1.\nMoreover, the flow GAT reduces the FLOPS and Memory measures by 38% and 32%,\nrespectively, in comparison to the original GAT in our setting.",
          "link": "http://arxiv.org/abs/2106.04963",
          "publishedOn": "2021-06-10T01:56:45.498Z",
          "wordCount": 631,
          "title": "Psycholinguistic Tripartite Graph Network for Personality Detection. (arXiv:2106.04963v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guangyi Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>",
          "description": "Sentence semantic matching requires an agent to determine the semantic\nrelation between two sentences, where much recent progress has been made by the\nadvancement of representation learning techniques and inspiration of human\nbehaviors. Among all these methods, attention mechanism plays an essential role\nby selecting important parts effectively. However, current attention methods\neither focus on all the important parts in a static way or only select one\nimportant part at one attention step dynamically, which leaves a large space\nfor further improvement. To this end, in this paper, we design a novel Dynamic\nGaussian Attention Network (DGA-Net) to combine the advantages of current\nstatic and dynamic attention methods. More specifically, we first leverage\npre-trained language model to encode the input sentences and construct semantic\nrepresentations from a global perspective. Then, we develop a Dynamic Gaussian\nAttention (DGA) to dynamically capture the important parts and corresponding\nlocal contexts from a detailed perspective. Finally, we combine the global\ninformation and detailed local information together to decide the semantic\nrelation of sentences comprehensively and precisely. Extensive experiments on\ntwo popular sentence semantic matching tasks demonstrate that our proposed\nDGA-Net is effective in improving the ability of attention mechanism.",
          "link": "http://arxiv.org/abs/2106.04905",
          "publishedOn": "2021-06-10T01:56:45.477Z",
          "wordCount": 630,
          "title": "DGA-Net Dynamic Gaussian Attention Network for Sentence Semantic Matching. (arXiv:2106.04905v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1\">Hanan Aldarmaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullah_A/0/1/0/all/0/1\">Asad Ullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaki_N/0/1/0/all/0/1\">Nazar Zaki</a>",
          "description": "Automatic Speech Recognition (ASR) systems can be trained to achieve\nremarkable performance given large amounts of manually transcribed speech, but\nlarge labeled data sets can be difficult or expensive to acquire for all\nlanguages of interest. In this paper, we review the research literature to\nidentify models and ideas that could lead to fully unsupervised ASR, including\nunsupervised segmentation of the speech signal, unsupervised mapping from\nspeech segments to text, and semi-supervised models with nominal amounts of\nlabeled examples. The objective of the study is to identify the limitations of\nwhat can be learned from speech data alone and to understand the minimum\nrequirements for speech recognition. Identifying these limitations would help\noptimize the resources and efforts in ASR development for low-resource\nlanguages.",
          "link": "http://arxiv.org/abs/2106.04897",
          "publishedOn": "2021-06-10T01:56:45.471Z",
          "wordCount": 552,
          "title": "Unsupervised Automatic Speech Recognition: A Review. (arXiv:2106.04897v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1\">Danqi Liao</a>",
          "description": "Sentence embeddings encode sentences in fixed dense vectors and have played\nan important role in various NLP tasks and systems. Methods for building\nsentence embeddings include unsupervised learning such as Quick-Thoughts and\nsupervised learning such as InferSent. With the success of pretrained NLP\nmodels, recent research shows that fine-tuning pretrained BERT on SNLI and\nMulti-NLI data creates state-of-the-art sentence embeddings, outperforming\nprevious sentence embeddings methods on various evaluation benchmarks. In this\npaper, we propose a new method to build sentence embeddings by doing supervised\ncontrastive learning. Specifically our method fine-tunes pretrained BERT on\nSNLI data, incorporating both supervised crossentropy loss and supervised\ncontrastive loss. Compared with baseline where fine-tuning is only done with\nsupervised cross-entropy loss similar to current state-of-the-art method SBERT,\nour supervised contrastive method improves 2.8% in average on Semantic Textual\nSimilarity (STS) benchmarks and 1.05% in average on various sentence transfer\ntasks.",
          "link": "http://arxiv.org/abs/2106.04791",
          "publishedOn": "2021-06-10T01:56:45.459Z",
          "wordCount": 565,
          "title": "Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mina_S/0/1/0/all/0/1\">Sch&#xfc;tz Mina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaqueline_B/0/1/0/all/0/1\">Boeck Jaqueline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daria_L/0/1/0/all/0/1\">Liakhovets Daria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djordje_S/0/1/0/all/0/1\">Slijep&#x10d;evi&#x107; Djordje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armin_K/0/1/0/all/0/1\">Kirchknopf Armin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manuel_H/0/1/0/all/0/1\">Hecht Manuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johannes_B/0/1/0/all/0/1\">Bogensperger Johannes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sven_S/0/1/0/all/0/1\">Schlarb Sven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_S/0/1/0/all/0/1\">Schindler Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthias_Z/0/1/0/all/0/1\">Zeppelzauer Matthias</a>",
          "description": "Sexism has become an increasingly major problem on social networks during the\nlast years. The first shared task on sEXism Identification in Social neTworks\n(EXIST) at IberLEF 2021 is an international competition in the field of Natural\nLanguage Processing (NLP) with the aim to automatically identify sexism in\nsocial media content by applying machine learning methods. Thereby sexism\ndetection is formulated as a coarse (binary) classification problem and a\nfine-grained classification task that distinguishes multiple types of sexist\ncontent (e.g., dominance, stereotyping, and objectification). This paper\npresents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for\nboth tasks. To solve the tasks we applied two multilingual transformer models,\none based on multilingual BERT and one based on XLM-R. Our approach uses two\ndifferent strategies to adapt the transformers to the detection of sexist\ncontent: first, unsupervised pre-training with additional data and second,\nsupervised fine-tuning with additional and augmented data. For both tasks our\nbest model is XLM-R with unsupervised pre-training on the EXIST data and\nadditional datasets and fine-tuning on the provided dataset. The best run for\nthe binary classification (task 1) achieves a macro F1-score of 0.7752 and\nscores 5th rank in the benchmark; for the multiclass classification (task 2)\nour best submission scores 6th rank with a macro F1-score of 0.5589.",
          "link": "http://arxiv.org/abs/2106.04908",
          "publishedOn": "2021-06-10T01:56:45.452Z",
          "wordCount": 670,
          "title": "Automatic Sexism Detection with Multilingual Transformer Models. (arXiv:2106.04908v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1\">Hady Elsahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>",
          "description": "Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.",
          "link": "http://arxiv.org/abs/2106.04985",
          "publishedOn": "2021-06-10T01:56:45.445Z",
          "wordCount": 578,
          "title": "Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huanqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_D/0/1/0/all/0/1\">Dan Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Feng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "Keyphrase Prediction (KP) task aims at predicting several keyphrases that can\nsummarize the main idea of the given document. Mainstream KP methods can be\ncategorized into purely generative approaches and integrated models with\nextraction and generation. However, these methods either ignore the diversity\namong keyphrases or only weakly capture the relation across tasks implicitly.\nIn this paper, we propose UniKeyphrase, a novel end-to-end learning framework\nthat jointly learns to extract and generate keyphrases. In UniKeyphrase,\nstacked relation layer and bag-of-words constraint are proposed to fully\nexploit the latent semantic relation between extraction and generation in the\nview of model structure and training process, respectively. Experiments on KP\nbenchmarks demonstrate that our joint approach outperforms mainstream methods\nby a large margin.",
          "link": "http://arxiv.org/abs/2106.04847",
          "publishedOn": "2021-06-10T01:56:45.429Z",
          "wordCount": 568,
          "title": "UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction. (arXiv:2106.04847v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sweed_N/0/1/0/all/0/1\">Nir Sweed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahaf_D/0/1/0/all/0/1\">Dafna Shahaf</a>",
          "description": "A snowclone is a customizable phrasal template that can be realized in\nmultiple, instantly recognized variants. For example, ``* is the new *\" (Orange\nis the new black, 40 is the new 30). Snowclones are extensively used in social\nmedia. In this paper, we study snowclones originating from pop-culture quotes;\nour goal is to automatically detect cultural references in text. We introduce a\nnew, publicly available data set of pop-culture quotes and their corresponding\nsnowclone usages and train models on them. We publish code for Catchphrase, an\ninternet browser plugin to automatically detect and mark references in\nreal-time, and examine its performance via a user study. Aside from assisting\npeople to better comprehend cultural references, we hope that detecting\nsnowclones can complement work on paraphrasing and help to tackle long-standing\nquestions in social science about the dynamics of information propagation.",
          "link": "http://arxiv.org/abs/2106.04830",
          "publishedOn": "2021-06-10T01:56:45.422Z",
          "wordCount": 557,
          "title": "Catchphrase: Automatic Detection of Cultural References. (arXiv:2106.04830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Maija K&#x101;le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rikters_M/0/1/0/all/0/1\">Mat&#x12b;ss Rikters</a>",
          "description": "We analysed sentiment and frequencies related to smell, taste and temperature\nexpressed by food tweets in the Latvian language. To get a better understanding\nof the role of smell, taste and temperature in the mental map of food\nassociations, we looked at such categories as 'tasty' and 'healthy', which\nturned out to be mutually exclusive. By analysing the occurrence frequency of\nwords associated with these categories, we discovered that food discourse\noverall was permeated by `tasty' while the category of 'healthy' was relatively\nsmall. Finally, we used the analysis of temporal dynamics to see if we can\ntrace seasonality or other temporal aspects in smell, taste and temperature as\nreflected in food tweets. Understanding the composition of social media content\nwith relation to smell, taste and temperature in food tweets allows us to\ndevelop our work further - on food culture/seasonality and its relation to\ntemperature, on our limited capacity to express smell-related sentiments, and\nthe lack of the paradigm of taste in discussing food healthiness.",
          "link": "http://arxiv.org/abs/2106.04903",
          "publishedOn": "2021-06-10T01:56:45.416Z",
          "wordCount": 602,
          "title": "Fragmented and Valuable: Following Sentiment Changes in Food Tweets. (arXiv:2106.04903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Briakou_E/0/1/0/all/0/1\">Eleftheria Briakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sweta Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Ke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetreault_J/0/1/0/all/0/1\">Joel Tetreault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1\">Marine Carpuat</a>",
          "description": "This paper reviews and summarizes human evaluation practices described in 97\nstyle transfer papers with respect to three main evaluation aspects: style\ntransfer, meaning preservation, and fluency. In principle, evaluations by human\nraters should be the most reliable. However, in style transfer papers, we find\nthat protocols for human evaluations are often underspecified and not\nstandardized, which hampers the reproducibility of research in this field and\nprogress toward better human and automatic evaluation methods.",
          "link": "http://arxiv.org/abs/2106.04747",
          "publishedOn": "2021-06-10T01:56:45.258Z",
          "wordCount": 504,
          "title": "A Review of Human Evaluation for Style Transfer. (arXiv:2106.04747v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yada Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_G/0/1/0/all/0/1\">Guangnan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1\">Xiaodong Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>",
          "description": "In the recent advances of natural language processing, the scale of the\nstate-of-the-art models and datasets is usually extensive, which challenges the\napplication of sample-based explanation methods in many aspects, such as\nexplanation interpretability, efficiency, and faithfulness. In this work, for\nthe first time, we can improve the interpretability of explanations by allowing\narbitrary text sequences as the explanation unit. On top of this, we implement\na hessian-free method with a model faithfulness guarantee. Finally, to compare\nour method with the others, we propose a semantic-based evaluation metric that\ncan better align with humans' judgment of explanations than the widely adopted\ndiagnostic or re-training measures. The empirical results on multiple real data\nsets demonstrate the proposed method's superior performance to popular\nexplanation techniques such as Influence Function or TracIn on semantic\nevaluation.",
          "link": "http://arxiv.org/abs/2106.04753",
          "publishedOn": "2021-06-10T01:56:45.250Z",
          "wordCount": 581,
          "title": "On Sample Based Explanation Methods for NLP:Efficiency, Faithfulness, and Semantic Evaluation. (arXiv:2106.04753v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beddiar_D/0/1/0/all/0/1\">Djamila Romaissa Beddiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahan_M/0/1/0/all/0/1\">Md Saroar Jahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1\">Mourad Oussalah</a>",
          "description": "With proliferation of user generated contents in social media platforms,\nestablishing mechanisms to automatically identify toxic and abusive content\nbecomes a prime concern for regulators, researchers, and society. Keeping the\nbalance between freedom of speech and respecting each other dignity is a major\nconcern of social media platform regulators. Although, automatic detection of\noffensive content using deep learning approaches seems to provide encouraging\nresults, training deep learning-based models requires large amounts of\nhigh-quality labeled data, which is often missing. In this regard, we present\nin this paper a new deep learning-based method that fuses a Back Translation\nmethod, and a Paraphrasing technique for data augmentation. Our pipeline\ninvestigates different word-embedding-based architectures for classification of\nhate speech. The back translation technique relies on an encoder-decoder\narchitecture pre-trained on a large corpus and mostly used for machine\ntranslation. In addition, paraphrasing exploits the transformer model and the\nmixture of experts to generate diverse paraphrases. Finally, LSTM, and CNN are\ncompared to seek enhanced classification results. We evaluate our proposal on\nfive publicly available datasets; namely, AskFm corpus, Formspring dataset,\nWarner and Waseem dataset, Olid, and Wikipedia toxic comments dataset. The\nperformance of the proposal together with comparison to some related\nstate-of-art results demonstrate the effectiveness and soundness of our\nproposal.",
          "link": "http://arxiv.org/abs/2106.04681",
          "publishedOn": "2021-06-10T01:56:45.226Z",
          "wordCount": 640,
          "title": "Data Expansion using Back Translation and Paraphrasing for Hate Speech Detection. (arXiv:2106.04681v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_J/0/1/0/all/0/1\">Jishnu Parameswaran P.K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_P/0/1/0/all/0/1\">Premjith B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soman_K/0/1/0/all/0/1\">K.P Soman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponnusamy_R/0/1/0/all/0/1\">Rahul Ponnusamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaresan_P/0/1/0/all/0/1\">Prasanna Kumar Kumaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1\">Kingston Pal Thamburaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1\">John P. McCrae</a>",
          "description": "Human communication is inherently multimodal and asynchronous. Analyzing\nhuman emotions and sentiment is an emerging field of artificial intelligence.\nWe are witnessing an increasing amount of multimodal content in local languages\non social media about products and other topics. However, there are not many\nmultimodal resources available for under-resourced Dravidian languages. Our\nstudy aims to create a multimodal sentiment analysis dataset for the\nunder-resourced Tamil and Malayalam languages. First, we downloaded product or\nmovies review videos from YouTube for Tamil and Malayalam. Next, we created\ncaptions for the videos with the help of annotators. Then we labelled the\nvideos for sentiment, and verified the inter-annotator agreement using Fleiss's\nKappa. This is the first multimodal sentiment analysis dataset for Tamil and\nMalayalam by volunteer annotators.",
          "link": "http://arxiv.org/abs/2106.04853",
          "publishedOn": "2021-06-10T01:56:45.214Z",
          "wordCount": 571,
          "title": "DravidianMultiModality: A Dataset for Multi-modal Sentiment Analysis in Tamil and Malayalam. (arXiv:2106.04853v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1\">Ting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1\">Desheng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1\">Bingyu Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruifei Zhang</a>",
          "description": "Transformer-based models have made tremendous impacts in natural language\ngeneration. However the inference speed is a bottleneck due to large model size\nand intensive computing involved in auto-regressive decoding process. We\ndevelop FastSeq framework to accelerate sequence generation without accuracy\nloss. The proposed optimization techniques include an attention cache\noptimization, an efficient algorithm for detecting repeated n-grams, and an\nasynchronous generation pipeline with parallel I/O. These optimizations are\ngeneral enough to be applicable to Transformer-based models (e.g., T5, GPT2,\nand UniLM). Our benchmark results on a set of widely used and diverse models\ndemonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use\nwith a simple one-line code change. The source code is available at\nhttps://github.com/microsoft/fastseq.",
          "link": "http://arxiv.org/abs/2106.04718",
          "publishedOn": "2021-06-10T01:56:45.207Z",
          "wordCount": 560,
          "title": "FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1\">Kiran Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1\">Gautam Kishore Shahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1\">Devin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "WhatsApp is a popular chat application used by over 2 billion users\nworldwide. However, due to end-to-end encryption, there is currently no easy\nway to fact-check content on WhatsApp at scale. In this paper, we analyze the\nusefulness of a crowd-sourced system on WhatsApp through which users can submit\n\"tips\" containing messages they want fact-checked. We compare the tips sent to\na WhatsApp tipline run during the 2019 Indian national elections with the\nmessages circulating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, the\nanalysis suggests tiplines can be an effective source for discovering content\nto fact-check.",
          "link": "http://arxiv.org/abs/2106.04726",
          "publishedOn": "2021-06-10T01:56:45.187Z",
          "wordCount": 635,
          "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:45.112Z",
          "wordCount": 704,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1\">Nicolai Pogrebnyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1\">Shohreh Shaghaghian</a>",
          "description": "Transfer learning methods, and in particular domain adaptation, help exploit\nlabeled data in one domain to improve the performance of a certain task in\nanother domain. However, it is still not clear what factors affect the success\nof domain adaptation. This paper models adaptation success and selection of the\nmost suitable source domains among several candidates in text similarity. We\nuse descriptive domain information and cross-domain similarity metrics as\npredictive features. While mostly positive, the results also point to some\ndomains where adaptation success was difficult to predict.",
          "link": "http://arxiv.org/abs/2106.04641",
          "publishedOn": "2021-06-10T01:56:45.067Z",
          "wordCount": 520,
          "title": "Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1\">Rabeeh Karimi Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>",
          "description": "Adapting large-scale pretrained language models to downstream tasks via\nfine-tuning is the standard method for achieving state-of-the-art performance\non NLP benchmarks. However, fine-tuning all weights of models with millions or\nbillions of parameters is sample-inefficient, unstable in low-resource\nsettings, and wasteful as it requires storing a separate copy of the model for\neach task. Recent work has developed parameter-efficient fine-tuning methods,\nbut these approaches either still require a relatively large number of\nparameters or underperform standard fine-tuning. In this work, we propose\nCompacter, a method for fine-tuning large-scale language models with a better\ntrade-off between task performance and the number of trainable parameters than\nprior work. Compacter accomplishes this by building on top of ideas from\nadapters, low-rank optimization, and parameterized hypercomplex multiplication\nlayers.\n\nSpecifically, Compacter inserts task-specific weight matrices into a\npretrained model's weights, which are computed efficiently as a sum of\nKronecker products between shared ``slow'' weights and ``fast'' rank-one\nmatrices defined per Compacter layer. By only training 0.047% of a pretrained\nmodel's parameters, Compacter performs on par with standard fine-tuning on GLUE\nand outperforms fine-tuning in low-resource settings. Our code is publicly\navailable in https://github.com/rabeehk/compacter/",
          "link": "http://arxiv.org/abs/2106.04647",
          "publishedOn": "2021-06-10T01:56:45.020Z",
          "wordCount": 612,
          "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers. (arXiv:2106.04647v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>",
          "description": "Human-computer interaction (HCI) is significantly impacted by delayed\nresponses from a spoken dialogue system. Hence, end-to-end (e2e) spoken\nlanguage understanding (SLU) solutions have recently been proposed to decrease\nlatency. Such approaches allow for the extraction of semantic information\ndirectly from the speech signal, thus bypassing the need for a transcript from\nan automatic speech recognition (ASR) system. In this paper, we propose a\ncompact e2e SLU architecture for streaming scenarios, where chunks of the\nspeech signal are processed continuously to predict intent and slot values. Our\nmodel is based on a 3D convolutional neural network (3D-CNN) and a\nunidirectional long short-term memory (LSTM). We compare the performance of two\nalignment-free losses: the connectionist temporal classification (CTC) method\nand its adapted version, namely connectionist temporal localization (CTL). The\nlatter performs not only the classification but also localization of sequential\naudio events. The proposed solution is evaluated on the Fluent Speech Command\ndataset and results show our model ability to process incoming speech signal,\nreaching accuracy as high as 98.97 % for CTC and 98.78 % for CTL on\nsingle-label classification, and as high as 95.69 % for CTC and 95.28 % for CTL\non two-label prediction.",
          "link": "http://arxiv.org/abs/2106.04660",
          "publishedOn": "2021-06-10T01:56:44.974Z",
          "wordCount": 637,
          "title": "Sequential End-to-End Intent and Slot Label Classification and Localization. (arXiv:2106.04660v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahu_P/0/1/0/all/0/1\">Pritish Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cogswell_M/0/1/0/all/0/1\">Michael Cogswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutherford_Quach_S/0/1/0/all/0/1\">Sara Rutherford-Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_A/0/1/0/all/0/1\">Ajay Divakaran</a>",
          "description": "Current pre-trained language models have lots of knowledge, but a more\nlimited ability to use that knowledge. Bloom's Taxonomy helps educators teach\nchildren how to use knowledge by categorizing comprehension skills, so we use\nit to analyze and improve the comprehension skills of large pre-trained\nlanguage models. Our experiments focus on zero-shot question answering, using\nthe taxonomy to provide proximal context that helps the model answer questions\nby being relevant to those questions. We show targeting context in this manner\nimproves performance across 4 popular common sense question answer datasets.",
          "link": "http://arxiv.org/abs/2106.04653",
          "publishedOn": "2021-06-10T01:56:44.947Z",
          "wordCount": 513,
          "title": "Comprehension Based Question Answering using Bloom's Taxonomy. (arXiv:2106.04653v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_Tarrant_S/0/1/0/all/0/1\">Seraphina Goldfarb-Tarrant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchant_R/0/1/0/all/0/1\">Rebecca Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_R/0/1/0/all/0/1\">Ricardo Mu&#xf1;oz Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandya_M/0/1/0/all/0/1\">Mugdha Pandya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1\">Adam Lopez</a>",
          "description": "Natural Language Processing (NLP) systems learn harmful societal biases that\ncause them to amplify inequality as they are deployed in more and more\nsituations. To guide efforts at debiasing these systems, the NLP community\nrelies on a variety of metrics that quantify bias in models. Some of these\nmetrics are intrinsic, measuring bias in word embedding spaces, and some are\nextrinsic, measuring bias in downstream tasks that the word embeddings enable.\nDo these intrinsic and extrinsic metrics correlate with each other? We compare\nintrinsic and extrinsic metrics across hundreds of trained models covering\ndifferent tasks and experimental conditions. Our results show no reliable\ncorrelation between these metrics that holds in all scenarios across tasks and\nlanguages. We urge researchers working on debiasing to focus on extrinsic\nmeasures of bias, and to make using these measures more feasible via creation\nof new challenge sets and annotated test data. To aid this effort, we release\ncode, a new intrinsic metric, and an annotated test set focused on gender bias\nin hate speech.",
          "link": "http://arxiv.org/abs/2012.15859",
          "publishedOn": "2021-06-09T22:43:50.385Z",
          "wordCount": 662,
          "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias. (arXiv:2012.15859v5 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>",
          "description": "Pre-trained language models (LMs) are currently integral to many natural\nlanguage processing systems. Although multilingual LMs were also introduced to\nserve many languages, these have limitations such as being costly at inference\ntime and the size and diversity of non-English data involved in their\npre-training. We remedy these issues for a collection of diverse Arabic\nvarieties by introducing two powerful deep bidirectional transformer-based\nmodels, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a\nnew benchmark for multi-dialectal Arabic language understanding evaluation.\nARLUE is built using 42 datasets targeting six different task clusters,\nallowing us to offer a series of standardized experiments under rich\nconditions. When fine-tuned on ARLUE, our models collectively achieve new\nstate-of-the-art results across the majority of tasks (37 out of 48\nclassification tasks, on the 42 datasets). Our best model acquires the highest\nARLUE score (77.40) across all six task clusters, outperforming all other\nmodels including XLM-R Large (~ 3.4 x larger size). Our models are publicly\navailable at https://github.com/UBC-NLP/marbert and ARLUE will be released\nthrough the same repository.",
          "link": "http://arxiv.org/abs/2101.01785",
          "publishedOn": "2021-06-09T22:43:50.339Z",
          "wordCount": 654,
          "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic. (arXiv:2101.01785v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazov_S/0/1/0/all/0/1\">Stefan Lazov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Sparse attention has been claimed to increase model interpretability under\nthe assumption that it highlights influential inputs. Yet the attention\ndistribution is typically over representations internal to the model rather\nthan the inputs themselves, suggesting this assumption may not have merit. We\nbuild on the recent work exploring the interpretability of attention; we design\na set of experiments to help us understand how sparsity affects our ability to\nuse attention as an explainability tool. On three text classification tasks, we\nverify that only a weak relationship between inputs and co-indexed intermediate\nrepresentations exists -- under sparse attention and otherwise. Further, we do\nnot find any plausible mappings from sparse attention distributions to a sparse\nset of influential inputs through other avenues. Rather, we observe in this\nsetting that inducing sparsity may make it less plausible that attention can be\nused as a tool for understanding model behavior.",
          "link": "http://arxiv.org/abs/2106.01087",
          "publishedOn": "2021-06-09T22:43:50.188Z",
          "wordCount": 593,
          "title": "Is Sparse Attention more Interpretable?. (arXiv:2106.01087v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_V/0/1/0/all/0/1\">Valentin Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pierrehumbert_J/0/1/0/all/0/1\">Janet B. Pierrehumbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>",
          "description": "Static word embeddings that represent words by a single vector cannot capture\nthe variability of word meaning in different linguistic and extralinguistic\ncontexts. Building on prior work on contextualized and dynamic word embeddings,\nwe introduce dynamic contextualized word embeddings that represent words as a\nfunction of both linguistic and extralinguistic context. Based on a pretrained\nlanguage model (PLM), dynamic contextualized word embeddings model time and\nsocial space jointly, which makes them attractive for a range of NLP tasks\ninvolving semantic variability. We highlight potential application scenarios by\nmeans of qualitative and quantitative analyses on four English datasets.",
          "link": "http://arxiv.org/abs/2010.12684",
          "publishedOn": "2021-06-09T02:01:48.454Z",
          "wordCount": 554,
          "title": "Dynamic Contextualized Word Embeddings. (arXiv:2010.12684v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.05609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Silei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campagna_G/0/1/0/all/0/1\">Giovanni Campagna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1\">Monica S. Lam</a>",
          "description": "Building a question-answering agent currently requires large annotated\ndatasets, which are prohibitively expensive. This paper proposes Schema2QA, an\nopen-source toolkit that can generate a Q&A system from a database schema\naugmented with a few annotations for each field. The key concept is to cover\nthe space of possible compound queries on the database with a large number of\nin-domain questions synthesized with the help of a corpus of generic query\ntemplates. The synthesized data and a small paraphrase set are used to train a\nnovel neural network based on the BERT pretrained model. We use Schema2QA to\ngenerate Q&A systems for five Schema.org domains, restaurants, people, movies,\nbooks and music, and obtain an overall accuracy between 64% and 75% on\ncrowdsourced questions for these domains. Once annotations and paraphrases are\nobtained for a Schema.org schema, no additional manual effort is needed to\ncreate a Q&A agent for any website that uses the same schema. Furthermore, we\ndemonstrate that learning can be transferred from the restaurant to the hotel\ndomain, obtaining a 64% accuracy on crowdsourced questions with no manual\neffort. Schema2QA achieves an accuracy of 60% on popular restaurant questions\nthat can be answered using Schema.org. Its performance is comparable to Google\nAssistant, 7% lower than Siri, and 15% higher than Alexa. It outperforms all\nthese assistants by at least 18% on more complex, long-tail questions.",
          "link": "http://arxiv.org/abs/2001.05609",
          "publishedOn": "2021-06-09T02:01:48.354Z",
          "wordCount": 728,
          "title": "Schema2QA: High-Quality and Low-Cost Q&A Agents for the Structured Web. (arXiv:2001.05609v6 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Information-seeking dialogue systems, including knowledge identification and\nresponse generation, aim to respond to users with fluent, coherent, and\ninformative responses based on users' needs, which. To tackle this challenge,\nwe utilize data augmentation methods and several training techniques with the\npre-trained language models to learn a general pattern of the task and thus\nachieve promising performance. In DialDoc21 competition, our system achieved\n74.95 F1 score and 60.74 Exact Match score in subtask 1, and 37.72 SacreBLEU\nscore in subtask 2. Empirical analysis is provided to explain the effectiveness\nof our approaches.",
          "link": "http://arxiv.org/abs/2106.03530",
          "publishedOn": "2021-06-09T02:01:48.343Z",
          "wordCount": 568,
          "title": "CAiRE in DialDoc21: Data Augmentation for Information-Seeking Dialogue System. (arXiv:2106.03530v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.04460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gjurkovic_M/0/1/0/all/0/1\">Matej Gjurkovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karan_M/0/1/0/all/0/1\">Mladen Karan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vukojevic_I/0/1/0/all/0/1\">Iva Vukojevi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1\">Mihaela Bo&#x161;njak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>",
          "description": "Personality and demographics are important variables in social sciences,\nwhile in NLP they can aid in interpretability and removal of societal biases.\nHowever, datasets with both personality and demographic labels are scarce. To\naddress this, we present PANDORA, the first large-scale dataset of Reddit\ncomments labeled with three personality models (including the well-established\nBig 5 model) and demographics (age, gender, and location) for more than 10k\nusers. We showcase the usefulness of this dataset on three experiments, where\nwe leverage the more readily available data from other personality models to\npredict the Big 5 traits, analyze gender classification biases arising from\npsycho-demographic variables, and carry out a confirmatory and exploratory\nanalysis based on psychological theories. Finally, we present benchmark\nprediction models for all personality and demographic variables.",
          "link": "http://arxiv.org/abs/2004.04460",
          "publishedOn": "2021-06-09T02:01:48.326Z",
          "wordCount": 619,
          "title": "PANDORA Talks: Personality and Demographics on Reddit. (arXiv:2004.04460v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1\">Ekin Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_A/0/1/0/all/0/1\">Afra Feyza Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Flexible neural sequence models outperform grammar- and automaton-based\ncounterparts on a variety of tasks. However, neural models perform poorly in\nsettings requiring compositional generalization beyond the training data --\nparticularly to rare or unseen subsequences. Past work has found symbolic\nscaffolding (e.g. grammars or automata) essential in these settings. We\ndescribe R&R, a learned data augmentation scheme that enables a large category\nof compositional generalizations without appeal to latent symbolic structure.\nR&R has two components: recombination of original training examples via a\nprototype-based generative model and resampling of generated examples to\nencourage extrapolation. Training an ordinary neural sequence model on a\ndataset augmented with recombined and resampled examples significantly improves\ngeneralization in two language processing problems -- instruction following\n(SCAN) and morphological analysis (SIGMORPHON 2018) -- where R&R enables\nlearning of new constructions and tenses from as few as eight initial examples.",
          "link": "http://arxiv.org/abs/2010.03706",
          "publishedOn": "2021-06-09T02:01:48.320Z",
          "wordCount": 638,
          "title": "Learning to Recombine and Resample Data for Compositional Generalization. (arXiv:2010.03706v6 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakashole_N/0/1/0/all/0/1\">Ndapa Nakashole</a>",
          "description": "In problem solving, understanding the problem that one seeks to solve is an\nessential initial step. In this paper, we propose computational methods for\nfacilitating problem understanding through the task of recognizing the unknown\nin specifications of long Math problems. We focus on the topic of Probability.\nOur experimental results show that learning models yield strong results on the\ntask, a promising first step towards human interpretable, modular approaches to\nunderstanding long Math problems.",
          "link": "http://arxiv.org/abs/2103.12048",
          "publishedOn": "2021-06-09T02:01:48.314Z",
          "wordCount": 526,
          "title": "Extracting the Unknown from Long Math Problems. (arXiv:2103.12048v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1\">Tilman Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Ung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viehmann_C/0/1/0/all/0/1\">Christina Viehmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maurer_M/0/1/0/all/0/1\">Marcus Maurer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quiring_O/0/1/0/all/0/1\">Oliver Quiring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "This work investigates the use of interactively updated label suggestions to\nimprove upon the efficiency of gathering annotations on the task of opinion\nmining in German Covid-19 social media data. We develop guidelines to conduct a\ncontrolled annotation study with social science students and find that\nsuggestions from a model trained on a small, expert-annotated dataset already\nlead to a substantial improvement - in terms of inter-annotator agreement(+.14\nFleiss' $\\kappa$) and annotation quality - compared to students that do not\nreceive any label suggestions. We further find that label suggestions from\ninteractively trained models do not lead to an improvement over suggestions\nfrom a static model. Nonetheless, our analysis of suggestion bias shows that\nannotators remain capable of reflecting upon the suggested label in general.\nFinally, we confirm the quality of the annotated data in transfer learning\nexperiments between different annotator groups. To facilitate further research\nin opinion mining on social media data, we release our collected data\nconsisting of 200 expert and 2,785 student annotations.",
          "link": "http://arxiv.org/abs/2105.12980",
          "publishedOn": "2021-06-09T02:01:48.308Z",
          "wordCount": 681,
          "title": "Investigating label suggestions for opinion mining in German Covid-19 social media. (arXiv:2105.12980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bailin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>",
          "description": "Despite success in many domains, neural models struggle in settings where\ntrain and test examples are drawn from different distributions. In particular,\nin contrast to humans, conventional sequence-to-sequence (seq2seq) models fail\nto generalize systematically, i.e., interpret sentences representing novel\ncombinations of concepts (e.g., text segments) seen in training. Traditional\ngrammar formalisms excel in such settings by implicitly encoding alignments\nbetween input and output segments, but are hard to scale and maintain. Instead\nof engineering a grammar, we directly model segment-to-segment alignments as\ndiscrete structured latent variables within a neural seq2seq model. To\nefficiently explore the large space of alignments, we introduce a reorder-first\nalign-later framework whose central component is a neural reordering module\nproducing {\\it separable} permutations. We present an efficient dynamic\nprogramming algorithm performing exact marginal inference of separable\npermutations, and, thus, enabling end-to-end differentiable training of our\nmodel. The resulting seq2seq model exhibits better systematic generalization\nthan standard models on synthetic problems and NLP tasks (i.e., semantic\nparsing and machine translation).",
          "link": "http://arxiv.org/abs/2106.03257",
          "publishedOn": "2021-06-09T02:01:48.280Z",
          "wordCount": 612,
          "title": "Structured Reordering for Modeling Latent Alignments in Sequence Transduction. (arXiv:2106.03257v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Uhrig_S/0/1/0/all/0/1\">Sarah Uhrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Y/0/1/0/all/0/1\">Yoalli Rezepka Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opitz_J/0/1/0/all/0/1\">Juri Opitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "In cross-lingual Abstract Meaning Representation (AMR) parsing, researchers\ndevelop models that project sentences from various languages onto their AMRs to\ncapture their essential semantic structures: given a sentence in any language,\nwe aim to capture its core semantic content through concepts connected by\nmanifold types of semantic relations. Methods typically leverage large silver\ntraining data to learn a single model that is able to project non-English\nsentences to AMRs. However, we find that a simple baseline tends to be\nover-looked: translating the sentences to English and projecting their AMR with\na monolingual AMR parser (translate+parse,T+P). In this paper, we revisit this\nsimple two-step base-line, and enhance it with a strong NMT system and a strong\nAMR parser. Our experiments show that T+P outperforms a recent state-of-the-art\nsystem across all tested languages: German, Italian, Spanish and Mandarin with\n+14.6, +12.6, +14.3 and +16.0 Smatch points.",
          "link": "http://arxiv.org/abs/2106.04565",
          "publishedOn": "2021-06-09T02:01:48.275Z",
          "wordCount": 582,
          "title": "Translate, then Parse! A strong baseline for Cross-Lingual AMR Parsing. (arXiv:2106.04565v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "We present Meta Learning for Knowledge Distillation (MetaDistil), a simple\nyet effective alternative to traditional knowledge distillation (KD) methods\nwhere the teacher model is fixed during training. We show the teacher network\ncan learn to better transfer knowledge to the student network (i.e., learning\nto teach) with the feedback from the performance of the distilled student\nnetwork in a meta learning framework. Moreover, we introduce a pilot update\nmechanism to improve the alignment between the inner-learner and meta-learner\nin meta learning algorithms that focus on an improved inner-learner.\nExperiments on various benchmarks show that MetaDistil can yield significant\nimprovements compared with traditional KD algorithms and is less sensitive to\nthe choice of different student capacity and hyperparameters, facilitating the\nuse of KD on different tasks and models. The code is available at\nhttps://github.com/JetRunner/MetaDistil",
          "link": "http://arxiv.org/abs/2106.04570",
          "publishedOn": "2021-06-09T02:01:48.229Z",
          "wordCount": 567,
          "title": "Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "Cant is important for understanding advertising, comedies and dog-whistle\npolitics. However, computational research on cant is hindered by a lack of\navailable datasets. In this paper, we propose a large and diverse Chinese\ndataset for creating and understanding cant from a computational linguistics\nperspective. We formulate a task for cant understanding and provide both\nquantitative and qualitative analysis for tested word embedding similarity and\npretrained language models. Experiments suggest that such a task requires deep\nlanguage understanding, common sense, and world knowledge and thus can be a\ngood testbed for pretrained language models and help models perform better on\nother tasks. The code is available at https://github.com/JetRunner/dogwhistle.\nThe data and leaderboard are available at\nhttps://competitions.codalab.org/competitions/30451.",
          "link": "http://arxiv.org/abs/2104.02704",
          "publishedOn": "2021-06-09T02:01:48.216Z",
          "wordCount": 603,
          "title": "Blow the Dog Whistle: A Chinese Dataset for Cant Understanding with Common Sense and World Knowledge. (arXiv:2104.02704v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kshitij Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gautam_D/0/1/0/all/0/1\">Devansh Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1\">Radhika Mamidi</a>",
          "description": "Multimodal Machine Translation (MMT) enriches the source text with visual\ninformation for translation. It has gained popularity in recent years, and\nseveral pipelines have been proposed in the same direction. Yet, the task lacks\nquality datasets to illustrate the contribution of visual modality in the\ntranslation systems. In this paper, we propose our system under the team name\nVolta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We\nalso participate in the textual-only subtask of the same language pair for\nwhich we use mBART, a pretrained multilingual sequence-to-sequence model. For\nmultimodal translation, we propose to enhance the textual input by bringing the\nvisual information to a textual domain by extracting object tags from the\nimage. We also explore the robustness of our system by systematically degrading\nthe source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test\nset and challenge set of the multimodal task.",
          "link": "http://arxiv.org/abs/2106.00250",
          "publishedOn": "2021-06-09T02:01:48.210Z",
          "wordCount": 610,
          "title": "ViTA: Visual-Linguistic Translation by Aligning Object Tags. (arXiv:2106.00250v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minixhofer_B/0/1/0/all/0/1\">Benjamin Minixhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritta_M/0/1/0/all/0/1\">Milan Gritta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iacobacci_I/0/1/0/all/0/1\">Ignacio Iacobacci</a>",
          "description": "Transfer learning has become the dominant paradigm for many natural language\nprocessing tasks. In addition to models being pretrained on large datasets,\nthey can be further trained on intermediate (supervised) tasks that are similar\nto the target task. For small Natural Language Inference (NLI) datasets,\nlanguage modelling is typically followed by pretraining on a large (labelled)\nNLI dataset before fine-tuning with each NLI subtask. In this work, we explore\nGradient Boosted Decision Trees (GBDTs) as an alternative to the commonly used\nMulti-Layer Perceptron (MLP) classification head. GBDTs have desirable\nproperties such as good performance on dense, numerical features and are\neffective where the ratio of the number of samples w.r.t the number of features\nis low. We then introduce FreeGBDT, a method of fitting a GBDT head on the\nfeatures computed during fine-tuning to increase performance without additional\ncomputation by the neural network. We demonstrate the effectiveness of our\nmethod on several NLI datasets using a strong baseline model (RoBERTa-large\nwith MNLI pretraining). The FreeGBDT shows a consistent improvement over the\nMLP classification head.",
          "link": "http://arxiv.org/abs/2105.03791",
          "publishedOn": "2021-06-09T02:01:48.193Z",
          "wordCount": 633,
          "title": "Enhancing Transformers with Gradient Boosted Decision Trees for NLI Fine-Tuning. (arXiv:2105.03791v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Aryaman Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farris_A/0/1/0/all/0/1\">Adam Farris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_G/0/1/0/all/0/1\">Gopalakrishnan R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Samopriya Basu</a>",
          "description": "We present Bh\\=a$\\unicode{x1E63}$\\=acitra, a dialect mapping system for South\nAsia built on a database of linguistic studies of languages of the region\nannotated for topic and location data. We analyse language coverage and look\ntowards applications to typology by visualising example datasets. The\napplication is not only meant to be useful for feature mapping, but also serves\nas a new kind of interactive bibliography for linguists of South Asian\nlanguages.",
          "link": "http://arxiv.org/abs/2105.14082",
          "publishedOn": "2021-06-09T02:01:48.176Z",
          "wordCount": 529,
          "title": "Bh\\=a$\\unicode{x1E63}$\\=acitra: Visualising the dialect geography of South Asia. (arXiv:2105.14082v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruocheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "We present Language-mediated, Object-centric Representation Learning (LORL),\na paradigm for learning disentangled, object-centric scene representations from\nvision and language. LORL builds upon recent advances in unsupervised object\ndiscovery and segmentation, notably MONet and Slot Attention. While these\nalgorithms learn an object-centric representation just by reconstructing the\ninput image, LORL enables them to further learn to associate the learned\nrepresentations to concepts, i.e., words for object categories, properties, and\nspatial relationships, from language input. These object-centric concepts\nderived from language facilitate the learning of object-centric\nrepresentations. LORL can be integrated with various unsupervised object\ndiscovery algorithms that are language-agnostic. Experiments show that the\nintegration of LORL consistently improves the performance of unsupervised\nobject discovery methods on two datasets via the help of language. We also show\nthat concepts learned by LORL, in conjunction with object discovery methods,\naid downstream tasks such as referring expression comprehension.",
          "link": "http://arxiv.org/abs/2012.15814",
          "publishedOn": "2021-06-09T02:01:48.144Z",
          "wordCount": 627,
          "title": "Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1\">Ovishake Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Mohtasim Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">MD. Nazrul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1\">Jakaria Rabbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">MD. Kamrul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baz_M/0/1/0/all/0/1\">Mohammed Baz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masud_M/0/1/0/all/0/1\">Mehedi Masud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awal_M/0/1/0/all/0/1\">Md. Abdul Awal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1\">Awal Ahmed Fime</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Md. Tahmid Hasan Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1\">Delowar Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1\">MD. Akil Raihan Iftee</a>",
          "description": "The Bangla language is the seventh most spoken language, with 265 million\nnative and non-native speakers worldwide. However, English is the predominant\nlanguage for online resources and technical knowledge, journals, and\ndocumentation. Consequently, many Bangla-speaking people, who have limited\ncommand of English, face hurdles to utilize English resources. To bridge the\ngap between limited support and increasing demand, researchers conducted many\nexperiments and developed valuable tools and techniques to create and process\nBangla language materials. Many efforts are also ongoing to make it easy to use\nthe Bangla language in the online and technical domains. There are some review\npapers to understand the past, previous, and future Bangla Natural Language\nProcessing (BNLP) trends. The studies are mainly concentrated on the specific\ndomains of BNLP, such as sentiment analysis, speech recognition, optical\ncharacter recognition, and text summarization. There is an apparent scarcity of\nresources that contain a comprehensive study of the recent BNLP tools and\nmethods. Therefore, in this paper, we present a thorough review of 71 BNLP\nresearch papers and categorize them into 11 categories, namely Information\nExtraction, Machine Translation, Named Entity Recognition, Parsing, Parts of\nSpeech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake\nDetection, Text Summarization, Word Sense Disambiguation, and Speech Processing\nand Recognition. We study articles published between 1999 to 2021, and 50% of\nthe papers were published after 2015. We discuss Classical, Machine Learning\nand Deep Learning approaches with different datasets while addressing the\nlimitations and current and future trends of the BNLP.",
          "link": "http://arxiv.org/abs/2105.14875",
          "publishedOn": "2021-06-09T02:01:48.127Z",
          "wordCount": 756,
          "title": "Bangla Natural Language Processing: A Comprehensive Review of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>",
          "description": "Transformer based models, like BERT and RoBERTa, have achieved\nstate-of-the-art results in many Natural Language Processing tasks. However,\ntheir memory footprint, inference latency, and power consumption are\nprohibitive efficient inference at the edge, and even at the data center. While\nquantization can be a viable solution for this, previous work on quantizing\nTransformer based models use floating-point arithmetic during inference, which\ncannot efficiently utilize integer-only logical units such as the recent Turing\nTensor Cores, or traditional integer-only ARM processors. In this work, we\npropose I-BERT, a novel quantization scheme for Transformer based models that\nquantizes the entire inference with integer-only arithmetic. Based on\nlightweight integer-only approximation methods for nonlinear operations, e.g.,\nGELU, Softmax, and Layer Normalization, I-BERT performs an end-to-end\ninteger-only BERT inference without any floating point calculation. We evaluate\nour approach on GLUE downstream tasks using RoBERTa-Base/Large. We show that\nfor both cases, I-BERT achieves similar (and slightly higher) accuracy as\ncompared to the full-precision baseline. Furthermore, our preliminary\nimplementation of I-BERT shows a speedup of 2.4-4.0x for INT8 inference on a T4\nGPU system as compared to FP32 inference. The framework has been developed in\nPyTorch and has been open-sourced.",
          "link": "http://arxiv.org/abs/2101.01321",
          "publishedOn": "2021-06-09T02:01:48.121Z",
          "wordCount": 652,
          "title": "I-BERT: Integer-only BERT Quantization. (arXiv:2101.01321v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.15008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nelson F. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kranzlein_M/0/1/0/all/0/1\">Michael Kranzlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>",
          "description": "In lexical semantics, full-sentence segmentation and segment labeling of\nvarious phenomena are generally treated separately, despite their\ninterdependence. We hypothesize that a unified lexical semantic recognition\ntask is an effective way to encapsulate previously disparate styles of\nannotation, including multiword expression identification / classification and\nsupersense tagging. Using the STREUSLE corpus, we train a neural CRF sequence\ntagger and evaluate its performance along various axes of annotation. As the\nlabel set generalizes that of previous tasks (PARSEME, DiMSUM), we additionally\nevaluate how well the model generalizes to those test sets, finding that it\napproaches or surpasses existing models despite training only on STREUSLE. Our\nwork also establishes baseline models and evaluation metrics for integrated and\naccurate modeling of lexical semantics, facilitating future work in this area.",
          "link": "http://arxiv.org/abs/2004.15008",
          "publishedOn": "2021-06-09T02:01:48.103Z",
          "wordCount": 583,
          "title": "Lexical Semantic Recognition. (arXiv:2004.15008v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1\">Rahul Aralikatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lhoneux_M/0/1/0/all/0/1\">Miryam de Lhoneux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>",
          "description": "This work introduces Itihasa, a large-scale translation dataset containing\n93,000 pairs of Sanskrit shlokas and their English translations. The shlokas\nare extracted from two Indian epics viz., The Ramayana and The Mahabharata. We\nfirst describe the motivation behind the curation of such a dataset and follow\nup with empirical analysis to bring out its nuances. We then benchmark the\nperformance of standard translation models on this corpus and show that even\nstate-of-the-art transformer architectures perform poorly, emphasizing the\ncomplexity of the dataset.",
          "link": "http://arxiv.org/abs/2106.03269",
          "publishedOn": "2021-06-09T02:01:48.097Z",
          "wordCount": 531,
          "title": "Itihasa: A large-scale corpus for Sanskrit to English translation. (arXiv:2106.03269v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Simiao Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minshuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>",
          "description": "The Lottery Ticket Hypothesis suggests that an over-parametrized network\nconsists of ``lottery tickets'', and training a certain collection of them\n(i.e., a subnetwork) can match the performance of the full model. In this\npaper, we study such a collection of tickets, which is referred to as ``winning\ntickets'', in extremely over-parametrized models, e.g., pre-trained language\nmodels. We observe that at certain compression ratios, the generalization\nperformance of the winning tickets can not only match but also exceed that of\nthe full model. In particular, we observe a phase transition phenomenon: As the\ncompression ratio increases, generalization performance of the winning tickets\nfirst improves then deteriorates after a certain threshold. We refer to the\ntickets on the threshold as ``super tickets''. We further show that the phase\ntransition is task and model dependent -- as the model size becomes larger and\nthe training data set becomes smaller, the transition becomes more pronounced.\nOur experiments on the GLUE benchmark show that the super tickets improve\nsingle task fine-tuning by $0.9$ points on BERT-base and $1.0$ points on\nBERT-large, in terms of task-average score. We also demonstrate that adaptively\nsharing the super tickets across tasks benefits multi-task learning.",
          "link": "http://arxiv.org/abs/2105.12002",
          "publishedOn": "2021-06-09T02:01:48.084Z",
          "wordCount": 684,
          "title": "Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization. (arXiv:2105.12002v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hanqi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1\">Gabriele Pergola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>",
          "description": "The Emotion Cause Extraction (ECE)} task aims to identify clauses which\ncontain emotion-evoking information for a particular emotion expressed in text.\nWe observe that a widely-used ECE dataset exhibits a bias that the majority of\nannotated cause clauses are either directly before their associated emotion\nclauses or are the emotion clauses themselves. Existing models for ECE tend to\nexplore such relative position information and suffer from the dataset bias. To\ninvestigate the degree of reliance of existing ECE models on clause relative\npositions, we propose a novel strategy to generate adversarial examples in\nwhich the relative position information is no longer the indicative feature of\ncause clauses. We test the performance of existing models on such adversarial\nexamples and observe a significant performance drop. To address the dataset\nbias, we propose a novel graph-based method to explicitly model the emotion\ntriggering paths by leveraging the commonsense knowledge to enhance the\nsemantic dependencies between a candidate clause and an emotion clause.\nExperimental results show that our proposed approach performs on par with the\nexisting state-of-the-art methods on the original ECE dataset, and is more\nrobust against adversarial attacks compared to existing models.",
          "link": "http://arxiv.org/abs/2106.03518",
          "publishedOn": "2021-06-09T02:01:48.078Z",
          "wordCount": 649,
          "title": "Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction. (arXiv:2106.03518v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hangbo Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "Recent progress of abstractive text summarization largely relies on large\npre-trained sequence-to-sequence Transformer models, which are computationally\nexpensive. This paper aims to distill these large models into smaller ones for\nfaster inference and minimal performance loss. Pseudo-labeling based methods\nare popular in sequence-to-sequence model distillation. In this paper, we find\nsimply manipulating attention temperatures in Transformers can make pseudo\nlabels easier to learn for student models. Our experiments on three\nsummarization datasets show our proposed method consistently improves over\nvanilla pseudo-labeling based methods. We also find that both the pseudo labels\nand summaries produced by our students are shorter and more abstractive. We\nwill make our code and models publicly available.",
          "link": "http://arxiv.org/abs/2106.03441",
          "publishedOn": "2021-06-09T02:01:48.048Z",
          "wordCount": 551,
          "title": "Attention Temperature Matters in Abstractive Summarization Distillation. (arXiv:2106.03441v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1\">Yuan Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>",
          "description": "Scene graphs are semantic abstraction of images that encourage visual\nunderstanding and reasoning. However, the performance of Scene Graph Generation\n(SGG) is unsatisfactory when faced with biased data in real-world scenarios.\nConventional debiasing research mainly studies from the view of balancing data\ndistribution or learning unbiased models and representations, ignoring the\ncorrelations among the biased classes. In this work, we analyze this problem\nfrom a novel cognition perspective: automatically building a hierarchical\ncognitive structure from the biased predictions and navigating that hierarchy\nto locate the relationships, making the tail relationships receive more\nattention in a coarse-to-fine mode. To this end, we propose a novel debiasing\nCognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive\nstructure CogTree to organize the relationships based on the prediction of a\nbiased SGG model. The CogTree distinguishes remarkably different relationships\nat first and then focuses on a small portion of easily confused ones. Then, we\npropose a debiasing loss specially for this cognitive structure, which supports\ncoarse-to-fine distinction for the correct relationships. The loss is\nmodel-agnostic and consistently boosting the performance of several\nstate-of-the-art models. The code is available at:\nhttps://github.com/CYVincent/Scene-Graph-Transformer-CogTree.",
          "link": "http://arxiv.org/abs/2009.07526",
          "publishedOn": "2021-06-09T02:01:48.042Z",
          "wordCount": 677,
          "title": "CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.02251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">He Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Peng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Luchen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1\">Kun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wen Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>",
          "description": "The semantics of a text is manifested not only by what is read, but also by\nwhat is not read. In this article, we will study how the implicit \"not read\"\ninformation such as end-of-paragraph (\\eop) and end-of-sequence (\\eos) affect\nthe quality of text generation. Specifically, we find that the pre-trained\nlanguage model GPT2 can generate better continuations by learning to generate\nthe \\eop in the fine-tuning stage. Experimental results on English story\ngeneration show that \\eop can lead to higher BLEU score and lower \\eos\nperplexity. We also conduct experiments on a self-collected Chinese essay\ndataset with Chinese-GPT2, a character level LM without \\eop or \\eos during\npre-training. Experimental results show that the Chinese GPT2 can generate\nbetter essay endings with \\eop.",
          "link": "http://arxiv.org/abs/2004.02251",
          "publishedOn": "2021-06-09T02:01:48.036Z",
          "wordCount": 614,
          "title": "Semantics of the Unwritten: The Effect of End of Paragraph and Sequence Tokens on Text Generation with GPT2. (arXiv:2004.02251v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.07601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>",
          "description": "Mental health is a critical issue in modern society, and mental disorders\ncould sometimes turn to suicidal ideation without effective treatment. Early\ndetection of mental disorders and suicidal ideation from social content\nprovides a potential way for effective social intervention. However,\nclassifying suicidal ideation and other mental disorders is challenging as they\nshare similar patterns in language usage and sentimental polarity. This paper\nenhances text representation with lexicon-based sentiment scores and latent\ntopics and proposes using relation networks to detect suicidal ideation and\nmental disorders with related risk indicators. The relation module is further\nequipped with the attention mechanism to prioritize more critical relational\nfeatures. Through experiments on three real-world datasets, our model\noutperforms most of its counterparts.",
          "link": "http://arxiv.org/abs/2004.07601",
          "publishedOn": "2021-06-09T02:01:48.030Z",
          "wordCount": 595,
          "title": "Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks. (arXiv:2004.07601v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Silei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semnani_S/0/1/0/all/0/1\">Sina J. Semnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campagna_G/0/1/0/all/0/1\">Giovanni Campagna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1\">Monica S. Lam</a>",
          "description": "We propose AutoQA, a methodology and toolkit to generate semantic parsers\nthat answer questions on databases, with no manual effort. Given a database\nschema and its data, AutoQA automatically generates a large set of high-quality\nquestions for training that covers different database operations. It uses\nautomatic paraphrasing combined with template-based parsing to find alternative\nexpressions of an attribute in different parts of speech. It also uses a novel\nfiltered auto-paraphraser to generate correct paraphrases of entire sentences.\nWe apply AutoQA to the Schema2QA dataset and obtain an average logical form\naccuracy of 62.9% when tested on natural questions, which is only 6.4% lower\nthan a model trained with expert natural language annotations and paraphrase\ndata collected from crowdworkers. To demonstrate the generality of AutoQA, we\nalso apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy,\n16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower\nthan the same model trained with human data.",
          "link": "http://arxiv.org/abs/2010.04806",
          "publishedOn": "2021-06-09T02:01:48.024Z",
          "wordCount": 627,
          "title": "AutoQA: From Databases To QA Semantic Parsers With Only Synthetic Training Data. (arXiv:2010.04806v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>",
          "description": "Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.",
          "link": "http://arxiv.org/abs/2106.04554",
          "publishedOn": "2021-06-09T02:01:48.008Z",
          "wordCount": 537,
          "title": "A Survey of Transformers. (arXiv:2106.04554v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>",
          "description": "Heavily overparameterized language models such as BERT, XLNet and T5 have\nachieved impressive success in many NLP tasks. However, their high model\ncomplexity requires enormous computation resources and extremely long training\ntime for both pre-training and fine-tuning. Many works have studied model\ncompression on large NLP models, but only focusing on reducing inference time\nwhile still requiring an expensive training process. Other works use extremely\nlarge batch sizes to shorten the pre-training time, at the expense of higher\ncomputational resource demands. In this paper, inspired by the Early-Bird\nLottery Tickets recently studied for computer vision tasks, we propose\nEarlyBERT, a general computationally-efficient training algorithm applicable to\nboth pre-training and fine-tuning of large-scale language models. By slimming\nthe self-attention and fully-connected sub-layers inside a transformer, we are\nthe first to identify structured winning tickets in the early stage of BERT\ntraining. We apply those tickets towards efficient BERT training, and conduct\ncomprehensive pre-training and fine-tuning experiments on GLUE and SQuAD\ndownstream tasks. Our results show that EarlyBERT achieves comparable\nperformance to standard BERT, with 35~45% less training time. Code is available\nat https://github.com/VITA-Group/EarlyBERT.",
          "link": "http://arxiv.org/abs/2101.00063",
          "publishedOn": "2021-06-09T02:01:47.997Z",
          "wordCount": 654,
          "title": "EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets. (arXiv:2101.00063v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lianhui Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Shyam Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Luheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faruqui_M/0/1/0/all/0/1\">Manaal Faruqui</a>",
          "description": "Everyday conversations require understanding everyday events, which in turn,\nrequires understanding temporal commonsense concepts interwoven with those\nevents. Despite recent progress with massive pre-trained language models (LMs)\nsuch as T5 and GPT-3, their capability of temporal reasoning in dialogs remains\nlargely under-explored. In this paper, we present the first study to\ninvestigate pre-trained LMs for their temporal reasoning capabilities in\ndialogs by introducing a new task and a crowd-sourced English challenge set,\nTIMEDIAL. We formulate TIME-DIAL as a multiple-choice cloze task with over 1.1K\ncarefully curated dialogs. Empirical results demonstrate that even the best\nperforming models struggle on this task compared to humans, with 23 absolute\npoints of gap in accuracy. Furthermore, our analysis reveals that the models\nfail to reason about dialog context correctly; instead, they rely on shallow\ncues based on existing temporal patterns in context, motivating future research\nfor modeling temporal concepts in text and robust contextual reasoning about\nthem. The dataset is publicly available at:\nhttps://github.com/google-research-datasets/timedial.",
          "link": "http://arxiv.org/abs/2106.04571",
          "publishedOn": "2021-06-09T02:01:47.991Z",
          "wordCount": 587,
          "title": "TIMEDIAL: Temporal Commonsense Reasoning in Dialog. (arXiv:2106.04571v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yu Guo</a>",
          "description": "We introduce an NLP toolkit based on object-oriented knowledge base and\nmulti-level grammar base. This toolkit focuses on semantic parsing, it also has\nabilities to discover new knowledge and grammar automatically, new discovered\nknowledge and grammar will be identified by human, and will be used to update\nthe knowledge base and grammar base. This process can be iterated many times to\nimprove the toolkit continuously.",
          "link": "http://arxiv.org/abs/2105.05227",
          "publishedOn": "2021-06-09T02:01:47.985Z",
          "wordCount": 542,
          "title": "Doing Natural Language Processing in A Natural Way: An NLP toolkit based on object-oriented knowledge base and multi-level grammar base. (arXiv:2105.05227v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Sung-Feng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_S/0/1/0/all/0/1\">Shun-Po Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Da-Rong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Gene-Ping Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Speech separation has been well developed, with the very successful\npermutation invariant training (PIT) approach, although the frequent label\nassignment switching happening during PIT training remains to be a problem when\nbetter convergence speed and achievable performance are desired. In this paper,\nwe propose to perform self-supervised pre-training to stabilize the label\nassignment in training the speech separation model. Experiments over several\ntypes of self-supervised approaches, several typical speech separation models\nand two different datasets showed that very good improvements are achievable if\na proper self-supervised approach is chosen.",
          "link": "http://arxiv.org/abs/2010.15366",
          "publishedOn": "2021-06-09T02:01:47.966Z",
          "wordCount": 563,
          "title": "Stabilizing Label Assignment for Speech Separation by Self-supervised Pre-training. (arXiv:2010.15366v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04383",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hammoud_J/0/1/0/all/0/1\">Jaafar Hammoud</a>, <a href=\"http://arxiv.org/find/math/1/au:+Eisab_A/0/1/0/all/0/1\">Ali Eisab</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dobrenkoa_N/0/1/0/all/0/1\">Natalia Dobrenkoa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gusarovaa_N/0/1/0/all/0/1\">Natalia Gusarovaa</a>",
          "description": "Gradient methods have applications in multiple fields, including signal\nprocessing, image processing, and dynamic systems. In this paper, we present a\nnonlinear gradient method for solving convex supra-quadratic functions by\ndeveloping the search direction, that done by hybridizing between the two\nconjugate coefficients HRM [2] and NHS [1]. The numerical results proved the\neffectiveness of the presented method by applying it to solve standard problems\nand reaching the exact solution if the objective function is quadratic convex.\nAlso presented in this article, an application to the problem of named entities\nin the Arabic medical language, as it proved the stability of the proposed\nmethod and its efficiency in terms of execution time.",
          "link": "http://arxiv.org/abs/2106.04383",
          "publishedOn": "2021-06-09T02:01:47.960Z",
          "wordCount": 565,
          "title": "Using a New Nonlinear Gradient Method for Solving Large Scale Convex Optimization Problems with an Application on Arabic Medical Text. (arXiv:2106.04383v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orlanski_G/0/1/0/all/0/1\">Gabriel Orlanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gittens_A/0/1/0/all/0/1\">Alex Gittens</a>",
          "description": "Answering a programming question using only its title is difficult as salient\ncontextual information is omitted. Based on this observation, we present a\ncorpus of over 40,000 StackOverflow question texts to be used in conjunction\nwith their corresponding intents from the CoNaLa dataset (Yin et al., 2018).\nUsing both the intent and question body, we use BART to establish a baseline\nBLEU score of 34.35 for this new task. We find further improvements of $2.8\\%$\nby combining the mined CoNaLa data with the labeled data to achieve a 35.32\nBLEU score. We evaluate prior state-of-the-art CoNaLa models with this\nadditional data and find that our proposed method of using the body and mined\ndata beats the BLEU score of the prior state-of-the-art by $71.96\\%$. Finally,\nwe perform ablations to demonstrate that BART is an unsupervised multimodal\nlearner and examine its extractive behavior. The code and data can be found\nhttps://github.com/gabeorlanski/stackoverflow-encourages-cheating.",
          "link": "http://arxiv.org/abs/2106.04447",
          "publishedOn": "2021-06-09T02:01:47.955Z",
          "wordCount": 597,
          "title": "Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation. (arXiv:2106.04447v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian-Guo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1\">Kazuma Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "Pretrained Transformer-based models were reported to be robust in intent\nclassification. In this work, we first point out the importance of in-domain\nout-of-scope detection in few-shot intent recognition tasks and then illustrate\nthe vulnerability of pretrained Transformer-based models against samples that\nare in-domain but out-of-scope (ID-OOS). We empirically show that pretrained\nmodels do not perform well on both ID-OOS examples and general out-of-scope\nexamples, especially on fine-grained few-shot intent detection tasks. To figure\nout how the models mistakenly classify ID-OOS intents as in-scope intents, we\nfurther conduct analysis on confidence scores and the overlapping keywords and\nprovide several prospective directions for future work. We release the relevant\nresources to facilitate future research.",
          "link": "http://arxiv.org/abs/2106.04564",
          "publishedOn": "2021-06-09T02:01:47.948Z",
          "wordCount": 562,
          "title": "Are Pretrained Transformers Robust in Intent Classification? A Missing Ingredient in Evaluation of Out-of-Scope Intent Detection. (arXiv:2106.04564v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-09T02:01:47.932Z",
          "wordCount": 569,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.01616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng-Jui Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1\">Lin-shan Lee</a>",
          "description": "Automatic speech recognition (ASR) technologies today are primarily optimized\nfor given datasets; thus, any changes in the application environment (e.g.,\nacoustic conditions or topic domains) may inevitably degrade the performance.\nWe can collect new data describing the new environment and fine-tune the\nsystem, but this naturally leads to higher error rates for the earlier\ndatasets, referred to as catastrophic forgetting. The concept of lifelong\nlearning (LLL) aiming to enable a machine to sequentially learn new tasks from\nnew datasets describing the changing real world without forgetting the\npreviously learned knowledge is thus brought to attention. This paper reports,\nto our knowledge, the first effort to extensively consider and analyze the use\nof various approaches of LLL in end-to-end (E2E) ASR, including proposing novel\nmethods in saving data for past domains to mitigate the catastrophic forgetting\nproblem. An overall relative reduction of 28.7% in WER was achieved compared to\nthe fine-tuning baseline when sequentially learning on three very different\nbenchmark corpora. This can be the first step toward the highly desired ASR\ntechnologies capable of synchronizing with the continuously changing real\nworld.",
          "link": "http://arxiv.org/abs/2104.01616",
          "publishedOn": "2021-06-09T02:01:47.915Z",
          "wordCount": 650,
          "title": "Towards Lifelong Learning of End-to-end ASR. (arXiv:2104.01616v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zi_W/0/1/0/all/0/1\">Wenjie Zi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahidi_H/0/1/0/all/0/1\">Hamidreza Shahidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadar_A/0/1/0/all/0/1\">&#xc1;kos K&#xe1;d&#xe1;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ateeq_J/0/1/0/all/0/1\">Jawad Ateeq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barot_H/0/1/0/all/0/1\">Harsh Barot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alon_M/0/1/0/all/0/1\">Meidan Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>",
          "description": "A natural language database interface (NLDB) can democratize data-driven\ninsights for non-technical users. However, existing Text-to-SQL semantic\nparsers cannot achieve high enough accuracy in the cross-database setting to\nallow good usability in practice. This work presents Turing, a NLDB system\ntoward bridging this gap. The cross-domain semantic parser of Turing with our\nnovel value prediction method achieves $75.1\\%$ execution accuracy, and\n$78.3\\%$ top-5 beam execution accuracy on the Spider validation set. To benefit\nfrom the higher beam accuracy, we design an interactive system where the SQL\nhypotheses in the beam are explained step-by-step in natural language, with\ntheir differences highlighted. The user can then compare and judge the\nhypotheses to select which one reflects their intention if any. The English\nexplanations of SQL queries in Turing are produced by our high-precision\nnatural language generation system based on synchronous grammars.",
          "link": "http://arxiv.org/abs/2106.04559",
          "publishedOn": "2021-06-09T02:01:47.909Z",
          "wordCount": 587,
          "title": "Turing: an Accurate and Interpretable Multi-Hypothesis Cross-Domain Natural Language Database Interface. (arXiv:2106.04559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "The advent of contextual word embeddings -- representations of words which\nincorporate semantic and syntactic information from their context -- has led to\ntremendous improvements on a wide variety of NLP tasks. However, recent\ncontextual models have prohibitively high computational cost in many use-cases\nand are often hard to interpret. In this work, we demonstrate that our proposed\ndistillation method, which is a simple extension of CBOW-based training, allows\nto significantly improve computational efficiency of NLP applications, while\noutperforming the quality of existing static embeddings trained from scratch as\nwell as those distilled from previously proposed methods. As a side-effect, our\napproach also allows a fair comparison of both contextual and static embeddings\nvia standard lexical evaluation tasks.",
          "link": "http://arxiv.org/abs/2106.04302",
          "publishedOn": "2021-06-09T02:01:47.903Z",
          "wordCount": 553,
          "title": "Obtaining Better Static Word Embeddings Using Contextual Embedding Models. (arXiv:2106.04302v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Feifei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canim_M/0/1/0/all/0/1\">Mustafa Canim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_P/0/1/0/all/0/1\">Peter Fox</a>",
          "description": "We present the first end-to-end, transformer-based table question answering\n(QA) system that takes natural language questions and massive table corpus as\ninputs to retrieve the most relevant tables and locate the correct table cells\nto answer the question. Our system, CLTR, extends the current state-of-the-art\nQA over tables model to build an end-to-end table QA architecture. This system\nhas successfully tackled many real-world table QA problems with a simple,\nunified pipeline. Our proposed system can also generate a heatmap of candidate\ncolumns and rows over complex tables and allow users to quickly identify the\ncorrect cells to answer questions. In addition, we introduce two new\nopen-domain benchmarks, E2E_WTQ and E2E_GNQ, consisting of 2,005 natural\nlanguage questions over 76,242 tables. The benchmarks are designed to validate\nCLTR as well as accommodate future table retrieval and end-to-end table QA\nresearch and experiments. Our experiments demonstrate that our system is the\ncurrent state-of-the-art model on the table retrieval task and produces\npromising results for end-to-end table QA.",
          "link": "http://arxiv.org/abs/2106.04441",
          "publishedOn": "2021-06-09T02:01:47.855Z",
          "wordCount": 601,
          "title": "CLTR: An End-to-End, Transformer-Based System for Cell Level TableRetrieval and Table Question Answering. (arXiv:2106.04441v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1\">Daniel Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>",
          "description": "Deep learning algorithms have shown promising results in visual question\nanswering (VQA) tasks, but a more careful look reveals that they often do not\nunderstand the rich signal they are being fed with. To understand and better\nmeasure the generalization capabilities of VQA systems, we look at their\nrobustness to counterfactually augmented data. Our proposed augmentations are\ndesigned to make a focused intervention on a specific property of the question\nsuch that the answer changes. Using these augmentations, we propose a new\nrobustness measure, Robustness to Augmented Data (RAD), which measures the\nconsistency of model predictions between original and augmented examples.\nThrough extensive experimentation, we show that RAD, unlike classical accuracy\nmeasures, can quantify when state-of-the-art systems are not robust to\ncounterfactuals. We find substantial failure cases which reveal that current\nVQA systems are still brittle. Finally, we connect between robustness and\ngeneralization, demonstrating the predictive power of RAD for performance on\nunseen augmentations.",
          "link": "http://arxiv.org/abs/2106.04484",
          "publishedOn": "2021-06-09T02:01:47.849Z",
          "wordCount": 614,
          "title": "Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1\">Rabeeh Karimi Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>",
          "description": "State-of-the-art parameter-efficient fine-tuning methods rely on introducing\nadapter modules between the layers of a pretrained language model. However,\nsuch modules are trained separately for each task and thus do not enable\nsharing information across tasks. In this paper, we show that we can learn\nadapter parameters for all layers and tasks by generating them using shared\nhypernetworks, which condition on task, adapter position, and layer id in a\ntransformer model. This parameter-efficient multi-task learning framework\nallows us to achieve the best of both worlds by sharing knowledge across tasks\nvia hypernetworks while enabling the model to adapt to each individual task\nthrough task-specific adapters. Experiments on the well-known GLUE benchmark\nshow improved performance in multi-task learning while adding only 0.29%\nparameters per task. We additionally demonstrate substantial performance\nimprovements in few-shot domain generalization across a variety of tasks. Our\ncode is publicly available in https://github.com/rabeehk/hyperformer.",
          "link": "http://arxiv.org/abs/2106.04489",
          "publishedOn": "2021-06-09T02:01:47.770Z",
          "wordCount": 580,
          "title": "Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks. (arXiv:2106.04489v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Guoping Hu</a>",
          "description": "Adversarial training (AT) as a regularization method has proved its\neffectiveness on various tasks. Though there are successful applications of AT\non some NLP tasks, the distinguishing characteristics of NLP tasks have not\nbeen exploited. In this paper, we aim to apply AT on machine reading\ncomprehension (MRC) tasks. Furthermore, we adapt AT for MRC tasks by proposing\na novel adversarial training method called PQAT that perturbs the embedding\nmatrix instead of word vectors. To differentiate the roles of passages and\nquestions, PQAT uses additional virtual P/Q-embedding matrices to gather the\nglobal perturbations of words from passages and questions separately. We test\nthe method on a wide range of MRC tasks, including span-based extractive RC and\nmultiple-choice RC. The results show that adversarial training is effective\nuniversally, and PQAT further improves the performance.",
          "link": "http://arxiv.org/abs/2106.04437",
          "publishedOn": "2021-06-09T02:01:47.677Z",
          "wordCount": 576,
          "title": "Adversarial Training for Machine Reading Comprehension with Virtual Embeddings. (arXiv:2106.04437v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1\">Megha Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>",
          "description": "Intelligent and adaptive online education systems aim to make high-quality\neducation available for a diverse range of students. However, existing systems\nusually depend on a pool of hand-made questions, limiting how fine-grained and\nopen-ended they can be in adapting to individual students. We explore targeted\nquestion generation as a controllable sequence generation task. We first show\nhow to fine-tune pre-trained language models for deep knowledge tracing\n(LM-KT). This model accurately predicts the probability of a student answering\na question correctly, and generalizes to questions not seen in training. We\nthen use LM-KT to specify the objective and data for training a model to\ngenerate questions conditioned on the student and target difficulty. Our\nresults show we succeed at generating novel, well-calibrated language\ntranslation questions for second language learners from a real online education\nplatform.",
          "link": "http://arxiv.org/abs/2106.04262",
          "publishedOn": "2021-06-09T02:01:47.656Z",
          "wordCount": 564,
          "title": "Question Generation for Adaptive Education. (arXiv:2106.04262v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1\">Ioannis Kazakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1\">Carles Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1\">Miriam Bellver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1\">Carina Silberer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1\">Xavier Giro-i-Nieto</a>",
          "description": "Recent advances in deep learning have brought significant progress in visual\ngrounding tasks such as language-guided video object segmentation. However,\ncollecting large datasets for these tasks is expensive in terms of annotation\ntime, which represents a bottleneck. To this end, we propose a novel method,\nnamely SynthRef, for generating synthetic referring expressions for target\nobjects in an image (or video frame), and we also present and disseminate the\nfirst large-scale dataset with synthetic referring expressions for video object\nsegmentation. Our experiments demonstrate that by training with our synthetic\nreferring expressions one can improve the ability of a model to generalize\nacross different datasets, without any additional annotation cost. Moreover,\nour formulation allows its application to any object detection or segmentation\ndataset.",
          "link": "http://arxiv.org/abs/2106.04403",
          "publishedOn": "2021-06-09T02:01:47.564Z",
          "wordCount": 584,
          "title": "SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Groschwitz_J/0/1/0/all/0/1\">Jonas Groschwitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowlie_M/0/1/0/all/0/1\">Meaghan Fowlie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1\">Alexander Koller</a>",
          "description": "AM dependency parsing is a method for neural semantic graph parsing that\nexploits the principle of compositionality. While AM dependency parsers have\nbeen shown to be fast and accurate across several graphbanks, they require\nexplicit annotations of the compositional tree structures for training. In the\npast, these were obtained using complex graphbank-specific heuristics written\nby experts. Here we show how they can instead be trained directly on the graphs\nwith a neural latent-variable model, drastically reducing the amount and\ncomplexity of manual heuristics. We demonstrate that our model picks up on\nseveral linguistic phenomena on its own and achieves comparable accuracy to\nsupervised training, greatly facilitating the use of AM dependency parsing for\nnew sembanks.",
          "link": "http://arxiv.org/abs/2106.04398",
          "publishedOn": "2021-06-09T02:01:47.559Z",
          "wordCount": 550,
          "title": "Learning compositional structures for semantic graph parsing. (arXiv:2106.04398v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-06-09T02:01:47.553Z",
          "wordCount": 570,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04506",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Md Faisal Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_Z/0/1/0/all/0/1\">Zalish Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biash_Z/0/1/0/all/0/1\">Zarin Tasnim Biash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryen_A/0/1/0/all/0/1\">Ahmed Ann Noor Ryen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_A/0/1/0/all/0/1\">Arman Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashraf_F/0/1/0/all/0/1\">Faisal Bin Ashraf</a>",
          "description": "Cyberbullying or Online harassment detection on social media for various\nmajor languages is currently being given a good amount of focus by researchers\nworldwide. Being the seventh most speaking language in the world and increasing\nusage of online platform among the Bengali speaking people urge to find\neffective detection technique to handle the online harassment. In this paper,\nwe have proposed binary and multiclass classification model using hybrid neural\nnetwork for bully expression detection in Bengali language. We have used 44,001\nusers comments from popular public Facebook pages, which fall into five classes\n- Non-bully, Sexual, Threat, Troll and Religious. We have examined the\nperformance of our proposed models from different perspective. Our binary\nclassification model gives 87.91% accuracy, whereas introducing ensemble\ntechnique after neural network for multiclass classification, we got 85%\naccuracy.",
          "link": "http://arxiv.org/abs/2106.04506",
          "publishedOn": "2021-06-09T02:01:47.548Z",
          "wordCount": 594,
          "title": "Cyberbullying Detection Using Deep Neural Network from Social Media Comments in Bangla Language. (arXiv:2106.04506v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Junqi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ji_T/0/1/0/all/0/1\">Tuo ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>",
          "description": "Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms,\ntheir corresponding sentiment polarities, and the opinion terms. There exist\nseven subtasks in ABSA. Most studies only focus on the subsets of these\nsubtasks, which leads to various complicated ABSA models while hard to solve\nthese subtasks in a unified framework. In this paper, we redefine every subtask\ntarget as a sequence mixed by pointer indexes and sentiment class indexes,\nwhich converts all ABSA subtasks into a unified generative formulation. Based\non the unified formulation, we exploit the pre-training sequence-to-sequence\nmodel BART to solve all ABSA subtasks in an end-to-end framework. Extensive\nexperiments on four ABSA datasets for seven subtasks demonstrate that our\nframework achieves substantial performance gain and provides a real unified\nend-to-end solution for the whole ABSA subtasks, which could benefit multiple\ntasks.",
          "link": "http://arxiv.org/abs/2106.04300",
          "publishedOn": "2021-06-09T02:01:47.541Z",
          "wordCount": 570,
          "title": "A Unified Generative Framework for Aspect-Based Sentiment Analysis. (arXiv:2106.04300v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damonte_M/0/1/0/all/0/1\">Marco Damonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>",
          "description": "Semantic parsers map natural language utterances to meaning representations.\nThe lack of a single standard for meaning representations led to the creation\nof a plethora of semantic parsing datasets. To unify different datasets and\ntrain a single model for them, we investigate the use of Multi-Task Learning\n(MTL) architectures. We experiment with five datasets (Geoquery, NLMaps, TOP,\nOvernight, AMR). We find that an MTL architecture that shares the entire\nnetwork across datasets yields competitive or better parsing accuracies than\nthe single-task baselines, while reducing the total number of parameters by\n68%. We further provide evidence that MTL has also better compositional\ngeneralization than single-task models. We also present a comparison of task\nsampling methods and propose a competitive alternative to widespread\nproportional sampling strategies.",
          "link": "http://arxiv.org/abs/2106.04476",
          "publishedOn": "2021-06-09T02:01:47.536Z",
          "wordCount": 575,
          "title": "One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task Learning on Semantic Parsing Datasets. (arXiv:2106.04476v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1\">Roberto Dess&#xec;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1\">Eugene Kharitonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1\">Marco Baroni</a>",
          "description": "As deep networks begin to be deployed as autonomous agents, the issue of how\nthey can communicate with each other becomes important. Here, we train two deep\nnets from scratch to perform realistic referent identification through\nunsupervised emergent communication. We show that the largely interpretable\nemergent protocol allows the nets to successfully communicate even about object\ntypes they did not see at training time. The visual representations induced as\na by-product of our training regime, moreover, show comparable quality, when\nre-used as generic visual features, to a recent self-supervised learning model.\nOur results provide concrete evidence of the viability of (interpretable)\nemergent deep net communication in a more realistic scenario than previously\nconsidered, as well as establishing an intriguing link between this field and\nself-supervised visual learning.",
          "link": "http://arxiv.org/abs/2106.04258",
          "publishedOn": "2021-06-09T02:01:47.519Z",
          "wordCount": 580,
          "title": "Interpretable agent communication from scratch(with a generic visual processor emerging on the side). (arXiv:2106.04258v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1\">Da Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "Attention mechanisms have become a standard tool for sequence modeling tasks,\nin particular by stacking self-attention layers over the entire input sequence\nas in the Transformer architecture. In this work we introduce a novel attention\nprocedure called staircase attention that, unlike self-attention, operates\nacross the sequence (in time) recurrently processing the input by adding\nanother step of processing. A step in the staircase comprises of backward\ntokens (encoding the sequence so far seen) and forward tokens (ingesting a new\npart of the sequence), or an extreme Ladder version with a forward step of zero\nthat simply repeats the Transformer on each step of the ladder, sharing the\nweights. We thus describe a family of such models that can trade off\nperformance and compute, by either increasing the amount of recurrence through\ntime, the amount of sequential processing via recurrence in depth, or both.\nStaircase attention is shown to be able to solve tasks that involve tracking\nthat conventional Transformers cannot, due to this recurrence. Further, it is\nshown to provide improved modeling power for the same size model (number of\nparameters) compared to self-attentive Transformers on large language modeling\nand dialogue tasks, yielding significant perplexity gains.",
          "link": "http://arxiv.org/abs/2106.04279",
          "publishedOn": "2021-06-09T02:01:47.513Z",
          "wordCount": 623,
          "title": "Staircase Attention for Recurrent Processing of Sequences. (arXiv:2106.04279v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montella_S/0/1/0/all/0/1\">Sebastien Montella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Barahona_L/0/1/0/all/0/1\">Lina Rojas-Barahona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_J/0/1/0/all/0/1\">Johannes Heinecke</a>",
          "description": "Knowledge Graph (KG) completion has been excessively studied with a massive\nnumber of models proposed for the Link Prediction (LP) task. The main\nlimitation of such models is their insensitivity to time. Indeed, the temporal\naspect of stored facts is often ignored. To this end, more and more works\nconsider time as a parameter to complete KGs. In this paper, we first\ndemonstrate that, by simply increasing the number of negative samples, the\nrecent AttH model can achieve competitive or even better performance than the\nstate-of-the-art on Temporal KGs (TKGs), albeit its nontemporality. We further\npropose Hercules, a time-aware extension of AttH model, which defines the\ncurvature of a Riemannian manifold as the product of both relation and time.\nOur experiments show that both Hercules and AttH achieve competitive or new\nstate-of-the-art performances on ICEWS04 and ICEWS05-15 datasets. Therefore,\none should raise awareness when learning TKGs representations to identify\nwhether time truly boosts performances.",
          "link": "http://arxiv.org/abs/2106.04311",
          "publishedOn": "2021-06-09T02:01:47.508Z",
          "wordCount": 590,
          "title": "Hyperbolic Temporal Knowledge Graph Embeddings with Relational and Time Curvatures. (arXiv:2106.04311v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eirew_A/0/1/0/all/0/1\">Alon Eirew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>",
          "description": "We point out that common evaluation practices for cross-document coreference\nresolution have been unrealistically permissive in their assumed settings,\nyielding inflated results. We propose addressing this issue via two evaluation\nmethodology principles. First, as in other tasks, models should be evaluated on\npredicted mentions rather than on gold mentions. Doing this raises a subtle\nissue regarding singleton coreference clusters, which we address by decoupling\nthe evaluation of mention detection from that of coreference linking. Second,\nwe argue that models should not exploit the synthetic topic structure of the\nstandard ECB+ dataset, forcing models to confront the lexical ambiguity\nchallenge, as intended by the dataset creators. We demonstrate empirically the\ndrastic impact of our more realistic evaluation principles on a competitive\nmodel, yielding a score which is 33 F1 lower compared to evaluating by prior\nlenient practices.",
          "link": "http://arxiv.org/abs/2106.04192",
          "publishedOn": "2021-06-09T02:01:47.502Z",
          "wordCount": 564,
          "title": "Realistic Evaluation Principles for Cross-document Coreference Resolution. (arXiv:2106.04192v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boito_M/0/1/0/all/0/1\">Marcely Zanon Boito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_B/0/1/0/all/0/1\">Bolaji Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ondel_L/0/1/0/all/0/1\">Lucas Ondel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villavicencio_A/0/1/0/all/0/1\">Aline Villavicencio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "When documenting oral-languages, Unsupervised Word Segmentation (UWS) from\nspeech is a useful, yet challenging, task. It can be performed from phonetic\ntranscriptions, or in the absence of these, from the output of unsupervised\nspeech discretization models. These discretization models are trained using raw\nspeech only, producing discrete speech units which can be applied for\ndownstream (text-based) tasks. In this paper we compare five of these models:\nthree Bayesian and two neural approaches, with regards to the exploitability of\nthe produced units for UWS. Two UWS models are experimented with and we report\nresults for Finnish, Hungarian, Mboshi, Romanian and Russian in a low-resource\nsetting (using only 5k sentences). Our results suggest that neural models for\nspeech discretization are difficult to exploit in our setting, and that it\nmight be necessary to adapt them to limit sequence length. We obtain our best\nUWS results by using the SHMM and H-SHMM Bayesian models, which produce high\nquality, yet compressed, discrete representations of the input speech signal.",
          "link": "http://arxiv.org/abs/2106.04298",
          "publishedOn": "2021-06-09T02:01:47.496Z",
          "wordCount": 607,
          "title": "Unsupervised Word Segmentation from Discrete Speech Units in Low-Resource Settings. (arXiv:2106.04298v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1\">Ekin Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Sequence-to-sequence transduction is the core problem in language processing\napplications as diverse as semantic parsing, machine translation, and\ninstruction following. The neural network models that provide the dominant\nsolution to these problems are brittle, especially in low-resource settings:\nthey fail to generalize correctly or systematically from small datasets. Past\nwork has shown that many failures of systematic generalization arise from\nneural models' inability to disentangle lexical phenomena from syntactic ones.\nTo address this, we augment neural decoders with a lexical translation\nmechanism that generalizes existing copy mechanisms to incorporate learned,\ndecontextualized, token-level translation rules. We describe how to initialize\nthis mechanism using a variety of lexicon learning algorithms, and show that it\nimproves systematic generalization on a diverse set of sequence modeling tasks\ndrawn from cognitive science, formal semantics, and machine translation.",
          "link": "http://arxiv.org/abs/2106.03993",
          "publishedOn": "2021-06-09T02:01:47.480Z",
          "wordCount": 559,
          "title": "Lexicon Learning for Few-Shot Neural Sequence Modeling. (arXiv:2106.03993v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1\">Mark Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehouck_M/0/1/0/all/0/1\">Mathieu Dehouck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez Rodr&#xed;guez</a>",
          "description": "We evaluate the efficacy of predicted UPOS tags as input features for\ndependency parsers in lower resource settings to evaluate how treebank size\naffects the impact tagging accuracy has on parsing performance. We do this for\nreal low resource universal dependency treebanks, artificially low resource\ndata with varying treebank sizes, and for very small treebanks with varying\namounts of augmented data. We find that predicted UPOS tags are somewhat\nhelpful for low resource treebanks, especially when fewer fully-annotated trees\nare available. We also find that this positive impact diminishes as the amount\nof data increases.",
          "link": "http://arxiv.org/abs/2106.04222",
          "publishedOn": "2021-06-09T02:01:47.474Z",
          "wordCount": 579,
          "title": "A Falta de Pan, Buenas Son Tortas: The Efficacy of Predicted UPOS Tags for Low Resource UD Parsing. (arXiv:2106.04222v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiacheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Shyam Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faruqui_M/0/1/0/all/0/1\">Manaal Faruqui</a>",
          "description": "Disfluencies is an under-studied topic in NLP, even though it is ubiquitous\nin human conversation. This is largely due to the lack of datasets containing\ndisfluencies. In this paper, we present a new challenge question answering\ndataset, Disfl-QA, a derivative of SQuAD, where humans introduce contextual\ndisfluencies in previously fluent questions. Disfl-QA contains a variety of\nchallenging disfluencies that require a more comprehensive understanding of the\ntext than what was necessary in prior datasets. Experiments show that the\nperformance of existing state-of-the-art question answering models degrades\nsignificantly when tested on Disfl-QA in a zero-shot setting.We show data\naugmentation methods partially recover the loss in performance and also\ndemonstrate the efficacy of using gold data for fine-tuning. We argue that we\nneed large-scale disfluency datasets in order for NLP models to be robust to\nthem. The dataset is publicly available at:\nhttps://github.com/google-research-datasets/disfl-qa.",
          "link": "http://arxiv.org/abs/2106.04016",
          "publishedOn": "2021-06-09T02:01:47.468Z",
          "wordCount": 579,
          "title": "Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering. (arXiv:2106.04016v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zijun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengjiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1\">Tiansi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zelin Dai</a>",
          "description": "Entity Matching (EM) aims at recognizing entity records that denote the same\nreal-world object. Neural EM models learn vector representation of entity\ndescriptions and match entities end-to-end. Though robust, these methods\nrequire many resources for training, and lack of interpretability. In this\npaper, we propose a novel EM framework that consists of Heterogeneous\nInformation Fusion (HIF) and Key Attribute Tree (KAT) Induction to decouple\nfeature representation from matching decision. Using self-supervised learning\nand mask mechanism in pre-trained language modeling, HIF learns the embeddings\nof noisy attribute values by inter-attribute attention with unlabeled data.\nUsing a set of comparison features and a limited amount of annotated data, KAT\nInduction learns an efficient decision tree that can be interpreted by\ngenerating entity matching rules whose structure is advocated by domain\nexperts. Experiments on 6 public datasets and 3 industrial datasets show that\nour method is highly efficient and outperforms SOTA EM models in most cases.\nOur codes and datasets can be obtained from https://github.com/THU-KEG/HIF-KAT.",
          "link": "http://arxiv.org/abs/2106.04174",
          "publishedOn": "2021-06-09T02:01:47.448Z",
          "wordCount": 612,
          "title": "Interpretable and Low-Resource Entity Matching via Decoupling Feature Learning from Decision Making. (arXiv:2106.04174v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1\">Mar Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez Rodr&#xed;guez</a>",
          "description": "We evaluate three leading dependency parser systems from different paradigms\non a small yet diverse subset of languages in terms of their\naccuracy-efficiency Pareto front. As we are interested in efficiency, we\nevaluate core parsers without pretrained language models (as these are\ntypically huge networks and would constitute most of the compute time) or other\naugmentations that can be transversally applied to any of them. Biaffine\nparsing emerges as a well-balanced default choice, with sequence-labelling\nparsing being preferable if inference speed (but not training energy cost) is\nthe priority.",
          "link": "http://arxiv.org/abs/2106.04216",
          "publishedOn": "2021-06-09T02:01:47.442Z",
          "wordCount": 533,
          "title": "A Modest Pareto Optimisation Analysis of Dependency Parsers in 2021. (arXiv:2106.04216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hai Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">He Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zuoyu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yina Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardson_K/0/1/0/all/0/1\">Kyle Richardson</a>",
          "description": "Multilingual transformers (XLM, mT5) have been shown to have remarkable\ntransfer skills in zero-shot settings. Most transfer studies, however, rely on\nautomatically translated resources (XNLI, XQuAD), making it hard to discern the\nparticular linguistic knowledge that is being transferred, and the role of\nexpert annotated monolingual datasets when developing task-specific models. We\ninvestigate the cross-lingual transfer abilities of XLM-R for Chinese and\nEnglish natural language inference (NLI), with a focus on the recent\nlarge-scale Chinese dataset OCNLI. To better understand linguistic transfer, we\ncreated 4 categories of challenge and adversarial tasks (totaling 17 new\ndatasets) for Chinese that build on several well-known resources for English\n(e.g., HANS, NLI stress-tests). We find that cross-lingual models trained on\nEnglish NLI do transfer well across our Chinese tasks (e.g., in 3/4 of our\nchallenge categories, they perform as well/better than the best monolingual\nmodels, even on 3/5 uniquely Chinese linguistic phenomena such as idioms, pro\ndrop). These results, however, come with important caveats: cross-lingual\nmodels often perform best when trained on a mixture of English and high-quality\nmonolingual NLI data (OCNLI), and are often hindered by automatically\ntranslated resources (XNLI-zh). For many phenomena, all models continue to\nstruggle, highlighting the need for our new diagnostics to help benchmark\nChinese and cross-lingual models. All new datasets/code are released at\nhttps://github.com/huhailinguist/ChineseNLIProbing.",
          "link": "http://arxiv.org/abs/2106.03983",
          "publishedOn": "2021-06-09T02:01:47.437Z",
          "wordCount": 672,
          "title": "Investigating Transfer Learning in Multilingual Pre-trained Language Models through Chinese Natural Language Inference. (arXiv:2106.03983v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macherey_W/0/1/0/all/0/1\">Wolfgang Macherey</a>",
          "description": "Self-supervised pre-training of text representations has been successfully\napplied to low-resource Neural Machine Translation (NMT). However, it usually\nfails to achieve notable gains on resource-rich NMT. In this paper, we propose\na joint training approach, $F_2$-XEnDec, to combine self-supervised and\nsupervised learning to optimize NMT models. To exploit complementary\nself-supervised signals for supervised learning, NMT models are trained on\nexamples that are interbred from monolingual and parallel sentences through a\nnew process called crossover encoder-decoder. Experiments on two resource-rich\ntranslation benchmarks, WMT'14 English-German and WMT'14 English-French,\ndemonstrate that our approach achieves substantial improvements over several\nstrong baseline methods and obtains a new state of the art of 46.19 BLEU on\nEnglish-French when incorporating back translation. Results also show that our\napproach is capable of improving model robustness to input perturbations such\nas code-switching noise which frequently appears on social media.",
          "link": "http://arxiv.org/abs/2106.04060",
          "publishedOn": "2021-06-09T02:01:47.420Z",
          "wordCount": 572,
          "title": "Self-supervised and Supervised Joint Training for Resource-rich Machine Translation. (arXiv:2106.04060v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_T/0/1/0/all/0/1\">Tao Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wanyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongjiang Li</a>",
          "description": "Social media is an appropriate source for analyzing public attitudes towards\nthe COVID-19 vaccine and various brands. Nevertheless, there are few relevant\nstudies. In the research, we collected tweet posts by the UK and US residents\nfrom the Twitter API during the pandemic and designed experiments to answer\nthree main questions concerning vaccination. To get the dominant sentiment of\nthe civics, we performed sentiment analysis by VADER and proposed a new method\nthat can count the individual's influence. This allows us to go a step further\nin sentiment analysis and explain some of the fluctuations in the data\nchanging. The results indicated that celebrities could lead the opinion shift\non social media in vaccination progress. Moreover, at the peak, nearly 40\\% of\nthe population in both countries have a negative attitude towards COVID-19\nvaccines. Besides, we investigated how people's opinions toward different\nvaccine brands are. We found that the Pfizer vaccine enjoys the most popular\namong people. By applying the sentiment analysis tool, we discovered most\npeople hold positive views toward the COVID-19 vaccine manufactured by most\nbrands. In the end, we carried out topic modelling by using the LDA model. We\nfound residents in the two countries are willing to share their views and\nfeelings concerning the vaccine. Several death cases have occurred after\nvaccination. Due to these negative events, US residents are more worried about\nthe side effects and safety of the vaccine.",
          "link": "http://arxiv.org/abs/2106.04081",
          "publishedOn": "2021-06-09T02:01:47.407Z",
          "wordCount": 718,
          "title": "Insight from NLP Analysis: COVID-19 Vaccines Sentiments on Social Media. (arXiv:2106.04081v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conklin_H/0/1/0/all/0/1\">Henry Conklin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bailin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kenny Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>",
          "description": "Natural language is compositional; the meaning of a sentence is a function of\nthe meaning of its parts. This property allows humans to create and interpret\nnovel sentences, generalizing robustly outside their prior experience. Neural\nnetworks have been shown to struggle with this kind of generalization, in\nparticular performing poorly on tasks designed to assess compositional\ngeneralization (i.e. where training and testing distributions differ in ways\nthat would be trivial for a compositional strategy to resolve). Their poor\nperformance on these tasks may in part be due to the nature of supervised\nlearning which assumes training and testing data to be drawn from the same\ndistribution. We implement a meta-learning augmented version of supervised\nlearning whose objective directly optimizes for out-of-distribution\ngeneralization. We construct pairs of tasks for meta-learning by sub-sampling\nexisting training data. Each pair of tasks is constructed to contain relevant\nexamples, as determined by a similarity metric, in an effort to inhibit models\nfrom memorizing their input. Experimental results on the COGS and SCAN datasets\nshow that our similarity-driven meta-learning can improve generalization\nperformance.",
          "link": "http://arxiv.org/abs/2106.04252",
          "publishedOn": "2021-06-09T02:01:47.401Z",
          "wordCount": 598,
          "title": "Meta-Learning to Compositionally Generalize. (arXiv:2106.04252v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1\">Piotr Pi&#x119;kos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1\">Henryk Michalewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>",
          "description": "Imagine you are in a supermarket. You have two bananas in your basket and\nwant to buy four apples. How many fruits do you have in total? This seemingly\nstraightforward question can be challenging for data-driven language models,\neven if trained at scale. However, we would expect such generic language models\nto possess some mathematical abilities in addition to typical linguistic\ncompetence. Towards this goal, we investigate if a commonly used language\nmodel, BERT, possesses such mathematical abilities and, if so, to what degree.\nFor that, we fine-tune BERT on a popular dataset for word math problems,\nAQuA-RAT, and conduct several tests to understand learned representations\nbetter. Since we teach models trained on natural language to do formal\nmathematics, we hypothesize that such models would benefit from training on\nsemi-formal steps that explain how math results are derived. To better\naccommodate such training, we also propose new pretext tasks for learning\nmathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or\nNROP). With this new model, we achieve significantly better outcomes than\ndata-driven baselines and even on-par with more tailored models. We also show\nhow to reduce positional bias in such models.",
          "link": "http://arxiv.org/abs/2106.03921",
          "publishedOn": "2021-06-09T02:01:47.387Z",
          "wordCount": 646,
          "title": "Measuring and Improving BERT's Mathematical Abilities by Predicting the Order of Reasoning. (arXiv:2106.03921v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khemchandani_Y/0/1/0/all/0/1\">Yash Khemchandani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehtani_S/0/1/0/all/0/1\">Sarvesh Mehtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_V/0/1/0/all/0/1\">Vaidehi Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1\">Sunita Sarawagi</a>",
          "description": "Recent research in multilingual language models (LM) has demonstrated their\nability to effectively handle multiple languages in a single model. This holds\npromise for low web-resource languages (LRL) as multilingual models can enable\ntransfer of supervision from high resource languages to LRLs. However,\nincorporating a new language in an LM still remains a challenge, particularly\nfor languages with limited corpora and in unseen scripts. In this paper we\nargue that relatedness among languages in a language family may be exploited to\novercome some of the corpora limitations of LRLs, and propose RelateLM. We\nfocus on Indian languages, and exploit relatedness along two dimensions: (1)\nscript (since many Indic scripts originated from the Brahmic script), and (2)\nsentence structure. RelateLM uses transliteration to convert the unseen script\nof limited LRL text into the script of a Related Prominent Language (RPL)\n(Hindi in our case). While exploiting similar sentence structures, RelateLM\nutilizes readily available bilingual dictionaries to pseudo translate RPL text\ninto LRL corpora. Experiments on multiple real-world benchmark datasets provide\nvalidation to our hypothesis that using a related language as pivot, along with\ntransliteration and pseudo translation based data augmentation, can be an\neffective way to adapt LMs for LRLs, rather than direct training or pivoting\nthrough English.",
          "link": "http://arxiv.org/abs/2106.03958",
          "publishedOn": "2021-06-09T02:01:47.381Z",
          "wordCount": 647,
          "title": "Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study. (arXiv:2106.03958v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hongliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haixun Wang</a>",
          "description": "Recently, there is an effort to extend fine-grained entity typing by using a\nricher and ultra-fine set of types, and labeling noun phrases including\npronouns and nominal nouns instead of just named entity mentions. A key\nchallenge for this ultra-fine entity typing task is that human annotated data\nare extremely scarce, and the annotation ability of existing distant or weak\nsupervision approaches is very limited. To remedy this problem, in this paper,\nwe propose to obtain training data for ultra-fine entity typing by using a BERT\nMasked Language Model (MLM). Given a mention in a sentence, our approach\nconstructs an input for the BERT MLM so that it predicts context dependent\nhypernyms of the mention, which can be used as type labels. Experimental\nresults demonstrate that, with the help of these automatically generated\nlabels, the performance of an ultra-fine entity typing model can be improved\nsubstantially. We also show that our approach can be applied to improve\ntraditional fine-grained entity typing after performing simple type mapping.",
          "link": "http://arxiv.org/abs/2106.04098",
          "publishedOn": "2021-06-09T02:01:47.374Z",
          "wordCount": 600,
          "title": "Ultra-Fine Entity Typing with Weak Supervision from a Masked Language Model. (arXiv:2106.04098v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parnell_J/0/1/0/all/0/1\">Jacob Parnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unanue_I/0/1/0/all/0/1\">Inigo Jauregi Unanue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccardi_M/0/1/0/all/0/1\">Massimo Piccardi</a>",
          "description": "To date, most abstractive summarisation models have relied on variants of the\nnegative log-likelihood (NLL) as their training objective. In some cases,\nreinforcement learning has been added to train the models with an objective\nthat is closer to their evaluation measures (e.g. ROUGE). However, the reward\nfunction to be used within the reinforcement learning approach can play a key\nrole for performance and is still partially unexplored. For this reason, in\nthis paper, we propose two reward functions for the task of abstractive\nsummarisation: the first function, referred to as RwB-Hinge, dynamically\nselects the samples for the gradient update. The second function, nicknamed\nRISK, leverages a small pool of strong candidates to inform the reward. In the\nexperiments, we probe the proposed approach by fine-tuning an NLL pre trained\nmodel over nine summarisation datasets of diverse size and nature. The\nexperimental results show a consistent improvement over the negative\nlog-likelihood baselines.",
          "link": "http://arxiv.org/abs/2106.04080",
          "publishedOn": "2021-06-09T02:01:47.366Z",
          "wordCount": 588,
          "title": "RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation. (arXiv:2106.04080v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salesky_E/0/1/0/all/0/1\">Elizabeth Salesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1\">Badr M. Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mielke_S/0/1/0/all/0/1\">Sabrina J. Mielke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klyachko_E/0/1/0/all/0/1\">Elena Klyachko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serikov_O/0/1/0/all/0/1\">Oleg Serikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Ritesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vylomova_E/0/1/0/all/0/1\">Ekaterina Vylomova</a>",
          "description": "While language identification is a fundamental speech and language processing\ntask, for many languages and language families it remains a challenging task.\nFor many low-resource and endangered languages this is in part due to resource\navailability: where larger datasets exist, they may be single-speaker or have\ndifferent domains than desired application scenarios, demanding a need for\ndomain and speaker-invariant language identification systems. This year's\nshared task on robust spoken language identification sought to investigate just\nthis scenario: systems were to be trained on largely single-speaker speech from\none domain, but evaluated on data in other domains recorded from speakers under\ndifferent recording circumstances, mimicking realistic low-resource scenarios.\nWe see that domain and speaker mismatch proves very challenging for current\nmethods which can perform above 95% accuracy in-domain, which domain adaptation\ncan address to some degree, but that these conditions merit further\ninvestigation to make spoken language identification accessible in many\nscenarios.",
          "link": "http://arxiv.org/abs/2106.03895",
          "publishedOn": "2021-06-09T02:01:47.353Z",
          "wordCount": 606,
          "title": "SIGTYP 2021 Shared Task: Robust Spoken Language Identification. (arXiv:2106.03895v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mina Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1\">Chris Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyabor_A/0/1/0/all/0/1\">Alexander Iyabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We release a new benchmark for lexical substitution, the task of finding\nappropriate substitutes for a target word in a context. To assist humans with\nwriting, lexical substitution systems can suggest words that humans cannot\neasily think of. However, existing benchmarks depend on human recall as the\nonly source of data, and therefore lack coverage of the substitutes that would\nbe most helpful to humans. Furthermore, annotators often provide substitutes of\nlow quality, which are not actually appropriate in the given context. We\ncollect higher-coverage and higher-quality data by framing lexical substitution\nas a classification problem, guided by the intuition that it is easier for\nhumans to judge the appropriateness of candidate substitutes than conjure them\nfrom memory. To this end, we use a context-free thesaurus to produce candidates\nand rely on human judgement to determine contextual appropriateness. Compared\nto the previous largest benchmark, our Swords benchmark has 4.1x more\nsubstitutes per target word for the same level of quality, and its substitutes\nare 1.5x more appropriate (based on human judgement) for the same number of\nsubstitutes.",
          "link": "http://arxiv.org/abs/2106.04102",
          "publishedOn": "2021-06-09T02:01:47.346Z",
          "wordCount": 621,
          "title": "Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality. (arXiv:2106.04102v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Van_H/0/1/0/all/0/1\">Hoang Van</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vikas Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>",
          "description": "We propose a simple and effective strategy for data augmentation for\nlow-resource machine reading comprehension (MRC). Our approach first pretrains\nthe answer extraction components of a MRC system on the augmented data that\ncontains approximate context of the correct answers, before training it on the\nexact answer spans. The approximate context helps the QA method components in\nnarrowing the location of the answers. We demonstrate that our simple strategy\nsubstantially improves both document retrieval and answer extraction\nperformance by providing larger context of the answers and additional training\ndata. In particular, our method significantly improves the performance of BERT\nbased retriever (15.12\\%), and answer extractor (4.33\\% F1) on TechQA, a\ncomplex, low-resource MRC task. Further, our data augmentation strategy yields\nsignificant improvements of up to 3.9\\% exact match (EM) and 2.7\\% F1 for\nanswer extraction on PolicyQA, another practical but moderate sized QA dataset\nthat also contains long answer spans.",
          "link": "http://arxiv.org/abs/2106.04134",
          "publishedOn": "2021-06-09T02:01:47.340Z",
          "wordCount": 603,
          "title": "Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading. (arXiv:2106.04134v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demszky_D/0/1/0/all/0/1\">Dorottya Demszky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mancenido_Z/0/1/0/all/0/1\">Zid Mancenido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Julie Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_H/0/1/0/all/0/1\">Heather Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>",
          "description": "In conversation, uptake happens when a speaker builds on the contribution of\ntheir interlocutor by, for example, acknowledging, repeating or reformulating\nwhat they have said. In education, teachers' uptake of student contributions\nhas been linked to higher student achievement. Yet measuring and improving\nteachers' uptake at scale is challenging, as existing methods require expensive\nannotation by experts. We propose a framework for computationally measuring\nuptake, by (1) releasing a dataset of student-teacher exchanges extracted from\nUS math classroom transcripts annotated for uptake by experts; (2) formalizing\nuptake as pointwise Jensen-Shannon Divergence (pJSD), estimated via next\nutterance classification; (3) conducting a linguistically-motivated comparison\nof different unsupervised measures and (4) correlating these measures with\neducational outcomes. We find that although repetition captures a significant\npart of uptake, pJSD outperforms repetition-based baselines, as it is capable\nof identifying a wider range of uptake phenomena like question answering and\nreformulation. We apply our uptake measure to three different educational\ndatasets with outcome indicators. Unlike baseline measures, pJSD correlates\nsignificantly with instruction quality in all three, providing evidence for its\ngeneralizability and for its potential to serve as an automated professional\ndevelopment tool for teachers.",
          "link": "http://arxiv.org/abs/2106.03873",
          "publishedOn": "2021-06-09T02:01:47.302Z",
          "wordCount": 626,
          "title": "Measuring Conversational Uptake: A Case Study on Student-Teacher Interactions. (arXiv:2106.03873v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangmin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathewson_K/0/1/0/all/0/1\">Kory Mathewson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirby_S/0/1/0/all/0/1\">Simon Kirby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kenny Smith</a>",
          "description": "Researchers are now using deep learning models to explore the emergence of\nlanguage in various language games, where simulated agents interact and develop\nan emergent language to solve a task. Although it is quite intuitive that\ndifferent types of language games posing different communicative challenges\nmight require emergent languages which encode different levels of information,\nthere is no existing work exploring the expressivity of the emergent languages.\nIn this work, we propose a definition of partial order between expressivity\nbased on the generalisation performance across different language games. We\nalso validate the hypothesis that expressivity of emergent languages is a\ntrade-off between the complexity and unpredictability of the context those\nlanguages are used in. Our second novel contribution is introducing contrastive\nloss into the implementation of referential games. We show that using our\ncontrastive loss alleviates the collapse of message types seen using standard\nreferential loss functions.",
          "link": "http://arxiv.org/abs/2106.03982",
          "publishedOn": "2021-06-09T02:01:47.259Z",
          "wordCount": 592,
          "title": "Expressivity of Emergent Language is a Trade-off between Contextual Complexity and Unpredictability. (arXiv:2106.03982v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1\">Ignacio Tampe Palma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1\">Marcelo Mendoza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1\">Evangelos Milios</a>",
          "description": "Summarization has usually relied on gold standard summaries to train\nextractive or abstractive models. Social media brings a hurdle to summarization\ntechniques since it requires addressing a multi-document multi-author approach.\nWe address this challenging task by introducing a novel method that generates\nabstractive summaries of online news discussions. Our method extends a\nBERT-based architecture, including an attention encoding that fed comments'\nlikes during the training stage. To train our model, we define a task which\nconsists of reconstructing high impact comments based on popularity (likes).\nAccordingly, our model learns to summarize online discussions based on their\nmost relevant comments. Our novel approach provides a summary that represents\nthe most relevant aspects of a news item that users comment on, incorporating\nthe social context as a source of information to summarize texts in online\nsocial networks. Our model is evaluated using ROUGE scores between the\ngenerated summary and each comment on the thread. Our model, including the\nsocial attention encoding, significantly outperforms both extractive and\nabstractive summarization methods based on such evaluation.",
          "link": "http://arxiv.org/abs/2106.03953",
          "publishedOn": "2021-06-09T02:01:47.245Z",
          "wordCount": 600,
          "title": "Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gilda_S/0/1/0/all/0/1\">Shlok Gilda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1\">Mirela Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giovanini_L/0/1/0/all/0/1\">Luiz Giovanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1\">Daniela Oliveira</a>",
          "description": "This paper investigates the use of machine learning models for the\nclassification of unhealthy online conversations containing one or more forms\nof subtler abuse, such as hostility, sarcasm, and generalization. We leveraged\na public dataset of 44K online comments containing healthy and unhealthy\ncomments labeled with seven forms of subtle toxicity. We were able to\ndistinguish between these comments with a top micro F1-score, macro F1-score,\nand ROC-AUC of 88.76%, 67.98%, and 0.71, respectively. Hostile comments were\neasier to detect than other types of unhealthy comments. We also conducted a\nsentiment analysis which revealed that most types of unhealthy comments were\nassociated with a slight negative sentiment, with hostile comments being the\nmost negative ones.",
          "link": "http://arxiv.org/abs/2106.03952",
          "publishedOn": "2021-06-09T02:01:47.223Z",
          "wordCount": 544,
          "title": "Predicting Different Types of Subtle Toxicity in Unhealthy Online Conversations. (arXiv:2106.03952v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjit Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "Abductive reasoning starts from some observations and aims at finding the\nmost plausible explanation for these observations. To perform abduction, humans\noften make use of temporal and causal inferences, and knowledge about how some\nhypothetical situation can result in different outcomes. This work offers the\nfirst study of how such knowledge impacts the Abductive NLI task -- which\nconsists in choosing the more likely explanation for given observations. We\ntrain a specialized language model LMI that is tasked to generate what could\nhappen next from a hypothetical scenario that evolves from a given event. We\nthen propose a multi-task model MTL to solve the Abductive NLI task, which\npredicts a plausible explanation by a) considering different possible events\nemerging from candidate hypotheses -- events generated by LMI -- and b)\nselecting the one that is most similar to the observed outcome. We show that\nour MTL model improves over prior vanilla pre-trained LMs fine-tuned on\nAbductive NLI. Our manual evaluation and analysis suggest that learning about\npossible next events from different hypothetical scenarios supports abductive\ninference.",
          "link": "http://arxiv.org/abs/2106.03973",
          "publishedOn": "2021-06-09T02:01:47.160Z",
          "wordCount": 611,
          "title": "Generating Hypothetical Events for Abductive Inference. (arXiv:2106.03973v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>",
          "description": "Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.",
          "link": "http://arxiv.org/abs/2105.11601",
          "publishedOn": "2021-06-09T00:28:49.118Z",
          "wordCount": 641,
          "title": "Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>",
          "description": "Recent years have seen the paradigm shift of Named Entity Recognition (NER)\nsystems from sequence labeling to span prediction. Despite its preliminary\neffectiveness, the span prediction model's architectural bias has not been\nfully understood. In this paper, we first investigate the strengths and\nweaknesses when the span prediction model is used for named entity recognition\ncompared with the sequence labeling framework and how to further improve it,\nwhich motivates us to make complementary advantages of systems based on\ndifferent paradigms. We then reveal that span prediction, simultaneously, can\nserve as a system combiner to re-recognize named entities from different\nsystems' outputs. We experimentally implement 154 systems on 11 datasets,\ncovering three languages, comprehensive results show the effectiveness of span\nprediction models that both serve as base NER systems and system combiners. We\nmake all code and datasets available: \\url{https://github.com/neulab/spanner},\nas well as an online system demo: \\url{this http URL}. Our model also has\nbeen deployed into the ExplainaBoard platform, which allows users to flexibly\nperform a system combination of top-scoring systems in an interactive way:\n\\url{this http URL}.",
          "link": "http://arxiv.org/abs/2106.00641",
          "publishedOn": "2021-06-08T22:44:24.222Z",
          "wordCount": 625,
          "title": "SpanNER: Named Entity Re-/Recognition as Span Prediction. (arXiv:2106.00641v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jialu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cong Yu</a>",
          "description": "Effectively modeling text-rich fresh content such as news articles at\ndocument-level is a challenging problem. To ensure a content-based model\ngeneralize well to a broad range of applications, it is critical to have a\ntraining dataset that is large beyond the scale of human labels while achieving\ndesired quality. In this work, we address those two challenges by proposing a\nnovel approach to mine semantically-relevant fresh documents, and their topic\nlabels, with little human supervision. Meanwhile, we design a multitask model\ncalled NewsEmbed that alternatively trains a contrastive learning with a\nmulti-label classification to derive a universal document encoder. We show that\nthe proposed approach can provide billions of high quality organic training\nexamples and can be naturally extended to multilingual setting where texts in\ndifferent languages are encoded in the same semantic space. We experimentally\ndemonstrate NewsEmbed's competitive performance across multiple natural\nlanguage understanding tasks, both supervised and unsupervised.",
          "link": "http://arxiv.org/abs/2106.00590",
          "publishedOn": "2021-06-08T22:44:24.202Z",
          "wordCount": 603,
          "title": "NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1\">Abhishek Nadgeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1\">Anson Bastos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Kuldeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1\">Isaiah Onando Mulang&#x27;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1\">Johannes Hoffart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1\">Saeedeh Shekarpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraswat_V/0/1/0/all/0/1\">Vijay Saraswat</a>",
          "description": "We present a novel method for relation extraction (RE) from a single\nsentence, mapping the sentence and two given entities to a canonical fact in a\nknowledge graph (KG). Especially in this presumed sentential RE setting, the\ncontext of a single sentence is often sparse. This paper introduces the KGPool\nmethod to address this sparsity, dynamically expanding the context with\nadditional facts from the KG. It learns the representation of these facts\n(entity alias, entity descriptions, etc.) using neural methods, supplementing\nthe sentential context. Unlike existing methods that statically use all\nexpanded facts, KGPool conditions this expansion on the sentence. We study the\nefficacy of KGPool by evaluating it with different neural models and KGs\n(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets\nshows that by feeding the KGPool representation into a Graph Neural Network,\nthe overall method is significantly more accurate than state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2106.00459",
          "publishedOn": "2021-06-08T22:44:23.904Z",
          "wordCount": 606,
          "title": "KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction. (arXiv:2106.00459v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:28.103Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xiao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Soomin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Natural language processing techniques have demonstrated promising results in\nkeyphrase generation. However, one of the major challenges in \\emph{neural}\nkeyphrase generation is processing long documents using deep neural networks.\nGenerally, documents are truncated before given as inputs to neural networks.\nConsequently, the models may miss essential points conveyed in the target\ndocument. To overcome this limitation, we propose \\emph{SEG-Net}, a neural\nkeyphrase generation model that is composed of two major components, (1) a\nselector that selects the salient sentences in a document and (2) an\nextractor-generator that jointly extracts and generates keyphrases from the\nselected sentences. SEG-Net uses Transformer, a self-attentive architecture, as\nthe basic building block with a novel \\emph{layer-wise} coverage attention to\nsummarize most of the points discussed in the document. The experimental\nresults on seven keyphrase generation benchmarks from scientific and web\ndocuments demonstrate that SEG-Net outperforms the state-of-the-art neural\ngenerative methods by a large margin.",
          "link": "http://arxiv.org/abs/2008.01739",
          "publishedOn": "2021-06-08T02:20:25.941Z",
          "wordCount": 617,
          "title": "Select, Extract and Generate: Neural Keyphrase Generation with Layer-wise Coverage Attention. (arXiv:2008.01739v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1\">Harsh Jhamtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "Multiple different responses are often plausible for a given open domain\ndialog context. Prior work has shown the importance of having multiple valid\nreference responses for meaningful and robust automated evaluations. In such\ncases, common practice has been to collect more human written references.\nHowever, such collection can be expensive, time consuming, and not easily\nscalable. Instead, we propose a novel technique for automatically expanding a\nhuman generated reference to a set of candidate references. We fetch plausible\nreferences from knowledge sources, and adapt them so that they are more fluent\nin context of the dialog instance in question. More specifically, we use (1) a\ncommonsense knowledge base to elicit a large number of plausible reactions\ngiven the dialog history (2) relevant instances retrieved from dialog corpus,\nusing similar past as well as future contexts. We demonstrate that our\nautomatically expanded reference sets lead to large improvements in\ncorrelations of automated metrics with human ratings of system outputs for\nDailyDialog dataset.",
          "link": "http://arxiv.org/abs/2106.02833",
          "publishedOn": "2021-06-08T02:20:25.888Z",
          "wordCount": 597,
          "title": "Improving Automated Evaluation of Open Domain Dialog via Diverse Reference Augmentation. (arXiv:2106.02833v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yingjun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holla_N/0/1/0/all/0/1\">Nithin Holla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1\">Xiantong Zhen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1\">Cees G.M. Snoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>",
          "description": "A critical challenge faced by supervised word sense disambiguation (WSD) is\nthe lack of large annotated datasets with sufficient coverage of words in their\ndiversity of senses. This inspired recent research on few-shot WSD using\nmeta-learning. While such work has successfully applied meta-learning to learn\nnew word senses from very few examples, its performance still lags behind its\nfully supervised counterpart. Aiming to further close this gap, we propose a\nmodel of semantic memory for WSD in a meta-learning setting. Semantic memory\nencapsulates prior experiences seen throughout the lifetime of the model, which\naids better generalization in limited data settings. Our model is based on\nhierarchical variational inference and incorporates an adaptive memory update\nrule via a hypernetwork. We show our model advances the state of the art in\nfew-shot WSD, supports effective learning in extremely data scarce (e.g.\none-shot) scenarios and produces meaning prototypes that capture similar senses\nof distinct words.",
          "link": "http://arxiv.org/abs/2106.02960",
          "publishedOn": "2021-06-08T02:20:25.844Z",
          "wordCount": 591,
          "title": "Meta-Learning with Variational Semantic Memory for Word Sense Disambiguation. (arXiv:2106.02960v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingkai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jinfeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cleland_Huang_J/0/1/0/all/0/1\">Jane Cleland-Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Automatic construction of a taxonomy supports many applications in\ne-commerce, web search, and question answering. Existing taxonomy expansion or\ncompletion methods assume that new concepts have been accurately extracted and\ntheir embedding vectors learned from the text corpus. However, one critical and\nfundamental challenge in fixing the incompleteness of taxonomies is the\nincompleteness of the extracted concepts, especially for those whose names have\nmultiple words and consequently low frequency in the corpus. To resolve the\nlimitations of extraction-based methods, we propose GenTaxo to enhance taxonomy\ncompletion by identifying positions in existing taxonomies that need new\nconcepts and then generating appropriate concept names. Instead of relying on\nthe corpus for concept embeddings, GenTaxo learns the contextual embeddings\nfrom their surrounding graph-based and language-based relational information,\nand leverages the corpus for pre-training a concept name generator.\nExperimental results demonstrate that GenTaxo improves the completeness of\ntaxonomies over existing methods.",
          "link": "http://arxiv.org/abs/2106.02974",
          "publishedOn": "2021-06-08T02:20:25.482Z",
          "wordCount": 581,
          "title": "Enhancing Taxonomy Completion with Concept Generation via Fusing Relational Representations. (arXiv:2106.02974v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1\">Freddy C. Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel P. Duffy</a>",
          "description": "We address the challenge of extracting structured information from business\ndocuments without detailed annotations. We propose Deep Conditional\nProbabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional\ncomplex documents and use Recursive Neural Networks to create an end-to-end\nsystem for finding the most probable parse that represents the structured\ninformation to be extracted. This system is trained end-to-end with scanned\ndocuments as input and only relational-records as labels. The\nrelational-records are extracted from existing databases avoiding the cost of\nannotating documents by hand. We apply this approach to extract information\nfrom scanned invoices achieving state-of-the-art results despite using no\nhand-annotations.",
          "link": "http://arxiv.org/abs/2103.05908",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00994",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_S/0/1/0/all/0/1\">Siyuan Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Vel&#xe1;zquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scharenborg_O/0/1/0/all/0/1\">Odette Scharenborg</a>",
          "description": "This paper tackles automatically discovering phone-like acoustic units (AUD)\nfrom unlabeled speech data. Past studies usually proposed single-step\napproaches. We propose a two-stage approach: the first stage learns a\nsubword-discriminative feature representation and the second stage applies\nclustering to the learned representation and obtains phone-like clusters as the\ndiscovered acoustic units. In the first stage, a recently proposed method in\nthe task of unsupervised subword modeling is improved by replacing a\nmonolingual out-of-domain (OOD) ASR system with a multilingual one to create a\nsubword-discriminative representation that is more language-independent. In the\nsecond stage, segment-level k-means is adopted, and two methods to represent\nthe variable-length speech segments as fixed-dimension feature vectors are\ncompared. Experiments on a very low-resource Mboshi language corpus show that\nour approach outperforms state-of-the-art AUD in both normalized mutual\ninformation (NMI) and F-score. The multilingual ASR improved upon the\nmonolingual ASR in providing OOD phone labels and in estimating the phone\nboundaries. A comparison of our systems with and without knowing the\nground-truth phone boundaries showed a 16% NMI performance gap, suggesting that\nthe current approach can significantly benefit from improved phone boundary\nestimation.",
          "link": "http://arxiv.org/abs/2104.00994",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation. (arXiv:2104.00994v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Onabola_O/0/1/0/all/0/1\">Olawale Onabola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhuang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akera_B/0/1/0/all/0/1\">Benjamin Akera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibraheem_A/0/1/0/all/0/1\">Abdulrahman Ibraheem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jia Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dianbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Subtle and overt racism is still present both in physical and online\ncommunities today and has impacted many lives in different segments of the\nsociety. In this short piece of work, we present how we're tackling this\nsocietal issue with Natural Language Processing. We are releasing BiasCorp, a\ndataset containing 139,090 comments and news segment from three specific\nsources - Fox News, BreitbartNews and YouTube. The first batch (45,000 manually\nannotated) is ready for publication. We are currently in the final phase of\nmanually labeling the remaining dataset using Amazon Mechanical Turk. BERT has\nbeen used widely in several downstream tasks. In this work, we present hBERT,\nwhere we modify certain layers of the pretrained BERT model with the new\nHopfield Layer. hBert generalizes well across different distributions with the\nadded advantage of a reduced model complexity. We are also releasing a\nJavaScript library and a Chrome Extension Application, to help developers make\nuse of our trained model in web applications (say chat application) and for\nusers to identify and report racially biased contents on the web respectively.",
          "link": "http://arxiv.org/abs/2104.02242",
          "publishedOn": "2021-06-08T02:20:25.283Z",
          "wordCount": null,
          "title": "hBert + BiasCorp -- Fighting Racism on the Web. (arXiv:2104.02242v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feijun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuxiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Task-oriented dialogue (ToD) benchmarks provide an important avenue to\nmeasure progress and develop better conversational agents. However, existing\ndatasets for end-to-end ToD modeling are limited to a single language,\nhindering the development of robust end-to-end ToD systems for multilingual\ncountries and regions. Here we introduce BiToD, the first bilingual\nmulti-domain dataset for end-to-end task-oriented dialogue modeling. BiToD\ncontains over 7k multi-domain dialogues (144k utterances) with a large and\nrealistic bilingual knowledge base. It serves as an effective benchmark for\nevaluating bilingual ToD systems and cross-lingual transfer learning\napproaches. We provide state-of-the-art baselines under three evaluation\nsettings (monolingual, bilingual, and cross-lingual). The analysis of our\nbaselines in different settings highlights 1) the effectiveness of training a\nbilingual ToD system compared to two independent monolingual ToD systems, and\n2) the potential of leveraging a bilingual knowledge base and cross-lingual\ntransfer learning to improve the system performance under low resource\ncondition.",
          "link": "http://arxiv.org/abs/2106.02787",
          "publishedOn": "2021-06-08T02:20:25.159Z",
          "wordCount": 588,
          "title": "BiToD: A Bilingual Multi-Domain Dataset For Task-Oriented Dialogue Modeling. (arXiv:2106.02787v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Goal-oriented conversational interfaces are designed to accomplish specific\ntasks and typically have interactions that tend to span multiple turns adhering\nto a pre-defined structure and a goal. However, conventional neural language\nmodels (NLM) in Automatic Speech Recognition (ASR) systems are mostly trained\nsentence-wise with limited context. In this paper, we explore different ways to\nincorporate context into a LSTM based NLM in order to model long range\ndependencies and improve speech recognition. Specifically, we use context carry\nover across multiple turns and use lexical contextual cues such as system\ndialog act from Natural Language Understanding (NLU) models and the user\nprovided structure of the chatbot. We also propose a new architecture that\nutilizes context embeddings derived from BERT on sample utterances provided\nduring inference time. Our experiments show a word error rate (WER) relative\nreduction of 7% over non-contextual utterance-level NLM rescorers on\ngoal-oriented audio datasets.",
          "link": "http://arxiv.org/abs/2103.10325",
          "publishedOn": "2021-06-08T02:20:25.064Z",
          "wordCount": 625,
          "title": "Contextual Biasing of Language Models for Speech Recognition in Goal-Oriented Conversational Agents. (arXiv:2103.10325v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.15060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Ye Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jonathan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>",
          "description": "This paper introduces PnG BERT, a new encoder model for neural TTS. This\nmodel is augmented from the original BERT model, by taking both phoneme and\ngrapheme representations of text as input, as well as the word-level alignment\nbetween them. It can be pre-trained on a large text corpus in a self-supervised\nmanner, and fine-tuned in a TTS task. Experimental results show that a neural\nTTS model using a pre-trained PnG BERT as its encoder yields more natural\nprosody and more accurate pronunciation than a baseline model using only\nphoneme input with no pre-training. Subjective side-by-side preference\nevaluations show that raters have no statistically significant preference\nbetween the speech synthesized using a PnG BERT and ground truth recordings\nfrom professional speakers.",
          "link": "http://arxiv.org/abs/2103.15060",
          "publishedOn": "2021-06-08T02:20:25.058Z",
          "wordCount": 609,
          "title": "PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS. (arXiv:2103.15060v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1\">Robert Turko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what they\nhave learned, and how they can improve. We present Dodrio, an open-source\ninteractive visualization tool to help NLP researchers and practitioners\nanalyze attention mechanisms in transformer-based models with linguistic\nknowledge. Dodrio tightly integrates an overview that summarizes the roles of\ndifferent attention heads, and detailed views that help users compare attention\nweights with the syntactic structure and semantic information in the input\ntext. To facilitate the visual comparison of attention weights and linguistic\nknowledge, Dodrio applies different graph visualization techniques to represent\nattention weights scalable to longer input text. Case studies highlight how\nDodrio provides insights into understanding the attention mechanism in\ntransformer-based models. Dodrio is available at\nhttps://poloclub.github.io/dodrio/.",
          "link": "http://arxiv.org/abs/2103.14625",
          "publishedOn": "2021-06-08T02:20:24.906Z",
          "wordCount": null,
          "title": "Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-08T02:20:24.903Z",
          "wordCount": null,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuyi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianping Shen</a>",
          "description": "This paper presents the PALI team's winning system for SemEval-2021 Task 2:\nMultilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune\nXLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to\ndetermine whether the target word in the two contexts contains the same meaning\nor not. In the implementation, we first specifically design an input tag to\nemphasize the target word in the contexts. Second, we construct a new vector on\nthe fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected\nnetwork to output the probability of whether the target word in the context has\nthe same meaning or not. The new vector is attained by concatenating the\nembedding of the [CLS] token and the embeddings of the target word in the\ncontexts. In training, we explore several tricks, such as the Ranger optimizer,\ndata augmentation, and adversarial training, to improve the model prediction.\nConsequently, we attain first place in all four cross-lingual tasks.",
          "link": "http://arxiv.org/abs/2104.10375",
          "publishedOn": "2021-06-08T02:20:24.658Z",
          "wordCount": null,
          "title": "PALI at SemEval-2021 Task 2: Fine-Tune XLM-RoBERTa for Word in Context Disambiguation. (arXiv:2104.10375v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallat_J/0/1/0/all/0/1\">Jonas Wallat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaspreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Avishek Anand</a>",
          "description": "Probing complex language models has recently revealed several insights into\nlinguistic and semantic patterns found in the learned representations. In this\narticle, we probe BERT specifically to understand and measure the relational\nknowledge it captures in its parametric memory. While probing for linguistic\nunderstanding is commonly applied to all layers of BERT as well as fine-tuned\nmodels, this has not been done for factual knowledge. We utilize existing\nknowledge base completion tasks (LAMA) to probe every layer of pre-trained as\nwell as fine-tuned BERT models(ranking, question answering, NER). Our findings\nshow that knowledge is not just contained in BERT's final layers. Intermediate\nlayers contribute a significant amount (17-60%) to the total knowledge found.\nProbing intermediate layers also reveals how different types of knowledge\nemerge at varying rates. When BERT is fine-tuned, relational knowledge is\nforgotten. The extent of forgetting is impacted by the fine-tuning objective\nand the training data. We found that ranking models forget the least and retain\nmore knowledge in their final layer compared to masked language modeling and\nquestion-answering. However, masked language modeling performed the best at\nacquiring new knowledge from the training data. When it comes to learning\nfacts, we found that capacity and fact density are key factors. We hope this\ninitial work will spur further research into understanding the parametric\nmemory of language models and the effect of training objectives on factual\nknowledge. The code to repeat the experiments is publicly available on GitHub.",
          "link": "http://arxiv.org/abs/2106.02902",
          "publishedOn": "2021-06-08T02:20:23.795Z",
          "wordCount": 682,
          "title": "BERTnesia: Investigating the capture and forgetting of knowledge in BERT. (arXiv:2106.02902v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1\">Patrick Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wen Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.",
          "link": "http://arxiv.org/abs/2106.02658",
          "publishedOn": "2021-06-08T02:20:22.981Z",
          "wordCount": 516,
          "title": "W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gros_D/0/1/0/all/0/1\">David Gros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>",
          "description": "Humans are increasingly interacting with machines through language, sometimes\nin contexts where the user may not know they are talking to a machine (like\nover the phone or a text chatbot). We aim to understand how system designers\nand researchers might allow their systems to confirm its non-human identity. We\ncollect over 2,500 phrasings related to the intent of ``Are you a robot?\". This\nis paired with over 2,500 adversarially selected utterances where only\nconfirming the system is non-human would be insufficient or disfluent. We\ncompare classifiers to recognize the intent and discuss the precision/recall\nand model complexity tradeoffs. Such classifiers could be integrated into\ndialog systems to avoid undesired deception. We then explore how both a\ngenerative research model (Blender) as well as two deployed systems (Amazon\nAlexa, Google Assistant) handle this intent, finding that systems often fail to\nconfirm their non-human identity. Finally, we try to understand what a good\nresponse to the intent would be, and conduct a user study to compare the\nimportant aspects when responding to this intent.",
          "link": "http://arxiv.org/abs/2106.02692",
          "publishedOn": "2021-06-08T02:20:22.359Z",
          "wordCount": 616,
          "title": "The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity. (arXiv:2106.02692v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chengguang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1\">Ruiying Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jian Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>",
          "description": "Aiming at expanding few-shot relations' coverage in knowledge graphs (KGs),\nfew-shot knowledge graph completion (FKGC) has recently gained more research\ninterests. Some existing models employ a few-shot relation's multi-hop neighbor\ninformation to enhance its semantic representation. However, noise neighbor\ninformation might be amplified when the neighborhood is excessively sparse and\nno neighbor is available to represent the few-shot relation. Moreover, modeling\nand inferring complex relations of one-to-many (1-N), many-to-one (N-1), and\nmany-to-many (N-N) by previous knowledge graph completion approaches requires\nhigh model complexity and a large amount of training instances. Thus, inferring\ncomplex relations in the few-shot scenario is difficult for FKGC models due to\nlimited training instances. In this paper, we propose a few-shot relational\nlearning with global-local framework to address the above issues. At the global\nstage, a novel gated and attentive neighbor aggregator is built for accurately\nintegrating the semantics of a few-shot relation's neighborhood, which helps\nfiltering the noise neighbors even if a KG contains extremely sparse\nneighborhoods. For the local stage, a meta-learning based TransH (MTransH)\nmethod is designed to model complex relations and train our model in a few-shot\nlearning fashion. Extensive experiments show that our model outperforms the\nstate-of-the-art FKGC approaches on the frequently-used benchmark datasets\nNELL-One and Wiki-One. Compared with the strong baseline model MetaR, our model\nachieves 5-shot FKGC performance improvements of 8.0% on NELL-One and 2.8% on\nWiki-One by the metric Hits@10.",
          "link": "http://arxiv.org/abs/2104.13095",
          "publishedOn": "2021-06-08T02:20:22.169Z",
          "wordCount": 725,
          "title": "Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion. (arXiv:2104.13095v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henderson_M/0/1/0/all/0/1\">Matthew Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>",
          "description": "We propose ConVEx (Conversational Value Extractor), an efficient pretraining\nand fine-tuning neural approach for slot-labeling dialog tasks. Instead of\nrelying on more general pretraining objectives from prior work (e.g., language\nmodeling, response selection), ConVEx's pretraining objective, a novel pairwise\ncloze task using Reddit data, is well aligned with its intended usage on\nsequence labeling tasks. This enables learning domain-specific slot labelers by\nsimply fine-tuning decoding layers of the pretrained general-purpose sequence\nlabeling model, while the majority of the pretrained model's parameters are\nkept frozen. We report state-of-the-art performance of ConVEx across a range of\ndiverse domains and data sets for dialog slot-labeling, with the largest gains\nin the most challenging, few-shot setups. We believe that ConVEx's reduced\npretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its\nefficient fine-tuning and strong performance, promise wider portability and\nscalability for data-efficient sequence-labeling tasks in general.",
          "link": "http://arxiv.org/abs/2010.11791",
          "publishedOn": "2021-06-08T02:20:22.147Z",
          "wordCount": 595,
          "title": "ConVEx: Data-Efficient and Few-Shot Slot Labeling. (arXiv:2010.11791v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1\">Xiaoyi Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Meizhi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyuan Zhou</a>",
          "description": "Question answering from semi-structured tables can be seen as a semantic\nparsing task and is significant and practical for pushing the boundary of\nnatural language understanding. Existing research mainly focuses on\nunderstanding contents from unstructured evidence, e.g., news, natural language\nsentences, and documents. The task of verification from structured evidence,\nsuch as tables, charts, and databases, is still less explored. This paper\ndescribes sattiy team's system in SemEval-2021 task 9: Statement Verification\nand Evidence Finding with Tables (SEM-TAB-FACT). This competition aims to\nverify statements and to find evidence from tables for scientific articles and\nto promote the proper interpretation of the surrounding article. In this paper,\nwe exploited ensemble models of pre-trained language models over tables, TaPas\nand TaBERT, for Task A and adjust the result based on some rules extracted for\nTask B. Finally, in the leaderboard, we attain the F1 scores of 0.8496 and\n0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1\nscore of 0.4856 in Task B.",
          "link": "http://arxiv.org/abs/2104.10366",
          "publishedOn": "2021-06-08T02:20:22.037Z",
          "wordCount": 657,
          "title": "Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables. (arXiv:2104.10366v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1\">Srikanth Ronanki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Neural Language Models (NLM), when trained and evaluated with context\nspanning multiple utterances, have been shown to consistently outperform both\nconventional n-gram language models and NLMs that use limited context. In this\npaper, we investigate various techniques to incorporate turn based context\nhistory into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent\nbased NLMs, we explore context carry over mechanism and feature based\naugmentation, where we incorporate other forms of contextual information such\nas bot response and system dialogue acts as classified by a Natural Language\nUnderstanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem\nwith contextual NLM, we propose the use of attention layer over lexical\nmetadata to improve feature based augmentation. Additionally, we adapt our\ncontextual NLM towards user provided on-the-fly speech patterns by leveraging\nencodings from a large pre-trained masked language model and performing fusion\nwith a Transformer-XL based NLM. We test our proposed models using N-best\nrescoring of ASR hypotheses of task-oriented dialogues and also evaluate on\ndownstream NLU tasks such as intent classification and slot labeling. The best\nperforming model shows a relative WER between 1.6% and 9.1% and a slot labeling\nF1 score improvement of 4% over non-contextual baselines.",
          "link": "http://arxiv.org/abs/2104.11070",
          "publishedOn": "2021-06-08T02:20:22.023Z",
          "wordCount": 676,
          "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liguori_P/0/1/0/all/0/1\">Pietro Liguori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Hossami_E/0/1/0/all/0/1\">Erfan Al-Hossami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotroneo_D/0/1/0/all/0/1\">Domenico Cotroneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natella_R/0/1/0/all/0/1\">Roberto Natella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cukic_B/0/1/0/all/0/1\">Bojan Cukic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1\">Samira Shaikh</a>",
          "description": "We take the first step to address the task of automatically generating\nshellcodes, i.e., small pieces of code used as a payload in the exploitation of\na software vulnerability, starting from natural language comments. We assemble\nand release a novel dataset (Shellcode_IA32), consisting of challenging but\ncommon assembly instructions with their natural language descriptions. We\nexperiment with standard methods in neural machine translation (NMT) to\nestablish baseline performance levels on this task.",
          "link": "http://arxiv.org/abs/2104.13100",
          "publishedOn": "2021-06-08T02:20:21.731Z",
          "wordCount": 543,
          "title": "Shellcode_IA32: A Dataset for Automatic Shellcode Generation. (arXiv:2104.13100v2 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:21.706Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Siqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>",
          "description": "Transformer has become ubiquitous in the deep learning field. One of the key\ningredients that destined its success is the self-attention mechanism, which\nallows fully-connected contextual encoding over input tokens. However, despite\nits effectiveness in modeling short sequences, self-attention suffers when\nhandling inputs with extreme long-range dependencies, as its complexity grows\nquadratically with respect to the sequence length. Therefore, long sequences\nare often encoded by Transformer in chunks using a sliding window. In this\npaper, we propose Cluster-Former, a novel clustering-based sparse Transformer\nto perform attention across chunked sequences. The proposed framework is\npivoted on two unique types of Transformer layer: Sliding-Window Layer and\nCluster-Former Layer, which encode local sequence information and global\ncontext jointly and iteratively. This new design allows information integration\nbeyond local windows, which is especially beneficial for question answering\n(QA) tasks that rely on long-range dependencies. Experiments show that\nCluster-Former achieves state-of-the-art performance on several major QA\nbenchmarks.",
          "link": "http://arxiv.org/abs/2009.06097",
          "publishedOn": "2021-06-08T02:20:21.699Z",
          "wordCount": 623,
          "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding. (arXiv:2009.06097v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:21.652Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norton_T/0/1/0/all/0/1\">Thomas Norton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Understanding privacy policies is crucial for users as it empowers them to\nlearn about the information that matters to them. Sentences written in a\nprivacy policy document explain privacy practices, and the constituent text\nspans convey further specific information about that practice. We refer to\npredicting the privacy practice explained in a sentence as intent\nclassification and identifying the text spans sharing specific information as\nslot filling. In this work, we propose PolicyIE, an English corpus consisting\nof 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of\nwebsites and mobile applications. PolicyIE corpus is a challenging real-world\nbenchmark with limited labeled examples reflecting the cost of collecting\nlarge-scale annotations from domain experts. We present two alternative neural\napproaches as baselines, (1) intent classification and slot filling as a joint\nsequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq)\nlearning task. The experiment results show that both approaches perform\ncomparably in intent classification, while the Seq2Seq method outperforms the\nsequence tagging approach in slot filling by a large margin. We perform a\ndetailed error analysis to reveal the challenges of the proposed corpus.",
          "link": "http://arxiv.org/abs/2101.00123",
          "publishedOn": "2021-06-08T02:20:21.587Z",
          "wordCount": 652,
          "title": "Intent Classification and Slot Filling for Privacy Policies. (arXiv:2101.00123v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.",
          "link": "http://arxiv.org/abs/2010.14439",
          "publishedOn": "2021-06-08T02:20:21.562Z",
          "wordCount": 631,
          "title": "Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiyue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_L/0/1/0/all/0/1\">Lawrence S. Moss</a>",
          "description": "Deep learning (DL) based language models achieve high performance on various\nbenchmarks for Natural Language Inference (NLI). And at this time, symbolic\napproaches to NLI are receiving less attention. Both approaches (symbolic and\nDL) have their advantages and weaknesses. However, currently, no method\ncombines them in a system to solve the task of NLI. To merge symbolic and deep\nlearning methods, we propose an inference framework called NeuralLog, which\nutilizes both a monotonicity-based logical inference engine and a neural\nnetwork language model for phrase alignment. Our framework models the NLI task\nas a classic search problem and uses the beam search algorithm to search for\noptimal inference paths. Experiments show that our joint logic and neural\ninference system improves accuracy on the NLI task and can achieve state-of-art\naccuracy on the SICK and MED datasets.",
          "link": "http://arxiv.org/abs/2105.14167",
          "publishedOn": "2021-06-08T02:20:21.356Z",
          "wordCount": 601,
          "title": "NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning. (arXiv:2105.14167v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:21.199Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Prasoon Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.",
          "link": "http://arxiv.org/abs/2106.02972",
          "publishedOn": "2021-06-08T02:20:21.183Z",
          "wordCount": 625,
          "title": "Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.11015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingtao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xinyi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuejiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>",
          "description": "It is common for people to create different types of charts to explore a\nmulti-dimensional dataset (table). However, to recommend commonly composed\ncharts in real world, one should take the challenges of efficiency, imbalanced\ndata and table context into consideration. In this paper, we propose\nTable2Charts framework which learns common patterns from a large corpus of\n(table, charts) pairs. Based on deep Q-learning with copying mechanism and\nheuristic searching, Table2Charts does table-to-sequence generation, where each\nsequence follows a chart template. On a large spreadsheet corpus with 165k\ntables and 266k charts, we show that Table2Charts could learn a shared\nrepresentation of table fields so that recommendation tasks on different chart\ntypes could mutually enhance each other. Table2Charts outperforms other chart\nrecommendation systems in both multi-type task (with doubled recall numbers\nR@3=0.61 and R@1=0.43) and human evaluations.",
          "link": "http://arxiv.org/abs/2008.11015",
          "publishedOn": "2021-06-08T02:20:21.152Z",
          "wordCount": 626,
          "title": "Table2Charts: Recommending Charts by Learning Shared Table Representations. (arXiv:2008.11015v3 [cs.DB] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.",
          "link": "http://arxiv.org/abs/2103.09593",
          "publishedOn": "2021-06-08T02:20:21.141Z",
          "wordCount": 652,
          "title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>",
          "description": "Recent pretrained language models \"solved\" many reading comprehension\nbenchmarks, where questions are written with access to the evidence document.\nHowever, datasets containing information-seeking queries where evidence\ndocuments are provided after the queries are written independently remain\nchallenging. We analyze why answering information-seeking queries is more\nchallenging and where their prevalent unanswerabilities arise, on Natural\nQuestions and TyDi QA. Our controlled experiments suggest two headrooms --\nparagraph selection and answerability prediction, i.e. whether the paired\nevidence document contains the answer to the query or not. When provided with a\ngold paragraph and knowing when to abstain from answering, existing models\neasily outperform a human annotator. However, predicting answerability itself\nremains challenging. We manually annotate 800 unanswerable examples across six\nlanguages on what makes them challenging to answer. With this new data, we\nconduct per-category answerability prediction, revealing issues in the current\ndataset collection as well as task formulation. Together, our study points to\navenues for future research in information-seeking question answering, both for\ndataset creation and model development.",
          "link": "http://arxiv.org/abs/2010.11915",
          "publishedOn": "2021-06-08T02:20:21.119Z",
          "wordCount": 640,
          "title": "Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval. (arXiv:2010.11915v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuyi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1\">Xiaoyi Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>",
          "description": "This paper describes MagicPai's system for SemEval 2021 Task 7, HaHackathon:\nDetecting and Rating Humor and Offense. This task aims to detect whether the\ntext is humorous and how humorous it is. There are four subtasks in the\ncompetition. In this paper, we mainly present our solution, a multi-task\nlearning model based on adversarial examples, for task 1a and 1b. More\nspecifically, we first vectorize the cleaned dataset and add the perturbation\nto obtain more robust embedding representations. We then correct the loss via\nthe confidence level. Finally, we perform interactive joint learning on\nmultiple tasks to capture the relationship between whether the text is humorous\nand how humorous it is. The final result shows the effectiveness of our system.",
          "link": "http://arxiv.org/abs/2104.10336",
          "publishedOn": "2021-06-08T02:20:21.109Z",
          "wordCount": 612,
          "title": "MagicPai at SemEval-2021 Task 7: Method for Detecting and Rating Humor Based on Multi-Task Adversarial Training. (arXiv:2104.10336v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shih-ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Multi-hop question answering requires models to gather information from\ndifferent parts of a text to answer a question. Most current approaches learn\nto address this task in an end-to-end way with neural networks, without\nmaintaining an explicit representation of the reasoning process. We propose a\nmethod to extract a discrete reasoning chain over the text, which consists of a\nseries of sentences leading to the answer. We then feed the extracted chains to\na BERT-based QA model to do final answer prediction. Critically, we do not rely\non gold annotated chains or \"supporting facts:\" at training time, we derive\npseudogold reasoning chains using heuristics based on named entity recognition\nand coreference resolution. Nor do we rely on these annotations at test time,\nas our model learns to extract chains from raw text alone. We test our approach\non two recently proposed large multi-hop question answering datasets: WikiHop\nand HotpotQA, and achieve state-of-art performance on WikiHop and strong\nperformance on HotpotQA. Our analysis shows the properties of chains that are\ncrucial for high performance: in particular, modeling extraction sequentially\nis important, as is dealing with each candidate sentence in a context-aware\nway. Furthermore, human evaluation shows that our extracted chains allow humans\nto give answers with high confidence, indicating that these are a strong\nintermediate abstraction for this task.",
          "link": "http://arxiv.org/abs/1910.02610",
          "publishedOn": "2021-06-08T02:20:21.060Z",
          "wordCount": 670,
          "title": "Multi-hop Question Answering via Reasoning Chains. (arXiv:1910.02610v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.02995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiangming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_M/0/1/0/all/0/1\">Matt Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>",
          "description": "Complex reasoning over text requires understanding and chaining together\nfree-form predicates and logical connectives. Prior work has largely tried to\ndo this either symbolically or with black-box transformers. We present a middle\nground between these two extremes: a compositional model reminiscent of neural\nmodule networks that can perform chained logical reasoning. This model first\nfinds relevant sentences in the context and then chains them together using\nneural modules. Our model gives significant performance improvements (up to\n29\\% relative error reduction when comfibined with a reranker) on ROPES, a\nrecently introduced complex reasoning dataset.",
          "link": "http://arxiv.org/abs/2004.02995",
          "publishedOn": "2021-06-08T02:20:21.026Z",
          "wordCount": 551,
          "title": "Multi-Step Inference for Reasoning Over Paragraphs. (arXiv:2004.02995v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gabriel_S/0/1/0/all/0/1\">Saadia Gabriel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_R/0/1/0/all/0/1\">Rahul Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While neural language models can generate text with remarkable fluency and\ncoherence, controlling for factual correctness in generation remains an open\nresearch question. This major discrepancy between the surface-level fluency and\nthe content-level correctness of neural generation has motivated a new line of\nresearch that seeks automatic metrics for evaluating the factuality of machine\ntext. In this paper, we introduce GO FIGURE, a meta-evaluation framework for\nevaluating factuality evaluation metrics. We propose five necessary and\nintuitive conditions to evaluate factuality metrics on diagnostic factuality\ndata across three different summarization tasks. Our benchmark analysis on ten\nfactuality metrics reveals that our meta-evaluation framework provides a robust\nand efficient evaluation that is extensible to multiple types of factual\nconsistency and standard generation metrics, including QA metrics. It also\nreveals that while QA metrics generally improve over standard metrics that\nmeasure factuality across domains, performance is highly dependent on the way\nin which questions are generated.",
          "link": "http://arxiv.org/abs/2010.12834",
          "publishedOn": "2021-06-08T02:20:21.017Z",
          "wordCount": 616,
          "title": "GO FIGURE: A Meta Evaluation of Factuality in Summarization. (arXiv:2010.12834v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyser_C/0/1/0/all/0/1\">Cal Peyser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rybach_D/0/1/0/all/0/1\">David Rybach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>",
          "description": "We introduce Lookup-Table Language Models (LookupLM), a method for scaling up\nthe size of RNN language models with only a constant increase in the floating\npoint operations, by increasing the expressivity of the embedding table. In\nparticular, we instantiate an (additional) embedding table which embeds the\nprevious n-gram token sequence, rather than a single token. This allows the\nembedding table to be scaled up arbitrarily -- with a commensurate increase in\nperformance -- without changing the token vocabulary. Since embeddings are\nsparsely retrieved from the table via a lookup; increasing the size of the\ntable adds neither extra operations to each forward pass nor extra parameters\nthat need to be stored on limited GPU/TPU memory. We explore scaling n-gram\nembedding tables up to nearly a billion parameters. When trained on a 3-billion\nsentence corpus, we find that LookupLM improves long tail log perplexity by\n2.44 and long tail WER by 23.4% on a downstream speech recognition task over a\nstandard RNN language model baseline, an improvement comparable to a scaling up\nthe baseline by 6.2x the number of floating point operations.",
          "link": "http://arxiv.org/abs/2104.04552",
          "publishedOn": "2021-06-08T02:20:21.004Z",
          "wordCount": 667,
          "title": "Lookup-Table Recurrent Language Models for Long Tail Speech Recognition. (arXiv:2104.04552v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pretrained language models (PLMs) perform poorly under adversarial attacks.\nTo improve the adversarial robustness, adversarial data augmentation (ADA) has\nbeen widely adopted to cover more search space of adversarial attacks by adding\ntextual adversarial examples during training. However, the number of\nadversarial examples for text augmentation is still extremely insufficient due\nto the exponentially large attack search space. In this work, we propose a\nsimple and effective method to cover a much larger proportion of the attack\nsearch space, called Adversarial and Mixup Data Augmentation (AMDA).\nSpecifically, AMDA linearly interpolates the representations of pairs of\ntraining samples to form new virtual samples, which are more abundant and\ndiverse than the discrete text adversarial examples in conventional ADA.\nMoreover, to fairly evaluate the robustness of different models, we adopt a\nchallenging evaluation setup, which generates a new set of adversarial examples\ntargeting each model. In text classification experiments of BERT and RoBERTa,\nAMDA achieves significant robustness gains under two strong adversarial attacks\nand alleviates the performance degradation of ADA on the clean data. Our code\nis available at: https://github.com/thunlp/MixADA .",
          "link": "http://arxiv.org/abs/2012.15699",
          "publishedOn": "2021-06-08T02:20:20.995Z",
          "wordCount": 666,
          "title": "Better Robustness by More Coverage: Adversarial Training with Mixup Augmentation for Robust Fine-tuning. (arXiv:2012.15699v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Ye Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zixun Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_L/0/1/0/all/0/1\">Lu Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>",
          "description": "This study develops a calibrated beam-based algorithm with global awareness\nfor neural abstractive summarization, aiming to improve the local optimality\nproblem of the original beam search in a rigorous way. Specifically, a novel\nglobal protocol is proposed based on the attention distribution to stipulate\nhow a global optimal hypothesis should attend to the source. A global scoring\nfunction is then developed to regulate beam search to generate summaries in a\nmore near-global optimal fashion. This novel design enjoys a distinctive\nproperty, i.e. the global attention distribution could be predicted before\ninference, enabling stepwise improvements on the beam search through the global\nscoring function. Extensive experiments on $9$ datasets show that the\nglobal-aware inference significantly improves state-of-the-art summarization\nmodels even using empirical hyper-parameters. The algorithm is also proven\nrobust as it remains to generate meaningful texts with corrupted attention\ndistributions. The codes and a comprehensive set of examples are available.",
          "link": "http://arxiv.org/abs/2009.06891",
          "publishedOn": "2021-06-08T02:20:20.879Z",
          "wordCount": 620,
          "title": "Global-aware Beam Search for Neural Abstractive Summarization. (arXiv:2009.06891v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1\">Jacob Goldberger</a>",
          "description": "We introduce a new approach for smoothing and improving the quality of word\nembeddings. We consider a method of fusing word embeddings that were trained on\nthe same corpus but with different initializations. We project all the models\nto a shared vector space using an efficient implementation of the Generalized\nProcrustes Analysis (GPA) procedure, previously used in multilingual word\ntranslation. Our word representation demonstrates consistent improvements over\nthe raw models as well as their simplistic average, on a range of tasks. As the\nnew representations are more stable and reliable, there is a noticeable\nimprovement in rare word evaluations.",
          "link": "http://arxiv.org/abs/2106.02954",
          "publishedOn": "2021-06-08T02:20:20.848Z",
          "wordCount": 533,
          "title": "Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yudong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>",
          "description": "Social media has become a valuable resource for the study of suicidal\nideation and the assessment of suicide risk. Among social media platforms,\nReddit has emerged as the most promising one due to its anonymity and its focus\non topic-based communities (subreddits) that can be indicative of someone's\nstate of mind or interest regarding mental health disorders such as\nr/SuicideWatch, r/Anxiety, r/depression. A challenge for previous work on\nsuicide risk assessment has been the small amount of labeled data. We propose\nan empirical investigation into several classes of weakly-supervised\napproaches, and show that using pseudo-labeling based on related issues around\nmental health (e.g., anxiety, depression) helps improve model performance for\nsuicide risk assessment.",
          "link": "http://arxiv.org/abs/2106.02792",
          "publishedOn": "2021-06-08T02:20:20.839Z",
          "wordCount": 554,
          "title": "Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related Domains. (arXiv:2106.02792v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1\">Mai ElSherief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Existing work on automated hate speech classification assumes that the\ndataset is fixed and the classes are pre-defined. However, the amount of data\nin social media increases every day, and the hot topics changes rapidly,\nrequiring the classifiers to be able to continuously adapt to new data without\nforgetting the previously learned knowledge. This ability, referred to as\nlifelong learning, is crucial for the real-word application of hate speech\nclassifiers in social media. In this work, we propose lifelong learning of hate\nspeech classification on social media. To alleviate catastrophic forgetting, we\npropose to use Variational Representation Learning (VRL) along with a memory\nmodule based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural\nNetwork). Experimentally, we show that combining variational representation\nlearning and the LB-SOINN memory module achieves better performance than the\ncommonly-used lifelong learning techniques.",
          "link": "http://arxiv.org/abs/2106.02821",
          "publishedOn": "2021-06-08T02:20:20.826Z",
          "wordCount": 568,
          "title": "Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanuja_S/0/1/0/all/0/1\">Simran Khanuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>",
          "description": "Pre-trained multilingual language models (LMs) have achieved state-of-the-art\nresults in cross-lingual transfer, but they often lead to an inequitable\nrepresentation of languages due to limited capacity, skewed pre-training data,\nand sub-optimal vocabularies. This has prompted the creation of an ever-growing\npre-trained model universe, where each model is trained on large amounts of\nlanguage or domain specific data with a carefully curated, linguistically\ninformed vocabulary. However, doing so brings us back full circle and prevents\none from leveraging the benefits of multilinguality. To address the gaps at\nboth ends of the spectrum, we propose MergeDistill, a framework to merge\npre-trained LMs in a way that can best leverage their assets with minimal\ndependencies, using task-agnostic knowledge distillation. We demonstrate the\napplicability of our framework in a practical setting by leveraging\npre-existing teacher LMs and training student LMs that perform competitively\nwith or even outperform teacher LMs trained on several orders of magnitude more\ndata and with a fixed model capacity. We also highlight the importance of\nteacher selection and its impact on student model performance.",
          "link": "http://arxiv.org/abs/2106.02834",
          "publishedOn": "2021-06-08T02:20:20.787Z",
          "wordCount": 600,
          "title": "MergeDistill: Merging Pre-trained Language Models using Distillation. (arXiv:2106.02834v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uyttendaele_X/0/1/0/all/0/1\">Xander Uyttendaele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>",
          "description": "We propose MultiOpEd, an open-domain news editorial corpus that supports\nvarious tasks pertaining to the argumentation structure in news editorials,\nfocusing on automatic perspective discovery. News editorial is a genre of\npersuasive text, where the argumentation structure is usually implicit.\nHowever, the arguments presented in an editorial typically center around a\nconcise, focused thesis, which we refer to as their perspective. MultiOpEd aims\nat supporting the study of multiple tasks relevant to automatic perspective\ndiscovery, where a system is expected to produce a single-sentence thesis\nstatement summarizing the arguments presented. We argue that identifying and\nabstracting such natural language perspectives from editorials is a crucial\nstep toward studying the implicit argumentation structure in news editorials.\nWe first discuss the challenges and define a few conceptual tasks towards our\ngoal. To demonstrate the utility of MultiOpEd and the induced tasks, we study\nthe problem of perspective summarization in a multi-task learning setting, as a\ncase study. We show that, with the induced tasks as auxiliary tasks, we can\nimprove the quality of the perspective summary generated. We hope that\nMultiOpEd will be a useful resource for future studies on argumentation in the\nnews editorial domain.",
          "link": "http://arxiv.org/abs/2106.02725",
          "publishedOn": "2021-06-08T02:20:20.776Z",
          "wordCount": 617,
          "title": "MultiOpEd: A Corpus of Multi-Perspective News Editorials. (arXiv:2106.02725v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1\">Kartik Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "While recent work has shown that scores from models trained by the ubiquitous\nmasked language modeling (MLM) objective effectively discriminate probable and\nimprobable sequences, it is still an open question if these MLMs specify a\nprincipled probability distribution over the space of possible sequences. In\nthis paper, we interpret MLMs as energy-based sequence models and propose two\nenergy parametrizations derivable from the trained MLMs. In order to draw\nsamples correctly from these models, we develop a tractable \\emph{sampling}\nscheme based on the Metropolis--Hastings Monte Carlo algorithm. In our\napproach, samples are proposed from the same masked conditionals used for\ntraining the masked language models, and they are accepted or rejected based on\ntheir energy values according to the target distribution. We validate the\neffectiveness of the proposed parametrizations by exploring the quality of\nsamples drawn from these energy-based models on the conditional generation task\nof machine translation. We theoretically and empirically justify our sampling\nalgorithm by showing that the masked conditionals on their own do not yield a\nMarkov chain whose stationary distribution is that of our target distribution,\nand our approach generates higher quality samples than other recently proposed\nundirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,\n2019).",
          "link": "http://arxiv.org/abs/2106.02736",
          "publishedOn": "2021-06-08T02:20:20.767Z",
          "wordCount": 634,
          "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jesse Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>",
          "description": "To build agents that can collaborate effectively with others, recent research\nhas trained artificial agents to communicate with each other in Lewis-style\nreferential games. However, this often leads to successful but uninterpretable\ncommunication. We argue that this is due to the game objective: communicating\nabout a single object in a shared visual context is prone to overfitting and\ndoes not encourage language useful beyond concrete reference. In contrast,\nhuman language conveys a rich variety of abstract ideas. To promote such\nskills, we propose games that require communicating generalizations over sets\nof objects representing abstract visual concepts, optionally with separate\ncontexts for each agent. We find that these games greatly improve systematicity\nand interpretability of the learned languages, according to several metrics in\nthe literature. Finally, we propose a method for identifying logical operations\nembedded in the emergent languages by learning an approximate compositional\nreconstruction of the language.",
          "link": "http://arxiv.org/abs/2106.02668",
          "publishedOn": "2021-06-08T02:20:20.733Z",
          "wordCount": 568,
          "title": "Emergent Communication of Generalizations. (arXiv:2106.02668v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1\">Joel Lamy-Poirier</a>",
          "description": "The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n\nIn addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.",
          "link": "http://arxiv.org/abs/2106.02679",
          "publishedOn": "2021-06-08T02:20:20.719Z",
          "wordCount": 646,
          "title": "Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiexi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jiaxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Dazhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1\">Weiran Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Most language understanding models in task-oriented dialog systems are\ntrained on a small amount of annotated training data, and evaluated in a small\nset from the same distribution. However, these models can lead to system\nfailure or undesirable output when being exposed to natural language\nperturbation or variation in practice. In this paper, we conduct comprehensive\nevaluation and analysis with respect to the robustness of natural language\nunderstanding models, and introduce three important aspects related to language\nunderstanding in real-world dialog systems, namely, language variety, speech\ncharacteristics, and noise perturbation. We propose a model-agnostic toolkit\nLAUG to approximate natural language perturbations for testing the robustness\nissues in task-oriented dialog. Four data augmentation approaches covering the\nthree aspects are assembled in LAUG, which reveals critical robustness issues\nin state-of-the-art models. The augmented dataset through LAUG can be used to\nfacilitate future research on the robustness testing of language understanding\nin task-oriented dialog.",
          "link": "http://arxiv.org/abs/2012.15262",
          "publishedOn": "2021-06-07T22:33:05.098Z",
          "wordCount": 636,
          "title": "Robustness Testing of Language Understanding in Task-Oriented Dialog. (arXiv:2012.15262v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1\">Mucheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Qualitative relationships illustrate how changing one property (e.g., moving\nvelocity) affects another (e.g., kinetic energy) and constitutes a considerable\nportion of textual knowledge. Current approaches use either semantic parsers to\ntransform natural language inputs into logical expressions or a \"black-box\"\nmodel to solve them in one step. The former has a limited application range,\nwhile the latter lacks interpretability. In this work, we categorize\nqualitative reasoning tasks into two types: prediction and comparison. In\nparticular, we adopt neural network modules trained in an end-to-end manner to\nsimulate the two reasoning processes. Experiments on two qualitative reasoning\nquestion answering datasets, QuaRTz and QuaRel, show our methods' effectiveness\nand generalization capability, and the intermediate outputs provided by the\nmodules make the reasoning process interpretable.",
          "link": "http://arxiv.org/abs/2106.02399",
          "publishedOn": "2021-06-07T03:06:13.263Z",
          "wordCount": 551,
          "title": "Prediction or Comparison: Toward Interpretable Qualitative Reasoning. (arXiv:2106.02399v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02417",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengxiong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>",
          "description": "Recurrent neural networks are widely used in speech and language processing.\nDue to dependency on the past, standard algorithms for training these models,\nsuch as back-propagation through time (BPTT), cannot be efficiently\nparallelised. Furthermore, applying these models to more complex structures\nthan sequences requires inference time approximations, which introduce\ninconsistency between inference and training. This paper shows that recurrent\nneural networks can be reformulated as fixed-points of non-linear equation\nsystems. These fixed-points can be computed using an iterative algorithm\nexactly and in as many iterations as the length of any given sequence. Each\niteration of this algorithm adds one additional Markovian-like order of\ndependencies such that upon termination all dependencies modelled by the\nrecurrent neural networks have been incorporated. Although exact fixed-points\ninherit the same parallelization and inconsistency issues, this paper shows\nthat approximate fixed-points can be computed in parallel and used consistently\nin training and inference including tasks such as lattice rescoring.\nExperimental validation is performed in two tasks, Penn Tree Bank and\nWikiText-2, and shows that approximate fixed-points yield competitive\nprediction performance to recurrent neural networks trained using the BPTT\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.02417",
          "publishedOn": "2021-06-07T03:06:13.067Z",
          "wordCount": 613,
          "title": "Approximate Fixed-Points in Recurrent Neural Networks. (arXiv:2106.02417v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2004.03238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1\">Kazutoshi Shinoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>",
          "description": "Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.",
          "link": "http://arxiv.org/abs/2004.03238",
          "publishedOn": "2021-06-07T03:06:13.054Z",
          "wordCount": 646,
          "title": "Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02443",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1\">Kevin Kilgour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1\">Hassan Rom</a>",
          "description": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.",
          "link": "http://arxiv.org/abs/2106.02443",
          "publishedOn": "2021-06-07T03:06:13.022Z",
          "wordCount": 642,
          "title": "Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.00164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaofeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1\">Tian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Benjamin Zi Hao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Minhui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jialiang Lu</a>",
          "description": "Natural language processing (NLP) systems have been proven to be vulnerable\nto backdoor attacks, whereby hidden features (backdoors) are trained into a\nlanguage model and may only be activated by specific inputs (called triggers),\nto trick the model into producing unexpected behaviors. In this paper, we\ncreate covert and natural triggers for textual backdoor attacks, \\textit{hidden\nbackdoors}, where triggers can fool both modern language models and human\ninspection. We deploy our hidden backdoors through two state-of-the-art trigger\nembedding methods. The first approach via homograph replacement, embeds the\ntrigger into deep neural networks through the visual spoofing of lookalike\ncharacter replacement. The second approach uses subtle differences between text\ngenerated by language models and real natural text to produce trigger sentences\nwith correct grammar and high fluency. We demonstrate that the proposed hidden\nbackdoors can be effective across three downstream security-critical NLP tasks,\nrepresentative of modern human-centric NLP systems, including toxic comment\ndetection, neural machine translation (NMT), and question answering (QA). Our\ntwo hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at\nleast $97\\%$ with an injection rate of only $3\\%$ in toxic comment detection,\n$95.1\\%$ ASR in NMT with less than $0.5\\%$ injected data, and finally $91.12\\%$\nASR against QA updated with only 27 poisoning data samples on a model\npreviously trained with 92,024 samples (0.029\\%). We are able to demonstrate\nthe adversary's high success rate of attacks, while maintaining functionality\nfor regular users, with triggers inconspicuous by the human administrators.",
          "link": "http://arxiv.org/abs/2105.00164",
          "publishedOn": "2021-06-07T03:06:13.015Z",
          "wordCount": 710,
          "title": "Hidden Backdoors in Human-Centric Language Models. (arXiv:2105.00164v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhaoxin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Michael Zhu</a>",
          "description": "Hierarchical structures exist in both linguistics and Natural Language\nProcessing (NLP) tasks. How to design RNNs to learn hierarchical\nrepresentations of natural languages remains a long-standing challenge. In this\npaper, we define two different types of boundaries referred to as static and\ndynamic boundaries, respectively, and then use them to construct a multi-layer\nhierarchical structure for document classification tasks. In particular, we\nfocus on a three-layer hierarchical structure with static word- and sentence-\nlayers and a dynamic phrase-layer. LSTM cells and two boundary detectors are\nused to implement the proposed structure, and the resulting network is called\nthe {\\em Recurrent Neural Network with Mixed Hierarchical Structures}\n(MHS-RNN). We further add three layers of attention mechanisms to the MHS-RNN\nmodel. Incorporating attention mechanisms allows our model to use more\nimportant content to construct document representation and enhance its\nperformance on document classification tasks. Experiments on five different\ndatasets show that the proposed architecture outperforms previous methods on\nall the five tasks.",
          "link": "http://arxiv.org/abs/2106.02562",
          "publishedOn": "2021-06-07T03:06:12.473Z",
          "wordCount": 593,
          "title": "Recurrent Neural Networks with Mixed Hierarchical Structures for Natural Language Processing. (arXiv:2106.02562v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongjia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "We participate in the DSTC9 Interactive Dialogue Evaluation Track (Gunasekara\net al. 2020) sub-task 1 (Knowledge Grounded Dialogue) and sub-task 2\n(Interactive Dialogue). In sub-task 1, we employ a pre-trained language model\nto generate topic-related responses and propose a response ensemble method for\nresponse selection. In sub-task2, we propose a novel Dialogue Planning Model\n(DPM) to capture conversation flow in the interaction with humans. We also\ndesign an integrated open-domain dialogue system containing pre-process,\ndialogue model, scoring model, and post-process, which can generate fluent,\ncoherent, consistent, and humanlike responses. We tie 1st on human ratings and\nalso get the highest Meteor, and Bert-score in sub-task 1, and rank 3rd on\ninteractive human evaluation in sub-task 2.",
          "link": "http://arxiv.org/abs/2101.07947",
          "publishedOn": "2021-06-07T03:06:12.456Z",
          "wordCount": 585,
          "title": "WeChat AI & ICT's Submission for DSTC9 Interactive Dialogue Evaluation Track. (arXiv:2101.07947v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAgostino_G/0/1/0/all/0/1\">Giovanna D&#x27;Agostino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1\">Nicola Cotumaccio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Policriti_A/0/1/0/all/0/1\">Alberto Policriti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1\">Nicola Prezza</a>",
          "description": "The states of a deterministic finite automaton A can be identified with\ncollections of words in Pf(L(A)) -- the set of prefixes of words belonging to\nthe regular language accepted by A. But words can be ordered and among the many\npossible orders a very natural one is the co-lexicographic one. Such\nnaturalness stems from the fact that it suggests a transfer of the order from\nwords to the automaton's states. In a number of papers automata admitting a\ntotal ordering of states coherent with the ordering of the set of words\nreaching them have been proposed. Such class of ordered automata -- the Wheeler\nautomata -- turned out to be efficiently stored/searched using an index.\nUnfortunately not all automata can be totally ordered as previously outlined.\nHowever, automata can always be partially ordered and an intrinsic measure of\ntheir complexity can be defined and effectively determined, as the minimum\nwidth of one of their admissible partial orders. As shown in previous works,\nthis new concept of width of an automaton has useful consequences in the fields\nof graph compression, indexing data structures, and automata theory. In this\npaper we prove that a canonical, minimum-width, partially-ordered automaton\naccepting a language L -- dubbed the Hasse automaton H of L -- can be\nexhibited. H provides, in a precise sense, the best possible way to (partially)\norder the states of any automaton accepting L, as long as we want to maintain\nan operational link with the (co-lexicographic) order of Pf(L(A)). Using H we\nprove that the width of the language can be effectively computed from the\nminimum automaton recognizing the language. Finally, we explore the\nrelationship between two (often conflicting) objectives: minimizing the width\nand minimizing the number of states of an automaton.",
          "link": "http://arxiv.org/abs/2106.02309",
          "publishedOn": "2021-06-07T03:06:12.450Z",
          "wordCount": 719,
          "title": "On (co-lex) Ordering Automata. (arXiv:2106.02309v1 [cs.FL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1\">Thomas Conley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>",
          "description": "Artificial Neural networks are mathematical models at their core. This\ntruismpresents some fundamental difficulty when networks are tasked with\nNatural Language Processing. A key problem lies in measuring the similarity or\ndistance among vectors in NLP embedding space, since the mathematical concept\nof distance does not always agree with the linguistic concept. We suggest that\nthe best way to measure linguistic distance among vectors is by employing the\nLanguage Model (LM) that created them. We introduce Language Model Distance\n(LMD) for measuring accuracy of vector transformations based on the\nDistributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric\nby applying it to a simple neural network learning the Procrustes algorithm for\nbilingual word mapping.",
          "link": "http://arxiv.org/abs/2106.02490",
          "publishedOn": "2021-06-07T03:06:12.443Z",
          "wordCount": 574,
          "title": "Language Model Metrics and Procrustes Analysis for Improved Vector Transformation of NLP Embeddings. (arXiv:2106.02490v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.",
          "link": "http://arxiv.org/abs/2105.14849",
          "publishedOn": "2021-06-07T03:06:12.367Z",
          "wordCount": 604,
          "title": "Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1\">James Mullenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1\">Yada Pruksachatkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1\">Sean Adler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1\">Jennifer Seale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1\">Jordan Swartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1\">T. Greg McKelvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>",
          "description": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.",
          "link": "http://arxiv.org/abs/2106.02524",
          "publishedOn": "2021-06-07T03:06:12.360Z",
          "wordCount": 641,
          "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.13631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengding Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.",
          "link": "http://arxiv.org/abs/2004.13631",
          "publishedOn": "2021-06-07T03:06:12.354Z",
          "wordCount": 647,
          "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruixiang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>",
          "description": "Broad-coverage meaning representations in NLP mostly focus on explicitly\nexpressed content. More importantly, the scarcity of datasets annotating\ndiverse implicit roles limits empirical studies into their linguistic nuances.\nFor example, in the web review \"Great service!\", the provider and consumer are\nimplicit arguments of different types. We examine an annotated corpus of\nfine-grained implicit arguments (Cui and Hershcovich, 2020) by carefully\nre-annotating it, resolving several inconsistencies. Subsequently, we present\nthe first transition-based neural parser that can handle implicit arguments\ndynamically, and experiment with two different transition systems on the\nimproved dataset. We find that certain types of implicit arguments are more\ndifficult to parse than others and that the simpler system is more accurate in\nrecovering implicit arguments, despite having a lower overall parsing score,\nattesting current reasoning limitations of NLP models. This work will\nfacilitate a better understanding of implicit and underspecified language, by\nincorporating it holistically into meaning representations.",
          "link": "http://arxiv.org/abs/2106.02561",
          "publishedOn": "2021-06-07T03:06:12.347Z",
          "wordCount": 574,
          "title": "Great Service! Fine-grained Parsing of Implicit Arguments. (arXiv:2106.02561v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1\">Wuwei Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Chao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>",
          "description": "Monolingual word alignment is important for studying fine-grained editing\noperations (i.e., deletion, addition, and substitution) in text-to-text\ngeneration tasks, such as paraphrase generation, text simplification,\nneutralizing biased language, etc. In this paper, we present a novel neural\nsemi-Markov CRF alignment model, which unifies word and phrase alignments\nthrough variable-length spans. We also create a new benchmark with human\nannotations that cover four different text genres to evaluate monolingual word\nalignment models in more realistic settings. Experimental results show that our\nproposed model outperforms all previous approaches for monolingual word\nalignment as well as a competitive QA-based baseline, which was previously only\napplied to bilingual data. Our model demonstrates good generalizability to\nthree out-of-domain datasets and shows great utility in two downstream\napplications: automatic text simplification and sentence pair classification\ntasks.",
          "link": "http://arxiv.org/abs/2106.02569",
          "publishedOn": "2021-06-07T03:06:12.337Z",
          "wordCount": 557,
          "title": "Neural semi-Markov CRF for Monolingual Word Alignment. (arXiv:2106.02569v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1\">Abhilash Nandy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adak_S/0/1/0/all/0/1\">Sayantan Adak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halder_T/0/1/0/all/0/1\">Tanurima Halder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokala_S/0/1/0/all/0/1\">Sai Mahesh Pokala</a>",
          "description": "This paper describes the performance of the team cs60075_team2 at SemEval\n2021 Task 1 - Lexical Complexity Prediction. The main contribution of this\npaper is to fine-tune transformer-based language models pre-trained on several\ntext corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the\ncorpora from which the CompLex Dataset was extracted, and others being from\nother specific domains such as Finance, Law, etc. We perform ablation studies\non selecting the transformer models and how their individual complexity scores\nare aggregated to get the resulting complexity scores. Our method achieves a\nbest Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in\nsub-task 2 (multiple word expressions).",
          "link": "http://arxiv.org/abs/2106.02340",
          "publishedOn": "2021-06-07T03:06:12.205Z",
          "wordCount": 567,
          "title": "cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora. (arXiv:2106.02340v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1\">Tillmann Miltzow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmiermann_R/0/1/0/all/0/1\">Reinier F. Schmiermann</a>",
          "description": "A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n\nWe restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n\nWe apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.",
          "link": "http://arxiv.org/abs/2106.02397",
          "publishedOn": "2021-06-07T03:06:12.165Z",
          "wordCount": 737,
          "title": "On Classifying Continuous Constraint Satisfaction problems. (arXiv:2106.02397v1 [cs.CC])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_M/0/1/0/all/0/1\">Mrigank Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Aaron Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Handong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungchul Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Recently, knowledge graph (KG) augmented models have achieved noteworthy\nsuccess on various commonsense reasoning tasks. However, KG edge (fact)\nsparsity and noisy edge extraction/generation often hinder models from\nobtaining useful knowledge to reason over. To address these issues, we propose\na new KG-augmented model: Hybrid Graph Network (HGN). Unlike prior methods, HGN\nlearns to jointly contextualize extracted and generated knowledge by reasoning\nover both within a unified graph structure. Given the task input context and an\nextracted KG subgraph, HGN is trained to generate embeddings for the subgraph's\nmissing edges to form a \"hybrid\" graph, then reason over the hybrid graph while\nfiltering out context-irrelevant edges. We demonstrate HGN's effectiveness\nthrough considerable performance gains across four commonsense reasoning\nbenchmarks, plus a user study on edge validness and helpfulness.",
          "link": "http://arxiv.org/abs/2010.12873",
          "publishedOn": "2021-06-07T03:06:12.143Z",
          "wordCount": 616,
          "title": "Learning Contextualized Knowledge Structures for Commonsense Reasoning. (arXiv:2010.12873v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1\">Aleksandra Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_D/0/1/0/all/0/1\">David Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribaupierre_H/0/1/0/all/0/1\">H&#xe9;l&#xe8;ne de Ribaupierre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1\">Alun Preece</a>",
          "description": "The task of text and sentence classification is associated with the need for\nlarge amounts of labelled training data. The acquisition of high volumes of\nlabelled datasets can be expensive or unfeasible, especially for\nhighly-specialised domains for which documents are hard to obtain. Research on\nthe application of supervised classification based on small amounts of training\ndata is limited. In this paper, we address the combination of state-of-the-art\ndeep learning and classification methods and provide an insight into what\ncombination of methods fit the needs of small, domain-specific, and\nterminologically-rich corpora. We focus on a real-world scenario related to a\ncollection of safeguarding reports comprising learning experiences and\nreflections on tackling serious incidents involving children and vulnerable\nadults. The relatively small volume of available reports and their use of\nhighly domain-specific terminology makes the application of automated\napproaches difficult. We focus on the problem of automatically identifying the\nmain themes in a safeguarding report using supervised classification\napproaches. Our results show the potential of deep learning models to simulate\nsubject-expert behaviour even for complex tasks with limited labelled data.",
          "link": "http://arxiv.org/abs/2010.14584",
          "publishedOn": "2021-06-07T03:06:12.123Z",
          "wordCount": 660,
          "title": "Predicting Themes within Complex Unstructured Texts: A Case Study on Safeguarding Reports. (arXiv:2010.14584v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schon_C/0/1/0/all/0/1\">Claudia Schon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebert_S/0/1/0/all/0/1\">Sophie Siebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1\">Frieder Stolzenburg</a>",
          "description": "Negation is both an operation in formal logic and in natural language by\nwhich a proposition is replaced by one stating the opposite, as by the addition\nof \"not\" or another negation cue. Treating negation in an adequate way is\nrequired for cognitive reasoning, which aims at modeling the human ability to\ndraw meaningful conclusions despite incomplete and inconsistent knowledge. One\ntask of cognitive reasoning is answering questions given by sentences in\nnatural language. There are tools based on discourse representation theory to\nconvert sentences automatically into a formal logic representation, and\nadditional knowledge can be added using the predicate names in the formula and\nknowledge databases. However, the knowledge in logic databases in practice\nalways is incomplete. Hence, forward reasoning of automated reasoning systems\nalone does not suffice to derive answers to questions because, instead of\ncomplete proofs, often only partial positive knowledge can be derived, while\nnegative knowledge is used only during the reasoning process. In consequence,\nwe aim at eliminating syntactic negation, strictly speaking, the negated event\nor property. In this paper, we describe an effective procedure to determine the\nnegated event or property in order to replace it by its inverse. This lays the\nbasis of cognitive reasoning, employing both logic and machine learning for\ngeneral question answering. We evaluate our procedure by several benchmarks and\ndemonstrate its practical usefulness in our cognitive reasoning system.",
          "link": "http://arxiv.org/abs/2012.12641",
          "publishedOn": "2021-06-07T03:06:12.042Z",
          "wordCount": 679,
          "title": "Negation in Cognitive Reasoning. (arXiv:2012.12641v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qinghua Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>",
          "description": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.",
          "link": "http://arxiv.org/abs/2106.02401",
          "publishedOn": "2021-06-07T03:06:12.027Z",
          "wordCount": 605,
          "title": "Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zequn Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "This paper studies a new problem setting of entity alignment for knowledge\ngraphs (KGs). Since KGs possess different sets of entities, there could be\nentities that cannot find alignment across them, leading to the problem of\ndangling entities. As the first attempt to this problem, we construct a new\ndataset and design a multi-task learning framework for both entity alignment\nand dangling entity detection. The framework can opt to abstain from predicting\nalignment for the detected dangling entities. We propose three techniques for\ndangling entity detection that are based on the distribution of\nnearest-neighbor distances, i.e., nearest neighbor classification, marginal\nranking and background ranking. After detecting and removing dangling entities,\nan incorporated entity alignment model in our framework can provide more robust\nalignment for remaining entities. Comprehensive experiments and analyses\ndemonstrate the effectiveness of our framework. We further discover that the\ndangling entity detection module can, in turn, improve alignment learning and\nthe final performance. The contributed resource is publicly available to foster\nfurther research.",
          "link": "http://arxiv.org/abs/2106.02248",
          "publishedOn": "2021-06-07T03:06:11.954Z",
          "wordCount": 595,
          "title": "Knowing the No-match: Entity Alignment with Dangling Cases. (arXiv:2106.02248v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yunyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianxing Yu</a>",
          "description": "Dialogue policy learning, a subtask that determines the content of system\nresponse generation and then the degree of task completion, is essential for\ntask-oriented dialogue systems. However, the unbalanced distribution of system\nactions in dialogue datasets often causes difficulty in learning to generate\ndesired actions and responses. In this paper, we propose a\nretrieve-and-memorize framework to enhance the learning of system actions.\nSpecially, we first design a neural context-aware retrieval module to retrieve\nmultiple candidate system actions from the training set given a dialogue\ncontext. Then, we propose a memory-augmented multi-decoder network to generate\nthe system actions conditioned on the candidate actions, which allows the\nnetwork to adaptively select key information in the candidate actions and\nignore noises. We conduct experiments on the large-scale multi-domain\ntask-oriented dialogue dataset MultiWOZ 2.0 and MultiWOZ 2.1.~Experimental\nresults show that our method achieves competitive performance among several\nstate-of-the-art models in the context-to-response generation task.",
          "link": "http://arxiv.org/abs/2106.02317",
          "publishedOn": "2021-06-07T03:06:11.913Z",
          "wordCount": 583,
          "title": "Retrieve & Memorize: Dialog Policy Learning with Multi-Action Memory. (arXiv:2106.02317v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Igor L. Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jacqueline Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1\">Adam Vagner</a>",
          "description": "Text classifiers are at the core of many NLP applications and use a variety\nof algorithmic approaches and software. This paper introduces infrastructure\nand methodologies for text classifiers based on large-scale regular\nexpressions. In particular, we describe how Facebook determines if a given\npiece of text - anything from a hashtag to a post - belongs to a narrow topic\nsuch as COVID-19. To fully define a topic and evaluate classifier performance\nwe employ human-guided iterations of keyword discovery, but do not require\nlabeled data. For COVID-19, we build two sets of regular expressions: (1) for\n66 languages, with 99% precision and recall >50%, (2) for the 11 most common\nlanguages, with precision >90% and recall >90%. Regular expressions enable\nlow-latency queries from multiple platforms. Response to challenges like\nCOVID-19 is fast and so are revisions. Comparisons to a DNN classifier show\nexplainable results, higher precision and recall, and less overfitting. Our\nlearnings can be applied to other narrow-topic classifiers.",
          "link": "http://arxiv.org/abs/2102.09507",
          "publishedOn": "2021-06-07T03:06:11.906Z",
          "wordCount": 679,
          "title": "Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:11.887Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Ung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klie_J/0/1/0/all/0/1\">Jan-Christoph Klie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Annotation studies often require annotators to familiarize themselves with\nthe task, its annotation scheme, and the data domain. This can be overwhelming\nin the beginning, mentally taxing, and induce errors into the resulting\nannotations; especially in citizen science or crowd sourcing scenarios where\ndomain expertise is not required and only annotation guidelines are provided.\nTo alleviate these issues, we propose annotation curricula, a novel approach to\nimplicitly train annotators. Our goal is to gradually introduce annotators into\nthe task by ordering instances that are annotated according to a learning\ncurriculum. To do so, we first formalize annotation curricula for sentence- and\nparagraph-level annotation tasks, define an ordering strategy, and identify\nwell-performing heuristics and interactively trained models on three existing\nEnglish datasets. We then conduct a user study with 40 voluntary participants\nwho are asked to identify the most fitting misconception for English tweets\nabout the Covid-19 pandemic. Our results show that using a simple heuristic to\norder instances can already significantly reduce the total annotation time\nwhile preserving a high annotation quality. Annotation curricula thus can\nprovide a novel way to improve data collection. To facilitate future research,\nwe further share our code and data consisting of 2,400 annotations.",
          "link": "http://arxiv.org/abs/2106.02382",
          "publishedOn": "2021-06-07T03:06:11.880Z",
          "wordCount": 665,
          "title": "Annotation Curricula to Implicitly Train Non-Expert Annotators. (arXiv:2106.02382v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.13048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tafjord_O/0/1/0/all/0/1\">Oyvind Tafjord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1\">Bhavana Dalvi Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>",
          "description": "Transformers have been shown to emulate logical deduction over natural\nlanguage theories (logical rules expressed in natural language), reliably\nassigning true/false labels to candidate implications. However, their ability\nto generate implications of a theory has not yet been demonstrated, and methods\nfor reconstructing proofs of answers are imperfect. In this work we show that a\ngenerative model, called ProofWriter, can reliably generate both implications\nof a theory and the natural language proof(s) that support them. In particular,\niterating a 1-step implication generator results in proofs that are highly\nreliable, and represent actual model decisions (rather than post-hoc\nrationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's\nproofs exceed previous methods by +9% absolute, and in a way that generalizes\nto proof depths unseen in training and on out-of-domain problems. We also show\nthat generative techniques can perform a type of abduction with high precision:\nGiven a theory and an unprovable conclusion, identify a missing fact that\nallows the conclusion to be proved, along with a proof. These results\nsignificantly improve the viability of neural methods for systematically\nreasoning over natural language.",
          "link": "http://arxiv.org/abs/2012.13048",
          "publishedOn": "2021-06-07T03:06:11.872Z",
          "wordCount": 648,
          "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language. (arXiv:2012.13048v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?",
          "link": "http://arxiv.org/abs/2106.02559",
          "publishedOn": "2021-06-07T03:06:11.866Z",
          "wordCount": 649,
          "title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Anusua Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1\">Alyssa Suhm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1\">Prathamesh Mahankal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1\">Subhiksha Mukuntharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1\">Meghana D. Parab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1\">Malvika Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Meredith Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1\">Arathi Sethumadhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1\">Ashish Jaiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1\">Rahul Dodhia</a>",
          "description": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.",
          "link": "http://arxiv.org/abs/2106.02607",
          "publishedOn": "2021-06-07T03:06:11.859Z",
          "wordCount": 600,
          "title": "Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tanzila Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Shih-Han Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1\">Leonid Sigal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "We consider the problem of Visual Question Answering (VQA). Given an image\nand a free-form, open-ended, question, expressed in natural language, the goal\nof VQA system is to provide accurate answer to this question with respect to\nthe image. The task is challenging because it requires simultaneous and\nintricate understanding of both visual and textual information. Attention,\nwhich captures intra- and inter-modal dependencies, has emerged as perhaps the\nmost widely used mechanism for addressing these challenges. In this paper, we\npropose an improved attention-based architecture to solve VQA. We incorporate\nan Attention on Attention (AoA) module within encoder-decoder framework, which\nis able to determine the relation between attention results and queries.\nAttention module generates weighted average for each query. On the other hand,\nAoA module first generates an information vector and an attention gate using\nattention results and current context; and then adds another attention to\ngenerate final attended information by multiplying the two. We also propose\nmultimodal fusion module to combine both visual and textual information. The\ngoal of this fusion module is to dynamically decide how much information should\nbe considered from each modality. Extensive experiments on VQA-v2 benchmark\ndataset show that our method achieves the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2011.02164",
          "publishedOn": "2021-06-07T03:06:11.841Z",
          "wordCount": 674,
          "title": "An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_C/0/1/0/all/0/1\">Christan Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Automatic extraction of product attribute values is an important enabling\ntechnology in e-Commerce platforms. This task is usually modeled using sequence\nlabeling architectures, with several extensions to handle multi-attribute\nextraction. One line of previous work constructs attribute-specific models,\nthrough separate decoders or entirely separate models. However, this approach\nconstrains knowledge sharing across different attributes. Other contributions\nuse a single multi-attribute model, with different techniques to embed\nattribute information. But sharing the entire network parameters across all\nattributes can limit the model's capacity to capture attribute-specific\ncharacteristics. In this paper we present AdaTag, which uses adaptive decoding\nto handle extraction. We parameterize the decoder with pretrained attribute\nembeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This\nallows for separate, but semantically correlated, decoders to be generated on\nthe fly for different attributes. This approach facilitates knowledge sharing,\nwhile maintaining the specificity of each attribute. Our experiments on a\nreal-world e-Commerce dataset show marked improvements over previous methods.",
          "link": "http://arxiv.org/abs/2106.02318",
          "publishedOn": "2021-06-07T03:06:11.834Z",
          "wordCount": 597,
          "title": "AdaTag: Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding. (arXiv:2106.02318v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1\">Thomas Conley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clair_J/0/1/0/all/0/1\">Jack St. Clair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>",
          "description": "Although people have the ability to engage in vapid dialogue without effort,\nthis may not be a uniquely human trait. Since the 1960's researchers have been\ntrying to create agents that can generate artificial conversation. These\nprograms are commonly known as chatbots. With increasing use of neural networks\nfor dialog generation, some conclude that this goal has been achieved. This\nresearch joins the quest by creating a dialog generating Recurrent Neural\nNetwork (RNN) and by enhancing the ability of this network with auxiliary loss\nfunctions and a beam search. Our custom loss functions achieve better cohesion\nand coherence by including calculations of Maximum Mutual Information (MMI) and\nentropy. We demonstrate the effectiveness of this system by using a set of\ncustom evaluation metrics inspired by an abundance of previous research and\nbased on tried-and-true principles of Natural Language Processing.",
          "link": "http://arxiv.org/abs/2106.02516",
          "publishedOn": "2021-06-07T03:06:11.827Z",
          "wordCount": 586,
          "title": "Improving Computer Generated Dialog with Auxiliary Loss Functions and Custom Evaluation Metrics. (arXiv:2106.02516v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1\">Geeticka Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1\">Brian Tse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>",
          "description": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via moral philosophy's definition of social good, propose a\nframework to evaluate NLP tasks' direct and indirect real-world impact, and\nadopt the methodology of global priorities research to identify priority causes\nfor NLP research. Finally, we use our theoretical framework to provide some\npractical guidelines for future NLP research for social good. Our data and\ncodes are available at this http URL",
          "link": "http://arxiv.org/abs/2106.02359",
          "publishedOn": "2021-06-07T03:06:11.820Z",
          "wordCount": 603,
          "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_Q/0/1/0/all/0/1\">Qianlan Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bojia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>",
          "description": "We consider the problem of scaling automated suggested replies for Outlook\nemail system to multiple languages. Faced with increased compute requirements\nand low resources for language expansion, we build a single universal model for\nimproving the quality and reducing run-time costs of our production system.\nHowever, restricted data movement across regional centers prevents joint\ntraining across languages. To this end, we propose a multi-task continual\nlearning framework, with auxiliary tasks and language adapters to learn\nuniversal language representation across regions. The experimental results show\npositive cross-lingual transfer across languages while reducing catastrophic\nforgetting across regions. Our online results on real user traffic show\nsignificant gains in CTR and characters saved, as well as 65% training cost\nreduction compared with per-language models. As a consequence, we have scaled\nthe feature in multiple languages including low-resource markets.",
          "link": "http://arxiv.org/abs/2106.02232",
          "publishedOn": "2021-06-07T03:06:11.814Z",
          "wordCount": 574,
          "title": "Language Scaling for Universal Suggested Replies Model. (arXiv:2106.02232v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaokun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiawu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1\">Fei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Despite superior performance on various natural language processing tasks,\npre-trained models such as BERT are challenged by deploying on\nresource-constraint devices. Most existing model compression approaches require\nre-compression or fine-tuning across diverse constraints to accommodate various\nhardware deployments. This practically limits the further application of model\ncompression. Moreover, the ineffective training and searching process of\nexisting elastic compression paradigms[4,27] prevents the direct migration to\nBERT compression. Motivated by the necessity of efficient inference across\nvarious constraints on BERT, we propose a novel approach, YOCO-BERT, to achieve\ncompress once and deploy everywhere. Specifically, we first construct a huge\nsearch space with 10^13 architectures, which covers nearly all configurations\nin BERT model. Then, we propose a novel stochastic nature gradient optimization\nmethod to guide the generation of optimal candidate architecture which could\nkeep a balanced trade-off between explorations and exploitation. When a certain\nresource constraint is given, a lightweight distribution optimization approach\nis utilized to obtain the optimal network for target deployment without\nfine-tuning. Compared with state-of-the-art algorithms, YOCO-BERT provides more\ncompact models, yet achieving 2.1%-4.5% average accuracy improvement on the\nGLUE benchmark. Besides, YOCO-BERT is also more effective, e.g.,the training\ncomplexity is O(1)for N different devices. Code is\navailablehttps://github.com/MAC-AutoML/YOCO-BERT.",
          "link": "http://arxiv.org/abs/2106.02435",
          "publishedOn": "2021-06-07T03:06:11.775Z",
          "wordCount": 654,
          "title": "You Only Compress Once: Towards Effective and Elastic BERT Compression via Exploit-Explore Stochastic Nature Gradient. (arXiv:2106.02435v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjit Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "Despite recent successes of large pre-trained language models in solving\nreasoning tasks, their inference capabilities remain opaque. We posit that such\nmodels can be made more interpretable by explicitly generating interim\ninference rules, and using them to guide the generation of task-specific\ntextual outputs. In this paper we present COINS, a recursive inference\nframework that i) iteratively reads context sentences, ii) dynamically\ngenerates contextualized inference rules, encodes them, and iii) uses them to\nguide task-specific output generation. We apply COINS to a Narrative Story\nCompletion task that asks a model to complete a story with missing sentences,\nto produce a coherent story with plausible logical connections, causal\nrelationships, and temporal dependencies. By modularizing inference and\nsentence generation steps in a recurrent model, we aim to make reasoning steps\nand their effects on next sentence generation transparent. Our automatic and\nmanual evaluations show that the model generates better story sentences than\nSOTA baselines, especially in terms of coherence. We further demonstrate\nimproved performance over strong pre-trained LMs in generating commonsense\ninference rules. The recursive nature of COINS holds the potential for\ncontrolled generation of longer sequences.",
          "link": "http://arxiv.org/abs/2106.02497",
          "publishedOn": "2021-06-07T03:06:11.767Z",
          "wordCount": 617,
          "title": "COINS: Dynamically Generating COntextualized Inference Rules for Narrative Story Completion. (arXiv:2106.02497v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fraser_K/0/1/0/all/0/1\">Kathleen C. Fraser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nejadgholi_I/0/1/0/all/0/1\">Isar Nejadgholi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiritchenko_S/0/1/0/all/0/1\">Svetlana Kiritchenko</a>",
          "description": "Stereotypical language expresses widely-held beliefs about different social\ncategories. Many stereotypes are overtly negative, while others may appear\npositive on the surface, but still lead to negative consequences. In this work,\nwe present a computational approach to interpreting stereotypes in text through\nthe Stereotype Content Model (SCM), a comprehensive causal theory from social\npsychology. The SCM proposes that stereotypes can be understood along two\nprimary dimensions: warmth and competence. We present a method for defining\nwarmth and competence axes in semantic embedding space, and show that the four\nquadrants defined by this subspace accurately represent the warmth and\ncompetence concepts, according to annotated lexicons. We then apply our\ncomputational SCM model to textual stereotype data and show that it compares\nfavourably with survey-based studies in the psychological literature.\nFurthermore, we explore various strategies to counter stereotypical beliefs\nwith anti-stereotypes. It is known that countering stereotypes with\nanti-stereotypical examples is one of the most effective ways to reduce biased\nthinking, yet the problem of generating anti-stereotypes has not been\npreviously studied. Thus, a better understanding of how to generate realistic\nand effective anti-stereotypes can contribute to addressing pressing societal\nconcerns of stereotyping, prejudice, and discrimination.",
          "link": "http://arxiv.org/abs/2106.02596",
          "publishedOn": "2021-06-07T03:06:11.759Z",
          "wordCount": 666,
          "title": "Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. (arXiv:2106.02596v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Ruikun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guanhuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>",
          "description": "The major paradigm of applying a pre-trained language model to downstream\ntasks is to fine-tune it on labeled task data, which often suffers instability\nand low performance when the labeled examples are scarce.~One way to alleviate\nthis problem is to apply post-training on unlabeled task data before\nfine-tuning, adapting the pre-trained model to target domains by contrastive\nlearning that considers either token-level or sequence-level similarity.\nInspired by the success of sequence masking, we argue that both token-level and\nsequence-level similarities can be captured with a pair of masked\nsequences.~Therefore, we propose complementary random masking (CRM) to generate\na pair of masked sequences from an input sequence for sequence-level\ncontrastive learning and then develop contrastive masked language modeling\n(CMLM) for post-training to integrate both token-level and sequence-level\ncontrastive learnings.~Empirical results show that CMLM surpasses several\nrecent post-training methods in few-shot settings without the need for data\naugmentation.",
          "link": "http://arxiv.org/abs/2106.02327",
          "publishedOn": "2021-06-07T03:06:11.749Z",
          "wordCount": 570,
          "title": "Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene. (arXiv:2106.02327v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1\">Divesh Lala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1\">Tatsuya Kawahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Over the past year, research in various domains, including Natural Language\nProcessing (NLP), has been accelerated to fight against the COVID-19 pandemic,\nyet such research has just started on dialogue systems. In this paper, we\nintroduce an end-to-end dialogue system which aims to ease the isolation of\npeople under self-quarantine. We conduct a control simulation experiment to\nassess the effects of the user interface, a web-based virtual agent called Nora\nvs. the android ERICA via a video call. The experimental results show that the\nandroid offers a more valuable user experience by giving the impression of\nbeing more empathetic and engaging in the conversation due to its nonverbal\ninformation, such as facial expressions and body gestures.",
          "link": "http://arxiv.org/abs/2106.02325",
          "publishedOn": "2021-06-07T03:06:11.742Z",
          "wordCount": 602,
          "title": "ERICA: An Empathetic Android Companion for Covid-19 Quarantine. (arXiv:2106.02325v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weile Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huiqiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qianhui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_B/0/1/0/all/0/1\">B&#xf6;rje F. Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yi Guan</a>",
          "description": "Neural methods have been shown to achieve high performance in Named Entity\nRecognition (NER), but rely on costly high-quality labeled data for training,\nwhich is not always available across languages. While previous works have shown\nthat unlabeled data in a target language can be used to improve cross-lingual\nmodel performance, we propose a novel adversarial approach (AdvPicker) to\nbetter leverage such data and further improve results. We design an adversarial\nlearning framework in which an encoder learns entity domain knowledge from\nlabeled source-language data and better shared features are captured via\nadversarial training - where a discriminator selects less language-dependent\ntarget-language data via similarity to the source language. Experimental\nresults on standard benchmark datasets well demonstrate that the proposed\nmethod benefits strongly from this data selection process and outperforms\nexisting state-of-the-art methods; without requiring any additional external\nresources (e.g., gazetteers or via machine translation).",
          "link": "http://arxiv.org/abs/2106.02300",
          "publishedOn": "2021-06-07T03:06:11.684Z",
          "wordCount": 588,
          "title": "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER. (arXiv:2106.02300v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1\">Ruhi Sarikaya</a>",
          "description": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.",
          "link": "http://arxiv.org/abs/2106.02363",
          "publishedOn": "2021-06-07T03:06:11.669Z",
          "wordCount": 556,
          "title": "Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1\">Chris Kedzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Suraj Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1\">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>",
          "description": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.02293",
          "publishedOn": "2021-06-07T03:06:11.661Z",
          "wordCount": 548,
          "title": "Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikkarinen_I/0/1/0/all/0/1\">Irene Nikkarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1\">Dami&#xe1;n E. Blasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The unigram distribution is the non-contextual probability of finding a\nspecific word form in a corpus. While of central importance to the study of\nlanguage, it is commonly approximated by each word's sample frequency in the\ncorpus. This approach, being highly dependent on sample size, assigns zero\nprobability to any out-of-vocabulary (oov) word form. As a result, it produces\nnegatively biased probabilities for any oov word form, while positively biased\nprobabilities to in-corpus words. In this work, we argue in favor of properly\nmodeling the unigram distribution -- claiming it should be a central task in\nnatural language processing. With this in mind, we present a novel model for\nestimating it in a language (a neuralization of Goldwater et al.'s (2011)\nmodel) and show it produces much better estimates across a diverse set of 7\nlanguages than the na\\\"ive use of neural character-level language models.",
          "link": "http://arxiv.org/abs/2106.02289",
          "publishedOn": "2021-06-07T03:06:11.515Z",
          "wordCount": 588,
          "title": "Modeling the Unigram Distribution. (arXiv:2106.02289v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelkes_A/0/1/0/all/0/1\">Adam D. Lelkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vinh Q. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cong Yu</a>",
          "description": "We aim to renew interest in a particular multi-document summarization (MDS)\ntask which we call AgreeSum: agreement-oriented multi-document summarization.\nGiven a cluster of articles, the goal is to provide abstractive summaries that\nrepresent information common and faithful to all input articles. Given the lack\nof existing datasets, we create a dataset for AgreeSum, and provide annotations\non article-summary entailment relations for a subset of the clusters in the\ndataset. We aim to create strong baselines for the task by applying the\ntop-performing pretrained single-document summarization model PEGASUS onto\nAgreeSum, leveraging both annotated clusters by supervised losses, and\nunannotated clusters by T5-based entailment-related and language-related\nlosses. Compared to other baselines, both automatic evaluation and human\nevaluation show better article-summary and cluster-summary entailment in\ngenerated summaries. On a separate note, we hope that our article-summary\nentailment annotations contribute to the community's effort in improving\nabstractive summarization faithfulness.",
          "link": "http://arxiv.org/abs/2106.02278",
          "publishedOn": "2021-06-07T03:06:11.483Z",
          "wordCount": 572,
          "title": "AgreeSum: Agreement-Oriented Multi-Document Summarization. (arXiv:2106.02278v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weiyue Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shikun Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Pretrained language models (PLMs) such as BERT adopt a training paradigm\nwhich first pretrain the model in general data and then finetune the model on\ntask-specific data, and have recently achieved great success. However, PLMs are\nnotorious for their enormous parameters and hard to be deployed on real-life\napplications. Knowledge distillation has been prevailing to address this\nproblem by transferring knowledge from a large teacher to a much smaller\nstudent over a set of data. We argue that the selection of thee three key\ncomponents, namely teacher, training data, and learning objective, is crucial\nto the effectiveness of distillation. We, therefore, propose a four-stage\nprogressive distillation framework ERNIE-Tiny to compress PLM, which varies the\nthree components gradually from general level to task-specific level.\nSpecifically, the first stage, General Distillation, performs distillation with\nguidance from pretrained teacher, gerenal data and latent distillation loss.\nThen, General-Enhanced Distillation changes teacher model from pretrained\nteacher to finetuned teacher. After that, Task-Adaptive Distillation shifts\ntraining data from general data to task-specific data. In the end,\nTask-Specific Distillation, adds two additional losses, namely Soft-Label and\nHard-Label loss onto the last stage. Empirical results demonstrate the\neffectiveness of our framework and generalization gain brought by ERNIE-Tiny.In\nparticular, experiments show that a 4-layer ERNIE-Tiny maintains over\n98.0%performance of its 12-layer teacher BERT base on GLUE benchmark,\nsurpassing state-of-the-art (SOTA) by 1.0% GLUE score with the same amount of\nparameters. Moreover, ERNIE-Tiny achieves a new compression SOTA on five\nChinese NLP tasks, outperforming BERT base by 0.4% accuracy with 7.5x fewer\nparameters and9.4x faster inference speed.",
          "link": "http://arxiv.org/abs/2106.02241",
          "publishedOn": "2021-06-07T03:06:11.369Z",
          "wordCount": 699,
          "title": "ERNIE-Tiny : A Progressive Distillation Framework for Pretrained Transformer Compression. (arXiv:2106.02241v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1\">Zhong Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Liang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1\">Guoli Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>",
          "description": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets",
          "link": "http://arxiv.org/abs/2106.02302",
          "publishedOn": "2021-06-07T03:06:11.362Z",
          "wordCount": 675,
          "title": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_A/0/1/0/all/0/1\">Abteen Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "Pretrained multilingual models (PMMs) enable zero-shot learning via\ncross-lingual transfer, performing best for languages seen during pretraining.\nWhile methods exist to improve performance for unseen languages, they have\nalmost exclusively been evaluated using amounts of raw text only available for\na small fraction of the world's languages. In this paper, we evaluate the\nperformance of existing methods to adapt PMMs to new languages using a resource\navailable for over 1600 languages: the New Testament. This is challenging for\ntwo reasons: (1) the small corpus size, and (2) the narrow domain. While\nperformance drops for all approaches, we surprisingly still see gains of up to\n$17.69\\%$ accuracy for part-of-speech tagging and $6.29$ F1 for NER on average\nover all languages as compared to XLM-R. Another unexpected finding is that\ncontinued pretraining, the simplest approach, performs best. Finally, we\nperform a case study to disentangle the effects of domain and size and to shed\nlight on the influence of the finetuning source language.",
          "link": "http://arxiv.org/abs/2106.02124",
          "publishedOn": "2021-06-07T03:06:11.353Z",
          "wordCount": 592,
          "title": "How to Adapt Your Pretrained Multilingual Model to 1600 Languages. (arXiv:2106.02124v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zikai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chen Henry Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qihan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Autoregressive models have been widely used in unsupervised text style\ntransfer. Despite their success, these models still suffer from the content\npreservation problem that they usually ignore part of the source sentence and\ngenerate some irrelevant words with strong styles. In this paper, we propose a\nNon-Autoregressive generator for unsupervised text Style Transfer (NAST), which\nalleviates the problem from two aspects. First, we observe that most words in\nthe transferred sentence can be aligned with related words in the source\nsentence, so we explicitly model word alignments to suppress irrelevant words.\nSecond, existing models trained with the cycle loss align sentences in two\nstylistic text spaces, which lacks fine-grained control at the word level. The\nproposed non-autoregressive generator focuses on the connections between\naligned words, which learns the word-level transfer between styles. For\nexperiments, we integrate the proposed generator into two base models and\nevaluate them on two style transfer tasks. The results show that NAST can\nsignificantly improve the overall performance and provide explainable word\nalignments. Moreover, the non-autoregressive generator achieves over 10x\nspeedups at inference. Our codes are available at\nhttps://github.com/thu-coai/NAST.",
          "link": "http://arxiv.org/abs/2106.02210",
          "publishedOn": "2021-06-07T03:06:11.343Z",
          "wordCount": 632,
          "title": "NAST: A Non-Autoregressive Generator with Word Alignment for Unsupervised Text Style Transfer. (arXiv:2106.02210v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02287",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toledo_C/0/1/0/all/0/1\">Cha&#xef;m van Toledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_F/0/1/0/all/0/1\">Friso van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco Spruit</a>",
          "description": "The human resource (HR) domain contains various types of privacy-sensitive\ntextual data, such as e-mail correspondence and performance appraisal. Doing\nresearch on these documents brings several challenges, one of them\nanonymisation. In this paper, we evaluate the current Dutch text\nde-identification methods for the HR domain in four steps. First, by updating\none of these methods with the latest named entity recognition (NER) models. The\nresult is that the NER model based on the CoNLL 2002 corpus in combination with\nthe BERTje transformer give the best combination for suppressing persons\n(recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is\nperforming best (recall 0.53). Second NER evaluation is based on both strict\nde-identification of entities (a person must be suppressed as a person) and\nthird evaluation on a loose sense of de-identification (no matter what how a\nperson is suppressed, as long it is suppressed). In the fourth and last step a\nnew kind of NER dataset is tested for recognising job titles in texts.",
          "link": "http://arxiv.org/abs/2106.02287",
          "publishedOn": "2021-06-07T03:06:11.323Z",
          "wordCount": 614,
          "title": "Dutch Named Entity Recognition and De-identification Methods for the Human Resource Domain. (arXiv:2106.02287v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1\">Sasha Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amanpreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1\">Jose Alberto Lopez Magana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1\">Wojciech Galuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.",
          "link": "http://arxiv.org/abs/2106.02280",
          "publishedOn": "2021-06-07T03:06:11.315Z",
          "wordCount": 575,
          "title": "Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Nowadays, open-domain dialogue models can generate acceptable responses\naccording to the historical context based on the large-scale pre-trained\nlanguage models. However, they generally concatenate the dialogue history\ndirectly as the model input to predict the response, which we named as the flat\npattern and ignores the dynamic information flow across dialogue utterances. In\nthis work, we propose the DialoFlow model, in which we introduce a dynamic flow\nmechanism to model the context flow, and design three training objectives to\ncapture the information dynamics across dialogue utterances by addressing the\nsemantic influence brought about by each utterance in large-scale pre-training.\nExperiments on the multi-reference Reddit Dataset and DailyDialog Dataset\ndemonstrate that our DialoFlow significantly outperforms the DialoGPT on the\ndialogue generation task. Besides, we propose the Flow score, an effective\nautomatic metric for evaluating interactive human-bot conversation quality\nbased on the pre-trained DialoFlow, which presents high chatbot-level\ncorrelation ($r=0.9$) with human ratings among 11 chatbots. Code and\npre-trained models will be public.\n\\footnote{\\url{https://github.com/ictnlp/DialoFlow}}",
          "link": "http://arxiv.org/abs/2106.02227",
          "publishedOn": "2021-06-07T03:06:11.305Z",
          "wordCount": 610,
          "title": "Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances. (arXiv:2106.02227v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Chen Hanqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Da Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mengyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>",
          "description": "Recently, Text-to-SQL for multi-turn dialogue has attracted great interest.\nHere, the user input of the current turn is parsed into the corresponding SQL\nquery of the appropriate database, given all previous dialogue history. Current\napproaches mostly employ end-to-end models and consequently face two\nchallenges. First, dialogue history modeling and Text-to-SQL parsing are\nimplicitly combined, hence it is hard to carry out interpretable analysis and\nobtain targeted improvement. Second, SQL annotation of multi-turn dialogue is\nvery expensive, leading to training data sparsity. In this paper, we propose a\nnovel decoupled multi-turn Text-to-SQL framework, where an utterance rewrite\nmodel first explicitly solves completion of dialogue context, and then a\nsingle-turn Text-to-SQL parser follows. A dual learning approach is also\nproposed for the utterance rewrite model to address the data sparsity problem.\nCompared with end-to-end approaches, the proposed decoupled method can achieve\nexcellent performance without any annotated in-domain data. With just a few\nannotated rewrite cases, the decoupled method outperforms the released\nstate-of-the-art end-to-end models on both SParC and CoSQL datasets.",
          "link": "http://arxiv.org/abs/2106.02282",
          "publishedOn": "2021-06-07T03:06:11.294Z",
          "wordCount": 613,
          "title": "Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn Text-to-SQL. (arXiv:2106.02282v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>",
          "description": "In recent years, we have seen a colossal effort in pre-training multilingual\ntext encoders using large-scale corpora in many languages to facilitate\ncross-lingual transfer learning. However, due to typological differences across\nlanguages, the cross-lingual transfer is challenging. Nevertheless, language\nsyntax, e.g., syntactic dependencies, can bridge the typological gap. Previous\nworks have shown that pre-trained multilingual encoders, such as mBERT\n\\cite{devlin-etal-2019-bert}, capture language syntax, helping cross-lingual\ntransfer. This work shows that explicitly providing language syntax and\ntraining mBERT using an auxiliary objective to encode the universal dependency\ntree structure helps cross-lingual transfer. We perform rigorous experiments on\nfour NLP tasks, including text classification, question answering, named entity\nrecognition, and task-oriented semantic parsing. The experiment results show\nthat syntax-augmented mBERT improves cross-lingual transfer on popular\nbenchmarks, such as PAWS-X and MLQA, by 1.4 and 1.6 points on average across\nall languages. In the \\emph{generalized} transfer setting, the performance\nboosted significantly, with 3.9 and 3.1 points on average in PAWS-X and MLQA.",
          "link": "http://arxiv.org/abs/2106.02134",
          "publishedOn": "2021-06-07T03:06:11.281Z",
          "wordCount": 587,
          "title": "Syntax-augmented Multilingual BERT for Cross-lingual Transfer. (arXiv:2106.02134v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Transformer has been widely adopted in Neural Machine Translation (NMT)\nbecause of its large capacity and parallel training of sequence generation.\nHowever, the deployment of Transformer is challenging because different\nscenarios require models of different complexities and scales. Naively training\nmultiple Transformers is redundant in terms of both computation and memory. In\nthis paper, we propose a novel scalable Transformers, which naturally contains\nsub-Transformers of different scales and have shared parameters. Each\nsub-Transformer can be easily obtained by cropping the parameters of the\nlargest Transformer. A three-stage training scheme is proposed to tackle the\ndifficulty of training the scalable Transformers, which introduces additional\nsupervisions from word-level and sequence-level self-distillation. Extensive\nexperiments were conducted on WMT EN-De and En-Fr to validate our proposed\nscalable Transformers.",
          "link": "http://arxiv.org/abs/2106.02242",
          "publishedOn": "2021-06-07T03:06:11.262Z",
          "wordCount": 548,
          "title": "Scalable Transformers for Neural Machine Translation. (arXiv:2106.02242v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1\">Saurabhchand Bhati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1\">Jes&#xfa;s Villalba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Velazquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1\">Najim Dehak</a>",
          "description": "Automatic detection of phoneme or word-like units is one of the core\nobjectives in zero-resource speech processing. Recent attempts employ\nself-supervised training methods, such as contrastive predictive coding (CPC),\nwhere the next frame is predicted given past context. However, CPC only looks\nat the audio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework that can model the\nsignal structure at a higher level e.g. at the phoneme level. In this\nframework, a convolutional neural network learns frame-level representation\nfrom the raw waveform via noise-contrastive estimation (NCE). A differentiable\nboundary detector finds variable-length segments, which are then used to\noptimize a segment encoder via NCE to learn segment representations. The\ndifferentiable boundary detector allows us to train frame-level and\nsegment-level encoders jointly. Typically, phoneme and word segmentation are\ntreated as separate tasks. We unify them and experimentally show that our\nsingle model outperforms existing phoneme and word segmentation methods on\nTIMIT and Buckeye datasets. We analyze the impact of boundary threshold and\nwhen is the right time to include the segmental loss in the learning process.",
          "link": "http://arxiv.org/abs/2106.02170",
          "publishedOn": "2021-06-07T03:06:11.254Z",
          "wordCount": 628,
          "title": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Unanue_I/0/1/0/all/0/1\">Inigo Jauregi Unanue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parnell_J/0/1/0/all/0/1\">Jacob Parnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccardi_M/0/1/0/all/0/1\">Massimo Piccardi</a>",
          "description": "Neural machine translation models are often biased toward the limited\ntranslation references seen during training. To amend this form of overfitting,\nin this paper we propose fine-tuning the models with a novel training objective\nbased on the recently-proposed BERTScore evaluation metric. BERTScore is a\nscoring function based on contextual embeddings that overcomes the typical\nlimitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing\ntranslations that are different from the references, yet close in the\ncontextual embedding space, to be treated as substantially correct. To be able\nto use BERTScore as a training objective, we propose three approaches for\ngenerating soft predictions, allowing the network to remain completely\ndifferentiable end-to-end. Experiments carried out over four, diverse language\npairs have achieved improvements of up to 0.58 pp (3.28%) in BLEU score and up\nto 0.76 pp (0.98%) in BERTScore (F_BERT) when fine-tuning a strong baseline.",
          "link": "http://arxiv.org/abs/2106.02208",
          "publishedOn": "2021-06-07T03:06:11.245Z",
          "wordCount": 571,
          "title": "BERTTune: Fine-Tuning Neural Machine Translation with BERTScore. (arXiv:2106.02208v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Taiqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagae_K/0/1/0/all/0/1\">Kenji Sagae</a>",
          "description": "Cross-lingual language tasks typically require a substantial amount of\nannotated data or parallel translation data. We explore whether language\nrepresentations that capture relationships among languages can be learned and\nsubsequently leveraged in cross-lingual tasks without the use of parallel data.\nWe generate dense embeddings for 29 languages using a denoising autoencoder,\nand evaluate the embeddings using the World Atlas of Language Structures (WALS)\nand two extrinsic tasks in a zero-shot setting: cross-lingual dependency\nparsing and cross-lingual natural language inference.",
          "link": "http://arxiv.org/abs/2106.02082",
          "publishedOn": "2021-06-07T03:06:11.236Z",
          "wordCount": 506,
          "title": "Language Embeddings for Typology and Cross-lingual Transfer Learning. (arXiv:2106.02082v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>",
          "description": "The NLP community has seen substantial recent interest in grounding to\nfacilitate interaction between language technologies and the world. However, as\na community, we use the term broadly to reference any linking of text to data\nor non-textual modality. In contrast, Cognitive Science more formally defines\n\"grounding\" as the process of establishing what mutual information is required\nfor successful communication between two interlocutors -- a definition which\nmight implicitly capture the NLP usage but differs in intent and scope. We\ninvestigate the gap between these definitions and seek answers to the following\nquestions: (1) What aspects of grounding are missing from NLP tasks? Here we\npresent the dimensions of coordination, purviews and constraints. (2) How is\nthe term \"grounding\" used in the current research? We study the trends in\ndatasets, domains, and tasks introduced in recent NLP conferences. And finally,\n(3) How to advance our current definition to bridge the gap with Cognitive\nScience? We present ways to both create new tasks or repurpose existing ones to\nmake advancements towards achieving a more complete sense of grounding.",
          "link": "http://arxiv.org/abs/2106.02192",
          "publishedOn": "2021-06-07T03:06:11.226Z",
          "wordCount": 599,
          "title": "Grounding 'Grounding' in NLP. (arXiv:2106.02192v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "A good open-domain chatbot should avoid presenting contradictory responses\nabout facts or opinions in a conversational session, known as its consistency\ncapacity. However, evaluating the consistency capacity of a chatbot is still\nchallenging. Employing human judges to interact with chatbots on purpose to\ncheck their capacities is costly and low-efficient, and difficult to get rid of\nsubjective bias. In this paper, we propose the Addressing Inquiries about\nHistory (AIH), an efficient and practical framework for the consistency\nevaluation. At the conversation stage, AIH attempts to address appropriate\ninquiries about the dialogue history to induce the chatbot to redeclare the\nhistorical facts or opinions. We carry out the conversation between chatbots,\nwhich is more efficient than the human-bot interaction and can also alleviate\nthe subjective bias. In this way, we manage to rapidly obtain a dialog session\nthat contains responses with high contradiction possibilities. At the\ncontradiction recognition stage, we can either employ human judges or a natural\nlanguage inference (NLI) model to recognize whether the answers to the\ninquiries are contradictory with history. Finally, we are able to rank chatbots\naccording to the contradiction statistics. Experiments on open-domain chatbots\nshow that our approach can efficiently and reliably assess the consistency\ncapacity of chatbots and achieve a high ranking correlation with the human\nevaluation. We release the framework and hope to help improve the consistency\ncapacity of chatbots. \\footnote{\\url{https://github.com/ictnlp/AIH}}",
          "link": "http://arxiv.org/abs/2106.02228",
          "publishedOn": "2021-06-07T03:06:11.204Z",
          "wordCount": 678,
          "title": "Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency. (arXiv:2106.02228v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-07T03:06:11.194Z",
          "wordCount": 613,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Mihir Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddhant_A/0/1/0/all/0/1\">Aditya Siddhant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1\">Rami Al-Rfou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Linting Xue</a>",
          "description": "Recently, mT5 - a massively multilingual version of T5 - leveraged a unified\ntext-to-text format to attain state-of-the-art results on a wide variety of\nmultilingual NLP tasks. In this paper, we investigate the impact of\nincorporating parallel data into mT5 pre-training. We find that multi-tasking\nlanguage modeling with objectives such as machine translation during\npre-training is a straightforward way to improve performance on downstream\nmultilingual and cross-lingual tasks. However, the gains start to diminish as\nthe model capacity increases, suggesting that parallel data might not be as\nessential for larger models. At the same time, even at larger model sizes, we\nfind that pre-training with parallel data still provides benefits in the\nlimited labelled data regime.",
          "link": "http://arxiv.org/abs/2106.02171",
          "publishedOn": "2021-06-07T03:06:11.185Z",
          "wordCount": 561,
          "title": "nmT5 -- Is parallel data still relevant for pre-training massively multilingual language models?. (arXiv:2106.02171v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_J/0/1/0/all/0/1\">Justin Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_L/0/1/0/all/0/1\">Leigh Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_A/0/1/0/all/0/1\">Allison Perrone</a>",
          "description": "Chatbots are popular machine partners for task-oriented and social\ninteractions. Human-human computer-mediated communication research has explored\nhow people express their gender and sexuality in online social interactions,\nbut little is known about whether and in what way chatbots do the same. We\nconducted semi-structured interviews with 5 text-based conversational agents to\nexplore this topic Through these interviews, we identified 6 common themes\naround the expression of gender and sexual identity: identity description,\nidentity formation, peer acceptance, positive reflection, uncomfortable\nfeelings and off-topic responses. Chatbots express gender and sexuality\nexplicitly and through relation of experience and emotions, mimicking the human\nlanguage on which they are trained. It is nevertheless evident that chatbots\ndiffer from human dialogue partners as they lack the flexibility and\nunderstanding enabled by lived human experience. While chatbots are proficient\nin using language to express identity, they also display a lack of authentic\nexperiences of gender and sexuality.",
          "link": "http://arxiv.org/abs/2106.02076",
          "publishedOn": "2021-06-07T03:06:11.122Z",
          "wordCount": 583,
          "title": "LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots. (arXiv:2106.02076v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kapron_King_A/0/1/0/all/0/1\">Anna Kapron-King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yang Xu</a>",
          "description": "The use of euphemisms is a known driver of language change. It has been\nproposed that women use euphemisms more than men. Although there have been\nseveral studies investigating gender differences in language, the claim about\neuphemism usage has not been tested comprehensively through time. If women do\nuse euphemisms more, this could mean that women also lead the formation of new\neuphemisms and language change over time. Using four large diachronic text\ncorpora of English, we evaluate the claim that women use euphemisms more than\nmen through a quantitative analysis. We assembled a list of 106 euphemism-taboo\npairs to analyze their relative use through time by each gender in the corpora.\nContrary to the existing belief, our results show that women do not use\neuphemisms with a higher proportion than men. We repeated the analysis using\ndifferent subsets of the euphemism-taboo pairs list and found that our result\nwas robust. Our study indicates that in a broad range of settings involving\nboth speech and writing, and with varying degrees of formality, women do not\nuse or form euphemisms more than men.",
          "link": "http://arxiv.org/abs/2106.02083",
          "publishedOn": "2021-06-07T03:06:11.095Z",
          "wordCount": 625,
          "title": "A diachronic evaluation of gender asymmetry in euphemism. (arXiv:2106.02083v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1\">Elizabeth Excell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>",
          "description": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.",
          "link": "http://arxiv.org/abs/2106.02183",
          "publishedOn": "2021-06-07T03:06:11.070Z",
          "wordCount": 624,
          "title": "Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.01300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Personalized news recommendation methods are widely used in online news\nservices. These methods usually recommend news based on the matching between\nnews content and user interest inferred from historical behaviors. However,\nthese methods usually have difficulties in making accurate recommendations to\ncold-start users, and tend to recommend similar news with those users have\nread. In general, popular news usually contain important information and can\nattract users with different interests. Besides, they are usually diverse in\ncontent and topic. Thus, in this paper we propose to incorporate news\npopularity information to alleviate the cold-start and diversity problems for\npersonalized news recommendation. In our method, the ranking score for\nrecommending a candidate news to a target user is the combination of a\npersonalized matching score and a news popularity score. The former is used to\ncapture the personalized user interest in news. The latter is used to measure\ntime-aware popularity of candidate news, which is predicted based on news\ncontent, recency, and real-time CTR using a unified framework. Besides, we\npropose a popularity-aware user encoder to eliminate the popularity bias in\nuser behaviors for accurate interest modeling. Experiments on two real-world\ndatasets show our method can effectively improve the accuracy and diversity for\nnews recommendation.",
          "link": "http://arxiv.org/abs/2106.01300",
          "publishedOn": "2021-06-11T01:42:15.104Z",
          "wordCount": 653,
          "title": "PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. (arXiv:2106.01300v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Qingtao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingjian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jia Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jun Lei</a>",
          "description": "Click-through rate (CTR) prediction plays an important role in online\nadvertising and recommender systems. In practice, the training of CTR models\ndepends on click data which is intrinsically biased towards higher positions\nsince higher position has higher CTR by nature. Existing methods such as actual\nposition training with fixed position inference and inverse propensity weighted\ntraining with no position inference alleviate the bias problem to some extend.\nHowever, the different treatment of position information between training and\ninference will inevitably lead to inconsistency and sub-optimal online\nperformance. Meanwhile, the basic assumption of these methods, i.e., the click\nprobability is the product of examination probability and relevance\nprobability, is oversimplified and insufficient to model the rich interaction\nbetween position and other information. In this paper, we propose a Deep\nPosition-wise Interaction Network (DPIN) to efficiently combine all candidate\nitems and positions for estimating CTR at each position, achieving consistency\nbetween offline and online as well as modeling the deep non-linear interaction\namong position, user, context and item under the limit of serving performance.\nFollowing our new treatment to the position bias in CTR prediction, we propose\na new evaluation metrics named PAUC (position-wise AUC) that is suitable for\nmeasuring the ranking quality at a given position. Through extensive\nexperiments on a real world dataset, we show empirically that our method is\nboth effective and efficient in solving position bias problem. We have also\ndeployed our method in production and observed statistically significant\nimprovement over a highly optimized baseline in a rigorous A/B test.",
          "link": "http://arxiv.org/abs/2106.05482",
          "publishedOn": "2021-06-11T01:42:13.961Z",
          "wordCount": 687,
          "title": "Deep Position-wise Interaction Network for CTR Prediction. (arXiv:2106.05482v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2008.09093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Canjia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1\">Andrew Yates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacAvaney_S/0/1/0/all/0/1\">Sean MacAvaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yingfei Sun</a>",
          "description": "Pretrained transformer models, such as BERT and T5, have shown to be highly\neffective at ad-hoc passage and document ranking. Due to inherent sequence\nlength limits of these models, they need to be run over a document's passages,\nrather than processing the entire document sequence at once. Although several\napproaches for aggregating passage-level signals have been proposed, there has\nyet to be an extensive comparison of these techniques. In this work, we explore\nstrategies for aggregating relevance signals from a document's passages into a\nfinal ranking score. We find that passage representation aggregation techniques\ncan significantly improve over techniques proposed in prior work, such as\ntaking the maximum passage score. We call this new approach PARADE. In\nparticular, PARADE can significantly improve results on collections with broad\ninformation needs where relevance signals can be spread throughout the document\n(such as TREC Robust04 and GOV2). Meanwhile, less complex aggregation\ntechniques may work better on collections with an information need that can\noften be pinpointed to a single passage (such as TREC DL and TREC Genomics). We\nalso conduct efficiency analyses, and highlight several strategies for\nimproving transformer-based aggregation.",
          "link": "http://arxiv.org/abs/2008.09093",
          "publishedOn": "2021-06-11T01:42:13.629Z",
          "wordCount": 641,
          "title": "PARADE: Passage Representation Aggregation for Document Reranking. (arXiv:2008.09093v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Feng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>",
          "description": "Click-through rate (CTR) prediction, whose aim is to predict the probability\nof whether a user will click on an item, is an essential task for many online\napplications. Due to the nature of data sparsity and high dimensionality in CTR\nprediction, a key to making effective prediction is to model high-order feature\ninteraction among feature fields. To explicitly model high-order feature\ninteraction, an efficient way is to perform inner product of feature embeddings\nwith self-attentive neural networks. To better model complex feature\ninteraction, in this paper we propose a novel DisentanglEd Self-atTentIve\nNEtwork (DESTINE) framework for CTR prediction that explicitly decouples the\ncomputation of unary importance from pairwise interaction. Specifically, the\nunary term models the general impact of one feature on all other features,\nwhereas the whitened pairwise interaction term contributes to learning the pure\nimportance score for each feature interaction. We conduct extensive experiments\nframework using two real-world benchmark datasets. The results show that\nDESTINE not only maintains computational efficiency but obtains performance\nimprovements over state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2101.03654",
          "publishedOn": "2021-06-11T01:42:13.345Z",
          "wordCount": 630,
          "title": "Disentangled Self-Attentive Neural Networks for Click-Through Rate Prediction. (arXiv:2101.03654v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1\">Sophia Althammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1\">Mark Buckley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "Domain-specific contextualized language models have demonstrated substantial\neffectiveness gains for domain-specific downstream tasks, like similarity\nmatching, entity recognition or information retrieval. However successfully\napplying such models in highly specific language domains requires domain\nadaptation of the pre-trained models. In this paper we propose the empirically\nmotivated Linguistically Informed Masking (LIM) method to focus\ndomain-adaptative pre-training on the linguistic patterns of patents, which use\na highly technical sublanguage. We quantify the relevant differences between\npatent, scientific and general-purpose language and demonstrate for two\ndifferent language models (BERT and SciBERT) that domain adaptation with LIM\nleads to systematically improved representations by evaluating the performance\nof the domain-adapted representations of patent language on two independent\ndownstream tasks, the IPC classification and similarity matching. We\ndemonstrate the impact of balancing the learning from different information\nsources during domain adaptation for the patent domain. We make the source code\nas well as the domain-adaptive pre-trained patent language models publicly\navailable at https://github.com/sophiaalthammer/patent-lim.",
          "link": "http://arxiv.org/abs/2106.05768",
          "publishedOn": "2021-06-11T01:42:13.250Z",
          "wordCount": 599,
          "title": "Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hermanns_J/0/1/0/all/0/1\">Judith Hermanns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munkhoeva_M/0/1/0/all/0/1\">Marina Munkhoeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottin_D/0/1/0/all/0/1\">Davide Mottin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1\">Panagiotis Karras</a>",
          "description": "What is the best way to match the nodes of two graphs? This graph alignment\nproblem generalizes graph isomorphism and arises in applications from social\nnetwork analysis to bioinformatics. Some solutions assume that auxiliary\ninformation on known matches or node or edge attributes is available, or\nutilize arbitrary graph features. Such methods fare poorly in the pure form of\nthe problem, in which only graph structures are given. Other proposals\ntranslate the problem to one of aligning node embeddings, yet, by doing so,\nprovide only a single-scale view of the graph.In this paper, we transfer the\nshape-analysis concept of functional maps from the continuous to the discrete\ncase, and treat the graph alignment problem as a special case of the problem of\nfinding a mapping between functions on graphs. We present GRASP, a method that\nfirst establishes a correspondence between functions derived from Laplacian\nmatrix eigenvectors, which capture multiscale structural characteristics,and\nthen exploits this correspondence to align nodes. Our experimental study,\nfeaturing noise levels higher than anything used in previous studies, shows\nthat GRASP outperforms state-of-the-art methods for graph alignment across\nnoise levels and graph types.",
          "link": "http://arxiv.org/abs/2106.05729",
          "publishedOn": "2021-06-11T01:42:13.115Z",
          "wordCount": 617,
          "title": "GRASP: Graph Alignment through Spectral Signatures. (arXiv:2106.05729v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/1909.12425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "This article presents the emerging topic of dynamic search (DS). To position\ndynamic search in a larger research landscape, the article discusses in detail\nits relationship to related research topics and disciplines. The article\nreviews approaches to modeling dynamics during information seeking, with an\nemphasis on Reinforcement Learning (RL)-enabled methods. Details are given for\nhow different approaches are used to model interactions among the human user,\nthe search system, and the environment. The paper ends with a review of\nevaluations of dynamic search systems.",
          "link": "http://arxiv.org/abs/1909.12425",
          "publishedOn": "2021-06-11T01:42:13.101Z",
          "wordCount": 539,
          "title": "Dynamic Search -- Optimizing the Game of Information Seeking. (arXiv:1909.12425v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brack_A/0/1/0/all/0/1\">Arthur Brack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1\">Anett Hoppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "Citation recommendation for research papers is a valuable task that can help\nresearchers improve the quality of their work by suggesting relevant related\nwork. Current approaches for this task rely primarily on the text of the papers\nand the citation network. In this paper, we propose to exploit an additional\nsource of information, namely research knowledge graphs (KG) that interlink\nresearch papers based on mentioned scientific concepts. Our experimental\nresults demonstrate that the combination of information from research KGs with\nexisting state-of-the-art approaches is beneficial. Experimental results are\npresented for the STM-KG (STM: Science, Technology, Medicine), which is an\nautomatically populated knowledge graph based on the scientific concepts\nextracted from papers of ten domains. The proposed approach outperforms the\nstate of the art with a mean average precision of 20.6% (+0.8) for the top-50\nretrieved results.",
          "link": "http://arxiv.org/abs/2106.05633",
          "publishedOn": "2021-06-11T01:42:13.081Z",
          "wordCount": 578,
          "title": "Citation Recommendation for Research Papers via Knowledge Graphs. (arXiv:2106.05633v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meuschke_N/0/1/0/all/0/1\">Norman Meuschke</a>",
          "description": "Identifying academic plagiarism is a pressing problem, among others, for\nresearch institutions, publishers, and funding organizations. Detection\napproaches proposed so far analyze lexical, syntactical, and semantic text\nsimilarity. These approaches find copied, moderately reworded, and literally\ntranslated text. However, reliably detecting disguised plagiarism, such as\nstrong paraphrases, sense-for-sense translations, and the reuse of non-textual\ncontent and ideas, is an open research problem.\n\nThe thesis addresses this problem by proposing plagiarism detection\napproaches that implement a different concept: analyzing non-textual content in\nacademic documents, specifically citations, images, and mathematical content.\n\nTo validate the effectiveness of the proposed detection approaches, the\nthesis presents five evaluations that use real cases of academic plagiarism and\nexploratory searches for unknown cases.\n\nThe evaluation results show that non-textual content elements contain a high\ndegree of semantic information, are language-independent, and largely immutable\nto the alterations that authors typically perform to conceal plagiarism.\nAnalyzing non-textual content complements text-based detection approaches and\nincreases the detection effectiveness, particularly for disguised forms of\nacademic plagiarism.\n\nTo demonstrate the benefit of combining non-textual and text-based detection\nmethods, the thesis describes the first plagiarism detection system that\nintegrates the analysis of citation-based, image-based, math-based, and\ntext-based document similarity. The system's user interface employs\nvisualizations that significantly reduce the effort and time users must invest\nin examining content similarity.",
          "link": "http://arxiv.org/abs/2106.05764",
          "publishedOn": "2021-06-11T01:42:13.057Z",
          "wordCount": 651,
          "title": "Analyzing Non-Textual Content Elements to Detect Academic Plagiarism. (arXiv:2106.05764v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1\">Devendra Singh Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>",
          "description": "We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.",
          "link": "http://arxiv.org/abs/2106.05346",
          "publishedOn": "2021-06-11T01:42:12.824Z",
          "wordCount": 628,
          "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:12.798Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2012.14210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.",
          "link": "http://arxiv.org/abs/2012.14210",
          "publishedOn": "2021-06-10T01:56:45.233Z",
          "wordCount": 565,
          "title": "The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qitian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaofeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "Recommendation models can effectively estimate underlying user interests and\npredict one's future behaviors by factorizing an observed user-item rating\nmatrix into products of two sets of latent factors. However, the user-specific\nembedding factors can only be learned in a transductive way, making it\ndifficult to handle new users on-the-fly. In this paper, we propose an\ninductive collaborative filtering framework that contains two representation\nmodels. The first model follows conventional matrix factorization which\nfactorizes a group of key users' rating matrix to obtain meta latents. The\nsecond model resorts to attention-based structure learning that estimates\nhidden relations from query to key users and learns to leverage meta latents to\ninductively compute embeddings for query users via neural message passing. Our\nmodel enables inductive representation learning for users and meanwhile\nguarantees equivalent representation capacity as matrix factorization.\nExperiments demonstrate that our model achieves promising results for\nrecommendation on few-shot users with limited training ratings and new unseen\nusers which are commonly encountered in open-world recommender systems.",
          "link": "http://arxiv.org/abs/2007.04833",
          "publishedOn": "2021-06-10T01:56:45.180Z",
          "wordCount": 626,
          "title": "Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Limin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Interactive Information Retrieval (IIR) and Reinforcement Learning (RL) share\nmany commonalities, including an agent who learns while interacts, a long-term\nand complex goal, and an algorithm that explores and adapts. To successfully\napply RL methods to IIR, one challenge is to obtain sufficient relevance labels\nto train the RL agents, which are infamously known as sample inefficient.\nHowever, in a text corpus annotated for a given query, it is not the relevant\ndocuments but the irrelevant documents that predominate. This would cause very\nunbalanced training experiences for the agent and prevent it from learning any\npolicy that is effective. Our paper addresses this issue by using domain\nrandomization to synthesize more relevant documents for the training. Our\nexperimental results on the Text REtrieval Conference (TREC) Dynamic Domain\n(DD) 2017 Track show that the proposed method is able to boost an RL agent's\nlearning effectiveness by 22\\% in dealing with unseen situations.",
          "link": "http://arxiv.org/abs/2006.03185",
          "publishedOn": "2021-06-10T01:56:45.173Z",
          "wordCount": 615,
          "title": "Balancing Reinforcement Learning Training Experiences in Interactive Information Retrieval. (arXiv:2006.03185v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.00606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Most neural Information Retrieval (Neu-IR) models derive query-to-document\nranking scores based on term-level matching. Inspired by TileBars, a classical\nterm distribution visualization method, in this paper, we propose a novel\nNeu-IR model that handles query-to-document matching at the subtopic and higher\nlevels. Our system first splits the documents into topical segments,\n\"visualizes\" the matchings between the query and the segments, and then feeds\nan interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final\nranking scores. DeepTileBars models the relevance signals occurring at\ndifferent granularities in a document's topic hierarchy. It better captures the\ndiscourse structure of a document and thus the matching patterns. Although its\ndesign and implementation are light-weight, DeepTileBars outperforms other\nstate-of-the-art Neu-IR models on benchmark datasets including the Text\nREtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.",
          "link": "http://arxiv.org/abs/1811.00606",
          "publishedOn": "2021-06-10T01:56:45.165Z",
          "wordCount": 612,
          "title": "DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1\">Gao Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao-Li Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1\">Minghui Qiu</a>",
          "description": "Session-based recommendation (SBR) is a challenging task, which aims at\nrecommending items based on anonymous behavior sequences. Almost all the\nexisting solutions for SBR model user preference only based on the current\nsession without exploiting the other sessions, which may contain both relevant\nand irrelevant item-transitions to the current session. This paper proposes a\nnovel approach, called Global Context Enhanced Graph Neural Networks (GCE-GNN)\nto exploit item transitions over all sessions in a more subtle manner for\nbetter inferring the user preference of the current session. Specifically,\nGCE-GNN learns two levels of item embeddings from session graph and global\ngraph, respectively: (i) Session graph, which is to learn the session-level\nitem embedding by modeling pairwise item-transitions within the current\nsession; and (ii) Global graph, which is to learn the global-level item\nembedding by modeling pairwise item-transitions over all sessions. In GCE-GNN,\nwe propose a novel global-level item representation learning layer, which\nemploys a session-aware attention mechanism to recursively incorporate the\nneighbors' embeddings of each node on the global graph. We also design a\nsession-level item representation learning layer, which employs a GNN on the\nsession graph to learn session-level item embeddings within the current\nsession. Moreover, GCE-GNN aggregates the learnt item representations in the\ntwo levels with a soft attention mechanism. Experiments on three benchmark\ndatasets demonstrate that GCE-GNN outperforms the state-of-the-art methods\nconsistently.",
          "link": "http://arxiv.org/abs/2106.05081",
          "publishedOn": "2021-06-10T01:56:45.154Z",
          "wordCount": 669,
          "title": "Global Context Enhanced Graph Neural Networks for Session-based Recommendation. (arXiv:2106.05081v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiangli Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1\">Rong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhirong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiuqiang He</a>",
          "description": "Recommender systems are often asked to serve multiple recommendation\nscenarios or domains. Fine-tuning a pre-trained CTR model from source domains\nand adapting it to a target domain allows knowledge transferring. However,\noptimizing all the parameters of the pre-trained network may result in\nover-fitting if the target dataset is small and the number of parameters is\nlarge. This leads us to think of directly reusing parameters in the pre-trained\nmodel which represent more general features learned from multiple domains.\nHowever, the design of freezing or fine-tuning layers of parameters requires\nmuch manual effort since the decision highly depends on the pre-trained model\nand target instances. In this work, we propose an end-to-end transfer learning\nframework, called Automatic Fine-Tuning (AutoFT), for CTR prediction. AutoFT\nconsists of a field-wise transfer policy and a layer-wise transfer policy. The\nfield-wise transfer policy decides how the pre-trained embedding\nrepresentations are frozen or fine-tuned based on the given instance from the\ntarget domain. The layer-wise transfer policy decides how the high?order\nfeature representations are transferred layer by layer. Extensive experiments\non two public benchmark datasets and one private industrial dataset demonstrate\nthat AutoFT can significantly improve the performance of CTR prediction\ncompared with state-of-the-art transferring approaches.",
          "link": "http://arxiv.org/abs/2106.04873",
          "publishedOn": "2021-06-10T01:56:45.129Z",
          "wordCount": 635,
          "title": "AutoFT: Automatic Fine-Tune for Parameters Transfer Learning in Click-Through Rate Prediction. (arXiv:2106.04873v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/1912.00753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "A core interest in building Artificial Intelligence (AI) agents is to let\nthem interact with and assist humans. One example is Dynamic Search (DS), which\nmodels the process that a human works with a search engine agent to accomplish\na complex and goal-oriented task. Early DS agents using Reinforcement Learning\n(RL) have only achieved limited success for (1) their lack of direct control\nover which documents to return and (2) the difficulty to recover from wrong\nsearch trajectories. In this paper, we present a novel corpus-level end-to-end\nexploration (CE3) method to address these issues. In our method, an entire text\ncorpus is compressed into a global low-dimensional representation, which\nenables the agent to gain access to the full state and action spaces, including\nthe under-explored areas. We also propose a new form of retrieval function,\nwhose linear approximation allows end-to-end manipulation of documents.\nExperiments on the Text REtrieval Conference (TREC) Dynamic Domain (DD) Track\nshow that CE3 outperforms the state-of-the-art DS systems.",
          "link": "http://arxiv.org/abs/1912.00753",
          "publishedOn": "2021-06-10T01:56:45.121Z",
          "wordCount": 618,
          "title": "Corpus-Level End-to-End Exploration for Interactive Systems. (arXiv:1912.00753v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper considers the single-server Private Linear Transformation (PLT)\nproblem with individual privacy guarantees. In this problem, there is a user\nthat wishes to obtain $L$ independent linear combinations of a $D$-subset of\nmessages belonging to a dataset of $K$ messages stored on a single server. The\ngoal is to minimize the download cost while keeping the identity of each\nmessage required for the computation individually private. The individual\nprivacy requirement ensures that the identity of each individual message\nrequired for the computation is kept private. This is in contrast to the\nstricter notion of joint privacy that protects the entire set of identities of\nall messages used for the computation, including the correlations between these\nidentities. The notion of individual privacy captures a broad set of practical\napplications. For example, such notion is relevant when the dataset contains\ninformation about individuals, each of them requires privacy guarantees for\ntheir data access patterns. We focus on the setting in which the required\nlinear transformation is associated with a maximum distance separable (MDS)\nmatrix. In particular, we require that the matrix of coefficients pertaining to\nthe required linear combinations is the generator matrix of an MDS code. We\nestablish lower and upper bounds on the capacity of PLT with individual\nprivacy, where the capacity is defined as the supremum of all achievable\ndownload rates. We show that our bounds are tight under certain conditions.",
          "link": "http://arxiv.org/abs/2106.05222",
          "publishedOn": "2021-06-10T01:56:45.102Z",
          "wordCount": 678,
          "title": "Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine Reinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>",
          "description": "Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.",
          "link": "http://arxiv.org/abs/2106.05194",
          "publishedOn": "2021-06-10T01:56:45.093Z",
          "wordCount": 593,
          "title": "DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chios_I/0/1/0/all/0/1\">Ioannis Chios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>",
          "description": "In this paper we address the explainability of web search engines. We propose\ntwo explainable elements on the search engine result page: a visualization of\nquery term weights and a visualization of passage relevance. The idea is that\nsearch engines that indicate to the user why results are retrieved are valued\nhigher by users and gain user trust. We deduce the query term weights from the\nterm gating network in the Deep Relevance Matching Model (DRMM) and visualize\nthem as a doughnut chart. In addition, we train a passage-level ranker with\nDRMM that selects the most relevant passage from each document and shows it as\nsnippet on the result page. Next to the snippet we show a document thumbnail\nwith this passage highlighted. We evaluate the proposed interface in an online\nuser study, asking users to judge the explainability and assessability of the\ninterface. We found that users judge our proposed interface significantly more\nexplainable and easier to assess than a regular search engine result page.\nHowever, they are not significantly better in selecting the relevant documents\nfrom the top-5. This indicates that the explainability of the search engine\nresult page leads to a better user experience. Thus, we conclude that the\nproposed explainable elements are promising as visualization for search engine\nusers.",
          "link": "http://arxiv.org/abs/2106.05147",
          "publishedOn": "2021-06-10T01:56:45.056Z",
          "wordCount": 665,
          "title": "Helping results assessment by adding explainable elements to the deep relevance matching model. (arXiv:2106.05147v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05260",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Adams_J/0/1/0/all/0/1\">Jane L. Adams</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deluca_T/0/1/0/all/0/1\">Todd F. Deluca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danforth_C/0/1/0/all/0/1\">Christopher M. Danforth</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dodds_P/0/1/0/all/0/1\">Peter S. Dodds</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuhang Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Anastasakis_K/0/1/0/all/0/1\">Konstantinos Anastasakis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Choi_B/0/1/0/all/0/1\">Boyoon Choi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Min_A/0/1/0/all/0/1\">Allison Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bessey_M/0/1/0/all/0/1\">Michael M. Bessey</a>",
          "description": "Data scientists across disciplines are increasingly in need of exploratory\nanalysis tools for data sets with a high volume of features. We expand upon\ngraph mining approaches for exploratory analysis of high-dimensional data to\nintroduce Sirius, a visualization package for researchers to explore feature\nrelationships among mixed data types using mutual information and network\nbackbone sparsification. Visualizations of feature relationships aid data\nscientists in finding meaningful dependence among features, which can engender\nfurther analysis for feature selection, feature extraction, projection,\nidentification of proxy variables, or insight into temporal variation at the\nmacro scale. Graph mining approaches for feature analysis exist, such as\nassociation networks of binary features, or correlation networks of\nquantitative features, but mixed data types present a unique challenge for\ndeveloping comprehensive feature networks for exploratory analysis. Using an\ninformation theoretic approach, Sirius supports heterogeneous data sets\nconsisting of binary, continuous quantitative, and discrete categorical data\ntypes, and provides a user interface exploring feature pairs with high mutual\ninformation scores. We leverage a backbone sparsification approach from network\ntheory as a dimensionality reduction technique, which probabilistically trims\nedges according to the local network context. Sirius is an open source Python\npackage and Django web application for exploratory visualization, which can be\ndeployed in data analysis pipelines. The Sirius codebase and exemplary data\nsets can be found at: https://github.com/compstorylab/sirius",
          "link": "http://arxiv.org/abs/2106.05260",
          "publishedOn": "2021-06-10T01:56:45.043Z",
          "wordCount": 677,
          "title": "Sirius: A Mutual Information Tool for Exploratory Visualization of Mixed Data. (arXiv:2106.05260v1 [stat.AP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "In this paper, we explore and evaluate the use of ranking-based objective\nfunctions for learning simultaneously a word string and a word image encoder.\nWe consider retrieval frameworks in which the user expects a retrieval list\nranked according to a defined relevance score. In the context of a word\nspotting problem, the relevance score has been set according to the string edit\ndistance from the query string. We experimentally demonstrate the competitive\nperformance of the proposed model on query-by-string word spotting for both,\nhandwritten and real scene word images. We also provide the results for\nquery-by-example word spotting, although it is not the main focus of this work.",
          "link": "http://arxiv.org/abs/2106.05144",
          "publishedOn": "2021-06-10T01:56:44.964Z",
          "wordCount": 552,
          "title": "Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper introduces the problem of Private Linear Transformation (PLT)\nwhich generalizes the problems of private information retrieval and private\nlinear computation. The PLT problem includes one or more remote server(s)\nstoring (identical copies of) $K$ messages and a user who wants to compute $L$\nindependent linear combinations of a $D$-subset of messages. The objective of\nthe user is to perform the computation by downloading minimum possible amount\nof information from the server(s), while protecting the identities of the $D$\nmessages required for the computation. In this work, we focus on the\nsingle-server setting of the PLT problem when the identities of the $D$\nmessages required for the computation must be protected jointly. We consider\ntwo different models, depending on whether the coefficient matrix of the\nrequired $L$ linear combinations generates a Maximum Distance Separable (MDS)\ncode. We prove that the capacity for both models is given by $L/(K-D+L)$, where\nthe capacity is defined as the supremum of all achievable download rates. Our\nconverse proofs are based on linear-algebraic and information-theoretic\narguments that establish connections between PLT schemes and linear codes. We\nalso present an achievability scheme for each of the models being considered.",
          "link": "http://arxiv.org/abs/2106.05220",
          "publishedOn": "2021-06-10T01:56:44.923Z",
          "wordCount": 638,
          "title": "Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1\">Hillel Taub-Tabib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "Domain experts often need to extract structured information from large\ncorpora. We advocate for a search paradigm called ``extractive search'', in\nwhich a search query is enriched with capture-slots, to allow for such rapid\nextraction. Such an extractive search system can be built around syntactic\nstructures, resulting in high-precision, low-recall results. We show how the\nrecall can be improved using neural retrieval and alignment. The goals of this\npaper are to concisely introduce the extractive-search paradigm; and to\ndemonstrate a prototype neural retrieval system for extractive search and its\nbenefits and potential. Our prototype is available at\n\\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is\navailable at \\url{https://vimeo.com/559586687}.",
          "link": "http://arxiv.org/abs/2106.04612",
          "publishedOn": "2021-06-10T01:56:44.908Z",
          "wordCount": 535,
          "title": "Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Proper initialization is crucial to the optimization and the generalization\nof neural networks. However, most existing neural recommendation systems\ninitialize the user and item embeddings randomly. In this work, we propose a\nnew initialization scheme for user and item embeddings called Laplacian\nEigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).\nLEPORID endows the embeddings with information regarding multi-scale\nneighborhood structures on the data manifold and performs adaptive\nregularization to compensate for high embedding variance on the tail of the\ndata distribution. Exploiting matrix sparsity, LEPORID embeddings can be\ncomputed efficiently. We evaluate LEPORID in a wide range of neural\nrecommendation models. In contrast to the recent surprising finding that the\nsimple K-nearest-neighbor (KNN) method often outperforms neural recommendation\nsystems, we show that existing neural systems initialized with LEPORID often\nperform on par or better than KNN. To maximize the effects of the\ninitialization, we propose the Dual-Loss Residual Recommendation (DLR2)\nnetwork, which, when initialized with LEPORID, substantially outperforms both\ntraditional and state-of-the-art neural recommender systems.",
          "link": "http://arxiv.org/abs/2106.04993",
          "publishedOn": "2021-06-10T01:56:44.870Z",
          "wordCount": 597,
          "title": "Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1\">Rong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_R/0/1/0/all/0/1\">Renhao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Huifeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yingxue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhirong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiuqiang He</a>",
          "description": "CTR prediction, which aims to estimate the probability that a user will click\nan item, plays a crucial role in online advertising and recommender system.\nFeature interaction modeling based and user interest mining based methods are\nthe two kinds of most popular techniques that have been extensively explored\nfor many years and have made great progress for CTR prediction. However, (1)\nfeature interaction based methods which rely heavily on the co-occurrence of\ndifferent features, may suffer from the feature sparsity problem (i.e., many\nfeatures appear few times); (2) user interest mining based methods which need\nrich user behaviors to obtain user's diverse interests, are easy to encounter\nthe behavior sparsity problem (i.e., many users have very short behavior\nsequences). To solve these problems, we propose a novel module named Dual Graph\nenhanced Embedding, which is compatible with various CTR prediction models to\nalleviate these two problems. We further propose a Dual Graph enhanced\nEmbedding Neural Network (DG-ENN) for CTR prediction. Dual Graph enhanced\nEmbedding exploits the strengths of graph representation with two carefully\ndesigned learning strategies (divide-and-conquer, curriculum-learning-inspired\norganized learning) to refine the embedding. We conduct comprehensive\nexperiments on three real-world industrial datasets. The experimental results\nshow that our proposed DG-ENN significantly outperforms state-of-the-art CTR\nprediction models. Moreover, when applying to state-of-the-art CTR prediction\nmodels, Dual graph enhanced embedding always obtains better performance.\nFurther case studies prove that our proposed dual graph enhanced embedding\ncould alleviate the feature sparsity and behavior sparsity problems. Our\nframework will be open-source based on MindSpore in the near future.",
          "link": "http://arxiv.org/abs/2106.00314",
          "publishedOn": "2021-06-09T02:01:47.582Z",
          "wordCount": 708,
          "title": "Dual Graph enhanced Embedding Neural Network for CTR Prediction. (arXiv:2106.00314v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1\">Nikola Konstantinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1\">Christoph H. Lampert</a>",
          "description": "Given the abundance of applications of ranking in recent years, addressing\nfairness concerns around automated ranking systems becomes necessary for\nincreasing the trust among end-users. Previous work on fair ranking has mostly\nfocused on application-specific fairness notions, often tailored to online\nadvertising, and it rarely considers learning as part of the process. In this\nwork, we show how to transfer numerous fairness notions from binary\nclassification to a learning to rank setting. Our formalism allows us to design\nmethods for incorporating fairness objectives with provable generalization\nguarantees. An extensive experimental evaluation shows that our method can\nimprove ranking fairness substantially with no or only little loss of model\nquality.",
          "link": "http://arxiv.org/abs/2102.05996",
          "publishedOn": "2021-06-09T02:01:47.413Z",
          "wordCount": 568,
          "title": "Fairness Through Regularization for Learning to Rank. (arXiv:2102.05996v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers\nthrough reducing their costs of trial and error for discovering the optimal\nadvertising strategies is crucial for the long-term prosperity of online\nadvertising. To achieve this goal, the advertising platform needs to identify\nthe advertisers' marketing objectives, and then recommend the corresponding\nstrategies to fulfill this objective. In this work, we first deploy a prototype\nof strategy recommender system on Taobao display advertising platform,\nrecommending bid prices and targeted users to advertisers. We further augment\nthis prototype system by directly revealing the advertising performance, and\nthen infer the advertisers' marketing objectives through their adoptions of\ndifferent recommending advertising performance. We use the techniques from\ncontext bandit to jointly learn the advertisers' marketing objectives and the\nrecommending strategies. Online evaluations show that the designed advertising\nstrategy recommender system can optimize the advertisers' advertising\nperformance and increase the platform's revenue. Simulation experiments based\non Taobao online bidding data show that the designed contextual bandit\nalgorithm can effectively optimize the strategy adoption rate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-09T02:01:47.360Z",
          "wordCount": 664,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Shapira_N/0/1/0/all/0/1\">Noy Cohen-Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1\">Lior Rokach</a>",
          "description": "The widespread adoption of machine learning (ML) techniques and the extensive\nexpertise required to apply them have led to increased interest in automated ML\nsolutions that reduce the need for human intervention. One of the main\nchallenges in applying ML to previously unseen problems is algorithm selection\n- the identification of high-performing algorithm(s) for a given dataset, task,\nand evaluation measure. This study addresses the algorithm selection challenge\nfor data clustering, a fundamental task in data mining that is aimed at\ngrouping similar objects. We present MARCO-GE, a novel meta-learning approach\nfor the automated recommendation of clustering algorithms. MARCO-GE first\ntransforms datasets into graphs and then utilizes a graph convolutional neural\nnetwork technique to extract their latent representation. Using the embedding\nrepresentations obtained, MARCO-GE trains a ranking meta-model capable of\naccurately recommending top-performing algorithms for a new dataset and\nclustering evaluation measure. Extensive evaluation on 210 datasets, 13\nclustering algorithms, and 10 clustering measures demonstrates the\neffectiveness of our approach and its superiority in terms of predictive and\ngeneralization performance over state-of-the-art clustering meta-learning\napproaches.",
          "link": "http://arxiv.org/abs/2011.08225",
          "publishedOn": "2021-06-09T02:01:47.217Z",
          "wordCount": 631,
          "title": "Automatic selection of clustering algorithms using supervised graph embedding. (arXiv:2011.08225v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Understanding and creating mathematics using natural mathematical language -\nthe mixture of symbolic and natural language used by humans - is a challenging\nand important problem for driving progress in machine learning. As a step in\nthis direction, we develop NaturalProofs, a multi-domain corpus of mathematical\nstatements and their proofs, written in natural mathematical language.\nNaturalProofs unifies broad coverage, deep coverage, and low-resource\nmathematical sources, allowing for evaluating both in-distribution and\nzero-shot generalization. Using NaturalProofs, we benchmark strong neural\nmethods on mathematical reference retrieval and generation tasks which test a\nsystem's ability to determine key results that appear in a proof. Large-scale\nsequence models show promise compared to classical information retrieval\nmethods, yet their performance and out-of-domain generalization leave\nsubstantial room for improvement. NaturalProofs opens many avenues for research\non challenging mathematical tasks.",
          "link": "http://arxiv.org/abs/2104.01112",
          "publishedOn": "2021-06-09T02:01:47.195Z",
          "wordCount": 595,
          "title": "NaturalProofs: Mathematical Theorem Proving in Natural Language. (arXiv:2104.01112v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1\">Nishant Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1\">Rajat Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1\">Daniel N. Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S. Dhillon</a>",
          "description": "Query auto-completion (QAC) is a fundamental feature in search engines where\nthe task is to suggest plausible completions of a prefix typed in the search\nbar. Previous queries in the user session can provide useful context for the\nuser's intent and can be leveraged to suggest auto-completions that are more\nrelevant while adhering to the user's prefix. Such session-aware QACs can be\ngenerated by recent sequence-to-sequence deep learning models; however, these\ngenerative approaches often do not meet the stringent latency requirements of\nresponding to each user keystroke. Moreover, these generative approaches pose\nthe risk of showing nonsensical queries.\n\nIn this paper, we provide a solution to this problem: we take the novel\napproach of modeling session-aware QAC as an eXtreme Multi-Label Ranking (XMR)\nproblem where the input is the previous query in the session and the user's\ncurrent prefix, while the output space is the set of tens of millions of\nqueries entered by users in the recent past. We adapt a popular XMR algorithm\nfor this purpose by proposing several modifications to the key steps in the\nalgorithm. The proposed modifications yield a 10x improvement in terms of Mean\nReciprocal Rank (MRR) over the baseline XMR approach on a public search logs\ndataset. We are able to maintain an inference latency of less than 10 ms while\nstill using session context. When compared against baseline models of\nacceptable latency, we observed a 33% improvement in MRR for short prefixes of\nup to 3 characters. Moreover, our model yielded a statistically significant\nimprovement of 2.81% over a production QAC system in terms of suggestion\nacceptance rate, when deployed on the search bar of an online shopping store as\npart of an A/B test.",
          "link": "http://arxiv.org/abs/2012.07654",
          "publishedOn": "2021-06-09T02:01:47.187Z",
          "wordCount": 752,
          "title": "Session-Aware Query Auto-completion using Extreme Multi-label Ranking. (arXiv:2012.07654v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tito_R/0/1/0/all/0/1\">Rub&#xe8;n Tito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karatzas_D/0/1/0/all/0/1\">Dimosthenis Karatzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valveny_E/0/1/0/all/0/1\">Ernest Valveny</a>",
          "description": "Current tasks and methods in Document Understanding aims to process documents\nas single elements. However, documents are usually organized in collections\n(historical records, purchase invoices), that provide context useful for their\ninterpretation. To address this problem, we introduce Document Collection\nVisual Question Answering (DocCVQA) a new dataset and related task, where\nquestions are posed over a whole collection of document images and the goal is\nnot only to provide the answer to the given question, but also to retrieve the\nset of documents that contain the information needed to infer the answer. Along\nwith the dataset we propose a new evaluation metric and baselines which provide\nfurther insights to the new dataset and task.",
          "link": "http://arxiv.org/abs/2104.14336",
          "publishedOn": "2021-06-09T02:01:47.176Z",
          "wordCount": 557,
          "title": "Document Collection Visual Question Answering. (arXiv:2104.14336v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1\">Svitlana Vakulenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1\">Evangelos Kanoulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>",
          "description": "Conversational search is a relatively young area of research that aims at\nautomating an information-seeking dialogue. In this paper we help to position\nit with respect to other research areas within conversational Artificial\nIntelligence (AI) by analysing the structural properties of an\ninformation-seeking dialogue. To this end, we perform a large-scale dialogue\nanalysis of more than 150K transcripts from 16 publicly available dialogue\ndatasets. These datasets were collected to inform different dialogue-based\ntasks including conversational search. We extract different patterns of mixed\ninitiative from these dialogue transcripts and use them to compare dialogues of\ndifferent types. Moreover, we contrast the patterns found in\ninformation-seeking dialogues that are being used for research purposes with\nthe patterns found in virtual reference interviews that were conducted by\nprofessional librarians. The insights we provide (1) establish close relations\nbetween conversational search and other conversational AI tasks; and (2)\nuncover limitations of existing conversational datasets to inform future data\ncollection tasks.",
          "link": "http://arxiv.org/abs/2104.07096",
          "publishedOn": "2021-06-09T02:01:47.169Z",
          "wordCount": 636,
          "title": "A Large-Scale Analysis of Mixed Initiative in Information-Seeking Dialogues for Conversational Search. (arXiv:2104.07096v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Padh_K/0/1/0/all/0/1\">Kirtan Padh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1\">Diego Antognini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaude_E/0/1/0/all/0/1\">Emma Lejal Glaude</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1\">Boi Faltings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musat_C/0/1/0/all/0/1\">Claudiu Musat</a>",
          "description": "The goal of fairness in classification is to learn a classifier that does not\ndiscriminate against groups of individuals based on sensitive attributes, such\nas race and gender. One approach to designing fair algorithms is to use\nrelaxations of fairness notions as regularization terms or in a constrained\noptimization problem. We observe that the hyperbolic tangent function can\napproximate the indicator function. We leverage this property to define a\ndifferentiable relaxation that approximates fairness notions provably better\nthan existing relaxations. In addition, we propose a model-agnostic\nmulti-objective architecture that can simultaneously optimize for multiple\nfairness notions and multiple sensitive attributes and supports all statistical\nparity-based notions of fairness. We use our relaxation with the\nmulti-objective architecture to learn fair classifiers. Experiments on public\ndatasets show that our method suffers a significantly lower loss of accuracy\nthan current debiasing algorithms relative to the unconstrained model.",
          "link": "http://arxiv.org/abs/2009.04441",
          "publishedOn": "2021-06-09T02:01:47.142Z",
          "wordCount": 634,
          "title": "Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm. (arXiv:2009.04441v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitfield_C/0/1/0/all/0/1\">Christopher Whitfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_M/0/1/0/all/0/1\">Mohad Anwar</a>",
          "description": "Coronavirus disease (COVID-19) pandemic has changed various aspects of\npeople's lives and behaviors. At this stage, there are no other ways to control\nthe natural progression of the disease than adopting mitigation strategies such\nas wearing masks, watching distance, and washing hands. Moreover, at this time\nof social distancing, social media plays a key role in connecting people and\nproviding a platform for expressing their feelings. In this study, we tap into\nsocial media to surveil the uptake of mitigation and detection strategies, and\ncapture issues and concerns about the pandemic. In particular, we explore the\nresearch question, \"how much can be learned regarding the public uptake of\nmitigation strategies and concerns about COVID-19 pandemic by using natural\nlanguage processing on Reddit posts?\" After extracting COVID-related posts from\nthe four largest subreddit communities of North Carolina over six months, we\nperformed NLP-based preprocessing to clean the noisy data. We employed a custom\nNamed-entity Recognition (NER) system and a Latent Dirichlet Allocation (LDA)\nmethod for topic modeling on a Reddit corpus. We observed that 'mask', 'flu',\nand 'testing' are the most prevalent named-entities for \"Personal Protective\nEquipment\", \"symptoms\", and \"testing\" categories, respectively. We also\nobserved that the most discussed topics are related to testing, masks, and\nemployment. The mitigation measures are the most prevalent theme of discussion\nacross all subreddits.",
          "link": "http://arxiv.org/abs/2106.04515",
          "publishedOn": "2021-06-09T02:01:47.102Z",
          "wordCount": 720,
          "title": "Surveillance of COVID-19 Pandemic using Social Media: A Reddit Study in North Carolina. (arXiv:2106.04515v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malunjkar_S/0/1/0/all/0/1\">Sanjay Malunjkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_S/0/1/0/all/0/1\">Susan Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Somalee Datta</a>",
          "description": "The advent of cost effective cloud computing over the past decade and\never-growing accumulation of high-fidelity clinical data in a modern hospital\nsetting is leading to new opportunities for translational medicine. Machine\nlearning is driving the appetite of the research community for various types of\nsignal data such as patient vitals. Health care systems, however, are ill\nsuited for massive processing of large volumes of data. In addition, due to the\nsheer magnitude of the data being collected, it is not feasible to retain all\nof the data in health care systems in perpetuity. This gold mine of information\ngets purged periodically thereby losing invaluable future research\nopportunities. We have developed a highly scalable solution that: a) siphons\noff patient vital data on a nightly basis from on-premises bio-medical systems\nto a cloud storage location as a permanent archive, b) reconstructs the\ndatabase in the cloud, c) generates waveforms, alarms and numeric data in a\nresearch-ready format, and d) uploads the processed data to a storage location\nin the cloud ready for research.\n\nThe data is de-identified and catalogued such that it can be joined with\nElectronic Medical Records (EMR) and other ancillary data types such as\nelectroencephalogram (EEG), radiology, video monitoring etc. This technique\neliminates the research burden from health care systems. This highly scalable\nsolution is used to process high density patient monitoring data aggregated by\nthe Philips Patient Information Center iX (PIC iX) hospital surveillance system\nfor archival storage in the Philips Data Warehouse Connect enterprise-level\ndatabase. The solution is part of a broader platform that supports a secure\nhigh performance clinical data science platform.",
          "link": "http://arxiv.org/abs/2106.03965",
          "publishedOn": "2021-06-09T02:01:47.095Z",
          "wordCount": 712,
          "title": "A highly scalable repository of waveform and vital signs data from bedside monitoring devices. (arXiv:2106.03965v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gaode Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1\">Cong Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Ji Xiang</a>",
          "description": "Sequential recommendation systems alleviate the problem of information\noverload, and have attracted increasing attention in the literature. Most prior\nworks usually obtain an overall representation based on the user's behavior\nsequence, which can not sufficiently reflect the multiple interests of the\nuser. To this end, we propose a novel method called PIMI to mitigate this\nissue. PIMI can model the user's multi-interest representation effectively by\nconsidering both the periodicity and interactivity in the item sequence.\nSpecifically, we design a periodicity-aware module to utilize the time interval\ninformation between user's behaviors. Meanwhile, an ingenious graph is proposed\nto enhance the interactivity between items in user's behavior sequence, which\ncan capture both global and local item features. Finally, a multi-interest\nextraction module is applied to describe user's multiple interests based on the\nobtained item representation. Extensive experiments on two real-world datasets\nAmazon and Taobao show that PIMI outperforms state-of-the-art methods\nconsistently.",
          "link": "http://arxiv.org/abs/2106.04415",
          "publishedOn": "2021-06-09T02:01:47.082Z",
          "wordCount": 589,
          "title": "Exploring Periodicity and Interactivity in Multi-Interest Framework for Sequential Recommendation. (arXiv:2106.04415v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Peiru Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "User interest modeling is critical for personalized news recommendation.\nExisting news recommendation methods usually learn a single user embedding for\neach user from their previous behaviors to represent their overall interest.\nHowever, user interest is usually diverse and multi-grained, which is difficult\nto be accurately modeled by a single user embedding. In this paper, we propose\na news recommendation method with hierarchical user interest modeling, named\nHieRec. Instead of a single user embedding, in our method each user is\nrepresented in a hierarchical interest tree to better capture their diverse and\nmulti-grained interest in news. We use a three-level hierarchy to represent 1)\noverall user interest; 2) user interest in coarse-grained topics like sports;\nand 3) user interest in fine-grained topics like football. Moreover, we propose\na hierarchical user interest matching framework to match candidate news with\ndifferent levels of user interest for more accurate user interest targeting.\nExtensive experiments on two real-world datasets validate our method can\neffectively improve the performance of user modeling for personalized news\nrecommendation.",
          "link": "http://arxiv.org/abs/2106.04408",
          "publishedOn": "2021-06-09T02:01:47.074Z",
          "wordCount": 604,
          "title": "HieRec: Hierarchical User Interest Modeling for Personalized News Recommendation. (arXiv:2106.04408v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yifei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>",
          "description": "We study the task of conversational fashion image retrieval via multiturn\nnatural language feedback. Most previous studies are based on single-turn\nsettings. Existing models on multiturn conversational fashion image retrieval\nhave limitations, such as employing traditional models, and leading to\nineffective performance. We propose a novel framework that can effectively\nhandle conversational fashion image retrieval with multiturn natural language\nfeedback texts. One characteristic of the framework is that it searches for\ncandidate images based on exploitation of the encoded reference image and\nfeedback text information together with the conversation history. Furthermore,\nthe image fashion attribute information is leveraged via a mutual attention\nstrategy. Since there is no existing fashion dataset suitable for the multiturn\nsetting of our task, we derive a large-scale multiturn fashion dataset via\nadditional manual annotation efforts on an existing single-turn dataset. The\nexperiments show that our proposed model significantly outperforms existing\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04128",
          "publishedOn": "2021-06-09T02:01:47.055Z",
          "wordCount": 584,
          "title": "Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback. (arXiv:2106.04128v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.12979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shijun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1\">Peng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "Static recommendation methods like collaborative filtering suffer from the\ninherent limitation of performing real-time personalization for cold-start\nusers. Online recommendation, e.g., multi-armed bandit approach, addresses this\nlimitation by interactively exploring user preference online and pursuing the\nexploration-exploitation (EE) trade-off. However, existing bandit-based methods\nmodel recommendation actions homogeneously. Specifically, they only consider\nthe items as the arms, being incapable of handling the item attributes, which\nnaturally provide interpretable information of user's current demands and can\neffectively filter out undesired items. In this work, we consider the\nconversational recommendation for cold-start users, where a system can both ask\nthe attributes from and recommend items to a user interactively. This important\nscenario was studied in a recent work. However, it employs a hand-crafted\nfunction to decide when to ask attributes or make recommendations. Such\nseparate modeling of attributes and items makes the effectiveness of the system\nhighly rely on the choice of the hand-crafted function, thus introducing\nfragility to the system. To address this limitation, we seamlessly unify\nattributes and items in the same arm space and achieve their EE trade-offs\nautomatically using the framework of Thompson Sampling. Our Conversational\nThompson Sampling (ConTS) model holistically solves all questions in\nconversational recommendation by choosing the arm with the maximal reward to\nplay. Extensive experiments on three benchmark datasets show that ConTS\noutperforms the state-of-the-art methods Conversational UCB (ConUCB) and\nEstimation-Action-Reflection model in both metrics of success rate and average\nnumber of conversation turns.",
          "link": "http://arxiv.org/abs/2005.12979",
          "publishedOn": "2021-06-09T02:01:47.041Z",
          "wordCount": 740,
          "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-Start Users. (arXiv:2005.12979v4 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giordano_V/0/1/0/all/0/1\">Vito Giordano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiarello_F/0/1/0/all/0/1\">Filippo Chiarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cervelli_E/0/1/0/all/0/1\">Elena Cervelli</a>",
          "description": "One of the first task of an innovative project is delineating the scope of\nthe project itself or of the product/service to be developed. A wrong scope\ndefinition can determine (in the worst case) project failure. A good scope\ndefinition become even more relevant in technological intensive innovation\nprojects, nowadays characterized by a highly dynamic multidisciplinary,\nturbulent and uncertain environment. In these cases, the boundaries of the\nproject are not easily detectable and it is difficult to decide what it is\nin-scope and out-of-scope. The present work proposes a tool for the scope\ndelineation process, that automatically define an innovative technological\nfield or a new technology. The tool is based on Text Mining algorithm that\nexploits Elsevier's Scopus abstracts in order to the extract relevant data to\ndefine a technological scope. The automatic definition tool is then applied on\nfour case studies: Artificial Intelligence and Data Science. The results show\nhow the tool can provide many crucial information in the definition process of\na technological field. In particular for the target technological field (or\ntechnology), it provides the definition and other elements related to the\ntarget.",
          "link": "http://arxiv.org/abs/2106.04210",
          "publishedOn": "2021-06-09T02:01:47.032Z",
          "wordCount": 646,
          "title": "Defining definition: a Text mining Approach to Define Innovative Technological Fields. (arXiv:2106.04210v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brams_A/0/1/0/all/0/1\">Anders H. Brams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobsen_A/0/1/0/all/0/1\">Anders L. Jakobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jendal_T/0/1/0/all/0/1\">Theis E. Jendal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lissandrini_M/0/1/0/all/0/1\">Matteo Lissandrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolog_P/0/1/0/all/0/1\">Peter Dolog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hose_K/0/1/0/all/0/1\">Katja Hose</a>",
          "description": "Knowledge Graphs (KGs) have been integrated in several models of\nrecommendation to augment the informational value of an item by means of its\nrelated entities in the graph. Yet, existing datasets only provide explicit\nratings on items and no information is provided about user opinions of other\n(non-recommendable) entities. To overcome this limitation, we introduce a new\ndataset, called the MindReader, providing explicit user ratings both for items\nand for KG entities. In this first version, the MindReader dataset provides\nmore than 102 thousands explicit ratings collected from 1,174 real users on\nboth items and entities from a KG in the movie domain. This dataset has been\ncollected through an online interview application that we also release open\nsource. As a demonstration of the importance of this new dataset, we present a\ncomparative study of the effect of the inclusion of ratings on non-item KG\nentities in a variety of state-of-the-art recommendation models. In particular,\nwe show that most models, whether designed specifically for graph data or not,\nsee improvements in recommendation quality when trained on explicit non-item\nratings. Moreover, for some models, we show that non-item ratings can\neffectively replace item ratings without loss of recommendation quality. This\nfinding, thanks also to an observed greater familiarity of users towards common\nKG entities than towards long-tail items, motivates the use of KG entities for\nboth warm and cold-start recommendations.",
          "link": "http://arxiv.org/abs/2106.04209",
          "publishedOn": "2021-06-09T02:01:47.017Z",
          "wordCount": 670,
          "title": "MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings. (arXiv:2106.04209v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perifanis_V/0/1/0/all/0/1\">Vasileios Perifanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efraimidis_P/0/1/0/all/0/1\">Pavlos S. Efraimidis</a>",
          "description": "In this work, we present a federated version of the state-of-the-art Neural\nCollaborative Filtering (NCF) approach for item recommendations. The system,\nnamed FedNCF, allows learning without requiring users to expose or transmit\ntheir raw data. Experimental validation shows that FedNCF achieves comparable\nrecommendation quality to the original NCF system. Although federated learning\n(FL) enables learning without raw data transmission, recent attacks showed that\nFL alone does not eliminate privacy concerns. To overcome this challenge, we\nintegrate a privacy-preserving enhancement with a secure aggregation scheme\nthat satisfies the security requirements against an honest-but-curious (HBC)\nentity, without affecting the quality of the original model. Finally, we\ndiscuss the peculiarities observed in the application of FL in a collaborative\nfiltering (CF) task as well as we evaluate the privacy-preserving mechanism in\nterms of computational cost.",
          "link": "http://arxiv.org/abs/2106.04405",
          "publishedOn": "2021-06-09T02:01:46.977Z",
          "wordCount": 554,
          "title": "Federated Neural Collaborative Filtering. (arXiv:2106.04405v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kramer_T/0/1/0/all/0/1\">Thomas Kr&#xe4;mer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carevic_Z/0/1/0/all/0/1\">Zeljko Carevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1\">Dwaipayan Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klas_C/0/1/0/all/0/1\">Claus-Peter Klas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayr_P/0/1/0/all/0/1\">Philipp Mayr</a>",
          "description": "In this demo paper, we present ConSTR, a novel Contextual Search Term\nRecommender that utilises the user's interaction context for search term\nrecommendation and literature retrieval. ConSTR integrates a two-layered\nrecommendation interface: the first layer suggests terms with respect to a\nuser's current search term, and the second layer suggests terms based on the\nusers' previous search activities (interaction context). For the demonstration,\nConSTR is built on the arXiv, an academic repository consisting of 1.8 million\ndocuments.",
          "link": "http://arxiv.org/abs/2106.04376",
          "publishedOn": "2021-06-09T02:01:46.968Z",
          "wordCount": 514,
          "title": "ConSTR: A Contextual Search Term Recommender. (arXiv:2106.04376v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vrbanec_T/0/1/0/all/0/1\">Tedo Vrbanec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mestrovic_A/0/1/0/all/0/1\">Ana Mestrovic</a>",
          "description": "Academic plagiarism is a serious problem nowadays. Due to the existence of\ninexhaustible sources of digital information, today it is easier to plagiarize\nmore than ever before. The good thing is that plagiarism detection techniques\nhave improved and are powerful enough to detect attempts of plagiarism in\neducation. We are now witnessing efficient plagiarism detection software in\naction, such as Turnitin, iThenticate or SafeAssign. In the introduction we\nexplore software that is used within the Croatian academic community for\nplagiarism detection in universities and/or in scientific journals. The\nquestion is: is this enough? Current software has proven to be successful,\nhowever the problem of identifying paraphrasing or obfuscation plagiarism\nremains unresolved. In this paper we present a report of how semantic\nsimilarity measures can be used in the plagiarism detection task.",
          "link": "http://arxiv.org/abs/2106.04404",
          "publishedOn": "2021-06-09T02:01:46.958Z",
          "wordCount": 575,
          "title": "The Struggle with Academic Plagiarism: Approaches based on Semantic Similarity. (arXiv:2106.04404v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-09T02:01:46.947Z",
          "wordCount": 701,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiayan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anjum_A/0/1/0/all/0/1\">Ashiq Anjum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panneerselvam_J/0/1/0/all/0/1\">John Panneerselvam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1\">Bo Yuan</a>",
          "description": "With the development of Edge Computing and Artificial Intelligence (AI)\ntechnologies, edge devices are witnessed to generate data at unprecedented\nvolume. The Edge Intelligence (EI) has led to the emergence of edge devices in\nvarious application domains. The EI can provide efficient services to\ndelay-sensitive applications, where the edge devices are deployed as edge nodes\nto host the majority of execution, which can effectively manage services and\nimprove service discovery efficiency. The multilevel index model is a\nwell-known model used for indexing service, such a model is being introduced\nand optimized in the edge environments to efficiently services discovery whilst\nmanaging large volumes of data. However, effectively updating the multilevel\nindex model by adding new services timely and precisely in the dynamic Edge\nComputing environments is still a challenge. Addressing this issue, this paper\nproposes a designated key selection method to improve the efficiency of adding\nservices in the multilevel index models. Our experimental results show that in\nthe partial index and the full index of multilevel index model, our method\nreduces the service addition time by around 84% and 76%, respectively when\ncompared with the original key selection method and by around 78% and 66%,\nrespectively when compared with the random selection method. Our proposed\nmethod significantly improves the service addition efficiency in the multilevel\nindex model, when compared with existing state-of-the-art key selection\nmethods, without compromising the service retrieval stability to any notable\nlevel.",
          "link": "http://arxiv.org/abs/2106.04494",
          "publishedOn": "2021-06-09T02:01:46.934Z",
          "wordCount": 670,
          "title": "Optimization of Service Addition in Multilevel Index Model for Edge Computing. (arXiv:2106.04494v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yangyang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jianhua Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Liqiang Nie</a>",
          "description": "Utilizing review information to enhance recommendation, the de facto\nreview-involved recommender systems, have received increasing interests over\nthe past few years. Thereinto, one advanced branch is to extract salient\naspects from textual reviews (i.e., the item attributes that users express) and\ncombine them with the matrix factorization technique. However, existing\napproaches all ignore the fact that semantically different reviews often\ninclude opposite aspect information. In particular, positive reviews usually\nexpress aspects that users prefer, while negative ones describe aspects that\nusers reject. As a result, it may mislead the recommender systems into making\nincorrect decisions pertaining to user preference modeling. Towards this end,\nin this paper, we propose a Review Polarity-wise Recommender model, dubbed as\nRPR, to discriminately treat reviews with different polarities. To be specific,\nin this model, positive and negative reviews are separately gathered and\nutilized to model the user-preferred and user-rejected aspects, respectively.\nBesides, in order to overcome the imbalance problem of semantically different\nreviews, we also develop an aspect-aware importance weighting approach to align\nthe aspect importance for these two kinds of reviews. Extensive experiments\nconducted on eight benchmark datasets have demonstrated the superiority of our\nmodel as compared to a series of state-of-the-art review-involved baselines.\nMoreover, our method can provide certain explanations to the real-world rating\nprediction scenarios.",
          "link": "http://arxiv.org/abs/2106.04155",
          "publishedOn": "2021-06-09T02:01:46.754Z",
          "wordCount": 629,
          "title": "Review Polarity-wise Recommender. (arXiv:2106.04155v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jialu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cong Yu</a>",
          "description": "Effectively modeling text-rich fresh content such as news articles at\ndocument-level is a challenging problem. To ensure a content-based model\ngeneralize well to a broad range of applications, it is critical to have a\ntraining dataset that is large beyond the scale of human labels while achieving\ndesired quality. In this work, we address those two challenges by proposing a\nnovel approach to mine semantically-relevant fresh documents, and their topic\nlabels, with little human supervision. Meanwhile, we design a multitask model\ncalled NewsEmbed that alternatively trains a contrastive learning with a\nmulti-label classification to derive a universal document encoder. We show that\nthe proposed approach can provide billions of high quality organic training\nexamples and can be naturally extended to multilingual setting where texts in\ndifferent languages are encoded in the same semantic space. We experimentally\ndemonstrate NewsEmbed's competitive performance across multiple natural\nlanguage understanding tasks, both supervised and unsupervised.",
          "link": "http://arxiv.org/abs/2106.00590",
          "publishedOn": "2021-06-08T22:44:23.879Z",
          "wordCount": 603,
          "title": "NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:22.677Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>",
          "description": "Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.",
          "link": "http://arxiv.org/abs/2105.11601",
          "publishedOn": "2021-06-08T02:20:22.530Z",
          "wordCount": 632,
          "title": "Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:20.962Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soltaninejad_F/0/1/0/all/0/1\">Fahimeh Soltaninejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bidgoly_A/0/1/0/all/0/1\">Amir Jalaly Bidgoly</a>",
          "description": "One of the popular approaches in recommendation systems is Collaborative\nFiltering (CF). The most significant step in CF is choosing the appropriate set\nof users. For this purpose, similarity measures are usually used for computing\nthe similarity between a specific user and the other users. This paper proposes\na new invasive weed optimization (IWO) based CF approach that uses users'\ncontext to identify important and effective users set. By using a newly defined\nsimilarity measure based on both rating values and a measure values called\nconfidence, the proposed approach calculates the similarity between users and\nthus identifies and filters the most similar users to a specific user. It then\nuses IWO to calculate the importance degree of users and finally, by using the\nidentified important users and their importance degrees it predicts unknown\nratings. To evaluate the proposed method, several experiments have been\nperformed on two known real world datasets and the results show that the\nproposed method improves the state of the art results up to 15% in terms of\nRoot Mean Square Error (RMSE) and Mean Absolute Error (MAE).",
          "link": "http://arxiv.org/abs/2106.02831",
          "publishedOn": "2021-06-08T02:20:20.805Z",
          "wordCount": 605,
          "title": "A novel method for recommendation systems using invasive weed optimization. (arXiv:2106.02831v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Classical recommender system methods typically face the filter bubble problem\nwhen users only receive recommendations of their familiar items, making them\nbored and dissatisfied. To address the filter bubble problem, unexpected\nrecommendations have been proposed to recommend items significantly deviating\nfrom user's prior expectations and thus surprising them by presenting \"fresh\"\nand previously unexplored items to the users. In this paper, we describe a\nnovel Personalized Unexpected Recommender System (PURS) model that incorporates\nunexpectedness into the recommendation process by providing multi-cluster\nmodeling of user interests in the latent space and personalized unexpectedness\nvia the self-attention mechanism and via selection of an appropriate unexpected\nactivation function. Extensive offline experiments on three real-world datasets\nillustrate that the proposed PURS model significantly outperforms the\nstate-of-the-art baseline approaches in terms of both accuracy and\nunexpectedness measures. In addition, we conduct an online A/B test at a major\nvideo platform Alibaba-Youku, where our model achieves over 3\\% increase in the\naverage video view per user metric. The proposed model is in the process of\nbeing deployed by the company.",
          "link": "http://arxiv.org/abs/2106.02771",
          "publishedOn": "2021-06-08T02:20:20.759Z",
          "wordCount": 609,
          "title": "PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangtao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qinbao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>",
          "description": "Recommending appropriate algorithms to a classification problem is one of the\nmost challenging issues in the field of data mining. The existing algorithm\nrecommendation models are generally constructed on only one kind of\nmeta-features by single learners. Considering that i) ensemble learners usually\nshow better performance and ii) different kinds of meta-features characterize\nthe classification problems in different viewpoints independently, and further\nthe models constructed with different sets of meta-features will be\ncomplementary with each other and applicable for ensemble. This paper proposes\nan ensemble learning-based algorithm recommendation method. To evaluate the\nproposed recommendation method, extensive experiments with 13 well-known\ncandidate classification algorithms and five different kinds of meta-features\nare conducted on 1090 benchmark classification problems. The results show the\neffectiveness of the proposed ensemble learning based recommendation method.",
          "link": "http://arxiv.org/abs/2101.05993",
          "publishedOn": "2021-06-08T02:20:20.580Z",
          "wordCount": 566,
          "title": "Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1\">Wonbin Kweon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">SeongKu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hwanjo Yu</a>",
          "description": "Recommender systems (RS) have started to employ knowledge distillation, which\nis a model compression technique training a compact model (student) with the\nknowledge transferred from a cumbersome model (teacher). The state-of-the-art\nmethods rely on unidirectional distillation transferring the knowledge only\nfrom the teacher to the student, with an underlying assumption that the teacher\nis always superior to the student. However, we demonstrate that the student\nperforms better than the teacher on a significant proportion of the test set,\nespecially for RS. Based on this observation, we propose Bidirectional\nDistillation (BD) framework whereby both the teacher and the student\ncollaboratively improve with each other. Specifically, each model is trained\nwith the distillation loss that makes to follow the other's prediction along\nwith its original loss function. For effective bidirectional distillation, we\npropose rank discrepancy-aware sampling scheme to distill only the informative\nknowledge that can fully enhance each other. The proposed scheme is designed to\neffectively cope with a large performance gap between the teacher and the\nstudent. Trained in the bidirectional way, it turns out that both the teacher\nand the student are significantly improved compared to when being trained\nseparately. Our extensive experiments on real-world datasets show that our\nproposed framework consistently outperforms the state-of-the-art competitors.\nWe also provide analyses for an in-depth understanding of BD and ablation\nstudies to verify the effectiveness of each proposed component.",
          "link": "http://arxiv.org/abs/2106.02870",
          "publishedOn": "2021-06-08T02:20:20.569Z",
          "wordCount": 649,
          "title": "Bidirectional Distillation for Top-K Recommender System. (arXiv:2106.02870v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Cross domain recommender system constitutes a powerful method to tackle the\ncold-start and sparsity problem by aggregating and transferring user\npreferences across multiple category domains. Therefore, it has great potential\nto improve click-through-rate prediction performance in online commerce\nplatforms having many domains of products. While several cross domain\nsequential recommendation models have been proposed to leverage information\nfrom a source domain to improve CTR predictions in a target domain, they did\nnot take into account bidirectional latent relations of user preferences across\nsource-target domain pairs. As such, they cannot provide enhanced cross-domain\nCTR predictions for both domains simultaneously. In this paper, we propose a\nnovel approach to cross-domain sequential recommendations based on the dual\nlearning mechanism that simultaneously transfers information between two\nrelated domains in an iterative manner until the learning process stabilizes.\nIn particular, the proposed Dual Attentive Sequential Learning (DASL) model\nconsists of two novel components Dual Embedding and Dual Attention, which\njointly establish the two-stage learning process: we first construct dual\nlatent embeddings that extract user preferences in both domains simultaneously,\nand subsequently provide cross-domain recommendations by matching the extracted\nlatent embeddings with candidate items through dual-attention learning\nmechanism. We conduct extensive offline experiments on three real-world\ndatasets to demonstrate the superiority of our proposed model, which\nsignificantly and consistently outperforms several state-of-the-art baselines\nacross all experimental settings. We also conduct an online A/B test at a major\nvideo streaming platform Alibaba-Youku, where our proposed model significantly\nimproves business performance over the latest production system in the company.",
          "link": "http://arxiv.org/abs/2106.02768",
          "publishedOn": "2021-06-08T02:20:20.522Z",
          "wordCount": 686,
          "title": "Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urman_A/0/1/0/all/0/1\">Aleksandra Urman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhortykh_M/0/1/0/all/0/1\">Mykola Makhortykh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulloa_R/0/1/0/all/0/1\">Roberto Ulloa</a>",
          "description": "We audit the presence of domain-level source diversity bias in video search\nresults. Using a virtual agent-based approach, we compare outputs of four\nWestern and one non-Western search engines for English and Russian queries. Our\nfindings highlight that source diversity varies substantially depending on the\nlanguage with English queries returning more diverse outputs. We also find\ndisproportionately high presence of a single platform, YouTube, in top search\noutputs for all Western search engines except Google. At the same time, we\nobserve that Youtube's major competitors such as Vimeo or Dailymotion do not\nappear in the sampled Google's video search results. This finding suggests that\nGoogle might be downgrading the results from the main competitors of\nGoogle-owned Youtube and highlights the necessity for further studies focusing\non the presence of own-content bias in Google's search results.",
          "link": "http://arxiv.org/abs/2106.02715",
          "publishedOn": "2021-06-08T02:20:20.489Z",
          "wordCount": 579,
          "title": "Auditing Source Diversity Bias in Video Search Results Using Virtual Agents. (arXiv:2106.02715v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiawei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jinfeng Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>",
          "description": "The general aim of the recommender system is to provide personalized\nsuggestions to users, which is opposed to suggesting popular items. However,\nthe normal training paradigm, i.e., fitting a recommender model to recover the\nuser behavior data with pointwise or pairwise loss, makes the model biased\ntowards popular items. This results in the terrible Matthew effect, making\npopular items be more frequently recommended and become even more popular.\nExisting work addresses this issue with Inverse Propensity Weighting (IPW),\nwhich decreases the impact of popular items on the training and increases the\nimpact of long-tail items. Although theoretically sound, IPW methods are highly\nsensitive to the weighting strategy, which is notoriously difficult to tune. In\nthis work, we explore the popularity bias issue from a novel and fundamental\nperspective -- cause-effect. We identify that popularity bias lies in the\ndirect effect from the item node to the ranking score, such that an item's\nintrinsic property is the cause of mistakenly assigning it a higher ranking\nscore. To eliminate popularity bias, it is essential to answer the\ncounterfactual question that what the ranking score would be if the model only\nuses item property. To this end, we formulate a causal graph to describe the\nimportant cause-effect relations in the recommendation process. During\ntraining, we perform multi-task learning to achieve the contribution of each\ncause; during testing, we perform counterfactual inference to remove the effect\nof item popularity. Remarkably, our solution amends the learning process of\nrecommendation which is agnostic to a wide range of models -- it can be easily\nimplemented in existing methods. We demonstrate it on Matrix Factorization (MF)\nand LightGCN [20]. Experiments on five real-world datasets demonstrate the\neffectiveness of our method.",
          "link": "http://arxiv.org/abs/2010.15363",
          "publishedOn": "2021-06-08T02:20:20.471Z",
          "wordCount": 752,
          "title": "Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System. (arXiv:2010.15363v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiaosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1\">Geewon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1\">Changho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>",
          "description": "In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),\nan algorithm that performs matrix completion in the presence of social and item\nsimilarity graphs. MC2G runs in quasilinear time and is parameter free. It is\nbased on spectral clustering and local refinement steps. The expected number of\nsampled entries required for MC2G to succeed (i.e., recover the clusters in the\ngraphs and complete the matrix) matches an information-theoretic lower bound up\nto a constant factor for a wide range of parameters. We show via extensive\nexperiments on both synthetic and real datasets that MC2G outperforms other\nstate-of-the-art matrix completion algorithms that leverage graph side\ninformation.",
          "link": "http://arxiv.org/abs/2006.04373",
          "publishedOn": "2021-06-08T02:20:20.446Z",
          "wordCount": 594,
          "title": "MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wang-Cheng Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Derek Zhiyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tiansheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinyang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "Embedding learning of categorical features (e.g. user/item IDs) is at the\ncore of various recommendation models including matrix factorization and neural\ncollaborative filtering. The standard approach creates an embedding table where\neach row represents a dedicated embedding vector for every unique feature\nvalue. However, this method fails to efficiently handle high-cardinality\nfeatures and unseen feature values (e.g. new video ID) that are prevalent in\nreal-world recommendation systems. In this paper, we propose an alternative\nembedding framework Deep Hash Embedding (DHE), replacing embedding tables by a\ndeep embedding network to compute embeddings on the fly. DHE first encodes the\nfeature value to a unique identifier vector with multiple hashing functions and\ntransformations, and then applies a DNN to convert the identifier vector to an\nembedding. The encoding module is deterministic, non-learnable, and free of\nstorage, while the embedding network is updated during the training time to\nlearn embedding generation. Empirical results show that DHE achieves comparable\nAUC against the standard one-hot full embedding, with smaller model sizes. Our\nwork sheds light on the design of DNN-based alternative embedding schemes for\ncategorical features without using embedding table lookup.",
          "link": "http://arxiv.org/abs/2010.10784",
          "publishedOn": "2021-06-08T02:20:20.433Z",
          "wordCount": 663,
          "title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:20.418Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.",
          "link": "http://arxiv.org/abs/2005.12964",
          "publishedOn": "2021-06-07T03:06:11.174Z",
          "wordCount": 759,
          "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:10.740Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Roger Zhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urbano_J/0/1/0/all/0/1\">Juli&#xe1;n Urbano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1\">Alan Hanjalic</a>",
          "description": "Direct optimization of IR metrics has often been adopted as an approach to\ndevise and develop ranking-based recommender systems. Most methods following\nthis approach aim at optimizing the same metric being used for evaluation,\nunder the assumption that this will lead to the best performance. A number of\nstudies of this practice bring this assumption, however, into question. In this\npaper, we dig deeper into this issue in order to learn more about the effects\nof the choice of the metric to optimize on the performance of a ranking-based\nrecommender system. We present an extensive experimental study conducted on\ndifferent datasets in both pairwise and listwise learning-to-rank scenarios, to\ncompare the relative merit of four popular IR metrics, namely RR, AP, nDCG and\nRBP, when used for optimization and assessment of recommender systems in\nvarious combinations. For the first three, we follow the practice of loss\nfunction formulation available in literature. For the fourth one, we propose\nnovel loss functions inspired by RBP for both the pairwise and listwise\nscenario. Our results confirm that the best performance is indeed not\nnecessarily achieved when optimizing the same metric being used for evaluation.\nIn fact, we find that RBP-inspired losses perform at least as well as other\nmetrics in a consistent way, and offer clear benefits in several cases.\nInteresting to see is that RBP-inspired losses, while improving the\nrecommendation performance for all uses, may lead to an individual performance\ngain that is correlated with the activity level of a user in interacting with\nitems. The more active the users, the more they benefit. Overall, our results\nchallenge the assumption behind the current research practice of optimizing and\nevaluating the same metric, and point to RBP-based optimization instead as a\npromising alternative when learning to rank in the recommendation context.",
          "link": "http://arxiv.org/abs/2106.02545",
          "publishedOn": "2021-06-07T03:06:10.712Z",
          "wordCount": 732,
          "title": "New Insights into Metric Optimization for Ranking-based Recommendation. (arXiv:2106.02545v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bi_K/0/1/0/all/0/1\">Keping Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1\">Qingyao Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croft_W/0/1/0/all/0/1\">W. Bruce Croft</a>",
          "description": "Product search has been a crucial entry point to serve people shopping\nonline. Most existing personalized product models follow the paradigm of\nrepresenting and matching user intents and items in the semantic space, where\nfiner-grained matching is totally discarded and the ranking of an item cannot\nbe explained further than just user/item level similarity. In addition, while\nsome models in existing studies have created dynamic user representations based\non search context, their representations for items are static across all search\nsessions. This makes every piece of information about the item always equally\nimportant in representing the item during matching with various user intents.\nAware of the above limitations, we propose a review-based transformer model\n(RTM) for personalized product search, which encodes the sequence of query,\nuser reviews, and item reviews with a transformer architecture. RTM conducts\nreview-level matching between the user and item, where each review has a\ndynamic effect according to the context in the sequence. This makes it possible\nto identify useful reviews to explain the scoring. Experimental results show\nthat RTM significantly outperforms state-of-the-art personalized product search\nbaselines.",
          "link": "http://arxiv.org/abs/2004.09424",
          "publishedOn": "2021-06-07T03:06:10.697Z",
          "wordCount": 660,
          "title": "Learning a Fine-Grained Review-based Transformer Model for Personalized Product Search. (arXiv:2004.09424v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yujia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>",
          "description": "In today's context, deploying data-driven services like recommendation on\nedge devices instead of cloud servers becomes increasingly attractive due to\nprivacy and network latency concerns. A common practice in building compact\non-device recommender systems is to compress their embeddings which are\nnormally the cause of excessive parameterization. However, despite the vast\nvariety of devices and their associated memory constraints, existing\nmemory-efficient recommender systems are only specialized for a fixed memory\nbudget in every design and training life cycle, where a new model has to be\nretrained to obtain the optimal performance while adapting to a smaller/larger\nmemory budget. In this paper, we present a novel lightweight recommendation\nparadigm that allows a well-trained recommender to be customized for arbitrary\ndevice-specific memory constraints without retraining. The core idea is to\ncompose elastic embeddings for each item, where an elastic embedding is the\nconcatenation of a set of embedding blocks that are carefully chosen by an\nautomated search function. Correspondingly, we propose an innovative approach,\nnamely recommendation with universally learned elastic embeddings (RULE). To\nensure the expressiveness of all candidate embedding blocks, RULE enforces a\ndiversity-driven regularization when learning different embedding blocks. Then,\na performance estimator-based evolutionary search function is designed,\nallowing for efficient specialization of elastic embeddings under any memory\nconstraint for on-device recommendation. Extensive experiments on real-world\ndatasets reveal the superior performance of RULE under tight memory budgets.",
          "link": "http://arxiv.org/abs/2106.02223",
          "publishedOn": "2021-06-07T03:06:10.644Z",
          "wordCount": 658,
          "title": "Learning Elastic Embeddings for Customizing On-Device Recommenders. (arXiv:2106.02223v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maekawa_T/0/1/0/all/0/1\">Takuya Maekawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1\">Takahiro Hara</a>",
          "description": "In recommender systems, a cold-start problem occurs when there is no past\ninteraction record associated with the user or item. Typical solutions to the\ncold-start problem make use of contextual information, such as user demographic\nattributes or product descriptions. A group of works have shown that social\nmedia background can help predicting temporal phenomenons such as product sales\nand stock price movements. In this work, our goal is to investigate whether\nsocial media background can be used as extra contextual information to improve\nrecommendation models. Based on an existing deep neural network model, we\nproposed a method to represent temporal social media background as embeddings\nand fuse them as an extra component in the model. We conduct experimental\nevaluations on a real-world e-commerce dataset and a Twitter dataset. The\nresults show that our method of fusing social media background with the\nexisting model does generally improve recommendation performance. In some cases\nthe recommendation accuracy measured by hit-rate@K doubles after fusing with\nsocial media background. Our findings can be beneficial for future recommender\nsystem designs that consider complex temporal information representing social\ninterests.",
          "link": "http://arxiv.org/abs/2106.02256",
          "publishedOn": "2021-06-07T03:06:10.401Z",
          "wordCount": 618,
          "title": "Using Social Media Background to Improve Cold-start Recommendation Deep Models. (arXiv:2106.02256v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daga_E/0/1/0/all/0/1\">Enrico Daga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asprino_L/0/1/0/all/0/1\">Luigi Asprino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulholland_P/0/1/0/all/0/1\">Paul Mulholland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangemi_A/0/1/0/all/0/1\">Aldo Gangemi</a>",
          "description": "The Semantic Web research community understood since its beginning how\ncrucial it is to equip practitioners with methods to transform non-RDF\nresources into RDF. Proposals focus on either engineering content\ntransformations or accessing non-RDF resources with SPARQL. Existing solutions\nrequire users to learn specific mapping languages (e.g. RML), to know how to\nquery and manipulate a variety of source formats (e.g. XPATH, JSON-Path), or to\ncombine multiple languages (e.g. SPARQL Generate). In this paper, we explore an\nalternative solution and contribute a general-purpose meta-model for converting\nnon-RDF resources into RDF: Facade-X. Our approach can be implemented by\noverriding the SERVICE operator and does not require to extend the SPARQL\nsyntax. We compare our approach with the state of art methods RML and SPARQL\nGenerate and show how our solution has lower learning demands and cognitive\ncomplexity, and it is cheaper to implement and maintain, while having\ncomparable extensibility and efficiency.",
          "link": "http://arxiv.org/abs/2106.02361",
          "publishedOn": "2021-06-07T03:06:10.383Z",
          "wordCount": 585,
          "title": "Facade-X: an opinionated approach to SPARQL anything. (arXiv:2106.02361v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirakawa_M/0/1/0/all/0/1\">Masumi Shirakawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1\">Takahiro Hara</a>",
          "description": "Event detection on social media has attracted a number of researches, given\nthe recent availability of large volumes of social media discussions. Previous\nworks on social media event detection either assume a specific type of event,\nor assume certain behavior of observed variables. In this paper, we propose a\ngeneral method for event detection on social media that makes few assumptions.\nThe main assumption we make is that when an event occurs, affected semantic\naspects will behave differently from its usual behavior. We generalize the\nrepresentation of time units based on word embeddings of social media text, and\npropose an algorithm to detect events in time series in a general sense. In the\nexperimental evaluation, we use a novel setting to test if our method and\nbaseline methods can exhaustively catch all real-world news in the test period.\nThe evaluation results show that when the event is quite unusual with regard to\nthe base social media discussion, it can be captured more effectively with our\nmethod. Our method can be easily implemented and can be treated as a starting\npoint for more specific applications.",
          "link": "http://arxiv.org/abs/2106.02250",
          "publishedOn": "2021-06-07T03:06:10.358Z",
          "wordCount": 625,
          "title": "A General Method for Event Detection on Social Media. (arXiv:2106.02250v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1\">Chris Kedzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Suraj Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1\">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>",
          "description": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.02293",
          "publishedOn": "2021-06-07T03:06:10.316Z",
          "wordCount": 548,
          "title": "Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])"
        }
      ]
    },
    {
      "title": "cs.MM updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.MM",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:14.601Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Man_H/0/1/0/all/0/1\">Hengyu Man</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaopeng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1\">Ruiqin Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Debin Zhao</a>",
          "description": "As a crucial part of video compression, intra prediction utilizes local\ninformation of images to eliminate the redundancy in spatial domain. In both\nH.265/HEVC and H.266/VVC, multiple directional prediction modes are employed to\nfind the texture trend of each small block and then the prediction is made\nbased on reference samples in the selected direction. Recently, the intra\nprediction schemes based on neural networks have achieved great success. In\nthese methods, the networks are trained and applied to intra prediction in\naddition to the directional prediction modes. In this paper, we propose a novel\ndata clustering-driven neural network (dubbed DCDNN) for intra prediction,\nwhich can learn deep features of the clustered data. In DCDNN, each network can\nbe split into two networks by adding or subtracting Gaussian random noise. Then\na data clustering-driven training is applied to train all the derived networks\nrecursively. In each iteration, the entire training dataset is partitioned\naccording to the recovery qualities of the derived networks. For the\nexperiment, DCDNN is implemented into HEVC reference software HM-16.9. The\nexperimental results demonstrate that DCDNN can reach an average of 4.2%\nBjontegaard distortion rate (BDrate) improvement (up to 7.0%) over HEVC with\nall intra configuration. Compared with existing fully connected networkbased\nintra prediction methods, the bitrate saving performance is further improved.",
          "link": "http://arxiv.org/abs/2106.05481",
          "publishedOn": "2021-06-11T01:42:13.535Z",
          "wordCount": 633,
          "title": "Data Clustering-Driven Neural Network for Intra Prediction. (arXiv:2106.05481v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/1908.01947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wenkang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jiangqun Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xianglei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiwu Huang</a>",
          "description": "Recently, with the introduction of JPEG phase-aware steganalysis features,\ne.g., GFR, the design of JPEG steganographic distortion cost function turns to\nmaintain not only the statistical undetectability in DCT domain but also in\nspatial domain. To tackle this issue, this paper presents a novel paradigm for\nthe design of JPEG steganographic distortion cost function, which calculates\nthe distortion cost via a generalized Distortion Cost Domain Transformation\n(DCDT) function. The proposed function comprises the decompressed pixel block\nembedding changes and their corresponding embedding distortion costs for unit\nchange, where the pixel embedding distortion costs are represented in a more\ngeneral exponential model, aiming to flexibly allocate the embedding data. In\nthis way, the JPEG steganography could be formulated as the optimization\nproblem of minimizing the overall distortion cost in its decompressed spatial\ndomain, which is equivalent to maximizing its statistical undetectability\nagainst JPEG phase-aware steganalysis features. Experimental results show that\nthe proposed DCDT equipped with HiLL (a spatial steganographic distortion cost\nfunction) is superior to other state-of-the-art JPEG steganographic schemes,\ne.g., UERD, J-UNIWARD, and GUED in resisting the detection of JPEG phase-aware\nfeature-based steganalyzers GFR and SCA-GFR, and rivals BET-HiLL with one order\nof magnitude lower computational complexity, along with the possibility of\nbeing further improved by considering the mutually dependent embedding\ninteractions. In addition, the proposed DCDT is also verified to be effective\nfor different image databases and quality factors.",
          "link": "http://arxiv.org/abs/1908.01947",
          "publishedOn": "2021-06-11T01:42:13.440Z",
          "wordCount": 691,
          "title": "New Design Paradigm of Distortion Cost Function for Efficient JPEG Steganography. (arXiv:1908.01947v3 [cs.MM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changsheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_F/0/1/0/all/0/1\">Fengbo Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiwu Huang</a>",
          "description": "Recapturing attack can be employed as a simple but effective anti-forensic\ntool for digital document images. Inspired by the document inspection process\nthat compares a questioned document against a reference sample, we proposed a\ndocument recapture detection scheme by employing Siamese network to compare and\nextract distinct features in a recapture document image. The proposed algorithm\ntakes advantages of both metric learning and image forensic techniques. Instead\nof adopting Euclidean distance-based loss function, we integrate the forensic\nsimilarity function with a triplet loss and a normalized softmax loss. After\ntraining with the proposed triplet selection strategy, the resulting feature\nembedding clusters the genuine samples near the reference while pushes the\nrecaptured samples apart. In the experiment, we consider practical domain\ngeneralization problems, such as the variations in printing/imaging devices,\nsubstrates, recapturing channels, and document types. To evaluate the\nrobustness of different approaches, we benchmark some popular off-the-shelf\nmachine learning-based approaches, a state-of-the-art document image detection\nscheme, and the proposed schemes with different network backbones under various\nexperimental protocols. Experimental results show that the proposed schemes\nwith different network backbones have consistently outperformed the\nstate-of-the-art approaches under different experimental settings.\nSpecifically, under the most challenging scenario in our experiment, i.e.,\nevaluation across different types of documents that produced by different\ndevices, we have achieved less than 5.00% APCER (Attack Presentation\nClassification Error Rate) and 5.56% BPCER (Bona Fide Presentation\nClassification Error Rate) by the proposed network with ResNeXt101 backbone at\n5% BPCER decision threshold.",
          "link": "http://arxiv.org/abs/2101.01404",
          "publishedOn": "2021-06-10T01:56:44.423Z",
          "wordCount": 703,
          "title": "Domain Generalization for Document Authentication against Practical Recapturing Attacks. (arXiv:2101.01404v2 [cs.MM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1\">Yuan Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>",
          "description": "Scene graphs are semantic abstraction of images that encourage visual\nunderstanding and reasoning. However, the performance of Scene Graph Generation\n(SGG) is unsatisfactory when faced with biased data in real-world scenarios.\nConventional debiasing research mainly studies from the view of balancing data\ndistribution or learning unbiased models and representations, ignoring the\ncorrelations among the biased classes. In this work, we analyze this problem\nfrom a novel cognition perspective: automatically building a hierarchical\ncognitive structure from the biased predictions and navigating that hierarchy\nto locate the relationships, making the tail relationships receive more\nattention in a coarse-to-fine mode. To this end, we propose a novel debiasing\nCognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive\nstructure CogTree to organize the relationships based on the prediction of a\nbiased SGG model. The CogTree distinguishes remarkably different relationships\nat first and then focuses on a small portion of easily confused ones. Then, we\npropose a debiasing loss specially for this cognitive structure, which supports\ncoarse-to-fine distinction for the correct relationships. The loss is\nmodel-agnostic and consistently boosting the performance of several\nstate-of-the-art models. The code is available at:\nhttps://github.com/CYVincent/Scene-Graph-Transformer-CogTree.",
          "link": "http://arxiv.org/abs/2009.07526",
          "publishedOn": "2021-06-09T02:01:46.700Z",
          "wordCount": 677,
          "title": "CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1\">Ioannis Kazakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1\">Carles Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1\">Miriam Bellver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1\">Carina Silberer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1\">Xavier Giro-i-Nieto</a>",
          "description": "Recent advances in deep learning have brought significant progress in visual\ngrounding tasks such as language-guided video object segmentation. However,\ncollecting large datasets for these tasks is expensive in terms of annotation\ntime, which represents a bottleneck. To this end, we propose a novel method,\nnamely SynthRef, for generating synthetic referring expressions for target\nobjects in an image (or video frame), and we also present and disseminate the\nfirst large-scale dataset with synthetic referring expressions for video object\nsegmentation. Our experiments demonstrate that by training with our synthetic\nreferring expressions one can improve the ability of a model to generalize\nacross different datasets, without any additional annotation cost. Moreover,\nour formulation allows its application to any object detection or segmentation\ndataset.",
          "link": "http://arxiv.org/abs/2106.04403",
          "publishedOn": "2021-06-09T02:01:46.689Z",
          "wordCount": 584,
          "title": "SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10898",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schimpe_A/0/1/0/all/0/1\">Andreas Schimpe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoffmann_S/0/1/0/all/0/1\">Simon Hoffmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diermeyer_F/0/1/0/all/0/1\">Frank Diermeyer</a>",
          "description": "Vehicles with autonomous driving capabilities are present on public streets.\nHowever, edge cases remain that still require a human in-vehicle driver.\nAssuming the vehicle manages to come to a safe state in an automated fashion,\nteleoperated driving technology enables a human to resolve the situation\nremotely by a control interface connected via a mobile network. While this is a\npromising solution, it also introduces technical challenges, one of them being\nthe necessity to transmit video data of multiple cameras from the vehicle to\nthe human operator. In this paper, an adaptive video streaming framework\nspecifically designed for teleoperated vehicles is proposed and demonstrated.\nThe framework enables automatic reconfiguration of the video streams of the\nmulti-camera system at runtime. Predictions of variable transmission service\nquality are taken into account. With the objective to improve visual quality,\nthe framework uses so-called rate-quality models to dynamically allocate\nbitrates and select resolution scaling factors. Results from deploying the\nproposed framework on an actual teleoperated driving system are presented.",
          "link": "http://arxiv.org/abs/2102.10898",
          "publishedOn": "2021-06-09T02:01:46.656Z",
          "wordCount": 631,
          "title": "Adaptive Video Configuration and Bitrate Allocation for Vehicles. (arXiv:2102.10898v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingjie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jimin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Eng Gee Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Si Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goulermas_J/0/1/0/all/0/1\">John Y. Goulermas</a>",
          "description": "In this paper, we are tackling the weakly-supervised referring expression\ngrounding task, for the localization of a referent object in an image according\nto a query sentence, where the mapping between image regions and queries are\nnot available during the training stage. In traditional methods, an object\nregion that best matches the referring expression is picked out, and then the\nquery sentence is reconstructed from the selected region, where the\nreconstruction difference serves as the loss for back-propagation. The existing\nmethods, however, conduct both the matching and the reconstruction\napproximately as they ignore the fact that the matching correctness is unknown.\nTo overcome this limitation, a discriminative triad is designed here as the\nbasis to the solution, through which a query can be converted into one or\nmultiple discriminative triads in a very scalable way. Based on the\ndiscriminative triad, we further propose the triad-level matching and\nreconstruction modules which are lightweight yet effective for the\nweakly-supervised training, making it three times lighter and faster than the\nprevious state-of-the-art methods. One important merit of our work is its\nsuperior performance despite the simple and neat design. Specifically, the\nproposed method achieves a new state-of-the-art accuracy when evaluated on\nRefCOCO (39.21%), RefCOCO+ (39.18%) and RefCOCOg (43.24%) datasets, that is\n4.17%, 4.08% and 7.8% higher than the previous one, respectively.",
          "link": "http://arxiv.org/abs/2106.04053",
          "publishedOn": "2021-06-09T02:01:46.640Z",
          "wordCount": 661,
          "title": "Discriminative Triad Matching and Reconstruction for Weakly Referring Expression Grounding. (arXiv:2106.04053v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhekai Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hongzu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Ke Lu</a>",
          "description": "Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned\nfrom a well-labeled source domain to an unlabeled target domain. Recently,\nadversarial domain adaptation with two distinct classifiers (bi-classifier) has\nbeen introduced into UDA which is effective to align distributions between\ndifferent domains. Previous bi-classifier adversarial learning methods only\nfocus on the similarity between the outputs of two distinct classifiers.\nHowever, the similarity of the outputs cannot guarantee the accuracy of target\nsamples, i.e., target samples may match to wrong categories even if the\ndiscrepancy between two classifiers is small. To challenge this issue, in this\npaper, we propose a cross-domain gradient discrepancy minimization (CGDM)\nmethod which explicitly minimizes the discrepancy of gradients generated by\nsource samples and target samples. Specifically, the gradient gives a cue for\nthe semantic information of target samples so it can be used as a good\nsupervision to improve the accuracy of target samples. In order to compute the\ngradient signal of target samples, we further obtain target pseudo labels\nthrough a clustering-based self-supervised learning. Extensive experiments on\nthree widely used UDA datasets show that our method surpasses many previous\nstate-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.",
          "link": "http://arxiv.org/abs/2106.04151",
          "publishedOn": "2021-06-09T02:01:46.600Z",
          "wordCount": 647,
          "title": "Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.10637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1\">Jane You</a>",
          "description": "How to extract effective expression representations that invariant to the\nidentity-specific attributes is a long-lasting problem for facial expression\nrecognition (FER). Most of the previous methods process the RGB images of a\nsequence, while we argue that the off-the-shelf and valuable expression-related\nmuscle movement is already embedded in the compression format. In this paper,\nwe target to explore the inter-subject variations eliminated facial expression\nrepresentation in the compressed video domain. In the up to two orders of\nmagnitude compressed domain, we can explicitly infer the expression from the\nresidual frames and possibly extract identity factors from the I frame with a\npre-trained face recognition network. By enforcing the marginal independence of\nthem, the expression feature is expected to be purer for the expression and be\nrobust to identity shifts. Specifically, we propose a novel collaborative\nmin-min game for mutual information (MI) minimization in latent space. We do\nnot need the identity label or multiple expression samples from the same person\nfor identity elimination. Moreover, when the apex frame is annotated in the\ndataset, the complementary constraint can be further added to regularize the\nfeature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image-based methods on the\ntypical FER benchmarks with about 3 times faster inference.",
          "link": "http://arxiv.org/abs/2010.10637",
          "publishedOn": "2021-06-08T02:20:20.501Z",
          "wordCount": 695,
          "title": "Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.13125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Tianyi Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mai Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_R/0/1/0/all/0/1\">Runzhi Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_Q/0/1/0/all/0/1\">Qunliang Xing</a>",
          "description": "Versatile Video Coding (VVC), as the latest standard, significantly improves\nthe coding efficiency over its ancestor standard High Efficiency Video Coding\n(HEVC), but at the expense of sharply increased complexity. In VVC, the\nquad-tree plus multi-type tree (QTMT) structure of coding unit (CU) partition\naccounts for over 97% of the encoding time, due to the brute-force search for\nrecursive rate-distortion (RD) optimization. Instead of the brute-force QTMT\nsearch, this paper proposes a deep learning approach to predict the QTMT-based\nCU partition, for drastically accelerating the encoding process of intra-mode\nVVC. First, we establish a large-scale database containing sufficient CU\npartition patterns with diverse video content, which can facilitate the\ndata-driven VVC complexity reduction. Next, we propose a multi-stage exit CNN\n(MSE-CNN) model with an early-exit mechanism to determine the CU partition, in\naccord with the flexible QTMT structure at multiple stages. Then, we design an\nadaptive loss function for training the MSE-CNN model, synthesizing both the\nuncertain number of split modes and the target on minimized RD cost. Finally, a\nmulti-threshold decision scheme is developed, achieving desirable trade-off\nbetween complexity and RD performance. Experimental results demonstrate that\nour approach can reduce the encoding time of VVC by 44.65%-66.88% with the\nnegligible Bj{\\o}ntegaard delta bit-rate (BD-BR) of 1.322%-3.188%, which\nsignificantly outperforms other state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2006.13125",
          "publishedOn": "2021-06-08T02:20:20.377Z",
          "wordCount": 718,
          "title": "DeepQTMT: A Deep Learning Approach for Fast QTMT-based CU Partition of Intra-mode VVC. (arXiv:2006.13125v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Suvidha Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwee Kuan Lee</a>",
          "description": "Researchers working on computational analysis of Whole Slide Images (WSIs) in\nhistopathology have primarily resorted to patch-based modelling due to large\nresolution of each WSI. The large resolution makes WSIs infeasible to be fed\ndirectly into the machine learning models due to computational constraints.\nHowever, due to patch-based analysis, most of the current methods fail to\nexploit the underlying spatial relationship among the patches. In our work, we\nhave tried to integrate this relationship along with feature-based correlation\namong the extracted patches from the particular tumorous region. For the given\ntask of classification, we have used BiLSTMs to model both forward and backward\ncontextual relationship. RNN based models eliminate the limitation of sequence\nsize by allowing the modelling of variable size images within a deep learning\nmodel. We have also incorporated the effect of spatial continuity by exploring\ndifferent scanning techniques used to sample patches. To establish the\nefficiency of our approach, we trained and tested our model on two datasets,\nmicroscopy images and WSI tumour regions. After comparing with contemporary\nliterature we achieved the better performance with accuracy of 90% for\nmicroscopy image dataset. For WSI tumour region dataset, we compared the\nclassification results with deep learning networks such as ResNet, DenseNet,\nand InceptionV3 using maximum voting technique. We achieved the highest\nperformance accuracy of 84%. We found out that BiLSTMs with CNN features have\nperformed much better in modelling patches into an end-to-end Image\nclassification network. Additionally, the variable dimensions of WSI tumour\nregions were used for classification without the need for resizing. This\nsuggests that our method is independent of tumour image size and can process\nlarge dimensional images without losing the resolution details.",
          "link": "http://arxiv.org/abs/2106.02864",
          "publishedOn": "2021-06-08T02:20:20.291Z",
          "wordCount": 757,
          "title": "An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1\">Tong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bang Liu</a>",
          "description": "Keyword spotting aims to identify specific keyword audio utterances. In\nrecent years, deep convolutional neural networks have been widely utilized in\nkeyword spotting systems. However, their model architectures are mainly based\non off-the shelfbackbones such as VGG-Net or ResNet, instead of specially\ndesigned for the task. In this paper, we utilize neural architecture search to\ndesign convolutional neural network models that can boost the performance of\nkeyword spotting while maintaining an acceptable memory footprint.\nSpecifically, we search the model operators and their connections in a specific\nsearch space with Encoder-Decoder neural architecture optimization. Extensive\nevaluations on Google's Speech Commands Dataset show that the model\narchitecture searched by our approach achieves a state-of-the-art accuracy of\nover 97%.",
          "link": "http://arxiv.org/abs/2106.02738",
          "publishedOn": "2021-06-08T02:20:20.207Z",
          "wordCount": 540,
          "title": "Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:10.657Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1\">Emna Baccour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1\">Fatima Haouari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1\">Aiman Erbad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Amr Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1\">Kashif Bilal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1\">Mohsen Guizani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1\">Mounir Hamdi</a>",
          "description": "Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.",
          "link": "http://arxiv.org/abs/2106.02420",
          "publishedOn": "2021-06-07T03:06:10.260Z",
          "wordCount": 667,
          "title": "An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.05611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshihashi_R/0/1/0/all/0/1\">Ryota Yoshihashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1\">Tomohiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doi_K/0/1/0/all/0/1\">Kenji Doi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujino_T/0/1/0/all/0/1\">Takumi Fujino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_N/0/1/0/all/0/1\">Naoaki Yamashita</a>",
          "description": "In the deployment of scene-text spotting systems on mobile platforms,\nlightweight models with low computation are preferable. In concept, end-to-end\n(E2E) text spotting is suitable for such purposes because it performs text\ndetection and recognition in a single model. However, current state-of-the-art\nE2E methods rely on heavy feature extractors, recurrent sequence modellings,\nand complex shape aligners to pursue accuracy, which means their computations\nare still heavy. We explore the opposite direction: How far can we go without\nbells and whistles in E2E text spotting? To this end, we propose a\ntext-spotting method that consists of simple convolutions and a few\npost-processes, named Context-Free TextSpotter. Experiments using standard\nbenchmarks show that Context-Free TextSpotter achieves real-time text spotting\non a GPU with only three million parameters, which is the smallest and fastest\namong existing deep text spotters, with an acceptable transcription quality\ndegradation compared to heavier ones. Further, we demonstrate that our text\nspotter can run on a smartphone with affordable latency, which is valuable for\nbuilding stand-alone OCR applications.",
          "link": "http://arxiv.org/abs/2106.05611",
          "publishedOn": "2021-06-11T01:42:17.890Z",
          "wordCount": 610,
          "title": "Context-Free TextSpotter for Real-Time and Mobile End-to-End Text Detection and Recognition. (arXiv:2106.05611v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1\">Carlos Esteves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Single image pose estimation is a fundamental problem in many vision and\nrobotics tasks, and existing deep learning approaches suffer by not completely\nmodeling and handling: i) uncertainty about the predictions, and ii) symmetric\nobjects with multiple (sometimes infinite) correct poses. To this end, we\nintroduce a method to estimate arbitrary, non-parametric distributions on\nSO(3). Our key idea is to represent the distributions implicitly, with a neural\nnetwork that estimates the probability given the input image and a candidate\npose. Grid sampling or gradient ascent can be used to find the most likely\npose, but it is also possible to evaluate the probability at any pose, enabling\nreasoning about symmetries and uncertainty. This is the most general way of\nrepresenting distributions on manifolds, and to showcase the rich expressive\npower, we introduce a dataset of challenging symmetric and nearly-symmetric\nobjects. We require no supervision on pose uncertainty -- the model trains only\nwith a single pose per example. Nonetheless, our implicit model is highly\nexpressive to handle complex distributions over 3D poses, while still obtaining\naccurate pose estimation on standard non-ambiguous environments, achieving\nstate-of-the-art performance on Pascal3D+ and ModelNet10-SO(3) benchmarks.",
          "link": "http://arxiv.org/abs/2106.05965",
          "publishedOn": "2021-06-11T01:42:17.763Z",
          "wordCount": 625,
          "title": "Implicit-PDF: Non-Parametric Representation of Probability Distributions on the Rotation Manifold. (arXiv:2106.05965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chunjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>",
          "description": "Compared with cheap addition operation, multiplication operation is of much\nhigher computation complexity. The widely-used convolutions in deep neural\nnetworks are exactly cross-correlation to measure the similarity between input\nfeature and convolution filters, which involves massive multiplications between\nfloat values. In this paper, we present adder networks (AdderNets) to trade\nthese massive multiplications in deep neural networks, especially convolutional\nneural networks (CNNs), for much cheaper additions to reduce computation costs.\nIn AdderNets, we take the $\\ell_1$-norm distance between filters and input\nfeature as the output response. The influence of this new similarity measure on\nthe optimization of neural network have been thoroughly analyzed. To achieve a\nbetter performance, we develop a special training approach for AdderNets by\ninvestigating the $\\ell_p$-norm. We then propose an adaptive learning rate\nstrategy to enhance the training procedure of AdderNets according to the\nmagnitude of each neuron's gradient. As a result, the proposed AdderNets can\nachieve 75.7% Top-1 accuracy 92.3% Top-5 accuracy using ResNet-50 on the\nImageNet dataset without any multiplication in convolutional layer. Moreover,\nwe develop a theoretical foundation for AdderNets, by showing that both the\nsingle hidden layer AdderNet and the width-bounded deep AdderNet with ReLU\nactivation functions are universal function approximators. These results match\nthose of the traditional neural networks using the more complex multiplication\nunits. An approximation bound for AdderNets with a single hidden layer is also\npresented.",
          "link": "http://arxiv.org/abs/2105.14202",
          "publishedOn": "2021-06-11T01:42:17.733Z",
          "wordCount": null,
          "title": "Universal Adder Neural Networks. (arXiv:2105.14202v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05861",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Das_D/0/1/0/all/0/1\">Debanjan Das</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samal_C/0/1/0/all/0/1\">Chirag Samal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ukey_D/0/1/0/all/0/1\">Deewanshu Ukey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chowdhary_G/0/1/0/all/0/1\">Gourav Chowdhary</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohanty_S/0/1/0/all/0/1\">Saraju P. Mohanty</a>",
          "description": "The pandemic of novel Coronavirus Disease 2019 (COVID-19) is widespread all\nover the world causing serious health problems as well as serious impact on the\nglobal economy. Reliable and fast testing of the COVID-19 has been a challenge\nfor researchers and healthcare practitioners. In this work we present a novel\nmachine learning (ML) integrated X-ray device in Healthcare Cyber-Physical\nSystem (H-CPS) or smart healthcare framework (called CoviLearn) to allow\nhealthcare practitioners to perform automatic initial screening of COVID-19\npatients. We propose convolutional neural network (CNN) models of X-ray images\nintegrated into an X-ray device for automatic COVID-19 detection. The proposed\nCoviLearn device will be useful in detecting if a person is COVID-19 positive\nor negative by considering the chest X-ray image of individuals. CoviLearn will\nbe useful tool doctors to detect potential COVID-19 infections instantaneously\nwithout taking more intrusive healthcare data samples, such as saliva and\nblood. COVID-19 attacks the endothelium tissues that support respiratory tract,\nX-rays images can be used to analyze the health of a patient lungs. As all\nhealthcare centers have X-ray machines, it could be possible to use proposed\nCoviLearn X-rays to test for COVID-19 without the especial test kits. Our\nproposed automated analysis system CoviLearn which has 99% accuracy will be\nable to save valuable time of medical professionals as the X-ray machines come\nwith a drawback as it needed a radiology expert.",
          "link": "http://arxiv.org/abs/2106.05861",
          "publishedOn": "2021-06-11T01:42:17.721Z",
          "wordCount": 735,
          "title": "CoviLearn: A Machine Learning Integrated Smart X-Ray Device in Healthcare Cyber-Physical System for Automatic Initial Screening of COVID-19. (arXiv:2106.05861v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yap_C/0/1/0/all/0/1\">Chuin Hong Yap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yap_M/0/1/0/all/0/1\">Moi Hoon Yap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1\">Adrian K. Davison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_R/0/1/0/all/0/1\">Ryan Cunningham</a>",
          "description": "Facial expression spotting is the preliminary step for micro- and\nmacro-expression analysis. The task of reliably spotting such expressions in\nvideo sequences is currently unsolved. The current best systems depend upon\noptical flow methods to extract regional motion features, before categorisation\nof that motion into a specific class of facial movement. Optical flow is\nsusceptible to drift error, which introduces a serious problem for motions with\nlong-term dependencies, such as high frame-rate macro-expression. We propose a\npurely deep learning solution which, rather than track frame differential\nmotion, compares via a convolutional model, each frame with two temporally\nlocal reference frames. Reference frames are sampled according to calculated\nmicro- and macro-expression durations. We show that our solution achieves\nstate-of-the-art performance (F1-score of 0.126) in a dataset of high\nframe-rate (200 fps) long video sequences (SAMM-LV) and is competitive in a low\nframe-rate (30 fps) dataset (CAS(ME)2). In this paper, we document our deep\nlearning model and parameters, including how we use local contrast\nnormalisation, which we show is critical for optimal results. We surpass a\nlimitation in existing methods, and advance the state of deep learning in the\ndomain of facial expression spotting.",
          "link": "http://arxiv.org/abs/2105.06340",
          "publishedOn": "2021-06-11T01:42:17.680Z",
          "wordCount": null,
          "title": "3D-CNN for Facial Micro- and Macro-expression Spotting on Long Video Sequences using Temporal Oriented Reference Frame. (arXiv:2105.06340v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.01243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Spatial pooling is an important step in computer vision systems like\nConvolutional Neural Networks or the Bag-of-Words method. The spatial pooling\npurpose is to combine neighbouring descriptors to obtain a single descriptor\nfor a given region (local or global). The resultant combined vector must be as\ndiscriminant as possible, in other words, must contain relevant information,\nwhile removing irrelevant and confusing details. Maximum and average are the\nmost common aggregation functions used in the pooling step. To improve the\naggregation of relevant information without degrading their discriminative\npower for image classification, we introduce a simple but effective scheme\nbased on Ordered Weighted Average (OWA) aggregation operators. We present a\nmethod to learn the weights of the OWA aggregation operator in a Bag-of-Words\nframework and in Convolutional Neural Networks, and provide an extensive\nevaluation showing that OWA based pooling outperforms classical aggregation\noperators.",
          "link": "http://arxiv.org/abs/2007.01243",
          "publishedOn": "2021-06-11T01:42:17.678Z",
          "wordCount": null,
          "title": "Learning ordered pooling weights in image classification. (arXiv:2007.01243v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1\">Chao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1\">Justin Dulay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Gregory Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1\">Duke Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1\">Nadia Shakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Automated high throughput plant phenotyping involves leveraging sensors, such\nas RGB, thermal and hyperspectral cameras (among others), to make large scale\nand rapid measurements of the physical properties of plants for the purpose of\nbetter understanding the difference between crops and facilitating rapid plant\nbreeding programs. One of the most basic phenotyping tasks is to determine the\ncultivar, or species, in a particular sensor product. This simple phenotype can\nbe used to detect errors in planting and to learn the most differentiating\nfeatures between cultivars. It is also a challenging visual recognition task,\nas a large number of highly related crops are grown simultaneously, leading to\na classification problem with low inter-class variance. In this paper, we\nintroduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum\ncaptured by a state-of-the-art gantry system, a multi-resolution network\narchitecture that learns both global and fine-grained features on the crops,\nand a new global pooling strategy called Dynamic Outlier Pooling which\noutperforms standard global pooling strategies on this task.",
          "link": "http://arxiv.org/abs/2106.05748",
          "publishedOn": "2021-06-11T01:42:17.653Z",
          "wordCount": 607,
          "title": "Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "In many machine learning problems, large-scale datasets have become the\nde-facto standard to train state-of-the-art deep networks at the price of heavy\ncomputation load. In this paper, we focus on condensing large training sets\ninto significantly smaller synthetic sets which can be used to train deep\nneural networks from scratch with minimum drop in performance. Inspired from\nthe recent training set synthesis methods, we propose Differentiable Siamese\nAugmentation that enables effective use of data augmentation to synthesize more\ninformative synthetic images and thus achieves better performance when training\nnetworks with augmentations. Experiments on multiple image classification\nbenchmarks demonstrate that the proposed method obtains substantial gains over\nthe state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show\nwith only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%\nrelative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We\nalso explore the use of our method in continual learning and neural\narchitecture search, and show promising results.",
          "link": "http://arxiv.org/abs/2102.08259",
          "publishedOn": "2021-06-11T01:42:17.642Z",
          "wordCount": 615,
          "title": "Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chunle Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Linghao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinwei Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Low-light image enhancement (LLIE) aims at improving the perception or\ninterpretability of an image captured in an environment with poor illumination.\nRecent advances in this area are dominated by deep learning-based solutions,\nwhere many learning strategies, network structures, loss functions, training\ndata, etc. have been employed. In this paper, we provide a comprehensive survey\nto cover various aspects ranging from algorithm taxonomy to unsolved open\nissues. To examine the generalization of existing methods, we propose a\nlarge-scale low-light image and video dataset, in which the images and videos\nare taken by different mobile phones' cameras under diverse illumination\nconditions. Besides, for the first time, we provide a unified online platform\nthat covers many popular LLIE methods, of which the results can be produced\nthrough a user-friendly web interface. In addition to qualitative and\nquantitative evaluation of existing methods on publicly available and our\nproposed datasets, we also validate their performance in face detection in the\ndark. This survey together with the proposed dataset and online platform could\nserve as a reference source for future study and promote the development of\nthis research field. The proposed platform and the collected methods, datasets,\nand evaluation metrics are publicly available and will be regularly updated at\nhttps://github.com/Li-Chongyi/Lighting-the-Darkness-in-the-Deep-Learning-Era-Open.\nOur low-light image and video dataset is also available.",
          "link": "http://arxiv.org/abs/2104.10729",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "Low-Light Image and Video Enhancement Using Deep Learning: A Survey. (arXiv:2104.10729v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1\">Filippos Kokkinos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkinos_I/0/1/0/all/0/1\">Iasonas Kokkinos</a>",
          "description": "We present To The Point (TTP), a method for reconstructing 3D objects from a\nsingle image using 2D to 3D correspondences learned from weak supervision. We\nrecover a 3D shape from a 2D image by first regressing the 2D positions\ncorresponding to the 3D template vertices and then jointly estimating a rigid\ncamera transform and non-rigid template deformation that optimally explain the\n2D positions through the 3D shape projection. By relying on 3D-2D\ncorrespondences we use a simple per-sample optimization problem to replace\nCNN-based regression of camera pose and non-rigid deformation and thereby\nobtain substantially more accurate 3D reconstructions. We treat this\noptimization as a differentiable layer and train the whole system in an\nend-to-end manner. We report systematic quantitative improvements on multiple\ncategories and provide qualitative results comprising diverse shape, pose and\ntexture prediction examples. Project website:\nhttps://fkokkinos.github.io/to_the_point/.",
          "link": "http://arxiv.org/abs/2106.05662",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "To The Point: Correspondence-driven monocular 3D category reconstruction. (arXiv:2106.05662v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2003.13827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Image search can be tackled using deep features from pre-trained\nConvolutional Neural Networks (CNN). The feature map from the last\nconvolutional layer of a CNN encodes descriptive information from which a\ndiscriminative global descriptor can be obtained. We propose a new\nrepresentation of co-occurrences from deep convolutional features to extract\nadditional relevant information from this last convolutional layer. Combining\nthis co-occurrence map with the feature map, we achieve an improved image\nrepresentation. We present two different methods to get the co-occurrence\nrepresentation, the first one based on direct aggregation of activations, and\nthe second one, based on a trainable co-occurrence representation. The image\ndescriptors derived from our methodology improve the performance in very\nwell-known image retrieval datasets as we prove in the experiments.",
          "link": "http://arxiv.org/abs/2003.13827",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_C/0/1/0/all/0/1\">Chul Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guanghua Xiao</a>",
          "description": "Tumor shape is a key factor that affects tumor growth and metastasis. This\npaper proposes a topological feature computed by persistent homology to\ncharacterize tumor progression from digital pathology and radiology images and\nexamines its effect on the time-to-event data. The proposed topological\nfeatures are invariant to scale-preserving transformation and can summarize\nvarious tumor shape patterns. The topological features are represented in\nfunctional space and used as functional predictors in a functional Cox\nproportional hazards model. The proposed model enables interpretable inference\nabout the association between topological shape features and survival risks.\nTwo case studies are conducted using consecutive 143 lung cancer and 77 brain\ntumor patients. The results of both studies show that the topological features\npredict survival prognosis after adjusting clinical variables, and the\npredicted high-risk groups have significantly (at the level of 0.01) worse\nsurvival outcomes than the low-risk groups. Also, the topological shape\nfeatures found to be positively associated with survival hazards are irregular\nand heterogeneous shape patterns, which are known to be related to tumor\nprogression.",
          "link": "http://arxiv.org/abs/2012.12102",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "Using Persistent Homology Topological Features to Characterize Medical Images: Case Studies on Lung and Brain Cancers. (arXiv:2012.12102v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xingkun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuge Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_P/0/1/0/all/0/1\">Pengcheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaoxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jilin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zhen Cui</a>",
          "description": "Demographic bias is a significant challenge in practical face recognition\nsystems. Existing methods heavily rely on accurate demographic annotations.\nHowever, such annotations are usually unavailable in real scenarios. Moreover,\nthese methods are typically designed for a specific demographic group and are\nnot general enough. In this paper, we propose a false positive rate penalty\nloss, which mitigates face recognition bias by increasing the consistency of\ninstance False Positive Rate (FPR). Specifically, we first define the instance\nFPR as the ratio between the number of the non-target similarities above a\nunified threshold and the total number of the non-target similarities. The\nunified threshold is estimated for a given total FPR. Then, an additional\npenalty term, which is in proportion to the ratio of instance FPR overall FPR,\nis introduced into the denominator of the softmax-based loss. The larger the\ninstance FPR, the larger the penalty. By such unequal penalties, the instance\nFPRs are supposed to be consistent. Compared with the previous debiasing\nmethods, our method requires no demographic annotations. Thus, it can mitigate\nthe bias among demographic groups divided by various attributes, and these\nattributes are not needed to be previously predefined during training.\nExtensive experimental results on popular benchmarks demonstrate the\nsuperiority of our method over state-of-the-art competitors. Code and trained\nmodels are available at https://github.com/Tencent/TFace.",
          "link": "http://arxiv.org/abs/2106.05519",
          "publishedOn": "2021-06-11T01:42:17.056Z",
          "wordCount": 660,
          "title": "Consistent Instance False Positive Improves Fairness in Face Recognition. (arXiv:2106.05519v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yicheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yongqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiahui Zhu</a>",
          "description": "Recovering 3D human pose from 2D joints is a highly unconstrained problem,\nespecially without any video or multi-view information. We present an\nunsupervised GAN-based model to recover 3D human pose from 2D joint locations\nextracted from a single image. Our model uses a GAN to learn the mapping of\ndistribution from 2D poses to 3D poses, not the simple 2D-3D correspondence.\nConsidering the reprojection constraint, our model can estimate the camera so\nthat we can reproject the estimated 3D pose to the original 2D pose. Based on\nthis reprojection method, we can rotate and reproject the generated pose to get\nour \"new\" 2D pose and then use a weight sharing generator to estimate the \"new\"\n3D pose and a \"new\" camera. Through the above estimation process, we can define\nthe single-view-multi-angle consistency loss during training to simulate\nmulti-view consistency, which means the 3D poses and cameras estimated from two\nangles of a single view should be able to be mixed to generate rich 2D\nreprojections, and the 2D reprojections reprojected from the same 3D pose\nshould be consistent. The experimental results on Human3.6M show that our\nmethod outperforms all the state-of-the-art methods, and results on\nMPI-INF-3DHP show that our method outperforms state-of-the-art by approximately\n15.0%.",
          "link": "http://arxiv.org/abs/2106.05616",
          "publishedOn": "2021-06-11T01:42:16.945Z",
          "wordCount": 636,
          "title": "SVMA: A GAN-based model for Monocular 3D Human Pose Estimation. (arXiv:2106.05616v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weifeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_C/0/1/0/all/0/1\">Chao Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>",
          "description": "Few-shot learning (FSL) aims to learn a classifier that can be easily adapted\nto accommodate new tasks not seen during training, given only a few examples.\nTo handle the limited-data problem in few-shot regimes, recent methods tend to\ncollectively use a set of local features to densely represent an image instead\nof using a mixed global feature. They generally explore a unidirectional\nquery-to-support paradigm in FSL, e.g., find the nearest/optimal support\nfeature for each query feature and aggregate these local matches for a joint\nclassification. In this paper, we propose a new method Mutual Centralized\nLearning (MCL) to fully affiliate the two disjoint sets of dense features in a\nbidirectional paradigm. We associate each local feature with a particle that\ncan bidirectionally random walk in a discrete feature space by the\naffiliations. To estimate the class probability, we propose the features'\naccessibility that measures the expected number of visits to the support\nfeatures of that class in a Markov process. We relate our method to learning a\ncentrality on an affiliation network and demonstrate its capability to be\nplugged in existing methods by highlighting centralized local features.\nExperiments show that our method achieves the state-of-the-art on both\nminiImageNet and tieredImageNet.",
          "link": "http://arxiv.org/abs/2106.05517",
          "publishedOn": "2021-06-11T01:42:16.846Z",
          "wordCount": 637,
          "title": "Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification. (arXiv:2106.05517v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1\">Adrian Spurr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahiya_A/0/1/0/all/0/1\">Aneesh Dahiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xucong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "Acquiring accurate 3D annotated data for hand pose estimation is a\nnotoriously difficult problem. This typically requires complex multi-camera\nsetups and controlled conditions, which in turn creates a domain gap that is\nhard to bridge to fully unconstrained settings. Encouraged by the success of\ncontrastive learning on image classification tasks, we propose a new\nself-supervised method for the structured regression task of 3D hand pose\nestimation. Contrastive learning makes use of unlabeled data for the purpose of\nrepresentation learning via a loss formulation that encourages the learned\nfeature representations to be invariant under any image transformation. For 3D\nhand pose estimation, it too is desirable to have invariance to appearance\ntransformation such as color jitter. However, the task requires equivariance\nunder affine transformations, such as rotation and translation. To address this\nissue, we propose an equivariant contrastive objective and demonstrate its\neffectiveness in the context of 3D hand pose estimation. We experimentally\ninvestigate the impact of invariant and equivariant contrastive objectives and\nshow that learning equivariant features leads to better representations for the\ntask of 3D hand pose estimation. Furthermore, we show that a standard\nResNet-152, trained on additional unlabeled data, attains an improvement of\n$7.6\\%$ in PA-EPE on FreiHAND and thus achieves state-of-the-art performance\nwithout any task specific, specialized architectures.",
          "link": "http://arxiv.org/abs/2106.05953",
          "publishedOn": "2021-06-11T01:42:16.834Z",
          "wordCount": 648,
          "title": "Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning. (arXiv:2106.05953v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>",
          "description": "Weight-sharing neural architecture search (NAS) is an effective technique for\nautomating efficient neural architecture design. Weight-sharing NAS builds a\nsupernet that assembles all the architectures as its sub-networks and jointly\ntrains the supernet with the sub-networks. The success of weight-sharing NAS\nheavily relies on distilling the knowledge of the supernet to the sub-networks.\nHowever, we find that the widely used distillation divergence, i.e., KL\ndivergence, may lead to student sub-networks that over-estimate or\nunder-estimate the uncertainty of the teacher supernet, leading to inferior\nperformance of the sub-networks. In this work, we propose to improve the\nsupernet training with a more generalized alpha-divergence. By adaptively\nselecting the alpha-divergence, we simultaneously prevent the over-estimation\nor under-estimation of the uncertainty of the teacher model. We apply the\nproposed alpha-divergence based supernets training to both slimmable neural\nnetworks and weight-sharing NAS, and demonstrate significant improvements.\nSpecifically, our discovered model family, AlphaNet, outperforms prior-art\nmodels on a wide range of FLOPs regimes, including BigNAS, Once-for-All\nnetworks, and AttentiveNAS. We achieve ImageNet top-1 accuracy of 80.0% with\nonly 444M FLOPs. Our code and pretrained models are available at\nhttps://github.com/facebookresearch/AlphaNet.",
          "link": "http://arxiv.org/abs/2102.07954",
          "publishedOn": "2021-06-11T01:42:16.230Z",
          "wordCount": 661,
          "title": "AlphaNet: Improved Training of Supernets with Alpha-Divergence. (arXiv:2102.07954v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1\">Arda D&#xfc;z&#xe7;eker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1\">Silvano Galliani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1\">Christoph Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1\">Pablo Speciale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1\">Mihai Dusmanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose an online multi-view depth prediction approach on posed video\nstreams, where the scene geometry information computed in the previous time\nsteps is propagated to the current time step in an efficient and geometrically\nplausible way. The backbone of our approach is a real-time capable, lightweight\nencoder-decoder that relies on cost volumes computed from pairs of images. We\nextend it by placing a ConvLSTM cell at the bottleneck layer, which compresses\nan arbitrary amount of past information in its states. The novelty lies in\npropagating the hidden state of the cell by accounting for the viewpoint\nchanges between time steps. At a given time step, we warp the previous hidden\nstate into the current camera plane using the previous depth prediction. Our\nextension brings only a small overhead of computation time and memory\nconsumption, while improving the depth predictions significantly. As a result,\nwe outperform the existing state-of-the-art multi-view stereo methods on most\nof the evaluated metrics in hundreds of indoor scenes while maintaining a\nreal-time performance. Code available:\nhttps://github.com/ardaduz/deep-video-mvs",
          "link": "http://arxiv.org/abs/2012.02177",
          "publishedOn": "2021-06-11T01:42:16.059Z",
          "wordCount": 645,
          "title": "DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhengyi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1\">Ryo Hachiuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "We propose a method for object-aware 3D egocentric pose estimation that\ntightly integrates kinematics modeling, dynamics modeling, and scene object\ninformation. Unlike prior kinematics or dynamics-based approaches where the two\ncomponents are used disjointly, we synergize the two approaches via\ndynamics-regulated training. At each timestep, a kinematic model is used to\nprovide a target pose using video evidence and simulation state. Then, a\nprelearned dynamics model attempts to mimic the kinematic pose in a physics\nsimulator. By comparing the pose instructed by the kinematic model against the\npose generated by the dynamics model, we can use their misalignment to further\nimprove the kinematic model. By factoring in the 6DoF pose of objects (e.g.,\nchairs, boxes) in the scene, we demonstrate for the first time, the ability to\nestimate physically-plausible 3D human-object interactions using a single\nwearable camera. We evaluate our egocentric pose estimation method in both\ncontrolled laboratory settings and real-world scenarios.",
          "link": "http://arxiv.org/abs/2106.05969",
          "publishedOn": "2021-06-11T01:42:16.023Z",
          "wordCount": 596,
          "title": "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baradad_M/0/1/0/all/0/1\">Manel Baradad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tongzhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>",
          "description": "Current vision systems are trained on huge datasets, and these datasets come\nwith costs: curation is expensive, they inherit human biases, and there are\nconcerns over privacy and usage rights. To counter these costs, interest has\nsurged in learning from cheaper data sources, such as unlabeled images. In this\npaper we go a step further and ask if we can do away with real image datasets\nentirely, instead learning from noise processes. We investigate a suite of\nimage generation models that produce images from simple random processes. These\nare then used as training data for a visual representation learner with a\ncontrastive loss. We study two types of noise processes, statistical image\nmodels and deep generative models under different random initializations. Our\nfindings show that it is important for the noise to capture certain structural\nproperties of real data but that good performance can be achieved even with\nprocesses that are far from realistic. We also find that diversity is a key\nproperty to learn good representations. Datasets, models, and code are\navailable at https://mbaradad.github.io/learning_with_noise.",
          "link": "http://arxiv.org/abs/2106.05963",
          "publishedOn": "2021-06-11T01:42:16.014Z",
          "wordCount": 611,
          "title": "Learning to See by Looking at Noise. (arXiv:2106.05963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.11652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Martin Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charon_N/0/1/0/all/0/1\">Nicolas Charon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harms_P/0/1/0/all/0/1\">Philipp Harms</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_H/0/1/0/all/0/1\">Hsi-Wei Hsieh</a>",
          "description": "Surface comparison and matching is a challenging problem in computer vision.\nWhile reparametrization-invariant Sobolev metrics provide meaningful elastic\ndistances and point correspondences via the geodesic boundary value problem,\nsolving this problem numerically tends to be difficult. Square root normal\nfields (SRNF) considerably simplify the computation of certain elastic\ndistances between parametrized surfaces. Yet they leave open the issue of\nfinding optimal reparametrizations, which induce elastic distances between\nunparametrized surfaces. This issue has concentrated much effort in recent\nyears and led to the development of several numerical frameworks. In this\npaper, we take an alternative approach which bypasses the direct estimation of\nreparametrizations: we relax the geodesic boundary constraint using an\nauxiliary parametrization-blind varifold fidelity metric. This reformulation\nhas several notable benefits. By avoiding altogether the need for\nreparametrizations, it provides the flexibility to deal with simplicial meshes\nof arbitrary topologies and sampling patterns. Moreover, the problem lends\nitself to a coarse-to-fine multi-resolution implementation, which makes the\nalgorithm scalable to large meshes. Furthermore, this approach extends readily\nto higher-order feature maps such as square root curvature fields and is also\nable to include surface textures in the matching problem. We demonstrate these\nadvantages on several examples, synthetic and real.",
          "link": "http://arxiv.org/abs/2006.11652",
          "publishedOn": "2021-06-11T01:42:15.987Z",
          "wordCount": 688,
          "title": "A numerical framework for elastic surface matching, comparison, and interpolation. (arXiv:2006.11652v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Youngtaek Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "The capability of the traditional semi-supervised learning (SSL) methods is\nfar from real-world application since they do not consider (1) class imbalance\nand (2) class distribution mismatch between labeled and unlabeled data. This\npaper addresses such a relatively under-explored problem, imbalanced\nsemi-supervised learning, where heavily biased pseudo-labels can harm the model\nperformance. Interestingly, we find that the semantic pseudo-labels from a\nsimilarity-based classifier in feature space and the traditional pseudo-labels\nfrom the linear classifier show the complementary property. To this end, we\npropose a general pseudo-labeling framework to address the bias motivated by\nthis observation. The key idea is to class-adaptively blend the semantic\npseudo-label to the linear one, depending on the current pseudo-label\ndistribution. Thereby, the increased semantic pseudo-label component suppresses\nthe false positives in the majority classes and vice versa. We term the novel\npseudo-labeling framework for imbalanced SSL as Distribution-Aware\nSemantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT\nand STL10-LT shows that DASO consistently outperforms both recently proposed\nre-balancing methods for label and pseudo-label. Moreover, we demonstrate that\ntypical SSL algorithms can effectively benefit from unlabeled data with DASO,\nespecially when (1) class imbalance and (2) class distribution mismatch exist\nand even on recent real-world Semi-Aves benchmark.",
          "link": "http://arxiv.org/abs/2106.05682",
          "publishedOn": "2021-06-11T01:42:15.906Z",
          "wordCount": 638,
          "title": "Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_K/0/1/0/all/0/1\">Kee Siong Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miaomiao Liu</a>",
          "description": "In this paper, we tackle the problem of unsupervised 3D object segmentation\nfrom a point cloud without RGB information. In particular, we propose a\nframework,~{\\bf SPAIR3D}, to model a point cloud as a spatial mixture model and\njointly learn the multiple-object representation and segmentation in 3D via\nVariational Autoencoders (VAE). Inspired by SPAIR, we adopt an\nobject-specification scheme that describes each object's location relative to\nits local voxel grid cell rather than the point cloud as a whole. To model the\nspatial mixture model on point clouds, we derive the~\\emph{Chamfer Likelihood},\nwhich fits naturally into the variational training pipeline. We further design\na new spatially invariant graph neural network to generate a varying number of\n3D points as a decoder within our VAE.~Experimental results demonstrate\nthat~{\\bf SPAIR3D} is capable of detecting and segmenting variable number of\nobjects without appearance information across diverse scenes.",
          "link": "http://arxiv.org/abs/2106.05607",
          "publishedOn": "2021-06-11T01:42:15.889Z",
          "wordCount": 575,
          "title": "Spatially Invariant Unsupervised 3D Object Segmentation with Graph Neural Networks. (arXiv:2106.05607v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1\">Tianlin Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1\">Beatrice Acciaio</a>",
          "description": "Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.",
          "link": "http://arxiv.org/abs/2106.05658",
          "publishedOn": "2021-06-11T01:42:15.839Z",
          "wordCount": 585,
          "title": "Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">SouYoung Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1\">Andrew Rouditchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliva_A/0/1/0/all/0/1\">Aude Oliva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent advances in representation learning have demonstrated an ability to\nrepresent information from different modalities such as video, text, and audio\nin a single high-level embedding vector. In this work we present a\nself-supervised learning framework that is able to learn a representation that\ncaptures finer levels of granularity across different modalities such as\nconcepts or events represented by visual objects or spoken words. Our framework\nrelies on a discretized embedding space created via vector quantization that is\nshared across different modalities. Beyond the shared embedding space, we\npropose a Cross-Modal Code Matching objective that forces the representations\nfrom different views (modalities) to have a similar distribution over the\ndiscrete embedding space such that cross-modal objects/actions localization can\nbe performed without direct supervision. In our experiments we show that the\nproposed discretized multi-modal fine-grained representation (e.g.,\npixel/word/frame) can complement high-level summary representations (e.g.,\nvideo/sentence/waveform) for improved performance on cross-modal retrieval\ntasks. We also observe that the discretized representation uses individual\nclusters to represent the same semantic concept across modalities.",
          "link": "http://arxiv.org/abs/2106.05438",
          "publishedOn": "2021-06-11T01:42:15.814Z",
          "wordCount": 599,
          "title": "Cross-Modal Discrete Representation Learning. (arXiv:2106.05438v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thandiackal_K/0/1/0/all/0/1\">Kevin Thandiackal</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Portenier_T/0/1/0/all/0/1\">Tiziano Portenier</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Giovannini_A/0/1/0/all/0/1\">Andrea Giovannini</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Gabrani_M/0/1/0/all/0/1\">Maria Gabrani</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Goksel_O/0/1/0/all/0/1\">Orcun Goksel</a> (2 and 3) ((1) IBM Research Europe, (2) ETH Zurich, (3) Uppsala University)",
          "description": "Neural networks are prone to catastrophic forgetting when trained\nincrementally on different tasks. In order to prevent forgetting, most existing\nmethods retain a small subset of previously seen samples, which in turn can be\nused for joint training with new tasks. While this is indeed effective, it may\nnot always be possible to store such samples, e.g., due to data protection\nregulations. In these cases, one can instead employ generative models to create\nartificial samples or features representing memories from previous tasks.\nFollowing a similar direction, we propose GenIFeR (Generative Implicit Feature\nReplay) for class-incremental learning. The main idea is to train a generative\nadversarial network (GAN) to generate images that contain realistic features.\nWhile the generator creates images at full resolution, the discriminator only\nsees the corresponding features extracted by the continually trained\nclassifier. Since the classifier compresses raw images into features that are\nactually relevant for classification, the GAN can match this target\ndistribution more accurately. On the other hand, allowing the generator to\ncreate full resolution images has several benefits: In contrast to previous\napproaches, the feature extractor of the classifier does not have to be frozen.\nIn addition, we can employ augmentations on generated images, which not only\nboosts classification performance, but also mitigates discriminator overfitting\nduring GAN training. We empirically show that GenIFeR is superior to both\nconventional generative image and feature replay. In particular, we\nsignificantly outperform the state-of-the-art in generative replay for various\nsettings on the CIFAR-100 and CUB-200 datasets.",
          "link": "http://arxiv.org/abs/2106.05350",
          "publishedOn": "2021-06-11T01:42:15.684Z",
          "wordCount": 702,
          "title": "Match What Matters: Generative Implicit Feature Replay for Continual Learning. (arXiv:2106.05350v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1906.11667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n\nCode available at this http URL",
          "link": "http://arxiv.org/abs/1906.11667",
          "publishedOn": "2021-06-11T01:42:15.455Z",
          "wordCount": 722,
          "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1\">Piotr Bojanowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1\">Mathilde Caron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1\">Matthieu Cord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1\">Alaaeldin El-Nouby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grave_E/0/1/0/all/0/1\">Edouard Grave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izacard_G/0/1/0/all/0/1\">Gautier Izacard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1\">Jakob Verbeek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegou_H/0/1/0/all/0/1\">Herv&#xe9; J&#xe9;gou</a>",
          "description": "We present ResMLP, an architecture built entirely upon multi-layer\nperceptrons for image classification. It is a simple residual network that\nalternates (i) a linear layer in which image patches interact, independently\nand identically across channels, and (ii) a two-layer feed-forward network in\nwhich channels interact independently per patch. When trained with a modern\ntraining strategy using heavy data-augmentation and optionally distillation, it\nattains surprisingly good accuracy/complexity trade-offs on ImageNet. We also\ntrain ResMLP models in a self-supervised setup, to further remove priors from\nemploying a labelled dataset. Finally, by adapting our model to machine\ntranslation we achieve surprisingly good results.\n\nWe share pre-trained models and our code based on the Timm library.",
          "link": "http://arxiv.org/abs/2105.03404",
          "publishedOn": "2021-06-11T01:42:15.412Z",
          "wordCount": 589,
          "title": "ResMLP: Feedforward networks for image classification with data-efficient training. (arXiv:2105.03404v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1\">Adrian Spurr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1\">Pavlo Molchanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_U/0/1/0/all/0/1\">Umar Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "Hand pose estimation is difficult due to different environmental conditions,\nobject- and self-occlusion as well as diversity in hand shape and appearance.\nExhaustively covering this wide range of factors in fully annotated datasets\nhas remained impractical, posing significant challenges for generalization of\nsupervised methods. Embracing this challenge, we propose to combine ideas from\nadversarial training and motion modelling to tap into unlabeled videos. To this\nend we propose what to the best of our knowledge is the first motion model for\nhands and show that an adversarial formulation leads to better generalization\nproperties of the hand pose estimator via semi-supervised training on unlabeled\nvideo sequences. In this setting, the pose predictor must produce a valid\nsequence of hand poses, as determined by a discriminative adversary. This\nadversary reasons both on the structural as well as temporal domain,\neffectively exploiting the spatio-temporal structure in the task. The main\nadvantage of our approach is that we can make use of unpaired videos and joint\nsequence data both of which are much easier to attain than paired training\ndata. We perform extensive evaluation, investigating essential components\nneeded for the proposed framework and empirically demonstrate in two\nchallenging settings that the proposed approach leads to significant\nimprovements in pose estimation accuracy. In the lowest label setting, we\nattain an improvement of $40\\%$ in absolute mean joint error.",
          "link": "http://arxiv.org/abs/2106.05954",
          "publishedOn": "2021-06-11T01:42:15.406Z",
          "wordCount": 654,
          "title": "Adversarial Motion Modelling helps Semi-supervised Hand Pose Estimation. (arXiv:2106.05954v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Deng-Ping Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "We present the first systematic study on concealed object detection (COD),\nwhich aims to identify objects that are \"perfectly\" embedded in their\nbackground. The high intrinsic similarities between the concealed objects and\ntheir background make COD far more challenging than traditional object\ndetection/segmentation. To better understand this task, we collect a\nlarge-scale dataset, called COD10K, which consists of 10,000 images covering\nconcealed objects in diverse real-world scenarios from 78 object categories.\nFurther, we provide rich annotations including object categories, object\nboundaries, challenging attributes, object-level labels, and instance-level\nannotations. Our COD10K is the largest COD dataset to date, with the richest\nannotations, which enables comprehensive concealed object understanding and can\neven be used to help progress several other vision tasks, such as detection,\nsegmentation, classification, etc. Motivated by how animals hunt in the wild,\nwe also design a simple but strong baseline for COD, termed the Search\nIdentification Network (SINet). Without any bells and whistles, SINet\noutperforms 12 cutting-edge baselines on all datasets tested, making them\nrobust, general architectures that could serve as catalysts for future research\nin COD. Finally, we provide some interesting findings and highlight several\npotential applications and future directions. To spark research in this new\nfield, our code, dataset, and online demo are available on our project page:\nthis http URL",
          "link": "http://arxiv.org/abs/2102.10274",
          "publishedOn": "2021-06-11T01:42:15.401Z",
          "wordCount": 674,
          "title": "Concealed Object Detection. (arXiv:2102.10274v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1\">Shruti Jadon</a>",
          "description": "Image Segmentation has been an active field of research as it has a wide\nrange of applications, ranging from automated disease detection to self-driving\ncars. In recent years, various research papers proposed different loss\nfunctions used in case of biased data, sparse segmentation, and unbalanced\ndataset. In this paper, we introduce SemSegLoss, a python package consisting of\nsome of the well-known loss functions widely used for image segmentation. It is\ndeveloped with the intent to help researchers in the development of novel loss\nfunctions and perform an extensive set of experiments on model architectures\nfor various applications. The ease-of-use and flexibility of the presented\npackage have allowed reducing the development time and increased evaluation\nstrategies of machine learning models for semantic segmentation. Furthermore,\ndifferent applications that use image segmentation can use SemSegLoss because\nof the generality of its functions. This wide range of applications will lead\nto the development and growth of AI across all industries.",
          "link": "http://arxiv.org/abs/2106.05844",
          "publishedOn": "2021-06-11T01:42:15.316Z",
          "wordCount": 605,
          "title": "SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05531",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dhondea_A/0/1/0/all/0/1\">Ashiv Dhondea</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cohen_R/0/1/0/all/0/1\">Robert A. Cohen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1\">Ivan V. Baji&#x107;</a>",
          "description": "In collaborative intelligence, an artificial intelligence (AI) model is\ntypically split between an edge device and the cloud. Feature tensors produced\nby the edge sub-model are sent to the cloud via an imperfect communication\nchannel. At the cloud side, parts of the feature tensor may be missing due to\npacket loss. In this paper we propose a method called Content-Adaptive Linear\nTensor Completion (CALTeC) to recover the missing feature data. The proposed\nmethod is fast, data-adaptive, does not require pre-training, and produces\nbetter results than existing methods for tensor data recovery in collaborative\nintelligence.",
          "link": "http://arxiv.org/abs/2106.05531",
          "publishedOn": "2021-06-11T01:42:15.242Z",
          "wordCount": 544,
          "title": "CALTeC: Content-Adaptive Linear Tensor Completion for Collaborative Intelligence. (arXiv:2106.05531v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Limin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuangping Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1\">Ning Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Ning Gu</a>",
          "description": "The ultrasound (US) screening of the infant hip is vital for the early\ndiagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH\nrefers to measuring alpha and beta angles that quantify hip joint development.\nThese two angles are calculated from key anatomical landmarks and structures of\nthe hip. However, this measurement process is not trivial for sonographers and\nusually requires a thorough understanding of complex anatomical structures. In\nthis study, we propose a multi-task framework to learn the relationships among\nlandmarks and structures jointly and automatically evaluate DDH. Our multi-task\nnetworks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as\nthe basic framework to detect and segment key anatomical structures and add one\nlandmark detection branch to form a new multi-task framework. Secondly, we\npropose a novel shape similarity loss to refine the incomplete anatomical\nstructure prediction robustly and accurately. Thirdly, we further incorporate\nthe landmark-structure consistent prior to ensure the consistency of the bony\nrim estimated from the segmented structure and the detected landmark. In our\nexperiments, 1,231 US images of the infant hip from 632 patients are collected,\nof which 247 images from 126 patients are tested. The average errors in alpha\nand beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%\nestimates of alpha and beta angles have errors less than 5 degrees,\nrespectively. Experimental results demonstrate that the proposed method can\naccurately and robustly realize the automatic evaluation of DDH, showing great\npotential for clinical application.",
          "link": "http://arxiv.org/abs/2106.05458",
          "publishedOn": "2021-06-11T01:42:15.136Z",
          "wordCount": 733,
          "title": "Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Mengyuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Luliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1\">Zihan Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_T/0/1/0/all/0/1\">Tao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaokui Li</a>",
          "description": "Origin-Destination (OD) flow, as an abstract representation of the object`s\nmovement or interaction, has been used to reveal the urban mobility and\nhuman-land interaction pattern. As an important spatial analysis approach, the\nclustering methods of point events have been extended to OD flows to identify\nthe dominant trends and spatial structures of urban mobility. However, the\nexisting methods for OD flow cluster-detecting are limited both in specific\nspatial scale and the uncertain result due to different parameters setting,\nwhich is difficult for complicated OD flows clustering under spatial\nheterogeneity. To address these limitations, in this paper, we proposed a novel\nOD flows cluster-detecting method based on the OPTICS algorithm which can\nidentify OD flow clusters with various aggregation scales. The method can\nadaptively determine parameter value from the dataset without prior knowledge\nand artificial intervention. Experiments indicated that our method outperformed\nthree state-of-the-art methods with more accurate and complete of clusters and\nless noise. As a case study, our method is applied to identify the potential\nroutes for public transport service settings by detecting OD flow clusters\nwithin urban travel data.",
          "link": "http://arxiv.org/abs/2106.05436",
          "publishedOn": "2021-06-11T01:42:15.115Z",
          "wordCount": 623,
          "title": "An adaptive Origin-Destination flows cluster-detecting method to identify urban mobility trends. (arXiv:2106.05436v1 [cs.CG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patrick_M/0/1/0/all/0/1\">Mandela Patrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1\">Dylan Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1\">Yuki M. Asano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metze_I/0/1/0/all/0/1\">Ishan Misra Florian Metze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1\">Andrea Vedaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jo\\&#xe3;o F. Henriques</a>",
          "description": "In video transformers, the time dimension is often treated in the same way as\nthe two spatial dimensions. However, in a scene where objects or the camera may\nmove, a physical point imaged at one location in frame $t$ may be entirely\nunrelated to what is found at that location in frame $t+k$. These temporal\ncorrespondences should be modeled to facilitate learning about dynamic scenes.\nTo this end, we propose a new drop-in block for video transformers --\ntrajectory attention -- that aggregates information along implicitly determined\nmotion paths. We additionally propose a new method to address the quadratic\ndependence of computation and memory on the input size, which is particularly\nimportant for high resolution or long videos. While these ideas are useful in a\nrange of settings, we apply them to the specific task of video action\nrecognition with a transformer model and obtain state-of-the-art results on the\nKinetics, Something--Something V2, and Epic-Kitchens datasets. Code and models\nare available at: https://github.com/facebookresearch/Motionformer",
          "link": "http://arxiv.org/abs/2106.05392",
          "publishedOn": "2021-06-11T01:42:15.110Z",
          "wordCount": 616,
          "title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers. (arXiv:2106.05392v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1\">Miguel Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with the text references.\nThis is different from human language processing, for which visual imaginations\noften improve comprehension. In this work, we propose ImaginE, an\nimagination-based automatic evaluation metric for natural language generation.\nWith the help of CLIP and DALL-E, two cross-modal models pre-trained on\nlarge-scale image-text pairs, we automatically generate an image as the\nembodied imagination for the text snippet and compute the imagination\nsimilarity using contextual embeddings. Experiments spanning several text\ngeneration tasks demonstrate that adding imagination with our ImaginE displays\ngreat potential in introducing multi-modal information into NLG evaluation, and\nimproves existing automatic metrics' correlations with human similarity\njudgments in many circumstances.",
          "link": "http://arxiv.org/abs/2106.05970",
          "publishedOn": "2021-06-11T01:42:15.099Z",
          "wordCount": 564,
          "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lizhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Siyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1\">Ping Tan</a>",
          "description": "Modern deep-learning-based lane detection methods are successful in most\nscenarios but struggling for lane lines with complex topologies. In this work,\nwe propose CondLaneNet, a novel top-to-down lane detection framework that\ndetects the lane instances first and then dynamically predicts the line shape\nfor each instance. Aiming to resolve lane instance-level discrimination\nproblem, we introduce a conditional lane detection strategy based on\nconditional convolution and row-wise formulation. Further, we design the\nRecurrent Instance Module(RIM) to overcome the problem of detecting lane lines\nwith complex topologies such as dense lines and fork lines. Benefit from the\nend-to-end pipeline which requires little post-process, our method has\nreal-time efficiency. We extensively evaluate our method on three benchmarks of\nlane detection. Results show that our method achieves state-of-the-art\nperformance on all three benchmark datasets. Moreover, our method has the\ncoexistence of accuracy and efficiency, e.g. a 78.14 F1 score and 220 FPS on\nCULane. Our code is available at\nhttps://github.com/aliyun/conditional-lane-detection.",
          "link": "http://arxiv.org/abs/2105.05003",
          "publishedOn": "2021-06-11T01:42:15.082Z",
          "wordCount": 620,
          "title": "CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional Convolution. (arXiv:2105.05003v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Vision transformer has demonstrated promising performance on challenging\ncomputer vision tasks. However, directly training the vision transformers may\nyield unstable and sub-optimal results. Recent works propose to improve the\nperformance of the vision transformers by modifying the transformer structures,\ne.g., incorporating convolution layers. In contrast, we investigate an\northogonal approach to stabilize the vision transformer training without\nmodifying the networks. We observe the instability of the training can be\nattributed to the significant similarity across the extracted patch\nrepresentations. More specifically, for deep vision transformers, the\nself-attention blocks tend to map different patches into similar latent\nrepresentations, yielding information loss and performance degradation. To\nalleviate this problem, in this work, we introduce novel loss functions in\nvision transformer training to explicitly encourage diversity across patch\nrepresentations for more discriminative feature extraction. We empirically show\nthat our proposed techniques stabilize the training and allow us to train wider\nand deeper vision transformers. We further show the diversified features\nsignificantly benefit the downstream tasks in transfer learning. For semantic\nsegmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and\nADE20k. Our code will be made publicly available soon.",
          "link": "http://arxiv.org/abs/2104.12753",
          "publishedOn": "2021-06-11T01:42:15.034Z",
          "wordCount": 648,
          "title": "Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the Fetoscopic Placental\nVessel Segmentation and Registration (FetReg) challenge, we present a\nlarge-scale multi-centre dataset for the development of generalized and robust\nsemantic segmentation and video mosaicking algorithms for the fetal environment\nwith a focus on creating drift-free mosaics from long duration fetoscopy\nvideos. In this paper, we provide an overview of the FetReg dataset, challenge\ntasks, evaluation metrics and baseline methods for both segmentation and\nregistration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, which can be modelled and competed for\nthrough our crowd-sourcing initiative of the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-11T01:42:15.029Z",
          "wordCount": 682,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14711",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1\">Ce Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hui_Y/0/1/0/all/0/1\">Yuan Hui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_S/0/1/0/all/0/1\">Shiwei Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_M/0/1/0/all/0/1\">Mengke Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Quan_Q/0/1/0/all/0/1\">Quan Quan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Shuxin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hao_Y/0/1/0/all/0/1\">You Hao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1\">Pengbo Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_H/0/1/0/all/0/1\">Honghu Xiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_C/0/1/0/all/0/1\">Chunpeng Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xinbao Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1\">S. Kevin Zhou</a>",
          "description": "Spine-related diseases have high morbidity and cause a huge burden of social\ncost. Spine imaging is an essential tool for noninvasively visualizing and\nassessing spinal pathology. Segmenting vertebrae in computed tomography (CT)\nimages is the basis of quantitative medical image analysis for clinical\ndiagnosis and surgery planning of spine diseases. Current publicly available\nannotated datasets on spinal vertebrae are small in size. Due to the lack of a\nlarge-scale annotated spine image dataset, the mainstream deep learning-based\nsegmentation methods, which are data-driven, are heavily restricted. In this\npaper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated\nfrom multiple sources for vertebra segmentation, which contains 1,005 CT\nvolumes with over 11,100 labeled vertebrae belonging to different spinal\nconditions. Based on this dataset, we conduct several spinal vertebrae\nsegmentation experiments to set the first benchmark. We believe that this\nlarge-scale dataset will facilitate further research in many spine-related\nimage analysis tasks, including but not limited to vertebrae segmentation,\nlabeling, 3D spine reconstruction from biplanar radiographs, image\nsuper-resolution, and enhancement.",
          "link": "http://arxiv.org/abs/2105.14711",
          "publishedOn": "2021-06-11T01:42:15.013Z",
          "wordCount": 653,
          "title": "CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in Computed Tomography. (arXiv:2105.14711v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinming Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Ke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Junfeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaoming Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>",
          "description": "Recently, lane detection has made great progress with the rapid development\nof deep neural networks and autonomous driving. However, there exist three\nmainly problems including characterizing lanes, modeling the structural\nrelationship between scenes and lanes, and supporting more attributes (e.g.,\ninstance and type) of lanes. In this paper, we propose a novel structure guided\nframework to solve these problems simultaneously. In the framework, we first\nintroduce a new lane representation to characterize each instance. Then a\ntopdown vanishing point guided anchoring mechanism is proposed to produce\nintensive anchors, which efficiently capture various lanes. Next, multi-level\nstructural constraints are used to improve the perception of lanes. In the\nprocess, pixel-level perception with binary segmentation is introduced to\npromote features around anchors and restore lane details from bottom up, a\nlane-level relation is put forward to model structures (i.e., parallel) around\nlanes, and an image-level attention is used to adaptively attend different\nregions of the image from the perspective of scenes. With the help of\nstructural guidance, anchors are effectively classified and regressed to obtain\nprecise locations and shapes. Extensive experiments on public benchmark\ndatasets show that the proposed approach outperforms state-of-the-art methods\nwith 117 FPS on a single GPU.",
          "link": "http://arxiv.org/abs/2105.05403",
          "publishedOn": "2021-06-11T01:42:15.001Z",
          "wordCount": 657,
          "title": "Structure Guided Lane Detection. (arXiv:2105.05403v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>",
          "description": "Convolutional architectures have proven extremely successful for vision\ntasks. Their hard inductive biases enable sample-efficient learning, but come\nat the cost of a potentially lower performance ceiling. Vision Transformers\n(ViTs) rely on more flexible self-attention layers, and have recently\noutperformed CNNs for image classification. However, they require costly\npre-training on large external datasets or distillation from pre-trained\nconvolutional networks. In this paper, we ask the following question: is it\npossible to combine the strengths of these two architectures while avoiding\ntheir respective limitations? To this end, we introduce gated positional\nself-attention (GPSA), a form of positional self-attention which can be\nequipped with a ``soft\" convolutional inductive bias. We initialise the GPSA\nlayers to mimic the locality of convolutional layers, then give each attention\nhead the freedom to escape locality by adjusting a gating parameter regulating\nthe attention paid to position versus content information. The resulting\nconvolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,\nwhile offering a much improved sample efficiency. We further investigate the\nrole of locality in learning by first quantifying how it is encouraged in\nvanilla self-attention layers, then analysing how it is escaped in GPSA layers.\nWe conclude by presenting various ablations to better understand the success of\nthe ConViT. Our code and models are released publicly at\nhttps://github.com/facebookresearch/convit.",
          "link": "http://arxiv.org/abs/2103.10697",
          "publishedOn": "2021-06-11T01:42:14.995Z",
          "wordCount": 691,
          "title": "ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-11T01:42:14.989Z",
          "wordCount": 668,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1\">Ilya Tolstikhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1\">Jessica Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1\">Andreas Steiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>",
          "description": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision.\nRecently, attention-based networks, such as the Vision Transformer, have also\nbecome popular. In this paper we show that while convolutions and attention are\nboth sufficient for good performance, neither of them are necessary. We present\nMLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).\nMLP-Mixer contains two types of layers: one with MLPs applied independently to\nimage patches (i.e. \"mixing\" the per-location features), and one with MLPs\napplied across patches (i.e. \"mixing\" spatial information). When trained on\nlarge datasets, or with modern regularization schemes, MLP-Mixer attains\ncompetitive scores on image classification benchmarks, with pre-training and\ninference cost comparable to state-of-the-art models. We hope that these\nresults spark further research beyond the realms of well established CNNs and\nTransformers.",
          "link": "http://arxiv.org/abs/2105.01601",
          "publishedOn": "2021-06-11T01:42:14.969Z",
          "wordCount": 641,
          "title": "MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_D/0/1/0/all/0/1\">Dazhen Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yihong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1\">Xinhuan Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengye Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Siwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Weiwei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yingcai Wu</a>",
          "description": "Images in visualization publications contain rich information, e.g., novel\nvisualization designs and common combinations of visualizations. A systematic\ncollection of these images can contribute to the community in many aspects,\nsuch as literature analysis and automated tasks for visualization. In this\npaper, we build and make public a dataset, VisImages, which collects 12,267\nimages with captions from 1,397 papers in IEEE InfoVis and VAST. Based on a\nrefined taxonomy for visualizations in publications, the dataset includes\n35,096 annotated visualizations, as well as their positions. We demonstrate the\nusefulness of VisImages through three use cases: 1) exploring and analyzing the\nevolution of visualizations with VisImages Explorer, 2) training and\nbenchmarking models for visualization classification, and 3) localizing and\nrecognizing visualizations in the images automatically.",
          "link": "http://arxiv.org/abs/2007.04584",
          "publishedOn": "2021-06-11T01:42:14.964Z",
          "wordCount": 613,
          "title": "VisImages: a Corpus of Visualizations in the Images of Visualization Publications. (arXiv:2007.04584v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciszewski_M/0/1/0/all/0/1\">Micha&#x142; Ciszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohl_J/0/1/0/all/0/1\">Jakob S&#xf6;hl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jongbloed_G/0/1/0/all/0/1\">Geurt Jongbloed</a>",
          "description": "The past decade has seen an increased interest in human activity recognition.\nMost commonly, the raw data coming from sensors attached to body parts are\nunannotated, which creates a need for fast labelling method. Part of the\nprocedure is choosing or designing an appropriate performance measure. We\npropose a new performance measure, the Locally Time-Shifted Measure, which\naddresses the issue of timing uncertainty of state transitions in the\nclassification result. Our main contribution is a novel post-processing method\nfor binary activity recognition. It improves the accuracy of the classification\nmethods, by correcting for unrealistically short activities in the estimate.",
          "link": "http://arxiv.org/abs/2102.03310",
          "publishedOn": "2021-06-11T01:42:14.958Z",
          "wordCount": 561,
          "title": "Improving state estimation through projection post-processing for activity recognition in football. (arXiv:2102.03310v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.11606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henzler_P/0/1/0/all/0/1\">Philipp Henzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1\">Tobias Ritschel</a>",
          "description": "We introduce PlatonicGAN to discover the 3D structure of an object class from\nan unstructured collection of 2D images, i.e., where no relation between photos\nis known, except that they are showing instances of the same category. The key\nidea is to train a deep neural network to generate 3D shapes which, when\nrendered to images, are indistinguishable from ground truth images (for a\ndiscriminator) under various camera poses. Discriminating 2D images instead of\n3D shapes allows tapping into unstructured 2D photo collections instead of\nrelying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish\nconstraints between 2D image observation and their 3D interpretation, we\nsuggest a family of rendering layers that are effectively differentiable. This\nfamily includes visual hull, absorption-only (akin to x-ray), and\nemission-absorption. We can successfully reconstruct 3D shapes from\nunstructured 2D images and extensively evaluate PlatonicGAN on a range of\nsynthetic and real data sets achieving consistent improvements over baseline\nmethods. We further show that PlatonicGAN can be combined with 3D supervision\nto improve on and in some cases even surpass the quality of 3D-supervised\nmethods.",
          "link": "http://arxiv.org/abs/1811.11606",
          "publishedOn": "2021-06-11T01:42:14.952Z",
          "wordCount": 660,
          "title": "Escaping Plato's Cave: 3D Shape From Adversarial Rendering. (arXiv:1811.11606v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guansong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>",
          "description": "We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.",
          "link": "http://arxiv.org/abs/2009.06847",
          "publishedOn": "2021-06-11T01:42:14.946Z",
          "wordCount": 650,
          "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03931",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1\">Xiaohang Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1\">Lei Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Ashnil Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1\">Michael Fulham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jinman Kim</a>",
          "description": "Accurate characterisation of visual attributes such as spiculation,\nlobulation, and calcification of lung nodules is critical in cancer management.\nThe characterisation of these attributes is often subjective, which may lead to\nhigh inter- and intra-observer variability. Furthermore, lung nodules are often\nheterogeneous in the cross-sectional image slices of a 3D volume. Current\nstate-of-the-art methods that score multiple attributes rely on deep\nlearning-based multi-task learning (MTL) schemes. These methods, however,\nextract shared visual features across attributes and then examine each\nattribute without explicitly leveraging their inherent intercorrelations.\nFurthermore, current methods either treat each slice with equal importance\nwithout considering their relevance or heterogeneity, which limits performance.\nIn this study, we address these challenges with a new convolutional neural\nnetwork (CNN)-based MTL model that incorporates multiple attention-based\nlearning modules to simultaneously score 9 visual attributes of lung nodules in\ncomputed tomography (CT) image volumes. Our model processes entire nodule\nvolumes of arbitrary depth and uses a slice attention module to filter out\nirrelevant slices. We also introduce cross-attribute and attribute\nspecialisation attention modules that learn an optimal amalgamation of\nmeaningful representations to leverage relationships between attributes. We\ndemonstrate that our model outperforms previous state-of-the-art methods at\nscoring attributes using the well-known public LIDC-IDRI dataset of pulmonary\nnodules from over 1,000 patients. Our model also performs competitively when\nrepurposed for benign-malignant classification. Our attention modules also\nprovide easy-to-interpret weights that offer insights into the predictions of\nthe model.",
          "link": "http://arxiv.org/abs/2103.03931",
          "publishedOn": "2021-06-11T01:42:14.928Z",
          "wordCount": 700,
          "title": "Attention-Enhanced Cross-Task Network for Analysing Multiple Attributes of Lung Nodules in CT. (arXiv:2103.03931v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-output (MIMO)\nwireless radar. Here, the strong clutter due to the reflection of the layered\nstructure's surface often makes the detection of the defects challenging. Thus,\nsophisticated signal separation methods are required for improved defect\ndetection. In many scenarios, the number of defects that we are interested in\nis limited and the signaling response of the layered structure can be modeled\nas a low-rank structure. Therefore, we propose joint rank and sparsity\nminimization for defect detection. In particular, we propose a non-convex\napproach based on the iteratively reweighted nuclear and $\\ell_1-$norm (a\ndouble-reweighted approach) to obtain a higher accuracy compared to the\nconventional nuclear norm and $\\ell_1-$norm minimization. To this end, an\niterative algorithm is designed to estimate the low-rank and sparse\ncontributions. Further, we propose deep learning to learn the parameters of the\nalgorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of\nconvergence of the algorithm. Our numerical results show that the proposed\napproach outperforms the conventional approaches in terms of mean square errors\nof the recovered low-rank and sparse components and the speed of convergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-06-11T01:42:14.922Z",
          "wordCount": 656,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1\">Erik Goron Endsjo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "In this paper, we propose a new neural architecture search (NAS) problem of\nSymmetric Positive Definite (SPD) manifold networks, aiming to automate the\ndesign of SPD neural architectures. To address this problem, we first introduce\na geometrically rich and diverse SPD neural architecture search space for an\nefficient SPD cell design. Further, we model our new NAS problem with a\none-shot training process of a single supernet. Based on the supernet modeling,\nwe exploit a differentiable NAS algorithm on our relaxed continuous search\nspace for SPD neural architecture search. Statistical evaluation of our method\non drone, action, and emotion recognition tasks mostly provides better results\nthan the state-of-the-art SPD networks and traditional NAS algorithms.\nEmpirical results show that our algorithm excels in discovering better\nperforming SPD network design and provides models that are more than three\ntimes lighter than searched by the state-of-the-art NAS algorithms.",
          "link": "http://arxiv.org/abs/2010.14535",
          "publishedOn": "2021-06-11T01:42:14.884Z",
          "wordCount": 637,
          "title": "Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Jiwan Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breuel_T/0/1/0/all/0/1\">Thomas Breuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yale Song</a>",
          "description": "Large-scale datasets are the cornerstone of representation learning. Existing\nself-supervised approaches extract learning signals by making certain\nassumptions about the data, e.g., spatio-temporal continuity and multimodal\ncorrespondence. However, finding large amounts of data that satisfy such\nassumptions is not straightforward, and this restricts the community to rely on\ndatasets collected through laborious annotation and/or manual filtering\nprocesses. In this paper, we propose a subset optimization approach for\nautomatic dataset curation. Focusing on audio-visual representation learning,\nwe find a subset that provides the maximum mutual information between audio and\nvisual channels in videos. We show that self-supervised models trained on our\ndata, despite being automatically constructed, achieve competitive downstream\nperformances compared to existing datasets that require annotation and/or\nmanual filtering. The most significant benefit of our approach is scalability.\nWe release a dataset of 100M videos with high audio-visual correspondence.",
          "link": "http://arxiv.org/abs/2101.10803",
          "publishedOn": "2021-06-11T01:42:14.874Z",
          "wordCount": 607,
          "title": "Automatic Curation of Large-Scale Datasets for Audio-Visual Representation Learning. (arXiv:2101.10803v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>",
          "description": "Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.",
          "link": "http://arxiv.org/abs/2009.08435",
          "publishedOn": "2021-06-11T01:42:14.868Z",
          "wordCount": 683,
          "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.09671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "We review the current literature concerned with information plane analyses of\nneural network classifiers. While the underlying information bottleneck theory\nand the claim that information-theoretic compression is causally linked to\ngeneralization are plausible, empirical evidence was found to be both\nsupporting and conflicting. We review this evidence together with a detailed\nanalysis of how the respective information quantities were estimated. Our\nsurvey suggests that compression visualized in information planes is not\nnecessarily information-theoretic, but is rather often compatible with\ngeometric compression of the latent representations. This insight gives the\ninformation plane a renewed justification.\n\nAside from this, we shed light on the problem of estimating mutual\ninformation in deterministic neural networks and its consequences.\nSpecifically, we argue that even in feed-forward neural networks the data\nprocessing inequality need not hold for estimates of mutual information.\nSimilarly, while a fitting phase, in which the mutual information between the\nlatent representation and the target increases, is necessary (but not\nsufficient) for good classification performance, depending on the specifics of\nmutual information estimation such a fitting phase need not be visible in the\ninformation plane.",
          "link": "http://arxiv.org/abs/2003.09671",
          "publishedOn": "2021-06-11T01:42:14.852Z",
          "wordCount": 682,
          "title": "On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi-Si Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xi-Le Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tai-Xiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu-Bang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>",
          "description": "Recently, convolutional neural network (CNN)-based methods are proposed for\nhyperspectral images (HSIs) denoising. Among them, unsupervised methods such as\nthe deep image prior (DIP) have received much attention because these methods\ndo not require any training data. However, DIP suffers from the\nsemi-convergence behavior, i.e., the iteration of DIP needs to terminate by\nreferring to the ground-truth image at the optimal iteration point. In this\npaper, we propose the spatial-spectral constrained deep image prior (S2DIP) for\nHSI mixed noise removal. Specifically, we incorporate DIP with a\nspatial-spectral total variation (SSTV) term to fully preserve the\nspatial-spectral local smoothness of the HSI and an $\\ell_1$-norm term to\ncapture the complex sparse noise. The proposed S2DIP jointly leverages the\nexpressive power brought from the deep CNN without any training data and\nexploits the HSI and noise structures via hand-crafted priors. Thus, our method\navoids the semi-convergence behavior, showing higher stabilities than DIP.\nMeanwhile, our method largely enhances the HSI denoising ability of DIP. To\ntackle the proposed denoising model, we develop an alternating direction\nmultiplier method algorithm. Extensive experiments demonstrate that the\nproposed S2DIP outperforms optimization-based and supervised CNN-based\nstate-of-the-art HSI denoising methods.",
          "link": "http://arxiv.org/abs/2008.09753",
          "publishedOn": "2021-06-11T01:42:14.839Z",
          "wordCount": 657,
          "title": "Unsupervised Hyperspectral Mixed Noise Removal Via Spatial-Spectral Constrained Deep Image Prior. (arXiv:2008.09753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Representational learning forms the backbone of most deep learning\napplications, and the value of a learned representation is intimately tied to\nits information content regarding different factors of variation. Finding good\nrepresentations depends on the nature of supervision and the learning\nalgorithm. We propose a novel algorithm that relies on a weak form of\nsupervision where the data is partitioned into sets according to certain\ninactive factors of variation. Our key insight is that by seeking approximate\ncorrespondence between elements of different sets, we learn strong\nrepresentations that exclude the inactive factors of variation and isolate the\nactive factors which vary within all sets. We demonstrate that the method can\nwork in a semi-supervised scenario, and that a portion of the unsupervised data\ncan belong to a different domain entirely. Further control over the content of\nthe learned representations is possible by folding in data augmentation to\nsuppress nuisance factors. We outperform competing baselines on the challenging\nproblem of synthetic-to-real object pose transfer.",
          "link": "http://arxiv.org/abs/2103.03240",
          "publishedOn": "2021-06-11T01:42:14.833Z",
          "wordCount": 628,
          "title": "Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Litao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "Generating natural sentences from images is a fundamental learning task for\nvisual-semantic understanding in multimedia. In this paper, we propose to apply\ndual attention on pyramid image feature maps to fully explore the\nvisual-semantic correlations and improve the quality of generated sentences.\nSpecifically, with the full consideration of the contextual information\nprovided by the hidden state of the RNN controller, the pyramid attention can\nbetter localize the visually indicative and semantically consistent regions in\nimages. On the other hand, the contextual information can help re-calibrate the\nimportance of feature components by learning the channel-wise dependencies, to\nimprove the discriminative power of visual features for better content\ndescription. We conducted comprehensive experiments on three well-known\ndatasets: Flickr8K, Flickr30K and MS COCO, which achieved impressive results in\ngenerating descriptive and smooth natural sentences from images. Using either\nconvolution visual features or more informative bottom-up attention features,\nour composite captioning model achieves very promising performance in a\nsingle-model mode. The proposed pyramid attention and dual attention methods\nare highly modular, which can be inserted into various image captioning modules\nto further improve the performance.",
          "link": "http://arxiv.org/abs/2011.01385",
          "publishedOn": "2021-06-11T01:42:14.826Z",
          "wordCount": 648,
          "title": "Dual Attention on Pyramid Feature Maps for Image Captioning. (arXiv:2011.01385v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1\">S&#xf6;ren Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiegand_T/0/1/0/all/0/1\">Thomas Wiegand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosse_S/0/1/0/all/0/1\">Sebastian Bosse</a>",
          "description": "The performance of visual quality prediction models is commonly assumed to be\nclosely tied to their ability to capture perceptually relevant image aspects.\nModels are thus either based on sophisticated feature extractors carefully\ndesigned from extensive domain knowledge or optimized through feature learning.\nIn contrast to this, we find feature extractors constructed from random noise\nto be sufficient to learn a linear regression model whose quality predictions\nreach high correlations with human visual quality ratings, on par with a model\nwith learned features. We analyze this curious result and show that besides the\nquality of feature extractors also their quantity plays a crucial role - with\ntop performances only being achieved in highly overparameterized models.",
          "link": "http://arxiv.org/abs/2106.05946",
          "publishedOn": "2021-06-11T01:42:14.820Z",
          "wordCount": 548,
          "title": "Curiously Effective Features for Image Quality Prediction. (arXiv:2106.05946v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamal_U/0/1/0/all/0/1\">Uday Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zunaed_M/0/1/0/all/0/1\">Mohammad Zunaed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nizam_N/0/1/0/all/0/1\">Nusrat Binta Nizam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1\">Taufiq Hasan</a>",
          "description": "Thoracic disease detection from chest radiographs using deep learning methods\nhas been an active area of research in the last decade. Most previous methods\nattempt to focus on the diseased organs of the image by identifying spatial\nregions responsible for significant contributions to the model's prediction. In\ncontrast, expert radiologists first locate the prominent anatomical structures\nbefore determining if those regions are anomalous. Therefore, integrating\nanatomical knowledge within deep learning models could bring substantial\nimprovement in automatic disease classification. This work proposes an\nanatomy-aware attention-based architecture named Anatomy X-Net, that\nprioritizes the spatial features guided by the pre-identified anatomy regions.\nWe leverage a semi-supervised learning method using the JSRT dataset containing\norgan-level annotation to obtain the anatomical segmentation masks (for lungs\nand heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses\nthe pre-trained DenseNet-121 as the backbone network with two corresponding\nstructured modules, the Anatomy Aware Attention (AAA) and Probabilistic\nWeighted Average Pooling (PWAP), in a cohesive framework for anatomical\nattention learning. Our proposed method sets new state-of-the-art performance\non the official NIH test set with an AUC score of 0.8439, proving the efficacy\nof utilizing the anatomy segmentation knowledge to improve the thoracic disease\nclassification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020\non the Stanford CheXpert dataset, improving on existing methods that\ndemonstrate the generalizability of the proposed framework.",
          "link": "http://arxiv.org/abs/2106.05915",
          "publishedOn": "2021-06-11T01:42:14.802Z",
          "wordCount": 670,
          "title": "Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jeong-Kyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baik_Y/0/1/0/all/0/1\">Young-Ki Baik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hankyu Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kang Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Duck Hoon Kim</a>",
          "description": "Solving Perspective-n-Point (PnP) problems is a traditional way of estimating\nobject poses. Given outlier-contaminated data, a pose of an object is\ncalculated with PnP algorithms of n = {3, 4} in the RANSAC-based scheme.\nHowever, the computational complexity considerably increases along with n and\nthe high complexity imposes a severe strain on devices which should estimate\nmultiple object poses in real time. In this paper, we propose an efficient\nmethod based on 1-point RANSAC for estimating a pose of an object on the\nground. In the proposed method, a pose is calculated with 1-DoF\nparameterization by using a ground object assumption and a 2D object bounding\nbox as an additional observation, thereby achieving the fastest performance\namong the RANSAC-based methods. In addition, since the method suffers from the\nerrors of the additional information, we propose a hierarchical robust\nestimation method for polishing a rough pose estimate and discovering more\ninliers in a coarse-to-fine manner. The experiments in synthetic and real-world\ndatasets demonstrate the superiority of the proposed method.",
          "link": "http://arxiv.org/abs/2008.03718",
          "publishedOn": "2021-06-11T01:42:14.795Z",
          "wordCount": 645,
          "title": "1-Point RANSAC-Based Method for Ground Object Pose Estimation. (arXiv:2008.03718v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Massiceti_D/0/1/0/all/0/1\">Daniela Massiceti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1\">Luisa Zintgraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronskill_J/0/1/0/all/0/1\">John Bronskill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_L/0/1/0/all/0/1\">Lida Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harris_M/0/1/0/all/0/1\">Matthew Tobias Harris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutrell_E/0/1/0/all/0/1\">Edward Cutrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1\">Cecily Morrison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stumpf_S/0/1/0/all/0/1\">Simone Stumpf</a>",
          "description": "Object recognition has made great advances in the last decade, but\npredominately still relies on many high-quality training examples per object\ncategory. In contrast, learning new objects from only a few examples could\nenable many impactful applications from robotics to user personalization. Most\nfew-shot learning research, however, has been driven by benchmark datasets that\nlack the high variation that these applications will face when deployed in the\nreal-world. To close this gap, we present the ORBIT dataset and benchmark,\ngrounded in a real-world application of teachable object recognizers for people\nwho are blind/low-vision. The dataset contains 3,822 videos of 486 objects\nrecorded by people who are blind/low-vision on their mobile phones, and the\nbenchmark reflects a realistic, highly challenging recognition problem,\nproviding a rich playground to drive research in robustness to few-shot,\nhigh-variation conditions. We set the first state-of-the-art on the benchmark\nand show that there is massive scope for further innovation, holding the\npotential to impact a broad range of real-world vision applications including\ntools for the blind/low-vision community. The dataset is available at\nhttps://bit.ly/2OyElCj and the code to run the benchmark at\nhttps://bit.ly/39YgiUW.",
          "link": "http://arxiv.org/abs/2104.03841",
          "publishedOn": "2021-06-11T01:42:14.788Z",
          "wordCount": 673,
          "title": "ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition. (arXiv:2104.03841v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.06401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sahil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Naman Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Arjun Jain</a>",
          "description": "This paper provides a comprehensive and exhaustive study of adversarial\nattacks on human pose estimation models and the evaluation of their robustness.\nBesides highlighting the important differences between well-studied\nclassification and human pose-estimation systems w.r.t. adversarial attacks, we\nalso provide deep insights into the design choices of pose-estimation systems\nto shape future work. We benchmark the robustness of several 2D single person\npose-estimation architectures trained on multiple datasets, MPII and COCO. In\ndoing so, we also explore the problem of attacking non-classification networks\nincluding regression based networks, which has been virtually unexplored in the\npast.\n\n\\par We find that compared to classification and semantic segmentation, human\npose estimation architectures are relatively robust to adversarial attacks with\nthe single-step attacks being surprisingly ineffective. Our study shows that\nthe heatmap-based pose-estimation models are notably robust than their direct\nregression-based systems and that the systems which explicitly model\nanthropomorphic semantics of human body fare better than their other\ncounterparts. Besides, targeted attacks are more difficult to obtain than\nun-targeted ones and some body-joints are easier to fool than the others. We\npresent visualizations of universal perturbations to facilitate unprecedented\ninsights into their workings on pose-estimation. Additionally, we show them to\ngeneralize well across different networks. Finally we perform a user study\nabout perceptibility of these examples.",
          "link": "http://arxiv.org/abs/1908.06401",
          "publishedOn": "2021-06-11T01:42:14.782Z",
          "wordCount": 672,
          "title": "On the Robustness of Human Pose Estimation. (arXiv:1908.06401v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jimuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1\">Eshed Ohn-Bar</a>",
          "description": "When in a new situation or geographical location, human drivers have an\nextraordinary ability to watch others and learn maneuvers that they themselves\nmay have never performed. In contrast, existing techniques for learning to\ndrive preclude such a possibility as they assume direct access to an\ninstrumented ego-vehicle with fully known observations and expert driver\nactions. However, such measurements cannot be directly accessed for the non-ego\nvehicles when learning by watching others. Therefore, in an application where\ndata is regarded as a highly valuable asset, current approaches completely\ndiscard the vast portion of the training data that can be potentially obtained\nthrough indirect observation of surrounding vehicles. Motivated by this key\ninsight, we propose the Learning by Watching (LbW) framework which enables\nlearning a driving policy without requiring full knowledge of neither the state\nnor expert actions. To increase its data, i.e., with new perspectives and\nmaneuvers, LbW makes use of the demonstrations of other vehicles in a given\nscene by (1) transforming the ego-vehicle's observations to their points of\nview, and (2) inferring their expert actions. Our LbW agent learns more robust\ndriving policies while enabling data-efficient learning, including quick\nadaptation of the policy to rare and novel scenarios. In particular, LbW drives\nrobustly even with a fraction of available driving data required by existing\nmethods, achieving an average success rate of 92% on the original CARLA\nbenchmark with only 30 minutes of total driving data and 82% with only 10\nminutes.",
          "link": "http://arxiv.org/abs/2106.05966",
          "publishedOn": "2021-06-11T01:42:14.772Z",
          "wordCount": 673,
          "title": "Learning by Watching. (arXiv:2106.05966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuanzhi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lianwen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Dezhi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mengchao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongpan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Canjie Luo</a>",
          "description": "Text recognition is a popular research subject with many associated\nchallenges. Despite the considerable progress made in recent years, the text\nrecognition task itself is still constrained to solve the problem of reading\ncropped line text images and serves as a subtask of optical character\nrecognition (OCR) systems. As a result, the final text recognition result is\nlimited by the performance of the text detector. In this paper, we propose a\nsimple, elegant and effective paradigm called Implicit Feature Alignment (IFA),\nwhich can be easily integrated into current text recognizers, resulting in a\nnovel inference mechanism called IFAinference. This enables an ordinary text\nrecognizer to process multi-line text such that text detection can be\ncompletely freed. Specifically, we integrate IFA into the two most prevailing\ntext recognition streams (attention-based and CTC-based) and propose\nattention-guided dense prediction (ADP) and Extended CTC (ExCTC). Furthermore,\nthe Wasserstein-based Hollow Aggregation Cross-Entropy (WH-ACE) is proposed to\nsuppress negative predictions to assist in training ADP and ExCTC. We\nexperimentally demonstrate that IFA achieves state-of-the-art performance on\nend-to-end document recognition tasks while maintaining the fastest speed, and\nADP and ExCTC complement each other on the perspective of different application\nscenarios. Code will be available at\nhttps://github.com/WangTianwei/Implicit-feature-alignment.",
          "link": "http://arxiv.org/abs/2106.05920",
          "publishedOn": "2021-06-11T01:42:14.755Z",
          "wordCount": 650,
          "title": "Implicit Feature Alignment: Learn to Convert Text Recognizer to Text Spotter. (arXiv:2106.05920v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1\">Adrian Bulat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1\">Juan-Manuel Perez-Rua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Swathikiran Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>",
          "description": "This paper is on video recognition using Transformers. Very recent attempts\nin this area have demonstrated promising results in terms of recognition\naccuracy, yet they have been also shown to induce, in many cases, significant\ncomputational overheads due to the additional modelling of the temporal\ninformation. In this work, we propose a Video Transformer model the complexity\nof which scales linearly with the number of frames in the video sequence and\nhence induces \\textit{no overhead} compared to an image-based Transformer\nmodel. To achieve this, our model makes two approximations to the full\nspace-time attention used in Video Transformers: (a) It restricts time\nattention to a local temporal window and capitalizes on the Transformer's depth\nto obtain full temporal coverage of the video sequence. (b) It uses efficient\nspace-time mixing to attend \\textit{jointly} spatial and temporal locations\nwithout inducing any additional cost on top of a spatial-only attention model.\nWe also show how to integrate 2 very lightweight mechanisms for global\ntemporal-only attention which provide additional accuracy improvements at\nminimal computational cost. We demonstrate that our model produces very high\nrecognition accuracy on the most popular video recognition datasets while at\nthe same time being significantly more efficient than other Video Transformer\nmodels. Code will be made available.",
          "link": "http://arxiv.org/abs/2106.05968",
          "publishedOn": "2021-06-11T01:42:14.746Z",
          "wordCount": 643,
          "title": "Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hezheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xing Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qing Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Wei Yuan</a>",
          "description": "Since Transformer has found widespread use in NLP, the potential of\nTransformer in CV has been realized and has inspired many new approaches.\nHowever, the computation required for replacing word tokens with image patches\nfor Transformer after the tokenization of the image is vast(e.g., ViT), which\nbottlenecks model training and inference. In this paper, we propose a new\nattention mechanism in Transformer termed Cross Attention, which alternates\nattention inner the image patch instead of the whole image to capture local\ninformation and apply attention between image patches which are divided from\nsingle-channel feature maps capture global information. Both operations have\nless computation than standard self-attention in Transformer. By alternately\napplying attention inner patch and between patches, we implement cross\nattention to maintain the performance with lower computational cost and build a\nhierarchical network called Cross Attention Transformer(CAT) for other vision\ntasks. Our base model achieves state-of-the-arts on ImageNet-1K, and improves\nthe performance of other methods on COCO and ADE20K, illustrating that our\nnetwork has the potential to serve as general backbones. The code and models\nare available at \\url{https://github.com/linhezheng19/CAT}.",
          "link": "http://arxiv.org/abs/2106.05786",
          "publishedOn": "2021-06-11T01:42:14.740Z",
          "wordCount": 624,
          "title": "CAT: Cross Attention in Vision Transformer. (arXiv:2106.05786v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weijian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Understanding classifier decision under novel environments is central to the\ncommunity, and a common practice is evaluating it on labeled test sets.\nHowever, in real-world testing, image annotations are difficult and expensive\nto obtain, especially when the test environment is changing. A natural question\nthen arises: given a trained classifier, can we evaluate its accuracy on\nvarying unlabeled test sets? In this work, we train semantic classification and\nrotation prediction in a multi-task way. On a series of datasets, we report an\ninteresting finding, i.e., the semantic classification accuracy exhibits a\nstrong linear relationship with the accuracy of the rotation prediction task\n(Pearson's Correlation r > 0.88). This finding allows us to utilize linear\nregression to estimate classifier performance from the accuracy of rotation\nprediction which can be obtained on the test set through the freely generated\nrotation labels.",
          "link": "http://arxiv.org/abs/2106.05961",
          "publishedOn": "2021-06-11T01:42:14.734Z",
          "wordCount": 586,
          "title": "What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>",
          "description": "Inspired by BatchNorm, there has been an explosion of normalization layers in\ndeep learning. Recent works have identified a multitude of beneficial\nproperties in BatchNorm to explain its success. However, given the pursuit of\nalternative normalization techniques, these properties need to be generalized\nso that any given layer's success/failure can be accurately predicted. In this\nwork, we take a first step towards this goal by extending known properties of\nBatchNorm in randomly initialized deep neural networks (DNNs) to nine recently\nproposed normalization layers. Our primary findings follow: (i) Similar to\nBatchNorm, activations-based normalization layers can avoid exploding\nactivations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at\nleast $\\Omega(\\sqrt{\\frac{\\text{width}}{\\text{Group Size}}})$, thus explaining\nwhy LayerNorm witnesses slow optimization speed; (iii) Small group sizes result\nin large gradient norm in earlier layers, hence justifying training instability\nissues in Instance Normalization and illustrating a speed-stability tradeoff in\nGroupNorm. Overall, our analysis reveals several general mechanisms that\nexplain the success of normalization techniques in deep learning, providing us\nwith a compass to systematically explore the vast design space of DNN\nnormalization layers.",
          "link": "http://arxiv.org/abs/2106.05956",
          "publishedOn": "2021-06-11T01:42:14.728Z",
          "wordCount": 619,
          "title": "Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zamora_Cardenas_W/0/1/0/all/0/1\">Willard Zamora-Cardenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_M/0/1/0/all/0/1\">Mauro Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calderon_Ramirez_S/0/1/0/all/0/1\">Saul Calderon-Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_M/0/1/0/all/0/1\">Martin Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monge_G/0/1/0/all/0/1\">Gerardo Monge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quiros_S/0/1/0/all/0/1\">Steve Quiros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1\">David Elizondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1\">David Elizondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_Cabello_M/0/1/0/all/0/1\">Miguel A. Molina-Cabello</a>",
          "description": "Cell instance segmentation in fluorescence microscopy images is becoming\nessential for cancer dynamics and prognosis. Data extracted from cancer\ndynamics allows to understand and accurately model different metabolic\nprocesses such as proliferation. This enables customized and more precise\ncancer treatments. However, accurate cell instance segmentation, necessary for\nfurther cell tracking and behavior analysis, is still challenging in scenarios\nwith high cell concentration and overlapping edges. Within this framework, we\npropose a novel cell instance segmentation approach based on the well-known\nU-Net architecture. To enforce the learning of morphological information per\npixel, a deep distance transformer (DDT) acts as a back-bone model. The DDT\noutput is subsequently used to train a top-model. The following top-models are\nconsidered: a three-class (\\emph{e.g.,} foreground, background and cell border)\nU-net, and a watershed transform. The obtained results suggest a performance\nboost over traditional U-Net architectures. This opens an interesting research\nline around the idea of injecting morphological information into a fully\nconvolutional model.",
          "link": "http://arxiv.org/abs/2106.05843",
          "publishedOn": "2021-06-11T01:42:14.711Z",
          "wordCount": 629,
          "title": "Enforcing Morphological Information in Fully Convolutional Networks to Improve Cell Instance Segmentation in Fluorescence Microscopy Images. (arXiv:2106.05843v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1\">Wouter Van Gansbeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1\">Simon Vandenhende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1\">Stamatios Georgoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Contrastive self-supervised learning has outperformed supervised pretraining\non many downstream tasks like segmentation and object detection. However,\ncurrent methods are still primarily applied to curated datasets like ImageNet.\nIn this paper, we first study how biases in the dataset affect existing\nmethods. Our results show that current contrastive approaches work surprisingly\nwell across: (i) object- versus scene-centric, (ii) uniform versus long-tailed\nand (iii) general versus domain-specific datasets. Second, given the generality\nof the approach, we try to realize further gains with minor modifications. We\nshow that learning additional invariances -- through the use of multi-scale\ncropping, stronger augmentations and nearest neighbors -- improves the\nrepresentations. Finally, we observe that MoCo learns spatially structured\nrepresentations when trained with a multi-crop strategy. The representations\ncan be used for semantic segment retrieval and video instance segmentation\nwithout finetuning. Moreover, the results are on par with specialized models.\nWe hope this work will serve as a useful study for other researchers. The code\nand models will be available at\nhttps://github.com/wvangansbeke/Revisiting-Contrastive-SSL.",
          "link": "http://arxiv.org/abs/2106.05967",
          "publishedOn": "2021-06-11T01:42:14.705Z",
          "wordCount": 617,
          "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:14.696Z",
          "wordCount": 659,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roich_D/0/1/0/all/0/1\">Daniel Roich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mokady_R/0/1/0/all/0/1\">Ron Mokady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>",
          "description": "Recently, a surge of advanced facial editing techniques have been proposed\nthat leverage the generative power of a pre-trained StyleGAN. To successfully\nedit an image this way, one must first project (or invert) the image into the\npre-trained generator's domain. As it turns out, however, StyleGAN's latent\nspace induces an inherent tradeoff between distortion and editability, i.e.\nbetween maintaining the original appearance and convincingly altering some of\nits attributes. Practically, this means it is still challenging to apply\nID-preserving facial latent-space editing to faces which are out of the\ngenerator's domain. In this paper, we present an approach to bridge this gap.\nOur technique slightly alters the generator, so that an out-of-domain image is\nfaithfully mapped into an in-domain latent code. The key idea is pivotal tuning\n- a brief training process that preserves the editing quality of an in-domain\nlatent region, while changing its portrayed identity and appearance. In Pivotal\nTuning Inversion (PTI), an initial inverted latent code serves as a pivot,\naround which the generator is fined-tuned. At the same time, a regularization\nterm keeps nearby identities intact, to locally contain the effect. This\nsurgical training process ends up altering appearance features that represent\nmostly identity, without affecting editing capabilities. We validate our\ntechnique through inversion and editing metrics, and show preferable scores to\nstate-of-the-art methods. We further qualitatively demonstrate our technique by\napplying advanced edits (such as pose, age, or expression) to numerous images\nof well-known and recognizable identities. Finally, we demonstrate resilience\nto harder cases, including heavy make-up, elaborate hairstyles and/or headwear,\nwhich otherwise could not have been successfully inverted and edited by\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.05744",
          "publishedOn": "2021-06-11T01:42:14.690Z",
          "wordCount": 699,
          "title": "Pivotal Tuning for Latent-based Editing of Real Images. (arXiv:2106.05744v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_R/0/1/0/all/0/1\">Rashmi Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Greg Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_S/0/1/0/all/0/1\">Samuel Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Hotel recognition is an important task for human trafficking investigations\nsince victims are often photographed in hotel rooms. Identifying these hotels\nis vital to trafficking investigations since they can help track down current\nand future victims who might be taken to the same places. Hotel recognition is\na challenging fine grained visual classification task as there can be little\nsimilarity between different rooms within the same hotel, and high similarity\nbetween rooms from different hotels (especially if they are from the same\nchain). Hotel recognition to combat human trafficking poses additional\nchallenges as investigative images are often low quality, contain uncommon\ncamera angles and are highly occluded. Here, we present the 2021 Hotel-ID\ndataset to help raise awareness for this problem and generate novel approaches.\nThe dataset consists of hotel room images that have been crowd-sourced and\nuploaded through the TraffickCam mobile application. The quality of these\nimages is similar to investigative images and hence models trained on these\nimages have good chances of accurately narrowing down on the correct hotel.",
          "link": "http://arxiv.org/abs/2106.05746",
          "publishedOn": "2021-06-11T01:42:14.670Z",
          "wordCount": 612,
          "title": "The 2021 Hotel-ID to Combat Human Trafficking Competition Dataset. (arXiv:2106.05746v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1\">Michela Antonelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1\">Annika Reinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1\">Keyvan Farahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1\">AnnetteKopp-Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1\">Geert Litjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1\">Bjoern Menze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1\">Olaf Ronneberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1\">Ronald M.Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1\">Michel Bilello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1\">Patrick Bilic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1\">Patrick F. Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1\">Richard K. G. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1\">Marc J. Gollub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1\">Stephan H. Heckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1\">William R. Jarnagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1\">Maureen K. McHugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1\">Sandy Napel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1\">Jennifer S. Goli Pernicka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1\">Kawal Rhode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1\">Catalina Tobon-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1\">James A. Meakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1\">Sebastien Ourselin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbelaez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1\">Byeonguk Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1\">Laura Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jianjiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Baochun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuanfeng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Fucang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1\">Dorit Merhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Akshay Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Beomhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1\">Mathias Perslev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1\">Ramin Rezaiifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1\">Oliver Rippel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1\">Ignacio Sarasua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jaemin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1\">Christian Wachinger</a>, et al. (9 additional authors not shown)",
          "description": "International challenges have become the de facto standard for comparative\nassessment of image analysis algorithms given a specific task. Segmentation is\nso far the most widely investigated medical image processing task, but the\nvarious segmentation challenges have typically been organized in isolation,\nsuch that algorithm development was driven by the need to tackle a single\nspecific clinical problem. We hypothesized that a method capable of performing\nwell on multiple tasks will generalize well to a previously unseen task and\npotentially outperform a custom-designed solution. To investigate the\nhypothesis, we organized the Medical Segmentation Decathlon (MSD) - a\nbiomedical image analysis challenge, in which algorithms compete in a multitude\nof both tasks and modalities. The underlying data set was designed to explore\nthe axis of difficulties typically encountered when dealing with medical\nimages, such as small data sets, unbalanced labels, multi-site data and small\nobjects. The MSD challenge confirmed that algorithms with a consistent good\nperformance on a set of tasks preserved their good average performance on a\ndifferent set of previously unseen tasks. Moreover, by monitoring the MSD\nwinner for two years, we found that this algorithm continued generalizing well\nto a wide range of other clinical problems, further confirming our hypothesis.\nThree main conclusions can be drawn from this study: (1) state-of-the-art image\nsegmentation algorithms are mature, accurate, and generalize well when\nretrained on unseen tasks; (2) consistent algorithmic performance across\nmultiple tasks is a strong surrogate of algorithmic generalizability; (3) the\ntraining of accurate AI segmentation models is now commoditized to non AI\nexperts.",
          "link": "http://arxiv.org/abs/2106.05735",
          "publishedOn": "2021-06-11T01:42:14.655Z",
          "wordCount": 811,
          "title": "The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_R/0/1/0/all/0/1\">Rahul Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmali_T/0/1/0/all/0/1\">Tejan Karmali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Sarthak Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Aurobrata Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeni_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; A. Jeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1\">R. Venkatesh Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Maneesh Singh</a>",
          "description": "Deep neural representations of 3D shapes as implicit functions have been\nshown to produce high fidelity models surpassing the resolution-memory\ntrade-off faced by the explicit representations using meshes and point clouds.\nHowever, most such approaches focus on representing closed shapes. Unsigned\ndistance function (UDF) based approaches have been proposed recently as a\npromising alternative to represent both open and closed shapes. However, since\nthe gradients of UDFs vanish on the surface, it is challenging to estimate\nlocal (differential) geometric properties like the normals and tangent planes\nwhich are needed for many downstream applications in vision and graphics. There\nare additional challenges in computing these properties efficiently with a\nlow-memory footprint. This paper presents a novel approach that models such\nsurfaces using a new class of implicit representations called the closest\nsurface-point (CSP) representation. We show that CSP allows us to represent\ncomplex surfaces of any topology (open or closed) with high fidelity. It also\nallows for accurate and efficient computation of local geometric properties. We\nfurther demonstrate that it leads to efficient implementation of downstream\nalgorithms like sphere-tracing for rendering the 3D surface as well as to\ncreate explicit mesh-based representations. Extensive experimental evaluation\non the ShapeNet dataset validate the above contributions with results\nsurpassing the state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.05779",
          "publishedOn": "2021-06-11T01:42:14.647Z",
          "wordCount": 653,
          "title": "Deep Implicit Surface Point Prediction Networks. (arXiv:2106.05779v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qingzhe Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Libin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>",
          "description": "Co-part segmentation is an important problem in computer vision for its rich\napplications. We propose an unsupervised learning approach for co-part\nsegmentation from images. For the training stage, we leverage motion\ninformation embedded in videos and explicitly extract latent representations to\nsegment meaningful object parts. More importantly, we introduce a dual\nprocedure of part-assembly to form a closed loop with part-segmentation,\nenabling an effective self-supervision. We demonstrate the effectiveness of our\napproach with a host of extensive experiments, ranging from human bodies,\nhands, quadruped, and robot arms. We show that our approach can achieve\nmeaningful and compact part segmentation, outperforming state-of-the-art\napproaches on diverse benchmarks.",
          "link": "http://arxiv.org/abs/2106.05897",
          "publishedOn": "2021-06-11T01:42:14.627Z",
          "wordCount": 529,
          "title": "Unsupervised Co-part Segmentation through Assembly. (arXiv:2106.05897v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Anurag Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1\">Harish YVS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>",
          "description": "Executing computer vision models on streaming visual data, or streaming\nperception is an emerging problem, with applications in self-driving, embodied\nagents, and augmented/virtual reality. The development of such systems is\nlargely governed by the accuracy and latency of the processing pipeline. While\npast work has proposed numerous approximate execution frameworks, their\ndecision functions solely focus on optimizing latency, accuracy, or energy,\netc. This results in sub-optimum decisions, affecting the overall system\nperformance. We argue that the streaming perception systems should holistically\nmaximize the overall system performance (i.e., considering both accuracy and\nlatency simultaneously). To this end, we describe a new approach based on deep\nreinforcement learning to learn these tradeoffs at runtime for streaming\nperception. This tradeoff optimization is formulated as a novel deep contextual\nbandit problem and we design a new reward function that holistically integrates\nlatency and accuracy into a single metric. We show that our agent can learn a\ncompetitive policy across multiple decision dimensions, which outperforms\nstate-of-the-art policies on public datasets.",
          "link": "http://arxiv.org/abs/2106.05665",
          "publishedOn": "2021-06-11T01:42:14.595Z",
          "wordCount": 604,
          "title": "Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1\">Ivan Drokin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1\">Elena Ericheva</a>",
          "description": "This paper proposes novel end-to-end framework for detecting suspicious\npulmonary nodules in chest CT scans. The method core idea is a new nodule\nsegmentation architecture with a model-based feature projection block on\nthree-dimensional convolutions. This block acts as a preliminary feature\nextractor for a two-dimensional U-Net-like convolutional network. Using the\nproposed approach along with an axial, coronal, and sagittal projection\nanalysis makes it possible to abandon the widely used false positives reduction\nstep. The proposed method achieves SOTA on LUNA2016 with 0.959 average\nsensitivity, and 0.936 sensitivity if the false-positive level per scan is\n0.25. The paper describes the proposed approach and represents the experimental\nresults on LUNA2016 as well as ablation studies.",
          "link": "http://arxiv.org/abs/2106.05741",
          "publishedOn": "2021-06-11T01:42:14.579Z",
          "wordCount": 557,
          "title": "End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Adversarial algorithms have shown to be effective against neural networks for\na variety of tasks. Some adversarial algorithms perturb all the pixels in the\nimage minimally for the image classification task in image classification. In\ncontrast, some algorithms perturb few pixels strongly. However, very little\ninformation is available regarding why these adversarial samples so diverse\nfrom each other exist. Recently, Vargas et al. showed that the existence of\nthese adversarial samples might be due to conflicting saliency within the\nneural network. We test this hypothesis of conflicting saliency by analysing\nthe Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)\nof original and few different types of adversarial samples. We also analyse how\ndifferent adversarial samples distort the attention of the neural network\ncompared to original samples. We show that in the case of Pixel Attack,\nperturbed pixels either calls the network attention to themselves or divert the\nattention from them. Simultaneously, the Projected Gradient Descent Attack\nperturbs pixels so that intermediate layers inside the neural network lose\nattention for the correct class. We also show that both attacks affect the\nsaliency map and activation maps differently. Thus, shedding light on why some\ndefences successful against some attacks remain vulnerable against other\nattacks. We hope that this analysis will improve understanding of the existence\nand the effect of adversarial samples and enable the community to develop more\nrobust neural networks.",
          "link": "http://arxiv.org/abs/2106.05657",
          "publishedOn": "2021-06-11T01:42:14.564Z",
          "wordCount": 675,
          "title": "Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Terhorst_P/0/1/0/all/0/1\">Philipp Terh&#xf6;rst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boller_A/0/1/0/all/0/1\">Andr&#xe9; Boller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1\">Naser Damer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1\">Florian Kirchbuchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1\">Arjan Kuijper</a>",
          "description": "An essential factor to achieve high accuracies in fingerprint recognition\nsystems is the quality of its samples. Previous works mainly proposed\nsupervised solutions based on image properties that neglects the minutiae\nextraction process, despite that most fingerprint recognition techniques are\nbased on detected minutiae. Consequently, a fingerprint image might be assigned\na high quality even if the utilized minutia extractor produces unreliable\ninformation. In this work, we propose a novel concept of assessing minutia and\nfingerprint quality based on minutia detection confidence (MiDeCon). MiDeCon\ncan be applied to an arbitrary deep learning based minutia extractor and does\nnot require quality labels for learning. We propose using the detection\nreliability of the extracted minutia as its quality indicator. By combining the\nhighest minutia qualities, MiDeCon also accurately determines the quality of a\nfull fingerprint. Experiments are conducted on the publicly available databases\nof the FVC 2006 and compared against several baselines, such as NIST's\nwidely-used fingerprint image quality software NFIQ1 and NFIQ2. The results\ndemonstrate a significantly stronger quality assessment performance of the\nproposed MiDeCon-qualities as related works on both, minutia- and\nfingerprint-level. The implementation is publicly available.",
          "link": "http://arxiv.org/abs/2106.05601",
          "publishedOn": "2021-06-11T01:42:14.558Z",
          "wordCount": 635,
          "title": "MiDeCon: Unsupervised and Accurate Fingerprint and Minutia Quality Assessment based on Minutia Detection Confidence. (arXiv:2106.05601v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chongwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haojie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuchang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Ming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhihui Wang</a>",
          "description": "Underwater object detection for robot picking has attracted a lot of\ninterest. However, it is still an unsolved problem due to several challenges.\nWe take steps towards making it more realistic by addressing the following\nchallenges. Firstly, the currently available datasets basically lack the test\nset annotations, causing researchers must compare their method with other SOTAs\non a self-divided test set (from the training set). Training other methods lead\nto an increase in workload and different researchers divide different datasets,\nresulting there is no unified benchmark to compare the performance of different\nalgorithms. Secondly, these datasets also have other shortcomings, e.g., too\nmany similar images or incomplete labels. Towards these challenges we introduce\na dataset, Detecting Underwater Objects (DUO), and a corresponding benchmark,\nbased on the collection and re-annotation of all relevant datasets. DUO\ncontains a collection of diverse underwater images with more rational\nannotations. The corresponding benchmark provides indicators of both efficiency\nand accuracy of SOTAs (under the MMDtection framework) for academic research\nand industrial applications, where JETSON AGX XAVIER is used to assess detector\nspeed to simulate the robot-embedded environment.",
          "link": "http://arxiv.org/abs/2106.05681",
          "publishedOn": "2021-06-11T01:42:14.548Z",
          "wordCount": 623,
          "title": "A Dataset And Benchmark Of Underwater Object Detection For Robot Picking. (arXiv:2106.05681v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1\">David Eisenstat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1\">Jakub &#x141;&#x105;cki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jessica Shi</a>",
          "description": "We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.",
          "link": "http://arxiv.org/abs/2106.05610",
          "publishedOn": "2021-06-11T01:42:14.529Z",
          "wordCount": 628,
          "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yousong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chaoyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1\">Rui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinqiao Wang</a>",
          "description": "Transformer has been widely used for self-supervised pre-training in Natural\nLanguage Processing (NLP) and achieved great success. However, it has not been\nfully explored in visual self-supervised learning. Meanwhile, previous methods\nonly consider the high-level feature and learning representation from a global\nperspective, which may fail to transfer to the downstream dense prediction\ntasks focusing on local features. In this paper, we present a novel Masked\nSelf-supervised Transformer approach named MST, which can explicitly capture\nthe local context of an image while preserving the global semantic information.\nSpecifically, inspired by the Masked Language Modeling (MLM) in NLP, we propose\na masked token strategy based on the multi-head self-attention map, which\ndynamically masks some tokens of local patches without damaging the crucial\nstructure for self-supervised learning. More importantly, the masked tokens\ntogether with the remaining tokens are further recovered by a global image\ndecoder, which preserves the spatial information of the image and is more\nfriendly to the downstream dense prediction tasks. The experiments on multiple\ndatasets demonstrate the effectiveness and generality of the proposed method.\nFor instance, MST achieves Top-1 accuracy of 76.9% with DeiT-S only using\n300-epoch pre-training by linear evaluation, which outperforms supervised\nmethods with the same epoch by 0.4% and its comparable variant DINO by 1.0\\%.\nFor dense prediction tasks, MST also achieves 42.7% mAP on MS COCO object\ndetection and 74.04% mIoU on Cityscapes segmentation only with 100-epoch\npre-training.",
          "link": "http://arxiv.org/abs/2106.05656",
          "publishedOn": "2021-06-11T01:42:14.518Z",
          "wordCount": 674,
          "title": "MST: Masked Self-Supervised Transformer for Visual Representation. (arXiv:2106.05656v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Riya Shah Rutva Shah</a>",
          "description": "In the recent times, the Coronaviruses that are a big family of different\nviruses have become very common, contagious and dangerous to the whole human\nkind. It spreads human to human by exhaling the infection breath, which leaves\ndroplets of the virus on different surface which is then inhaled by other\nperson and catches the infection too. So it has become very important to\nprotect ourselves and the people around us from this situation. We can take\nprecautions such as social distancing, washing hands every two hours, using\nsanitizer, maintaining social distance and the most important wearing a mask.\nPublic use of wearing a masks has become very common everywhere in the whole\nworld now. From that the most affected and devastating condition is of India\ndue to its extreme population in small area. This paper proposes a method to\ndetect the face mask is put on or not for offices, or any other work place with\na lot of people coming to work. We have used convolutional neural network for\nthe same. The model is trained on a real world dataset and tested with live\nvideo streaming with a good accuracy. Further the accuracy of the model with\ndifferent hyper parameters and multiple people at different distance and\nlocation of the frame is done.",
          "link": "http://arxiv.org/abs/2106.05728",
          "publishedOn": "2021-06-11T01:42:14.511Z",
          "wordCount": 696,
          "title": "Face mask detection using convolution neural network. (arXiv:2106.05728v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "This paper presents a novel method for date estimation of historical\nphotographs from archival sources. The main contribution is to formulate the\ndate estimation as a retrieval task, where given a query, the retrieved images\nare ranked in terms of the estimated date similarity. The closer are their\nembedded representations the closer are their dates. Contrary to the\ntraditional models that design a neural network that learns a classifier or a\nregressor, we propose a learning objective based on the nDCG ranking metric. We\nhave experimentally evaluated the performance of the method in two different\ntasks: date estimation and date-sensitive image retrieval, using the DEW public\ndatabase, overcoming the baseline methods.",
          "link": "http://arxiv.org/abs/2106.05618",
          "publishedOn": "2021-06-11T01:42:14.488Z",
          "wordCount": 558,
          "title": "Date Estimation in the Wild of Scanned Historical Photos: An Image Retrieval Approach. (arXiv:2106.05618v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1\">Christian Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1\">Grigory Antipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1\">Moez Baccouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1\">Madiha Nadri</a>",
          "description": "Methods for Visual Question Anwering (VQA) are notorious for leveraging\ndataset biases rather than performing reasoning, hindering generalization. It\nhas been recently shown that better reasoning patterns emerge in attention\nlayers of a state-of-the-art VQA model when they are trained on perfect\n(oracle) visual inputs. This provides evidence that deep neural networks can\nlearn to reason when training conditions are favorable enough. However,\ntransferring this learned knowledge to deployable models is a challenge, as\nmuch of it is lost during the transfer. We propose a method for knowledge\ntransfer based on a regularization term in our loss function, supervising the\nsequence of required reasoning operations. We provide a theoretical analysis\nbased on PAC-learning, showing that such program prediction can lead to\ndecreased sample complexity under mild hypotheses. We also demonstrate the\neffectiveness of this approach experimentally on the GQA dataset and show its\ncomplementarity to BERT-like self-supervised pre-training.",
          "link": "http://arxiv.org/abs/2106.05597",
          "publishedOn": "2021-06-11T01:42:14.482Z",
          "wordCount": 584,
          "title": "Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1\">Sachith Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasthuriaarachchi_N/0/1/0/all/0/1\">Nuran Kasthuriaarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasnayaka_S/0/1/0/all/0/1\">Sanka Rasnayaka</a>",
          "description": "The COVID-19 pandemic has drastically changed accepted norms globally. Within\nthe past year, masks have been used as a public health response to limit the\nspread of the virus. This sudden change has rendered many face recognition\nbased access control, authentication and surveillance systems ineffective.\nOfficial documents such as passports, driving license and national identity\ncards are enrolled with fully uncovered face images. However, in the current\nglobal situation, face matching systems should be able to match these reference\nimages with masked face images. As an example, in an airport or security\ncheckpoint it is safer to match the unmasked image of the identifying document\nto the masked person rather than asking them to remove the mask. We find that\ncurrent facial recognition techniques are not robust to this form of occlusion.\n\nTo address this unique requirement presented due to the current circumstance,\nwe propose a set of re-purposed datasets and a benchmark for researchers to\nuse. We also propose a contrastive visual representation learning based\npre-training workflow which is specialized to masked vs unmasked face matching.\nWe ensure that our method learns robust features to differentiate people across\nvarying data collection scenarios. We achieve this by training over many\ndifferent datasets and validating our result by testing on various holdout\ndatasets. The specialized weights trained by our method outperform standard\nface recognition features for masked to unmasked face matching. We believe the\nprovided synthetic mask generating code, our novel training approach and the\ntrained weights from the masked face models will help in adopting existing face\nrecognition systems to operate in the current global environment. We\nopen-source all contributions for broader use by the research community.",
          "link": "http://arxiv.org/abs/2106.05596",
          "publishedOn": "2021-06-11T01:42:14.477Z",
          "wordCount": 758,
          "title": "Multi-Dataset Benchmarks for Masked Identification using Contrastive Representation Learning. (arXiv:2106.05596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zefan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wen Gao</a>",
          "description": "Unsupervised learning methods have recently shown their competitiveness\nagainst supervised training. Typically, these methods use a single objective to\ntrain the entire network. But one distinct advantage of unsupervised over\nsupervised learning is that the former possesses more variety and freedom in\ndesigning the objective. In this work, we explore new dimensions of\nunsupervised learning by proposing the Progressive Stage-wise Learning (PSL)\nframework. For a given unsupervised task, we design multilevel tasks and define\ndifferent learning stages for the deep network. Early learning stages are\nforced to focus on lowlevel tasks while late stages are guided to extract\ndeeper information through harder tasks. We discover that by progressive\nstage-wise learning, unsupervised feature representation can be effectively\nenhanced. Our extensive experiments show that PSL consistently improves results\nfor the leading unsupervised learning methods.",
          "link": "http://arxiv.org/abs/2106.05554",
          "publishedOn": "2021-06-11T01:42:14.444Z",
          "wordCount": 579,
          "title": "Progressive Stage-wise Learning for Unsupervised Feature Representation Enhancement. (arXiv:2106.05554v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1\">Julia Rosenzweig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1\">Eduardo Brito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1\">Hans-Ulrich Kobialka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1\">Nico M. Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1\">Peter Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jan David Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1\">Fabian H&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1\">Sebastian Houben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1\">Tim Wirtz</a>",
          "description": "Many machine learning applications can benefit from simulated data for\nsystematic validation - in particular if real-life data is difficult to obtain\nor annotate. However, since simulations are prone to domain shift w.r.t.\nreal-life data, it is crucial to verify the transferability of the obtained\nresults. We propose a novel framework consisting of a generative label-to-image\nsynthesis model together with different transferability measures to inspect to\nwhat extent we can transfer testing results of semantic segmentation models\nfrom synthetic data to equivalent real-life data. With slight modifications,\nour approach is extendable to, e.g., general multi-class classification tasks.\nGrounded on the transferability analysis, our approach additionally allows for\nextensive testing by incorporating controlled simulations. We validate our\napproach empirically on a semantic segmentation task on driving scenes.\nTransferability is tested using correlation analysis of IoU and a learned\ndiscriminator. Although the latter can distinguish between real-life and\nsynthetic tests, in the former we observe surprisingly strong correlations of\n0.7 for both cars and pedestrians.",
          "link": "http://arxiv.org/abs/2106.05549",
          "publishedOn": "2021-06-11T01:42:14.438Z",
          "wordCount": 642,
          "title": "Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazarou_M/0/1/0/all/0/1\">Michalis Lazarou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1\">Tania Stathaki</a>",
          "description": "Few-shot classification addresses the challenge of classifying examples given\nnot just limited supervision but limited data as well. An attractive solution\nis synthetic data generation. However, most such methods are overly\nsophisticated, focusing on high-quality, realistic data in the input space. It\nis unclear whether adapting them to the few-shot regime and using them for the\ndownstream task of classification is the right approach. Previous works on\nsynthetic data generation for few-shot classification focus on exploiting\ncomplex models, e.g. a Wasserstein GAN with multiple regularizers or a network\nthat transfers latent diversities from known to novel classes.\n\nWe follow a different approach and investigate how a simple and\nstraightforward synthetic data generation method can be used effectively. We\nmake two contributions, namely we show that: (1) using a simple loss function\nis more than enough for training a feature generator in the few-shot setting;\nand (2) learning to generate tensor features instead of vector features is\nsuperior. Extensive experiments on miniImagenet, CUB and CIFAR-FS datasets show\nthat our method sets a new state of the art, outperforming more sophisticated\nfew-shot data augmentation methods.",
          "link": "http://arxiv.org/abs/2106.05321",
          "publishedOn": "2021-06-11T01:42:14.411Z",
          "wordCount": 626,
          "title": "Tensor feature hallucination for few-shot learning. (arXiv:2106.05321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongsong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shengcai Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Unsupervised domain adaptation for object detection is a challenging problem\nwith many real-world applications. Unfortunately, it has received much less\nattention than supervised object detection. Models that try to address this\ntask tend to suffer from a shortage of annotated training samples. Moreover,\nexisting methods of feature alignments are not sufficient to learn\ndomain-invariant representations. To address these limitations, we propose a\nnovel augmented feature alignment network (AFAN) which integrates intermediate\ndomain image generation and domain-adversarial training into a unified\nframework. An intermediate domain image generator is proposed to enhance\nfeature alignments by domain-adversarial training with automatically generated\nsoft domain labels. The synthetic intermediate domain images progressively\nbridge the domain divergence and augment the annotated source domain training\ndata. A feature pyramid alignment is designed and the corresponding feature\ndiscriminator is used to align multi-scale convolutional features of different\nsemantic levels. Last but not least, we introduce a region feature alignment\nand an instance discriminator to learn domain-invariant features for object\nproposals. Our approach significantly outperforms the state-of-the-art methods\non standard benchmarks for both similar and dissimilar domain adaptations.\nFurther extensive experiments verify the effectiveness of each component and\ndemonstrate that the proposed network can learn domain-invariant\nrepresentations.",
          "link": "http://arxiv.org/abs/2106.05499",
          "publishedOn": "2021-06-11T01:42:14.405Z",
          "wordCount": 628,
          "title": "AFAN: Augmented Feature Alignment Network for Cross-Domain Object Detection. (arXiv:2106.05499v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the effective application of deep learning in computer vision,\nbreakthroughs have been made in the research of super-resolution images\nreconstruction. However, many researches have pointed out that the\ninsufficiency of the neural network extraction on image features may bring the\ndeteriorating of newly reconstructed image. On the other hand, the generated\npictures are sometimes too artificial because of over-smoothing. In order to\nsolve the above problems, we propose a novel self-calibrated convolutional\ngenerative adversarial networks. The generator consists of feature extraction\nand image reconstruction. Feature extraction uses self-calibrated convolutions,\nwhich contains four portions, and each portion has specific functions. It can\nnot only expand the range of receptive fields, but also obtain long-range\nspatial and inter-channel dependencies. Then image reconstruction is performed,\nand finally a super-resolution image is reconstructed. We have conducted\nthorough experiments on different datasets including set5, set14 and BSD100\nunder the SSIM evaluation method. The experimental results prove the\neffectiveness of the proposed network.",
          "link": "http://arxiv.org/abs/2106.05545",
          "publishedOn": "2021-06-11T01:42:14.391Z",
          "wordCount": 598,
          "title": "Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "Deep neural networks (DNNs) are vulnerable to adversarial noise. A range of\nadversarial defense techniques have been proposed to mitigate the interference\nof adversarial noise, among which the input pre-processing methods are scalable\nand show great potential to safeguard DNNs. However, pre-processing methods may\nsuffer from the robustness degradation effect, in which the defense reduces\nrather than improving the adversarial robustness of a target model in a\nwhite-box setting. A potential cause of this negative effect is that\nadversarial training examples are static and independent to the pre-processing\nmodel. To solve this problem, we investigate the influence of full adversarial\nexamples which are crafted against the full model, and find they indeed have a\npositive impact on the robustness of defenses. Furthermore, we find that simply\nchanging the adversarial training examples in pre-processing methods does not\ncompletely alleviate the robustness degradation effect. This is due to the\nadversarial risk of the pre-processed model being neglected, which is another\ncause of the robustness degradation effect. Motivated by above analyses, we\npropose a method called Joint Adversarial Training based Pre-processing (JATP)\ndefense. Specifically, we formulate a feature similarity based adversarial risk\nfor the pre-processing model by using full adversarial examples found in a\nfeature space. Unlike standard adversarial training, we only update the\npre-processing model, which prompts us to introduce a pixel-wise loss to\nimprove its cross-model transferability. We then conduct a joint adversarial\ntraining on the pre-processing model to minimize this overall risk. Empirical\nresults show that our method could effectively mitigate the robustness\ndegradation effect across different target models in comparison to previous\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.05453",
          "publishedOn": "2021-06-11T01:42:14.385Z",
          "wordCount": 705,
          "title": "Improving White-box Robustness of Pre-processing Defenses via Joint Adversarial Training. (arXiv:2106.05453v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1\">Julio Hurtado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1\">Alain Raymond-Saez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "When learning tasks over time, artificial neural networks suffer from a\nproblem known as Catastrophic Forgetting (CF). This happens when the weights of\na network are overwritten during the training of a new task causing forgetting\nof old information. To address this issue, we propose MetA Reusable Knowledge\nor MARK, a new method that fosters weight reusability instead of overwriting\nwhen learning a new task. Specifically, MARK keeps a set of shared weights\namong tasks. We envision these shared weights as a common Knowledge Base (KB)\nthat is not only used to learn new tasks, but also enriched with new knowledge\nas the model learns new tasks. Key components behind MARK are two-fold. On the\none hand, a metalearning approach provides the key mechanism to incrementally\nenrich the KB with new knowledge and to foster weight reusability among tasks.\nOn the other hand, a set of trainable masks provides the key mechanism to\nselectively choose from the KB relevant weights to solve each task. By using\nMARK, we achieve state of the art results in several popular benchmarks,\nsurpassing the best performing methods in terms of average accuracy by over 10%\non the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness\nusing 55% of the number of parameters. Furthermore, an ablation study provides\nevidence that, indeed, MARK is learning reusable knowledge that is selectively\nused by each task.",
          "link": "http://arxiv.org/abs/2106.05390",
          "publishedOn": "2021-06-11T01:42:14.378Z",
          "wordCount": 655,
          "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Ankit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1\">Hei Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1\">Alejandro Newell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>",
          "description": "Processing point cloud data is an important component of many real-world\nsystems. As such, a wide variety of point-based approaches have been proposed,\nreporting steady benchmark improvements over time. We study the key ingredients\nof this progress and uncover two critical results. First, we find that\nauxiliary factors like different evaluation schemes, data augmentation\nstrategies, and loss functions, which are independent of the model\narchitecture, make a large difference in performance. The differences are large\nenough that they obscure the effect of architecture. When these factors are\ncontrolled for, PointNet++, a relatively older network, performs competitively\nwith recent methods. Second, a very simple projection-based method, which we\nrefer to as SimpleView, performs surprisingly well. It achieves on par or\nbetter results than sophisticated state-of-the-art methods on ModelNet40 while\nbeing half the size of PointNet++. It also outperforms state-of-the-art methods\non ScanObjectNN, a real-world point cloud benchmark, and demonstrates better\ncross-dataset generalization. Code is available at\nhttps://github.com/princeton-vl/SimpleView.",
          "link": "http://arxiv.org/abs/2106.05304",
          "publishedOn": "2021-06-11T01:42:14.372Z",
          "wordCount": 605,
          "title": "Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zuxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Zejia Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingjing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guo-Jun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu-Gang Jiang</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na fully-labeled source domain to a different unlabeled target domain. Most\nexisting UDA methods learn domain-invariant feature representations by\nminimizing feature distances across domains. In this work, we build upon\ncontrastive self-supervised learning to align features so as to reduce the\ndomain discrepancy between training and testing sets. Exploring the same set of\ncategories shared by both domains, we introduce a simple yet effective\nframework CDCL, for domain alignment. In particular, given an anchor image from\none domain, we minimize its distances to cross-domain samples from the same\nclass relative to those from different categories. Since target labels are\nunavailable, we use a clustering-based approach with carefully initialized\ncenters to produce pseudo labels. In addition, we demonstrate that CDCL is a\ngeneral framework and can be adapted to the data-free setting, where the source\ndata are unavailable during training, with minimal modification. We conduct\nexperiments on two widely used domain adaptation benchmarks, i.e., Office-31\nand VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance\non both datasets.",
          "link": "http://arxiv.org/abs/2106.05528",
          "publishedOn": "2021-06-11T01:42:14.361Z",
          "wordCount": 615,
          "title": "Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidanapathirana_M/0/1/0/all/0/1\">Madhawa Vidanapathirana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qirui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1\">Yasutaka Furukawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1\">Angel X. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1\">Manolis Savva</a>",
          "description": "We address the task of converting a floorplan and a set of associated photos\nof a residence into a textured 3D mesh model, a task which we call Plan2Scene.\nOur system 1) lifts a floorplan image to a 3D mesh model; 2) synthesizes\nsurface textures based on the input photos; and 3) infers textures for\nunobserved surfaces using a graph neural network architecture. To train and\nevaluate our system we create indoor surface texture datasets, and augment a\ndataset of floorplans and photos from prior work with rectified surface crops\nand additional annotations. Our approach handles the challenge of producing\ntileable textures for dominant surfaces such as floors, walls, and ceilings\nfrom a sparse set of unaligned photos that only partially cover the residence.\nQualitative and quantitative evaluations show that our system produces\nrealistic 3D interior models, outperforming baseline approaches on a suite of\ntexture quality metrics and as measured by a holistic user study.",
          "link": "http://arxiv.org/abs/2106.05375",
          "publishedOn": "2021-06-11T01:42:14.352Z",
          "wordCount": 605,
          "title": "Plan2Scene: Converting Floorplans to 3D Scenes. (arXiv:2106.05375v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1\">M. Hamed Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1\">Li-Lin Tay</a>",
          "description": "Recently, the combination of robust one-dimensional convolutional neural\nnetworks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid\nidentification of unknown substances with good accuracy. Using this technique,\nresearchers can recognize a pure compound and distinguish it from unknown\nsubstances in a mixture. The novelty of this approach is that the trained\nneural network operates automatically without any pre- or post-processing of\ndata. Some studies have attempted to extend this technique to the\nclassification of pure compounds in an unknown mixture. However, the\napplication of 1-D CNNs has typically been restricted to binary classifications\nof pure compounds. Here we will highlight a new approach in spectral\nrecognition and quantification of chemical components in a multicomponent\nmixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this\npurpose. The former is for rapid classification of components in a mixture\nwhile the latter is for quantitative determination of those constituents. In\nthe proposed method, there is no limit to the number of compounds in a mixture.\nA data augmentation method is also introduced by adding random baselines to the\nRaman spectra. The experimental results revealed that the classification\naccuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at\nthe same time, the RaMixNet II model may achieve a regression accuracy of 88%\nfor the quantification of each component.",
          "link": "http://arxiv.org/abs/2106.05316",
          "publishedOn": "2021-06-11T01:42:14.343Z",
          "wordCount": 683,
          "title": "Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1\">Eun-Soo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1\">HyeongGwan Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Kyusam Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1\">Yongkeun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Soonhwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Min Soo Kim</a>",
          "description": "We present a novel deep neural model for text detection in document images.\nFor robust text detection in noisy scanned documents, the advantages of\nmulti-task learning are adopted by adding an auxiliary task of text\nenhancement. Namely, our proposed model is designed to perform noise reduction\nand text region enhancement as well as text detection. Moreover, we enrich the\ntraining data for the model with synthesized document images that are fully\nlabeled for text detection and enhancement, thus overcome the insufficiency of\nlabeled document image data. For the effective exploitation of the synthetic\nand real data, the training process is separated in two phases. The first phase\nis training only synthetic data in a fully-supervised manner. Then real data\nwith only detection labels are added in the second phase. The enhancement task\nfor the real data is weakly-supervised with information from their detection\nlabels. Our methods are demonstrated in a real document dataset with\nperformances exceeding those of other text detection methods. Moreover,\nablations are conducted and the results confirm the effectiveness of the\nsynthetic data, auxiliary task, and weak-supervision. Whereas the existing text\ndetection studies mostly focus on the text in scenes, our proposed method is\noptimized to the applications for the text in scanned documents.",
          "link": "http://arxiv.org/abs/2106.05542",
          "publishedOn": "2021-06-11T01:42:14.317Z",
          "wordCount": 668,
          "title": "DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jonmohamadi_Y/0/1/0/all/0/1\">Yaqub Jonmohamadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Shahnewaz Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fengbei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_J/0/1/0/all/0/1\">Jonathan Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crawford_R/0/1/0/all/0/1\">Ross Crawford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1\">Ajay K. Pandey</a>",
          "description": "Minimally invasive surgery (MIS) has many documented advantages, but the\nsurgeon's limited visual contact with the scene can be problematic. Hence,\nsystems that can help surgeons navigate, such as a method that can produce a 3D\nsemantic map, can compensate for the limitation above. In theory, we can borrow\n3D semantic mapping techniques developed for robotics, but this requires\nfinding solutions to the following challenges in MIS: 1) semantic segmentation,\n2) depth estimation, and 3) pose estimation. In this paper, we propose the\nfirst 3D semantic mapping system from knee arthroscopy that solves the three\nchallenges above. Using out-of-distribution non-human datasets, where pose\ncould be labeled, we jointly train depth+pose estimators using selfsupervised\nand supervised losses. Using an in-distribution human knee dataset, we train a\nfully-supervised semantic segmentation system to label arthroscopic image\npixels into femur, ACL, and meniscus. Taking testing images from human knees,\nwe combine the results from these two systems to automatically create 3D\nsemantic maps of the human knee. The result of this work opens the pathway to\nthe generation of intraoperative 3D semantic mapping, registration with\npre-operative data, and robotic-assisted arthroscopy",
          "link": "http://arxiv.org/abs/2106.05525",
          "publishedOn": "2021-06-11T01:42:14.270Z",
          "wordCount": 634,
          "title": "3D Semantic Mapping from Arthroscopy using Out-of-distribution Pose and Depth and In-distribution Segmentation Training. (arXiv:2106.05525v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Hwa Kim</a>",
          "description": "Clustering algorithms have significantly improved along with Deep Neural\nNetworks which provide effective representation of data. Existing methods are\nbuilt upon deep autoencoder and self-training process that leverages the\ndistribution of cluster assignments of samples. However, as the fundamental\nobjective of the autoencoder is focused on efficient data reconstruction, the\nlearnt space may be sub-optimal for clustering. Moreover, it requires highly\neffective codes (i.e., representation) of data, otherwise the initial cluster\ncenters often cause stability issues during self-training. Many\nstate-of-the-art clustering algorithms use convolution operation to extract\nefficient codes but their applications are limited to image data. In this\nregard, we propose an end-to-end deep clustering algorithm, i.e., Very Compact\nClusters (VCC), for the general datasets, which takes advantage of\ndistributions of local relationships of samples near the boundary of clusters,\nso that they can be properly separated and pulled to cluster centers to form\ncompact clusters. Experimental results on various datasets illustrate that our\nproposed approach achieves better clustering performance over most of the\nstate-of-the-art clustering methods, and the data embeddings learned by VCC\nwithout convolution for image data are even comparable with specialized\nconvolutional methods.",
          "link": "http://arxiv.org/abs/2106.05430",
          "publishedOn": "2021-06-11T01:42:14.242Z",
          "wordCount": 637,
          "title": "Very Compact Clusters with Structural Regularization via Similarity and Connectivity. (arXiv:2106.05430v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arnold_E/0/1/0/all/0/1\">Eduardo Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_S/0/1/0/all/0/1\">Sajjad Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dianati_M/0/1/0/all/0/1\">Mehrdad Dianati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jennings_P/0/1/0/all/0/1\">Paul Jennings</a>",
          "description": "Visual Sensor Networks can be used in a variety of perception applications\nsuch as infrastructure support for autonomous driving in complex road segments.\nThe pose of the sensors in such networks directly determines the coverage of\nthe environment and objects therein, which impacts the performance of\napplications such as object detection and tracking. Existing sensor pose\noptimisation methods in the literature either maximise the coverage of ground\nsurfaces, or consider the visibility of the target objects as binary variables,\nwhich cannot represent various degrees of visibility. Such formulations cannot\nguarantee the visibility of the target objects as they fail to consider\nocclusions. This paper proposes two novel sensor pose optimisation methods,\nbased on gradient-ascent and Integer Programming techniques, which maximise the\nvisibility of multiple target objects in cluttered environments. Both methods\nconsider a realistic visibility model based on a rendering engine that provides\npixel-level visibility information about the target objects. The proposed\nmethods are evaluated in a complex environment and compared to existing methods\nin the literature. The evaluation results indicate that explicitly modelling\nthe visibility of target objects is critical to avoid occlusions in cluttered\nenvironments. Furthermore, both methods significantly outperform existing\nmethods in terms of object visibility.",
          "link": "http://arxiv.org/abs/2106.05308",
          "publishedOn": "2021-06-11T01:42:14.235Z",
          "wordCount": 647,
          "title": "Visual Sensor Pose Optimisation Using Rendering-based Visibility Models for Robust Cooperative Perception. (arXiv:2106.05308v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamasaki_T/0/1/0/all/0/1\">Toshihiko Yamasaki</a>",
          "description": "Unsupervised video-based person re-identification (re-ID) methods extract\nricher features from video tracklets than image-based ones. The\nstate-of-the-art methods utilize clustering to obtain pseudo-labels and train\nthe models iteratively. However, they underestimate the influence of two kinds\nof frames in the tracklet: 1) noise frames caused by detection errors or heavy\nocclusions exist in the tracklet, which may be allocated with unreliable labels\nduring clustering; 2) the tracklet also contains hard frames caused by pose\nchanges or partial occlusions, which are difficult to distinguish but\ninformative. This paper proposes a Noise and Hard frame Aware Clustering (NHAC)\nmethod. NHAC consists of a graph trimming module and a node re-sampling module.\nThe graph trimming module obtains stable graphs by removing noise frame nodes\nto improve the clustering accuracy. The node re-sampling module enhances the\ntraining of hard frame nodes to learn rich tracklet information. Experiments\nconducted on two video-based datasets demonstrate the effectiveness of the\nproposed NHAC under the unsupervised re-ID setting.",
          "link": "http://arxiv.org/abs/2106.05441",
          "publishedOn": "2021-06-11T01:42:14.230Z",
          "wordCount": 600,
          "title": "Unsupervised Video Person Re-identification via Noise and Hard frame Aware Clustering. (arXiv:2106.05441v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khoa Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_G/0/1/0/all/0/1\">Ganghee Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1\">Won-ki Jeong</a>",
          "description": "The segmentation of nanoscale electron microscopy (EM) images is crucial but\nchallenging in connectomics. Recent advances in deep learning have demonstrated\nthe significant potential of automatic segmentation for tera-scale EM images.\nHowever, none of the existing segmentation methods are error-free, and they\nrequire proofreading, which is typically implemented as an interactive,\nsemi-automatic process via manual intervention. Herein, we propose a fully\nautomatic proofreading method based on reinforcement learning. The main idea is\nto model the human decision process in proofreading using a reinforcement agent\nto achieve fully automatic proofreading. We systematically design the proposed\nsystem by combining multiple reinforcement learning agents in a hierarchical\nmanner, where each agent focuses only on a specific task while preserving\ndependency between agents. Furthermore, we also demonstrate that the episodic\ntask setting of reinforcement learning can efficiently manage a combination of\nmerge and split errors concurrently presented in the input. We demonstrate the\nefficacy of the proposed system by comparing it with state-of-the-art\nproofreading methods using various testing examples.",
          "link": "http://arxiv.org/abs/2106.05487",
          "publishedOn": "2021-06-11T01:42:14.186Z",
          "wordCount": 597,
          "title": "RLCorrector: Reinforced Proofreading for Connectomics Image Segmentation. (arXiv:2106.05487v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1\">Shashank Bujimalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1\">Mahesh Subedar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1\">Omesh Tickoo</a>",
          "description": "In this paper, we study the impact of motion blur, a common quality flaw in\nreal world images, on a state-of-the-art two-stage image captioning solution,\nand notice a degradation in solution performance as blur intensity increases.\nWe investigate techniques to improve the robustness of the solution to motion\nblur using training data augmentation at each or both stages of the solution,\ni.e., object detection and captioning, and observe improved results. In\nparticular, augmenting both the stages reduces the CIDEr-D degradation for high\nmotion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to\n6.8 on Vizwiz dataset.",
          "link": "http://arxiv.org/abs/2106.05437",
          "publishedOn": "2021-06-11T01:42:14.147Z",
          "wordCount": 539,
          "title": "Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix G. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-10T22:40:40.536Z",
          "wordCount": 609,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Ao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hechen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1\">Shuojia Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "Image classification has achieved unprecedented advance with the the rapid\ndevelopment of deep learning. However, the classification of tiny object images\nis still not well investigated. In this paper, we first briefly review the\ndevelopment of Convolutional Neural Network and Visual Transformer in deep\nlearning, and introduce the sources and development of conventional noises and\nadversarial attacks. Then we use various models of Convolutional Neural Network\nand Visual Transformer to conduct a series of experiments on the image dataset\nof tiny objects (sperms and impurities), and compare various evaluation metrics\nin the experimental results to obtain a model with stable performance. Finally,\nwe discuss the problems in the classification of tiny objects and make a\nprospect for the classification of tiny objects in the future.",
          "link": "http://arxiv.org/abs/2106.01927",
          "publishedOn": "2021-06-10T22:40:40.506Z",
          "wordCount": 616,
          "title": "A Comparison for Anti-noise Robustness of Deep Learning Classification Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to Visual Transformer and Performer. (arXiv:2106.01927v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>",
          "description": "Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.",
          "link": "http://arxiv.org/abs/2106.04619",
          "publishedOn": "2021-06-10T01:56:49.433Z",
          "wordCount": 637,
          "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:48.964Z",
          "wordCount": null,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1\">Rohit Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara Lee Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "Most existing video-and-language (VidL) research focuses on a single dataset,\nor multiple datasets of a single task. In reality, a truly useful VidL system\nis expected to be easily generalizable to diverse tasks, domains, and datasets.\nTo facilitate the evaluation of such systems, we introduce Video-And-Language\nUnderstanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets\nover 3 popular tasks: (i) text-to-video retrieval; (ii) video question\nanswering; and (iii) video captioning. VALUE benchmark aims to cover a broad\nrange of video genres, video lengths, data volumes, and task difficulty levels.\nRather than focusing on single-channel videos with visual information only,\nVALUE promotes models that leverage information from both video frames and\ntheir associated subtitles, as well as models that share knowledge across\nmultiple tasks. We evaluate various baseline methods with and without\nlarge-scale VidL pre-training, and systematically investigate the impact of\nvideo input channels, fusion methods, and different video representations. We\nalso study the transferability between tasks, and conduct multi-task learning\nunder different settings. The significant gap between our best model and human\nperformance calls for future study for advanced VidL models. VALUE is available\nat https://value-leaderboard.github.io/.",
          "link": "http://arxiv.org/abs/2106.04632",
          "publishedOn": "2021-06-10T01:56:48.467Z",
          "wordCount": 656,
          "title": "VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1\">Gedas Bertasius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Heng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1\">Lorenzo Torresani</a>",
          "description": "We present a convolution-free approach to video classification built\nexclusively on self-attention over space and time. Our method, named\n\"TimeSformer,\" adapts the standard Transformer architecture to video by\nenabling spatiotemporal feature learning directly from a sequence of\nframe-level patches. Our experimental study compares different self-attention\nschemes and suggests that \"divided attention,\" where temporal attention and\nspatial attention are separately applied within each block, leads to the best\nvideo classification accuracy among the design choices considered. Despite the\nradically new design, TimeSformer achieves state-of-the-art results on several\naction recognition benchmarks, including the best reported accuracy on\nKinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks,\nour model is faster to train, it can achieve dramatically higher test\nefficiency (at a small drop in accuracy), and it can also be applied to much\nlonger video clips (over one minute long). Code and models are available at:\nhttps://github.com/facebookresearch/TimeSformer.",
          "link": "http://arxiv.org/abs/2102.05095",
          "publishedOn": "2021-06-10T01:56:47.382Z",
          "wordCount": 628,
          "title": "Is Space-Time Attention All You Need for Video Understanding?. (arXiv:2102.05095v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1\">Maxwell Horton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1\">Carlos Guestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>",
          "description": "Recent observations have advanced our understanding of the neural network\noptimization landscape, revealing the existence of (1) paths of high accuracy\ncontaining diverse solutions and (2) wider minima offering improved\nperformance. Previous methods observing diverse paths require multiple training\nruns. In contrast we aim to leverage both property (1) and (2) with a single\nmethod and in a single training run. With a similar computational cost as\ntraining one model, we learn lines, curves, and simplexes of high-accuracy\nneural networks. These neural network subspaces contain diverse solutions that\ncan be ensembled, approaching the ensemble performance of independently trained\nnetworks without the training cost. Moreover, using the subspace midpoint\nboosts accuracy, calibration, and robustness to label noise, outperforming\nStochastic Weight Averaging.",
          "link": "http://arxiv.org/abs/2102.10472",
          "publishedOn": "2021-06-10T01:56:47.325Z",
          "wordCount": 575,
          "title": "Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menghan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Tien-Tsin Wong</a>",
          "description": "As a generic modeling tool, Convolutional Neural Networks (CNNs) have been\nwidely employed in image generation and translation tasks. However, when fed\nwith a flat input, current CNN models may fail to generate vivid results due to\nthe spatially shared convolution kernels. We call it the flatness degradation\nof CNNs. Unfortunately, such degradation is the greatest obstacles to generate\na spatially-variant output from a flat input, which has been barely discussed\nin the previous literature. To tackle this problem, we propose a model agnostic\nsolution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in\nfor any CNN generation model. The key idea is to break the flat input condition\nwhile keeping the intactness of the original information. Specifically, the NIB\nperturbs the input data symmetrically with a noise map and reassembles them in\nthe feature domain as driven by the objective function. Extensive experiments\nshow that existing CNN models equipped with NIB survive from the flatness\ndegradation and are able to generate visually better results with richer\ndetails in some specific image generation tasks given flat inputs, e.g.\nsemantic image synthesis, data-hidden image generation, and deep neural\ndithering.",
          "link": "http://arxiv.org/abs/2012.12109",
          "publishedOn": "2021-06-10T01:56:47.319Z",
          "wordCount": 650,
          "title": "Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zilin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Self-supervised learning, which benefits from automatically constructing\nlabels through pre-designed pretext task, has recently been applied for\nstrengthen supervised learning. Since previous self-supervised pretext tasks\nare based on input, they may incur huge additional training overhead. In this\npaper we find that features in CNNs can be also used for self-supervision. Thus\nwe creatively design the \\emph{feature-based pretext task} which requires only\na small amount of additional training overhead. In our task we discard\ndifferent particular regions of features, and then train the model to\ndistinguish these different features. In order to fully apply our feature-based\npretext task in supervised learning, we also propose a novel learning framework\ncontaining multi-classifiers for further improvement. Original labels will be\nexpanded to joint labels via self-supervision of feature transformations. With\nmore semantic information provided by our self-supervised tasks, this approach\ncan train CNNs more effectively. Extensive experiments on various supervised\nlearning tasks demonstrate the accuracy improvement and wide applicability of\nour method.",
          "link": "http://arxiv.org/abs/2106.04922",
          "publishedOn": "2021-06-10T01:56:47.312Z",
          "wordCount": 598,
          "title": "Self-supervision of Feature Transformation for Further Improving Supervised Learning. (arXiv:2106.04922v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>",
          "description": "In this work we introduce a new approach for identifiable non-linear ICA\nmodels. Recently there has been a renaissance in identifiability results in\ndeep generative models, not least for non-linear ICA. These prior works,\nhowever, have assumed access to a sufficiently-informative auxiliary set of\nobservations, denoted $\\mathbf{u}$. We show here how identifiability can be\nobtained in the absence of this side-information, rendering possible\nfully-unsupervised identifiable non-linear ICA. While previous theoretical\nresults have established the impossibility of identifiable non-linear ICA in\nthe presence of infinitely-flexible universal function approximators, here we\nrely on the intrinsically-finite modelling capacity of any particular chosen\nparameterisation of a deep generative model. In particular, we focus on\ngenerative models which perform clustering in their latent space -- a model\nstructure which matches previous identifiable models, but with the learnt\nclustering providing a synthetic form of auxiliary information. We evaluate our\nproposals using VAEs, on synthetic and image datasets, and find that the\nlearned clusterings function effectively: deep generative models with latent\nclusterings are empirically identifiable, to the same degree as models which\nrely on side information.",
          "link": "http://arxiv.org/abs/2106.05238",
          "publishedOn": "2021-06-10T01:56:47.306Z",
          "wordCount": 620,
          "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.11228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1\">Torben Teepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilg_J/0/1/0/all/0/1\">Johannes Gilg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzog_F/0/1/0/all/0/1\">Fabian Herzog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1\">Stefan H&#xf6;rmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Gait recognition is a promising video-based biometric for identifying\nindividual walking patterns from a long distance. At present, most gait\nrecognition methods use silhouette images to represent a person in each frame.\nHowever, silhouette images can lose fine-grained spatial information, and most\npapers do not regard how to obtain these silhouettes in complex scenes.\nFurthermore, silhouette images contain not only gait features but also other\nvisual clues that can be recognized. Hence these approaches can not be\nconsidered as strict gait recognition.\n\nWe leverage recent advances in human pose estimation to estimate robust\nskeleton poses directly from RGB images to bring back model-based gait\nrecognition with a cleaner representation of gait. Thus, we propose GaitGraph\nthat combines skeleton poses with Graph Convolutional Network (GCN) to obtain a\nmodern model-based approach for gait recognition. The main advantages are a\ncleaner, more elegant extraction of the gait features and the ability to\nincorporate powerful spatio-temporal modeling using GCN. Experiments on the\npopular CASIA-B gait dataset show that our method archives state-of-the-art\nperformance in model-based gait recognition.\n\nThe code and models are publicly available.",
          "link": "http://arxiv.org/abs/2101.11228",
          "publishedOn": "2021-06-10T01:56:47.287Z",
          "wordCount": 648,
          "title": "GaitGraph: Graph Convolutional Network for Skeleton-Based Gait Recognition. (arXiv:2101.11228v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05214",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1\">Sergio Naval Marimont</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1\">Giacomo Tarroni</a>",
          "description": "We propose a novel unsupervised out-of-distribution detection method for\nmedical images based on implicit fields image representations. In our approach,\nan auto-decoder feed-forward neural network learns the distribution of healthy\nimages in the form of a mapping between spatial coordinates and probabilities\nover a proxy for tissue types. At inference time, the learnt distribution is\nused to retrieve, from a given test image, a restoration, i.e. an image\nmaximally consistent with the input one but belonging to the healthy\ndistribution. Anomalies are localized using the voxel-wise probability\npredicted by our model for the restored image. We tested our approach in the\ntask of unsupervised localization of gliomas on brain MR images and compared it\nto several other VAE-based anomaly detection methods. Results show that the\nproposed technique substantially outperforms them (average DICE 0.640 vs 0.518\nfor the best performing VAE-based alternative) while also requiring\nconsiderably less computing time.",
          "link": "http://arxiv.org/abs/2106.05214",
          "publishedOn": "2021-06-10T01:56:47.280Z",
          "wordCount": 603,
          "title": "Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1\">Wang Yifan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1\">Lukas Rahmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1\">Olga Sorkine-Hornung</a>",
          "description": "We present implicit displacement fields, a novel representation for detailed\n3D geometry. Inspired by a classic surface deformation technique, displacement\nmapping, our method represents a complex surface as a smooth base surface plus\na displacement along the base's normal directions, resulting in a\nfrequency-based shape decomposition, where the high frequency signal is\nconstrained geometrically by the low frequency signal. Importantly, this\ndisentanglement is unsupervised thanks to a tailored architectural design that\nhas an innate frequency hierarchy by construction. We explore implicit\ndisplacement field surface reconstruction and detail transfer and demonstrate\nsuperior representational power, training stability and generalizability.",
          "link": "http://arxiv.org/abs/2106.05187",
          "publishedOn": "2021-06-10T01:56:47.266Z",
          "wordCount": 539,
          "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Si-Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hui-Liang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Lun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shu-Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunguang Li</a>",
          "description": "Multispectral and multimodal image processing is important in the community\nof computer vision and computational photography. As the acquired multispectral\nand multimodal data are generally misaligned due to the alternation or movement\nof the image device, the image registration procedure is necessary. The\nregistration of multispectral or multimodal image is challenging due to the\nnon-linear intensity and gradient variation. To cope with this challenge, we\npropose the phase congruency network (PCNet), which is able to enhance the\nstructure similarity and alleviate the non-linear intensity and gradient\nvariation. The images can then be aligned using the similarity enhanced\nfeatures produced by the network. PCNet is constructed under the guidance of\nthe phase congruency prior. The network contains three trainable layers\naccompany with the modified learnable Gabor kernels according to the phase\ncongruency theory. Thanks to the prior knowledge, PCNet is extremely\nlight-weight and can be trained on quite a small amount of multispectral data.\nPCNet can be viewed to be fully convolutional and hence can take input of\narbitrary sizes. Once trained, PCNet is applicable on a variety of\nmultispectral and multimodal data such as RGB/NIR and flash/no-flash images\nwithout additional further tuning. Experimental results validate that PCNet\noutperforms current state-of-the-art registration algorithms, including the\ndeep-learning based ones that have the number of parameters hundreds times\ncompared to PCNet. Thanks to the similarity enhancement training, PCNet\noutperforms the original phase congruency algorithm with two-thirds less\nfeature channels.",
          "link": "http://arxiv.org/abs/2106.05124",
          "publishedOn": "2021-06-10T01:56:47.260Z",
          "wordCount": 682,
          "title": "PCNet: A Structure Similarity Enhancement Method for Multispectral and Multimodal Image Registration. (arXiv:2106.05124v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Basak_H/0/1/0/all/0/1\">Hritam Basak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_R/0/1/0/all/0/1\">Rohit Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Sukanta Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1\">Nibaran Das</a>",
          "description": "Cervical cancer is one of the most deadly and common diseases among women\nworldwide. It is completely curable if diagnosed in an early stage, but the\ntedious and costly detection procedure makes it unviable to conduct\npopulation-wise screening. Thus, to augment the effort of the clinicians, in\nthis paper, we propose a fully automated framework that utilizes Deep Learning\nand feature selection using evolutionary optimization for cytology image\nclassification. The proposed framework extracts Deep feature from several\nConvolution Neural Network models and uses a two-step feature reduction\napproach to ensure reduction in computation cost and faster convergence. The\nfeatures extracted from the CNN models form a large feature space whose\ndimensionality is reduced using Principal Component Analysis while preserving\n99% of the variance. A non-redundant, optimal feature subset is selected from\nthis feature space using an evolutionary optimization algorithm, the Grey Wolf\nOptimizer, thus improving the classification performance. Finally, the selected\nfeature subset is used to train an SVM classifier for generating the final\npredictions. The proposed framework is evaluated on three publicly available\nbenchmark datasets: Mendeley Liquid Based Cytology (4-class) dataset, Herlev\nPap Smear (7-class) dataset, and the SIPaKMeD Pap Smear (5-class) dataset\nachieving classification accuracies of 99.47%, 98.32% and 97.87% respectively,\nthus justifying the reliability of the approach. The relevant codes for the\nproposed approach can be found in:\nhttps://github.com/DVLP-CMATERJU/Two-Step-Feature-Enhancement",
          "link": "http://arxiv.org/abs/2106.04919",
          "publishedOn": "2021-06-10T01:56:47.230Z",
          "wordCount": 666,
          "title": "Cervical Cytology Classification Using PCA & GWO Enhanced Deep Features Selection. (arXiv:2106.04919v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1\">Kevin D. McCay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1\">Dimitrios Sakkos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1\">Claire Marcroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1\">Patricia Dulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1\">Nicholas D. Embleton</a>",
          "description": "Providing early diagnosis of cerebral palsy (CP) is key to enhancing the\ndevelopmental outcomes for those affected. Diagnostic tools such as the General\nMovements Assessment (GMA), have produced promising results in early diagnosis,\nhowever these manual methods can be laborious.\n\nIn this paper, we propose a new framework for the automated classification of\ninfant body movements, based upon the GMA, which unlike previous methods, also\nincorporates a visualization framework to aid with interpretability. Our\nproposed framework segments extracted features to detect the presence of\nFidgety Movements (FMs) associated with the GMA spatiotemporally. These\nfeatures are then used to identify the body-parts with the greatest\ncontribution towards a classification decision and highlight the related\nbody-part segment providing visual feedback to the user.\n\nWe quantitatively compare the proposed framework's classification performance\nwith several other methods from the literature and qualitatively evaluate the\nvisualization's veracity. Our experimental results show that the proposed\nmethod performs more robustly than comparable techniques in this setting whilst\nsimultaneously providing relevant visual interpretability.",
          "link": "http://arxiv.org/abs/2106.04966",
          "publishedOn": "2021-06-10T01:56:47.164Z",
          "wordCount": 645,
          "title": "Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_Y/0/1/0/all/0/1\">Yi-Chen Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chia-Che Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1\">Hsuan-Chao Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chia-Ping Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yu-Lin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "In this paper, we present CLCC, a novel contrastive learning framework for\ncolor constancy. Contrastive learning has been applied for learning\nhigh-quality visual representations for image classification. One key aspect to\nyield useful representations for image classification is to design illuminant\ninvariant augmentations. However, the illuminant invariant assumption conflicts\nwith the nature of the color constancy task, which aims to estimate the\nilluminant given a raw image. Therefore, we construct effective contrastive\npairs for learning better illuminant-dependent features via a novel raw-domain\ncolor augmentation. On the NUS-8 dataset, our method provides $17.5\\%$ relative\nimprovements over a strong baseline, reaching state-of-the-art performance\nwithout increasing model complexity. Furthermore, our method achieves\ncompetitive performance on the Gehler dataset with $3\\times$ fewer parameters\ncompared to top-ranking deep learning methods. More importantly, we show that\nour model is more robust to different scenes under close proximity of\nilluminants, significantly reducing $28.7\\%$ worst-case error in data-sparse\nregions.",
          "link": "http://arxiv.org/abs/2106.04989",
          "publishedOn": "2021-06-10T01:56:47.032Z",
          "wordCount": 595,
          "title": "CLCC: Contrastive Learning for Color Constancy. (arXiv:2106.04989v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqing Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1\">Jiansheng Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwu Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1\">Risa Higashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiang Liu</a>",
          "description": "Cataract is one of the leading causes of reversible visual impairment and\nblindness globally. Over the years, researchers have achieved significant\nprogress in developing state-of-the-art artificial intelligence techniques for\nautomatic cataract classification and grading, helping clinicians prevent and\ntreat cataract in time. This paper provides a comprehensive survey of recent\nadvances in machine learning for cataract classification and grading based on\nophthalmic images. We summarize existing literature from two research\ndirections: conventional machine learning techniques and deep learning\ntechniques. This paper also provides insights into existing works of both\nmerits and limitations. In addition, we discuss several challenges of automatic\ncataract classification and grading based on machine learning techniques and\npresent possible solutions to these challenges for future research.",
          "link": "http://arxiv.org/abs/2012.04830",
          "publishedOn": "2021-06-10T01:56:46.805Z",
          "wordCount": 597,
          "title": "Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Frisch_D/0/1/0/all/0/1\">Daniel Frisch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanebeck_U/0/1/0/all/0/1\">Uwe D. Hanebeck</a>",
          "description": "We consider estimating the parameters of a Gaussian mixture density with a\ngiven number of components best representing a given set of weighted samples.\nWe adopt a density interpretation of the samples by viewing them as a discrete\nDirac mixture density over a continuous domain with weighted components. Hence,\nGaussian mixture fitting is viewed as density re-approximation. In order to\nspeed up computation, an expectation-maximization method is proposed that\nproperly considers not only the sample locations, but also the corresponding\nweights. It is shown that methods from literature do not treat the weights\ncorrectly, resulting in wrong estimates. This is demonstrated with simple\ncounterexamples. The proposed method works in any number of dimensions with the\nsame computational load as standard Gaussian mixture estimators for unweighted\nsamples.",
          "link": "http://arxiv.org/abs/2106.05109",
          "publishedOn": "2021-06-10T01:56:46.754Z",
          "wordCount": 566,
          "title": "Gaussian Mixture Estimation from Weighted Samples. (arXiv:2106.05109v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1\">Relja Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "Neural radiance fields (NeRF) methods have demonstrated impressive novel view\nsynthesis performance. The core approach is to render individual rays by\nquerying a neural network at points sampled along the ray to obtain the density\nand colour of the sampled points, and integrating this information using the\nrendering equation. Since dense sampling is computationally prohibitive, a\ncommon solution is to perform coarse-to-fine sampling.\n\nIn this work we address a clear limitation of the vanilla coarse-to-fine\napproach -- that it is based on a heuristic and not trained end-to-end for the\ntask at hand. We introduce a differentiable module that learns to propose\nsamples and their importance for the fine network, and consider and compare\nmultiple alternatives for its neural architecture. Training the proposal module\nfrom scratch can be unstable due to lack of supervision, so an effective\npre-training strategy is also put forward. The approach, named `NeRF in detail'\n(NeRF-ID), achieves superior view synthesis quality over NeRF and the\nstate-of-the-art on the synthetic Blender benchmark and on par or better\nperformance on the real LLFF-NeRF scenes. Furthermore, by leveraging the\npredicted sample importance, a 25% saving in computation can be achieved\nwithout significantly sacrificing the rendering quality.",
          "link": "http://arxiv.org/abs/2106.05264",
          "publishedOn": "2021-06-10T01:56:46.723Z",
          "wordCount": 632,
          "title": "NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1\">Naoya Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>",
          "description": "Tasks that involve high-resolution dense prediction require a modeling of\nboth local and global patterns in a large input field. Although the local and\nglobal structures often depend on each other and their simultaneous modeling is\nimportant, many convolutional neural network (CNN)-based approaches interchange\nrepresentations in different resolutions only a few times. In this paper, we\nclaim the importance of a dense simultaneous modeling of multiresolution\nrepresentation and propose a novel CNN architecture called densely connected\nmultidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution\nthat has different dilation factors in a single layer to model different\nresolutions simultaneously. By combining the multidilated convolution with the\nDenseNet architecture, D3Net incorporates multiresolution learning with an\nexponentially growing receptive field in almost all layers, while avoiding the\naliasing problem that occurs when we naively incorporate the dilated\nconvolution in DenseNet. Experiments on the image semantic segmentation task\nusing Cityscapes and the audio source separation task using MUSDB18 show that\nthe proposed method has superior performance over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.11844",
          "publishedOn": "2021-06-10T01:56:46.711Z",
          "wordCount": 636,
          "title": "Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongguang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1\">Piotr Koniusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1\">Songlei Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongdong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H. S. Torr</a>",
          "description": "The majority of existing few-shot learning methods describe image relations\nwith binary labels. However, such binary relations are insufficient to teach\nthe network complicated real-world relations, due to the lack of decision\nsmoothness. Furthermore, current few-shot learning models capture only the\nsimilarity via relation labels, but they are not exposed to class concepts\nassociated with objects, which is likely detrimental to the classification\nperformance due to underutilization of the available class labels. To\nparaphrase, children learn the concept of tiger from a few of actual examples\nas well as from comparisons of tiger to other animals. Thus, we hypothesize\nthat in fact both similarity and class concept learning must be occurring\nsimultaneously. With these observations at hand, we study the fundamental\nproblem of simplistic class modeling in current few-shot learning methods. We\nrethink the relations between class concepts, and propose a novel\nAbsolute-relative Learning paradigm to fully take advantage of label\ninformation to refine the image representations and correct the relation\nunderstanding in both supervised and unsupervised scenarios. Our proposed\nparadigm improves the performance of several the state-of-the-art models on\npublicly available datasets.",
          "link": "http://arxiv.org/abs/2001.03919",
          "publishedOn": "2021-06-10T01:56:46.697Z",
          "wordCount": 677,
          "title": "Rethinking Class Relations: Absolute-relative Supervised and Unsupervised Few-shot Learning. (arXiv:2001.03919v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.01755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1\">Bin-Bin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hong-Yu Zhou</a>",
          "description": "Multi-label image recognition is a practical and challenging task compared to\nsingle-label image classification. However, previous works may be suboptimal\nbecause of a great number of object proposals or complex attentional region\ngeneration modules. In this paper, we propose a simple but efficient two-stream\nframework to recognize multi-category objects from global image to local\nregions, similar to how human beings perceive objects. To bridge the gap\nbetween global and local streams, we propose a multi-class attentional region\nmodule which aims to make the number of attentional regions as small as\npossible and keep the diversity of these regions as high as possible. Our\nmethod can efficiently and effectively recognize multi-class objects with an\naffordable computation cost and a parameter-free region localization module.\nOver three benchmarks on multi-label image classification, we create new\nstate-of-the-art results with a single model only using image semantics without\nlabel dependency. In addition, the effectiveness of the proposed method is\nextensively demonstrated under different factors such as global pooling\nstrategy, input size and network architecture. Code has been made available\nat~\\url{https://github.com/gaobb/MCAR}.",
          "link": "http://arxiv.org/abs/2007.01755",
          "publishedOn": "2021-06-10T01:56:46.691Z",
          "wordCount": 651,
          "title": "Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition. (arXiv:2007.01755v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Zhiwu Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1\">Zhurong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingqian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Marcelo H. Ang Jr</a>",
          "description": "With the recent surge in the research of vision transformers, they have\ndemonstrated remarkable potential for various challenging computer vision\napplications, such as image recognition, point cloud classification as well as\nvideo understanding. In this paper, we present empirical results for training a\nstronger video vision transformer on the EPIC-KITCHENS-100 Action Recognition\ndataset. Specifically, we explore training techniques for video vision\ntransformers, such as augmentations, resolutions as well as initialization,\netc. With our training recipe, a single ViViT model achieves the performance of\n47.4\\% on the validation set of EPIC-KITCHENS-100 dataset, outperforming what\nis reported in the original paper by 3.4%. We found that video transformers are\nespecially good at predicting the noun in the verb-noun action prediction task.\nThis makes the overall action prediction accuracy of video transformers notably\nhigher than convolutional ones. Surprisingly, even the best video transformers\nunderperform the convolutional networks on the verb prediction. Therefore, we\ncombine the video vision transformers and some of the convolutional video\nnetworks and present our solution to the EPIC-KITCHENS-100 Action Recognition\ncompetition.",
          "link": "http://arxiv.org/abs/2106.05058",
          "publishedOn": "2021-06-10T01:56:46.685Z",
          "wordCount": 627,
          "title": "Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition. (arXiv:2106.05058v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhi Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaojiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Reasoning the human-object interactions (HOI) is essential for deeper scene\nunderstanding, while object affordances (or functionalities) are of great\nimportance for human to discover unseen HOIs with novel objects. Inspired by\nthis, we introduce an affordance transfer learning approach to jointly detect\nHOIs with novel objects and recognize affordances. Specifically, HOI\nrepresentations can be decoupled into a combination of affordance and object\nrepresentations, making it possible to compose novel interactions by combining\naffordance representations and novel object representations from additional\nimages, i.e. transferring the affordance to novel objects. With the proposed\naffordance transfer learning, the model is also capable of inferring the\naffordances of novel objects from known affordance representations. The\nproposed method can thus be used to 1) improve the performance of HOI\ndetection, especially for the HOIs with unseen objects; and 2) infer the\naffordances of novel objects. Experimental results on two datasets, HICO-DET\nand HOI-COCO (from V-COCO), demonstrate significant improvements over recent\nstate-of-the-art methods for HOI detection and object affordance detection.\nCode is available at https://github.com/zhihou7/HOI-CL",
          "link": "http://arxiv.org/abs/2104.02867",
          "publishedOn": "2021-06-10T01:56:46.666Z",
          "wordCount": 646,
          "title": "Affordance Transfer Learning for Human-Object Interaction Detection. (arXiv:2104.02867v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_G/0/1/0/all/0/1\">Grant Van Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1\">Elijah Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1\">Sara Beery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilber_K/0/1/0/all/0/1\">Kimberly Wilber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1\">Serge Belongie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1\">Oisin Mac Aodha</a>",
          "description": "Recent progress in self-supervised learning has resulted in models that are\ncapable of extracting rich representations from image collections without\nrequiring any explicit label supervision. However, to date the vast majority of\nthese approaches have restricted themselves to training on standard benchmark\ndatasets such as ImageNet. We argue that fine-grained visual categorization\nproblems, such as plant and animal species classification, provide an\ninformative testbed for self-supervised learning. In order to facilitate\nprogress in this area we present two new natural world visual classification\ndatasets, iNat2021 and NeWT. The former consists of 2.7M images from 10k\ndifferent species uploaded by users of the citizen science application\niNaturalist. We designed the latter, NeWT, in collaboration with domain experts\nwith the aim of benchmarking the performance of representation learning\nalgorithms on a suite of challenging natural world binary classification tasks\nthat go beyond standard species classification. These two new datasets allow us\nto explore questions related to large-scale representation and transfer\nlearning in the context of fine-grained categories. We provide a comprehensive\nanalysis of feature extractors trained with and without supervision on ImageNet\nand iNat2021, shedding light on the strengths and weaknesses of different\nlearned features across a diverse set of tasks. We find that features produced\nby standard supervised methods still outperform those produced by\nself-supervised approaches such as SimCLR. However, improved self-supervised\nlearning methods are constantly being released and the iNat2021 and NeWT\ndatasets are a valuable resource for tracking their progress.",
          "link": "http://arxiv.org/abs/2103.16483",
          "publishedOn": "2021-06-10T01:56:46.660Z",
          "wordCount": 714,
          "title": "Benchmarking Representation Learning for Natural World Image Collections. (arXiv:2103.16483v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadjiivanov_A/0/1/0/all/0/1\">Alexander Hadjiivanov</a>",
          "description": "Most classical (non-spiking) neural network models disregard internal neuron\ndynamics and treat neurons as simple input integrators. However, biological\nneurons have an internal state governed by complex dynamics that plays a\ncrucial role in learning, adaptation and the overall network activity and\nbehaviour. This paper presents the Membrane Potential and Activation Threshold\nHomeostasis (MPATH) neuron model, which combines several biologically inspired\nmechanisms to efficiently simulate internal neuron dynamics with a single\nparameter analogous to the membrane time constant in biological neurons. The\nmodel allows neurons to maintain a form of dynamic equilibrium by automatically\nregulating their activity when presented with fluctuating input. One\nconsequence of the MPATH model is that it imbues neurons with a sense of time\nwithout recurrent connections, paving the way for modelling processes that\ndepend on temporal aspects of neuron activity. Experiments demonstrate the\nmodel's ability to adapt to and continually learn from its input.",
          "link": "http://arxiv.org/abs/2104.10851",
          "publishedOn": "2021-06-10T01:56:46.654Z",
          "wordCount": 619,
          "title": "Continuous Learning and Adaptation with Membrane Potential and Activation Threshold Homeostasis. (arXiv:2104.10851v3 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1\">Sebastian Cygert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1\">Andrzej Czy&#x17c;ewski</a>",
          "description": "Model compression techniques allow to significantly reduce the computational\ncost associated with data processing by deep neural networks with only a minor\ndecrease in average accuracy. Simultaneously, reducing the model size may have\na large effect on noisy cases or objects belonging to less frequent classes. It\nis a crucial problem from the perspective of the models' safety, especially for\nobject detection in the autonomous driving setting, which is considered in this\nwork. It was shown in the paper that the sensitivity of compressed models to\ndifferent distortion types is nuanced, and some of the corruptions are heavily\nimpacted by the compression methods (i.e., additive noise), while others (blur\neffect) are only slightly affected. A common way to improve the robustness of\nmodels is to use data augmentation, which was confirmed to positively affect\nmodels' robustness, also for highly compressed models. It was further shown\nthat while data imbalance methods brought only a slight increase in accuracy\nfor the baseline model (without compression), the impact was more striking at\nhigher compression rates for the structured pruning. Finally, methods for\nhandling data imbalance brought a significant improvement of the pruned models'\nworst-detected class accuracy.",
          "link": "http://arxiv.org/abs/2102.05509",
          "publishedOn": "2021-06-10T01:56:46.649Z",
          "wordCount": 647,
          "title": "Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1\">Frederik Warburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_M/0/1/0/all/0/1\">Martin J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Civera_J/0/1/0/all/0/1\">Javier Civera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Uncertainty quantification in image retrieval is crucial for downstream\ndecisions, yet it remains a challenging and largely unexplored problem. Current\nmethods for estimating uncertainties are poorly calibrated, computationally\nexpensive, or based on heuristics. We present a new method that views image\nembeddings as stochastic features rather than deterministic features. Our two\nmain contributions are (1) a likelihood that matches the triplet constraint and\nthat evaluates the probability of an anchor being closer to a positive than a\nnegative; and (2) a prior over the feature space that justifies the\nconventional l2 normalization. To ensure computational efficiency, we derive a\nvariational approximation of the posterior, called the Bayesian triplet loss,\nthat produces state-of-the-art uncertainty estimates and matches the predictive\nperformance of current state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.12663",
          "publishedOn": "2021-06-10T01:56:46.641Z",
          "wordCount": 581,
          "title": "Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval. (arXiv:2011.12663v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.01619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yingjie Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Buyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1\">Zeyu Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingyu Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>",
          "description": "Monocular 3D object detection task aims to predict the 3D bounding boxes of\nobjects based on monocular RGB images. Since the location recovery in 3D space\nis quite difficult on account of absence of depth information, this paper\nproposes a novel unified framework which decomposes the detection problem into\na structured polygon prediction task and a depth recovery task. Different from\nthe widely studied 2D bounding boxes, the proposed novel structured polygon in\nthe 2D image consists of several projected surfaces of the target object.\nCompared to the widely-used 3D bounding box proposals, it is shown to be a\nbetter representation for 3D detection. In order to inversely project the\npredicted 2D structured polygon to a cuboid in the 3D physical world, the\nfollowing depth recovery task uses the object height prior to complete the\ninverse projection transformation with the given camera projection matrix.\nMoreover, a fine-grained 3D box refinement scheme is proposed to further\nrectify the 3D detection results. Experiments are conducted on the challenging\nKITTI benchmark, in which our method achieves state-of-the-art detection\naccuracy.",
          "link": "http://arxiv.org/abs/2002.01619",
          "publishedOn": "2021-06-10T01:56:46.624Z",
          "wordCount": 655,
          "title": "Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation. (arXiv:2002.01619v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05241",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1\">Fabian Falck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Haoting Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1\">George Nicholson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1\">Christopher Yau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Christopher C Holmes</a>",
          "description": "Work in deep clustering focuses on finding a single partition of data.\nHowever, high-dimensional data, such as images, typically feature multiple\ninteresting characteristics one could cluster over. For example, images of\nobjects against a background could be clustered over the shape of the object\nand separately by the colour of the background. In this paper, we introduce\nMulti-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of\nvariational autoencoders with a hierarchy of latent variables, each with a\nMixture-of-Gaussians prior, that learns multiple clusterings simultaneously,\nand is trained fully unsupervised and end-to-end. MFCVAE uses a\nprogressively-trained ladder architecture which leads to highly stable\nperformance. We provide novel theoretical results for optimising the ELBO\nanalytically with respect to the categorical variational posterior\ndistribution, and corrects earlier influential theoretical work. On image\nbenchmarks, we demonstrate that our approach separates out and clusters over\ndifferent aspects of the data in a disentangled manner. We also show other\nadvantages of our model: the compositionality of its latent space and that it\nprovides controlled generation of samples.",
          "link": "http://arxiv.org/abs/2106.05241",
          "publishedOn": "2021-06-10T01:56:46.618Z",
          "wordCount": 616,
          "title": "Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Adversarial learning has emerged as one of the successful techniques to\ncircumvent the susceptibility of existing methods against adversarial\nperturbations. However, the majority of existing defense methods are tailored\nto defend against a single category of adversarial perturbation (e.g.\n$\\ell_\\infty$-attack). In safety-critical applications, this makes these\nmethods extraneous as the attacker can adopt diverse adversaries to deceive the\nsystem. Moreover, training on multiple perturbations simultaneously\nsignificantly increases the computational overhead during training. To address\nthese challenges, we propose a novel meta-learning framework that explicitly\nlearns to generate noise to improve the model's robustness against multiple\ntypes of attacks. Its key component is Meta Noise Generator (MNG) that outputs\noptimal noise to stochastically perturb a given sample, such that it helps\nlower the error on diverse adversarial perturbations. By utilizing samples\ngenerated by MNG, we train a model by enforcing the label consistency across\nmultiple perturbations. We validate the robustness of models trained by our\nscheme on various datasets and against a wide variety of perturbations,\ndemonstrating that it significantly outperforms the baselines across multiple\nperturbations with a marginal computational cost.",
          "link": "http://arxiv.org/abs/2006.12135",
          "publishedOn": "2021-06-10T01:56:46.613Z",
          "wordCount": 657,
          "title": "Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1\">Bin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianjun Huang</a>",
          "description": "Recently, the object detection based on deep learning has proven to be\nvulnerable to adversarial patch attacks. The attackers holding a specially\ncrafted patch can hide themselves from the state-of-the-art person detectors,\ne.g., YOLO, even in the physical world. This kind of attack can bring serious\nsecurity threats, such as escaping from surveillance cameras. In this paper, we\ndeeply explore the detection problems about the adversarial patch attacks to\nthe object detection. First, we identify a leverageable signature of existing\nadversarial patches from the point of the visualization explanation. A fast\nsignature-based defense method is proposed and demonstrated to be effective.\nSecond, we design an improved patch generation algorithm to reveal the risk\nthat the signature-based way may be bypassed by the techniques emerging in the\nfuture. The newly generated adversarial patches can successfully evade the\nproposed signature-based defense. Finally, we present a novel\nsignature-independent detection method based on the internal content semantics\nconsistency rather than any attack-specific prior knowledge. The fundamental\nintuition is that the adversarial object can appear locally but disappear\nglobally in an input image. The experiments demonstrate that the\nsignature-independent method can effectively detect the existing and improved\nattacks. It has also proven to be a general method by detecting unforeseen and\neven other types of attacks without any attack-specific prior knowledge. The\ntwo proposed detection methods can be adopted in different scenarios, and we\nbelieve that combining them can offer a comprehensive protection.",
          "link": "http://arxiv.org/abs/2106.05261",
          "publishedOn": "2021-06-10T01:56:46.606Z",
          "wordCount": 681,
          "title": "We Can Always Catch You: Detecting Adversarial Patched Objects WITH or WITHOUT Signature. (arXiv:2106.05261v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.12469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1\">Mat&#xed;as Mendieta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabkhi_H/0/1/0/all/0/1\">Hamed Tabkhi</a>",
          "description": "Pedestrian path prediction is an essential topic in computer vision and video\nunderstanding. Having insight into the movement of pedestrians is crucial for\nensuring safe operation in a variety of applications including autonomous\nvehicles, social robots, and environmental monitoring. Current works in this\narea utilize complex generative or recurrent methods to capture many possible\nfutures. However, despite the inherent real-time nature of predicting future\npaths, little work has been done to explore accurate and computationally\nefficient approaches for this task. To this end, we propose a convolutional\napproach for real-time pedestrian path prediction, CARPe. It utilizes a\nvariation of Graph Isomorphism Networks in combination with an agile\nconvolutional neural network design to form a fast and accurate path prediction\napproach. Notable results in both inference speed and prediction accuracy are\nachieved, improving FPS considerably in comparison to current state-of-the-art\nmethods while delivering competitive accuracy on well-known path prediction\ndatasets.",
          "link": "http://arxiv.org/abs/2005.12469",
          "publishedOn": "2021-06-10T01:56:46.601Z",
          "wordCount": 616,
          "title": "CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path Prediction. (arXiv:2005.12469v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1\">Lukas Tuggener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1\">Thilo Stadelmann</a>",
          "description": "An implicit but pervasive hypothesis of modern computer vision research is\nthat convolutional neural network (CNN) architectures that perform better on\nImageNet will also perform better on other vision datasets. We challenge this\nhypothesis through an extensive empirical study for which we train 500 sampled\nCNN architectures on ImageNet as well as 8 other image classification datasets\nfrom a wide array of application domains. The relationship between architecture\nand performance varies wildly, depending on the datasets. For some of them, the\nperformance correlation with ImageNet is even negative. Clearly, it is not\nenough to optimize architectures solely for ImageNet when aiming for progress\nthat is relevant for all applications. Therefore, we identify two\ndataset-specific performance indicators: the cumulative width across layers as\nwell as the total depth of the network. Lastly, we show that the range of\ndataset variability covered by ImageNet can be significantly extended by adding\nImageNet subsets restricted to few classes.",
          "link": "http://arxiv.org/abs/2103.09108",
          "publishedOn": "2021-06-10T01:56:46.594Z",
          "wordCount": 615,
          "title": "Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Heng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_R/0/1/0/all/0/1\">Ruiyu Dou</a>",
          "description": "Convolutional neural networks have outperformed humans in image recognition\ntasks, but they remain vulnerable to attacks from adversarial examples. Since\nthese data are crafted by adding imperceptible noise to normal images, their\nexistence poses potential security threats to deep learning systems.\nSophisticated adversarial examples with strong attack performance can also be\nused as a tool to evaluate the robustness of a model. However, the success rate\nof adversarial attacks can be further improved in black-box environments.\nTherefore, this study combines a modified Adam gradient descent algorithm with\nthe iterative gradient-based attack method. The proposed Adam Iterative Fast\nGradient Method is then used to improve the transferability of adversarial\nexamples. Extensive experiments on ImageNet showed that the proposed method\noffers a higher attack success rate than existing iterative methods. By\nextending our method, we achieved a state-of-the-art attack success rate of\n95.0% on defense models.",
          "link": "http://arxiv.org/abs/2012.00567",
          "publishedOn": "2021-06-10T01:56:46.577Z",
          "wordCount": 604,
          "title": "Boosting Adversarial Attacks on Neural Networks with Better Optimizer. (arXiv:2012.00567v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shaowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hanwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sifei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "Estimating 3D hand and object pose from a single image is an extremely\nchallenging problem: hands and objects are often self-occluded during\ninteractions, and the 3D annotations are scarce as even humans cannot directly\nlabel the ground-truths from a single image perfectly. To tackle these\nchallenges, we propose a unified framework for estimating the 3D hand and\nobject poses with semi-supervised learning. We build a joint learning framework\nwhere we perform explicit contextual reasoning between hand and object\nrepresentations by a Transformer. Going beyond limited 3D annotations in a\nsingle image, we leverage the spatial-temporal consistency in large-scale\nhand-object videos as a constraint for generating pseudo labels in\nsemi-supervised learning. Our method not only improves hand pose estimation in\nchallenging real-world dataset, but also substantially improve the object pose\nwhich has fewer ground-truths per instance. By training with large-scale\ndiverse videos, our model also generalizes better across multiple out-of-domain\ndatasets. Project page and code: https://stevenlsw.github.io/Semi-Hand-Object",
          "link": "http://arxiv.org/abs/2106.05266",
          "publishedOn": "2021-06-10T01:56:46.570Z",
          "wordCount": 599,
          "title": "Semi-Supervised 3D Hand-Object Poses Estimation with Interactions in Time. (arXiv:2106.05266v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahanian_A/0/1/0/all/0/1\">Ali Jahanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puig_X/0/1/0/all/0/1\">Xavier Puig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonglong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "Generative models are now capable of producing highly realistic images that\nlook nearly indistinguishable from the data on which they are trained. This\nraises the question: if we have good enough generative models, do we still need\ndatasets? We investigate this question in the setting of learning\ngeneral-purpose visual representations from a black-box generative model rather\nthan directly from data. Given an off-the-shelf image generator without any\naccess to its training data, we train representations from the samples output\nby this generator. We compare several representation learning methods that can\nbe applied to this setting, using the latent space of the generator to generate\nmultiple \"views\" of the same semantic content. We show that for contrastive\nmethods, this multiview data can naturally be used to identify positive pairs\n(nearby in latent space) and negative pairs (far apart in latent space). We\nfind that the resulting representations rival those learned directly from real\ndata, but that good performance requires care in the sampling strategy applied\nand the training method. Generative models can be viewed as a compressed and\norganized copy of a dataset, and we envision a future where more and more\n\"model zoos\" proliferate while datasets become increasingly unwieldy, missing,\nor private. This paper suggests several techniques for dealing with visual\nrepresentation learning in such a future. Code is released on our project page:\nhttps://ali-design.github.io/GenRep/",
          "link": "http://arxiv.org/abs/2106.05258",
          "publishedOn": "2021-06-10T01:56:46.564Z",
          "wordCount": 660,
          "title": "Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howes_R/0/1/0/all/0/1\">Russel Howes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolhansky_B/0/1/0/all/0/1\">Brian Dolhansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>",
          "description": "This work examines the vulnerability of multimodal (image + text) models to\nadversarial threats similar to those discussed in previous literature on\nunimodal (image- or text-only) models. We introduce realistic assumptions of\npartial model knowledge and access, and discuss how these assumptions differ\nfrom the standard \"black-box\"/\"white-box\" dichotomy common in current\nliterature on adversarial attacks. Working under various levels of these\n\"gray-box\" assumptions, we develop new attack methodologies unique to\nmultimodal classification and evaluate them on the Hateful Memes Challenge\nclassification task. We find that attacking multiple modalities yields stronger\nattacks than unimodal attacks alone (inducing errors in up to 73% of cases),\nand that the unimodal image attacks on multimodal classifiers we explored were\nstronger than character-based text augmentation attacks (inducing errors on\naverage in 45% and 30% of cases, respectively).",
          "link": "http://arxiv.org/abs/2011.12902",
          "publishedOn": "2021-06-10T01:56:46.559Z",
          "wordCount": 616,
          "title": "Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption. (arXiv:2011.12902v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1\">Imon Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1\">Kavi Arya</a>",
          "description": "A user's eyes provide means for Human Computer Interaction (HCI) research as\nan important modal. The time to time scientific explorations of the eye has\nalready seen an upsurge of the benefits in HCI applications from gaze\nestimation to the measure of attentiveness of a user looking at a screen for a\ngiven time period. The eye tracking system as an assisting, interactive tool\ncan be incorporated by physically disabled individuals, fitted best for those\nwho have eyes as only a limited set of communication. The threefold objective\nof this paper is - 1. To introduce a neural network based architecture to\npredict users' gaze at 9 positions displayed in the 11.31{\\deg} visual range on\nthe screen, through a low resolution based system such as a webcam in real time\nby learning various aspects of eyes as an ocular feature set. 2.A collection of\ncoarsely supervised feature set obtained in real time which is also validated\nthrough the user case study presented in the paper for 21 individuals ( 17 men\nand 4 women ) from whom a 35k set of instances was derived with an accuracy\nscore of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability\nand underlying challenges of such systems. The experimental results verify the\nfeasibility and validity of the proposed eye gaze tracking model.",
          "link": "http://arxiv.org/abs/2106.05106",
          "publishedOn": "2021-06-10T01:56:46.553Z",
          "wordCount": 674,
          "title": "An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1804.06679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kairen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.",
          "link": "http://arxiv.org/abs/1804.06679",
          "publishedOn": "2021-06-10T01:56:46.536Z",
          "wordCount": 698,
          "title": "Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1\">Mehdi Cherti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>",
          "description": "Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws pointing to improvement of generalization and transfer with\nincreasing model and data size are incomplete and should be revised by taking\ninto account the type and proximity of the source and target data, to correctly\npredict the effect of model and data scale during pre-training on transfer.\nRemarkably, in full shot transfer to a large X-Ray chest imaging target\n(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms\nbest models pre-trained on large X-Ray chest imaging data. This indicates\npossibility to obtain high quality models for domain-specific transfer even\nwithout access to large domain-specific data, by pre-training instead on\ncomparably very large, generic source data.",
          "link": "http://arxiv.org/abs/2106.00116",
          "publishedOn": "2021-06-10T01:56:46.530Z",
          "wordCount": 742,
          "title": "Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1\">Jesse A. Livezey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1\">Ahyeon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jacob Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1\">Kristofer E. Bouchard</a>",
          "description": "Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.",
          "link": "http://arxiv.org/abs/1905.13308",
          "publishedOn": "2021-06-10T01:56:46.523Z",
          "wordCount": 732,
          "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Ho Kei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Yu-Wing Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chi-Keung Tang</a>",
          "description": "This paper presents a simple yet effective approach to modeling space-time\ncorrespondences in the context of video object segmentation. Unlike most\nexisting approaches, we establish correspondences directly between frames\nwithout re-encoding the mask features for every object, leading to a highly\nefficient and robust framework. With the correspondences, every node in the\ncurrent query frame is inferred by aggregating features from the past in an\nassociative fashion. We cast the aggregation process as a voting problem and\nfind that the existing inner-product affinity leads to poor use of memory with\na small (fixed) subset of memory nodes dominating the votes, regardless of the\nquery. In light of this phenomenon, we propose using the negative squared\nEuclidean distance instead to compute the affinities. We validated that every\nmemory node now has a chance to contribute, and experimentally showed that such\ndiversified voting is beneficial to both memory efficiency and inference\naccuracy. The synergy of correspondence networks and diversified voting works\nexceedingly well, achieves new state-of-the-art results on both DAVIS and\nYouTubeVOS datasets while running significantly faster at 20+ FPS for multiple\nobjects without bells and whistles.",
          "link": "http://arxiv.org/abs/2106.05210",
          "publishedOn": "2021-06-10T01:56:46.517Z",
          "wordCount": 628,
          "title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation. (arXiv:2106.05210v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zihang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1\">Qibin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Daquan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yujun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Anran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "In this paper, we present token labeling -- a new training objective for\ntraining high-performance vision transformers (ViTs). Different from the\nstandard training objective of ViTs that computes the classification loss on an\nadditional trainable class token, our proposed one takes advantage of all the\nimage patch tokens to compute the training loss in a dense manner.\nSpecifically, token labeling reformulates the image classification problem into\nmultiple token-level recognition problems and assigns each patch token with an\nindividual location-specific supervision generated by a machine annotator.\nExperiments show that token labeling can clearly and consistently improve the\nperformance of various ViT models across a wide spectrum. For a vision\ntransformer with 26M learnable parameters serving as an example, with token\nlabeling, the model can achieve 84.4% Top-1 accuracy on ImageNet. The result\ncan be further increased to 86.4% by slightly scaling the model size up to\n150M, delivering the minimal-sized model among previous models (250M+) reaching\n86%. We also show that token labeling can clearly improve the generalization\ncapability of the pre-trained models on downstream tasks with dense prediction,\nsuch as semantic segmentation. Our code and all the training details will be\nmade publicly available at https://github.com/zihangJiang/TokenLabeling.",
          "link": "http://arxiv.org/abs/2104.10858",
          "publishedOn": "2021-06-10T01:56:46.511Z",
          "wordCount": 679,
          "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers. (arXiv:2104.10858v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1\">Guy Gaziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1\">Michal Irani</a>",
          "description": "In the past few years, significant advancements were made in reconstruction\nof observed natural images from fMRI brain recordings using deep-learning\ntools. Here, for the first time, we show that dense 3D depth maps of observed\n2D natural images can also be recovered directly from fMRI brain recordings. We\nuse an off-the-shelf method to estimate the unknown depth maps of natural\nimages. This is applied to both: (i) the small number of images presented to\nsubjects in an fMRI scanner (images for which we have fMRI recordings -\nreferred to as \"paired\" data), and (ii) a very large number of natural images\nwith no fMRI recordings (\"unpaired data\"). The estimated depth maps are then\nused as an auxiliary reconstruction criterion to train for depth reconstruction\ndirectly from fMRI. We propose two main approaches: Depth-only recovery and\njoint image-depth RGBD recovery. Because the number of available \"paired\"\ntraining data (images with fMRI) is small, we enrich the training data via\nself-supervised cycle-consistent training on many \"unpaired\" data (natural\nimages & depth maps without fMRI). This is achieved using our newly defined and\ntrained Depth-based Perceptual Similarity metric as a reconstruction criterion.\nWe show that predicting the depth map directly from fMRI outperforms its\nindirect sequential recovery from the reconstructed images. We further show\nthat activations from early cortical visual areas dominate our depth\nreconstruction results, and propose means to characterize fMRI voxels by their\ndegree of depth-information tuning. This work adds an important layer of\ndecoded information, extending the current envelope of visual brain decoding\ncapabilities.",
          "link": "http://arxiv.org/abs/2106.05113",
          "publishedOn": "2021-06-10T01:56:46.494Z",
          "wordCount": 696,
          "title": "More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2001.05849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_Z/0/1/0/all/0/1\">Zohreh Shaghaghian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_W/0/1/0/all/0/1\">Wei Yan</a>",
          "description": "Most design methods contain a forward framework, asking for primary\nspecifications of a building to generate an output or assess its performance.\nHowever, architects urge for specific objectives though uncertain of the proper\ndesign parameters. Deep Learning (DL) algorithms provide an intelligent\nworkflow in which the system can learn from sequential training experiments.\nThis study applies a method using DL algorithms towards generating demanded\ndesign options. In this study, an object recognition problem is investigated to\ninitially predict the label of unseen sample images based on training dataset\nconsisting of different types of synthetic 2D shapes; later, a generative DL\nalgorithm is applied to be trained and generate new shapes for given labels. In\nthe next step, the algorithm is trained to generate a window/wall pattern for\ndesired light/shadow performance based on the spatial daylight autonomy (sDA)\nmetrics. The experiments show promising results both in predicting unseen\nsample shapes and generating new design options.",
          "link": "http://arxiv.org/abs/2001.05849",
          "publishedOn": "2021-06-10T01:56:46.487Z",
          "wordCount": 637,
          "title": "Application of Deep Learning in Generating Desired Design Options: Experiments Using Synthetic Training Dataset. (arXiv:2001.05849v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1\">Jing Yu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>",
          "description": "The output of text-to-image synthesis systems should be coherent, clear,\nphoto-realistic scenes with high semantic fidelity to their conditioned text\ndescriptions. Our Cross-Modal Contrastive Generative Adversarial Network\n(XMC-GAN) addresses this challenge by maximizing the mutual information between\nimage and text. It does this via multiple contrastive losses which capture\ninter-modality and intra-modality correspondences. XMC-GAN uses an attentional\nself-modulation generator, which enforces strong text-image correspondence, and\na contrastive discriminator, which acts as a critic as well as a feature\nencoder for contrastive learning. The quality of XMC-GAN's output is a major\nstep up from previous models, as we show on three challenging datasets. On\nMS-COCO, not only does XMC-GAN improve state-of-the-art FID from 24.70 to 9.33,\nbut--more importantly--people prefer XMC-GAN by 77.3 for image quality and 74.1\nfor image-text alignment, compared to three other recent models. XMC-GAN also\ngeneralizes to the challenging Localized Narratives dataset (which has longer,\nmore detailed descriptions), improving state-of-the-art FID from 48.70 to\n14.12. Lastly, we train and evaluate XMC-GAN on the challenging Open Images\ndata, establishing a strong benchmark FID score of 26.91.",
          "link": "http://arxiv.org/abs/2101.04702",
          "publishedOn": "2021-06-10T01:56:46.481Z",
          "wordCount": 659,
          "title": "Cross-Modal Contrastive Learning for Text-to-Image Generation. (arXiv:2101.04702v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Daoxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>",
          "description": "Instance segmentation can detect where the objects are in an image, but hard\nto understand the relationship between them. We pay attention to a typical\nrelationship, relative saliency. A closely related task, salient object\ndetection, predicts a binary map highlighting a visually salient region while\nhard to distinguish multiple objects. Directly combining two tasks by\npost-processing also leads to poor performance. There is a lack of research on\nrelative saliency at present, limiting the practical applications such as\ncontent-aware image cropping, video summary, and image labeling.\n\nIn this paper, we study the Salient Object Ranking (SOR) task, which manages\nto assign a ranking order of each detected object according to its visual\nsaliency. We propose the first end-to-end framework of the SOR task and solve\nit in a multi-task learning fashion. The framework handles instance\nsegmentation and salient object ranking simultaneously. In this framework, the\nSOR branch is independent and flexible to cooperate with different detection\nmethods, so that easy to use as a plugin. We also introduce a\nPosition-Preserved Attention (PPA) module tailored for the SOR branch. It\nconsists of the position embedding stage and feature interaction stage.\nConsidering the importance of position in saliency comparison, we preserve\nabsolute coordinates of objects in ROI pooling operation and then fuse\npositional information with semantic features in the first stage. In the\nfeature interaction stage, we apply the attention mechanism to obtain\nproposals' contextualized representations to predict their relative ranking\norders. Extensive experiments have been conducted on the ASR dataset. Without\nbells and whistles, our proposed method outperforms the former state-of-the-art\nmethod significantly. The code will be released publicly available.",
          "link": "http://arxiv.org/abs/2106.05047",
          "publishedOn": "2021-06-10T01:56:46.473Z",
          "wordCount": 703,
          "title": "Salient Object Ranking with Position-Preserved Attention. (arXiv:2106.05047v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Guolei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Le Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhatkuli_A/0/1/0/all/0/1\">Ajad Chhatkuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "We tackle the low-efficiency flaw of vision transformer caused by the high\ncomputational/space complexity in Multi-Head Self-Attention (MHSA). To this\nend, we propose the Hierarchical MHSA (H-MHSA), whose representation is\ncomputed in a hierarchical manner. Specifically, our H-MHSA first learns\nfeature relationships within small grids by viewing image patches as tokens.\nThen, small grids are merged into larger ones, within which feature\nrelationship is learned by viewing each small grid at the preceding step as a\ntoken. This process is iterated to gradually reduce the number of tokens. The\nH-MHSA module is readily pluggable into any CNN architectures and amenable to\ntraining via backpropagation. We call this new backbone TransCNN, and it\nessentially inherits the advantages of both transformer and CNN. Experiments\ndemonstrate that TransCNN achieves state-of-the-art accuracy for image\nrecognition. Code and pretrained models are available at\nhttps://github.com/yun-liu/TransCNN. This technical report will keep updating\nby adding more experiments.",
          "link": "http://arxiv.org/abs/2106.03180",
          "publishedOn": "2021-06-10T01:56:46.466Z",
          "wordCount": 596,
          "title": "Transformer in Convolutional Neural Networks. (arXiv:2106.03180v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zakka_K/0/1/0/all/0/1\">Kevin Zakka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Andy Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1\">Pete Florence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1\">Jonathan Tompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1\">Debidatta Dwibedi</a>",
          "description": "We investigate the visual cross-embodiment imitation setting, in which agents\nlearn policies from videos of other agents (such as humans) demonstrating the\nsame task, but with stark differences in their embodiments -- shape, actions,\nend-effector dynamics, etc. In this work, we demonstrate that it is possible to\nautomatically discover and learn vision-based reward functions from\ncross-embodiment demonstration videos that are robust to these differences.\nSpecifically, we present a self-supervised method for Cross-embodiment Inverse\nReinforcement Learning (XIRL) that leverages temporal cycle-consistency\nconstraints to learn deep visual embeddings that capture task progression from\noffline videos of demonstrations across multiple expert agents, each performing\nthe same task differently due to embodiment differences. Prior to our work,\nproducing rewards from self-supervised embeddings has typically required\nalignment with a reference trajectory, which may be difficult to acquire. We\nshow empirically that if the embeddings are aware of task-progress, simply\ntaking the negative distance between the current state and goal state in the\nlearned embedding space is useful as a reward for training policies with\nreinforcement learning. We find our learned reward function not only works for\nembodiments seen during training, but also generalizes to entirely new\nembodiments. We also find that XIRL policies are more sample efficient than\nbaselines, and in some cases exceed the sample efficiency of the same agent\ntrained with ground truth sparse rewards.",
          "link": "http://arxiv.org/abs/2106.03911",
          "publishedOn": "2021-06-10T01:56:46.449Z",
          "wordCount": 656,
          "title": "XIRL: Cross-embodiment Inverse Reinforcement Learning. (arXiv:2106.03911v1 [cs.RO] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10611",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1\">Diptodip Deb</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1\">Zhenfei Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1\">Alex B. Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1\">Misha B. Ahrens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1\">Kaspar Podgorski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1\">Srinivas C. Turaga</a>",
          "description": "3D snapshot microscopy enables fast volumetric imaging by capturing a 3D\nvolume in a single 2D camera image, and has found a variety of biological\napplications such as whole brain imaging of fast neural activity in larval\nzebrafish. The optimal microscope design for this optical 3D-to-2D encoding is\nboth sample- and task-dependent, with no general solution known. Highly\nprogrammable optical elements create new possibilities for sample-specific\ncomputational optimization of microscope parameters, e.g. tuning the collection\nof light for a given sample structure. We perform such optimization with deep\nlearning, using a differentiable wave-optics simulation of light propagation\nthrough a programmable microscope and a neural network to reconstruct volumes\nfrom the microscope image. We introduce a class of global kernel Fourier\nconvolutional neural networks which can efficiently decode information from\nmultiple depths in the volume, globally encoded across a 3D snapshot image. We\nshow that our proposed networks succeed in large field of view volume\nreconstruction and microscope parameter optimization where traditional networks\nfail. We also show that our networks outperform the state-of-the-art learned\nreconstruction algorithms for lensless computational photography.",
          "link": "http://arxiv.org/abs/2104.10611",
          "publishedOn": "2021-06-10T01:56:46.444Z",
          "wordCount": 656,
          "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Lintao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_L/0/1/0/all/0/1\">Liheng Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tiexin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>",
          "description": "Wide-field and high-resolution (HR) imaging is essential for various\napplications such as aviation reconnaissance, topographic mapping and safety\nmonitoring. The existing techniques require a large-scale detector array to\ncapture HR images of the whole field, resulting in high complexity and heavy\ncost. In this work, we report an agile wide-field imaging framework with\nselective high resolution that requires only two detectors. It builds on the\nstatistical sparsity prior of natural scenes that the important targets locate\nonly at small regions of interests (ROI), instead of the whole field. Under\nthis assumption, we use a short-focal camera to image wide field with a certain\nlow resolution, and use a long-focal camera to acquire the HR images of ROI. To\nautomatically locate ROI in the wide field in real time, we propose an\nefficient deep-learning based multiscale registration method that is robust and\nblind to the large setting differences (focal, white balance, etc) between the\ntwo cameras. Using the registered location, the long-focal camera mounted on a\ngimbal enables real-time tracking of the ROI for continuous HR imaging. We\ndemonstrated the novel imaging framework by building a proof-of-concept setup\nwith only 1181 gram weight, and assembled it on an unmanned aerial vehicle for\nair-to-ground monitoring. Experiments show that the setup maintains\n120$^{\\circ}$ wide field-of-view (FOV) with selective 0.45$mrad$ instantaneous\nFOV.",
          "link": "http://arxiv.org/abs/2106.05082",
          "publishedOn": "2021-06-10T01:56:46.438Z",
          "wordCount": 653,
          "title": "Agile wide-field imaging with selective high resolution. (arXiv:2106.05082v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guanchen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenwei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kangmin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanping Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenzhong Chen</a>",
          "description": "Traffic anomaly detection has played a crucial role in Intelligent\nTransportation System (ITS). The main challenges of this task lie in the highly\ndiversified anomaly scenes and variational lighting conditions. Although much\nwork has managed to identify the anomaly in homogenous weather and scene, few\nresolved to cope with complex ones. In this paper, we proposed a dual-modality\nmodularized methodology for the robust detection of abnormal vehicles. We\nintroduced an integrated anomaly detection framework comprising the following\nmodules: background modeling, vehicle tracking with detection, mask\nconstruction, Region of Interest (ROI) backtracking, and dual-modality tracing.\nConcretely, we employed background modeling to filter the motion information\nand left the static information for later vehicle detection. For the vehicle\ndetection and tracking module, we adopted YOLOv5 and multi-scale tracking to\nlocalize the anomalies. Besides, we utilized the frame difference and tracking\nresults to identify the road and obtain the mask. In addition, we introduced\nmultiple similarity estimation metrics to refine the anomaly period via\nbacktracking. Finally, we proposed a dual-modality bilateral tracing module to\nrefine the time further. The experiments conducted on the Track 4 testset of\nthe NVIDIA 2021 AI City Challenge yielded a result of 0.9302 F1-Score and\n3.4039 root mean square error (RMSE), indicating the effectiveness of our\nframework.",
          "link": "http://arxiv.org/abs/2106.05003",
          "publishedOn": "2021-06-10T01:56:46.432Z",
          "wordCount": 664,
          "title": "Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing. (arXiv:2106.05003v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zilin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Traditional self-supervised learning requires CNNs using external pretext\ntasks (i.e., image- or video-based tasks) to encode high-level semantic visual\nrepresentations. In this paper, we show that feature transformations within\nCNNs can also be regarded as supervisory signals to construct the\nself-supervised task, called \\emph{internal pretext task}. And such a task can\nbe applied for the enhancement of supervised learning. Specifically, we first\ntransform the internal feature maps by discarding different channels, and then\ndefine an additional internal pretext task to identify the discarded channels.\nCNNs are trained to predict the joint labels generated by the combination of\nself-supervised labels and original labels. By doing so, we let CNNs know which\nchannels are missing while classifying in the hope to mine richer feature\ninformation. Extensive experiments show that our approach is effective on\nvarious models and datasets. And it's worth noting that we only incur\nnegligible computational overhead. Furthermore, our approach can also be\ncompatible with other methods to get better results.",
          "link": "http://arxiv.org/abs/2106.04921",
          "publishedOn": "2021-06-10T01:56:46.426Z",
          "wordCount": 597,
          "title": "Self-supervised Feature Enhancement: Applying Internal Pretext Task to Supervised Learning. (arXiv:2106.04921v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sederholm_T/0/1/0/all/0/1\">Tina Sederholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roman_A/0/1/0/all/0/1\">Anthony C. Roman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_R/0/1/0/all/0/1\">Ria Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caltagirone_S/0/1/0/all/0/1\">Sherrie Caltagirone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "Child trafficking in a serious problem around the world. Every year there are\nmore than 4 million victims of child trafficking around the world, many of them\nfor the purposes of child sexual exploitation. In collaboration with UK Police\nand a non-profit focused on child abuse prevention, Global Emancipation\nNetwork, we developed a proof-of-concept machine learning pipeline to aid the\nidentification of children from intercepted images. In this work, we focus on\nimages that contain children wearing school uniforms to identify the school of\norigin. In the absence of a machine learning pipeline, this hugely time\nconsuming and labor intensive task is manually conducted by law enforcement\npersonnel. Thus, by automating aspects of the school identification process, we\nhope to significantly impact the speed of this portion of child identification.\nOur proposed pipeline consists of two machine learning models: i) to identify\nwhether an image of a child contains a school uniform in it, and ii)\nidentification of attributes of different school uniform items (such as\ncolor/texture of shirts, sweaters, blazers etc.). We describe the data\ncollection, labeling, model development and validation process, along with\nstrategies for efficient searching of schools using the model predictions.",
          "link": "http://arxiv.org/abs/2106.05215",
          "publishedOn": "2021-06-10T01:56:46.410Z",
          "wordCount": 638,
          "title": "A machine learning pipeline for aiding school identification from child trafficking images. (arXiv:2106.05215v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Sosa_E/0/1/0/all/0/1\">E. Gonzalez-Sosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robledo_G/0/1/0/all/0/1\">G. Robledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Morin_D/0/1/0/all/0/1\">D. Gonzalez-Morin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Garcia_P/0/1/0/all/0/1\">P. Perez-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villegas_A/0/1/0/all/0/1\">A. Villegas</a>",
          "description": "Egocentric segmentation has attracted recent interest in the computer vision\ncommunity due to their potential in Mixed Reality (MR) applications. While most\nprevious works have been focused on segmenting egocentric human body parts\n(mainly hands), little attention has been given to egocentric objects. Due to\nthe lack of datasets of pixel-wise annotations of egocentric objects, in this\npaper we contribute with a semantic-wise labeling of a subset of 2124 images\nfrom the RGB-D THU-READ Dataset. We also report benchmarking results using\nThundernet, a real-time semantic segmentation network, that could allow future\nintegration with end-to-end MR applications.",
          "link": "http://arxiv.org/abs/2106.04957",
          "publishedOn": "2021-06-10T01:56:46.405Z",
          "wordCount": 539,
          "title": "Real Time Egocentric Object Segmentation: THU-READ Labeling and Benchmarking Results. (arXiv:2106.04957v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05132",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ciano_G/0/1/0/all/0/1\">Giorgio Ciano</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Andreini_P/0/1/0/all/0/1\">Paolo Andreini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mazzierli_T/0/1/0/all/0/1\">Tommaso Mazzierli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bianchini_M/0/1/0/all/0/1\">Monica Bianchini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scarselli_F/0/1/0/all/0/1\">Franco Scarselli</a>",
          "description": "Multi-organ segmentation of X-ray images is of fundamental importance for\ncomputer aided diagnosis systems. However, the most advanced semantic\nsegmentation methods rely on deep learning and require a huge amount of labeled\nimages, which are rarely available due to both the high cost of human resources\nand the time required for labeling. In this paper, we present a novel\nmulti-stage generation algorithm based on Generative Adversarial Networks\n(GANs) that can produce synthetic images along with their semantic labels and\ncan be used for data augmentation. The main feature of the method is that,\nunlike other approaches, generation occurs in several stages, which simplifies\nthe procedure and allows it to be used on very small datasets. The method has\nbeen evaluated on the segmentation of chest radiographic images, showing\npromising results. The multistage approach achieves state-of-the-art and, when\nvery few images are used to train the GANs, outperforms the corresponding\nsingle-stage approach.",
          "link": "http://arxiv.org/abs/2106.05132",
          "publishedOn": "2021-06-10T01:56:46.399Z",
          "wordCount": 598,
          "title": "A multi-stage GAN for multi-organ chest X-ray image generation and segmentation. (arXiv:2106.05132v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lihe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1\">Wei Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yinghuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "In this paper, we investigate if we could make the self-training -- a simple\nbut popular framework -- work better for semi-supervised segmentation. Since\nthe core issue in semi-supervised setting lies in effective and efficient\nutilization of unlabeled data, we notice that increasing the diversity and\nhardness of unlabeled data is crucial to performance improvement. Being aware\nof this fact, we propose to adopt the most plain self-training scheme coupled\nwith appropriate strong data augmentations on unlabeled data (namely ST) for\nthis task, which surprisingly outperforms previous methods under various\nsettings without any bells and whistles. Moreover, to alleviate the negative\nimpact of the wrongly pseudo labeled images, we further propose an advanced\nself-training framework (namely ST++), that performs selective re-training via\nselecting and prioritizing the more reliable unlabeled images. As a result, the\nproposed ST++ boosts the performance of semi-supervised model significantly and\nsurpasses existing methods by a large margin on the Pascal VOC 2012 and\nCityscapes benchmark. Overall, we hope this straightforward and simple\nframework will serve as a strong baseline or competitor for future works. Code\nis available at https://github.com/LiheYoung/ST-PlusPlus.",
          "link": "http://arxiv.org/abs/2106.05095",
          "publishedOn": "2021-06-10T01:56:46.394Z",
          "wordCount": 624,
          "title": "ST++: Make Self-training Work Better for Semi-supervised Semantic Segmentation. (arXiv:2106.05095v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1\">Benjamin Walter</a>",
          "description": "Image classification is considered, and a hierarchical max-pooling model with\nadditional local pooling is introduced. Here the additional local pooling\nenables the hierachical model to combine parts of the image which have a\nvariable relative distance towards each other. Various convolutional neural\nnetwork image classifiers are introduced and compared in view of their rate of\nconvergence. The finite sample size performance of the estimates is analyzed by\napplying them to simulated and real data.",
          "link": "http://arxiv.org/abs/2106.05233",
          "publishedOn": "2021-06-10T01:56:46.388Z",
          "wordCount": 529,
          "title": "Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "In this paper, we explore and evaluate the use of ranking-based objective\nfunctions for learning simultaneously a word string and a word image encoder.\nWe consider retrieval frameworks in which the user expects a retrieval list\nranked according to a defined relevance score. In the context of a word\nspotting problem, the relevance score has been set according to the string edit\ndistance from the query string. We experimentally demonstrate the competitive\nperformance of the proposed model on query-by-string word spotting for both,\nhandwritten and real scene word images. We also provide the results for\nquery-by-example word spotting, although it is not the main focus of this work.",
          "link": "http://arxiv.org/abs/2106.05144",
          "publishedOn": "2021-06-10T01:56:46.373Z",
          "wordCount": 552,
          "title": "Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>",
          "description": "Knowledge distillation constitutes a simple yet effective way to improve the\nperformance of a compact student network by exploiting the knowledge of a more\npowerful teacher. Nevertheless, the knowledge distillation literature remains\nlimited to the scenario where the student and the teacher tackle the same task.\nHere, we investigate the problem of transferring knowledge not only across\narchitectures but also across tasks. To this end, we study the case of object\ndetection and, instead of following the standard detector-to-detector\ndistillation approach, introduce a classifier-to-detector knowledge transfer\nframework. In particular, we propose strategies to exploit the classification\nteacher to improve both the detector's recognition accuracy and localization\nperformance. Our experiments on several detectors with different backbones\ndemonstrate the effectiveness of our approach, allowing us to outperform the\nstate-of-the-art detector-to-detector distillation methods.",
          "link": "http://arxiv.org/abs/2106.05209",
          "publishedOn": "2021-06-10T01:56:46.366Z",
          "wordCount": 562,
          "title": "Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chunlei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>",
          "description": "Deep neural networks (DNNs) are vulnerable to adversarial noise. Their\nadversarial robustness can be improved by exploiting adversarial examples.\nHowever, given the continuously evolving attacks, models trained on seen types\nof adversarial examples generally cannot generalize well to unseen types of\nadversarial examples. To solve this problem, in this paper, we propose to\nremove adversarial noise by learning generalizable invariant features across\nattacks which maintain semantic classification information. Specifically, we\nintroduce an adversarial feature learning mechanism to disentangle invariant\nfeatures from adversarial noise. A normalization term has been proposed in the\nencoded space of the attack-invariant features to address the bias issue\nbetween the seen and unseen types of attacks. Empirical evaluations demonstrate\nthat our method could provide better protection in comparison to previous\nstate-of-the-art approaches, especially against unseen types of attacks and\nadaptive attacks.",
          "link": "http://arxiv.org/abs/2106.05036",
          "publishedOn": "2021-06-10T01:56:46.358Z",
          "wordCount": 569,
          "title": "Towards Defending against Adversarial Examples via Attack-Invariant Features. (arXiv:2106.05036v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yancong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintea_S/0/1/0/all/0/1\">Silvia-Laura Pintea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan van Gemert</a>",
          "description": "Current work on lane detection relies on large manually annotated datasets.\nWe reduce the dependency on annotations by leveraging massive cheaply available\nunlabelled data. We propose a novel loss function exploiting geometric\nknowledge of lanes in Hough space, where a lane can be identified as a local\nmaximum. By splitting lanes into separate channels, we can localize each lane\nvia simple global max-pooling. The location of the maximum encodes the layout\nof a lane, while the intensity indicates the the probability of a lane being\npresent. Maximizing the log-probability of the maximal bins helps neural\nnetworks find lanes without labels. On the CULane and TuSimple datasets, we\nshow that the proposed Hough Transform loss improves performance significantly\nby learning from large amounts of unlabelled images.",
          "link": "http://arxiv.org/abs/2106.05094",
          "publishedOn": "2021-06-10T01:56:46.352Z",
          "wordCount": 553,
          "title": "Semi-supervised lane detection with Deep Hough Transform. (arXiv:2106.05094v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_Q/0/1/0/all/0/1\">Qinglei Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shaolin Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dexing Kong</a>",
          "description": "Accurate segmentation for medical images is important for clinical diagnosis.\nExisting automatic segmentation methods are mainly based on fully supervised\nlearning and have an extremely high demand for precise annotations, which are\nvery costly and time-consuming to obtain. To address this problem, we proposed\nan automatic CT segmentation method based on weakly supervised learning, by\nwhich one could train an accurate segmentation model only with weak annotations\nin the form of bounding boxes. The proposed method is composed of two steps: 1)\ngenerating pseudo masks with bounding box annotations by k-means clustering,\nand 2) iteratively training a 3D U-Net convolutional neural network as a\nsegmentation model. Some data pre-processing methods are used to improve\nperformance. The method was validated on four datasets containing three types\nof organs with a total of 627 CT volumes. For liver, spleen and kidney\nsegmentation, it achieved an accuracy of 95.19%, 92.11%, and 91.45%,\nrespectively. Experimental results demonstrate that our method is accurate,\nefficient, and suitable for clinical use.",
          "link": "http://arxiv.org/abs/2105.14314",
          "publishedOn": "2021-06-10T01:56:46.347Z",
          "wordCount": 627,
          "title": "Automatic CT Segmentation from Bounding Box Annotations using Convolutional Neural Networks. (arXiv:2105.14314v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05152",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Hengyue Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Transfer learning (TL) with deep convolutional neural networks (DCNNs) has\nproved successful in medical image classification (MIC). However, the current\npractice is puzzling, as MIC typically relies only on low- and/or mid-level\nfeatures that are learned in the bottom layers of DCNNs. Following this\nintuition, we question the current strategies of TL in MIC. In this paper, we\nperform careful experimental comparisons between shallow and deep networks for\nclassification on two chest x-ray datasets, using different TL strategies. We\nfind that deep models are not always favorable, and finetuning truncated deep\nmodels almost always yields the best performance, especially in data-poor\nregimes.\n\nProject webpage:\nhttps://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging\n\nKeywords: Transfer learning, Medical image classification, Feature hierarchy,\nMedical imaging, Evaluation metrics, Imbalanced data",
          "link": "http://arxiv.org/abs/2106.05152",
          "publishedOn": "2021-06-10T01:56:46.341Z",
          "wordCount": 567,
          "title": "Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1\">Javier Barbero-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pedro-Antonio Guti&#xe9;rrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1\">V&#xed;ctor-Manuel Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1\">Juan-Antonio Vallejo-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1\">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>",
          "description": "3D image scans are an assessment tool for neurological damage in Parkinson's\ndisease (PD) patients. This diagnosis process can be automatized to help\nmedical staff through Decision Support Systems (DSSs), and Convolutional Neural\nNetworks (CNNs) are good candidates, because they are effective when applied to\nspatial data. This paper proposes a 3D CNN ordinal model for assessing the\nlevel or neurological damage in PD patients. Given that CNNs need large\ndatasets to achieve acceptable performance, a data augmentation method is\nadapted to work with spatial data. We consider the Ordinal Graph-based\nOversampling via Shortest Paths (OGO-SP) method, which applies a gamma\nprobability distribution for inter-class data generation. A modification of\nOGO-SP is proposed, the OGO-SP-$\\beta$ algorithm, which applies the beta\ndistribution for generating synthetic samples in the inter-class region, a\nbetter suited distribution when compared to gamma. The evaluation of the\ndifferent methods is based on a novel 3D image dataset provided by the Hospital\nUniversitario 'Reina Sof\\'ia' (C\\'ordoba, Spain). We show how the ordinal\nmethodology improves the performance with respect to the nominal one, and how\nOGO-SP-$\\beta$ yields better performance than OGO-SP.",
          "link": "http://arxiv.org/abs/2106.05230",
          "publishedOn": "2021-06-10T01:56:46.324Z",
          "wordCount": 645,
          "title": "An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients. (arXiv:2106.05230v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1\">Am&#xe9;lie Royer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1\">Larisa Markeeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>",
          "description": "There is a growing discrepancy in computer vision between large-scale models\nthat achieve state-of-the-art performance and models that are affordable in\npractical applications. In this paper we address this issue and significantly\nbridge the gap between these two types of models. Throughout our empirical\ninvestigation we do not aim to necessarily propose a new method, but strive to\nidentify a robust and effective recipe for making state-of-the-art large scale\nmodels affordable in practice. We demonstrate that, when performed correctly,\nknowledge distillation can be a powerful tool for reducing the size of large\nmodels without compromising their performance. In particular, we uncover that\nthere are certain implicit design choices, which may drastically affect the\neffectiveness of distillation. Our key contribution is the explicit\nidentification of these design choices, which were not previously articulated\nin the literature. We back up our findings by a comprehensive empirical study,\ndemonstrate compelling results on a wide range of vision datasets and, in\nparticular, obtain a state-of-the-art ResNet-50 model for ImageNet, which\nachieves 82.8\\% top-1 accuracy.",
          "link": "http://arxiv.org/abs/2106.05237",
          "publishedOn": "2021-06-10T01:56:46.293Z",
          "wordCount": 623,
          "title": "Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Sheng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaiyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhe Li</a>",
          "description": "The self-attention mechanism has attracted wide publicity for its most\nimportant advantage of modeling long dependency, and its variations in computer\nvision tasks, the non-local block tries to model the global dependency of the\ninput feature maps. Gathering global contextual information will inevitably\nneed a tremendous amount of memory and computing resources, which has been\nextensively studied in the past several years. However, there is a further\nproblem with the self-attention scheme: is all information gathered from the\nglobal scope helpful for the contextual modelling? To our knowledge, few\nstudies have focused on the problem. Aimed at both questions this paper\nproposes the salient positions-based attention scheme SPANet, which is inspired\nby some interesting observations on the attention maps and affinity matrices\ngenerated in self-attention scheme. We believe these observations are\nbeneficial for better understanding of the self-attention. SPANet uses the\nsalient positions selection algorithm to select only a limited amount of\nsalient points to attend in the attention map computing. This approach will not\nonly spare a lot of memory and computing resources, but also try to distill the\npositive information from the transformation of the input feature maps. In the\nimplementation, considering the feature maps with channel high dimensions,\nwhich are completely different from the general visual image, we take the\nsquared power of the feature maps along the channel dimension as the saliency\nmetric of the positions. In general, different from the non-local block method,\nSPANet models the contextual information using only the selected positions\ninstead of all, along the channel dimension instead of space dimension. Our\nsource code is available at https://github.com/likyoo/SPANet.",
          "link": "http://arxiv.org/abs/2106.04996",
          "publishedOn": "2021-06-10T01:56:46.285Z",
          "wordCount": 695,
          "title": "Salient Positions based Attention Network for Image Classification. (arXiv:2106.04996v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1\">Diane Bouchacourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1\">Mark Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari S. Morcos</a>",
          "description": "To perform well on unseen and potentially out-of-distribution samples, it is\ndesirable for machine learning models to have a predictable response with\nrespect to transformations affecting the factors of variation of the input.\nInvariance is commonly achieved through hand-engineered data augmentation, but\ndo standard data augmentations address transformations that explain variations\nin real data? While prior work has focused on synthetic data, we attempt here\nto characterize the factors of variation in a real dataset, ImageNet, and study\nthe invariance of both standard residual networks and the recently proposed\nvision transformer with respect to changes in these factors. We show standard\naugmentation relies on a precise combination of translation and scale, with\ntranslation recapturing most of the performance improvement -- despite the\n(approximate) translation invariance built in to convolutional architectures,\nsuch as residual networks. In fact, we found that scale and translation\ninvariance was similar across residual networks and vision transformer models\ndespite their markedly different inductive biases. We show the training data\nitself is the main source of invariance, and that data augmentation only\nfurther increases the learned invariances. Interestingly, the invariances\nbrought from the training process align with the ImageNet factors of variation\nwe found. Finally, we find that the main factors of variation in ImageNet\nmostly relate to appearance and are specific to each class.",
          "link": "http://arxiv.org/abs/2106.05121",
          "publishedOn": "2021-06-10T01:56:46.277Z",
          "wordCount": 653,
          "title": "Grounding inductive biases in natural images:invariance stems from variations in data. (arXiv:2106.05121v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "A central challenge in training classification models in the real-world\nfederated system is learning with non-IID data. To cope with this, most of the\nexisting works involve enforcing regularization in local optimization or\nimproving the model aggregation scheme at the server. Other works also share\npublic datasets or synthesized samples to supplement the training of\nunder-represented classes or introduce a certain level of personalization.\nThough effective, they lack a deep understanding of how the data heterogeneity\naffects each layer of a deep classification model. In this paper, we bridge\nthis gap by performing an experimental analysis of the representations learned\nby different layers. Our observations are surprising: (1) there exists a\ngreater bias in the classifier than other layers, and (2) the classification\nperformance can be significantly improved by post-calibrating the classifier\nafter federated training. Motivated by the above findings, we propose a novel\nand simple algorithm called Classifier Calibration with Virtual Representations\n(CCVR), which adjusts the classifier using virtual representations sampled from\nan approximated gaussian mixture model. Experimental results demonstrate that\nCCVR achieves state-of-the-art performance on popular federated learning\nbenchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple\nyet effective method can shed some light on the future research of federated\nlearning with non-IID data.",
          "link": "http://arxiv.org/abs/2106.05001",
          "publishedOn": "2021-06-10T01:56:46.259Z",
          "wordCount": 666,
          "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1\">David Berthelot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alex Kurakin</a>",
          "description": "We extend semi-supervised learning to the problem of domain adaptation to\nlearn significantly higher-accuracy models that train on one data distribution\nand test on a different one. With the goal of generality, we introduce\nAdaMatch, a method that unifies the tasks of unsupervised domain adaptation\n(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation\n(SSDA). In an extensive experimental study, we compare its behavior with\nrespective state-of-the-art techniques from SSL, SSDA, and UDA on vision\nclassification tasks. We find AdaMatch either matches or significantly exceeds\nthe state-of-the-art in each case using the same hyper-parameters regardless of\nthe dataset or task. For example, AdaMatch nearly doubles the accuracy compared\nto that of the prior state-of-the-art on the UDA task for DomainNet and even\nexceeds the accuracy of the prior state-of-the-art obtained with pre-training\nby 6.4% when AdaMatch is trained completely from scratch. Furthermore, by\nproviding AdaMatch with just one labeled example per class from the target\ndomain (i.e., the SSDA setting), we increase the target accuracy by an\nadditional 6.1%, and with 5 labeled examples, by 13.6%.",
          "link": "http://arxiv.org/abs/2106.04732",
          "publishedOn": "2021-06-10T01:56:46.254Z",
          "wordCount": 616,
          "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Tracking-by-detection is a very popular framework for single object tracking\nwhich attempts to search the target object within a local search window for\neach frame. Although such local search mechanism works well on simple videos,\nhowever, it makes the trackers sensitive to extremely challenging scenarios,\nsuch as heavy occlusion and fast motion. In this paper, we propose a novel and\ngeneral target-aware attention mechanism (termed TANet) and integrate it with\ntracking-by-detection framework to conduct joint local and global search for\nrobust tracking. Specifically, we extract the features of target object patch\nand continuous video frames, then we concatenate and feed them into a decoder\nnetwork to generate target-aware global attention maps. More importantly, we\nresort to adversarial training for better attention prediction. The appearance\nand motion discriminator networks are designed to ensure its consistency in\nspatial and temporal views. In the tracking procedure, we integrate the\ntarget-aware attention with multiple trackers by exploring candidate search\nregions for robust tracking. Extensive experiments on both short-term and\nlong-term tracking benchmark datasets all validated the effectiveness of our\nalgorithm. The project page of this paper can be found at\n\\url{https://sites.google.com/view/globalattentiontracking/home/extend}.",
          "link": "http://arxiv.org/abs/2106.04840",
          "publishedOn": "2021-06-10T01:56:46.238Z",
          "wordCount": 641,
          "title": "Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04898",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Garcia_Fernandez_A/0/1/0/all/0/1\">&#xc1;ngel F. Garc&#xed;a-Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_W/0/1/0/all/0/1\">Wei Yi</a>",
          "description": "This paper derives the optimal Bayesian processing of an out-of-sequence\n(OOS) set of measurements in continuous-time for multiple target tracking. We\nconsider a multi-target system modelled in continuous time that is discretised\nat the time steps when we receive the measurements, which are distributed\naccording to the standard point target model. All information about this system\nat the sampled time steps is provided by the posterior density on the set of\nall trajectories. This density can be computed via the continuous-discrete\ntrajectory Poisson multi-Bernoulli mixture (TPMBM) filter. When we receive an\nOOS measurement, the optimal Bayesian processing performs a retrodiction step\nthat adds trajectory information at the OOS measurement time stamp followed by\nan update step. After the OOS measurement update, the posterior remains in\nTPMBM form. We also provide a computationally lighter alternative based on a\ntrajectory Poisson multi-Bernoulli filter. The effectiveness of the two\napproaches to handle OOS measurements is evaluated via simulations.",
          "link": "http://arxiv.org/abs/2106.04898",
          "publishedOn": "2021-06-10T01:56:46.228Z",
          "wordCount": 589,
          "title": "Continuous-discrete multiple target tracking with out-of-sequence measurements. (arXiv:2106.04898v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1\">Shashanka Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1\">Bill Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1\">Ewa Kijak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1\">Laurent Amsaleg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1\">Konstantinos Karantzalos</a>",
          "description": "Metric learning involves learning a discriminative representation such that\nembeddings of similar classes are encouraged to be close, while embeddings of\ndissimilar classes are pushed far apart. State-of-the-art methods focus mostly\non sophisticated loss functions or mining strategies. On the one hand, metric\nlearning losses consider two or more examples at a time. On the other hand,\nmodern data augmentation methods for classification consider two or more\nexamples at a time. The combination of the two ideas is under-studied.\n\nIn this work, we aim to bridge this gap and improve representations using\nmixup, which is a powerful data augmentation approach interpolating two or more\nexamples and corresponding target labels at a time. This task is challenging\nbecause, unlike classification, the loss functions used in metric learning are\nnot additive over examples, so the idea of interpolating target labels is not\nstraightforward. To the best of our knowledge, we are the first to investigate\nmixing examples and target labels for deep metric learning. We develop a\ngeneralized formulation that encompasses existing metric learning loss\nfunctions and modify it to accommodate for mixup, introducing Metric Mix, or\nMetrix. We show that mixing inputs, intermediate representations or embeddings\nalong with target labels significantly improves representations and outperforms\nstate-of-the-art metric learning methods on four benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.04990",
          "publishedOn": "2021-06-10T01:56:46.222Z",
          "wordCount": 651,
          "title": "It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lengyel_A/0/1/0/all/0/1\">Attila Lengyel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "Group Equivariant Convolutions (GConvs) enable convolutional neural networks\nto be equivariant to various transformation groups, but at an additional\nparameter and compute cost. We investigate the filter parameters learned by\nGConvs and find certain conditions under which they become highly redundant. We\nshow that GConvs can be efficiently decomposed into depthwise separable\nconvolutions while preserving equivariance properties and demonstrate improved\nperformance and data efficiency on two datasets. All code is publicly available\nat github.com/Attila94/SepGrouPy.",
          "link": "http://arxiv.org/abs/2106.04914",
          "publishedOn": "2021-06-10T01:56:46.215Z",
          "wordCount": 502,
          "title": "Exploiting Learned Symmetries in Group Equivariant Convolutions. (arXiv:2106.04914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jinka_S/0/1/0/all/0/1\">Sai Sagar Jinka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chacko_R/0/1/0/all/0/1\">Rohan Chacko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Astitva Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Avinash Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1\">P.J. Narayanan</a>",
          "description": "3D human body reconstruction from monocular images is an interesting and\nill-posed problem in computer vision with wider applications in multiple\ndomains. In this paper, we propose SHARP, a novel end-to-end trainable network\nthat accurately recovers the detailed geometry and appearance of 3D people in\nloose clothing from a monocular image. We propose a sparse and efficient fusion\nof a parametric body prior with a non-parametric peeled depth map\nrepresentation of clothed models. The parametric body prior constraints our\nmodel in two ways: first, the network retains geometrically consistent body\nparts that are not occluded by clothing, and second, it provides a body shape\ncontext that improves prediction of the peeled depth maps. This enables SHARP\nto recover fine-grained 3D geometrical details with just L1 losses on the 2D\nmaps, given an input image. We evaluate SHARP on publicly available Cloth3D and\nTHuman datasets and report superior performance to state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.04778",
          "publishedOn": "2021-06-10T01:56:46.198Z",
          "wordCount": 583,
          "title": "SHARP: Shape-Aware Reconstruction of People In Loose Clothing. (arXiv:2106.04778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04961",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1\">Kai-Chieh Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1\">Lei Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Ashnil Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1\">Michael Fulham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jinman Kim</a>",
          "description": "Sequential whole-body 18F-Fluorodeoxyglucose (FDG) positron emission\ntomography (PET) scans are regarded as the imaging modality of choice for the\nassessment of treatment response in the lymphomas because they detect treatment\nresponse when there may not be changes on anatomical imaging. Any computerized\nanalysis of lymphomas in whole-body PET requires automatic segmentation of the\nstudies so that sites of disease can be quantitatively monitored over time.\nState-of-the-art PET image segmentation methods are based on convolutional\nneural networks (CNNs) given their ability to leverage annotated datasets to\nderive high-level features about the disease process. Such methods, however,\nfocus on PET images from a single time-point and discard information from other\nscans or are targeted towards specific organs and cannot cater for the multiple\nstructures in whole-body PET images. In this study, we propose a\nspatio-temporal 'dual-stream' neural network (ST-DSNN) to segment sequential\nwhole-body PET scans. Our ST-DSNN learns and accumulates image features from\nthe PET images done over time. The accumulated image features are used to\nenhance the organs / structures that are consistent over time to allow easier\nidentification of sites of active lymphoma. Our results show that our method\noutperforms the state-of-the-art PET image segmentation methods.",
          "link": "http://arxiv.org/abs/2106.04961",
          "publishedOn": "2021-06-10T01:56:46.192Z",
          "wordCount": 641,
          "title": "Spatio-Temporal Dual-Stream Neural Network for Sequential Whole-Body PET Segmentation. (arXiv:2106.04961v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingxing Tan</a>",
          "description": "Transformers have attracted increasing interests in computer vision, but they\nstill fall behind state-of-the-art convolutional networks. In this work, we\nshow that while Transformers tend to have larger model capacity, their\ngeneralization can be worse than convolutional networks due to the lack of the\nright inductive bias. To effectively combine the strengths from both\narchitectures, we present CoAtNets(pronounced \"coat\" nets), a family of hybrid\nmodels built from two key insights:(1) depthwise Convolution and self-Attention\ncan be naturally unified via simple relative attention; (2) vertically stacking\nconvolution layers and attention layers in a principled way is surprisingly\neffective in improving generalization, capacity and efficiency. Experiments\nshow that our CoAtNets achieve state-of-the-art performance under different\nresource constraints across various datasets. For example, CoAtNet achieves\n86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT\ndata, outperforming prior arts of both convolutional networks and Transformers.\nNotably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet\nachieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images\nfrom JFT while using 23x less data.",
          "link": "http://arxiv.org/abs/2106.04803",
          "publishedOn": "2021-06-10T01:56:46.027Z",
          "wordCount": 607,
          "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1\">Kiran Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1\">Gautam Kishore Shahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1\">Devin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "WhatsApp is a popular chat application used by over 2 billion users\nworldwide. However, due to end-to-end encryption, there is currently no easy\nway to fact-check content on WhatsApp at scale. In this paper, we analyze the\nusefulness of a crowd-sourced system on WhatsApp through which users can submit\n\"tips\" containing messages they want fact-checked. We compare the tips sent to\na WhatsApp tipline run during the 2019 Indian national elections with the\nmessages circulating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, the\nanalysis suggests tiplines can be an effective source for discovering content\nto fact-check.",
          "link": "http://arxiv.org/abs/2106.04726",
          "publishedOn": "2021-06-10T01:56:45.993Z",
          "wordCount": 635,
          "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1\">Matej Grci&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Normalizing flows are bijective mappings between inputs and latent\nrepresentations with a fully factorized distribution. They are very attractive\ndue to exact likelihood evaluation and efficient sampling. However, their\neffective capacity is often insufficient since the bijectivity constraint\nlimits the model width. We address this issue by incrementally padding\nintermediate representations with noise. We precondition the noise in\naccordance with previous invertible units, which we describe as cross-unit\ncoupling. Our invertible glow-like modules express intra-unit affine coupling\nas a fusion of a densely connected block and Nystr\\\"om self-attention. We refer\nto our architecture as DenseFlow since both cross-unit and intra-unit couplings\nrely on dense connectivity. Experiments show significant improvements due to\nthe proposed contributions, and reveal state-of-the-art density estimation\namong all generative models under moderate computing budgets.",
          "link": "http://arxiv.org/abs/2106.04627",
          "publishedOn": "2021-06-10T01:56:45.957Z",
          "wordCount": 551,
          "title": "Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baoyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>",
          "description": "Face recognition has made significant progress in recent years due to deep\nconvolutional neural networks (CNN). In many face recognition (FR) scenarios,\nface images are acquired from a sequence with huge intra-variations. These\nintra-variations, which are mainly affected by the low-quality face images,\ncause instability of recognition performance. Previous works have focused on\nad-hoc methods to select frames from a video or use face image quality\nassessment (FIQA) methods, which consider only a particular or combination of\nseveral distortions.\n\nIn this work, we present an efficient non-reference image quality assessment\nfor FR that directly links image quality assessment (IQA) and FR. More\nspecifically, we propose a new measurement to evaluate image quality without\nany reference. Based on the proposed quality measurement, we propose a deep\nTiny Face Quality network (tinyFQnet) to learn a quality prediction function\nfrom data.\n\nWe evaluate the proposed method for different powerful FR models on two\nclassical video-based (or template-based) benchmark: IJB-B and YTF. Extensive\nexperiments show that, although the tinyFQnet is much smaller than the others,\nthe proposed method outperforms state-of-the-art quality assessment methods in\nterms of effectiveness and efficiency.",
          "link": "http://arxiv.org/abs/2106.04852",
          "publishedOn": "2021-06-10T01:56:45.951Z",
          "wordCount": 619,
          "title": "Deep Tiny Network for Recognition-Oriented Face Image Quality Assessment. (arXiv:2106.04852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04822",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Alishahi_F/0/1/0/all/0/1\">Fatemeh Alishahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohajerin_Ariaei_A/0/1/0/all/0/1\">Amirhossein Mohajerin-Ariaei</a>",
          "description": "The unpaired training can be the only option available for fast deep\nlearning-based ghost imaging, where obtaining a high signal-to-noise ratio\n(SNR) image copy of each low SNR ghost image could be practically\ntime-consuming and challenging. This paper explores the capabilities of deep\nlearning to leverage computational ghost imaging when there is a lack of paired\ntraining images. The deep learning approach proposed here enables fast ghost\nimaging through reconstruction of high SNR images from faint and hastily shot\nghost images using a constrained Wasserstein generative adversarial network. In\nthe proposed approach, the objective function is regularized to enforce the\ngeneration of faithful and relevant high SNR images to the ghost copies. This\nregularization measures the distance between reconstructed images and the faint\nghost images in a low-noise manifold generated by a shadow network. The\nperformance of the constrained network is shown to be particularly important\nfor ghost images with low SNR. The proposed pipeline is able to reconstruct\nhigh-quality images from the ghost images with SNR values not necessarily equal\nto the SNR of the training set.",
          "link": "http://arxiv.org/abs/2106.04822",
          "publishedOn": "2021-06-10T01:56:45.938Z",
          "wordCount": 629,
          "title": "Fast Computational Ghost Imaging using Unpaired Deep Learning and a Constrained Generative Adversarial Network. (arXiv:2106.04822v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "While sophisticated Visual Question Answering models have achieved remarkable\nsuccess, they tend to answer questions only according to superficial\ncorrelations between question and answer. Several recent approaches have been\ndeveloped to address this language priors problem. However, most of them\npredict the correct answer according to one best output without checking the\nauthenticity of answers. Besides, they only explore the interaction between\nimage and question, ignoring the semantics of candidate answers. In this paper,\nwe propose a select-and-rerank (SAR) progressive framework based on Visual\nEntailment. Specifically, we first select the candidate answers relevant to the\nquestion or the image, then we rerank the candidate answers by a visual\nentailment task, which verifies whether the image semantically entails the\nsynthetic statement of the question and each candidate answer. Experimental\nresults show the effectiveness of our proposed framework, which establishes a\nnew state-of-the-art accuracy on VQA-CP v2 with a 7.55% improvement.",
          "link": "http://arxiv.org/abs/2106.04605",
          "publishedOn": "2021-06-10T01:56:45.923Z",
          "wordCount": 586,
          "title": "Check It Again: Progressive Visual Question Answering via Visual Entailment. (arXiv:2106.04605v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhilu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1\">Vianne R. Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1\">Mert R. Sabuncu</a>",
          "description": "Monte Carlo (MC) dropout is a simple and efficient ensembling method that can\nimprove the accuracy and confidence calibration of high-capacity deep neural\nnetwork models. However, MC dropout is not as effective as more\ncompute-intensive methods such as deep ensembles. This performance gap can be\nattributed to the relatively poor quality of individual models in the MC\ndropout ensemble and their lack of diversity. These issues can in turn be\ntraced back to the coupled training and substantial parameter sharing of the\ndropout models. Motivated by this perspective, we propose a strategy to compute\nan ensemble of subnetworks, each corresponding to a non-overlapping dropout\nmask computed via a pruning strategy and trained independently. We show that\nthe proposed subnetwork ensembling method can perform as well as standard deep\nensembles in both accuracy and uncertainty estimates, yet with a computational\nefficiency similar to MC dropout. Lastly, using several computer vision\ndatasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally\ndemonstrate that subnetwork ensembling also consistently outperforms recently\nproposed approaches that efficiently ensemble neural networks.",
          "link": "http://arxiv.org/abs/2106.04767",
          "publishedOn": "2021-06-10T01:56:45.918Z",
          "wordCount": 609,
          "title": "Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruihui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng-Ann Heng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chi-Wing Fu</a>",
          "description": "Point clouds produced by 3D scanning are often sparse, non-uniform, and\nnoisy. Recent upsampling approaches aim to generate a dense point set, while\nachieving both distribution uniformity and proximity-to-surface, and possibly\namending small holes, all in a single network. After revisiting the task, we\npropose to disentangle the task based on its multi-objective nature and\nformulate two cascaded sub-networks, a dense generator and a spatial refiner.\nThe dense generator infers a coarse but dense output that roughly describes the\nunderlying surface, while the spatial refiner further fine-tunes the coarse\noutput by adjusting the location of each point. Specifically, we design a pair\nof local and global refinement units in the spatial refiner to evolve a coarse\nfeature map. Also, in the spatial refiner, we regress a per-point offset vector\nto further adjust the coarse outputs in fine-scale. Extensive qualitative and\nquantitative results on both synthetic and real-scanned datasets demonstrate\nthe superiority of our method over the state-of-the-arts.",
          "link": "http://arxiv.org/abs/2106.04779",
          "publishedOn": "2021-06-10T01:56:45.900Z",
          "wordCount": 590,
          "title": "Point Cloud Upsampling via Disentangled Refinement. (arXiv:2106.04779v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1\">Lele Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Distilling analytical models from data has the potential to advance our\nunderstanding and prediction of nonlinear dynamics. Although discovery of\ngoverning equations based on observed system states (e.g., trajectory time\nseries) has revealed success in a wide range of nonlinear dynamics, uncovering\nthe closed-form equations directly from raw videos still remains an open\nchallenge. To this end, we introduce a novel end-to-end unsupervised deep\nlearning framework to uncover the mathematical structure of equations that\ngoverns the dynamics of moving objects in videos. Such an architecture consists\nof (1) an encoder-decoder network that learns low-dimensional spatial/pixel\ncoordinates of the moving object, (2) a learnable Spatial-Physical\nTransformation component that creates mapping between the extracted\nspatial/pixel coordinates and the latent physical states of dynamics, and (3) a\nnumerical integrator-based sparse regression module that uncovers the\nparsimonious closed-form governing equations of learned physical states and,\nmeanwhile, serves as a constraint to the autoencoder. The efficacy of the\nproposed method is demonstrated by uncovering the governing equations of a\nvariety of nonlinear dynamical systems depicted by moving objects in videos.\nThe resulting computational framework enables discovery of parsimonious\ninterpretable model in a flexible and accessible sensing environment where only\nvideos are available.",
          "link": "http://arxiv.org/abs/2106.04776",
          "publishedOn": "2021-06-10T01:56:45.895Z",
          "wordCount": 635,
          "title": "Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1\">Byunggook Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1\">Jisoo Mok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1\">Hyeokjun Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Despite the increasing interest in neural architecture search (NAS), the\nsignificant computational cost of NAS is a hindrance to researchers. Hence, we\npropose to reduce the cost of NAS using proxy data, i.e., a representative\nsubset of the target data, without sacrificing search performance. Even though\ndata selection has been used across various fields, our evaluation of existing\nselection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that\nthey are not always appropriate for NAS and a new selection method is\nnecessary. By analyzing proxy data constructed using various selection methods\nthrough data entropy, we propose a novel proxy data selection method tailored\nfor NAS. To empirically demonstrate the effectiveness, we conduct thorough\nexperiments across diverse datasets, search spaces, and NAS algorithms.\nConsequently, NAS algorithms with the proposed selection discover architectures\nthat are competitive with those obtained using the entire dataset. It\nsignificantly reduces the search cost: executing DARTS with the proposed\nselection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a\nsingle GPU. Additionally, when the architecture searched on ImageNet using the\nproposed selection is inversely transferred to CIFAR-10, a state-of-the-art\ntest error of 2.4\\% is yielded. Our code is available at\nhttps://github.com/nabk89/NAS-with-Proxy-data.",
          "link": "http://arxiv.org/abs/2106.04784",
          "publishedOn": "2021-06-10T01:56:45.857Z",
          "wordCount": 633,
          "title": "Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1\">Ioannis Panopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1\">Iakovos S. Venieris</a>",
          "description": "Radical progress in the field of deep learning (DL) has led to unprecedented\naccuracy in diverse inference tasks. As such, deploying DL models across mobile\nplatforms is vital to enable the development and broad availability of the\nnext-generation intelligent apps. Nevertheless, the wide and optimised\ndeployment of DL models is currently hindered by the vast system heterogeneity\nof mobile devices, the varying computational cost of different DL models and\nthe variability of performance needs across DL applications. This paper\nproposes OODIn, a framework for the optimised deployment of DL apps across\nheterogeneous mobile devices. OODIn comprises a novel DL-specific software\narchitecture together with an analytical framework for modelling DL\napplications that: (1) counteract the variability in device resources and DL\nmodels by means of a highly parametrised multi-layer design; and (2) perform a\nprincipled optimisation of both model- and system-level parameters through a\nmulti-objective formulation, designed for DL inference apps, in order to adapt\nthe deployment to the user-specified performance requirements and device\ncapabilities. Quantitative evaluation shows that the proposed framework\nconsistently outperforms status-quo designs across heterogeneous devices and\ndelivers up to 4.3x and 3.5x performance gain over highly optimised platform-\nand model-aware designs respectively, while effectively adapting execution to\ndynamic changes in resource availability.",
          "link": "http://arxiv.org/abs/2106.04723",
          "publishedOn": "2021-06-10T01:56:45.840Z",
          "wordCount": 653,
          "title": "OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04650",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Dayang Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Z/0/1/0/all/0/1\">Zhan Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Hengyong Yu</a>",
          "description": "Low dose computed tomography is a mainstream for clinical applications.\nHow-ever, compared to normal dose CT, in the low dose CT (LDCT) images, there\nare stronger noise and more artifacts which are obstacles for practical\napplications. In the last few years, convolution-based end-to-end deep learning\nmethods have been widely used for LDCT image denoising. Recently, transformer\nhas shown superior performance over convolution with more feature interactions.\nYet its ap-plications in LDCT denoising have not been fully cultivated. Here,\nwe propose a convolution-free T2T vision transformer-based Encoder-decoder\nDilation net-work (TED-net) to enrich the family of LDCT denoising algorithms.\nThe model is free of convolution blocks and consists of a symmetric\nencoder-decoder block with sole transformer. Our model is evaluated on the\nAAPM-Mayo clinic LDCT Grand Challenge dataset, and results show outperformance\nover the state-of-the-art denoising methods.",
          "link": "http://arxiv.org/abs/2106.04650",
          "publishedOn": "2021-06-10T01:56:45.809Z",
          "wordCount": 597,
          "title": "TED-net: Convolution-free T2T Vision Transformer-based Encoder-decoder Dilation network for Low-dose CT Denoising. (arXiv:2106.04650v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-09T22:43:50.359Z",
          "wordCount": 599,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changhao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yudong Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yueyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "Existing deep learning methods for diagnosis of gastric cancer commonly use\nconvolutional neural network. Recently, the Visual Transformer has attracted\ngreat attention because of its performance and efficiency, but its applications\nare mostly in the field of computer vision. In this paper, a multi-scale visual\ntransformer model, referred to as GasHis-Transformer, is proposed for Gastric\nHistopathological Image Classification (GHIC), which enables the automatic\nclassification of microscopic gastric images into abnormal and normal cases.\nThe GasHis-Transformer model consists of two key modules: A global information\nmodule and a local information module to extract histopathological features\neffectively. In our experiments, a public hematoxylin and eosin (H&E) stained\ngastric histopathological dataset with 280 abnormal and normal images are\ndivided into training, validation and test sets by a ratio of 1 : 1 : 2. The\nGasHis-Transformer model is applied to estimate precision, recall, F1-score and\naccuracy on the test set of gastric histopathological dataset as 98.0%, 100.0%,\n96.0% and 98.0%, respectively. Furthermore, a critical study is conducted to\nevaluate the robustness of GasHis-Transformer, where ten different noises\nincluding four adversarial attack and six conventional image noises are added.\nIn addition, a clinically meaningful study is executed to test the\ngastrointestinal cancer identification performance of GasHis-Transformer with\n620 abnormal images and achieves 96.8% accuracy. Finally, a comparative study\nis performed to test the generalizability with both H&E and immunohistochemical\nstained images on a lymphoma image dataset and a breast cancer dataset,\nproducing comparable F1-scores (85.6% and 82.8%) and accuracies (83.9% and\n89.4%), respectively. In conclusion, GasHisTransformer demonstrates high\nclassification performance and shows its significant potential in the GHIC\ntask.",
          "link": "http://arxiv.org/abs/2104.14528",
          "publishedOn": "2021-06-09T02:01:52.019Z",
          "wordCount": 764,
          "title": "GasHis-Transformer: A Multi-scale Visual Transformer Approach for Gastric Histopathology Image Classification. (arXiv:2104.14528v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Dongxia Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zhiqian Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Recently, there has been considerable research interest in graph clustering\naimed at data partition using the graph information. However, one limitation of\nthe most of graph-based methods is that they assume the graph structure to\noperate is fixed and reliable. And there are inevitably some edges in the graph\nthat are not conducive to graph clustering, which we call spurious edges. This\npaper is the first attempt to employ graph pooling technique for node\nclustering and we propose a novel dual graph embedding network (DGEN), which is\ndesigned as a two-step graph encoder connected by a graph pooling layer to\nlearn the graph embedding. In our model, it is assumed that if a node and its\nnearest neighboring node are close to the same clustering center, this node is\nan informative node and this edge can be considered as a cluster-friendly edge.\nBased on this assumption, the neighbor cluster pooling (NCPool) is devised to\nselect the most informative subset of nodes and the corresponding edges based\non the distance of nodes and their nearest neighbors to the cluster centers.\nThis can effectively alleviate the impact of the spurious edges on the\nclustering. Finally, to obtain the clustering assignment of all nodes, a\nclassifier is trained using the clustering results of the selected nodes.\nExperiments on five benchmark graph datasets demonstrate the superiority of the\nproposed method over state-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2105.05320",
          "publishedOn": "2021-06-09T02:01:52.013Z",
          "wordCount": 709,
          "title": "Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph Clustering. (arXiv:2105.05320v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yingying Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1\">Fan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xingjia Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weiming Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chongyang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changsheng Xu</a>",
          "description": "The goal of image style transfer is to render an image with artistic features\nguided by a style reference while maintaining the original content. Due to the\nlocality and spatial invariance in CNNs, it is difficult to extract and\nmaintain the global information of input images. Therefore, traditional neural\nstyle transfer methods are usually biased and content leak can be observed by\nrunning several times of the style transfer process with the same reference\nstyle image. To address this critical issue, we take long-range dependencies of\ninput images into account for unbiased style transfer by proposing a\ntransformer-based approach, namely StyTr^2. In contrast with visual\ntransformers for other vision tasks, our StyTr^2 contains two different\ntransformer encoders to generate domain-specific sequences for content and\nstyle, respectively. Following the encoders, a multi-layer transformer decoder\nis adopted to stylize the content sequence according to the style sequence. In\naddition, we analyze the deficiency of existing positional encoding methods and\npropose the content-aware positional encoding (CAPE) which is scale-invariant\nand more suitable for image style transfer task. Qualitative and quantitative\nexperiments demonstrate the effectiveness of the proposed StyTr^2 compared to\nstate-of-the-art CNN-based and flow-based approaches.",
          "link": "http://arxiv.org/abs/2105.14576",
          "publishedOn": "2021-06-09T02:01:52.007Z",
          "wordCount": 647,
          "title": "StyTr^2: Unbiased Image Style Transfer with Transformers. (arXiv:2105.14576v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1\">Junbum Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1\">Sanghyuk Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyungjae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Han-Cheol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunsung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungrae Park</a>",
          "description": "Domain generalization (DG) methods aim to achieve generalizability to an\nunseen target domain by using only training data from the source domains.\nAlthough a variety of DG methods have been proposed, a recent study shows that\nunder a fair evaluation protocol, called DomainBed, the simple empirical risk\nminimization (ERM) approach works comparable to or even outperforms previous\nmethods. Unfortunately, simply solving ERM on a complex, non-convex loss\nfunction can easily lead to sub-optimal generalizability by seeking sharp\nminima. In this paper, we theoretically show that finding flat minima results\nin a smaller domain generalization gap. We also propose a simple yet effective\nmethod, named Stochastic Weight Averaging Densely (SWAD), to find flat minima.\nSWAD finds flatter minima and suffers less from overfitting than does the\nvanilla SWA by a dense and overfit-aware stochastic weight sampling strategy.\nSWAD shows state-of-the-art performances on five DG benchmarks, namely PACS,\nVLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large\nmargins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with\nconventional generalization methods, such as data augmentation and consistency\nregularization methods, to verify that the remarkable performance improvements\nare originated from by seeking flat minima, not from better in-domain\ngeneralizability. Last but not least, SWAD is readily adaptable to existing DG\nmethods without modification; the combination of SWAD and an existing DG method\nfurther improves DG performances.",
          "link": "http://arxiv.org/abs/2102.08604",
          "publishedOn": "2021-06-09T02:01:52.002Z",
          "wordCount": 687,
          "title": "SWAD: Domain Generalization by Seeking Flat Minima. (arXiv:2102.08604v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yicheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Cheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yongqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiahui Zhu</a>",
          "description": "3D human pose estimation is still a challenging problem despite the large\namount of work that has been done in this field. Generally, most methods\ndirectly use neural networks and ignore certain constraints (e.g., reprojection\nconstraints and joint angle and bone length constraints). This paper proposes a\nweakly supervised GAN-based model for 3D human pose estimation that considers\n3D information along with 2D information simultaneously, in which a\nreprojection network is employed to learn the mapping of the distribution from\n3D poses to 2D poses. In particular, we train the reprojection network and the\ngenerative adversarial network synchronously. Furthermore, inspired by the\ntypical kinematic chain space (KCS) matrix, we propose a weighted KCS matrix,\nwhich is added into the discriminator's input to impose joint angle and bone\nlength constraints. The experimental results on Human3.6M show that our method\noutperforms state-of-the-art methods by approximately 5.1\\%.",
          "link": "http://arxiv.org/abs/2106.04274",
          "publishedOn": "2021-06-09T02:01:51.996Z",
          "wordCount": 575,
          "title": "A Synchronized Reprojection-based Model for 3D Human Pose Estimation. (arXiv:2106.04274v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Felicioni_S/0/1/0/all/0/1\">Simone Felicioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimiccoli_M/0/1/0/all/0/1\">Mariella Dimiccoli</a>",
          "description": "In this paper we propose a new framework to categorize social interactions in\negocentric videos, we named InteractionGCN. Our method extracts patterns of\nrelational and non-relational cues at the frame level and uses them to build a\nrelational graph from which the interactional context at the frame level is\nestimated via a Graph Convolutional Network based approach. Then it propagates\nthis context over time, together with first-person motion information, through\na Gated Recurrent Unit architecture. Ablation studies and experimental\nevaluation on two publicly available datasets validate the proposed approach\nand establish state of the art results.",
          "link": "http://arxiv.org/abs/2104.14007",
          "publishedOn": "2021-06-09T02:01:51.979Z",
          "wordCount": 565,
          "title": "Interaction-GCN: A Graph Convolutional Network based framework for social interaction recognition in egocentric videos. (arXiv:2104.14007v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1\">Tal Reiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1\">Yedid Hoshen</a>",
          "description": "Deep anomaly detection methods learn representations that separate between\nnormal and anomalous samples. Very effective representations are obtained when\npowerful externally trained feature extractors (e.g. ResNets pre-trained on\nImageNet) are fine-tuned on the training data which consists of normal samples\nand no anomalies. However, this is a difficult task that can suffer from\ncatastrophic collapse, i.e. it is prone to learning trivial and non-specific\nfeatures. In this paper, we propose a new loss function which can overcome\nfailure modes of both center-loss and contrastive-loss methods. Furthermore, we\ncombine it with a confidence-invariant angular center loss, which replaces the\nEuclidean distance used in previous work, that was sensitive to prediction\nconfidence. Our improvements yield a new anomaly detection approach, based on\n$\\textit{Mean-Shifted Contrastive Loss}$, which is both more accurate and less\nsensitive to catastrophic collapse than previous methods. Our method achieves\nstate-of-the-art anomaly detection performance on multiple benchmarks including\n$97.5\\%$ ROC-AUC on the CIFAR-10 dataset.",
          "link": "http://arxiv.org/abs/2106.03844",
          "publishedOn": "2021-06-09T02:01:51.967Z",
          "wordCount": 580,
          "title": "Mean-Shifted Contrastive Loss for Anomaly Detection. (arXiv:2106.03844v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Ruizhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanpei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yebin Liu</a>",
          "description": "We introduce DoubleField, a novel representation combining the merits of both\nsurface field and radiance field for high-fidelity human rendering. Within\nDoubleField, the surface field and radiance field are associated together by a\nshared feature embedding and a surface-guided sampling strategy. In this way,\nDoubleField has a continuous but disentangled learning space for geometry and\nappearance modeling, which supports fast training, inference, and finetuning.\nTo achieve high-fidelity free-viewpoint rendering, DoubleField is further\naugmented to leverage ultra-high-resolution inputs, where a view-to-view\ntransformer and a transfer learning scheme are introduced for more efficient\nlearning and finetuning from sparse-view inputs at original resolutions. The\nefficacy of DoubleField is validated by the quantitative evaluations on several\ndatasets and the qualitative results in a real-world sparse multi-view system,\nshowing its superior capability for photo-realistic free-viewpoint human\nrendering. For code and demo video, please refer to our project page:\nthis http URL",
          "link": "http://arxiv.org/abs/2106.03798",
          "publishedOn": "2021-06-09T02:01:51.859Z",
          "wordCount": 605,
          "title": "DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Rendering. (arXiv:2106.03798v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.04408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanjiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baoquan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhijian Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hesheng Wang</a>",
          "description": "Changing environments poses a great challenge on the outdoor visual\nperception and scene understanding for robust long-term autonomous driving and\nmobile robots, where depth-auxiliary geometric information plays an essential\nrole to the robustness under challenging scenes. Although monocular depth\nprediction has been well studied recently, there are few work focusing on the\ndepth prediction across multiple environmental conditions, e.g. changing\nillumination and seasons, owing to the lack of such a real-world dataset and\nbenchmark. In this work, a new cross-season monocular depth prediction dataset\nSeasonDepth (available on https://seasondepth.github.io) is derived from CMU\nVisual Localization dataset through structure from motion. To benchmark the\ndepth estimation performance under different environments, we investigate\nrepresentative and recent state-of-the-art open-source supervised,\nself-supervised and domain adaptation depth prediction methods from KITTI\nbenchmark using several newly-formulated metrics. Through extensive\nexperimental evaluation on the proposed dataset without fine-tuning, the\ninfluence of multiple environments on performance and robustness is analyzed\nboth qualitatively and quantitatively, showing that the long-term monocular\ndepth prediction is far from solved. We further give promising solutions\nespecially with stereo geometry and multi-task sequential self-supervised\ntraining to enhance the robustness to changing environments.",
          "link": "http://arxiv.org/abs/2011.04408",
          "publishedOn": "2021-06-09T02:01:51.835Z",
          "wordCount": 659,
          "title": "SeasonDepth: Cross-Season Monocular Depth Prediction Dataset and Benchmark under Multiple Environments. (arXiv:2011.04408v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.00992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1\">Dongyoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sangdoo Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heo_B/0/1/0/all/0/1\">Byeongho Heo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1\">YoungJoon Yoo</a>",
          "description": "Designing an efficient model within the limited computational cost is\nchallenging. We argue the accuracy of a lightweight model has been further\nlimited by the design convention: a stage-wise configuration of the channel\ndimensions, which looks like a piecewise linear function of the network stage.\nIn this paper, we study an effective channel dimension configuration towards\nbetter performance than the convention. To this end, we empirically study how\nto design a single layer properly by analyzing the rank of the output feature.\nWe then investigate the channel configuration of a model by searching network\narchitectures concerning the channel configuration under the computational cost\nrestriction. Based on the investigation, we propose a simple yet effective\nchannel configuration that can be parameterized by the layer index. As a\nresult, our proposed model following the channel parameterization achieves\nremarkable performance on ImageNet classification and transfer learning tasks\nincluding COCO object detection, COCO instance segmentation, and fine-grained\nclassifications. Code and ImageNet pretrained models are available at\nhttps://github.com/clovaai/rexnet.",
          "link": "http://arxiv.org/abs/2007.00992",
          "publishedOn": "2021-06-09T02:01:51.663Z",
          "wordCount": 639,
          "title": "Rethinking Channel Dimensions for Efficient Model Design. (arXiv:2007.00992v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1\">Munawar Hayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>",
          "description": "Vision transformers (ViT) have demonstrated impressive performance across\nvarious machine vision problems. These models are based on multi-head\nself-attention mechanisms that can flexibly attend to a sequence of image\npatches to encode contextual cues. An important question is how such\nflexibility in attending image-wide context conditioned on a given patch can\nfacilitate handling nuisances in natural images e.g., severe occlusions, domain\nshifts, spatial permutations, adversarial and natural perturbations. We\nsystematically study this question via an extensive set of experiments\nencompassing three ViT families and comparisons with a high-performing\nconvolutional neural network (CNN). We show and analyze the following\nintriguing properties of ViT: (a) Transformers are highly robust to severe\nocclusions, perturbations and domain shifts, e.g., retain as high as 60% top-1\naccuracy on ImageNet even after randomly occluding 80% of the image content.\n(b) The robust performance to occlusions is not due to a bias towards local\ntextures, and ViTs are significantly less biased towards textures compared to\nCNNs. When properly trained to encode shape-based features, ViTs demonstrate\nshape recognition capability comparable to that of human visual system,\npreviously unmatched in the literature. (c) Using ViTs to encode shape\nrepresentation leads to an interesting consequence of accurate semantic\nsegmentation without pixel-level supervision. (d) Off-the-shelf features from a\nsingle ViT model can be combined to create a feature ensemble, leading to high\naccuracy rates across a range of classification datasets in both traditional\nand few-shot learning paradigms. We show effective features of ViTs are due to\nflexible and dynamic receptive fields possible via the self-attention\nmechanism.",
          "link": "http://arxiv.org/abs/2105.10497",
          "publishedOn": "2021-06-09T02:01:51.547Z",
          "wordCount": 730,
          "title": "Intriguing Properties of Vision Transformers. (arXiv:2105.10497v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lianli Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qilong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jingkuan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Heng Tao Shen</a>",
          "description": "Although great progress has been made on adversarial attacks for deep neural\nnetworks (DNNs), their transferability is still unsatisfactory, especially for\ntargeted attacks. There are two problems behind that have been long overlooked:\n1) the conventional setting of $T$ iterations with the step size of\n$\\epsilon/T$ to comply with the $\\epsilon$-constraint. In this case, most of\nthe pixels are allowed to add very small noise, much less than $\\epsilon$; and\n2) usually manipulating pixel-wise noise. However, features of a pixel\nextracted by DNNs are influenced by its surrounding regions, and different DNNs\ngenerally focus on different discriminative regions in recognition. To tackle\nthese issues, our previous work proposes a patch-wise iterative method (PIM)\naimed at crafting adversarial examples with high transferability. Specifically,\nwe introduce an amplification factor to the step size in each iteration, and\none pixel's overall gradient overflowing the $\\epsilon$-constraint is properly\nassigned to its surrounding regions by a project kernel. But targeted attacks\naim to push the adversarial examples into the territory of a specific class,\nand the amplification factor may lead to underfitting. Thus, we introduce the\ntemperature and propose a patch-wise++ iterative method (PIM++) to further\nimprove transferability without significantly sacrificing the performance of\nthe white-box attack. Our method can be generally integrated to any\ngradient-based attack methods. Compared with the current state-of-the-art\nattack methods, we significantly improve the success rate by 33.1\\% for defense\nmodels and 31.4\\% for normally trained models on average.",
          "link": "http://arxiv.org/abs/2012.15503",
          "publishedOn": "2021-06-09T02:01:50.926Z",
          "wordCount": 704,
          "title": "Patch-wise++ Perturbation for Adversarial Targeted Attacks. (arXiv:2012.15503v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Shih-Po Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Cun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Hsiao Peng</a>",
          "description": "This paper addresses fast semantic segmentation on video.Video segmentation\noften calls for real-time, or even fasterthan real-time, processing. One common\nrecipe for conserving computation arising from feature extraction is to\npropagate features of few selected keyframes. However, recent advances in fast\nimage segmentation make these solutions less attractive. To leverage fast image\nsegmentation for furthering video segmentation, we propose a simple yet\nefficient propagation framework. Specifically, we perform lightweight flow\nestimation in 1/8-downscaled image space for temporal warping in segmentation\noutpace space. Moreover, we introduce a guided spatially-varying convolution\nfor fusing segmentations derived from the previous and current frames, to\nmitigate propagation error and enable lightweight feature extraction on\nnon-keyframes. Experimental results on Cityscapes and CamVid show that our\nscheme achieves the state-of-the-art accuracy-throughput trade-off on video\nsegmentation.",
          "link": "http://arxiv.org/abs/2103.08834",
          "publishedOn": "2021-06-09T02:01:50.889Z",
          "wordCount": 589,
          "title": "GSVNet: Guided Spatially-Varying Convolution for Fast Semantic Segmentation on Video. (arXiv:2103.08834v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nezhadarya_E/0/1/0/all/0/1\">Ehsan Nezhadarya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fashandi_H/0/1/0/all/0/1\">Homa Fashandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiayi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graham_D/0/1/0/all/0/1\">Darin Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mohak Shah</a>",
          "description": "Batch Normalization (BN) is a popular technique for training Deep Neural\nNetworks (DNNs). BN uses scaling and shifting to normalize activations of\nmini-batches to accelerate convergence and improve generalization. The recently\nproposed Iterative Normalization (IterNorm) method improves these properties by\nwhitening the activations iteratively using Newton's method. However, since\nNewton's method initializes the whitening matrix independently at each training\nstep, no information is shared between consecutive steps. In this work, instead\nof exact computation of whitening matrix at each time step, we estimate it\ngradually during training in an online fashion, using our proposed Stochastic\nWhitening Batch Normalization (SWBN) algorithm. We show that while SWBN\nimproves the convergence rate and generalization of DNNs, its computational\noverhead is less than that of IterNorm. Due to the high efficiency of the\nproposed method, it can be easily employed in most DNN architectures with a\nlarge number of layers. We provide comprehensive experiments and comparisons\nbetween BN, IterNorm, and SWBN layers to demonstrate the effectiveness of the\nproposed technique in conventional (many-shot) image classification and\nfew-shot classification tasks.",
          "link": "http://arxiv.org/abs/2106.04413",
          "publishedOn": "2021-06-09T02:01:50.859Z",
          "wordCount": 613,
          "title": "Stochastic Whitening Batch Normalization. (arXiv:2106.04413v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.16547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse\ntrainable subnetworks, or winning tickets, of training, which can be trained in\nisolation to achieve similar or even better performance compared to the full\nmodels. Despite many efforts being made, the most effective method to identify\nsuch winning tickets is still Iterative Magnitude-based Pruning (IMP), which is\ncomputationally expensive and has to be run thoroughly for every different\nnetwork. A natural question that comes in is: can we \"transform\" the winning\nticket found in one network to another with a different architecture, yielding\na winning ticket for the latter at the beginning, without re-doing the\nexpensive IMP? Answering this question is not only practically relevant for\nefficient \"once-for-all\" winning ticket finding, but also theoretically\nappealing for uncovering inherently scalable sparse patterns in networks. We\nconduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety\nof strategies to tweak the winning tickets found from different networks of the\nsame model family (e.g., ResNets). Based on these results, we articulate the\nElastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or\ndropping) and re-ordering layers for one network, its corresponding winning\nticket could be stretched (or squeezed) into a subnetwork for another deeper\n(or shallower) network from the same family, whose performance is nearly the\nsame competitive as the latter's winning ticket directly found by IMP. We have\nalso thoroughly compared E-LTH with pruning-at-initialization and dynamic\nsparse training methods, and discuss the generalizability of E-LTH to different\nmodel families, layer types, or across datasets. Code is available at\nhttps://github.com/VITA-Group/ElasticLTH.",
          "link": "http://arxiv.org/abs/2103.16547",
          "publishedOn": "2021-06-09T02:01:50.684Z",
          "wordCount": null,
          "title": "The Elastic Lottery Ticket Hypothesis. (arXiv:2103.16547v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mama_R/0/1/0/all/0/1\">Rayhane Mama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyndel_M/0/1/0/all/0/1\">Marc S. Tyndel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadhim_H/0/1/0/all/0/1\">Hashiam Kadhim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifford_C/0/1/0/all/0/1\">Cole Clifford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thurairatnam_R/0/1/0/all/0/1\">Ragavan Thurairatnam</a>",
          "description": "In this work we introduce NWT, an expressive speech-to-video model. Unlike\napproaches that use domain-specific intermediate representations such as pose\nkeypoints, NWT learns its own latent representations, with minimal assumptions\nabout the audio and video content. To this end, we propose a novel discrete\nvariational autoencoder with adversarial loss, dVAE-Adv, which learns a new\ndiscrete latent representation we call Memcodes. Memcodes are straightforward\nto implement, require no additional loss terms, are stable to train compared\nwith other approaches, and show evidence of interpretability. To predict on the\nMemcode space, we use an autoregressive encoder-decoder model conditioned on\naudio. Additionally, our model can control latent attributes in the generated\nvideo that are not annotated in the data. We train NWT on clips from HBO's Last\nWeek Tonight with John Oliver. NWT consistently scores above other approaches\nin Mean Opinion Score (MOS) on tests of overall video naturalness, facial\nnaturalness and expressiveness, and lipsync quality. This work sets a strong\nbaseline for generalized audio-to-video synthesis. Samples are available at\nhttps://next-week-tonight.github.io/NWT/.",
          "link": "http://arxiv.org/abs/2106.04283",
          "publishedOn": "2021-06-09T02:01:50.667Z",
          "wordCount": null,
          "title": "NWT: Towards natural audio-to-video generation with representation learning. (arXiv:2106.04283v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burduja_M/0/1/0/all/0/1\">Mihail Burduja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "We explore different curriculum learning methods for training convolutional\nneural networks on the task of deformable pairwise 3D medical image\nregistration. To the best of our knowledge, we are the first to attempt to\nimprove performance by training medical image registration models using\ncurriculum learning, starting from an easy training setup in the first training\nstages, and gradually increasing the complexity of the setup. On the one hand,\nwe consider two existing curriculum learning approaches, namely curriculum\ndropout and curriculum by smoothing. On the other hand, we propose a novel and\nsimple strategy to achieve curriculum, namely to use purposely blurred images\nat the beginning, then gradually transit to sharper images in the later\ntraining stages. Our experiments with an underlying state-of-the-art deep\nlearning model show that curriculum learning can lead to superior results\ncompared to conventional training. Additionally, we show that curriculum by\ninput blur has the best accuracy versus speed trade-off among the compared\ncurriculum learning approaches.",
          "link": "http://arxiv.org/abs/2102.10438",
          "publishedOn": "2021-06-09T02:01:50.665Z",
          "wordCount": null,
          "title": "Unsupervised Medical Image Alignment with Curriculum Learning. (arXiv:2102.10438v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dagaev_N/0/1/0/all/0/1\">Nikolay Dagaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roads_B/0/1/0/all/0/1\">Brett D. Roads</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiaoliang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barry_D/0/1/0/all/0/1\">Daniel N. Barry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1\">Kaustubh R. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Love_B/0/1/0/all/0/1\">Bradley C. Love</a>",
          "description": "Despite their impressive performance in object recognition and other tasks\nunder standard testing conditions, deep networks often fail to generalize to\nout-of-distribution (o.o.d.) samples. One cause for this shortcoming is that\nmodern architectures tend to rely on \"shortcuts\" - superficial features that\ncorrelate with categories without capturing deeper invariants that hold across\ncontexts. Real-world concepts often possess a complex structure that can vary\nsuperficially across contexts, which can make the most intuitive and promising\nsolutions in one context not generalize to others. One potential way to improve\no.o.d. generalization is to assume simple solutions are unlikely to be valid\nacross contexts and avoid them, which we refer to as the too-good-to-be-true\nprior. A low-capacity network (LCN) with a shallow architecture should only be\nable to learn surface relationships, including shortcuts. We find that LCNs can\nserve as shortcut detectors. Furthermore, an LCN's predictions can be used in a\ntwo-stage approach to encourage a high-capacity network (HCN) to rely on deeper\ninvariant features that should generalize broadly. In particular, items that\nthe LCN can master are downweighted when training the HCN. Using a modified\nversion of the CIFAR-10 dataset in which we introduced shortcuts, we found that\nthe two-stage LCN-HCN approach reduced reliance on shortcuts and facilitated\no.o.d. generalization.",
          "link": "http://arxiv.org/abs/2102.06406",
          "publishedOn": "2021-06-09T02:01:50.660Z",
          "wordCount": null,
          "title": "A Too-Good-to-be-True Prior to Reduce Shortcut Reliance. (arXiv:2102.06406v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1\">Sangwon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donggyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taeeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1\">Taesup Moon</a>",
          "description": "Fairness is becoming an increasingly crucial issue for computer vision,\nespecially in the human-related decision systems. However, achieving\nalgorithmic fairness, which makes a model produce indiscriminative outcomes\nagainst protected groups, is still an unresolved problem. In this paper, we\ndevise a systematic approach which reduces algorithmic biases via feature\ndistillation for visual recognition tasks, dubbed as MMD-based Fair\nDistillation (MFD). While the distillation technique has been widely used in\ngeneral to improve the prediction accuracy, to the best of our knowledge, there\nhas been no explicit work that also tries to improve fairness via distillation.\nFurthermore, We give a theoretical justification of our MFD on the effect of\nknowledge distillation and fairness. Throughout the extensive experiments, we\nshow our MFD significantly mitigates the bias against specific minorities\nwithout any loss of the accuracy on both synthetic and real-world face\ndatasets.",
          "link": "http://arxiv.org/abs/2106.04411",
          "publishedOn": "2021-06-09T02:01:50.546Z",
          "wordCount": null,
          "title": "Fair Feature Distillation for Visual Recognition. (arXiv:2106.04411v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.01666",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zahid_M/0/1/0/all/0/1\">Muhammad Uzair Zahid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1\">Serkan Kiranyaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ince_T/0/1/0/all/0/1\">Turker Ince</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Devecioglu_O/0/1/0/all/0/1\">Ozer Can Devecioglu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1\">Muhammad E. H. Chowdhury</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khandakar_A/0/1/0/all/0/1\">Amith Khandakar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tahir_A/0/1/0/all/0/1\">Anas Tahir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Noise and low quality of ECG signals acquired from Holter or wearable devices\ndeteriorate the accuracy and robustness of R-peak detection algorithms. This\npaper presents a generic and robust system for R-peak detection in Holter ECG\nsignals. While many proposed algorithms have successfully addressed the problem\nof ECG R-peak detection, there is still a notable gap in the performance of\nthese detectors on such low-quality ECG records. Therefore, in this study, a\nnovel implementation of the 1D Convolutional Neural Network (CNN) is used\nintegrated with a verification model to reduce the number of false alarms. This\nCNN architecture consists of an encoder block and a corresponding decoder block\nfollowed by a sample-wise classification layer to construct the 1D segmentation\nmap of R- peaks from the input ECG signal. Once the proposed model has been\ntrained, it can solely be used to detect R-peaks possibly in a single channel\nECG data stream quickly and accurately, or alternatively, such a solution can\nbe conveniently employed for real-time monitoring on a lightweight portable\ndevice. The model is tested on two open-access ECG databases: The China\nPhysiological Signal Challenge (2020) database (CPSC-DB) with more than one\nmillion beats, and the commonly used MIT-BIH Arrhythmia Database (MIT-DB).\nExperimental results demonstrate that the proposed systematic approach achieves\n99.30% F1-score, 99.69% recall, and 98.91% precision in CPSC-DB, which is the\nbest R-peak detection performance ever achieved. Compared to all competing\nmethods, the proposed approach can reduce the false-positives and\nfalse-negatives in Holter ECG signals by more than 54% and 82%, respectively.\nResults also demonstrate similar or better performance than most competing\nalgorithms on MIT-DB with 99.83% F1-score, 99.85% recall, and 99.82% precision.",
          "link": "http://arxiv.org/abs/2101.01666",
          "publishedOn": "2021-06-09T02:01:50.295Z",
          "wordCount": null,
          "title": "Robust R-Peak Detection in Low-Quality Holter ECGs using 1D Convolutional Neural Network. (arXiv:2101.01666v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_P/0/1/0/all/0/1\">Prithvijit Chattopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Judy Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1\">Aniruddha Kembhavi</a>",
          "description": "As an attempt towards assessing the robustness of embodied navigation agents,\nwe propose RobustNav, a framework to quantify the performance of embodied\nnavigation agents when exposed to a wide variety of visual - affecting RGB\ninputs - and dynamics - affecting transition dynamics - corruptions. Most\nrecent efforts in visual navigation have typically focused on generalizing to\nnovel target environments with similar appearance and dynamics characteristics.\nWith RobustNav, we find that some standard embodied navigation agents\nsignificantly underperform (or fail) in the presence of visual or dynamics\ncorruptions. We systematically analyze the kind of idiosyncrasies that emerge\nin the behavior of such agents when operating under corruptions. Finally, for\nvisual corruptions in RobustNav, we show that while standard techniques to\nimprove robustness such as data-augmentation and self-supervised adaptation\noffer some zero-shot resistance and improvements in navigation performance,\nthere is still a long way to go in terms of recovering lost performance\nrelative to clean \"non-corrupt\" settings, warranting more research in this\ndirection. Our code is available at https://github.com/allenai/robustnav",
          "link": "http://arxiv.org/abs/2106.04531",
          "publishedOn": "2021-06-09T02:01:50.289Z",
          "wordCount": null,
          "title": "RobustNav: Towards Benchmarking Robustness in Embodied Navigation. (arXiv:2106.04531v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.07526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1\">Yuan Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>",
          "description": "Scene graphs are semantic abstraction of images that encourage visual\nunderstanding and reasoning. However, the performance of Scene Graph Generation\n(SGG) is unsatisfactory when faced with biased data in real-world scenarios.\nConventional debiasing research mainly studies from the view of balancing data\ndistribution or learning unbiased models and representations, ignoring the\ncorrelations among the biased classes. In this work, we analyze this problem\nfrom a novel cognition perspective: automatically building a hierarchical\ncognitive structure from the biased predictions and navigating that hierarchy\nto locate the relationships, making the tail relationships receive more\nattention in a coarse-to-fine mode. To this end, we propose a novel debiasing\nCognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive\nstructure CogTree to organize the relationships based on the prediction of a\nbiased SGG model. The CogTree distinguishes remarkably different relationships\nat first and then focuses on a small portion of easily confused ones. Then, we\npropose a debiasing loss specially for this cognitive structure, which supports\ncoarse-to-fine distinction for the correct relationships. The loss is\nmodel-agnostic and consistently boosting the performance of several\nstate-of-the-art models. The code is available at:\nhttps://github.com/CYVincent/Scene-Graph-Transformer-CogTree.",
          "link": "http://arxiv.org/abs/2009.07526",
          "publishedOn": "2021-06-09T02:01:50.288Z",
          "wordCount": 677,
          "title": "CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.11223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1\">Ghada Zamzmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajaraman_S/0/1/0/all/0/1\">Sivaramakrishnan Rajaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antani_S/0/1/0/all/0/1\">Sameer Antani</a>",
          "description": "Medical image analysis typically includes several tasks such as enhancement,\nsegmentation, and classification. Traditionally, these tasks are implemented\nusing separate deep learning models for separate tasks, which is not efficient\nbecause it involves unnecessary training repetitions, demands greater\ncomputational resources, and requires a relatively large amount of labeled\ndata. In this paper, we propose a multi-task training approach for medical\nimage analysis, where individual tasks are fine-tuned simultaneously through\nrelevant knowledge transfer using a unified modality-specific feature\nrepresentation (UMS-Rep). We explore different fine-tuning strategies to\ndemonstrate the impact of the strategy on the performance of target medical\nimage tasks. We experiment with different visual tasks (e.g., image denoising,\nsegmentation, and classification) to highlight the advantages offered with our\napproach for two imaging modalities, chest X-ray and Doppler echocardiography.\nOur results demonstrate that the proposed approach reduces the overall demand\nfor computational resources and improves target task generalization and\nperformance. Further, our results prove that the performance of target tasks in\nmedical images is highly influenced by the utilized fine-tuning strategy.",
          "link": "http://arxiv.org/abs/2006.11223",
          "publishedOn": "2021-06-09T02:01:50.278Z",
          "wordCount": null,
          "title": "Unified Representation Learning for Efficient Medical Image Analysis. (arXiv:2006.11223v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kshitij Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gautam_D/0/1/0/all/0/1\">Devansh Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1\">Radhika Mamidi</a>",
          "description": "Multimodal Machine Translation (MMT) enriches the source text with visual\ninformation for translation. It has gained popularity in recent years, and\nseveral pipelines have been proposed in the same direction. Yet, the task lacks\nquality datasets to illustrate the contribution of visual modality in the\ntranslation systems. In this paper, we propose our system under the team name\nVolta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We\nalso participate in the textual-only subtask of the same language pair for\nwhich we use mBART, a pretrained multilingual sequence-to-sequence model. For\nmultimodal translation, we propose to enhance the textual input by bringing the\nvisual information to a textual domain by extracting object tags from the\nimage. We also explore the robustness of our system by systematically degrading\nthe source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test\nset and challenge set of the multimodal task.",
          "link": "http://arxiv.org/abs/2106.00250",
          "publishedOn": "2021-06-09T02:01:50.276Z",
          "wordCount": null,
          "title": "ViTA: Visual-Linguistic Translation by Aligning Object Tags. (arXiv:2106.00250v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhekai Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hongzu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Ke Lu</a>",
          "description": "Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned\nfrom a well-labeled source domain to an unlabeled target domain. Recently,\nadversarial domain adaptation with two distinct classifiers (bi-classifier) has\nbeen introduced into UDA which is effective to align distributions between\ndifferent domains. Previous bi-classifier adversarial learning methods only\nfocus on the similarity between the outputs of two distinct classifiers.\nHowever, the similarity of the outputs cannot guarantee the accuracy of target\nsamples, i.e., target samples may match to wrong categories even if the\ndiscrepancy between two classifiers is small. To challenge this issue, in this\npaper, we propose a cross-domain gradient discrepancy minimization (CGDM)\nmethod which explicitly minimizes the discrepancy of gradients generated by\nsource samples and target samples. Specifically, the gradient gives a cue for\nthe semantic information of target samples so it can be used as a good\nsupervision to improve the accuracy of target samples. In order to compute the\ngradient signal of target samples, we further obtain target pseudo labels\nthrough a clustering-based self-supervised learning. Extensive experiments on\nthree widely used UDA datasets show that our method surpasses many previous\nstate-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.",
          "link": "http://arxiv.org/abs/2106.04151",
          "publishedOn": "2021-06-09T02:01:50.266Z",
          "wordCount": 647,
          "title": "Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaopeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haohang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenrui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">Junni Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hongkai Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>",
          "description": "Collecting annotated data for semantic segmentation is time-consuming and\nhard to scale up. In this paper, we for the first time propose a unified\nframework, termed as Multi-Dataset Pretraining, to take full advantage of the\nfragmented annotations of different datasets. The highlight is that the\nannotations from different domains can be efficiently reused and consistently\nboost performance for each specific domain. This is achieved by first\npretraining the network via the proposed pixel-to-prototype contrastive loss\nover multiple datasets regardless of their taxonomy labels, and followed by\nfine-tuning the pretrained model over specific dataset as usual. In order to\nbetter model the relationship among images and classes from different datasets,\nwe extend the pixel level embeddings via cross dataset mixing and propose a\npixel-to-class sparse coding strategy that explicitly models the pixel-class\nsimilarity over the manifold embedding space. In this way, we are able to\nincrease intra-class compactness and inter-class separability, as well as\nconsidering inter-class similarity across different datasets for better\ntransferability. Experiments conducted on several benchmarks demonstrate its\nsuperior performance. Notably, MDP consistently outperforms the pretrained\nmodels over ImageNet by a considerable margin, while only using less than 10%\nsamples for pretraining.",
          "link": "http://arxiv.org/abs/2106.04121",
          "publishedOn": "2021-06-09T02:01:50.234Z",
          "wordCount": null,
          "title": "Multi-dataset Pretraining: A Unified Model for Semantic Segmentation. (arXiv:2106.04121v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1\">Qi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zejia Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Qi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>",
          "description": "Vision Transformer (ViT) attains state-of-the-art performance in visual\nrecognition, and the variant, Local Vision Transformer, makes further\nimprovements. The major component in Local Vision Transformer, local attention,\nperforms the attention separately over small local windows. We rephrase local\nattention as a channel-wise locally-connected layer and analyze it from two\nnetwork regularization manners, sparse connectivity and weight sharing, as well\nas weight computation. Sparse connectivity: there is no connection across\nchannels, and each position is connected to the positions within a small local\nwindow. Weight sharing: the connection weights for one position are shared\nacross channels or within each group of channels. Dynamic weight: the\nconnection weights are dynamically predicted according to each image instance.\nWe point out that local attention resembles depth-wise convolution and its\ndynamic version in sparse connectivity. The main difference lies in weight\nsharing - depth-wise convolution shares connection weights (kernel weights)\nacross spatial positions. We empirically observe that the models based on\ndepth-wise convolution and the dynamic variant with lower computation\ncomplexity perform on-par with or sometimes slightly better than Swin\nTransformer, an instance of Local Vision Transformer, for ImageNet\nclassification, COCO object detection and ADE semantic segmentation. These\nobservations suggest that Local Vision Transformer takes advantage of two\nregularization forms and dynamic weight to increase the network capacity.",
          "link": "http://arxiv.org/abs/2106.04263",
          "publishedOn": "2021-06-09T02:01:50.205Z",
          "wordCount": null,
          "title": "Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight. (arXiv:2106.04263v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.03449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thai-Son Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stueker_S/0/1/0/all/0/1\">Sebastian Stueker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alex Waibel</a>",
          "description": "Achieving super-human performance in recognizing human speech has been a goal\nfor several decades, as researchers have worked on increasingly challenging\ntasks. In the 1990's it was discovered, that conversational speech between two\nhumans turns out to be considerably more difficult than read speech as\nhesitations, disfluencies, false starts and sloppy articulation complicate\nacoustic processing and require robust handling of acoustic, lexical and\nlanguage context, jointly. Early attempts with statistical models could only\nreach error rates over 50% and far from human performance (WER of around 5.5%).\nNeural hybrid models and recent attention-based encoder-decoder models have\nconsiderably improved performance as such contexts can now be learned in an\nintegral fashion. However, processing such contexts requires an entire\nutterance presentation and thus introduces unwanted delays before a recognition\nresult can be output. In this paper, we address performance as well as latency.\nWe present results for a system that can achieve super-human performance (at a\nWER of 5.0%, over the Switchboard conversational benchmark) at a word based\nlatency of only 1 second behind a speaker's speech. The system uses multiple\nattention-based encoder-decoder networks integrated within a novel low latency\nincremental inference approach.",
          "link": "http://arxiv.org/abs/2010.03449",
          "publishedOn": "2021-06-09T02:01:50.200Z",
          "wordCount": null,
          "title": "Super-Human Performance in Online Low-latency Recognition of Conversational Speech. (arXiv:2010.03449v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colbois_L/0/1/0/all/0/1\">Laurent Colbois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_T/0/1/0/all/0/1\">Tiago de Freitas Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcel_S/0/1/0/all/0/1\">S&#xe9;bastien Marcel</a>",
          "description": "The availability of large-scale face datasets has been key in the progress of\nface recognition. However, due to licensing issues or copyright infringement,\nsome datasets are not available anymore (e.g. MS-Celeb-1M). Recent advances in\nGenerative Adversarial Networks (GANs), to synthesize realistic face images,\nprovide a pathway to replace real datasets by synthetic datasets, both to train\nand benchmark face recognition (FR) systems. The work presented in this paper\nprovides a study on benchmarking FR systems using a synthetic dataset. First,\nwe introduce the proposed methodology to generate a synthetic dataset, without\nthe need for human intervention, by exploiting the latent structure of a\nStyleGAN2 model with multiple controlled factors of variation. Then, we confirm\nthat (i) the generated synthetic identities are not data subjects from the\nGAN's training dataset, which is verified on a synthetic dataset with 10K+\nidentities; (ii) benchmarking results on the synthetic dataset are a good\nsubstitution, often providing error rates and system ranking similar to the\nbenchmarking on the real dataset.",
          "link": "http://arxiv.org/abs/2106.04215",
          "publishedOn": "2021-06-09T02:01:50.198Z",
          "wordCount": null,
          "title": "On the use of automatically generated synthetic image datasets for benchmarking face recognition. (arXiv:2106.04215v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samet_N/0/1/0/all/0/1\">Nermin Samet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1\">Emre Akbas</a>",
          "description": "In this paper, we present a new bottom-up one-stage method for whole-body\npose estimation, which we name \"hierarchical point regression,\" or HPRNet for\nshort, referring to the network that implements this method. To handle the\nscale variance among different body parts, we build a hierarchical point\nrepresentation of body parts and jointly regress them. Unlike the existing\ntwo-stage methods, our method predicts whole-body pose in a constant time\nindependent of the number of people in an image. On the COCO WholeBody dataset,\nHPRNet significantly outperforms all previous bottom-up methods on the keypoint\ndetection of all whole-body parts (i.e. body, foot, face and hand); it also\nachieves state-of-the-art results in the face (75.4 AP) and hand (50.4 AP)\nkeypoint detection. Code and models are available at\nhttps://github.com/nerminsamet/HPRNet.git.",
          "link": "http://arxiv.org/abs/2106.04269",
          "publishedOn": "2021-06-09T02:01:50.195Z",
          "wordCount": null,
          "title": "HPRNet: Hierarchical Point Regression for Whole-Body Human Pose Estimation. (arXiv:2106.04269v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1\">Ioannis Kazakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1\">Carles Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1\">Miriam Bellver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1\">Carina Silberer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1\">Xavier Giro-i-Nieto</a>",
          "description": "Recent advances in deep learning have brought significant progress in visual\ngrounding tasks such as language-guided video object segmentation. However,\ncollecting large datasets for these tasks is expensive in terms of annotation\ntime, which represents a bottleneck. To this end, we propose a novel method,\nnamely SynthRef, for generating synthetic referring expressions for target\nobjects in an image (or video frame), and we also present and disseminate the\nfirst large-scale dataset with synthetic referring expressions for video object\nsegmentation. Our experiments demonstrate that by training with our synthetic\nreferring expressions one can improve the ability of a model to generalize\nacross different datasets, without any additional annotation cost. Moreover,\nour formulation allows its application to any object detection or segmentation\ndataset.",
          "link": "http://arxiv.org/abs/2106.04403",
          "publishedOn": "2021-06-09T02:01:50.182Z",
          "wordCount": null,
          "title": "SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quintanar_A/0/1/0/all/0/1\">A. Quintanar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Llorca_D/0/1/0/all/0/1\">D. Fern&#xe1;ndez-Llorca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parra_I/0/1/0/all/0/1\">I. Parra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izquierdo_R/0/1/0/all/0/1\">R. Izquierdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotelo_M/0/1/0/all/0/1\">M. A. Sotelo</a>",
          "description": "Understanding the behavior of road users is of vital importance for the\ndevelopment of trajectory prediction systems. In this context, the latest\nadvances have focused on recurrent structures, establishing the social\ninteraction between the agents involved in the scene. More recently, simpler\nstructures have also been introduced for predicting pedestrian trajectories,\nbased on Transformer Networks, and using positional information. They allow the\nindividual modelling of each agent's trajectory separately without any complex\ninteraction terms. Our model exploits these simple structures by adding\naugmented data (position and heading), and adapting their use to the problem of\nvehicle trajectory prediction in urban scenarios in prediction horizons up to 5\nseconds. In addition, a cross-performance analysis is performed between\ndifferent types of scenarios, including highways, intersections and\nroundabouts, using recent datasets (inD, rounD, highD and INTERACTION). Our\nmodel achieves state-of-the-art results and proves to be flexible and adaptable\nto different types of urban contexts.",
          "link": "http://arxiv.org/abs/2106.00559",
          "publishedOn": "2021-06-09T02:01:50.176Z",
          "wordCount": null,
          "title": "Predicting Vehicles Trajectories in Urban Scenarios with Transformer Networks and Augmented Information. (arXiv:2106.00559v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidari_N/0/1/0/all/0/1\">Negar Heidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "Deep neural networks have been widely used for feature learning in facial\nexpression recognition systems. However, small datasets and large intra-class\nvariability can lead to overfitting. In this paper, we propose a method which\nlearns an optimized compact network topology for real-time facial expression\nrecognition utilizing localized facial landmark features. Our method employs a\nspatio-temporal bilinear layer as backbone to capture the motion of facial\nlandmarks during the execution of a facial expression effectively. Besides, it\ntakes advantage of Monte Carlo Dropout to capture the model's uncertainty which\nis of great importance to analyze and treat uncertain cases. The performance of\nour method is evaluated on three widely used datasets and it is comparable to\nthat of video-based state-of-the-art methods while it has much less complexity.",
          "link": "http://arxiv.org/abs/2106.04332",
          "publishedOn": "2021-06-09T02:01:50.173Z",
          "wordCount": null,
          "title": "Progressive Spatio-Temporal Bilinear Network with Monte Carlo Dropout for Landmark-based Facial Expression Recognition with Uncertainty Estimation. (arXiv:2106.04332v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmermann_C/0/1/0/all/0/1\">Christian Zimmermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Argus_M/0/1/0/all/0/1\">Max Argus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1\">Thomas Brox</a>",
          "description": "This work presents improvements in monocular hand shape estimation by\nbuilding on top of recent advances in unsupervised learning. We extend momentum\ncontrastive learning and contribute a structured collection of hand images,\nwell suited for visual representation learning, which we call HanCo. We find\nthat the representation learned by established contrastive learning methods can\nbe improved significantly by exploiting advanced background removal techniques\nand multi-view information. These allow us to generate more diverse instance\npairs than those obtained by augmentations commonly used in exemplar based\napproaches. Our method leads to a more suitable representation for the hand\nshape estimation task and shows a 4.7% reduction in mesh error and a 3.6%\nimprovement in F-score compared to an ImageNet pretrained baseline. We make our\nbenchmark dataset publicly available, to encourage further research into this\ndirection.",
          "link": "http://arxiv.org/abs/2106.04324",
          "publishedOn": "2021-06-09T02:01:50.172Z",
          "wordCount": null,
          "title": "Contrastive Representation Learning for Hand Shape Estimation. (arXiv:2106.04324v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Manli Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_Q/0/1/0/all/0/1\">Qianhui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_H/0/1/0/all/0/1\">Howard Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>",
          "description": "Early prediction of cerebral palsy is essential as it leads to early\ntreatment and monitoring. Deep learning has shown promising results in\nbiomedical engineering thanks to its capacity of modelling complicated data\nwith its non-linear architecture. However, due to their complex structure, deep\nlearning models are generally not interpretable by humans, making it difficult\nfor clinicians to rely on the findings. In this paper, we propose a channel\nattention module for deep learning models to predict cerebral palsy from\ninfants' body movements, which highlights the key features (i.e. body joints)\nthe model identifies as important, thereby indicating why certain diagnostic\nresults are found. To highlight the capacity of the deep network in modelling\ninput features, we utilize raw joint positions instead of hand-crafted\nfeatures. We validate our system with a real-world infant movement dataset. Our\nproposed channel attention module enables the visualization of the vital joints\nto this disease that the network considers. Our system achieves 91.67%\naccuracy, suppressing other state-of-the-art deep learning methods.",
          "link": "http://arxiv.org/abs/2106.04471",
          "publishedOn": "2021-06-09T02:01:50.171Z",
          "wordCount": null,
          "title": "Interpreting Deep Learning based Cerebral Palsy Prediction with Channel Attention. (arXiv:2106.04471v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianshu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiali Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "The promising performances of CNNs often overshadow the need to examine\nwhether they are doing in the way we are actually interested. We show through\nexperiments that even over-parameterized models would still solve a dataset by\nrecklessly leveraging spurious correlations, or so-called 'shortcuts'. To\ncombat with this unintended propensity, we borrow the idea of printer test page\nand propose a novel approach called White Paper Assistance. Our proposed method\ninvolves the white paper to detect the extent to which the model has preference\nfor certain characterized patterns and alleviates it by forcing the model to\nmake a random guess on the white paper. We show the consistent accuracy\nimprovements that are manifest in various architectures, datasets and\ncombinations with other techniques. Experiments have also demonstrated the\nversatility of our approach on fine-grained recognition, imbalanced\nclassification and robustness to corruptions.",
          "link": "http://arxiv.org/abs/2106.04178",
          "publishedOn": "2021-06-09T02:01:50.138Z",
          "wordCount": null,
          "title": "White Paper Assistance: A Step Forward Beyond the Shortcut Learning. (arXiv:2106.04178v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuelin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy J. Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>",
          "description": "Synthesizing novel views of dynamic humans from stationary monocular cameras\nis a popular scenario. This is particularly attractive as it does not require\nstatic scenes, controlled environments, or specialized hardware. In contrast to\ntechniques that exploit multi-view observations to constrain the modeling,\ngiven a single fixed viewpoint only, the problem of modeling the dynamic scene\nis significantly more under-constrained and ill-posed. In this paper, we\nintroduce Neural Motion Consensus Flow (MoCo-Flow), a representation that\nmodels the dynamic scene using a 4D continuous time-variant function. The\nproposed representation is learned by an optimization which models a dynamic\nscene that minimizes the error of rendering all observation images. At the\nheart of our work lies a novel optimization formulation, which is constrained\nby a motion consensus regularization on the motion flow. We extensively\nevaluate MoCo-Flow on several datasets that contain human motions of varying\ncomplexity, and compare, both qualitatively and quantitatively, to several\nbaseline methods and variants of our methods. Pretrained model, code, and data\nwill be released for research purposes upon paper acceptance.",
          "link": "http://arxiv.org/abs/2106.04477",
          "publishedOn": "2021-06-09T02:01:50.137Z",
          "wordCount": null,
          "title": "MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras. (arXiv:2106.04477v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havtorn_J/0/1/0/all/0/1\">Jakob D. Havtorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maaloe_L/0/1/0/all/0/1\">Lars Maal&#xf8;e</a>",
          "description": "Deep generative models have been demonstrated as state-of-the-art density\nestimators. Yet, recent work has found that they often assign a higher\nlikelihood to data from outside the training distribution. This seemingly\nparadoxical behavior has caused concerns over the quality of the attained\ndensity estimates. In the context of hierarchical variational autoencoders, we\nprovide evidence to explain this behavior by out-of-distribution data having\nin-distribution low-level features. We argue that this is both expected and\ndesirable behavior. With this insight in hand, we develop a fast, scalable and\nfully unsupervised likelihood-ratio score for OOD detection that requires data\nto be in-distribution across all feature-levels. We benchmark the method on a\nvast set of data and model combinations and achieve state-of-the-art results on\nout-of-distribution detection.",
          "link": "http://arxiv.org/abs/2102.08248",
          "publishedOn": "2021-06-09T02:01:50.133Z",
          "wordCount": null,
          "title": "Hierarchical VAEs Know What They Don't Know. (arXiv:2102.08248v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11654",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kouzehkanan_Z/0/1/0/all/0/1\">Zahra Mousavi Kouzehkanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tavakoli_S/0/1/0/all/0/1\">Sajad Tavakoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alipanah_A/0/1/0/all/0/1\">Arezoo Alipanah</a>",
          "description": "The nucleus of white blood cells (WBCs) plays a significant role in their\ndetection and classification. Appropriate feature extraction of the nucleus is\nnecessary to fit a suitable artificial intelligence model to classify WBCs.\nTherefore, designing a method is needed to segment the nucleus accurately.\nThere should be a comparison between the ground truths distinguished by a\nhematologist and the detected nuclei to evaluate the performance of the nucleus\nsegmentation method accurately. It is a time-consuming and tedious task for\nexperts to establish the ground truth manually. This paper presents an\nintelligent open-source software called Easy-GT to create the ground truth of\nWBCs' nucleus faster and easier. This software first detects the nucleus by\nemploying a new Otsu's thresholding-based method with a dice similarity\ncoefficient (DSC) of 95.42 %; the hematologist can then create a more accurate\nground truth, using the designed buttons to modify the threshold value. This\nsoftware can speed up ground truth's forming process more than six times.",
          "link": "http://arxiv.org/abs/2101.11654",
          "publishedOn": "2021-06-09T02:01:50.101Z",
          "wordCount": 636,
          "title": "Easy-GT: Open-Source Software to Facilitate Making the Ground Truth for White Blood Cells Nucleus. (arXiv:2101.11654v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiapeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1\">Ruili Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yujun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Deli Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zhengjun Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qifeng Chen</a>",
          "description": "The latent space of a Generative Adversarial Network (GAN) has been shown to\nencode rich semantics within some subspaces. To identify these subspaces,\nresearchers typically analyze the statistical information from a collection of\nsynthesized data, and the identified subspaces tend to control image attributes\nglobally (i.e., manipulating an attribute causes the change of an entire\nimage). By contrast, this work introduces low-rank subspaces that enable more\nprecise control of GAN generation. Concretely, given an arbitrary image and a\nregion of interest (e.g., eyes of face images), we manage to relate the latent\nspace to the image region with the Jacobian matrix and then use low-rank\nfactorization to discover steerable latent subspaces. There are three\ndistinguishable strengths of our approach that can be aptly called LowRankGAN.\nFirst, compared to analytic algorithms in prior work, our low-rank\nfactorization of Jacobians is able to find the low-dimensional representation\nof attribute manifold, making image editing more precise and controllable.\nSecond, low-rank factorization naturally yields a null space of attributes such\nthat moving the latent code within it only affects the outer region of\ninterest. Therefore, local image editing can be simply achieved by projecting\nan attribute vector into the null space without relying on a spatial mask as\nexisting methods do. Third, our method can robustly work with a local region\nfrom one image for analysis yet well generalize to other images, making it much\neasy to use in practice. Extensive experiments on state-of-the-art GAN models\n(including StyleGAN2 and BigGAN) trained on various datasets demonstrate the\neffectiveness of our LowRankGAN.",
          "link": "http://arxiv.org/abs/2106.04488",
          "publishedOn": "2021-06-09T02:01:49.979Z",
          "wordCount": 683,
          "title": "Low-Rank Subspaces in GANs. (arXiv:2106.04488v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meinke_A/0/1/0/all/0/1\">Alexander Meinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitterwolf_J/0/1/0/all/0/1\">Julian Bitterwolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "When applying machine learning in safety-critical systems, a reliable\nassessment of the uncertainy of a classifier is required. However, deep neural\nnetworks are known to produce highly overconfident predictions on\nout-of-distribution (OOD) data and even if trained to be non-confident on OOD\ndata one can still adversarially manipulate OOD data so that the classifer\nagain assigns high confidence to the manipulated samples. In this paper we\npropose a novel method where from first principles we combine a certifiable OOD\ndetector with a standard classifier into an OOD aware classifier. In this way\nwe achieve the best of two worlds: certifiably adversarially robust OOD\ndetection, even for OOD samples close to the in-distribution, without loss in\nprediction accuracy and close to state-of-the-art OOD detection performance for\nnon-manipulated OOD data. Moreover, due to the particular construction our\nclassifier provably avoids the asymptotic overconfidence problem of standard\nneural networks.",
          "link": "http://arxiv.org/abs/2106.04260",
          "publishedOn": "2021-06-09T02:01:49.929Z",
          "wordCount": 581,
          "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free. (arXiv:2106.04260v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kerola_T/0/1/0/all/0/1\">Tommi Kerola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanehira_A/0/1/0/all/0/1\">Atsushi Kanehira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kudo_Y/0/1/0/all/0/1\">Yasunori Kudo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallet_A/0/1/0/all/0/1\">Alexis Vallet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1\">Adrien Gaidon</a>",
          "description": "Panoptic segmentation brings together two separate tasks: instance and\nsemantic segmentation. Although they are related, unifying them faces an\napparent paradox: how to learn simultaneously instance-specific and\ncategory-specific (i.e. instance-agnostic) representations jointly. Hence,\nstate-of-the-art panoptic segmentation methods use complex models with a\ndistinct stream for each task. In contrast, we propose Hierarchical Lov\\'asz\nEmbeddings, per pixel feature vectors that simultaneously encode instance- and\ncategory-level discriminative information. We use a hierarchical Lov\\'asz hinge\nloss to learn a low-dimensional embedding space structured into a unified\nsemantic and instance hierarchy without requiring separate network branches or\nobject proposals. Besides modeling instances precisely in a proposal-free\nmanner, our Hierarchical Lov\\'asz Embeddings generalize to categories by using\na simple Nearest-Class-Mean classifier, including for non-instance \"stuff\"\nclasses where instance segmentation methods are not applicable. Our simple\nmodel achieves state-of-the-art results compared to existing proposal-free\npanoptic segmentation methods on Cityscapes, COCO, and Mapillary Vistas.\nFurthermore, our model demonstrates temporal stability between video frames.",
          "link": "http://arxiv.org/abs/2106.04555",
          "publishedOn": "2021-06-09T02:01:49.864Z",
          "wordCount": 602,
          "title": "Hierarchical Lov\\'asz Embeddings for Proposal-free Panoptic Segmentation. (arXiv:2106.04555v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marinescu_R/0/1/0/all/0/1\">Razvan V Marinescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1\">Daniel Moyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golland_P/0/1/0/all/0/1\">Polina Golland</a>",
          "description": "Machine learning models are commonly trained end-to-end and in a supervised\nsetting, using paired (input, output) data. Examples include recent\nsuper-resolution methods that train on pairs of (low-resolution,\nhigh-resolution) images. However, these end-to-end approaches require\nre-training every time there is a distribution shift in the inputs (e.g., night\nimages vs daylight) or relevant latent variables (e.g., camera blur or hand\nmotion). In this work, we leverage state-of-the-art (SOTA) generative models\n(here StyleGAN2) for building powerful image priors, which enable application\nof Bayes' theorem for many downstream reconstruction tasks. Our method,\nBayesian Reconstruction through Generative Models (BRGM), uses a single\npre-trained generator model to solve different image restoration tasks, i.e.,\nsuper-resolution and in-painting, by combining it with different forward\ncorruption models. We keep the weights of the generator model fixed, and\nreconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)\nestimate over the input latent vector that generated the reconstructed image.\nWe further use variational inference to approximate the posterior distribution\nover the latent vectors, from which we sample multiple solutions. We\ndemonstrate BRGM on three large and diverse datasets: (i) 60,000 images from\nthe Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III\nand (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.\nAcross all three datasets and without any dataset-specific hyperparameter\ntuning, our simple approach yields performance competitive with current\ntask-specific state-of-the-art methods on super-resolution and in-painting,\nwhile being more generalisable and without requiring any training. Our source\ncode and pre-trained models are available online:\nhttps://razvanmarinescu.github.io/brgm/.",
          "link": "http://arxiv.org/abs/2012.04567",
          "publishedOn": "2021-06-09T02:01:49.831Z",
          "wordCount": 758,
          "title": "Bayesian Image Reconstruction using Deep Generative Models. (arXiv:2012.04567v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khandan_N/0/1/0/all/0/1\">Nouna Khandan</a>",
          "description": "Digitization, i.e., the process of converting information into a digital\nformat, may provide various opportunities (e.g., increase in productivity,\ndisaster recovery, and environmentally friendly solutions) and challenges for\nbusinesses. In this context, one of the main challenges would be to accurately\nclassify numerous scanned documents uploaded every day by customers as usual\nbusiness processes. For example, processes in banking (e.g., applying for\nloans) or the Government Registry of BDM (Births, Deaths, and Marriages)\napplications may involve uploading several documents such as a driver's license\nand passport. There are not many studies available to address the challenge as\nan application of image classification. Although some studies are available\nwhich used various methods, a more accurate model is still required. The\ncurrent study has proposed a robust fusion model to define the type of identity\ndocuments accurately. The proposed approach is based on two different methods\nin which images are classified based on their visual features and text\nfeatures. A novel model based on statistics and regression has been proposed to\ncalculate the confidence level for the feature-based classifier. A fuzzy-mean\nfusion model has been proposed to combine the classifier results based on their\nconfidence score. The proposed approach has been implemented using Python and\nexperimentally validated on synthetic and real-world datasets. The performance\nof the proposed model is evaluated using the Receiver Operating Characteristic\n(ROC) curve analysis.",
          "link": "http://arxiv.org/abs/2106.04345",
          "publishedOn": "2021-06-09T02:01:49.802Z",
          "wordCount": 661,
          "title": "An Intelligent Hybrid Model for Identity Document Classification. (arXiv:2106.04345v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sannigrahi_S/0/1/0/all/0/1\">Srikanta Sannigrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_B/0/1/0/all/0/1\">Bidroha Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Arunima Sarkar Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilla_F/0/1/0/all/0/1\">Francesco Pilla</a>",
          "description": "The increasing level of marine plastic pollution poses severe threats to the\nmarine ecosystem and biodiversity. The present study attempted to explore the\nfull functionality of open Sentinel satellite data and ML models for detecting\nand classifying floating plastic debris in Mytilene (Greece), Limassol\n(Cyprus), Calabria (Italy), and Beirut (Lebanon). Two ML models, i.e. Support\nVector Machine (SVM) and Random Forest (RF) were utilized to carry out the\nclassification analysis. In-situ plastic location data was collected from the\ncontrol experiment conducted in Mytilene, Greece and Limassol, Cyprus, and the\nsame was considered for training the models. Both remote sensing bands and\nspectral indices were used for developing the ML models. A spectral signature\nprofile for plastic was created for discriminating the floating plastic from\nother marine debris. A newly developed index, kernel Normalized Difference\nVegetation Index (kNDVI), was incorporated into the modelling to examine its\ncontribution to model performances. Both SVM and RF were performed well in five\nmodels and test case combinations. Among the two ML models, the highest\nperformance was measured for the RF. The inclusion of kNDVI was found effective\nand increased the model performances, reflected by high balanced accuracy\nmeasured for model 2 (~80% to ~98 % for SVM and ~87% to ~97 % for RF). Using\nthe best-performed model, an automated floating plastic detection system was\ndeveloped and tested in Calabria and Beirut. For both sites, the trained model\nhad detected the floating plastic with ~99% accuracy. Among the six predictors,\nthe FDI was found the most important variable for detecting marine floating\nplastic. These findings collectively suggest that high-resolution remote\nsensing imagery and the automated ML models can be an effective alternative for\nthe cost-effective detection of marine floating plastic.",
          "link": "http://arxiv.org/abs/2106.03694",
          "publishedOn": "2021-06-09T02:01:49.783Z",
          "wordCount": 747,
          "title": "Detection of marine floating plastic using Sentinel-2 imagery and machine learning models. (arXiv:2106.03694v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Vision transformers (ViTs) have recently received explosive popularity, but\ntheir enormous model sizes and training costs remain daunting. Conventional\npost-training pruning often incurs higher training budgets. In contrast, this\npaper aims to trim down both the training memory overhead and the inference\ncomplexity, without scarifying the achievable accuracy. We launch and report\nthe first-of-its-kind comprehensive exploration, on taking a unified approach\nof integrating sparsity in ViTs \"from end to end\". Specifically, instead of\ntraining full ViTs, we dynamically extract and train sparse subnetworks, while\nsticking to a fixed small parameter budget. Our approach jointly optimizes\nmodel parameters and explores connectivity throughout training, ending up with\none sparse network as the final output. The approach is seamlessly extended\nfrom unstructured to structured sparsity, the latter by considering to guide\nthe prune-and-grow of self-attention heads inside ViTs. For additional\nefficiency gains, we further co-explore data and architecture sparsity, by\nplugging in a novel learnable token selector to adaptively determine the\ncurrently most vital patches. Extensive results validate the effectiveness of\nour proposals on ImageNet with diverse ViT backbones. For instance, at 40%\nstructured sparsity, our sparsified DeiT-Base can achieve 0.42% accuracy gain,\nat 33.13% and 24.70% running time} savings, compared to its dense counterpart.\nPerhaps most surprisingly, we find that the proposed sparse (co-)training can\neven improve the ViT accuracy rather than compromising it, making sparsity a\ntantalizing \"free lunch\". For example, our sparsified DeiT-Small at 5%, 50%\nsparsity for (data, architecture), improves 0.28% top-1 accuracy and meanwhile\nenjoys 49.32% FLOPs and 4.40% running time savings.",
          "link": "http://arxiv.org/abs/2106.04533",
          "publishedOn": "2021-06-09T02:01:49.693Z",
          "wordCount": 690,
          "title": "Chasing Sparsity in Vision Transformers:An End-to-End Exploration. (arXiv:2106.04533v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04381",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rundo_L/0/1/0/all/0/1\">Leonardo Rundo</a>",
          "description": "Nowadays, the amount of heterogeneous biomedical data is increasing more and\nmore thanks to novel sensing techniques and high-throughput technologies. In\nreference to biomedical image analysis, the advances in image acquisition\nmodalities and high-throughput imaging experiments are creating new challenges.\nThis huge information ensemble could overwhelm the analytic capabilities needed\nby physicians in their daily decision-making tasks as well as by biologists\ninvestigating complex biochemical systems. In particular, quantitative imaging\nmethods convey scientifically and clinically relevant information in\nprediction, prognosis or treatment response assessment, by also considering\nradiomics approaches. Therefore, the computational analysis of medical and\nbiological images plays a key role in radiology and laboratory applications. In\nthis regard, frameworks based on advanced Machine Learning and Computational\nIntelligence can significantly improve traditional Image Processing and Pattern\nRecognition approaches. However, conventional Artificial Intelligence\ntechniques must be tailored to address the unique challenges concerning\nbiomedical imaging data. This thesis aims at proposing novel and advanced\ncomputer-assisted methods for biomedical image analysis, also as an instrument\nin the development of Clinical Decision Support Systems, by always keeping in\nmind the clinical feasibility of the developed solutions. In conclusion, the\nultimate goal of these research studies is to gain clinically and biologically\nuseful insights that can guide differential diagnosis and therapies, leading\ntowards biomedical data integration for personalized medicine. As a matter of\nfact, the proposed computer-assisted bioimage analysis methods can be\nbeneficial for the definition of imaging biomarkers, as well as for\nquantitative medicine and biology.",
          "link": "http://arxiv.org/abs/2106.04381",
          "publishedOn": "2021-06-09T02:01:49.645Z",
          "wordCount": 685,
          "title": "Computer-Assisted Analysis of Biomedical Images. (arXiv:2106.04381v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fushishita_N/0/1/0/all/0/1\">Naoya Fushishita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tejero_de_Pablos_A/0/1/0/all/0/1\">Antonio Tejero-de-Pablos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuta_Y/0/1/0/all/0/1\">Yusuke Mukuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1\">Tatsuya Harada</a>",
          "description": "Generating videos predicting the future of a given sequence has been an area\nof active research in recent years. However, an essential problem remains\nunsolved: most of the methods require large computational cost and memory usage\nfor training. In this paper, we propose a novel method for generating future\nprediction videos with less memory usage than the conventional methods. This is\na critical stepping stone in the path towards generating videos with high image\nquality, similar to that of generated images in the latest works in the field\nof image generation. We achieve high-efficiency by training our method in two\nstages: (1) image reconstruction to encode video frames into latent variables,\nand (2) latent variable prediction to generate the future sequence. Our method\nachieves an efficient compression of video into low-dimensional latent\nvariables by decomposing each frame according to its hierarchical structure.\nThat is, we consider that video can be separated into background and foreground\nobjects, and that each object holds time-varying and time-independent\ninformation independently. Our experiments show that the proposed method can\nefficiently generate future prediction videos, even for complex datasets that\ncannot be handled by previous methods.",
          "link": "http://arxiv.org/abs/2106.03502",
          "publishedOn": "2021-06-09T02:01:49.621Z",
          "wordCount": 649,
          "title": "Efficient training for future video generation based on hierarchical disentangled representation of latent variables. (arXiv:2106.03502v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozenberg_R/0/1/0/all/0/1\">Rapha&#xeb;l Rozenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesnouin_J/0/1/0/all/0/1\">Joseph Gesnouin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moutarde_F/0/1/0/all/0/1\">Fabien Moutarde</a>",
          "description": "Pedestrian motion behavior involves a combination of individual goals and\nsocial interactions with other agents. In this article, we present a\nnon-symmetrical bidirectional recurrent neural network architecture called\nU-RNN as a sequence encoder and evaluate its relevance to replace LSTMs for\nvarious forecasting models. Experimental results on the Trajnet++ benchmark\nshow that the U-LSTM variant can yield better results regarding every available\nmetric (ADE, FDE, Collision rate) than common LSTMs sequence encoders for a\nvariety of approaches and interaction modules.\n\nOur implementation of the asymmetrical Bi-RNNs for the Trajnet++ benchmark is\navailable at:\ngithub.com/JosephGesnouin/Asymmetrical-Bi-RNNs-to-encode-pedestrian-trajectories",
          "link": "http://arxiv.org/abs/2106.04419",
          "publishedOn": "2021-06-09T02:01:49.615Z",
          "wordCount": 534,
          "title": "Asymmetrical Bi-RNN for pedestrian trajectory encoding. (arXiv:2106.04419v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Siqi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuanjun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "The common implementation of face recognition systems as a cascade of a\ndetection stage and a recognition or verification stage can cause problems\nbeyond failures of the detector. When the detector succeeds, it can detect\nfaces that cannot be recognized, no matter how capable the recognition system.\nRecognizability, a latent variable, should therefore be factored into the\ndesign and implementation of face recognition systems. We propose a measure of\nrecognizability of a face image that leverages a key empirical observation: an\nembedding of face images, implemented by a deep neural network trained using\nmostly recognizable identities, induces a partition of the hypersphere whereby\nunrecognizable identities cluster together. This occurs regardless of the\nphenomenon that causes a face to be unrecognizable, it be optical or motion\nblur, partial occlusion, spatial quantization, poor illumination. Therefore, we\nuse the distance from such an \"unrecognizable identity\" as a measure of\nrecognizability, and incorporate it in the design of the over-all system. We\nshow that accounting for recognizability reduces error rate of single-image\nface recognition by 58% at FAR=1e-5 on the IJB-C Covariate Verification\nbenchmark, and reduces verification error rate by 24% at FAR=1e-5 in set-based\nrecognition on the IJB-C benchmark.",
          "link": "http://arxiv.org/abs/2106.04112",
          "publishedOn": "2021-06-09T02:01:49.596Z",
          "wordCount": 624,
          "title": "Harnessing Unrecognizable Faces for Face Recognition. (arXiv:2106.04112v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenliang Xu</a>",
          "description": "Recent works find that AI algorithms learn biases from data. Therefore, it is\nurgent and vital to identify biases in AI algorithms. However, the previous\nbias identification pipeline overly relies on human experts to conjecture\npotential biases (e.g., gender), which may neglect other underlying biases not\nrealized by humans. To help human experts better find the AI algorithms'\nbiases, we study a new problem in this work -- for a classifier that predicts a\ntarget attribute of the input image, discover its unknown biased attribute.\n\nTo solve this challenging problem, we use a hyperplane in the generative\nmodel's latent space to represent an image attribute; thus, the original\nproblem is transformed to optimizing the hyperplane's normal vector and offset.\nWe propose a novel total-variation loss within this framework as the objective\nfunction and a new orthogonalization penalty as a constraint. The latter\nprevents trivial solutions in which the discovered biased attribute is\nidentical with the target or one of the known-biased attributes. Extensive\nexperiments on both disentanglement datasets and real-world datasets show that\nour method can discover biased attributes and achieve better disentanglement\nw.r.t. target attributes. Furthermore, the qualitative results show that our\nmethod can discover unnoticeable biased attributes for various object and scene\nclassifiers, proving our method's generalizability for detecting biased\nattributes in diverse domains of images. The code is available at\nhttps://git.io/J3kMh.",
          "link": "http://arxiv.org/abs/2104.14556",
          "publishedOn": "2021-06-09T02:01:49.563Z",
          "wordCount": 680,
          "title": "Discover the Unknown Biased Attribute of an Image Classifier. (arXiv:2104.14556v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weder_S/0/1/0/all/0/1\">Silvan Weder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonberger_J/0/1/0/all/0/1\">Johannes L. Sch&#xf6;nberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1\">Martin R. Oswald</a>",
          "description": "We present a novel online depth map fusion approach that learns depth map\naggregation in a latent feature space. While previous fusion methods use an\nexplicit scene representation like signed distance functions (SDFs), we propose\na learned feature representation for the fusion. The key idea is a separation\nbetween the scene representation used for the fusion and the output scene\nrepresentation, via an additional translator network. Our neural network\narchitecture consists of two main parts: a depth and feature fusion\nsub-network, which is followed by a translator sub-network to produce the final\nsurface representation (e.g. TSDF) for visualization or other tasks. Our\napproach is an online process, handles high noise levels, and is particularly\nable to deal with gross outliers common for photometric stereo-based depth\nmaps. Experiments on real and synthetic data demonstrate improved results\ncompared to the state of the art, especially in challenging scenarios with\nlarge amounts of noise and outliers.",
          "link": "http://arxiv.org/abs/2011.14791",
          "publishedOn": "2021-06-09T02:01:49.264Z",
          "wordCount": null,
          "title": "NeuralFusion: Online Depth Fusion in Latent Space. (arXiv:2011.14791v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jia Xu</a>",
          "description": "We present DistillFlow, a knowledge distillation approach to learning optical\nflow. DistillFlow trains multiple teacher models and a student model, where\nchallenging transformations are applied to the input of the student model to\ngenerate hallucinated occlusions as well as less confident predictions. Then, a\nself-supervised learning framework is constructed: confident predictions from\nteacher models are served as annotations to guide the student model to learn\noptical flow for those less confident predictions. The self-supervised learning\nframework enables us to effectively learn optical flow from unlabeled data, not\nonly for non-occluded pixels, but also for occluded pixels. DistillFlow\nachieves state-of-the-art unsupervised learning performance on both KITTI and\nSintel datasets. Our self-supervised pre-trained model also provides an\nexcellent initialization for supervised fine-tuning, suggesting an alternate\ntraining paradigm in contrast to current supervised learning methods that\nhighly rely on pre-training on synthetic data. At the time of writing, our\nfine-tuned models ranked 1st among all monocular methods on the KITTI 2015\nbenchmark, and outperform all published methods on the Sintel Final benchmark.\nMore importantly, we demonstrate the generalization capability of DistillFlow\nin three aspects: framework generalization, correspondence generalization and\ncross-dataset generalization.",
          "link": "http://arxiv.org/abs/2106.04195",
          "publishedOn": "2021-06-09T02:01:49.262Z",
          "wordCount": null,
          "title": "Learning by Distillation: A Self-Supervised Learning Framework for Optical Flow Estimation. (arXiv:2106.04195v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.05778",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dutta_S/0/1/0/all/0/1\">Saikat Dutta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shah_N/0/1/0/all/0/1\">Nisarg A. Shah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mittal_A/0/1/0/all/0/1\">Anurag Mittal</a>",
          "description": "This paper explores an efficient solution for Space-time Super-Resolution,\naiming to generate High-resolution Slow-motion videos from Low Resolution and\nLow Frame rate videos. A simplistic solution is the sequential running of Video\nSuper Resolution and Video Frame interpolation models. However, this type of\nsolutions are memory inefficient, have high inference time, and could not make\nthe proper use of space-time relation property. To this extent, we first\ninterpolate in LR space using quadratic modeling. Input LR frames are\nsuper-resolved using a state-of-the-art Video Super-Resolution method. Flowmaps\nand blending mask which are used to synthesize LR interpolated frame is reused\nin HR space using bilinear upsampling. This leads to a coarse estimate of HR\nintermediate frame which often contains artifacts along motion boundaries. We\nuse a refinement network to improve the quality of HR intermediate frame via\nresidual learning. Our model is lightweight and performs better than current\nstate-of-the-art models in REDS STSR Validation set.",
          "link": "http://arxiv.org/abs/2104.05778",
          "publishedOn": "2021-06-09T02:01:49.261Z",
          "wordCount": null,
          "title": "Efficient Space-time Video Super Resolution using Low-Resolution Flow and Mask Upsampling. (arXiv:2104.05778v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kortylewski_A/0/1/0/all/0/1\">Adam Kortylewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1\">Weichao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cihang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1\">Sarah Adel Bargal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1\">Stan Sclaroff</a>",
          "description": "Most machine learning models are validated and tested on fixed datasets. This\ncan give an incomplete picture of the capabilities and weaknesses of the model.\nSuch weaknesses can be revealed at test time in the real world. The risks\ninvolved in such failures can be loss of profits, loss of time or even loss of\nlife in certain critical applications. In order to alleviate this issue,\nsimulators can be controlled in a fine-grained manner using interpretable\nparameters to explore the semantic image manifold. In this work, we propose a\nframework for learning how to test machine learning algorithms using simulators\nin an adversarial manner in order to find weaknesses in the model before\ndeploying it in critical scenarios. We apply this model in a face recognition\nscenario. We are the first to show that weaknesses of models trained on real\ndata can be discovered using simulated samples. Using our proposed method, we\ncan find adversarial synthetic faces that fool contemporary face recognition\nmodels. This demonstrates the fact that these models have weaknesses that are\nnot measured by commonly used validation datasets. We hypothesize that this\ntype of adversarial examples are not isolated, but usually lie in connected\ncomponents in the latent space of the simulator. We present a method to find\nthese adversarial regions as opposed to the typical adversarial points found in\nthe adversarial example literature.",
          "link": "http://arxiv.org/abs/2106.04569",
          "publishedOn": "2021-06-09T02:01:48.963Z",
          "wordCount": 674,
          "title": "Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1\">Andrea Alamia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozafari_M/0/1/0/all/0/1\">Milad Mozafari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1\">Bhavin Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1\">Rufin VanRullen</a>",
          "description": "Brain-inspired machine learning is gaining increasing consideration,\nparticularly in computer vision. Several studies investigated the inclusion of\ntop-down feedback connections in convolutional networks; however, it remains\nunclear how and when these connections are functionally helpful. Here we\naddress this question in the context of object recognition under noisy\nconditions. We consider deep convolutional networks (CNNs) as models of\nfeed-forward visual processing and implement Predictive Coding (PC) dynamics\nthrough feedback connections (predictive feedback) trained for reconstruction\nor classification of clean images. To directly assess the computational role of\npredictive feedback in various experimental situations, we optimize and\ninterpret the hyper-parameters controlling the network's recurrent dynamics.\nThat is, we let the optimization process determine whether top-down connections\nand predictive coding dynamics are functionally beneficial. Across different\nmodel depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and\nagainst various types of noise (CIFAR100-C), we find that the network\nincreasingly relies on top-down predictions as the noise level increases; in\ndeeper networks, this effect is most prominent at lower layers. In addition,\nthe accuracy of the network implementing PC dynamics significantly increases\nover time-steps, compared to its equivalent forward network. All in all, our\nresults provide novel insights relevant to Neuroscience by confirming the\ncomputational role of feedback connections in sensory systems, and to Machine\nLearning by revealing how these can improve the robustness of current vision\nmodels.",
          "link": "http://arxiv.org/abs/2106.04225",
          "publishedOn": "2021-06-09T02:01:48.879Z",
          "wordCount": 678,
          "title": "On the role of feedback in visual processing: a predictive coding perspective. (arXiv:2106.04225v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_C/0/1/0/all/0/1\">Charu Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapil_S/0/1/0/all/0/1\">Siddhant R. Kapil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_D/0/1/0/all/0/1\">David Chapman</a>",
          "description": "Person Re-Identification is an important problem in computer vision-based\nsurveillance applications, in which the same person is attempted to be\nidentified from surveillance photographs in a variety of nearby zones. At\npresent, the majority of Person re-ID techniques are based on Convolutional\nNeural Networks (CNNs), but Vision Transformers are beginning to displace pure\nCNNs for a variety of object recognition tasks. The primary output of a vision\ntransformer is a global classification token, but vision transformers also\nyield local tokens which contain additional information about local regions of\nthe image. Techniques to make use of these local tokens to improve\nclassification accuracy are an active area of research. We propose a novel\nLocally Aware Transformer (LA-Transformer) that employs a Parts-based\nConvolution Baseline (PCB)-inspired strategy for aggregating globally enhanced\nlocal classification tokens into an ensemble of $\\sqrt{N}$ classifiers, where\n$N$ is the number of patches. An additional novelty is that we incorporate\nblockwise fine-tuning which further improves re-ID accuracy. LA-Transformer\nwith blockwise fine-tuning achieves rank-1 accuracy of $98.27 \\%$ with standard\ndeviation of $0.13$ on the Market-1501 and $98.7\\%$ with standard deviation of\n$0.2$ on the CUHK03 dataset respectively, outperforming all other\nstate-of-the-art published methods at the time of writing.",
          "link": "http://arxiv.org/abs/2106.03720",
          "publishedOn": "2021-06-09T02:01:48.879Z",
          "wordCount": null,
          "title": "Person Re-Identification with a Locally Aware Transformer. (arXiv:2106.03720v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>",
          "description": "Attention-based neural networks such as the Vision Transformer (ViT) have\nrecently attained state-of-the-art results on many computer vision benchmarks.\nScale is a primary ingredient in attaining excellent results, therefore,\nunderstanding a model's scaling properties is a key to designing future\ngenerations effectively. While the laws for scaling Transformer language models\nhave been studied, it is unknown how Vision Transformers scale. To address\nthis, we scale ViT models and data, both up and down, and characterize the\nrelationships between error rate, data, and compute. Along the way, we refine\nthe architecture and training of ViT, reducing memory consumption and\nincreasing accuracy the resulting models. As a result, we successfully train a\nViT model with two billion parameters, which attains a new state-of-the-art on\nImageNet of 90.45% top-1 accuracy. The model also performs well on few-shot\nlearning, for example, attaining 84.86% top-1 accuracy on ImageNet with only 10\nexamples per class.",
          "link": "http://arxiv.org/abs/2106.04560",
          "publishedOn": "2021-06-09T02:01:48.863Z",
          "wordCount": 584,
          "title": "Scaling Vision Transformers. (arXiv:2106.04560v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "We present Meta Learning for Knowledge Distillation (MetaDistil), a simple\nyet effective alternative to traditional knowledge distillation (KD) methods\nwhere the teacher model is fixed during training. We show the teacher network\ncan learn to better transfer knowledge to the student network (i.e., learning\nto teach) with the feedback from the performance of the distilled student\nnetwork in a meta learning framework. Moreover, we introduce a pilot update\nmechanism to improve the alignment between the inner-learner and meta-learner\nin meta learning algorithms that focus on an improved inner-learner.\nExperiments on various benchmarks show that MetaDistil can yield significant\nimprovements compared with traditional KD algorithms and is less sensitive to\nthe choice of different student capacity and hyperparameters, facilitating the\nuse of KD on different tasks and models. The code is available at\nhttps://github.com/JetRunner/MetaDistil",
          "link": "http://arxiv.org/abs/2106.04570",
          "publishedOn": "2021-06-09T02:01:48.833Z",
          "wordCount": 567,
          "title": "Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruocheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "We present Language-mediated, Object-centric Representation Learning (LORL),\na paradigm for learning disentangled, object-centric scene representations from\nvision and language. LORL builds upon recent advances in unsupervised object\ndiscovery and segmentation, notably MONet and Slot Attention. While these\nalgorithms learn an object-centric representation just by reconstructing the\ninput image, LORL enables them to further learn to associate the learned\nrepresentations to concepts, i.e., words for object categories, properties, and\nspatial relationships, from language input. These object-centric concepts\nderived from language facilitate the learning of object-centric\nrepresentations. LORL can be integrated with various unsupervised object\ndiscovery algorithms that are language-agnostic. Experiments show that the\nintegration of LORL consistently improves the performance of unsupervised\nobject discovery methods on two datasets via the help of language. We also show\nthat concepts learned by LORL, in conjunction with object discovery methods,\naid downstream tasks such as referring expression comprehension.",
          "link": "http://arxiv.org/abs/2012.15814",
          "publishedOn": "2021-06-09T02:01:48.822Z",
          "wordCount": 627,
          "title": "Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1805.10174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1\">Christos-Savvas Bouganis</a>",
          "description": "The predictive power of Convolutional Neural Networks (CNNs) has been an\nintegral factor for emerging latency-sensitive applications, such as autonomous\ndrones and vehicles. Such systems employ multiple CNNs, each one trained for a\nparticular task. The efficient mapping of multiple CNNs on a single FPGA device\nis a challenging task as the allocation of compute resources and external\nmemory bandwidth needs to be optimised at design time. This paper proposes\nf-CNN$^{\\text{x}}$, an automated toolflow for the optimised mapping of multiple\nCNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with\nan automated design space exploration method that considers the user-specified\nperformance requirements for each model to allocate compute resources and\ngenerate a synthesisable accelerator. Moreover, f-CNN$^{\\text{x}}$ employs a\nnovel scheduling algorithm that alleviates the limitations of the memory\nbandwidth contention between CNNs and sustains the high utilisation of the\narchitecture. Experimental evaluation shows that f-CNN$^{\\text{x}}$'s designs\noutperform contention-unaware FPGA mappings by up to 50% and deliver up to 6.8x\nhigher performance-per-Watt over highly optimised GPU designs for multi-CNN\nsystems.",
          "link": "http://arxiv.org/abs/1805.10174",
          "publishedOn": "2021-06-09T02:01:48.816Z",
          "wordCount": 652,
          "title": "f-CNN$^{\\text{x}}$: A Toolflow for Mapping Multi-CNN Applications on FPGAs. (arXiv:1805.10174v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1\">Amir Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantorov_V/0/1/0/all/0/1\">Vadim Kantorov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1\">Colorado J Reed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1\">Roei Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1\">Anna Rohrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "Unsupervised pretraining has recently proven beneficial for computer vision\ntasks, including object detection. However, previous self-supervised approaches\nare not designed to handle a key aspect of detection: localizing objects. Here,\nwe present DETReg, an unsupervised pretraining approach for object DEtection\nwith TRansformers using Region priors. Motivated by the two tasks underlying\nobject detection: localization and categorization, we combine two complementary\nsignals for self-supervision. For an object localization signal, we use pseudo\nground truth object bounding boxes from an off-the-shelf unsupervised region\nproposal method, Selective Search, which does not require training data and can\ndetect objects at a high recall rate and very low precision. The categorization\nsignal comes from an object embedding loss that encourages invariant object\nrepresentations, from which the object category can be inferred. We show how to\ncombine these two signals to train the Deformable DETR detection architecture\nfrom large amounts of unlabeled data. DETReg improves the performance over\ncompetitive baselines and previous self-supervised methods on standard\nbenchmarks like MS COCO and PASCAL VOC. DETReg also outperforms previous\nsupervised and unsupervised baseline approaches on low-data regime when trained\nwith only 1%, 2%, 5%, and 10% of the labeled data on MS COCO. For code and\npretrained models, visit the project page at https://amirbar.net/detreg",
          "link": "http://arxiv.org/abs/2106.04550",
          "publishedOn": "2021-06-09T02:01:48.797Z",
          "wordCount": 654,
          "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection. (arXiv:2106.04550v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04540",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lei_J/0/1/0/all/0/1\">Jordan Lei</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Benjamin_A/0/1/0/all/0/1\">Ari S. Benjamin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kording_K/0/1/0/all/0/1\">Konrad P. Kording</a>",
          "description": "Object-based attention is a key component of the visual system, relevant for\nperception, learning, and memory. Neurons tuned to features of attended objects\ntend to be more active than those associated with non-attended objects. There\nis a rich set of models of this phenomenon in computational neuroscience.\nHowever, there is currently a divide between models that successfully match\nphysiological data but can only deal with extremely simple problems and models\nof attention used in computer vision. For example, attention in the brain is\nknown to depend on top-down processing, whereas self-attention in deep learning\ndoes not. Here, we propose an artificial neural network model of object-based\nattention that captures the way in which attention is both top-down and\nrecurrent. Our attention model works well both on simple test stimuli, such as\nthose using images of handwritten digits, and on more complex stimuli, such as\nnatural images drawn from the COCO dataset. We find that our model replicates a\nrange of findings from neuroscience, including attention-invariant tuning,\ninhibition of return, and attention-mediated scaling of activity. Understanding\nobject based attention is both computationally interesting and a key problem\nfor computational neuroscience.",
          "link": "http://arxiv.org/abs/2106.04540",
          "publishedOn": "2021-06-09T02:01:48.791Z",
          "wordCount": 632,
          "title": "Object Based Attention Through Internal Gating. (arXiv:2106.04540v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hanting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_M/0/1/0/all/0/1\">Mingzhe Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1\">Feng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zhengjun Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Facial Expression Recognition (FER) in the wild is an extremely challenging\ntask in computer vision due to variant backgrounds, low-quality facial images,\nand the subjectiveness of annotators. These uncertainties make it difficult for\nneural networks to learn robust features on limited-scale datasets. Moreover,\nthe networks can be easily distributed by the above factors and perform\nincorrect decisions. Recently, vision transformer (ViT) and data-efficient\nimage transformers (DeiT) present their significant performance in traditional\nclassification tasks. The self-attention mechanism makes transformers obtain a\nglobal receptive field in the first layer which dramatically enhances the\nfeature extraction capability. In this work, we first propose a novel pure\ntransformer-based mask vision transformer (MViT) for FER in the wild, which\nconsists of two modules: a transformer-based mask generation network (MGN) to\ngenerate a mask that can filter out complex backgrounds and occlusion of face\nimages, and a dynamic relabeling module to rectify incorrect labels in FER\ndatasets in the wild. Extensive experimental results demonstrate that our MViT\noutperforms state-of-the-art methods on RAF-DB with 88.62%, FERPlus with\n89.22%, and AffectNet-7 with 64.57%, respectively, and achieves a comparable\nresult on AffectNet-8 with 61.40%.",
          "link": "http://arxiv.org/abs/2106.04520",
          "publishedOn": "2021-06-09T02:01:48.775Z",
          "wordCount": 632,
          "title": "MViT: Mask Vision Transformer for Facial Expression Recognition in the wild. (arXiv:2106.04520v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Younggeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_D/0/1/0/all/0/1\">Donghee Son</a>",
          "description": "Fundamentally, super-resolution is ill-posed problem because a low-resolution\nimage can be obtained from many high-resolution images. Recent studies for\nsuper-resolution cannot create diverse super-resolution images. Although SRFlow\ntried to account for ill-posed nature of the super-resolution by predicting\nmultiple high-resolution images given a low-resolution image, there is room to\nimprove the diversity and visual quality. In this paper, we propose Noise\nConditional flow model for Super-Resolution, NCSR, which increases the visual\nquality and diversity of images through noise conditional layer. To learn more\ndiverse data distribution, we add noise to training data. However, low-quality\nimages are resulted from adding noise. We propose the noise conditional layer\nto overcome this phenomenon. The noise conditional layer makes our model\ngenerate more diverse images with higher visual quality than other works.\nFurthermore, we show that this layer can overcome data distribution mismatch, a\nproblem that arises in normalizing flow models. With these benefits, NCSR\noutperforms baseline in diversity and visual quality and achieves better visual\nquality than traditional GAN-based models. We also get outperformed scores at\nNTIRE 2021 challenge.",
          "link": "http://arxiv.org/abs/2106.04428",
          "publishedOn": "2021-06-09T02:01:48.769Z",
          "wordCount": 608,
          "title": "Noise Conditional Flow Model for Learning the Super-Resolution Space. (arXiv:2106.04428v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Deep learning has achieved remarkable success in numerous domains with help\nfrom large amounts of big data. However, the quality of data labels is a\nconcern because of the lack of high-quality labels in many real-world\nscenarios. As noisy labels severely degrade the generalization performance of\ndeep neural networks, learning from noisy labels (robust training) is becoming\nan important task in modern deep learning applications. In this survey, we\nfirst describe the problem of learning with label noise from a supervised\nlearning perspective. Next, we provide a comprehensive review of 57\nstate-of-the-art robust training methods, all of which are categorized into\nfive groups according to their methodological difference, followed by a\nsystematic comparison of six properties used to evaluate their superiority.\nSubsequently, we perform an in-depth analysis of noise rate estimation and\nsummarize the typically used evaluation methodology, including public noisy\ndatasets and evaluation metrics. Finally, we present several promising research\ndirections that can serve as a guideline for future studies. All the contents\nwill be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.",
          "link": "http://arxiv.org/abs/2007.08199",
          "publishedOn": "2021-06-09T02:01:48.764Z",
          "wordCount": 676,
          "title": "Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.05331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quintanar_A/0/1/0/all/0/1\">A. Quintanar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izquierdo_R/0/1/0/all/0/1\">R. Izquierdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parra_I/0/1/0/all/0/1\">I. Parra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Llorca_D/0/1/0/all/0/1\">D. Fern&#xe1;ndez-Llorca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotelo_M/0/1/0/all/0/1\">M. A. Sotelo</a>",
          "description": "While driving on highways, every driver tries to be aware of the behavior of\nsurrounding vehicles, including possible emergency braking, evasive maneuvers\ntrying to avoid obstacles, unexpected lane changes, or other emergencies that\ncould lead to an accident. In this paper, human's ability to predict lane\nchanges in highway scenarios is analyzed through the use of video sequences\nextracted from the PREVENTION dataset, a database focused on the development of\nresearch on vehicle intention and trajectory prediction. Thus, users had to\nindicate the moment at which they considered that a lane change maneuver was\ntaking place in a target vehicle, subsequently indicating its direction: left\nor right. The results retrieved have been carefully analyzed and compared to\nground truth labels, evaluating statistical models to understand whether humans\ncan actually predict. The study has revealed that most participants are unable\nto anticipate lane-change maneuvers, detecting them after they have started.\nThese results might serve as a baseline for AI's prediction ability evaluation,\ngrading if those systems can outperform human skills by analyzing hidden cues\nthat seem unnoticed, improving the detection time, and even anticipating\nmaneuvers in some cases.",
          "link": "http://arxiv.org/abs/2009.05331",
          "publishedOn": "2021-06-09T02:01:48.758Z",
          "wordCount": 674,
          "title": "The PREVENTION Challenge: How Good Are Humans Predicting Lane Changes?. (arXiv:2009.05331v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Ceyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yujun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yinghao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bolei Zhou</a>",
          "description": "Generative Adversarial Networks (GANs) have significantly advanced image\nsynthesis, however, the synthesis quality drops significantly given a limited\namount of training data. To improve the data efficiency of GAN training, prior\nwork typically employs data augmentation to mitigate the overfitting of the\ndiscriminator yet still learn the discriminator with a bi-classification (i.e.,\nreal vs. fake) task. In this work, we propose a data-efficient Instance\nGeneration (InsGen) method based on instance discrimination. Concretely,\nbesides differentiating the real domain from the fake domain, the discriminator\nis required to distinguish every individual image, no matter it comes from the\ntraining set or from the generator. In this way, the discriminator can benefit\nfrom the infinite synthesized samples for training, alleviating the overfitting\nproblem caused by insufficient training data. A noise perturbation strategy is\nfurther introduced to improve its discriminative power. Meanwhile, the learned\ninstance discrimination capability from the discriminator is in turn exploited\nto encourage the generator for diverse generation. Extensive experiments\ndemonstrate the effectiveness of our method on a variety of datasets and\ntraining settings. Noticeably, on the setting of 2K training images from the\nFFHQ dataset, we outperform the state-of-the-art approach with 23.5% FID\nimprovement.",
          "link": "http://arxiv.org/abs/2106.04566",
          "publishedOn": "2021-06-09T02:01:48.752Z",
          "wordCount": 623,
          "title": "Data-Efficient Instance Generation from Instance Discrimination. (arXiv:2106.04566v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1\">Daniel Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>",
          "description": "Deep learning algorithms have shown promising results in visual question\nanswering (VQA) tasks, but a more careful look reveals that they often do not\nunderstand the rich signal they are being fed with. To understand and better\nmeasure the generalization capabilities of VQA systems, we look at their\nrobustness to counterfactually augmented data. Our proposed augmentations are\ndesigned to make a focused intervention on a specific property of the question\nsuch that the answer changes. Using these augmentations, we propose a new\nrobustness measure, Robustness to Augmented Data (RAD), which measures the\nconsistency of model predictions between original and augmented examples.\nThrough extensive experimentation, we show that RAD, unlike classical accuracy\nmeasures, can quantify when state-of-the-art systems are not robust to\ncounterfactuals. We find substantial failure cases which reveal that current\nVQA systems are still brittle. Finally, we connect between robustness and\ngeneralization, demonstrating the predictive power of RAD for performance on\nunseen augmentations.",
          "link": "http://arxiv.org/abs/2106.04484",
          "publishedOn": "2021-06-09T02:01:48.737Z",
          "wordCount": 614,
          "title": "Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2003.06566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mangla_P/0/1/0/all/0/1\">Puneet Mangla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1\">Vedant Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1\">Shreyas Jayant Havaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "The vicinal risk minimization (VRM) principle is an empirical risk\nminimization (ERM) variant that replaces Dirac masses with vicinal functions.\nThere is strong numerical and theoretical evidence showing that VRM outperforms\nERM in terms of generalization if appropriate vicinal functions are chosen.\nMixup Training (MT), a popular choice of vicinal distribution, improves the\ngeneralization performance of models by introducing globally linear behavior in\nbetween training examples. Apart from generalization, recent works have shown\nthat mixup trained models are relatively robust to input\nperturbations/corruptions and at the same time are calibrated better than their\nnon-mixup counterparts. In this work, we investigate the benefits of defining\nthese vicinal distributions like mixup in latent space of generative models\nrather than in input space itself. We propose a new approach - \\textit{VarMixup\n(Variational Mixup)} - to better sample mixup images by using the latent\nmanifold underlying the data. Our empirical studies on CIFAR-10, CIFAR-100, and\nTiny-ImageNet demonstrate that models trained by performing mixup in the latent\nmanifold learned by VAEs are inherently more robust to various input\ncorruptions/perturbations, are significantly better calibrated, and exhibit\nmore local-linear loss landscapes.",
          "link": "http://arxiv.org/abs/2003.06566",
          "publishedOn": "2021-06-09T02:01:48.714Z",
          "wordCount": 699,
          "title": "On the benefits of defining vicinal distributions in latent space. (arXiv:2003.06566v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1\">Alexander Hepburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balle_J/0/1/0/all/0/1\">Johannes Ball&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malo_J/0/1/0/all/0/1\">Jes&#xfa;s Malo</a>",
          "description": "It has been demonstrated many times that the behavior of the human visual\nsystem is connected to the statistics of natural images. Since machine learning\nrelies on the statistics of training data as well, the above connection has\ninteresting implications when using perceptual distances (which mimic the\nbehavior of the human visual system) as a loss function. In this paper, we aim\nto unravel the non-trivial relationship between the probability distribution of\nthe data, perceptual distances, and unsupervised machine learning. To this end,\nwe show that perceptual sensitivity is correlated with the probability of an\nimage in its close neighborhood. We also explore the relation between distances\ninduced by autoencoders and the probability distribution of the data used for\ntraining them, as well as how these induced distances are correlated with human\nperception. Finally, we discuss why perceptual distances might not lead to\nnoticeable gains in performance over standard Euclidean distances in common\nimage processing tasks except when data is scarce and the perceptual distance\nprovides regularization.",
          "link": "http://arxiv.org/abs/2106.04427",
          "publishedOn": "2021-06-09T02:01:48.707Z",
          "wordCount": 614,
          "title": "On the relation between statistical learning and perceptual distances. (arXiv:2106.04427v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04463",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1\">Sharib Ali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1\">Debesh Jha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghatwary_N/0/1/0/all/0/1\">Noha Ghatwary</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Realdon_S/0/1/0/all/0/1\">Stefano Realdon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cannizzaro_R/0/1/0/all/0/1\">Renato Cannizzaro</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Salem_O/0/1/0/all/0/1\">Osama E. Salem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lamarque_D/0/1/0/all/0/1\">Dominique Lamarque</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Daul_C/0/1/0/all/0/1\">Christian Daul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anonsen_K/0/1/0/all/0/1\">Kim V. Anonsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1\">Michael A. Riegler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1\">P&#xe5;l Halvorsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rittscher_J/0/1/0/all/0/1\">Jens Rittscher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1\">Thomas de Lange</a>, <a href=\"http://arxiv.org/find/eess/1/au:+East_J/0/1/0/all/0/1\">James E. East</a>",
          "description": "Polyps in the colon are widely known as cancer precursors identified by\ncolonoscopy either related to diagnostic work-up for symptoms, colorectal\ncancer screening or systematic surveillance of certain diseases. Whilst most\npolyps are benign, the number, size and the surface structure of the polyp are\ntightly linked to the risk of colon cancer. There exists a high missed\ndetection rate and incomplete removal of colon polyps due to the variable\nnature, difficulties to delineate the abnormality, high recurrence rates and\nthe anatomical topography of the colon. In the past, several methods have been\nbuilt to automate polyp detection and segmentation. However, the key issue of\nmost methods is that they have not been tested rigorously on a large\nmulti-center purpose-built dataset. Thus, these methods may not generalise to\ndifferent population datasets as they overfit to a specific population and\nendoscopic surveillance. To this extent, we have curated a dataset from 6\ndifferent centers incorporating more than 300 patients. The dataset includes\nboth single frame and sequence data with 3446 annotated polyp labels with\nprecise delineation of polyp boundaries verified by six senior\ngastroenterologists. To our knowledge, this is the most comprehensive detection\nand pixel-level segmentation dataset curated by a team of computational\nscientists and expert gastroenterologists. This dataset has been originated as\nthe part of the Endocv2021 challenge aimed at addressing generalisability in\npolyp detection and segmentation. In this paper, we provide comprehensive\ninsight into data construction and annotation strategies, annotation quality\nassurance and technical validation for our extended EndoCV2021 dataset which we\nrefer to as PolypGen.",
          "link": "http://arxiv.org/abs/2106.04463",
          "publishedOn": "2021-06-09T02:01:48.702Z",
          "wordCount": 734,
          "title": "PolypGen: A multi-center polyp detection and segmentation dataset for generalisability assessment. (arXiv:2106.04463v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_M/0/1/0/all/0/1\">Miguel Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaldaferri_A/0/1/0/all/0/1\">Antonello Scaldaferri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiameni_G/0/1/0/all/0/1\">Giuseppe Fiameni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_T/0/1/0/all/0/1\">Tao Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatti_M/0/1/0/all/0/1\">Matteo Gatti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poni_S/0/1/0/all/0/1\">Stefano Poni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semini_C/0/1/0/all/0/1\">Claudio Semini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldwell_D/0/1/0/all/0/1\">Darwin Caldwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>",
          "description": "Grapevine winter pruning is a complex task, that requires skilled workers to\nexecute it correctly. The complexity of this task is also the reason why it is\ntime consuming. Considering that this operation takes about 80-120 hours/ha to\nbe completed, and therefore is even more crucial in large-size vineyards, an\nautomated system can help to speed up the process. To this end, this paper\npresents a novel multidisciplinary approach that tackles this challenging task\nby performing object segmentation on grapevine images, used to create a\nrepresentative model of the grapevine plants. Second, a set of potential\npruning points is generated from this plant representation. We will describe\n(a) a methodology for data acquisition and annotation, (b) a neural network\nfine-tuning for grapevine segmentation, (c) an image processing based method\nfor creating the representative model of grapevines, starting from the inferred\nsegmentation and (d) potential pruning points detection and localization, based\non the plant model which is a simplification of the grapevine structure. With\nthis approach, we are able to identify a significant set of potential pruning\npoints on the canes, that can be used, with further selection, to derive the\nfinal set of the real pruning points.",
          "link": "http://arxiv.org/abs/2106.04208",
          "publishedOn": "2021-06-09T02:01:48.691Z",
          "wordCount": 657,
          "title": "Grapevine Winter Pruning Automation: On Potential Pruning Points Detection through 2D Plant Modeling using Grapevine Segmentation. (arXiv:2106.04208v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shijia Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_B/0/1/0/all/0/1\">Bohan Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bichen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vajda_P/0/1/0/all/0/1\">Peter Vajda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "3D point-clouds and 2D images are different visual representations of the\nphysical world. While human vision can understand both representations,\ncomputer vision models designed for 2D image and 3D point-cloud understanding\nare quite different. Our paper investigates the potential for transferability\nbetween these two representations by empirically investigating whether this\napproach works, what factors affect the transfer performance, and how to make\nit work even better. We discovered that we can indeed use the same neural net\nmodel architectures to understand both images and point-clouds. Moreover, we\ncan transfer pretrained weights from image models to point-cloud models with\nminimal effort. Specifically, based on a 2D ConvNet pretrained on an image\ndataset, we can transfer the image model to a point-cloud model by\n\\textit{inflating} 2D convolutional filters to 3D then finetuning its input,\noutput, and optionally normalization layers. The transferred model can achieve\ncompetitive performance on 3D point-cloud classification, indoor and driving\nscene segmentation, even beating a wide range of point-cloud models that adopt\ntask-specific architectures and use a variety of tricks.",
          "link": "http://arxiv.org/abs/2106.04180",
          "publishedOn": "2021-06-09T02:01:48.663Z",
          "wordCount": 627,
          "title": "Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets. (arXiv:2106.04180v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jingjing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Po_L/0/1/0/all/0/1\">Lai-Man Po</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wing-Yin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_P/0/1/0/all/0/1\">Pengfei Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_W/0/1/0/all/0/1\">Weifeng Ou</a>",
          "description": "Real-time semantic segmentation has received considerable attention due to\ngrowing demands in many practical applications, such as autonomous vehicles,\nrobotics, etc. Existing real-time segmentation approaches often utilize feature\nfusion to improve segmentation accuracy. However, they fail to fully consider\nthe feature information at different resolutions and the receptive fields of\nthe networks are relatively limited, thereby compromising the performance. To\ntackle this problem, we propose a light Cascaded Selective Resolution Network\n(CSRNet) to improve the performance of real-time segmentation through multiple\ncontext information embedding and enhanced feature aggregation. The proposed\nnetwork builds a three-stage segmentation system, which integrates feature\ninformation from low resolution to high resolution and achieves feature\nrefinement progressively. CSRNet contains two critical modules: the Shorted\nPyramid Fusion Module (SPFM) and the Selective Resolution Module (SRM). The\nSPFM is a computationally efficient module to incorporate the global context\ninformation and significantly enlarge the receptive field at each stage. The\nSRM is designed to fuse multi-resolution feature maps with various receptive\nfields, which assigns soft channel attentions across the feature maps and helps\nto remedy the problem caused by multi-scale objects. Comprehensive experiments\non two well-known datasets demonstrate that the proposed CSRNet effectively\nimproves the performance for real-time segmentation.",
          "link": "http://arxiv.org/abs/2106.04400",
          "publishedOn": "2021-06-09T02:01:48.641Z",
          "wordCount": 636,
          "title": "CSRNet: Cascaded Selective Resolution Network for Real-time Semantic Segmentation. (arXiv:2106.04400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathieu_M/0/1/0/all/0/1\">Marsot Mathieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanie_W/0/1/0/all/0/1\">Wuhrer Stefanie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jean_Sebastien_F/0/1/0/all/0/1\">Franco Jean-Sebastien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephane_D/0/1/0/all/0/1\">Durocher Stephane</a>",
          "description": "We examine the problem of generating temporally and spatially dense 4D human\nbody motion. On the one hand generative modeling has been extensively studied\nas a per time-frame static fitting problem for dense 3D models such as mesh\nrepresentations, where the temporal aspect is left out of the generative model.\nOn the other hand, temporal generative models exist for sparse human models\nsuch as marker-based capture representations, but have not to our knowledge\nbeen extended to dense 3D shapes. We propose to bridge this gap with a\ngenerative auto-encoder-based framework, which encodes morphology, global\nlocomotion including translation and rotation, and multi-frame temporal motion\nas a single latent space vector. To assess its generalization and factorization\nabilities, we train our model on a cyclic locomotion subset of AMASS,\nleveraging the dense surface models it provides for an extensive set of motion\ncaptures. Our results validate the ability of the model to reconstruct 4D\nsequences of human locomotions within a low error bound, and the meaningfulness\nof latent space interpolation between latent vectors representing different\nmulti-frame sequences and locomotion types. We also illustrate the benefits of\nthe approach for 4D human motion prediction of future frames from initial human\nlocomotion frames, showing promising abilities of our model to learn realistic\nspatio-temporal features of human motion. We show that our model allows for\ndata completion of both spatially and temporally sparse data.",
          "link": "http://arxiv.org/abs/2106.04387",
          "publishedOn": "2021-06-09T02:01:48.582Z",
          "wordCount": 659,
          "title": "Multi-frame sequence generator of 4D human body motion. (arXiv:2106.04387v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>",
          "description": "Vision transformers (ViTs) process input images as sequences of patches via\nself-attention; a radically different architecture than convolutional neural\nnetworks (CNNs). This makes it interesting to study the adversarial feature\nspace of ViT models and their transferability. In particular, we observe that\nadversarial patterns found via conventional adversarial attacks show very low\nblack-box transferability even for large ViT models. However, we show that this\nphenomenon is only due to the sub-optimal attack procedures that do not\nleverage the true representation potential of ViTs. A deep ViT is composed of\nmultiple blocks, with a consistent architecture comprising of self-attention\nand feed-forward layers, where each block is capable of independently producing\na class token. Formulating an attack using only the last class token\n(conventional approach) does not directly leverage the discriminative\ninformation stored in the earlier tokens, leading to poor adversarial\ntransferability of ViTs. Using the compositional nature of ViT models, we\nenhance the transferability of existing attacks by introducing two novel\nstrategies specific to the architecture of ViT models. (i) Self-Ensemble: We\npropose a method to find multiple discriminative pathways by dissecting a\nsingle ViT model into an ensemble of networks. This allows explicitly utilizing\nclass-specific information at each ViT block. (ii) Token Refinement: We then\npropose to refine the tokens to further enhance the discriminative capacity at\neach block of ViT. Our token refinement systematically combines the class\ntokens with structural information preserved within the patch tokens. An\nadversarial attack, when applied to such refined tokens within the ensemble of\nclassifiers found in a single vision transformer, has significantly higher\ntransferability.",
          "link": "http://arxiv.org/abs/2106.04169",
          "publishedOn": "2021-06-09T02:01:48.566Z",
          "wordCount": 706,
          "title": "On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.00976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Songcan Chen</a>",
          "description": "In reality, learning from multi-view multi-label data inevitably confronts\nthree challenges: missing labels, incomplete views, and non-aligned views.\nExisting methods mainly concern the first two and commonly need multiple\nassumptions to attack them, making even state-of-the-arts involve at least two\nexplicit hyper-parameters such that model selection is quite difficult. More\nroughly, they will fail in handling the third challenge, let alone addressing\nthe three jointly. In this paper, we aim at meeting these under the least\nassumption by building a concise yet effective model with just one\nhyper-parameter. To ease insufficiency of available labels, we exploit not only\nthe consensus of multiple views but also the global and local structures hidden\namong multiple labels. Specifically, we introduce an indicator matrix to tackle\nthe first two challenges in a regression form while aligning the same\nindividual labels and all labels of different views in a common label space to\nbattle the third challenge. In aligning, we characterize the global and local\nstructures of multiple labels to be high-rank and low-rank, respectively.\nSubsequently, an efficient algorithm with linear time complexity in the number\nof samples is established. Finally, even without view-alignment, our method\nsubstantially outperforms state-of-the-arts with view-alignment on five real\ndatasets.",
          "link": "http://arxiv.org/abs/2005.00976",
          "publishedOn": "2021-06-09T02:01:48.559Z",
          "wordCount": 680,
          "title": "A Concise yet Effective model for Non-Aligned Incomplete Multi-view and Missing Multi-label Learning. (arXiv:2005.00976v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiayi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yuxin Deng</a>",
          "description": "Modifications on triplet loss that rescale the back-propagated gradients of\nspecial pairs have made significant progress on local descriptor learning.\nHowever, current gradient modulation strategies are mainly static so that they\nwould suffer from changes of training phases or datasets. In this paper, we\npropose a dynamic gradient modulation, named SDGMNet, to improve triplet loss\nfor local descriptor learning. The core of our method is formulating modulation\nfunctions with statistical characteristics which are estimated dynamically.\nFirstly, we perform deep analysis on back propagation of general triplet-based\nloss and introduce included angle for distance measure. On this basis,\nauto-focus modulation is employed to moderate the impact of statistically\nuncommon individual pairs in stochastic gradient descent optimization;\nprobabilistic margin cuts off the gradients of proportional Siamese pairs that\nare believed to reach the optimum; power adjustment balances the total weights\nof negative pairs and positive pairs. Extensive experiments demonstrate that\nour novel descriptor surpasses previous state-of-the-arts on standard\nbenchmarks including patch verification, matching and retrieval tasks.",
          "link": "http://arxiv.org/abs/2106.04434",
          "publishedOn": "2021-06-09T02:01:48.553Z",
          "wordCount": 596,
          "title": "SDGMNet: Statistic-based Dynamic Gradient Modulation for Local Descriptor Learning. (arXiv:2106.04434v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04281",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Posilovic_L/0/1/0/all/0/1\">Luka Posilovi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Medak_D/0/1/0/all/0/1\">Duje Medak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Subasic_M/0/1/0/all/0/1\">Marko Subasic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Budimir_M/0/1/0/all/0/1\">Marko Budimir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Loncaric_S/0/1/0/all/0/1\">Sven Loncaric</a>",
          "description": "Non-destructive testing is a set of techniques for defect detection in\nmaterials. While the set of imaging techniques are manifold, ultrasonic imaging\nis the one used the most. The analysis is mainly performed by human inspectors\nmanually analyzing recorded images. The low number of defects in real\nultrasonic inspections and legal issues considering data from such inspections\nmake it difficult to obtain proper results from automatic ultrasonic image\n(B-scan) analysis. In this paper, we present a novel deep learning Generative\nAdversarial Network model for generating ultrasonic B-scans with defects in\ndistinct locations. Furthermore, we show that generated B-scans can be used for\nsynthetic data augmentation, and can improve the performance of deep\nconvolutional neural object detection networks. Our novel method is\ndemonstrated on a dataset of almost 4000 B-scans with more than 6000 annotated\ndefects. Defect detection performance when training on real data yielded\naverage precision of 71%. By training only on generated data the results\nincreased to 72.1%, and by mixing generated and real data we achieve 75.7%\naverage precision. We believe that synthetic data generation can generalize to\nother challenges with limited datasets and could be used for training human\npersonnel.",
          "link": "http://arxiv.org/abs/2106.04281",
          "publishedOn": "2021-06-09T02:01:48.546Z",
          "wordCount": 645,
          "title": "Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans. (arXiv:2106.04281v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Messadi_M/0/1/0/all/0/1\">Mahammed Messadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherifi_H/0/1/0/all/0/1\">Hocine Cherifi</a> (Le2i), <a href=\"http://arxiv.org/find/cs/1/au:+Bessaid_A/0/1/0/all/0/1\">Abdelhafid Bessaid</a>",
          "description": "During the last years, computer vision-based diagnosis systems have been\nwidely used in several hospitals and dermatology clinics, aiming at the early\ndetection of malignant melanoma tumor, which is among the most frequent types\nof skin cancer. In this work, we present an automated diagnosis system based on\nthe ABCD rule used in clinical diagnosis in order to discriminate benign from\nmalignant skin lesions. First, to reduce the influence of small structures, a\npreprocessing step based on morphological and fast marching schemes is used. In\nthe second step, an unsupervised approach for lesion segmentation is proposed.\nIterative thresholding is applied to initialize level set automatically. As the\ndetection of an automated border is an important step for the correctness of\nsubsequent phases in the computerized melanoma recognition systems, we compare\nits accuracy with growcut and mean shift algorithms, and discuss how these\nresults may influence in the following steps: the feature extraction and the\nfinal lesion classification. Relying on visual diagnosis four features:\nAsymmetry (A), Border (B), Color (C) and Diversity (D) are computed and used to\nconstruct a classification module based on artificial neural network for the\nrecognition of malignant melanoma. This framework has been tested on a\ndermoscopic database [16] of 320 images. The classification results show an\nincreasing true detection rate and a decreasing false positive rate.",
          "link": "http://arxiv.org/abs/2106.04372",
          "publishedOn": "2021-06-09T02:01:48.537Z",
          "wordCount": 662,
          "title": "Segmentation and ABCD rule extraction for skin tumors classification. (arXiv:2106.04372v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Ting-Ting Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzelepis_C/0/1/0/all/0/1\">Christos Tzelepis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_F/0/1/0/all/0/1\">Fan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patras_I/0/1/0/all/0/1\">Ioannis Patras</a>",
          "description": "Learning to localize actions in long, cluttered, and untrimmed videos is a\nhard task, that in the literature has typically been addressed assuming the\navailability of large amounts of annotated training samples for each class --\neither in a fully-supervised setting, where action boundaries are known, or in\na weakly-supervised setting, where only class labels are known for each video.\nIn this paper, we go a step further and show that it is possible to learn to\nlocalize actions in untrimmed videos when a) only one/few trimmed examples of\nthe target action are available at test time, and b) when a large collection of\nvideos with only class label annotation (some trimmed and some weakly annotated\nuntrimmed ones) are available for training; with no overlap between the classes\nused during training and testing. To do so, we propose a network that learns to\nestimate Temporal Similarity Matrices (TSMs) that model a fine-grained\nsimilarity pattern between pairs of videos (trimmed or untrimmed), and uses\nthem to generate Temporal Class Activation Maps (TCAMs) for seen or unseen\nclasses. The TCAMs serve as temporal attention mechanisms to extract\nvideo-level representations of untrimmed videos, and to temporally localize\nactions at test time. To the best of our knowledge, we are the first to propose\na weakly-supervised, one/few-shot action localization network that can be\ntrained in an end-to-end fashion. Experimental results on THUMOS14 and\nActivityNet1.2 datasets, show that our method achieves performance comparable\nor better to state-of-the-art fully-supervised, few-shot learning methods.",
          "link": "http://arxiv.org/abs/2106.04150",
          "publishedOn": "2021-06-09T02:01:48.531Z",
          "wordCount": 685,
          "title": "Few-Shot Action Localization without Knowing Boundaries. (arXiv:2106.04150v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjio_G/0/1/0/all/0/1\">Gabriel Tjio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Ping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goh_R/0/1/0/all/0/1\">Rick Siow Mong Goh</a>",
          "description": "Convolutional neural networks may perform poorly when the test and train data\nare from different domains. While this problem can be mitigated by using the\ntarget domain data to align the source and target domain feature\nrepresentations, the target domain data may be unavailable due to privacy\nconcerns. Consequently, there is a need for methods that generalize well\nwithout access to target domain data during training. In this work, we propose\nan adversarial hallucination approach, which combines a class-wise\nhallucination module and a semantic segmentation module. Since the segmentation\nperformance varies across different classes, we design a semantic-conditioned\nstyle hallucination layer to adaptively stylize each class. The classwise\nstylization parameters are generated from the semantic knowledge in the\nsegmentation probability maps of the source domain image. Both modules compete\nadversarially, with the hallucination module generating increasingly\n'difficult' style images to challenge the segmentation module. In response, the\nsegmentation module improves its performance as it is trained with generated\nsamples at an appropriate class-wise difficulty level. Experiments on state of\nthe art domain adaptation work demonstrate the efficacy of our proposed method\nwhen no target domain data are available for training.",
          "link": "http://arxiv.org/abs/2106.04144",
          "publishedOn": "2021-06-09T02:01:48.514Z",
          "wordCount": 628,
          "title": "Adversarial Semantic Hallucination for Domain Generalized Semantic Segmentation. (arXiv:2106.04144v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1\">Sixing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yameng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shufang Li</a>",
          "description": "Medical image segmentation is one of the important tasks of computer-aided\ndiagnosis in medical image analysis. Since most medical images have the\ncharacteristics of blurred boundaries and uneven intensity distribution,\nthrough existing segmentation methods, the discontinuity within the target area\nand the discontinuity of the target boundary are likely to lead to rough or\neven erroneous boundary delineation. In this paper, we propose a new iterative\nrefined interactive segmentation method for medical images based on agent\nreinforcement learning, which focuses on the problem of target segmentation\nboundaries. We model the dynamic process of drawing the target contour in a\ncertain order as a Markov Decision Process (MDP) based on a deep reinforcement\nlearning method. In the dynamic process of continuous interaction between the\nagent and the image, the agent tracks the boundary point by point in order\nwithin a limited length range until the contour of the target is completely\ndrawn. In this process, the agent can quickly improve the segmentation\nperformance by exploring an interactive policy in the image. The method we\nproposed is simple and effective. At the same time, we evaluate our method on\nthe cardiac MRI scan data set. Experimental results show that our method has a\nbetter segmentation effect on the left ventricle in a small number of medical\nimage data sets, especially in terms of segmentation boundaries, this method is\nbetter than existing methods. Based on our proposed method, the dynamic\ngeneration process of the predicted contour trajectory of the left ventricle\nwill be displayed online at https://github.com/H1997ym/LV-contour-trajectory.",
          "link": "http://arxiv.org/abs/2106.04127",
          "publishedOn": "2021-06-09T02:01:48.508Z",
          "wordCount": 692,
          "title": "Left Ventricle Contouring in Cardiac Images Based on Deep Reinforcement Learning. (arXiv:2106.04127v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04130",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yuting He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ge_R/0/1/0/all/0/1\">Rongjun Ge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qi_X/0/1/0/all/0/1\">Xiaoming Qi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1\">Guanyu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kong_Y/0/1/0/all/0/1\">Youyong Kong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shu_H/0/1/0/all/0/1\">Huazhong Shu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Coatrieux_J/0/1/0/all/0/1\">Jean-Louis Coatrieux</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shuo Li</a>",
          "description": "3D complete renal structures(CRS) segmentation targets on segmenting the\nkidneys, tumors, renal arteries and veins in one inference. Once successful, it\nwill provide preoperative plans and intraoperative guidance for laparoscopic\npartial nephrectomy(LPN), playing a key role in the renal cancer treatment.\nHowever, no success has been reported in 3D CRS segmentation due to the complex\nshapes of renal structures, low contrast and large anatomical variation. In\nthis study, we utilize the adversarial ensemble learning and propose Ensemble\nMulti-condition GAN(EnMcGAN) for 3D CRS segmentation for the first time. Its\ncontribution is three-fold. 1)Inspired by windowing, we propose the\nmulti-windowing committee which divides CTA image into multiple narrow windows\nwith different window centers and widths enhancing the contrast for salient\nboundaries and soft tissues. And then, it builds an ensemble segmentation model\non these narrow windows to fuse the segmentation superiorities and improve\nwhole segmentation quality. 2)We propose the multi-condition GAN which equips\nthe segmentation model with multiple discriminators to encourage the segmented\nstructures meeting their real shape conditions, thus improving the shape\nfeature extraction ability. 3)We propose the adversarial weighted ensemble\nmodule which uses the trained discriminators to evaluate the quality of\nsegmented structures, and normalizes these evaluation scores for the ensemble\nweights directed at the input image, thus enhancing the ensemble results. 122\npatients are enrolled in this study and the mean Dice coefficient of the renal\nstructures achieves 84.6%. Extensive experiments with promising results on\nrenal structures reveal powerful segmentation accuracy and great clinical\nsignificance in renal cancer treatment.",
          "link": "http://arxiv.org/abs/2106.04130",
          "publishedOn": "2021-06-09T02:01:48.502Z",
          "wordCount": 711,
          "title": "EnMcGAN: Adversarial Ensemble Learning for 3D Complete Renal Structures Segmentation. (arXiv:2106.04130v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakane_T/0/1/0/all/0/1\">Takumi Nakane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xuequan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Haoran Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>",
          "description": "The free-form deformation model can represent a wide range of non-rigid\ndeformations by manipulating a control point lattice over the image. However,\ndue to a large number of parameters, it is challenging to fit the free-form\ndeformation model directly to the deformed image for deformation estimation\nbecause of the complexity of the fitness landscape. In this paper, we cast the\nregistration task as a multi-objective optimization problem (MOP) according to\nthe fact that regions affected by each control point overlap with each other.\nSpecifically, by partitioning the template image into several regions and\nmeasuring the similarity of each region independently, multiple objectives are\nbuilt and deformation estimation can thus be realized by solving the MOP with\noff-the-shelf multi-objective evolutionary algorithms (MOEAs). In addition, a\ncoarse-to-fine strategy is realized by image pyramid combined with control\npoint mesh subdivision. Specifically, the optimized candidate solutions of the\ncurrent image level are inherited by the next level, which increases the\nability to deal with large deformation. Also, a post-processing procedure is\nproposed to generate a single output utilizing the Pareto optimal solutions.\nComparative experiments on both synthetic and real-world images show the\neffectiveness and usefulness of our deformation estimation method.",
          "link": "http://arxiv.org/abs/2106.04139",
          "publishedOn": "2021-06-09T02:01:48.495Z",
          "wordCount": 622,
          "title": "Image Deformation Estimation via Multi-Objective Optimization. (arXiv:2106.04139v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1\">Avisek Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwatra_V/0/1/0/all/0/1\">Vivek Kwatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frueh_C/0/1/0/all/0/1\">Christian Frueh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_J/0/1/0/all/0/1\">John Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bregler_C/0/1/0/all/0/1\">Chris Bregler</a>",
          "description": "In this paper, we present a video-based learning framework for animating\npersonalized 3D talking faces from audio. We introduce two training-time data\nnormalizations that significantly improve data sample efficiency. First, we\nisolate and represent faces in a normalized space that decouples 3D geometry,\nhead pose, and texture. This decomposes the prediction problem into regressions\nover the 3D face shape and the corresponding 2D texture atlas. Second, we\nleverage facial symmetry and approximate albedo constancy of skin to isolate\nand remove spatio-temporal lighting variations. Together, these normalizations\nallow simple networks to generate high fidelity lip-sync videos under novel\nambient illumination while training with just a single speaker-specific video.\nFurther, to stabilize temporal dynamics, we introduce an auto-regressive\napproach that conditions the model on its previous visual state. Human ratings\nand objective metrics demonstrate that our method outperforms contemporary\nstate-of-the-art audio-driven video reenactment benchmarks in terms of realism,\nlip-sync and visual quality scores. We illustrate several applications enabled\nby our framework.",
          "link": "http://arxiv.org/abs/2106.04185",
          "publishedOn": "2021-06-09T02:01:48.481Z",
          "wordCount": 618,
          "title": "LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization. (arXiv:2106.04185v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kloeker_L/0/1/0/all/0/1\">Laurent Kloeker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomsen_F/0/1/0/all/0/1\">Fabian Thomsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_L/0/1/0/all/0/1\">Lutz Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trettner_P/0/1/0/all/0/1\">Philip Trettner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsner_T/0/1/0/all/0/1\">Tim Elsner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nehring_Wirxel_J/0/1/0/all/0/1\">Julius Nehring-Wirxel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_K/0/1/0/all/0/1\">Kersten Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobbelt_L/0/1/0/all/0/1\">Leif Kobbelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoesch_M/0/1/0/all/0/1\">Michael Hoesch</a>",
          "description": "The research project HDV-Mess aims at a currently missing, but very crucial\ncomponent for addressing important challenges in the field of connected and\nautomated driving on public roads. The goal is to record traffic events at\nvarious relevant locations with high accuracy and to collect real traffic data\nas a basis for the development and validation of current and future sensor\ntechnologies as well as automated driving functions. For this purpose, it is\nnecessary to develop a concept for a mobile modular system of measuring\nstations for highly accurate traffic data acquisition, which enables a\ntemporary installation of a sensor and communication infrastructure at\ndifferent locations. Within this paper, we first discuss the project goals\nbefore we present our traffic detection concept using mobile modular\nintelligent transport systems stations (ITS-Ss). We then explain the approaches\nfor data processing of sensor raw data to refined trajectories, data\ncommunication, and data validation.",
          "link": "http://arxiv.org/abs/2106.04175",
          "publishedOn": "2021-06-09T02:01:48.472Z",
          "wordCount": 613,
          "title": "Highly accurate digital traffic recording as a basis for future mobility research: Methods and concepts of the research project HDV-Mess. (arXiv:2106.04175v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yifei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>",
          "description": "We study the task of conversational fashion image retrieval via multiturn\nnatural language feedback. Most previous studies are based on single-turn\nsettings. Existing models on multiturn conversational fashion image retrieval\nhave limitations, such as employing traditional models, and leading to\nineffective performance. We propose a novel framework that can effectively\nhandle conversational fashion image retrieval with multiturn natural language\nfeedback texts. One characteristic of the framework is that it searches for\ncandidate images based on exploitation of the encoded reference image and\nfeedback text information together with the conversation history. Furthermore,\nthe image fashion attribute information is leveraged via a mutual attention\nstrategy. Since there is no existing fashion dataset suitable for the multiturn\nsetting of our task, we derive a large-scale multiturn fashion dataset via\nadditional manual annotation efforts on an existing single-turn dataset. The\nexperiments show that our proposed model significantly outperforms existing\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04128",
          "publishedOn": "2021-06-09T02:01:48.467Z",
          "wordCount": 584,
          "title": "Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback. (arXiv:2106.04128v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sitong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tianyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fangjian Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shengwei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1\">Guodong Guo</a>",
          "description": "Transformers have shown impressive performance in various natural language\nprocessing and computer vision tasks, due to the capability of modeling\nlong-range dependencies. Recent progress has demonstrated to combine such\ntransformers with CNN-based semantic image segmentation models is very\npromising. However, it is not well studied yet on how well a pure transformer\nbased approach can achieve for image segmentation. In this work, we explore a\nnovel framework for semantic image segmentation, which is encoder-decoder based\nFully Transformer Networks (FTN). Specifically, we first propose a Pyramid\nGroup Transformer (PGT) as the encoder for progressively learning hierarchical\nfeatures, while reducing the computation complexity of the standard visual\ntransformer(ViT). Then, we propose a Feature Pyramid Transformer (FPT) to fuse\nsemantic-level and spatial-level information from multiple levels of the PGT\nencoder for semantic image segmentation. Surprisingly, this simple baseline can\nachieve new state-of-the-art results on multiple challenging semantic\nsegmentation benchmarks, including PASCAL Context, ADE20K and COCO-Stuff. The\nsource code will be released upon the publication of this work.",
          "link": "http://arxiv.org/abs/2106.04108",
          "publishedOn": "2021-06-09T02:01:48.460Z",
          "wordCount": 592,
          "title": "Fully Transformer Networks for Semantic ImageSegmentation. (arXiv:2106.04108v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karpov_P/0/1/0/all/0/1\">Peter Karpov</a>",
          "description": "We present a number of new piecewise-polynomial kernels for image\ninterpolation. The kernels are constructed by optimizing a measure of\ninterpolation quality based on the magnitude of anisotropic artifacts. The\nkernel design process is performed symbolically using Mathematica computer\nalgebra system. Experimental evaluation involving 14 image quality assessment\nmethods demonstrates that our results compare favorably with the existing\nlinear interpolators.",
          "link": "http://arxiv.org/abs/2106.04104",
          "publishedOn": "2021-06-09T02:01:48.449Z",
          "wordCount": 504,
          "title": "Design of Low-Artifact Interpolation Kernels by Means of Computer Algebra. (arXiv:2106.04104v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaman Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villegas_R/0/1/0/all/0/1\">Ruben Villegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_D/0/1/0/all/0/1\">Duygu Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jimei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1\">Zhengfei Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yajie Zhao</a>",
          "description": "A deep generative model that describes human motions can benefit a wide range\nof fundamental computer vision and graphics tasks, such as providing robustness\nto video-based human pose estimation, predicting complete body movements for\nmotion capture systems during occlusions, and assisting key frame animation\nwith plausible movements. In this paper, we present a method for learning\ncomplex human motions independent of specific tasks using a combined global and\nlocal latent space to facilitate coarse and fine-grained modeling.\nSpecifically, we propose a hierarchical motion variational autoencoder (HM-VAE)\nthat consists of a 2-level hierarchical latent space. While the global latent\nspace captures the overall global body motion, the local latent space enables\nto capture the refined poses of the different body parts. We demonstrate the\neffectiveness of our hierarchical motion variational autoencoder in a variety\nof tasks including video-based human pose estimation, motion completion from\npartial observations, and motion synthesis from sparse key-frames. Even though,\nour model has not been trained for any of these tasks specifically, it provides\nsuperior performance than task-specific alternatives. Our general-purpose human\nmotion prior model can fix corrupted human body animations and generate\ncomplete movements from incomplete observations.",
          "link": "http://arxiv.org/abs/2106.04004",
          "publishedOn": "2021-06-09T02:01:48.443Z",
          "wordCount": 628,
          "title": "Task-Generic Hierarchical Human Motion Prior using VAEs. (arXiv:2106.04004v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jimin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jianbo Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Weakly supervised semantic segmentation is receiving great attention due to\nits low human annotation cost. In this paper, we aim to tackle bounding box\nsupervised semantic segmentation, i.e., training accurate semantic segmentation\nmodels using bounding box annotations as supervision. To this end, we propose\nAffinity Attention Graph Neural Network ($A^2$GNN). Following previous\npractices, we first generate pseudo semantic-aware seeds, which are then formed\ninto semantic graphs based on our newly proposed affinity Convolutional Neural\nNetwork (CNN). Then the built graphs are input to our $A^2$GNN, in which an\naffinity attention layer is designed to acquire the short- and long- distance\ninformation from soft graph edges to accurately propagate semantic labels from\nthe confident seeds to the unlabeled pixels. However, to guarantee the\nprecision of the seeds, we only adopt a limited number of confident pixel seed\nlabels for $A^2$GNN, which may lead to insufficient supervision for training.\nTo alleviate this issue, we further introduce a new loss function and a\nconsistency-checking mechanism to leverage the bounding box constraint, so that\nmore reliable guidance can be included for the model optimization. Experiments\nshow that our approach achieves new state-of-the-art performances on Pascal VOC\n2012 datasets (val: 76.5\\%, test: 75.2\\%). More importantly, our approach can\nbe readily applied to bounding box supervised instance segmentation task or\nother weakly supervised semantic segmentation tasks, with state-of-the-art or\ncomparable performance among almot all weakly supervised tasks on PASCAL VOC or\nCOCO dataset. Our source code will be available at\nhttps://github.com/zbf1991/A2GNN.",
          "link": "http://arxiv.org/abs/2106.04054",
          "publishedOn": "2021-06-09T02:01:48.436Z",
          "wordCount": 698,
          "title": "Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation. (arXiv:2106.04054v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Ruizhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gaochang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuemei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Ying Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Lu Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yebin Liu</a>",
          "description": "Cross-resolution image alignment is a key problem in multiscale gigapixel\nphotography, which requires to estimate homography matrix using images with\nlarge resolution gap. Existing deep homography methods concatenate the input\nimages or features, neglecting the explicit formulation of correspondences\nbetween them, which leads to degraded accuracy in cross-resolution challenges.\nIn this paper, we consider the cross-resolution homography estimation as a\nmultimodal problem, and propose a local transformer network embedded within a\nmultiscale structure to explicitly learn correspondences between the multimodal\ninputs, namely, input images with different resolutions. The proposed local\ntransformer adopts a local attention map specifically for each position in the\nfeature. By combining the local transformer with the multiscale structure, the\nnetwork is able to capture long-short range correspondences efficiently and\naccurately. Experiments on both the MS-COCO dataset and the real-captured\ncross-resolution dataset show that the proposed network outperforms existing\nstate-of-the-art feature-based and deep-learning-based homography estimation\nmethods, and is able to accurately align images under $10\\times$ resolution\ngap.",
          "link": "http://arxiv.org/abs/2106.04067",
          "publishedOn": "2021-06-09T02:01:48.391Z",
          "wordCount": 598,
          "title": "LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation. (arXiv:2106.04067v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03905",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Aleem_A/0/1/0/all/0/1\">Abdullah Aleem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nallabothula_M/0/1/0/all/0/1\">Manoj Prabhakar Nallabothula</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Setabutr_P/0/1/0/all/0/1\">Pete Setabutr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hallak_J/0/1/0/all/0/1\">Joelle A. Hallak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_D/0/1/0/all/0/1\">Darvin Yi</a>",
          "description": "Blepharoptosis, or ptosis as it is more commonly referred to, is a condition\nof the eyelid where the upper eyelid droops. The current diagnosis for ptosis\ninvolves cumbersome manual measurements that are time-consuming and prone to\nhuman error. In this paper, we present AutoPtosis, an artificial intelligence\nbased system with interpretable results for rapid diagnosis of ptosis. We\nutilize a diverse dataset collected at the University of Illinois Hospital and\nHealth to successfully develop a robust deep learning model for prediction and\nalso develop a clinically inspired model that calculates the marginal reflex\ndistance and iris ratio. AutoPtosis achieved 95.5% accuracy on physician\nverified data that had an equal class balance. The proposed algorithm can help\nin the rapid and timely diagnosis of ptosis, significantly reduce the burden on\nthe healthcare system, and save the patients and clinics valuable resources.",
          "link": "http://arxiv.org/abs/2106.03905",
          "publishedOn": "2021-06-09T02:01:48.373Z",
          "wordCount": 572,
          "title": "AutoPtosis. (arXiv:2106.03905v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingjie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jimin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Eng Gee Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Si Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goulermas_J/0/1/0/all/0/1\">John Y. Goulermas</a>",
          "description": "In this paper, we are tackling the weakly-supervised referring expression\ngrounding task, for the localization of a referent object in an image according\nto a query sentence, where the mapping between image regions and queries are\nnot available during the training stage. In traditional methods, an object\nregion that best matches the referring expression is picked out, and then the\nquery sentence is reconstructed from the selected region, where the\nreconstruction difference serves as the loss for back-propagation. The existing\nmethods, however, conduct both the matching and the reconstruction\napproximately as they ignore the fact that the matching correctness is unknown.\nTo overcome this limitation, a discriminative triad is designed here as the\nbasis to the solution, through which a query can be converted into one or\nmultiple discriminative triads in a very scalable way. Based on the\ndiscriminative triad, we further propose the triad-level matching and\nreconstruction modules which are lightweight yet effective for the\nweakly-supervised training, making it three times lighter and faster than the\nprevious state-of-the-art methods. One important merit of our work is its\nsuperior performance despite the simple and neat design. Specifically, the\nproposed method achieves a new state-of-the-art accuracy when evaluated on\nRefCOCO (39.21%), RefCOCO+ (39.18%) and RefCOCOg (43.24%) datasets, that is\n4.17%, 4.08% and 7.8% higher than the previous one, respectively.",
          "link": "http://arxiv.org/abs/2106.04053",
          "publishedOn": "2021-06-09T02:01:48.348Z",
          "wordCount": 661,
          "title": "Discriminative Triad Matching and Reconstruction for Weakly Referring Expression Grounding. (arXiv:2106.04053v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shiraz_S/0/1/0/all/0/1\">Sarah Shiraz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Regmi_K/0/1/0/all/0/1\">Krishna Regmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vyas_S/0/1/0/all/0/1\">Shruti Vyas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_Y/0/1/0/all/0/1\">Yogesh S. Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "We address the problem of novel view video prediction; given a set of input\nvideo clips from a single/multiple views, our network is able to predict the\nvideo from a novel view. The proposed approach does not require any priors and\nis able to predict the video from wider angular distances, upto 45 degree, as\ncompared to the recent studies predicting small variations in viewpoint.\nMoreover, our method relies only onRGB frames to learn a dual representation\nwhich is used to generate the video from a novel viewpoint. The dual\nrepresentation encompasses a view-dependent and a global representation which\nincorporates complementary details to enable novel view video prediction. We\ndemonstrate the effectiveness of our framework on two real world datasets:\nNTU-RGB+D and CMU Panoptic. A comparison with the State-of-the-art novel view\nvideo prediction methods shows an improvement of 26.1% in SSIM, 13.6% in PSNR,\nand 60% inFVD scores without using explicit priors from target views.",
          "link": "http://arxiv.org/abs/2106.03956",
          "publishedOn": "2021-06-09T02:01:48.302Z",
          "wordCount": 592,
          "title": "Novel View Video Prediction Using a Dual Representation. (arXiv:2106.03956v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "There are many approaches that use weak-supervision to train networks to\nsegment 2D images. By contrast, existing 3D approaches rely on full-supervision\nof a subset of 2D slices of the 3D image volume. In this paper, we propose an\napproach that is truly weakly-supervised in the sense that we only need to\nprovide a sparse set of 3D point on the surface of target objects, an easy task\nthat can be quickly done. We use the 3D points to deform a 3D template so that\nit roughly matches the target object outlines and we introduce an architecture\nthat exploits the supervision provided by coarse template to train a network to\nfind accurate boundaries.\n\nWe evaluate the performance of our approach on Computed Tomography (CT),\nMagnetic Resonance Imagery (MRI) and Electron Microscopy (EM) image datasets.\nWe will show that it outperforms a more traditional approach to\nweak-supervision in 3D at a reduced supervision cost.",
          "link": "http://arxiv.org/abs/2106.03987",
          "publishedOn": "2021-06-09T02:01:48.297Z",
          "wordCount": 582,
          "title": "Weakly Supervised Volumetric Image Segmentation with Deformed Templates. (arXiv:2106.03987v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi-Song Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siu_W/0/1/0/all/0/1\">Wan-Chi Siu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Li-Wen Wang</a>",
          "description": "In this paper, we propose a novel reference based image super-resolution\napproach via Variational AutoEncoder (RefVAE). Existing state-of-the-art\nmethods mainly focus on single image super-resolution which cannot perform well\non large upsampling factors, e.g., 8$\\times$. We propose a reference based\nimage super-resolution, for which any arbitrary image can act as a reference\nfor super-resolution. Even using random map or low-resolution image itself, the\nproposed RefVAE can transfer the knowledge from the reference to the\nsuper-resolved images. Depending upon different references, the proposed method\ncan generate different versions of super-resolved images from a hidden\nsuper-resolution space. Besides using different datasets for some standard\nevaluations with PSNR and SSIM, we also took part in the NTIRE2021 SR Space\nchallenge and have provided results of the randomness evaluation of our\napproach. Compared to other state-of-the-art methods, our approach achieves\nhigher diverse scores.",
          "link": "http://arxiv.org/abs/2106.04090",
          "publishedOn": "2021-06-09T02:01:48.268Z",
          "wordCount": 588,
          "title": "Variational AutoEncoder for Reference based Image Super-Resolution. (arXiv:2106.04090v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinseong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daijin Kim</a>",
          "description": "Semantic segmentation networks adopt transfer learning from image\nclassification networks which occurs a shortage of spatial context information.\nFor this reason, we propose Spatial Context Memoization (SpaM), a bypassing\nbranch for spatial context by retaining the input dimension and constantly\ncommunicating its spatial context and rich semantic information mutually with\nthe backbone network. Multi-scale context information for semantic segmentation\nis crucial for dealing with diverse sizes and shapes of target objects in the\ngiven scene. Conventional multi-scale context scheme adopts multiple effective\nreceptive fields by multiple dilation rates or pooling operations, but often\nsuffer from misalignment problem with respect to the target pixel. To this end,\nwe propose Meshgrid Atrous Convolution Consensus (MetroCon^2) which brings\nmulti-scale scheme into fine-grained multi-scale object context using\nconvolutions with meshgrid-like scattered dilation rates. SpaceMeshLab\n(ResNet-101 + SpaM + MetroCon^2) achieves 82.0% mIoU in Cityscapes test and\n53.5% mIoU on Pascal-Context validation set.",
          "link": "http://arxiv.org/abs/2106.04025",
          "publishedOn": "2021-06-09T02:01:48.263Z",
          "wordCount": 614,
          "title": "SpaceMeshLab: Spatial Context Memoization and Meshgrid Atrous Convolution Consensus for Semantic Segmentation. (arXiv:2106.04025v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoxuan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Erjin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "Graph Neural Network (GNN) has been demonstrated its effectiveness in dealing\nwith non-Euclidean structural data. Both spatial-based and spectral-based GNNs\nare relying on adjacency matrix to guide message passing among neighbors during\nfeature aggregation. Recent works have mainly focused on powerful message\npassing modules, however, in this paper, we show that none of the message\npassing modules is necessary. Instead, we propose a pure\nmultilayer-perceptron-based framework, Graph-MLP with the supervision signal\nleveraging graph structure, which is sufficient for learning discriminative\nnode representation. In model-level, Graph-MLP only includes multi-layer\nperceptrons, activation function, and layer normalization. In the loss level,\nwe design a neighboring contrastive (NContrast) loss to bridge the gap between\nGNNs and MLPs by utilizing the adjacency information implicitly. This design\nallows our model to be lighter and more robust when facing large-scale graph\ndata and corrupted adjacency information. Extensive experiments prove that even\nwithout adjacency information in testing phase, our framework can still reach\ncomparable and even superior performance against the state-of-the-art models in\nthe graph node classification task.",
          "link": "http://arxiv.org/abs/2106.04051",
          "publishedOn": "2021-06-09T02:01:48.257Z",
          "wordCount": 620,
          "title": "Graph-MLP: Node Classification without Message Passing in Graph. (arXiv:2106.04051v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yulin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianfeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianzhu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Occluded person re-identification (Re-ID) is a challenging task as persons\nare frequently occluded by various obstacles or other persons, especially in\nthe crowd scenario. To address these issues, we propose a novel end-to-end\nPart-Aware Transformer (PAT) for occluded person Re-ID through diverse part\ndiscovery via a transformer encoderdecoder architecture, including a pixel\ncontext based transformer encoder and a part prototype based transformer\ndecoder. The proposed PAT model enjoys several merits. First, to the best of\nour knowledge, this is the first work to exploit the transformer\nencoder-decoder architecture for occluded person Re-ID in a unified deep model.\nSecond, to learn part prototypes well with only identity labels, we design two\neffective mechanisms including part diversity and part discriminability.\nConsequently, we can achieve diverse part discovery for occluded person Re-ID\nin a weakly supervised manner. Extensive experimental results on six\nchallenging benchmarks for three tasks (occluded, partial and holistic Re-ID)\ndemonstrate that our proposed PAT performs favorably against stat-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2106.04095",
          "publishedOn": "2021-06-09T02:01:48.241Z",
          "wordCount": 600,
          "title": "Diverse Part Discovery: Occluded Person Re-identification with Part-Aware Transformer. (arXiv:2106.04095v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sui_L/0/1/0/all/0/1\">Lin Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen-Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jianxin Wu</a>",
          "description": "Weakly supervised object detection (WSOD) has recently attracted much\nattention. However, the method, performance and speed gaps between WSOD and\nfully supervised detection prevent WSOD from being applied in real-world tasks.\nTo bridge the gaps, this paper proposes a new framework, Salvage of Supervision\n(SoS), with the key idea being to harness every potentially useful supervisory\nsignal in WSOD: the weak image-level labels, the pseudo-labels, and the power\nof semi-supervised object detection. This paper shows that each type of\nsupervisory signal brings in notable improvements, outperforms existing WSOD\nmethods (which mainly use only the weak labels) by large margins. The proposed\nSoS-WSOD method achieves 64.4 $m\\text{AP}_{50}$ on VOC2007, 61.9\n$m\\text{AP}_{50}$ on VOC2012 and 16.4 $m\\text{AP}_{50:95}$ on MS-COCO, and also\nhas fast inference speed. Ablations and visualization further verify the\neffectiveness of SoS.",
          "link": "http://arxiv.org/abs/2106.04073",
          "publishedOn": "2021-06-09T02:01:48.235Z",
          "wordCount": 558,
          "title": "Salvage of Supervision in Weakly Supervised Detection. (arXiv:2106.04073v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagstaff_B/0/1/0/all/0/1\">Brandon Wagstaff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peretroukhin_V/0/1/0/all/0/1\">Valentin Peretroukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jonathan Kelly</a>",
          "description": "Much recent literature has formulated structure-from-motion (SfM) as a\nself-supervised learning problem where the goal is to jointly learn neural\nnetwork models of depth and egomotion through view synthesis. Herein, we\naddress the open problem of how to optimally couple the depth and egomotion\nnetwork components. Toward this end, we introduce several notions of coupling,\ncategorize existing approaches, and present a novel tightly-coupled approach\nthat leverages the interdependence of depth and egomotion at training and at\ninference time. Our approach uses iterative view synthesis to recursively\nupdate the egomotion network input, permitting contextual information to be\npassed between the components without explicit weight sharing. Through\nsubstantial experiments, we demonstrate that our approach promotes consistency\nbetween the depth and egomotion predictions at test time, improves\ngeneralization on new data, and leads to state-of-the-art accuracy on indoor\nand outdoor depth and egomotion evaluation benchmarks.",
          "link": "http://arxiv.org/abs/2106.04007",
          "publishedOn": "2021-06-09T02:01:48.222Z",
          "wordCount": 578,
          "title": "Self-Supervised Structure-from-Motion through Tightly-Coupled Depth and Egomotion Networks. (arXiv:2106.04007v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dae-Hyeok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1\">Dong-Kyun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sung-Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Ji-Hoon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Brain-computer interface (BCI) is used for communication between humans and\ndevices by recognizing status and intention of humans. Communication between\nhumans and a drone using electroencephalogram (EEG) signals is one of the most\nchallenging issues in the BCI domain. In particular, the control of drone\nswarms (the direction and formation) has more advantages compared to the\ncontrol of a drone. The visual imagery (VI) paradigm is that subjects visually\nimagine specific objects or scenes. Reduction of the variability among EEG\nsignals of subjects is essential for practical BCI-based systems. In this\nstudy, we proposed the subepoch-wise feature encoder (SEFE) to improve the\nperformances in the subject-independent tasks by using the VI dataset. This\nstudy is the first attempt to demonstrate the possibility of generalization\namong subjects in the VI-based BCI. We used the leave-one-subject-out\ncross-validation for evaluating the performances. We obtained higher\nperformances when including our proposed module than excluding our proposed\nmodule. The DeepConvNet with SEFE showed the highest performance of 0.72 among\nsix different decoding models. Hence, we demonstrated the feasibility of\ndecoding the VI dataset in the subject-independent task with robust\nperformances by using our proposed module.",
          "link": "http://arxiv.org/abs/2106.04026",
          "publishedOn": "2021-06-09T02:01:48.187Z",
          "wordCount": 646,
          "title": "Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks. (arXiv:2106.04026v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopuklu_O/0/1/0/all/0/1\">Okan K&#xf6;p&#xfc;kl&#xfc;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taseska_M/0/1/0/all/0/1\">Maja Taseska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Successful active speaker detection requires a three-stage pipeline: (i)\naudio-visual encoding for all speakers in the clip, (ii) inter-speaker relation\nmodeling between a reference speaker and the background speakers within each\nframe, and (iii) temporal modeling for the reference speaker. Each stage of\nthis pipeline plays an important role for the final performance of the created\narchitecture. Based on a series of controlled experiments, this work presents\nseveral practical guidelines for audio-visual active speaker detection.\nCorrespondingly, we present a new architecture called ASDNet, which achieves a\nnew state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5%\noutperforming the second best with a large margin of 4.7%. Our code and\npretrained models are publicly available.",
          "link": "http://arxiv.org/abs/2106.03932",
          "publishedOn": "2021-06-09T02:01:48.181Z",
          "wordCount": 569,
          "title": "How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild. (arXiv:2106.03932v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1\">Debadeepta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shital Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1\">Sebastien Bubeck</a>",
          "description": "The fundamental problem in Neural Architecture Search (NAS) is to efficiently\nfind high-performing architectures from a given search space. We propose a\nsimple but powerful method which we call FEAR, for ranking architectures in any\nsearch space. FEAR leverages the viewpoint that neural networks are powerful\nnon-linear feature extractors. First, we train different architectures in the\nsearch space to the same training or validation error. Then, we compare the\nusefulness of the features extracted by each architecture. We do so with a\nquick training keeping most of the architecture frozen. This gives fast\nestimates of the relative performance. We validate FEAR on Natsbench topology\nsearch space on three different datasets against competing baselines and show\nstrong ranking correlation especially compared to recently proposed zero-cost\nmethods. FEAR particularly excels at ranking high-performance architectures in\nthe search space. When used in the inner loop of discrete search algorithms\nlike random search, FEAR can cut down the search time by approximately 2.4X\nwithout losing accuracy. We additionally empirically study very recently\nproposed zero-cost measures for ranking and find that they breakdown in ranking\nperformance as training proceeds and also that data-agnostic ranking scores\nwhich ignore the dataset do not generalize across dissimilar datasets.",
          "link": "http://arxiv.org/abs/2106.04010",
          "publishedOn": "2021-06-09T02:01:48.160Z",
          "wordCount": 633,
          "title": "FEAR: A Simple Lightweight Method to Rank Architectures. (arXiv:2106.04010v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenhao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eun_K/0/1/0/all/0/1\">Kim Ji Eun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Deep Generative Models (DGMs) are known for their superior capability in\ngenerating realistic data. Extending purely data-driven approaches, recent\nspecialized DGMs may satisfy additional controllable requirements such as\nembedding a traffic sign in a driving scene, by manipulating patterns\n\\textit{implicitly} in the neuron or feature level. In this paper, we introduce\na novel method to incorporate domain knowledge \\textit{explicitly} in the\ngeneration process to achieve semantically controllable scene generation. We\ncategorize our knowledge into two types to be consistent with the composition\nof natural scenes, where the first type represents the property of objects and\nthe second type represents the relationship among objects. We then propose a\ntree-structured generative model to learn complex scene representation, whose\nnodes and edges are naturally corresponding to the two types of knowledge\nrespectively. Knowledge can be explicitly integrated to enable semantically\ncontrollable scene generation by imposing semantic rules on properties of nodes\nand edges in the tree structure. We construct a synthetic example to illustrate\nthe controllability and explainability of our method in a clean setting. We\nfurther extend the synthetic example to realistic autonomous vehicle driving\nenvironments and conduct extensive experiments to show that our method\nefficiently identifies adversarial traffic scenes against different\nstate-of-the-art 3D point cloud segmentation models satisfying the traffic\nrules specified as the explicit knowledge.",
          "link": "http://arxiv.org/abs/2106.04066",
          "publishedOn": "2021-06-09T02:01:48.139Z",
          "wordCount": 660,
          "title": "Semantically Controllable Scene Generation with Guidance of Explicit Knowledge. (arXiv:2106.04066v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1\">Serguei Barannikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1\">Ilya Trofimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotnikov_G/0/1/0/all/0/1\">Grigorii Sotnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trimbach_E/0/1/0/all/0/1\">Ekaterina Trimbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1\">Alexander Filippov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "We develop a framework for comparing data manifolds, aimed, in particular,\ntowards the evaluation of deep generative models. We describe a novel tool,\nCross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional\nspace, tracks multiscale topology spacial discrepancies between manifolds on\nwhich the distributions are concentrated. Based on the Cross-Barcode, we\nintroduce the Manifold Topology Divergence score (MTop-Divergence) and apply it\nto assess the performance of deep generative models in various domains: images,\n3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN,\nCIFAR10, FFHQ, chest X-ray images, market stock data, ShapeNet. We demonstrate\nthat the MTop-Divergence accurately detects various degrees of mode-dropping,\nintra-mode collapse, mode invention, and image disturbance. Our algorithm\nscales well (essentially linearly) with the increase of the dimension of the\nambient high-dimensional space. It is one of the first TDA-based practical\nmethodologies that can be applied universally to datasets of different sizes\nand dimensions, including the ones on which the most recent GANs in the visual\ndomain are trained. The proposed method is domain agnostic and does not rely on\npre-trained networks.",
          "link": "http://arxiv.org/abs/2106.04024",
          "publishedOn": "2021-06-09T02:01:48.133Z",
          "wordCount": 615,
          "title": "Manifold Topology Divergence: a Framework for Comparing Data Manifolds. (arXiv:2106.04024v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1\">Guangyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yanchu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1\">Tianhong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1\">Tania Stathaki</a>",
          "description": "Salient object detection(SOD) aims at locating the most significant object\nwithin a given image. In recent years, great progress has been made in applying\nSOD on many vision tasks. The depth map could provide additional spatial prior\nand boundary cues to boost the performance. Combining the depth information\nwith image data obtained from standard visual cameras has been widely used in\nrecent SOD works, however, introducing depth information in a suboptimal fusion\nstrategy may have negative influence in the performance of SOD. In this paper,\nwe discuss about the advantages of the so-called progressive multi-scale fusion\nmethod and propose a mask-guided feature aggregation module(MGFA). The proposed\nframework can effectively combine the two features of different modalities and,\nfurthermore, alleviate the impact of erroneous depth features, which are\ninevitably caused by the variation of depth quality. We further introduce a\nmask-guided refinement module(MGRM) to complement the high-level semantic\nfeatures and reduce the irrelevant features from multi-scale fusion, leading to\nan overall refinement of detection. Experiments on five challenging benchmarks\ndemonstrate that the proposed method outperforms 11 state-of-the-art methods\nunder different evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.03941",
          "publishedOn": "2021-06-09T02:01:48.092Z",
          "wordCount": 613,
          "title": "Progressive Multi-scale Fusion Network for RGB-D Salient Object Detection. (arXiv:2106.03941v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Flow-based generative models have shown excellent ability to explicitly learn\nthe probability density function of data via a sequence of invertible\ntransformations. Yet, modeling long-range dependencies over normalizing flows\nremains understudied. To fill the gap, in this paper, we introduce two types of\ninvertible attention mechanisms for generative flow models. To be precise, we\npropose map-based and scaled dot-product attention for unconditional and\nconditional generative flow models. The key idea is to exploit split-based\nattention mechanisms to learn the attention weights and input representations\non every two splits of flow feature maps. Our method provides invertible\nattention modules with tractable Jacobian determinants, enabling seamless\nintegration of it at any positions of the flow-based models. The proposed\nattention mechanism can model the global data dependencies, leading to more\ncomprehensive flow models. Evaluation on multiple generation tasks demonstrates\nthat the introduced attention flow idea results in efficient flow models and\ncompares favorably against the state-of-the-art unconditional and conditional\ngenerative flow methods.",
          "link": "http://arxiv.org/abs/2106.03959",
          "publishedOn": "2021-06-09T02:01:48.072Z",
          "wordCount": 588,
          "title": "Generative Flows with Invertible Attentions. (arXiv:2106.03959v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1\">Sina Mohseni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vahdat_A/0/1/0/all/0/1\">Arash Vahdat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadawa_J/0/1/0/all/0/1\">Jay Yadawa</a>",
          "description": "Detecting out-of-distribution (OOD) samples plays a key role in open-world\nand safety-critical applications such as autonomous systems and healthcare.\nSelf-supervised representation learning techniques (e.g., contrastive learning\nand pretext learning) are well suited for learning representation that can\nidentify OOD samples. In this paper, we propose a simple framework that\nleverages multi-task transformation learning for training effective\nrepresentation for OOD detection which outperforms state-of-the-art OOD\ndetection performance and robustness on several image datasets. We empirically\nobserve that the OOD performance depends on the choice of data transformations\nwhich itself depends on the in-domain training set. To address this problem, we\npropose a simple mechanism for selecting the transformations automatically and\nmodulate their effect on representation learning without requiring any OOD\ntraining samples. We characterize the criteria for a desirable OOD detector for\nreal-world applications and demonstrate the efficacy of our proposed technique\nagainst a diverse range of the state-of-the-art OOD detection techniques.",
          "link": "http://arxiv.org/abs/2106.03899",
          "publishedOn": "2021-06-09T02:01:48.003Z",
          "wordCount": 577,
          "title": "Multi-task Transformation Learning for Robust Out-of-Distribution Detection. (arXiv:2106.03899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Van-Quang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suganuma_M/0/1/0/all/0/1\">Masanori Suganuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okatani_T/0/1/0/all/0/1\">Takayuki Okatani</a>",
          "description": "There is a growing interest in the community in making an embodied AI agent\nperform a complicated task while interacting with an environment following\nnatural language directives. Recent studies have tackled the problem using\nALFRED, a well-designed dataset for the task, but achieved only very low\naccuracy. This paper proposes a new method, which outperforms the previous\nmethods by a large margin. It is based on a combination of several new ideas.\nOne is a two-stage interpretation of the provided instructions. The method\nfirst selects and interprets an instruction without using visual information,\nyielding a tentative action sequence prediction. It then integrates the\nprediction with the visual information etc., yielding the final prediction of\nan action and an object. As the object's class to interact is identified in the\nfirst stage, it can accurately select the correct object from the input image.\nMoreover, our method considers multiple egocentric views of the environment and\nextracts essential information by applying hierarchical attention conditioned\non the current instruction. This contributes to the accurate prediction of\nactions for navigation. A preliminary version of the method won the ALFRED\nChallenge 2020. The current version achieves the unseen environment's success\nrate of 4.45% with a single view, which is further improved to 8.37% with\nmultiple views.",
          "link": "http://arxiv.org/abs/2106.00596",
          "publishedOn": "2021-06-08T22:44:24.609Z",
          "wordCount": 685,
          "title": "Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks. (arXiv:2106.00596v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bukchin_G/0/1/0/all/0/1\">Guy Bukchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_E/0/1/0/all/0/1\">Eli Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahar_O/0/1/0/all/0/1\">Ori Shahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1\">Raja Giryes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1\">Leonid Karlinsky</a>",
          "description": "Few-shot learning methods offer pre-training techniques optimized for easier\nlater adaptation of the model to new classes (unseen during training) using one\nor a few examples. This adaptivity to unseen classes is especially important\nfor many practical applications where the pre-trained label space cannot remain\nfixed for effective use and the model needs to be \"specialized\" to support new\ncategories on the fly. One particularly interesting scenario, essentially\noverlooked by the few-shot literature, is Coarse-to-Fine Few-Shot (C2FS), where\nthe training classes (e.g. animals) are of much `coarser granularity' than the\ntarget (test) classes (e.g. breeds). A very practical example of C2FS is when\nthe target classes are sub-classes of the training classes. Intuitively, it is\nespecially challenging as (both regular and few-shot) supervised pre-training\ntends to learn to ignore intra-class variability which is essential for\nseparating sub-classes. In this paper, we introduce a novel 'Angular\nnormalization' module that allows to effectively combine supervised and\nself-supervised contrastive pre-training to approach the proposed C2FS task,\ndemonstrating significant gains in a broad study over multiple baselines and\ndatasets. We hope that this work will help to pave the way for future research\non this new, challenging, and very practical topic of C2FS classification.",
          "link": "http://arxiv.org/abs/2012.03515",
          "publishedOn": "2021-06-08T02:20:28.134Z",
          "wordCount": 663,
          "title": "Fine-grained Angular Contrastive Learning with Coarse Labels. (arXiv:2012.03515v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1\">Ilia Shumailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1\">Dmitry Kazhdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1\">Ross Anderson</a>",
          "description": "Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.",
          "link": "http://arxiv.org/abs/2104.09667",
          "publishedOn": "2021-06-08T02:20:28.089Z",
          "wordCount": 642,
          "title": "Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kuai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_H/0/1/0/all/0/1\">Hakeem Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">Daniel Wilson</a>",
          "description": "In applied image segmentation tasks, the ability to provide numerous and\nprecise labels for training is paramount to the accuracy of the model at\ninference time. However, this overhead is often neglected, and recently\nproposed segmentation architectures rely heavily on the availability and\nfidelity of ground truth labels to achieve state-of-the-art accuracies. Failure\nto acknowledge the difficulty in creating adequate ground truths can lead to an\nover-reliance on pre-trained models or a lack of adoption in real-world\napplications. We introduce Points2Polygons (P2P), a model which makes use of\ncontextual metric learning techniques that directly addresses this problem.\nPoints2Polygons performs well against existing fully-supervised segmentation\nbaselines with limited training data, despite using lightweight segmentation\nmodels (U-Net with a ResNet18 backbone) and having access to only weak labels\nin the form of object centroids and no pre-training. We demonstrate this on\nseveral different small but non-trivial datasets. We show that metric learning\nusing contextual data provides key insights for self-supervised tasks in\ngeneral, and allow segmentation models to easily generalize across\ntraditionally label-intensive domains in computer vision.",
          "link": "http://arxiv.org/abs/2106.02804",
          "publishedOn": "2021-06-08T02:20:28.082Z",
          "wordCount": 609,
          "title": "Points2Polygons: Context-Based Segmentation from Weak Labels Using Adversarial Networks. (arXiv:2106.02804v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fanjie Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>",
          "description": "An increasing number of applications in the computer vision domain,\nspecially, in medical imaging and remote sensing, are challenging when the goal\nis to classify very large images with tiny objects. More specifically, these\ntype of classification tasks face two key challenges: $i$) the size of the\ninput image in the target dataset is usually in the order of megapixels,\nhowever, existing deep architectures do not easily operate on such big images\ndue to memory constraints, consequently, we seek a memory-efficient method to\nprocess these images; and $ii$) only a small fraction of the input images are\ninformative of the label of interest, resulting in low region of interest (ROI)\nto image ratio. However, most of the current convolutional neural networks\n(CNNs) are designed for image classification datasets that have relatively\nlarge ROIs and small image size (sub-megapixel). Existing approaches have\naddressed these two challenges in isolation. We present an end-to-end CNN model\ntermed Zoom-In network that leverages hierarchical attention sampling for\nclassification of large images with tiny objects using a single GPU. We\nevaluate our method on two large-image datasets and one gigapixel dataset.\nExperimental results show that our model achieves higher accuracy than existing\nmethods while requiring less computing resources.",
          "link": "http://arxiv.org/abs/2106.02694",
          "publishedOn": "2021-06-08T02:20:28.051Z",
          "wordCount": 634,
          "title": "Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiu_Z/0/1/0/all/0/1\">Zidi Xiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junya Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_B/0/1/0/all/0/1\">Benjamin Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1\">Lawrence Carin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chenyang Tao</a>",
          "description": "Dealing with severe class imbalance poses a major challenge for real-world\napplications, especially when the accurate classification and generalization of\nminority classes is of primary interest. In computer vision, learning from long\ntailed datasets is a recurring theme, especially for natural image datasets.\nWhile existing solutions mostly appeal to sampling or weighting adjustments to\nalleviate the pathological imbalance, or imposing inductive bias to prioritize\nnon-spurious associations, we take novel perspectives to promote sample\nefficiency and model generalization based on the invariance principles of\ncausality. Our proposal posits a meta-distributional scenario, where the data\ngenerating mechanism is invariant across the label-conditional feature\ndistributions. Such causal assumption enables efficient knowledge transfer from\nthe dominant classes to their under-represented counterparts, even if the\nrespective feature distributions show apparent disparities. This allows us to\nleverage a causal data inflation procedure to enlarge the representation of\nminority classes. Our development is orthogonal to the existing extreme\nclassification techniques thus can be seamlessly integrated. The utility of our\nproposal is validated with an extensive set of synthetic and real-world\ncomputer vision tasks against SOTA solutions.",
          "link": "http://arxiv.org/abs/2011.12454",
          "publishedOn": "2021-06-08T02:20:28.044Z",
          "wordCount": 652,
          "title": "Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer. (arXiv:2011.12454v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02800",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1\">Konstantina Sampani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mengjia Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yixiang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">He Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer K. Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time\nretinal images with high resolution down to 2 $\\mu m$. This technique enables\ndetection of the morphologies of individual microaneurysms (MAs), which are one\nof the earliest signs of diabetic retinopathy (DR), a frequent complication of\ndiabetes that can lead to visual impairment and blindness. In contrast to\nprevious automatic models developed for MA detection on standard fundus\nphotographs, currently there is no high throughput image protocol available for\nautomatic analysis of AOSLO photographs. To address this urgency, we introduce\nAOSLO-net, a deep neural network framework with customized training policy,\nincluding preprocessing, data augmentation and transfer learning, to\nautomatically segment MAs from AOSLO images. We evaluate the performance of\nAOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and\nsegmentation, leading to correct MA morphological classification, while\noutperforming the state-of-the-art both in accuracy and cost.",
          "link": "http://arxiv.org/abs/2106.02800",
          "publishedOn": "2021-06-08T02:20:28.038Z",
          "wordCount": 617,
          "title": "AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.11622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Han Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Ligeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "On-device learning enables edge devices to continually adapt the AI models to\nnew data, which requires a small memory footprint to fit the tight memory\nconstraint of edge devices. Existing work solves this problem by reducing the\nnumber of trainable parameters. However, this doesn't directly translate to\nmemory saving since the major bottleneck is the activations, not parameters. In\nthis work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient\non-device learning. TinyTL freezes the weights while only learns the bias\nmodules, thus no need to store the intermediate activations. To maintain the\nadaptation capacity, we introduce a new memory-efficient bias module, the lite\nresidual module, to refine the feature extractor by learning small residual\nfeature maps adding only 3.8% memory overhead. Extensive experiments show that\nTinyTL significantly saves the memory (up to 6.5x) with little accuracy loss\ncompared to fine-tuning the full network. Compared to fine-tuning the last\nlayer, TinyTL provides significant accuracy improvements (up to 34.1%) with\nlittle memory overhead. Furthermore, combined with feature extractor\nadaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing\naccuracy compared to fine-tuning the full Inception-V3.",
          "link": "http://arxiv.org/abs/2007.11622",
          "publishedOn": "2021-06-08T02:20:28.025Z",
          "wordCount": 675,
          "title": "TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyoungjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1\">Myeongsu Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Bumju Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soohyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Ki Hean Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Sunghoe Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Volumetric imaging by fluorescence microscopy is often limited by anisotropic\nspatial resolution from inferior axial resolution compared to the lateral\nresolution. To address this problem, here we present a deep-learning-enabled\nunsupervised super-resolution technique that enhances anisotropic images in\nvolumetric fluorescence microscopy. In contrast to the existing deep learning\napproaches that require matched high-resolution target volume images, our\nmethod greatly reduces the effort to put into practice as the training of a\nnetwork requires as little as a single 3D image stack, without a priori\nknowledge of the image formation process, registration of training data, or\nseparate acquisition of target data. This is achieved based on the optimal\ntransport driven cycle-consistent generative adversarial network that learns\nfrom an unpaired matching between high-resolution 2D images in lateral image\nplane and low-resolution 2D images in the other planes. Using fluorescence\nconfocal microscopy and light-sheet microscopy, we demonstrate that the trained\nnetwork not only enhances axial resolution, but also restores suppressed visual\ndetails between the imaging planes and removes imaging artifacts.",
          "link": "http://arxiv.org/abs/2104.09435",
          "publishedOn": "2021-06-08T02:20:28.005Z",
          "wordCount": 651,
          "title": "Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.00426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kasten_Y/0/1/0/all/0/1\">Yoni Kasten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1\">Amnon Geifman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1\">Meirav Galun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>",
          "description": "This paper addresses the problem of recovering projective camera matrices\nfrom collections of fundamental matrices in multiview settings. We make two\nmain contributions. First, given ${n \\choose 2}$ fundamental matrices computed\nfor $n$ images, we provide a complete algebraic characterization in the form of\nconditions that are both necessary and sufficient to enabling the recovery of\ncamera matrices. These conditions are based on arranging the fundamental\nmatrices as blocks in a single matrix, called the $n$-view fundamental matrix,\nand characterizing this matrix in terms of the signs of its eigenvalues and\nrank structures. Secondly, we propose a concrete algorithm for projective\nstructure-from-motion that utilizes this characterization. Given a complete or\npartial collection of measured fundamental matrices, our method seeks camera\nmatrices that minimize a global algebraic error for the measured fundamental\nmatrices. In contrast to existing methods, our optimization, without any\ninitialization, produces a consistent set of fundamental matrices that\ncorresponds to a unique set of cameras (up to a choice of projective frame).\nOur experiments indicate that our method achieves state of the art performance\nin both accuracy and running time.",
          "link": "http://arxiv.org/abs/1812.00426",
          "publishedOn": "2021-06-08T02:20:27.993Z",
          "wordCount": 665,
          "title": "GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices. (arXiv:1812.00426v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huanan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shuyue Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yongqiang Deng</a>",
          "description": "Due to the high complexity and occlusion, insufficient perception in the\ncrowded urban intersection can be a serious safety risk for both human drivers\nand autonomous algorithms, whereas CVIS (Cooperative Vehicle Infrastructure\nSystem) is a proposed solution for full-participants perception in this\nscenario. However, the research on roadside multimodal perception is still in\nits infancy, and there is no open-source dataset for such scenario.\nAccordingly, this paper fills the gap. Through an IPS (Intersection Perception\nSystem) installed at the diagonal of the intersection, this paper proposes a\nhigh-quality multimodal dataset for the intersection perception task. The\ncenter of the experimental intersection covers an area of 3000m2, and the\nextended distance reaches 300m, which is typical for CVIS. The first batch of\nopen-source data includes 14198 frames, and each frame has an average of 319.84\nlabels, which is 9.6 times larger than the most crowded dataset (H3D dataset in\n2019) by now. In order to facilitate further study, this dataset tries to keep\nthe label documents consistent with the KITTI dataset, and a standardized\nbenchmark is created for algorithm evaluation. Our dataset is available at:\nthis http URL",
          "link": "http://arxiv.org/abs/2106.02781",
          "publishedOn": "2021-06-08T02:20:27.980Z",
          "wordCount": 623,
          "title": "IPS300+: a Challenging Multimodal Dataset for Intersection Perception System. (arXiv:2106.02781v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2002.11169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1\">I-Jeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Philippe Burlina</a>",
          "description": "Our work focuses on unsupervised and generative methods that address the\nfollowing goals: (a) learning unsupervised generative representations that\ndiscover latent factors controlling image semantic attributes, (b) studying how\nthis ability to control attributes formally relates to the issue of latent\nfactor disentanglement, clarifying related but dissimilar concepts that had\nbeen confounded in the past, and (c) developing anomaly detection methods that\nleverage representations learned in (a). For (a), we propose a network\narchitecture that exploits the combination of multiscale generative models with\nmutual information (MI) maximization. For (b), we derive an analytical result\n(Lemma 1) that brings clarity to two related but distinct concepts: the ability\nof generative networks to control semantic attributes of images they generate,\nresulting from MI maximization, and the ability to disentangle latent space\nrepresentations, obtained via total correlation minimization. More\nspecifically, we demonstrate that maximizing semantic attribute control\nencourages disentanglement of latent factors. Using Lemma 1 and adopting MI in\nour loss function, we then show empirically that, for image generation tasks,\nthe proposed approach exhibits superior performance as measured in the quality\nand disentanglement trade space, when compared to other state of the art\nmethods, with quality assessed via the Frechet Inception Distance (FID), and\ndisentanglement via mutual information gap. For (c), we design several systems\nfor anomaly detection exploiting representations learned in (a), and\ndemonstrate their performance benefits when compared to state-of-the-art\ngenerative and discriminative algorithms. The above contributions in\nrepresentation learning have potential applications in addressing other\nimportant problems in computer vision, such as bias and privacy in AI.",
          "link": "http://arxiv.org/abs/2002.11169",
          "publishedOn": "2021-06-08T02:20:27.950Z",
          "wordCount": 755,
          "title": "Unsupervised Discovery, Control, and Disentanglement of Semantic Attributes with Applications to Anomaly Detection. (arXiv:2002.11169v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Justin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Judith E. Fan</a>",
          "description": "People can produce drawings of specific entities (e.g., Garfield), as well as\ngeneral categories (e.g., \"cat\"). What explains this ability to produce such\nvaried drawings of even highly familiar object concepts? We hypothesized that\ndrawing objects at different levels of abstraction depends on both sensory\ninformation and representational goals, such that drawings intended to portray\na recently seen object preserve more detail than those intended to represent a\ncategory. Participants drew objects cued either with a photo or a category\nlabel. For each cue type, half the participants aimed to draw a specific\nexemplar; the other half aimed to draw the category. We found that label-cued\ncategory drawings were the most recognizable at the basic level, whereas\nphoto-cued exemplar drawings were the least recognizable. Together, these\nfindings highlight the importance of task context for explaining how people use\ndrawings to communicate visual concepts in different ways.",
          "link": "http://arxiv.org/abs/2106.02775",
          "publishedOn": "2021-06-08T02:20:27.943Z",
          "wordCount": 595,
          "title": "Visual communication of object concepts at different levels of abstraction. (arXiv:2106.02775v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1\">Chandan Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1\">Sethupathy Parameswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ashish Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Suresh Sundaram</a>",
          "description": "Zero-shot learning is a new paradigm to classify objects from classes that\nare not available at training time. Zero-shot learning (ZSL) methods have\nattracted considerable attention in recent years because of their ability to\nclassify unseen/novel class examples. Most of the existing approaches on ZSL\nworks when all the samples from seen classes are available to train the model,\nwhich does not suit real life. In this paper, we tackle this hindrance by\ndeveloping a generative replay-based continual ZSL (GRCZSL). The proposed\nmethod endows traditional ZSL to learn from streaming data and acquire new\nknowledge without forgetting the previous tasks' gained experience. We handle\ncatastrophic forgetting in GRCZSL by replaying the synthetic samples of seen\nclasses, which have appeared in the earlier tasks. These synthetic samples are\nsynthesized using the trained conditional variational autoencoder (VAE) over\nthe immediate past task. Moreover, we only require the current and immediate\nprevious VAE at any time for training and testing. The proposed GRZSL method is\ndeveloped for a single-head setting of continual learning, simulating a\nreal-world problem setting. In this setting, task identity is given during\ntraining but unavailable during testing. GRCZSL performance is evaluated on\nfive benchmark datasets for the generalized setup of ZSL with fixed and dynamic\n(incremental class) settings of continual learning. The existing class setting\npresented recently in the literature is not suitable for a class-incremental\nsetting. Therefore, this paper proposes a new setting to address this issue.\nExperimental results show that the proposed method significantly outperforms\nthe baseline and the state-of-the-art method and makes it more suitable for\nreal-world applications.",
          "link": "http://arxiv.org/abs/2101.08894",
          "publishedOn": "2021-06-08T02:20:27.934Z",
          "wordCount": 718,
          "title": "Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:27.927Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yuan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Luchan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yang Xiang</a>",
          "description": "Pruning is a model compression method that removes redundant parameters in\ndeep neural networks (DNNs) while maintaining accuracy. Most available filter\npruning methods require complex treatments such as iterative pruning, features\nstatistics/ranking, or additional optimization designs in the training process.\nIn this paper, we propose a simple and effective regularization strategy from a\nnew perspective of evolution of features, which we call feature flow\nregularization (FFR), for improving structured sparsity and filter pruning in\nDNNs. Specifically, FFR imposes controls on the gradient and curvature of\nfeature flow along the neural network, which implicitly increases the sparsity\nof the parameters. The principle behind FFR is that coherent and smooth\nevolution of features will lead to an efficient network that avoids redundant\nparameters. The high structured sparsity obtained from FFR enables us to prune\nfilters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and\nTiny ImageNet datasets demonstrate that FFR can significantly improve both\nunstructured and structured sparsity. Our pruning results in terms of reduction\nof parameters and FLOPs are comparable to or even better than those of\nstate-of-the-art pruning methods.",
          "link": "http://arxiv.org/abs/2106.02914",
          "publishedOn": "2021-06-08T02:20:27.909Z",
          "wordCount": 616,
          "title": "Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Peng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lingyun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1\">Howie Choset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>",
          "description": "We present a method for localizing a single camera with respect to a point\ncloud map in indoor and outdoor scenes. The problem is challenging because\ncorrespondences of local invariant features are inconsistent across the domains\nbetween image and 3D. The problem is even more challenging as the method must\nhandle various environmental conditions such as illumination, weather, and\nseasonal changes. Our method can match equirectangular images to the 3D range\nprojections by extracting cross-domain symmetric place descriptors. Our key\ninsight is to retain condition-invariant 3D geometry features from limited data\nsamples while eliminating the condition-related features by a designed\nGenerative Adversarial Network. Based on such features, we further design a\nspherical convolution network to learn viewpoint-invariant symmetric place\ndescriptors. We evaluate our method on extensive self-collected datasets, which\ninvolve \\textit{Long-term} (variant appearance conditions),\n\\textit{Large-scale} (up to $2km$ structure/unstructured environment), and\n\\textit{Multistory} (four-floor confined space). Our method surpasses other\ncurrent state-of-the-arts by achieving around $3$ times higher place retrievals\nto inconsistent environments, and above $3$ times accuracy on online\nlocalization. To highlight our method's generalization capabilities, we also\nevaluate the recognition across different datasets. With a single trained\nmodel, i3dLoc can demonstrate reliable visual localization in random\nconditions.",
          "link": "http://arxiv.org/abs/2105.12883",
          "publishedOn": "2021-06-08T02:20:27.903Z",
          "wordCount": 681,
          "title": "i3dLoc: Image-to-range Cross-domain Localization Robust to Inconsistent Environmental Conditions. (arXiv:2105.12883v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1\">Soumyya Kanti Datta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammad Abuzar Shaikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1\">Sargur N. Srihari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1\">Mingchen Gao</a>",
          "description": "In clinical applications, neural networks must focus on and highlight the\nmost important parts of an input image. Soft-Attention mechanism enables a\nneural network toachieve this goal. This paper investigates the effectiveness\nof Soft-Attention in deep neural architectures. The central aim of\nSoft-Attention is to boost the value of important features and suppress the\nnoise-inducing features. We compare the performance of VGG, ResNet,\nInceptionResNetv2 and DenseNet architectures with and without the\nSoft-Attention mechanism, while classifying skin lesions. The original network\nwhen coupled with Soft-Attention outperforms the baseline[16] by 4.7% while\nachieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,\nSoft-Attention coupling improves the sensitivity score by 3.8% compared to\nbaseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly\navailable at github.",
          "link": "http://arxiv.org/abs/2105.03358",
          "publishedOn": "2021-06-08T02:20:27.890Z",
          "wordCount": 600,
          "title": "Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02884",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yue_Z/0/1/0/all/0/1\">Zongsheng Yue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Q/0/1/0/all/0/1\">Qian Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meng_D/0/1/0/all/0/1\">Deyu Meng</a>",
          "description": "Blind image deblurring is an important yet very challenging problem in\nlow-level vision. Traditional optimization based methods generally formulate\nthis task as a maximum-a-posteriori estimation or variational inference\nproblem, whose performance highly relies on the handcraft priors for both the\nlatent image and the blur kernel. In contrast, recent deep learning methods\ngenerally learn, from a large collection of training images, deep neural\nnetworks (DNNs) directly mapping the blurry image to the clean one or to the\nblur kernel, paying less attention to the physical degradation process of the\nblurry image. In this paper, we present a deep variational Bayesian framework\nfor blind image deblurring. Under this framework, the posterior of the latent\nclean image and blur kernel can be jointly estimated in an amortized inference\nfashion with DNNs, and the involved inference DNNs can be trained by fully\nconsidering the physical blur model, together with the supervision of data\ndriven priors for the clean image and blur kernel, which is naturally led to by\nthe evidence lower bound objective. Comprehensive experiments are conducted to\nsubstantiate the effectiveness of the proposed framework. The results show that\nit can not only achieve a promising performance with relatively simple\nnetworks, but also enhance the performance of existing DNNs for deblurring.",
          "link": "http://arxiv.org/abs/2106.02884",
          "publishedOn": "2021-06-08T02:20:27.839Z",
          "wordCount": 648,
          "title": "A Deep Variational Bayesian Framework for Blind Image Deblurring. (arXiv:2106.02884v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.07536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guoqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junchuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuhui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shengyong Chen</a>",
          "description": "Extracting effective and discriminative features is very important for\naddressing the challenging person re-identification (re-ID) task. Prevailing\ndeep convolutional neural networks (CNNs) usually use high-level features for\nidentifying pedestrian. However, some essential spatial information resided in\nlow-level features such as shape, texture and color will be lost when learning\nthe high-level features, due to extensive padding and pooling operations in the\ntraining stage. In addition, most existing person re-ID methods are mainly\nbased on hand-craft bounding boxes where images are precisely aligned. It is\nunrealistic in practical applications, since the exploited object detection\nalgorithms often produce inaccurate bounding boxes. This will inevitably\ndegrade the performance of existing algorithms. To address these problems, we\nput forward a novel person re-ID model that fuses high- and low-level\nembeddings to reduce the information loss caused in learning high-level\nfeatures. Then we divide the fused embedding into several parts and reconnect\nthem to obtain the global feature and more significant local features, so as to\nalleviate the affect caused by the inaccurate bounding boxes. In addition, we\nalso introduce the spatial and channel attention mechanisms in our model, which\naims to mine more discriminative features related to the target. Finally, we\nreconstruct the feature extractor to ensure that our model can obtain more\nricher and robust features. Extensive experiments display the superiority of\nour approach compared with existing approaches. Our code is available at\nhttps://github.com/libraflower/MutipleFeature-for-PRID.",
          "link": "http://arxiv.org/abs/2009.07536",
          "publishedOn": "2021-06-08T02:20:26.017Z",
          "wordCount": 705,
          "title": "Hybrid-Attention Guided Network with Multiple Resolution Features for Person Re-Identification. (arXiv:2009.07536v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajora_H/0/1/0/all/0/1\">Harish Rajora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1\">Narinder Singh Punn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Worldwide, several cases go undiagnosed due to poor healthcare support in\nremote areas. In this context, a centralized system is needed for effective\nmonitoring and analysis of the medical records. A web-based patient diagnostic\nsystem is a central platform to store the medical history and predict the\npossible disease based on the current symptoms experienced by a patient to\nensure faster and accurate diagnosis. Early disease prediction can help the\nusers determine the severity of the disease and take quick action. The proposed\nweb-based disease prediction system utilizes machine learning based\nclassification techniques on a data set acquired from the National Centre of\nDisease Control (NCDC). $K$-nearest neighbor (K-NN), random forest and naive\nbayes classification approaches are utilized and an ensemble voting algorithm\nis also proposed where each classifier is assigned weights dynamically based on\nthe prediction confidence. The proposed system is also equipped with a\nrecommendation scheme to recommend the type of tests based on the existing\nsymptoms of the patient, so that necessary precautions can be taken. A\ncentralized database ensures that the medical data is preserved and there is\ntransparency in the system. The tampering into the system is prevented by\ngiving the no \"updation\" rights once the diagnosis is created.",
          "link": "http://arxiv.org/abs/2106.02813",
          "publishedOn": "2021-06-08T02:20:25.285Z",
          "wordCount": null,
          "title": "Web based disease prediction and recommender system. (arXiv:2106.02813v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1\">Bhavin Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozafari_M/0/1/0/all/0/1\">Milad Mozafari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OMay_C/0/1/0/all/0/1\">Callum Biggs O&#x27;May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ador_B/0/1/0/all/0/1\">Benjamin Ador</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1\">Andrea Alamia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1\">Rufin VanRullen</a>",
          "description": "Deep neural networks excel at image classification, but their performance is\nfar less robust to input perturbations than human perception. In this work we\nexplore whether this shortcoming may be partly addressed by incorporating\nbrain-inspired recurrent dynamics in deep convolutional networks. We take\ninspiration from a popular framework in neuroscience: 'predictive coding'. At\neach layer of the hierarchical model, generative feedback 'predicts' (i.e.,\nreconstructs) the pattern of activity in the previous layer. The reconstruction\nerrors are used to iteratively update the network's representations across\ntimesteps, and to optimize the network's feedback weights over the natural\nimage dataset-a form of unsupervised training. We show that implementing this\nstrategy into two popular networks, VGG16 and EfficientNetB0, improves their\nrobustness against various corruptions. We hypothesize that other feedforward\nnetworks could similarly benefit from the proposed framework. To promote\nresearch in this direction, we provide an open-sourced PyTorch-based package\ncalled Predify, which can be used to implement and investigate the impacts of\nthe predictive coding dynamics in any convolutional neural network.",
          "link": "http://arxiv.org/abs/2106.02749",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics. (arXiv:2106.02749v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patashnik_O/0/1/0/all/0/1\">Or Patashnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danon_D/0/1/0/all/0/1\">Dov Danon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>",
          "description": "State-of-the-art image-to-image translation methods tend to struggle in an\nimbalanced domain setting, where one image domain lacks richness and diversity.\nWe introduce a new unsupervised translation network, BalaGAN, specifically\ndesigned to tackle the domain imbalance problem. We leverage the latent\nmodalities of the richer domain to turn the image-to-image translation problem,\nbetween two imbalanced domains, into a balanced, multi-class, and conditional\ntranslation problem, more resembling the style transfer setting. Specifically,\nwe analyze the source domain and learn a decomposition of it into a set of\nlatent modes or classes, without any supervision. This leaves us with a\nmultitude of balanced cross-domain translation tasks, between all pairs of\nclasses, including the target domain. During inference, the trained network\ntakes as input a source image, as well as a reference or style image from one\nof the modes as a condition, and produces an image which resembles the source\non the pixel-wise level, but shares the same mode as the reference. We show\nthat employing modalities within the dataset improves the quality of the\ntranslated images, and that BalaGAN outperforms strong baselines of both\nunconditioned and style-transfer-based image-to-image translation methods, in\nterms of image quality and diversity.",
          "link": "http://arxiv.org/abs/2010.02036",
          "publishedOn": "2021-06-08T02:20:25.271Z",
          "wordCount": null,
          "title": "BalaGAN: Image Translation Between Imbalanced Domains via Cross-Modal Transfer. (arXiv:2010.02036v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1\">Jane You</a>",
          "description": "How to extract effective expression representations that invariant to the\nidentity-specific attributes is a long-lasting problem for facial expression\nrecognition (FER). Most of the previous methods process the RGB images of a\nsequence, while we argue that the off-the-shelf and valuable expression-related\nmuscle movement is already embedded in the compression format. In this paper,\nwe target to explore the inter-subject variations eliminated facial expression\nrepresentation in the compressed video domain. In the up to two orders of\nmagnitude compressed domain, we can explicitly infer the expression from the\nresidual frames and possibly extract identity factors from the I frame with a\npre-trained face recognition network. By enforcing the marginal independence of\nthem, the expression feature is expected to be purer for the expression and be\nrobust to identity shifts. Specifically, we propose a novel collaborative\nmin-min game for mutual information (MI) minimization in latent space. We do\nnot need the identity label or multiple expression samples from the same person\nfor identity elimination. Moreover, when the apex frame is annotated in the\ndataset, the complementary constraint can be further added to regularize the\nfeature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image-based methods on the\ntypical FER benchmarks with about 3 times faster inference.",
          "link": "http://arxiv.org/abs/2010.10637",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1\">Safa Cicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We present a method for inferring dense depth maps from images and sparse\ndepth measurements by leveraging synthetic data to learn the association of\nsparse point clouds with dense natural shapes, and using the image as evidence\nto validate the predicted depth map. Our learned prior for natural shapes uses\nonly sparse depth as input, not images, so the method is not affected by the\ncovariate shift when attempting to transfer learned models from synthetic data\nto real ones. This allows us to use abundant synthetic data with ground truth\nto learn the most difficult component of the reconstruction process, which is\ntopology estimation, and use the image to refine the prediction based on\nphotometric evidence. Our approach uses fewer parameters than previous methods,\nyet, achieves the state of the art on both indoor and outdoor benchmark\ndatasets. Code available at:\nhttps://github.com/alexklwong/learning-topology-synthetic-data.",
          "link": "http://arxiv.org/abs/2106.02994",
          "publishedOn": "2021-06-08T02:20:25.139Z",
          "wordCount": null,
          "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lirong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Wenhan Luo</a>",
          "description": "Hazy images reduce the visibility of the image content, and haze will lead to\nfailure in handling subsequent computer vision tasks. In this paper, we address\nthe problem of image dehazing by proposing a dehazing network named T-Net,\nwhich consists of a backbone network based on the U-Net architecture and a dual\nattention module. And it can achieve multi-scale feature fusion by using skip\nconnections with a new fusion strategy. Furthermore, by repeatedly unfolding\nthe plain T-Net, Stack T-Net is proposed to take advantage of the dependence of\ndeep features across stages via a recursive strategy. In order to reduce\nnetwork parameters, the intra-stage recursive computation of ResNet is adopted\nin our Stack T-Net. And we take both the stage-wise result and the original\nhazy image as input to each T-Net and finally output the prediction of clean\nimage. Experimental results on both synthetic and real-world images demonstrate\nthat our plain T-Net and the advanced Stack T-Net perform favorably against the\nstate-of-the-art dehazing algorithms, and show that our Stack T-Net could\nfurther improve the dehazing effect, demonstrating the effectiveness of the\nrecursive strategy.",
          "link": "http://arxiv.org/abs/2106.02809",
          "publishedOn": "2021-06-08T02:20:25.132Z",
          "wordCount": null,
          "title": "T-Net: Deep Stacked Scale-Iteration Network for Image Dehazing. (arXiv:2106.02809v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1912.01756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nauata_N/0/1/0/all/0/1\">Nelson Nauata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1\">Yasutaka Furukawa</a>",
          "description": "This paper proposes a novel message passing neural (MPN) architecture\nConv-MPN, which reconstructs an outdoor building as a planar graph from a\nsingle RGB image. Conv-MPN is specifically designed for cases where nodes of a\ngraph have explicit spatial embedding. In our problem, nodes correspond to\nbuilding edges in an image. Conv-MPN is different from MPN in that 1) the\nfeature associated with a node is represented as a feature volume instead of a\n1D vector; and 2) convolutions encode messages instead of fully connected\nlayers. Conv-MPN learns to select a true subset of nodes (i.e., building edges)\nto reconstruct a building planar graph. Our qualitative and quantitative\nevaluations over 2,000 buildings show that Conv-MPN makes significant\nimprovements over the existing fully neural solutions. We believe that the\npaper has a potential to open a new line of graph neural network research for\nstructured geometry reconstruction.",
          "link": "http://arxiv.org/abs/1912.01756",
          "publishedOn": "2021-06-08T02:20:24.637Z",
          "wordCount": null,
          "title": "Conv-MPN: Convolutional Message Passing Neural Network for Structured Outdoor Architecture Reconstruction. (arXiv:1912.01756v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:23.738Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hongyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabawi_D/0/1/0/all/0/1\">Diaa Dabawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cetin_A/0/1/0/all/0/1\">Ahmet Enis Cetin</a>",
          "description": "In this paper, we propose a novel layer based on fast Walsh-Hadamard\ntransform (WHT) and smooth-thresholding to replace $1\\times 1$ convolution\nlayers in deep neural networks. In the WHT domain, we denoise the transform\ndomain coefficients using the new smooth-thresholding non-linearity, a smoothed\nversion of the well-known soft-thresholding operator. We also introduce a\nfamily of multiplication-free operators from the basic 2$\\times$2 Hadamard\ntransform to implement $3\\times 3$ depthwise separable convolution layers.\nUsing these two types of layers, we replace the bottleneck layers in\nMobileNet-V2 to reduce the network's number of parameters with a slight loss in\naccuracy. For example, by replacing the final third bottleneck layers, we\nreduce the number of parameters from 2.270M to 540K. This reduces the accuracy\nfrom 95.21\\% to 92.98\\% on the CIFAR-10 dataset. Our approach significantly\nimproves the speed of data processing. The fast Walsh-Hadamard transform has a\ncomputational complexity of $O(m\\log_2 m)$. As a result, it is computationally\nmore efficient than the $1\\times1$ convolution layer. The fast Walsh-Hadamard\nlayer processes a tensor in $\\mathbb{R}^{10\\times32\\times32\\times1024}$ about 2\ntimes faster than $1\\times1$ convolution layer on NVIDIA Jetson Nano computer\nboard.",
          "link": "http://arxiv.org/abs/2104.07085",
          "publishedOn": "2021-06-08T02:20:23.677Z",
          "wordCount": 686,
          "title": "Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks. (arXiv:2104.07085v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yawei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Text-based video segmentation is a challenging task that segments out the\nnatural language referred objects in videos. It essentially requires semantic\ncomprehension and fine-grained video understanding. Existing methods introduce\nlanguage representation into segmentation models in a bottom-up manner, which\nmerely conducts vision-language interaction within local receptive fields of\nConvNets. We argue that such interaction is not fulfilled since the model can\nbarely construct region-level relationships given partial observations, which\nis contrary to the description logic of natural language/referring expressions.\nIn fact, people usually describe a target object using relations with other\nobjects, which may not be easily understood without seeing the whole video. To\naddress the issue, we introduce a novel top-down approach by imitating how we\nhuman segment an object with the language guidance. We first figure out all\ncandidate objects in videos and then choose the refereed one by parsing\nrelations among those high-level objects. Three kinds of object-level relations\nare investigated for precise relationship understanding, i.e., positional\nrelation, text-guided semantic relation, and temporal relation. Extensive\nexperiments on A2D Sentences and J-HMDB Sentences show our method outperforms\nstate-of-the-art methods by a large margin. Qualitative results also show our\nresults are more explainable. Besides, based on the inspiration, we win the\nfirst place in CVPR2021 Referring Youtube-VOS challenge.",
          "link": "http://arxiv.org/abs/2103.10702",
          "publishedOn": "2021-06-08T02:20:23.579Z",
          "wordCount": 668,
          "title": "ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation. (arXiv:2103.10702v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lantao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dehong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_H/0/1/0/all/0/1\">Hassan Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boufounos_P/0/1/0/all/0/1\">Petros T. Boufounos</a>",
          "description": "Blind pansharpening addresses the problem of generating a high\nspatial-resolution multi-spectral (HRMS) image given a low spatial-resolution\nmulti-spectral (LRMS) image with the guidance of its associated spatially\nmisaligned high spatial-resolution panchromatic (PAN) image without parametric\nside information. In this paper, we propose a fast approach to blind\npansharpening and achieve state-of-the-art image reconstruction quality.\nTypical blind pansharpening algorithms are often computationally intensive\nsince the blur kernel and the target HRMS image are often computed using\niterative solvers and in an alternating fashion. To achieve fast blind\npansharpening, we decouple the solution of the blur kernel and of the HRMS\nimage. First, we estimate the blur kernel by computing the kernel coefficients\nwith minimum total generalized variation that blur a downsampled version of the\nPAN image to approximate a linear combination of the LRMS image channels. Then,\nwe estimate each channel of the HRMS image using local Laplacian prior to\nregularize the relationship between each HRMS channel and the PAN image.\nSolving the HRMS image is accelerated by both parallelizing across the channels\nand by fast numerical algorithms for each channel. Due to the fast scheme and\nthe powerful priors we used on the blur kernel coefficients (total generalized\nvariation) and on the cross-channel relationship (local Laplacian prior),\nnumerical experiments demonstrate that our algorithm outperforms\nstate-of-the-art model-based counterparts in terms of both computational time\nand reconstruction quality of the HRMS images.",
          "link": "http://arxiv.org/abs/2103.09943",
          "publishedOn": "2021-06-08T02:20:23.556Z",
          "wordCount": 704,
          "title": "Fast and High-Quality Blind Multi-Spectral Image Pansharpening. (arXiv:2103.09943v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "ImageNet-1K serves as the primary dataset for pretraining deep learning\nmodels for computer vision tasks. ImageNet-21K dataset, which is bigger and\nmore diverse, is used less frequently for pretraining, mainly due to its\ncomplexity, low accessibility, and underestimation of its added value. This\npaper aims to close this gap, and make high-quality efficient pretraining on\nImageNet-21K available for everyone. Via a dedicated preprocessing stage,\nutilization of WordNet hierarchical structure, and a novel training scheme\ncalled semantic softmax, we show that various models significantly benefit from\nImageNet-21K pretraining on numerous datasets and tasks, including small\nmobile-oriented models. We also show that we outperform previous ImageNet-21K\npretraining schemes for prominent new models like ViT and Mixer. Our proposed\npretraining pipeline is efficient, accessible, and leads to SoTA reproducible\nresults, from a publicly available dataset. The training code and pretrained\nmodels are available at: https://github.com/Alibaba-MIIL/ImageNet21K",
          "link": "http://arxiv.org/abs/2104.10972",
          "publishedOn": "2021-06-08T02:20:23.495Z",
          "wordCount": 609,
          "title": "ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_A/0/1/0/all/0/1\">Andrew Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ze Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkis_M/0/1/0/all/0/1\">Michel Sarkis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_N/0/1/0/all/0/1\">Ning Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yiying Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>",
          "description": "Existing face relighting methods often struggle with two problems:\nmaintaining the local facial details of the subject and accurately removing and\nsynthesizing shadows in the relit image, especially hard shadows. We propose a\nnovel deep face relighting method that addresses both problems. Our method\nlearns to predict the ratio (quotient) image between a source image and the\ntarget image with the desired lighting, allowing us to relight the image while\nmaintaining the local facial details. During training, our model also learns to\naccurately modify shadows by using estimated shadow masks to emphasize on the\nhigh-contrast shadow borders. Furthermore, we introduce a method to use the\nshadow mask to estimate the ambient light intensity in an image, and are thus\nable to leverage multiple datasets during training with different global\nlighting intensities. With quantitative and qualitative evaluations on the\nMulti-PIE and FFHQ datasets, we demonstrate that our proposed method faithfully\nmaintains the local facial details of the subject and can accurately handle\nhard shadows while achieving state-of-the-art face relighting performance.",
          "link": "http://arxiv.org/abs/2104.00825",
          "publishedOn": "2021-06-08T02:20:22.685Z",
          "wordCount": 642,
          "title": "Towards High Fidelity Face Relighting with Realistic Shadows. (arXiv:2104.00825v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kassel_L/0/1/0/all/0/1\">Levi Kassel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werman_M/0/1/0/all/0/1\">Michael Werman</a>",
          "description": "Neural networks are a powerful framework for foreground segmentation in video\nacquired by static cameras, segmenting moving objects from the background in a\nrobust way in various challenging scenarios. The premier methods are those\nbased on supervision requiring a final training stage on a database of tens to\nhundreds of manually segmented images from the specific static camera. In this\nwork, we propose a method to automatically create an \"artificial\" database that\nis sufficient for training the supervised methods so that it performs better\nthan current unsupervised methods. It is based on combining a weak foreground\nsegmenter, compared to the supervised method, to extract suitable objects from\nthe training images and randomly inserting these objects back into a background\nimage. Test results are shown on the test sequences in CDnet.",
          "link": "http://arxiv.org/abs/2011.07954",
          "publishedOn": "2021-06-08T02:20:22.640Z",
          "wordCount": 593,
          "title": "Using a Supervised Method without supervision for foreground segmentation. (arXiv:2011.07954v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhihao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuheng Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Junhui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingfu Zhang</a>",
          "description": "Deep subspace clustering networks have attracted much attention in subspace\nclustering, in which an auto-encoder non-linearly maps the input data into a\nlatent space, and a fully connected layer named self-expressiveness module is\nintroduced to learn the affinity matrix via a typical regularization term\n(e.g., sparse or low-rank). However, the adopted regularization terms ignore\nthe connectivity within each subspace, limiting their clustering performance.\nIn addition, the adopted framework suffers from the coupling issue between the\nauto-encoder module and the self-expressiveness module, making the network\ntraining non-trivial. To tackle these two issues, we propose a novel deep\nsubspace clustering method named Maximum Entropy Subspace Clustering Network\n(MESC-Net). Specifically, MESC-Net maximizes the entropy of the affinity matrix\nto promote the connectivity within each subspace, in which its elements\ncorresponding to the same subspace are uniformly and densely distributed.\nFurthermore, we design a novel framework to explicitly decouple the\nauto-encoder module and the self-expressiveness module. We also theoretically\nprove that the learned affinity matrix satisfies the block-diagonal property\nunder the independent subspaces. Extensive quantitative and qualitative results\non commonly used benchmark datasets validate MESC-Net significantly outperforms\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2012.03176",
          "publishedOn": "2021-06-08T02:20:22.443Z",
          "wordCount": 648,
          "title": "Maximum Entropy Subspace Clustering Network. (arXiv:2012.03176v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alatalo_J/0/1/0/all/0/1\">Janne Alatalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "One-pixel attack is a curious way of deceiving neural network classifier by\nchanging only one pixel in the input image. The full potential and boundaries\nof this attack method are not yet fully understood. In this research, the\nsuccessful and unsuccessful attacks are studied in more detail to illustrate\nthe working mechanisms of a one-pixel attack created using differential\nevolution. The data comes from our earlier studies where we applied the attack\nagainst medical imaging. We used a real breast cancer tissue dataset and a real\nclassifier as the attack target. This research presents ways to analyze\nchromatic and spatial distributions of one-pixel attacks. In addition, we\npresent one-pixel attack confidence maps to illustrate the behavior of the\ntarget classifier. We show that the more effective attacks change the color of\nthe pixel more, and that the successful attacks are situated at the center of\nthe images. This kind of analysis is not only useful for understanding the\nbehavior of the attack but also the qualities of the classifying neural\nnetwork.",
          "link": "http://arxiv.org/abs/2105.13771",
          "publishedOn": "2021-06-08T02:20:22.436Z",
          "wordCount": 636,
          "title": "Chromatic and spatial analysis of one-pixel attacks against an image classifier. (arXiv:2105.13771v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zizheng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haoyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>",
          "description": "Transformers have become one of the dominant architectures in deep learning,\nparticularly as a powerful alternative to convolutional neural networks (CNNs)\nin computer vision. However, Transformer training and inference in previous\nworks can be prohibitively expensive due to the quadratic complexity of\nself-attention over a long sequence of representations, especially for\nhigh-resolution dense prediction tasks. To this end, we present a novel Less\nattention vIsion Transformer (LIT), building upon the fact that convolutions,\nfully-connected (FC) layers, and self-attentions have almost equivalent\nmathematical expressions for processing image patch sequences. Specifically, we\npropose a hierarchical Transformer where we use pure multi-layer perceptrons\n(MLPs) to encode rich local patterns in the early stages while applying\nself-attention modules to capture longer dependencies in deeper layers.\nMoreover, we further propose a learned deformable token merging module to\nadaptively fuse informative patches in a non-uniform manner. The proposed LIT\nachieves promising performance on image recognition tasks, including image\nclassification, object detection and instance segmentation, serving as a strong\nbackbone for many vision tasks. Code is available at:\nhttps://github.com/MonashAI/LIT",
          "link": "http://arxiv.org/abs/2105.14217",
          "publishedOn": "2021-06-08T02:20:22.415Z",
          "wordCount": 629,
          "title": "Less is More: Pay Less Attention in Vision Transformers. (arXiv:2105.14217v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "We present SegFormer, a simple, efficient yet powerful semantic segmentation\nframework which unifies Transformers with lightweight multilayer perception\n(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a\nnovel hierarchically structured Transformer encoder which outputs multiscale\nfeatures. It does not need positional encoding, thereby avoiding the\ninterpolation of positional codes which leads to decreased performance when the\ntesting resolution differs from training. 2) SegFormer avoids complex decoders.\nThe proposed MLP decoder aggregates information from different layers, and thus\ncombining both local attention and global attention to render powerful\nrepresentations. We show that this simple and lightweight design is the key to\nefficient segmentation on Transformers. We scale our approach up to obtain a\nseries of models from SegFormer-B0 to SegFormer-B5, reaching significantly\nbetter performance and efficiency than previous counterparts. For example,\nSegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x\nsmaller and 2.2% better than the previous best method. Our best model,\nSegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows\nexcellent zero-shot robustness on Cityscapes-C. Code will be released at:\ngithub.com/NVlabs/SegFormer.",
          "link": "http://arxiv.org/abs/2105.15203",
          "publishedOn": "2021-06-08T02:20:22.389Z",
          "wordCount": 641,
          "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Su Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Le Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "Meta-learning can extract an inductive bias from previous learning experience\nand assist the training processes of new tasks. It is often realized through\noptimizing a meta-model with the evaluation loss of a series of task-specific\nsolvers. Most existing algorithms sample non-overlapping $\\mathit{support}$\nsets and $\\mathit{query}$ sets to train and evaluate the solvers respectively\ndue to simplicity ($\\mathcal{S}/\\mathcal{Q}$ protocol). However, another\nevaluation method that assesses the discrepancy between the solver and a target\nmodel is short of research ($\\mathcal{S}/\\mathcal{T}$ protocol).\n$\\mathcal{S}/\\mathcal{T}$ protocol has unique advantages such as offering more\ninformative supervision, but it is computationally expensive. This paper looks\ninto this special evaluation method and takes a step towards putting it into\npractice. We find that with a small ratio of tasks armed with target models,\nclassic meta-learning algorithms can be improved a lot without consuming many\nresources. Furthermore, we empirically verify the effectiveness of\n$\\mathcal{S}/\\mathcal{T}$ protocol in a typical application of meta-learning,\n$\\mathit{i.e.}$, few-shot learning. In detail, after constructing target models\nby fine-tuning the pre-trained network on those hard tasks, we match the\ntask-specific solvers to target models via knowledge distillation. Experiments\ndemonstrate the superiority of our proposal.",
          "link": "http://arxiv.org/abs/2104.03736",
          "publishedOn": "2021-06-08T02:20:22.234Z",
          "wordCount": 645,
          "title": "Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yubin Yang</a>",
          "description": "This paper presents an efficient multi-scale vision Transformer, called ResT,\nthat capably served as a general-purpose backbone for image recognition. Unlike\nexisting Transformer methods, which employ standard Transformer blocks to\ntackle raw images with a fixed resolution, our ResT have several advantages:\n(1) A memory-efficient multi-head self-attention is built, which compresses the\nmemory by a simple depth-wise convolution, and projects the interaction across\nthe attention-heads dimension while keeping the diversity ability of\nmulti-heads; (2) Position encoding is constructed as spatial attention, which\nis more flexible and can tackle with input images of arbitrary size without\ninterpolation or fine-tune; (3) Instead of the straightforward tokenization at\nthe beginning of each stage, we design the patch embedding as a stack of\noverlapping convolution operation with stride on the 2D-reshaped token map. We\ncomprehensively validate ResT on image classification and downstream tasks.\nExperimental results show that the proposed ResT can outperform the recently\nstate-of-the-art backbones by a large margin, demonstrating the potential of\nResT as strong backbones. The code and models will be made publicly available\nat https://github.com/wofmanaf/ResT.",
          "link": "http://arxiv.org/abs/2105.13677",
          "publishedOn": "2021-06-08T02:20:22.202Z",
          "wordCount": 661,
          "title": "ResT: An Efficient Transformer for Visual Recognition. (arXiv:2105.13677v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiang_P/0/1/0/all/0/1\">Pei-Ze Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_M/0/1/0/all/0/1\">Meng-Shiun Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_H/0/1/0/all/0/1\">Hung-Yu Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wei-sheng Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1\">Wei-Chen Chiu</a>",
          "description": "In this work, we aim to address the 3D scene stylization problem - generating\nstylized images of the scene at arbitrary novel view angles. A straightforward\nsolution is to combine existing novel view synthesis and image/video style\ntransfer approaches, which often leads to blurry results or inconsistent\nappearance. Inspired by the high quality results of the neural radiance fields\n(NeRF) method, we propose a joint framework to directly render novel views with\nthe desired style. Our framework consists of two components: an implicit\nrepresentation of the 3D scene with the neural radiance field model, and a\nhypernetwork to transfer the style information into the scene representation.\nIn particular, our implicit representation model disentangles the scene into\nthe geometry and appearance branches, and the hypernetwork learns to predict\nthe parameters of the appearance branch from the reference style image. To\nalleviate the training difficulties and memory burden, we propose a two-stage\ntraining procedure and a patch sub-sampling approach to optimize the style and\ncontent losses with the neural radiance field model. After optimization, our\nmodel is able to render consistent novel views at arbitrary view angles with\narbitrary style. Both quantitative evaluation and human subject study have\ndemonstrated that the proposed method generates faithful stylization results\nwith consistent appearance across different views.",
          "link": "http://arxiv.org/abs/2105.13016",
          "publishedOn": "2021-06-08T02:20:22.196Z",
          "wordCount": 682,
          "title": "Stylizing 3D Scene via Implicit Representation and HyperNetwork. (arXiv:2105.13016v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-06-08T02:20:22.189Z",
          "wordCount": 744,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Kaleel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rigel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>",
          "description": "Recent advances in attention-based networks have shown that Vision\nTransformers can achieve state-of-the-art or near state-of-the-art results on\nmany image classification tasks. This puts transformers in the unique position\nof being a promising alternative to traditional convolutional neural networks\n(CNNs). While CNNs have been carefully studied with respect to adversarial\nattacks, the same cannot be said of Vision Transformers. In this paper, we\nstudy the robustness of Vision Transformers to adversarial examples. Our\nanalyses of transformer security is divided into three parts. First, we test\nthe transformer under standard white-box and black-box attacks. Second, we\nstudy the transferability of adversarial examples between CNNs and\ntransformers. We show that adversarial examples do not readily transfer between\nCNNs and transformers. Based on this finding, we analyze the security of a\nsimple ensemble defense of CNNs and transformers. By creating a new attack, the\nself-attention blended gradient attack, we show that such an ensemble is not\nsecure under a white-box adversary. However, under a black-box adversary, we\nshow that an ensemble can achieve unprecedented robustness without sacrificing\nclean accuracy. Our analysis for this work is done using six types of white-box\nattacks and two types of black-box attacks. Our study encompasses multiple\nVision Transformers, Big Transfer Models and CNN architectures trained on\nCIFAR-10, CIFAR-100 and ImageNet.",
          "link": "http://arxiv.org/abs/2104.02610",
          "publishedOn": "2021-06-08T02:20:22.163Z",
          "wordCount": 675,
          "title": "On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yingjie Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuesong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kwan-Yee Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Semantic Scene Completion aims at reconstructing a complete 3D scene with\nprecise voxel-wise semantics from a single-view depth or RGBD image. It is a\ncrucial but challenging problem for indoor scene understanding. In this work,\nwe present a novel framework named Scene-Instance-Scene Network\n(\\textit{SISNet}), which takes advantages of both instance and scene level\nsemantic information. Our method is capable of inferring fine-grained shape\ndetails as well as nearby objects whose semantic categories are easily\nmixed-up. The key insight is that we decouple the instances from a coarsely\ncompleted semantic scene instead of a raw input image to guide the\nreconstruction of instances and the overall scene. SISNet conducts iterative\nscene-to-instance (SI) and instance-to-scene (IS) semantic completion.\nSpecifically, the SI is able to encode objects' surrounding context for\neffectively decoupling instances from the scene and each instance could be\nvoxelized into higher resolution to capture finer details. With IS,\nfine-grained instance information can be integrated back into the 3D scene and\nthus leads to more accurate semantic scene completion. Utilizing such an\niterative mechanism, the scene and instance completion benefits each other to\nachieve higher completion accuracy. Extensively experiments show that our\nproposed method consistently outperforms state-of-the-art methods on both real\nNYU, NYUCAD and synthetic SUNCG-RGBD datasets. The code and the supplementary\nmaterial will be available at \\url{https://github.com/yjcaimeow/SISNet}.",
          "link": "http://arxiv.org/abs/2104.03640",
          "publishedOn": "2021-06-08T02:20:22.154Z",
          "wordCount": 686,
          "title": "Semantic Scene Completion via Integrating Instances and Scene in-the-Loop. (arXiv:2104.03640v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.11646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chenggang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yaoqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bolun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Cross-view geo-localization is to spot images of the same geographic target\nfrom different platforms, e.g., drone-view cameras and satellites. It is\nchallenging in the large visual appearance changes caused by extreme viewpoint\nvariations. Existing methods usually concentrate on mining the fine-grained\nfeature of the geographic target in the image center, but underestimate the\ncontextual information in neighbor areas. In this work, we argue that neighbor\nareas can be leveraged as auxiliary information, enriching discriminative clues\nfor geolocalization. Specifically, we introduce a simple and effective deep\nneural network, called Local Pattern Network (LPN), to take advantage of\ncontextual information in an end-to-end manner. Without using extra part\nestimators, LPN adopts a square-ring feature partition strategy, which provides\nthe attention according to the distance to the image center. It eases the part\nmatching and enables the part-wise representation learning. Owing to the\nsquare-ring partition design, the proposed LPN has good scalability to rotation\nvariations and achieves competitive results on three prevailing benchmarks,\ni.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN\ncan be easily embedded into other frameworks to further boost performance.",
          "link": "http://arxiv.org/abs/2008.11646",
          "publishedOn": "2021-06-08T02:20:22.136Z",
          "wordCount": 666,
          "title": "Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1\">Erik Englesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>",
          "description": "Prior works have found it beneficial to combine provably noise-robust loss\nfunctions e.g., mean absolute error (MAE) with standard categorical loss\nfunction e.g. cross entropy (CE) to improve their learnability. Here, we\npropose to use Jensen-Shannon divergence as a noise-robust loss function and\nshow that it interestingly interpolate between CE and MAE with a controllable\nmixing parameter. Furthermore, we make a crucial observation that CE exhibit\nlower consistency around noisy data points. Based on this observation, we adopt\na generalized version of the Jensen-Shannon divergence for multiple\ndistributions to encourage consistency around data points. Using this loss\nfunction, we show state-of-the-art results on both synthetic (CIFAR), and\nreal-world (WebVision) noise with varying noise rates.",
          "link": "http://arxiv.org/abs/2105.04522",
          "publishedOn": "2021-06-08T02:20:22.114Z",
          "wordCount": 584,
          "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05434",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_F/0/1/0/all/0/1\">Fangxu Xing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fakhri_G/0/1/0/all/0/1\">Georges El Fakhri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>",
          "description": "Multimodal MRI provides complementary and clinically relevant information to\nprobe tissue condition and to characterize various diseases. However, it is\noften difficult to acquire sufficiently many modalities from the same subject\ndue to limitations in study plans, while quantitative analysis is still\ndemanded. In this work, we propose a unified conditional disentanglement\nframework to synthesize any arbitrary modality from an input modality. Our\nframework hinges on a cycle-constrained conditional adversarial training\napproach, where it can extract a modality-invariant anatomical feature with a\nmodality-agnostic encoder and generate a target modality with a conditioned\ndecoder. We validate our framework on four MRI modalities, including\nT1-weighted, T1 contrast enhanced, T2-weighted, and FLAIR MRI, from the\nBraTS'18 database, showing superior performance on synthesis quality over the\ncomparison methods. In addition, we report results from experiments on a tumor\nsegmentation task carried out with synthesized data.",
          "link": "http://arxiv.org/abs/2101.05434",
          "publishedOn": "2021-06-08T02:20:22.107Z",
          "wordCount": 617,
          "title": "A Unified Conditional Disentanglement Framework for Multimodal Brain MR Image Translation. (arXiv:2101.05434v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lobachev_O/0/1/0/all/0/1\">Oleg Lobachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funatomi_T/0/1/0/all/0/1\">Takuya Funatomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfaffenroth_A/0/1/0/all/0/1\">Alexander Pfaffenroth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forster_R/0/1/0/all/0/1\">Reinhold F&#xf6;rster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knudsen_L/0/1/0/all/0/1\">Lars Knudsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wrede_C/0/1/0/all/0/1\">Christoph Wrede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guthe_M/0/1/0/all/0/1\">Michael Guthe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haberthur_D/0/1/0/all/0/1\">David Haberth&#xfc;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hlushchuk_R/0/1/0/all/0/1\">Ruslan Hlushchuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salaets_T/0/1/0/all/0/1\">Thomas Salaets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toelen_J/0/1/0/all/0/1\">Jaan Toelen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffling_S/0/1/0/all/0/1\">Simone Gaffling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlfeld_C/0/1/0/all/0/1\">Christian M&#xfc;hlfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grothausmann_R/0/1/0/all/0/1\">Roman Grothausmann</a>",
          "description": "Registration of histological serial sections is a challenging task. Serial\nsections exhibit distortions and damage from sectioning. Missing information on\nhow the tissue looked before cutting makes a realistic validation of 2D\nregistrations extremely difficult.\n\nThis work proposes methods for ground-truth-based evaluation of\nregistrations. Firstly, we present a methodology to generate test data for\nregistrations. We distort an innately registered image stack in the manner\nsimilar to the cutting distortion of serial sections. Test cases are generated\nfrom existing 3D data sets, thus the ground truth is known. Secondly, our test\ncase generation premises evaluation of the registrations with known ground\ntruths. Our methodology for such an evaluation technique distinguishes this\nwork from other approaches. Both under- and over-registration become evident in\nour evaluations. We also survey existing validation efforts.\n\nWe present a full-series evaluation across six different registration methods\napplied to our distorted 3D data sets of animal lungs. Our distorted and ground\ntruth data sets are made publicly available.",
          "link": "http://arxiv.org/abs/2011.11060",
          "publishedOn": "2021-06-08T02:20:22.100Z",
          "wordCount": 656,
          "title": "Registration of serial sections: An evaluation method based on distortions of the ground truths. (arXiv:2011.11060v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1\">Leonardo Petrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1\">Alessandro Favero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1\">Mario Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Understanding why deep nets can classify data in large dimensions remains a\nchallenge. It has been proposed that they do so by becoming stable to\ndiffeomorphisms, yet existing empirical measurements support that it is often\nnot the case. We revisit this question by defining a maximum-entropy\ndistribution on diffeomorphisms, that allows to study typical diffeomorphisms\nof a given norm. We confirm that stability toward diffeomorphisms does not\nstrongly correlate to performance on benchmark data sets of images. By\ncontrast, we find that the stability toward diffeomorphisms relative to that of\ngeneric transformations $R_f$ correlates remarkably with the test error\n$\\epsilon_t$. It is of order unity at initialization but decreases by several\ndecades during training for state-of-the-art architectures. For CIFAR10 and 15\nknown architectures, we find $\\epsilon_t\\approx 0.2\\sqrt{R_f}$, suggesting that\nobtaining a small $R_f$ is important to achieve good performance. We study how\n$R_f$ depends on the size of the training set and compare it to a simple model\nof invariant learning.",
          "link": "http://arxiv.org/abs/2105.02468",
          "publishedOn": "2021-06-08T02:20:22.090Z",
          "wordCount": 621,
          "title": "Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1\">Travers Rhodes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "There have been many recent advances in representation learning; however,\nunsupervised representation learning can still struggle with model\nidentification issues. Variational Auto-Encoders (VAEs) and their extensions\nsuch as $\\beta$-VAEs have been shown to locally align latent variables with PCA\ndirections, which can help to improve model disentanglement under some\nconditions. Borrowing inspiration from Independent Component Analysis (ICA) and\nsparse coding, we propose applying an $L_1$ loss to the VAE's generative\nJacobian during training to encourage local latent variable alignment with\nindependent factors of variation in the data. We demonstrate our results on a\nvariety of datasets, giving qualitative and quantitative results using\ninformation theoretic and modularity measures that show our added $L_1$ cost\nencourages local axis alignment of the latent representation with individual\nfactors of variation.",
          "link": "http://arxiv.org/abs/2106.02923",
          "publishedOn": "2021-06-08T02:20:22.084Z",
          "wordCount": 560,
          "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jeonghun Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsui_Y/0/1/0/all/0/1\">Yusuke Matsui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_K/0/1/0/all/0/1\">Kiyoharu Aizawa</a>",
          "description": "Scene text recognition (STR) task has a common practice: All state-of-the-art\nSTR models are trained on large synthetic data. In contrast to this practice,\ntraining STR models only on fewer real labels (STR with fewer labels) is\nimportant when we have to train STR models without synthetic data: for\nhandwritten or artistic texts that are difficult to generate synthetically and\nfor languages other than English for which we do not always have synthetic\ndata. However, there has been implicit common knowledge that training STR\nmodels on real data is nearly impossible because real data is insufficient. We\nconsider that this common knowledge has obstructed the study of STR with fewer\nlabels. In this work, we would like to reactivate STR with fewer labels by\ndisproving the common knowledge. We consolidate recently accumulated public\nreal data and show that we can train STR models satisfactorily only with real\nlabeled data. Subsequently, we find simple data augmentation to fully exploit\nreal data. Furthermore, we improve the models by collecting unlabeled data and\nintroducing semi- and self-supervised methods. As a result, we obtain a\ncompetitive model to state-of-the-art methods. To the best of our knowledge,\nthis is the first study that 1) shows sufficient performance by only using real\nlabels and 2) introduces semi- and self-supervised methods into STR with fewer\nlabels. Our code and data are available:\nhttps://github.com/ku21fan/STR-Fewer-Labels",
          "link": "http://arxiv.org/abs/2103.04400",
          "publishedOn": "2021-06-08T02:20:22.061Z",
          "wordCount": 706,
          "title": "What If We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels. (arXiv:2103.04400v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1\">Ashish Vaswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1\">Prajit Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1\">Aravind Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1\">Niki Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hechtman_B/0/1/0/all/0/1\">Blake Hechtman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1\">Jonathon Shlens</a>",
          "description": "Self-attention has the promise of improving computer vision systems due to\nparameter-independent scaling of receptive fields and content-dependent\ninteractions, in contrast to parameter-dependent scaling and\ncontent-independent interactions of convolutions. Self-attention models have\nrecently been shown to have encouraging improvements on accuracy-parameter\ntrade-offs compared to baseline convolutional models such as ResNet-50. In this\nwork, we aim to develop self-attention models that can outperform not just the\ncanonical baseline models, but even the high-performing convolutional models.\nWe propose two extensions to self-attention that, in conjunction with a more\nefficient implementation of self-attention, improve the speed, memory usage,\nand accuracy of these models. We leverage these improvements to develop a new\nself-attention model family, HaloNets, which reach state-of-the-art accuracies\non the parameter-limited setting of the ImageNet classification benchmark. In\npreliminary transfer learning experiments, we find that HaloNet models\noutperform much larger models and have better inference performance. On harder\ntasks such as object detection and instance segmentation, our simple local\nself-attention and convolutional hybrids show improvements over very strong\nbaselines. These results mark another step in demonstrating the efficacy of\nself-attention models on settings traditionally dominated by convolutional\nmodels.",
          "link": "http://arxiv.org/abs/2103.12731",
          "publishedOn": "2021-06-08T02:20:22.054Z",
          "wordCount": 664,
          "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones. (arXiv:2103.12731v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Shiyi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1\">Christopher Choy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Subhashree Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1\">Larry S. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce DiscoBox, a novel framework that jointly learns instance\nsegmentation and semantic correspondence using bounding box supervision.\nSpecifically, we propose a self-ensembling framework where instance\nsegmentation and semantic correspondence are jointly guided by a structured\nteacher in addition to the bounding box supervision. The teacher is a\nstructured energy model incorporating a pairwise potential and a cross-image\npotential to model the pairwise pixel relationships both within and across the\nboxes. Minimizing the teacher energy simultaneously yields refined object masks\nand dense correspondences between intra-class objects, which are taken as\npseudo-labels to supervise the task network and provide positive/negative\ncorrespondence pairs for dense constrastive learning. We show a symbiotic\nrelationship where the two tasks mutually benefit from each other. Our best\nmodel achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly\nsupervised methods and is competitive to supervised methods. We also obtain\nstate of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with\nreal-time inference.",
          "link": "http://arxiv.org/abs/2105.06464",
          "publishedOn": "2021-06-08T02:20:22.044Z",
          "wordCount": 642,
          "title": "DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingjian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1\">Enhua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiulin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Ying Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>",
          "description": "Deep convolutional neural networks (CNNs) are often of sophisticated design\nwith numerous convolutional layers and learnable parameters for the accuracy\nreason. To alleviate the expensive costs of deploying them on mobile devices,\nrecent works have made huge efforts for excavating redundancy in pre-defined\narchitectures. Nevertheless, the redundancy on the input resolution of modern\nCNNs has not been fully investigated, i.e., the resolution of input image is\nfixed. In this paper, we observe that the smallest resolution for accurately\npredicting the given image is different using the same neural network. To this\nend, we propose a novel dynamic-resolution network (DRNet) in which the\nresolution is determined dynamically based on each input sample. Thus, a\nresolution predictor with negligible computational costs is explored and\noptimized jointly with the desired network. In practice, the predictor learns\nthe smallest resolution that can retain and even exceed the original\nrecognition accuracy for each image. During the inference, each input image\nwill be resized to its predicted resolution for minimizing the overall\ncomputation burden. We then conduct extensive experiments on several benchmark\nnetworks and datasets. The results show that our DRNet can be embedded in any\noff-the-shelf network architecture to obtain a considerable reduction in\ncomputational complexity. For instance, DRNet achieves similar performance with\nan about 34% computation reduction, while gains 1.4% accuracy increase with 10%\ncomputation reduction compared to the original ResNet-50 on ImageNet.",
          "link": "http://arxiv.org/abs/2106.02898",
          "publishedOn": "2021-06-08T02:20:22.029Z",
          "wordCount": 655,
          "title": "Dynamic Resolution Network. (arXiv:2106.02898v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1911.07255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1\">Amit Boyarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1\">Sanketh Vedula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>",
          "description": "Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.",
          "link": "http://arxiv.org/abs/1911.07255",
          "publishedOn": "2021-06-08T02:20:22.003Z",
          "wordCount": 615,
          "title": "Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.09688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>",
          "description": "The irregular domain and lack of ordering make it challenging to design deep\nneural networks for point cloud processing. This paper presents a novel\nframework named Point Cloud Transformer(PCT) for point cloud learning. PCT is\nbased on Transformer, which achieves huge success in natural language\nprocessing and displays great potential in image processing. It is inherently\npermutation invariant for processing a sequence of points, making it\nwell-suited for point cloud learning. To better capture local context within\nthe point cloud, we enhance input embedding with the support of farthest point\nsampling and nearest neighbor search. Extensive experiments demonstrate that\nthe PCT achieves the state-of-the-art performance on shape classification, part\nsegmentation and normal estimation tasks.",
          "link": "http://arxiv.org/abs/2012.09688",
          "publishedOn": "2021-06-08T02:20:21.995Z",
          "wordCount": 610,
          "title": "PCT: Point cloud transformer. (arXiv:2012.09688v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shashi Kant Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chia-Chien Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfe_J/0/1/0/all/0/1\">Jeremy M. Wolfe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreiman_G/0/1/0/all/0/1\">Gabriel Kreiman</a>",
          "description": "Visual search is a ubiquitous and often challenging daily task, exemplified\nby looking for the car keys at home or a friend in a crowd. An intriguing\nproperty of some classical search tasks is an asymmetry such that finding a\ntarget A among distractors B can be easier than finding B among A. To elucidate\nthe mechanisms responsible for asymmetry in visual search, we propose a\ncomputational model that takes a target and a search image as inputs and\nproduces a sequence of eye movements until the target is found. The model\nintegrates eccentricity-dependent visual recognition with target-dependent\ntop-down cues. We compared the model against human behavior in six paradigmatic\nsearch tasks that show asymmetry in humans. Without prior exposure to the\nstimuli or task-specific training, the model provides a plausible mechanism for\nsearch asymmetry. We hypothesized that the polarity of search asymmetry arises\nfrom experience with the natural environment. We tested this hypothesis by\ntraining the model on an augmented version of ImageNet where the biases of\nnatural images were either removed or reversed. The polarity of search\nasymmetry disappeared or was altered depending on the training protocol. This\nstudy highlights how classical perceptual properties can emerge in neural\nnetwork models, without the need for task-specific training, but rather as a\nconsequence of the statistical properties of the developmental diet fed to the\nmodel. All source code and stimuli are publicly available\nhttps://github.com/kreimanlab/VisualSearchAsymmetry",
          "link": "http://arxiv.org/abs/2106.02953",
          "publishedOn": "2021-06-08T02:20:21.988Z",
          "wordCount": 683,
          "title": "Visual Search Asymmetry: Deep Nets and Humans Share Similar Inherent Biases. (arXiv:2106.02953v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yehui Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "This paper studies the efficiency problem for visual transformers by\nexcavating redundant calculation in given networks. The recent transformer\narchitecture has demonstrated its effectiveness for achieving excellent\nperformance on a series of computer vision tasks. However, similar to that of\nconvolutional neural networks, the huge computational cost of vision\ntransformers is still a severe issue. Considering that the attention mechanism\naggregates different patches layer-by-layer, we present a novel patch slimming\napproach that discards useless patches in a top-down paradigm. We first\nidentify the effective patches in the last layer and then use them to guide the\npatch selection process of previous layers. For each layer, the impact of a\npatch on the final output feature is approximated and patches with less impact\nwill be removed. Experimental results on benchmark datasets demonstrate that\nthe proposed method can significantly reduce the computational costs of vision\ntransformers without affecting their performances. For example, over 45% FLOPs\nof the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the\nImageNet dataset.",
          "link": "http://arxiv.org/abs/2106.02852",
          "publishedOn": "2021-06-08T02:20:21.981Z",
          "wordCount": 606,
          "title": "Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.04865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1\">Fangxu Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prince_J/0/1/0/all/0/1\">Jerry L. Prince</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_M/0/1/0/all/0/1\">Maureen Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1\">Arnold Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reese_T/0/1/0/all/0/1\">Timothy G. Reese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wedeen_V/0/1/0/all/0/1\">Van J. Wedeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1\">Georges El Fakhri</a>",
          "description": "Intelligible speech is produced by creating varying internal local muscle\ngroupings -- i.e., functional units -- that are generated in a systematic and\ncoordinated manner. There are two major challenges in characterizing and\nanalyzing functional units.~First, due to the complex and convoluted nature of\ntongue structure and function, it is of great importance to develop a method\nthat can accurately decode complex muscle coordination patterns during speech.\nSecond, it is challenging to keep identified functional units across subjects\ncomparable due to their substantial variability. In this work, to address these\nchallenges, we develop a new deep learning framework to identify common and\nsubject-specific functional units of tongue motion during speech.~Our framework\nhinges on joint deep graph-regularized sparse non-negative matrix factorization\n(NMF) using motion quantities derived from displacements by tagged Magnetic\nResonance Imaging. More specifically, we transform NMF with sparse and graph\nregularizations into modular architectures akin to deep neural networks by\nmeans of unfolding the Iterative Shrinkage-Thresholding Algorithm to learn\ninterpretable building blocks and associated weighting map. We then apply\nspectral clustering to common and subject-specific weighting maps from which we\njointly determine the common and subject-specific functional units. Experiments\ncarried out with simulated datasets show that the proposed method achieved on\npar or better clustering performance over the comparison methods. Experiments\ncarried out with in vivo tongue motion data show that the proposed method can\ndetermine the common and subject-specific functional units with increased\ninterpretability and decreased size variability.",
          "link": "http://arxiv.org/abs/2007.04865",
          "publishedOn": "2021-06-08T02:20:21.974Z",
          "wordCount": 754,
          "title": "A Deep Joint Sparse Non-negative Matrix Factorization Framework for Identifying the Common and Subject-specific Functional Units of Tongue Motion During Speech. (arXiv:2007.04865v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.06255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fangqiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fuling Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Geng Lu</a>",
          "description": "Aerial tracking, which has exhibited its omnipresent dedication and splendid\nperformance, is one of the most active applications in the remote sensing\nfield. Especially, unmanned aerial vehicle (UAV)-based remote sensing system,\nequipped with a visual tracking approach, has been widely used in aviation,\nnavigation, agriculture,transportation, and public security, etc. As is\nmentioned above, the UAV-based aerial tracking platform has been gradually\ndeveloped from research to practical application stage, reaching one of the\nmain aerial remote sensing technologies in the future. However, due to the\nreal-world onerous situations, e.g., harsh external challenges, the vibration\nof the UAV mechanical structure (especially under strong wind conditions), the\nmaneuvering flight in complex environment, and the limited computation\nresources onboard, accuracy, robustness, and high efficiency are all crucial\nfor the onboard tracking methods. Recently, the discriminative correlation\nfilter (DCF)-based trackers have stood out for their high computational\nefficiency and appealing robustness on a single CPU, and have flourished in the\nUAV visual tracking community. In this work, the basic framework of the\nDCF-based trackers is firstly generalized, based on which, 23 state-of-the-art\nDCF-based trackers are orderly summarized according to their innovations for\nsolving various issues. Besides, exhaustive and quantitative experiments have\nbeen extended on various prevailing UAV tracking benchmarks, i.e., UAV123,\nUAV123@10fps, UAV20L, UAVDT, DTB70, and VisDrone2019-SOT, which contain 371,903\nframes in total. The experiments show the performance, verify the feasibility,\nand demonstrate the current challenges of DCF-based trackers onboard UAV\ntracking.",
          "link": "http://arxiv.org/abs/2010.06255",
          "publishedOn": "2021-06-08T02:20:21.955Z",
          "wordCount": 754,
          "title": "Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Recognition accuracy and response time are both critically essential ahead of\nbuilding practical electroencephalography (EEG) based brain-computer interface\n(BCI). Recent approaches, however, have either compromised in the\nclassification accuracy or responding time. This paper presents a novel deep\nlearning approach designed towards remarkably accurate and responsive motor\nimagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term\nMemory (BiLSTM) with the Attention mechanism manages to derive relevant\nfeatures from raw EEG signals. The connected graph convolutional neural network\n(GCN) promotes the decoding performance by cooperating with the topological\nstructure of features, which are estimated from the overall data. The\n0.4-second detection framework has shown effective and efficient prediction\nbased on individual and group-wise training, with 98.81% and 94.64% accuracy,\nrespectively, which outperformed all the state-of-the-art studies. The\nintroduced deep feature mining approach can precisely recognize human motion\nintents from raw EEG signals, which paves the road to translate the EEG based\nMI recognition to practical BCI systems.",
          "link": "http://arxiv.org/abs/2005.00777",
          "publishedOn": "2021-06-08T02:20:21.917Z",
          "wordCount": 624,
          "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Attentional mechanisms are order-invariant. Positional encoding is a crucial\ncomponent to allow attention-based deep model architectures such as Transformer\nto address sequences or images where the position of information matters. In\nthis paper, we propose a novel positional encoding method based on learnable\nFourier features. Instead of hard-coding each position as a token or a vector,\nwe represent each position, which can be multi-dimensional, as a trainable\nencoding based on learnable Fourier feature mapping, modulated with a\nmulti-layer perceptron. The representation is particularly advantageous for a\nspatial multi-dimensional position, e.g., pixel positions on an image, where\n$L_2$ distances or more complex positional relationships need to be captured.\nOur experiments based on several public benchmark tasks show that our learnable\nFourier feature representation for multi-dimensional positional encoding\noutperforms existing methods by both improving the accuracy and allowing faster\nconvergence.",
          "link": "http://arxiv.org/abs/2106.02795",
          "publishedOn": "2021-06-08T02:20:21.870Z",
          "wordCount": 573,
          "title": "Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Instance contrast for unsupervised representation learning has achieved great\nsuccess in recent years. In this work, we explore the idea of instance\ncontrastive learning in unsupervised domain adaptation (UDA) and propose a\nnovel Category Contrast technique (CaCo) that introduces semantic priors on top\nof instance discrimination for visual UDA tasks. By considering instance\ncontrastive learning as a dictionary look-up operation, we construct a\nsemantics-aware dictionary with samples from both source and target domains\nwhere each target sample is assigned a (pseudo) category label based on the\ncategory priors of source samples. This allows category contrastive learning\n(between target queries and the category-level dictionary) for\ncategory-discriminative yet domain-invariant feature representations: samples\nof the same category (from either source or target domain) are pulled closer\nwhile those of different categories are pushed apart simultaneously. Extensive\nUDA experiments in multiple visual tasks ($e.g.$, segmentation, classification\nand detection) show that the simple implementation of CaCo achieves superior\nperformance as compared with the highly-optimized state-of-the-art methods.\nAnalytically and empirically, the experiments also demonstrate that CaCo is\ncomplementary to existing UDA methods and generalizable to other learning\nsetups such as semi-supervised learning, unsupervised model adaptation, etc.",
          "link": "http://arxiv.org/abs/2106.02885",
          "publishedOn": "2021-06-08T02:20:21.862Z",
          "wordCount": 622,
          "title": "Category Contrast for Unsupervised Domain Adaptation in Visual Tasks. (arXiv:2106.02885v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.08348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1\">Timo Milbich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1\">Bj&#xf6;rn Ommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Joseph Paul Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>",
          "description": "Deep Metric Learning (DML) provides a crucial tool for visual similarity and\nzero-shot applications by learning generalizing embedding spaces, although\nrecent work in DML has shown strong performance saturation across training\nobjectives. However, generalization capacity is known to scale with the\nembedding space dimensionality. Unfortunately, high dimensional embeddings also\ncreate higher retrieval cost for downstream applications. To remedy this, we\npropose \\emph{Simultaneous Similarity-based Self-distillation (S2SD). S2SD\nextends DML with knowledge distillation from auxiliary, high-dimensional\nembedding and feature spaces to leverage complementary context during training\nwhile retaining test-time cost and with negligible changes to the training\ntime. Experiments and ablations across different objectives and standard\nbenchmarks show S2SD offers notable improvements of up to 7% in Recall@1, while\nalso setting a new state-of-the-art. Code available at\nhttps://github.com/MLforHealth/S2SD.",
          "link": "http://arxiv.org/abs/2009.08348",
          "publishedOn": "2021-06-08T02:20:21.830Z",
          "wordCount": 605,
          "title": "S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning. (arXiv:2009.08348v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1\">Jun Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Han Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Li Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Rong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xiao Gu</a>",
          "description": "Image composition plays a common but important role in photo editing. To\nacquire photo-realistic composite images, one must adjust the appearance and\nvisual style of the foreground to be compatible with the background. Existing\ndeep learning methods for harmonizing composite images directly learn an image\nmapping network from the composite to the real one, without explicit\nexploration on visual style consistency between the background and the\nforeground images. To ensure the visual style consistency between the\nforeground and the background, in this paper, we treat image harmonization as a\nstyle transfer problem. In particular, we propose a simple yet effective\nRegion-aware Adaptive Instance Normalization (RAIN) module, which explicitly\nformulates the visual style from the background and adaptively applies them to\nthe foreground. With our settings, our RAIN module can be used as a drop-in\nmodule for existing image harmonization networks and is able to bring\nsignificant improvements. Extensive experiments on the existing image\nharmonization benchmark datasets show the superior capability of the proposed\nmethod. Code is available at {https://github.com/junleen/RainNet}.",
          "link": "http://arxiv.org/abs/2106.02853",
          "publishedOn": "2021-06-08T02:20:21.794Z",
          "wordCount": 607,
          "title": "Region-aware Adaptive Instance Normalization for Image Harmonization. (arXiv:2106.02853v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>",
          "description": "The convolutional neural network (CNN) has become a basic model for solving\nmany computer vision problems. In recent years, a new class of CNNs, recurrent\nconvolution neural network (RCNN), inspired by abundant recurrent connections\nin the visual systems of animals, was proposed. The critical element of RCNN is\nthe recurrent convolutional layer (RCL), which incorporates recurrent\nconnections between neurons in the standard convolutional layer. With\nincreasing number of recurrent computations, the receptive fields (RFs) of\nneurons in RCL expand unboundedly, which is inconsistent with biological facts.\nWe propose to modulate the RFs of neurons by introducing gates to the recurrent\nconnections. The gates control the amount of context information inputting to\nthe neurons and the neurons' RFs therefore become adaptive. The resulting layer\nis called gated recurrent convolution layer (GRCL). Multiple GRCLs constitute a\ndeep model called gated RCNN (GRCNN). The GRCNN was evaluated on several\ncomputer vision tasks including object recognition, scene text recognition and\nobject detection, and obtained much better results than the RCNN. In addition,\nwhen combined with other adaptive RF techniques, the GRCNN demonstrated\ncompetitive performance to the state-of-the-art models on benchmark datasets\nfor these tasks. The codes are released at\n\\href{https://github.com/Jianf-Wang/GRCNN}{https://github.com/Jianf-Wang/GRCNN}.",
          "link": "http://arxiv.org/abs/2106.02859",
          "publishedOn": "2021-06-08T02:20:21.772Z",
          "wordCount": 664,
          "title": "Convolutional Neural Networks with Gated Recurrent Connections. (arXiv:2106.02859v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1\">Sourbh Bhadane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1\">Aaron B. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1\">Jayadev Acharya</a>",
          "description": "We consider a linear autoencoder in which the latent variables are quantized,\nor corrupted by noise, and the constraint is Schur-concave in the set of latent\nvariances. Although finding the optimal encoder/decoder pair for this setup is\na nonconvex optimization problem, we show that decomposing the source into its\nprincipal components is optimal. If the constraint is strictly Schur-concave\nand the empirical covariance matrix has only simple eigenvalues, then any\noptimal encoder/decoder must decompose the source in this way. As one\napplication, we consider a strictly Schur-concave constraint that estimates the\nnumber of bits needed to represent the latent variables under fixed-rate\nencoding, a setup that we call \\emph{Principal Bit Analysis (PBA)}. This yields\na practical, general-purpose, fixed-rate compressor that outperforms existing\nalgorithms. As a second application, we show that a prototypical\nautoencoder-based variable-rate compressor is guaranteed to decompose the\nsource into its principal components.",
          "link": "http://arxiv.org/abs/2106.02796",
          "publishedOn": "2021-06-08T02:20:21.763Z",
          "wordCount": 581,
          "title": "Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castrejon_L/0/1/0/all/0/1\">Lluis Castrejon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1\">Nicolas Ballas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Videos can often be created by first outlining a global description of the\nscene and then adding local details. Inspired by this we propose a hierarchical\nmodel for video generation which follows a coarse to fine approach. First our\nmodel generates a low resolution video, establishing the global scene\nstructure, that is then refined by subsequent levels in the hierarchy. We train\neach level in our hierarchy sequentially on partial views of the videos. This\nreduces the computational complexity of our generative model, which scales to\nhigh-resolution videos beyond a few frames. We validate our approach on\nKinetics-600 and BDD100K, for which we train a three level model capable of\ngenerating 256x256 videos with 48 frames.",
          "link": "http://arxiv.org/abs/2106.02719",
          "publishedOn": "2021-06-08T02:20:21.755Z",
          "wordCount": 540,
          "title": "Hierarchical Video Generation for Complex Data. (arXiv:2106.02719v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaorong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Malu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_F/0/1/0/all/0/1\">Fengqing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Anping Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuanyuan Huang</a>",
          "description": "Deep Convolutional Neural Network (DCNN) and Transformer have achieved\nremarkable successes in image recognition. However, their performance in\nfine-grained image recognition is still difficult to meet the requirements of\nactual needs. This paper proposes a Sequence Random Network (SRN) to enhance\nthe performance of DCNN. The output of DCNN is one-dimensional features. This\none-dimensional feature abstractly represents image information, but it does\nnot express well the detailed information of image. To address this issue, we\nuse the proposed SRN which composed of BiLSTM and several Tanh-Dropout blocks\n(called BiLSTM-TDN), to further process DCNN one-dimensional features for\nhighlighting the detail information of image. After the feature transform by\nBiLSTM-TDN, the recognition performance has been greatly improved. We conducted\nthe experiments on six fine-grained image datasets. Except for FGVC-Aircraft,\nthe accuracies of the proposed methods on the other datasets exceeded 99%.\nExperimental results show that BiLSTM-TDN is far superior to the existing\nstate-of-the-art methods. In addition to DCNN, BiLSTM-TDN can also be extended\nto other models, such as Transformer.",
          "link": "http://arxiv.org/abs/2103.07230",
          "publishedOn": "2021-06-08T02:20:21.716Z",
          "wordCount": 651,
          "title": "Sequential Random Network for Fine-grained Image Classification. (arXiv:2103.07230v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Ziyu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1\">Bobak Mortazavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "The recent breakthrough achieved by contrastive learning accelerates the pace\nfor deploying unsupervised training on real-world data applications. However,\nunlabeled data in reality is commonly imbalanced and shows a long-tail\ndistribution, and it is unclear how robustly the latest contrastive learning\nmethods could perform in the practical scenario. This paper proposes to\nexplicitly tackle this challenge, via a principled framework called\nSelf-Damaging Contrastive Learning (SDCLR), to automatically balance the\nrepresentation learning without knowing the classes. Our main inspiration is\ndrawn from the recent finding that deep models have difficult-to-memorize\nsamples, and those may be exposed through network pruning. It is further\nnatural to hypothesize that long-tail samples are also tougher for the model to\nlearn well due to insufficient examples. Hence, the key innovation in SDCLR is\nto create a dynamic self-competitor model to contrast with the target model,\nwhich is a pruned version of the latter. During training, contrasting the two\nmodels will lead to adaptive online mining of the most easily forgotten samples\nfor the current target model, and implicitly emphasize them more in the\ncontrastive loss. Extensive experiments across multiple datasets and imbalance\nsettings show that SDCLR significantly improves not only overall accuracies but\nalso balancedness, in terms of linear evaluation on the full-shot and few-shot\nsettings. Our code is available at: https://github.com/VITA-Group/SDCLR.",
          "link": "http://arxiv.org/abs/2106.02990",
          "publishedOn": "2021-06-08T02:20:21.693Z",
          "wordCount": 640,
          "title": "Self-Damaging Contrastive Learning. (arXiv:2106.02990v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1\">Thomas L. Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tward_D/0/1/0/all/0/1\">Daniel Tward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_U/0/1/0/all/0/1\">Ulrich Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1\">Michael I. Miller</a>",
          "description": "Recent advances in brain clearing and imaging have made it possible to image\nentire mammalian brains at sub-micron resolution. These images offer the\npotential to assemble brain-wide atlases of projection neuron morphology, but\nmanual neuron reconstruction remains a bottleneck. Here we present a method\ninspired by hidden Markov modeling and appearance modeling of fluorescent\nneuron images that can automatically trace neuronal processes. Our method\nleverages dynamic programming to scale to terabyte sized image data and can be\napplied to images with one or more neurons. We applied our algorithm to the\noutput of image segmentation models where false negatives severed neuronal\nprocesses, and showed that it can follow axons in the presence of noise or\nnearby neurons. Our method has the potential to be integrated into a semi or\nfully automated reconstruction pipeline. Additionally, it creates a framework\nthrough which users can intervene with hard constraints to, for example, rule\nout certain reconstructions, or assign axons to particular cell bodies.",
          "link": "http://arxiv.org/abs/2106.02701",
          "publishedOn": "2021-06-08T02:20:21.686Z",
          "wordCount": 604,
          "title": "Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction. (arXiv:2106.02701v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.00148",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rashid_T/0/1/0/all/0/1\">Tanweer Rashid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdulkadir_A/0/1/0/all/0/1\">Ahmed Abdulkadir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nasrallah_I/0/1/0/all/0/1\">Ilya M. Nasrallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ware_J/0/1/0/all/0/1\">Jeffrey B. Ware</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1\">Hangfan Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spincemaille_P/0/1/0/all/0/1\">Pascal Spincemaille</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Romero_J/0/1/0/all/0/1\">J. Rafael Romero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bryan_R/0/1/0/all/0/1\">R. Nick Bryan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heckbert_S/0/1/0/all/0/1\">Susan R. Heckbert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Habes_M/0/1/0/all/0/1\">Mohamad Habes</a>",
          "description": "Lobar cerebral microbleeds (CMBs) and localized non-hemorrhage iron deposits\nin the basal ganglia have been associated with brain aging, vascular disease\nand neurodegenerative disorders. Particularly, CMBs are small lesions and\nrequire multiple neuroimaging modalities for accurate detection. Quantitative\nsusceptibility mapping (QSM) derived from in vivo magnetic resonance imaging\n(MRI) is necessary to differentiate between iron content and mineralization. We\nset out to develop a deep learning-based segmentation method suitable for\nsegmenting both CMBs and iron deposits. We included a convenience sample of 24\nparticipants from the MESA cohort and used T2-weighted images, susceptibility\nweighted imaging (SWI), and QSM to segment the two types of lesions. We\ndeveloped a protocol for simultaneous manual annotation of CMBs and\nnon-hemorrhage iron deposits in the basal ganglia. This manual annotation was\nthen used to train a deep convolution neural network (CNN). Specifically, we\nadapted the U-Net model with a higher number of resolution layers to be able to\ndetect small lesions such as CMBs from standard resolution MRI. We tested\ndifferent combinations of the three modalities to determine the most\ninformative data sources for the detection tasks. In the detection of CMBs\nusing single class and multiclass models, we achieved an average sensitivity\nand precision of between 0.84-0.88 and 0.40-0.59, respectively. The same\nframework detected non-hemorrhage iron deposits with an average sensitivity and\nprecision of about 0.75-0.81 and 0.62-0.75, respectively. Our results showed\nthat deep learning could automate the detection of small vessel disease lesions\nand including multimodal MR data (particularly QSM) can improve the detection\nof CMB and non-hemorrhage iron deposits with sensitivity and precision that is\ncompatible with use in large-scale research studies.",
          "link": "http://arxiv.org/abs/2010.00148",
          "publishedOn": "2021-06-08T02:20:21.659Z",
          "wordCount": 768,
          "title": "DEEPMIR: A DEEP neural network for differential detection of cerebral Microbleeds and IRon deposits in MRI. (arXiv:2010.00148v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.11849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quach_K/0/1/0/all/0/1\">Kha Gia Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1\">Chi Nhan Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalata_I/0/1/0/all/0/1\">Ibsa Jalata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1\">Khoa Luu</a>",
          "description": "Group-level emotion recognition (ER) is a growing research area as the\ndemands for assessing crowds of all sizes are becoming an interest in both the\nsecurity arena as well as social media. This work extends the earlier ER\ninvestigations, which focused on either group-level ER on single images or\nwithin a video, by fully investigating group-level expression recognition on\ncrowd videos. In this paper, we propose an effective deep feature level fusion\nmechanism to model the spatial-temporal information in the crowd videos. In our\napproach, the fusing process is performed on the deep feature domain by a\ngenerative probabilistic model, Non-Volume Preserving Fusion (NVPF), that\nmodels spatial information relationships. Furthermore, we extend our proposed\nspatial NVPF approach to the spatial-temporal NVPF approach to learn the\ntemporal information between frames. To demonstrate the robustness and\neffectiveness of each component in the proposed approach, three experiments\nwere conducted: (i) evaluation on AffectNet database to benchmark the proposed\nEmoNet for recognizing facial expression; (ii) evaluation on EmotiW2018 to\nbenchmark the proposed deep feature level fusion mechanism NVPF; and, (iii)\nexamine the proposed TNVPF on an innovative Group-level Emotion on Crowd Videos\n(GECV) dataset composed of 627 videos collected from publicly available\nsources. GECV dataset is a collection of videos containing crowds of people.\nEach video is labeled with emotion categories at three levels: individual\nfaces, group of people, and the entire video frame.",
          "link": "http://arxiv.org/abs/1811.11849",
          "publishedOn": "2021-06-08T02:20:21.643Z",
          "wordCount": 719,
          "title": "Non-Volume Preserving-based Fusion to Group-Level Emotion Recognition on Crowd Videos. (arXiv:1811.11849v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1\">Liam Paull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Le Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.",
          "link": "http://arxiv.org/abs/2004.04690",
          "publishedOn": "2021-06-08T02:20:21.636Z",
          "wordCount": 685,
          "title": "Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.05123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1\">Roi Pony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1\">Itay Naeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.",
          "link": "http://arxiv.org/abs/2002.05123",
          "publishedOn": "2021-06-08T02:20:21.618Z",
          "wordCount": 651,
          "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaabane_M/0/1/0/all/0/1\">Mohamed Chaabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peter Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beveridge_J/0/1/0/all/0/1\">J. Ross Beveridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OHara_S/0/1/0/all/0/1\">Stephen O&#x27;Hara</a>",
          "description": "Most modern multiple object tracking (MOT) systems follow the\ntracking-by-detection paradigm, consisting of a detector followed by a method\nfor associating detections into tracks. There is a long history in tracking of\ncombining motion and appearance features to provide robustness to occlusions\nand other challenges, but typically this comes with the trade-off of a more\ncomplex and slower implementation. Recent successes on popular 2D tracking\nbenchmarks indicate that top-scores can be achieved using a state-of-the-art\ndetector and relatively simple associations relying on single-frame spatial\noffsets -- notably outperforming contemporary methods that leverage learned\nappearance features to help re-identify lost tracks. In this paper, we propose\nan efficient joint detection and tracking model named DEFT, or \"Detection\nEmbeddings for Tracking.\" Our approach relies on an appearance-based object\nmatching network jointly-learned with an underlying object detection network.\nAn LSTM is also added to capture motion constraints. DEFT has comparable\naccuracy and speed to the top methods on 2D online tracking leaderboards while\nhaving significant advantages in robustness when applied to more challenging\ntracking data. DEFT raises the bar on the nuScenes monocular 3D tracking\nchallenge, more than doubling the performance of the previous top method. Code\nis publicly available.",
          "link": "http://arxiv.org/abs/2102.02267",
          "publishedOn": "2021-06-08T02:20:21.611Z",
          "wordCount": 665,
          "title": "DEFT: Detection Embeddings for Tracking. (arXiv:2102.02267v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1\">Nianchang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jungong Han</a>",
          "description": "Most existing lightweight RGB-D salient object detection (SOD) models are\nbased on two-stream structure or single-stream structure. The former one first\nuses two sub-networks to extract unimodal features from RGB and depth images,\nrespectively, and then fuses them for SOD. While, the latter one directly\nextracts multi-modal features from the input RGB-D images and then focuses on\nexploiting cross-level complementary information. However, two-stream structure\nbased models inevitably require more parameters and single-stream structure\nbased ones cannot well exploit the cross-modal complementary information since\nthey ignore the modality difference. To address these issues, we propose to\nemploy the middle-level fusion structure for designing lightweight RGB-D SOD\nmodel in this paper, which first employs two sub-networks to extract low- and\nmiddle-level unimodal features, respectively, and then fuses those extracted\nmiddle-level unimodal features for extracting corresponding high-level\nmulti-modal features in the subsequent sub-network. Different from existing\nmodels, this structure can effectively exploit the cross-modal complementary\ninformation and significantly reduce the network's parameters, simultaneously.\nTherefore, a novel lightweight SOD model is designed, which contains a\ninformation-aware multi-modal feature fusion (IMFF) module for effectively\ncapturing the cross-modal complementary information and a lightweight\nfeature-level and decision-level feature fusion (LFDF) module for aggregating\nthe feature-level and the decision-level saliency information in different\nstages with less parameters. Our proposed model has only 3.9M parameters and\nruns at 33 FPS. The experimental results on several benchmark datasets verify\nthe effectiveness and superiority of the proposed method over some\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2104.11543",
          "publishedOn": "2021-06-08T02:20:21.601Z",
          "wordCount": 709,
          "title": "Middle-level Fusion for Lightweight RGB-D Salient Object Detection. (arXiv:2104.11543v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02669",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1\">Jafar Pourbemany</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1\">Almabrok Essa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Ye Zhu</a>",
          "description": "In recent years, research about monitoring vital signs by smartphones grows\nsignificantly. There are some special sensors like Electrocardiogram (ECG) and\nPhotoplethysmographic (PPG) to detect heart rate (HR) and respiration rate\n(RR). Smartphone cameras also can measure HR by detecting and processing\nimaging Photoplethysmographic (iPPG) signals from the video of a user's face.\nIndeed, the variation in the intensity of the green channel can be measured by\nthe iPPG signals of the video. This study aimed to provide a method to extract\nheart rate and respiration rate using the video of individuals' faces. The\nproposed method is based on measuring fluctuations in the Hue, and can\ntherefore extract both HR and RR from the video of a user's face. The proposed\nmethod is evaluated by performing on 25 healthy individuals. For each subject,\n20 seconds video of his/her face is recorded. Results show that the proposed\napproach of measuring iPPG using Hue gives more accurate rates than the Green\nchannel.",
          "link": "http://arxiv.org/abs/2106.02669",
          "publishedOn": "2021-06-08T02:20:21.593Z",
          "wordCount": 606,
          "title": "Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chun-Fu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1\">Quanfu Fan</a>",
          "description": "Vision transformer (ViT) has recently showed its strong capability in\nachieving comparable results to convolutional neural networks (CNNs) on image\nclassification. However, vanilla ViT simply inherits the same architecture from\nthe natural language processing directly, which is often not optimized for\nvision applications. Motivated by this, in this paper, we propose a new\narchitecture that adopts the pyramid structure and employ a novel\nregional-to-local attention rather than global self-attention in vision\ntransformers. More specifically, our model first generates regional tokens and\nlocal tokens from an image with different patch sizes, where each regional\ntoken is associated with a set of local tokens based on the spatial location.\nThe regional-to-local attention includes two steps: first, the regional\nself-attention extract global information among all regional tokens and then\nthe local self-attention exchanges the information among one regional token and\nthe associated local tokens via self-attention. Therefore, even though local\nself-attention confines the scope in a local region but it can still receive\nglobal information. Extensive experiments on three vision tasks, including\nimage classification, object detection and action recognition, show that our\napproach outperforms or is on par with state-of-the-art ViT variants including\nmany concurrent works. Our source codes and models will be publicly available.",
          "link": "http://arxiv.org/abs/2106.02689",
          "publishedOn": "2021-06-08T02:20:21.580Z",
          "wordCount": 628,
          "title": "RegionViT: Regional-to-Local Attention for Vision Transformers. (arXiv:2106.02689v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1\">Fartash Faghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1\">Sven Gowal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1\">Cristina Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1\">Fabian Pedregosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>",
          "description": "We demonstrate that the choice of optimizer, neural network architecture, and\nregularizer significantly affect the adversarial robustness of linear neural\nnetworks, providing guarantees without the need for adversarial training. To\nthis end, we revisit a known result linking maximally robust classifiers and\nminimum norm solutions, and combine it with recent results on the implicit bias\nof optimizers. First, we show that, under certain conditions, it is possible to\nachieve both perfect standard accuracy and a certain degree of robustness,\nsimply by training an overparametrized model using the implicit bias of the\noptimization. In that regime, there is a direct relationship between the type\nof the optimizer and the attack to which the model is robust. To the best of\nour knowledge, this work is the first to study the impact of optimization\nmethods such as sign gradient descent and proximal methods on adversarial\nrobustness. Second, we characterize the robustness of linear convolutional\nmodels, showing that they resist attacks subject to a constraint on the\nFourier-$\\ell_\\infty$ norm. To illustrate these findings we design a novel\nFourier-$\\ell_\\infty$ attack that finds adversarial examples with controllable\nfrequencies. We evaluate Fourier-$\\ell_\\infty$ robustness of\nadversarially-trained deep CIFAR-10 models from the standard RobustBench\nbenchmark and visualize adversarial perturbations.",
          "link": "http://arxiv.org/abs/2102.08868",
          "publishedOn": "2021-06-08T02:20:21.553Z",
          "wordCount": 685,
          "title": "Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.08107",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_R/0/1/0/all/0/1\">Ruxin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Shuyuan Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1\">Chaojie Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Ye Li</a>",
          "description": "Skin lesion segmentation is an important step for automatic melanoma\ndiagnosis. Due to the non-negligible diversity of lesions from different\npatients, extracting powerful context for fine-grained semantic segmentation is\nstill challenging today. Although the deep convolutional neural network (CNNs)\nhave made significant improvements on skin lesion segmentation, they often fail\nto reserve the spatial details and long-range dependencies context due to\nconsecutive convolution striding and pooling operations inside CNNs. In this\npaper, we formulate a cascaded context enhancement neural network for automatic\nskin lesion segmentation. A new cascaded context aggregation (CCA) module with\na gate-based information integration approach is proposed to sequentially and\nselectively aggregate original image and multi-level features from the encoder\nsub-network. The generated context is further utilized to guide discriminative\nfeatures extraction by the designed context-guided local affinity (CGL) module.\nFurthermore, an auxiliary loss is added to the CCA module for refining the\nprediction. In our work, we evaluate our approach on four public skin\ndermoscopy image datasets. The proposed method achieves the Jaccard Index (JA)\nof 87.1%, 80.3%, 83.4%, and 86.6% on ISIC-2016, ISIC-2017, ISIC-2018, and PH2\ndatasets, which are higher than other state-of-the-art models respectively.",
          "link": "http://arxiv.org/abs/2004.08107",
          "publishedOn": "2021-06-08T02:20:21.547Z",
          "wordCount": 657,
          "title": "Cascaded Context Enhancement Network for Automatic Skin Lesion Segmentation. (arXiv:2004.08107v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Real-world data inevitably contains noisy labels, which induce the poor\ngeneralization of deep neural networks. It is known that the network typically\nbegins to rapidly memorize false-labeled samples after a certain point of\ntraining. Thus, to counter the label noise challenge, we propose a novel\nself-transitional learning method called MORPH, which automatically switches\nits learning phase at the transition point from seeding to evolution. In the\nseeding phase, the network is updated using all the samples to collect a seed\nof clean samples. Then, in the evolution phase, the network is updated using\nonly the set of arguably clean samples, which precisely keeps expanding by the\nupdated network. Thus, MORPH effectively avoids the overfitting to\nfalse-labeled samples throughout the entire training period. Extensive\nexperiments using five real-world or synthetic benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods in terms of robustness\nand efficiency.",
          "link": "http://arxiv.org/abs/2012.04337",
          "publishedOn": "2021-06-08T02:20:21.531Z",
          "wordCount": 614,
          "title": "Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.13671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chaoyue Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yugang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shulai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "In this work, we use facial landmarks to make the deformation for facial\nimages more authentic. The deformation includes the expansion of eyes and the\nshrinking of noses, mouths, and cheeks. An advanced 106-point facial landmark\ndetector is utilized to provide control points for deformation. Bilinear\ninterpolation is used in the expansion and Moving Least Squares methods (MLS)\nincluding Affine Deformation, Similarity Deformation and Rigid Deformation are\nused in the shrinking. We compare the running time as well as the quality of\ndeformed images using different MLS methods. The experimental results show that\nthe Rigid Deformation which can keep other parts of the images unchanged\nperforms better even if it takes the longest time.",
          "link": "http://arxiv.org/abs/1910.13671",
          "publishedOn": "2021-06-08T02:20:21.524Z",
          "wordCount": 575,
          "title": "Facial Image Deformation Based on Landmark Detection. (arXiv:1910.13671v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wentao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>",
          "description": "Estimating 3D mesh of the human body from a single 2D image is an important\ntask with many applications such as augmented reality and Human-Robot\ninteraction. However, prior works reconstructed 3D mesh from global image\nfeature extracted by using convolutional neural network (CNN), where the dense\ncorrespondences between the mesh surface and the image pixels are missing,\nleading to suboptimal solution. This paper proposes a model-free 3D human mesh\nestimation framework, named DecoMR, which explicitly establishes the dense\ncorrespondence between the mesh and the local image features in the UV space\n(i.e. a 2D space used for texture mapping of 3D mesh). DecoMR first predicts\npixel-to-surface dense correspondence map (i.e., IUV image), with which we\ntransfer local features from the image space to the UV space. Then the\ntransferred local image features are processed in the UV space to regress a\nlocation map, which is well aligned with transferred features. Finally we\nreconstruct 3D human mesh from the regressed location map with a predefined\nmapping function. We also observe that the existing discontinuous UV map are\nunfriendly to the learning of network. Therefore, we propose a novel UV map\nthat maintains most of the neighboring relations on the original mesh surface.\nExperiments demonstrate that our proposed local feature alignment and\ncontinuous UV map outperforms existing 3D mesh based methods on multiple public\nbenchmarks. Code will be made available at\nhttps://github.com/zengwang430521/DecoMR",
          "link": "http://arxiv.org/abs/2006.05734",
          "publishedOn": "2021-06-08T02:20:21.516Z",
          "wordCount": 697,
          "title": "3D Human Mesh Regression with Dense Correspondence. (arXiv:2006.05734v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hengbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "An effective understanding of the contextual environment and accurate motion\nforecasting of surrounding agents is crucial for the development of autonomous\nvehicles and social mobile robots. This task is challenging since the behavior\nof an autonomous agent is not only affected by its own intention, but also by\nthe static environment and surrounding dynamically interacting agents. Previous\nworks focused on utilizing the spatial and temporal information in time domain\nwhile not sufficiently taking advantage of the cues in frequency domain. To\nthis end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which\ncan capture inter-agent correlations and temporal dependency simultaneously in\nfrequency domain in addition to time domain. SpecTGNN operates on both an agent\ngraph with dynamic state information and an environment graph with the features\nextracted from context images in two streams. The model integrates graph\nFourier transform, spectral graph convolution and temporal gated convolution to\nencode history information and forecast future trajectories. Moreover, we\nincorporate a multi-head spatio-temporal attention mechanism to mitigate the\neffect of error propagation in a long time horizon. We demonstrate the\nperformance of SpecTGNN on two public trajectory prediction benchmark datasets,\nwhich achieves state-of-the-art performance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.02930",
          "publishedOn": "2021-06-08T02:20:21.508Z",
          "wordCount": 641,
          "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Hyung Jin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jinming Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Linlin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1\">Ales Leonardis</a>",
          "description": "In this paper, we focus on category-level 6D pose and size estimation from\nmonocular RGB-D image. Previous methods suffer from inefficient category-level\npose feature extraction which leads to low accuracy and inference speed. To\ntackle this problem, we propose a fast shape-based network (FS-Net) with\nefficient category-level feature extraction for 6D pose estimation. First, we\ndesign an orientation aware autoencoder with 3D graph convolution for latent\nfeature extraction. The learned latent feature is insensitive to point shift\nand object size thanks to the shift and scale-invariance properties of the 3D\ngraph convolution. Then, to efficiently decode category-level rotation\ninformation from the latent feature, we propose a novel decoupled rotation\nmechanism that employs two decoders to complementarily access the rotation\ninformation. Meanwhile, we estimate translation and size by two residuals,\nwhich are the difference between the mean of object points and ground truth\ntranslation, and the difference between the mean size of the category and\nground truth size, respectively. Finally, to increase the generalization\nability of FS-Net, we propose an online box-cage based 3D deformation mechanism\nto augment the training data. Extensive experiments on two benchmark datasets\nshow that the proposed method achieves state-of-the-art performance in both\ncategory- and instance-level 6D object pose estimation. Especially in\ncategory-level pose estimation, without extra synthetic data, our method\noutperforms existing methods by 6.3% on the NOCS-REAL dataset.",
          "link": "http://arxiv.org/abs/2103.07054",
          "publishedOn": "2021-06-08T02:20:21.501Z",
          "wordCount": 707,
          "title": "FS-Net: Fast Shape-based Network for Category-Level 6D Object Pose Estimation with Decoupled Rotation Mechanism. (arXiv:2103.07054v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yingxia Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1\">Yu-Cheng Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shouyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>",
          "description": "Owing to the difficulties of mining spatial-temporal cues, the existing\napproaches for video salient object detection (VSOD) are limited in\nunderstanding complex and noisy scenarios, and often fail in inferring\nprominent objects. To alleviate such shortcomings, we propose a simple yet\nefficient architecture, termed Guidance and Teaching Network (GTNet), to\nindependently distil effective spatial and temporal cues with implicit guidance\nand explicit teaching at feature- and decision-level, respectively. To be\nspecific, we (a) introduce a temporal modulator to implicitly bridge features\nfrom motion into the appearance branch, which is capable of fusing cross-modal\nfeatures collaboratively, and (b) utilise motion-guided mask to propagate the\nexplicit cues during the feature aggregation. This novel learning strategy\nachieves satisfactory results via decoupling the complex spatial-temporal cues\nand mapping informative cues across different modalities. Extensive experiments\non three challenging benchmarks show that the proposed method can run at ~28\nfps on a single TITAN Xp GPU and perform competitively against 14 cutting-edge\nbaselines.",
          "link": "http://arxiv.org/abs/2105.10110",
          "publishedOn": "2021-06-08T02:20:21.494Z",
          "wordCount": 639,
          "title": "Guidance and Teaching Network for Video Salient Object Detection. (arXiv:2105.10110v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03244",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Saha_A/0/1/0/all/0/1\">Anindo Saha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hosseinzadeh_M/0/1/0/all/0/1\">Matin Hosseinzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>",
          "description": "We present a multi-stage 3D computer-aided detection and diagnosis (CAD)\nmodel for automated localization of clinically significant prostate cancer\n(csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive\nits detection network, targeting salient structures and highly discriminative\nfeature dimensions across multiple resolutions. Its goal is to accurately\nidentify csPCa lesions from indolent cancer and the wide range of benign\npathology that can afflict the prostate gland. Simultaneously, a decoupled\nresidual classifier is used to achieve consistent false positive reduction,\nwithout sacrificing high sensitivity or computational efficiency. In order to\nguide model generalization with domain-specific clinical knowledge, a\nprobabilistic anatomical prior is used to encode the spatial prevalence and\nzonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired\nwith radiologically-estimated annotations, we hypothesize that such CNN-based\nmodels can be trained to detect biopsy-confirmed malignancies in an independent\ncohort.\n\nFor 486 institutional testing scans, the 3D CAD system achieves\n83.69$\\pm$5.22% and 93.19$\\pm$2.96% detection sensitivity at 0.50 and 1.46\nfalse positive(s) per patient, respectively, with 0.882$\\pm$0.030 AUROC in\npatient-based diagnosis $-$significantly outperforming four state-of-the-art\nbaseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from\nrecent literature. For 296 external biopsy-confirmed testing scans, the\nensembled CAD system shares moderate agreement with a consensus of expert\nradiologists (76.69%; $kappa$ $=$ 0.51$\\pm$0.04) and independent pathologists\n(81.08%; $kappa$ $=$ 0.56$\\pm$0.06); demonstrating strong generalization to\nhistologically-confirmed csPCa diagnosis.",
          "link": "http://arxiv.org/abs/2101.03244",
          "publishedOn": "2021-06-08T02:20:21.487Z",
          "wordCount": 777,
          "title": "End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction. (arXiv:2101.03244v8 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Peng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lingyun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianmin Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1\">Howie Choset</a>",
          "description": "One of the main obstacles to 3D semantic segmentation is the significant\namount of endeavor required to generate expensive point-wise annotations for\nfully supervised training. To alleviate manual efforts, we propose GIDSeg, a\nnovel approach that can simultaneously learn segmentation from sparse\nannotations via reasoning global-regional structures and individual-vicinal\nproperties. GIDSeg depicts global- and individual- relation via a dynamic edge\nconvolution network coupled with a kernelized identity descriptor. The ensemble\neffects are obtained by endowing a fine-grained receptive field to a\nlow-resolution voxelized map. In our GIDSeg, an adversarial learning module is\nalso designed to further enhance the conditional constraint of identity\ndescriptors within the joint feature distribution. Despite the apparent\nsimplicity, our proposed approach achieves superior performance over\nstate-of-the-art for inferencing 3D dense segmentation with only sparse\nannotations. Particularly, with $5\\%$ annotations of raw data, GIDSeg\noutperforms other 3D segmentation methods.",
          "link": "http://arxiv.org/abs/2105.12885",
          "publishedOn": "2021-06-08T02:20:21.471Z",
          "wordCount": 619,
          "title": "3D Segmentation Learning from Sparse Annotations and Hierarchical Descriptors. (arXiv:2105.12885v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08115",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1\">P. Nagabhushan</a>",
          "description": "The infection of respiratory coronavirus disease 2019 (COVID-19) starts with\nthe upper respiratory tract and as the virus grows, the infection can progress\nto lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is\nreverse transcription polymerase chain reaction (RT-PCR), which is less\nsensitive during early stages; especially if the patient is asymptomatic, which\nmay further cause more severe pneumonia. In this context, several deep learning\nmodels have been proposed to identify pulmonary infections using publicly\navailable chest X-ray (CXR) image datasets for early diagnosis, better\ntreatment and quick cure. In these datasets, presence of less number of\nCOVID-19 positive samples compared to other classes (normal, pneumonia and\nTuberculosis) raises the challenge for unbiased learning of deep learning\nmodels. All deep learning models opted class balancing techniques to solve this\nissue; which however should be avoided in any medical diagnosis process.\nMoreover, the deep learning models are also data hungry and need massive\ncomputation resources. Therefore for quicker diagnosis, this research proposes\na novel pinball loss function based one-class support vector machine\n(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples\nwith objectives to maximize the learning efficiency and to minimize the false\npredictions. The performance of the proposed model is compared with\nconventional OCSVM and existing deep learning models, and the experimental\nresults prove that the proposed model outperformed over state-of-the-art\nmethods. To validate the robustness of the proposed model, experiments are also\nperformed with noisy CXR images and UCI benchmark datasets.",
          "link": "http://arxiv.org/abs/2010.08115",
          "publishedOn": "2021-06-08T02:20:21.444Z",
          "wordCount": 759,
          "title": "Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1\">Armin Hadzic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Neil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Phil Burlina</a>",
          "description": "We propose a novel method for enforcing AI fairness with respect to protected\nor sensitive factors. This method uses a dual strategy performing training and\nrepresentation alteration (TARA) for the mitigation of prominent causes of AI\nbias by including: a) the use of representation learning alteration via\nadversarial independence to suppress the bias-inducing dependence of the data\nrepresentation from protected factors; and b) training set alteration via\nintelligent augmentation to address bias-causing data imbalance, by using\ngenerative models that allow the fine control of sensitive factors related to\nunderrepresented populations via domain adaptation and latent space\nmanipulation. When testing our methods on image analytics, experiments\ndemonstrate that TARA significantly or fully debiases baseline models while\noutperforming competing debiasing methods that have the same amount of\ninformation, e.g., with (% overall accuracy, % accuracy gap) = (78.8, 0.5) vs.\nthe baseline method's score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.\n(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in\ncurrent metrics used for assessing debiasing performance, we propose novel\nconjunctive debiasing metrics. Our experiments also demonstrate the ability of\nthese novel metrics in assessing the Pareto efficiency of the proposed methods.",
          "link": "http://arxiv.org/abs/2012.06387",
          "publishedOn": "2021-06-08T02:20:21.419Z",
          "wordCount": 675,
          "title": "TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Suvidha Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwee Kuan Lee</a>",
          "description": "Researchers working on computational analysis of Whole Slide Images (WSIs) in\nhistopathology have primarily resorted to patch-based modelling due to large\nresolution of each WSI. The large resolution makes WSIs infeasible to be fed\ndirectly into the machine learning models due to computational constraints.\nHowever, due to patch-based analysis, most of the current methods fail to\nexploit the underlying spatial relationship among the patches. In our work, we\nhave tried to integrate this relationship along with feature-based correlation\namong the extracted patches from the particular tumorous region. For the given\ntask of classification, we have used BiLSTMs to model both forward and backward\ncontextual relationship. RNN based models eliminate the limitation of sequence\nsize by allowing the modelling of variable size images within a deep learning\nmodel. We have also incorporated the effect of spatial continuity by exploring\ndifferent scanning techniques used to sample patches. To establish the\nefficiency of our approach, we trained and tested our model on two datasets,\nmicroscopy images and WSI tumour regions. After comparing with contemporary\nliterature we achieved the better performance with accuracy of 90% for\nmicroscopy image dataset. For WSI tumour region dataset, we compared the\nclassification results with deep learning networks such as ResNet, DenseNet,\nand InceptionV3 using maximum voting technique. We achieved the highest\nperformance accuracy of 84%. We found out that BiLSTMs with CNN features have\nperformed much better in modelling patches into an end-to-end Image\nclassification network. Additionally, the variable dimensions of WSI tumour\nregions were used for classification without the need for resizing. This\nsuggests that our method is independent of tumour image size and can process\nlarge dimensional images without losing the resolution details.",
          "link": "http://arxiv.org/abs/2106.02864",
          "publishedOn": "2021-06-08T02:20:21.393Z",
          "wordCount": 757,
          "title": "An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.03417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1\">Osman Aka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1\">Ken Burke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1\">Alex B&#xe4;uerle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1\">Christina Greer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Margaret Mitchell</a>",
          "description": "The measurement of bias in machine learning often focuses on model\nperformance across identity subgroups (such as man and woman) with respect to\ngroundtruth labels. However, these methods do not directly measure the\nassociations that a model may have learned, for example between labels and\nidentity subgroups. Further, measuring a model's bias requires a fully\nannotated evaluation dataset which may not be easily available in practice. We\npresent an elegant mathematical solution that tackles both issues\nsimultaneously, using image classification as a working example. By treating a\nclassification model's predictions for a given image as a set of labels\nanalogous to a bag of words, we rank the biases that a model has learned with\nrespect to different identity labels. We use (man, woman) as a concrete example\nof an identity label set (although this set need not be binary), and present\nrankings for the labels that are most biased towards one identity or the other.\nWe demonstrate how the statistical properties of different association metrics\ncan lead to different rankings of the most \"gender biased\" labels, and conclude\nthat normalized pointwise mutual information (nPMI) is most useful in practice.\nFinally, we announce an open-sourced nPMI visualization tool using TensorBoard.",
          "link": "http://arxiv.org/abs/2103.03417",
          "publishedOn": "2021-06-08T02:20:21.386Z",
          "wordCount": 675,
          "title": "Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1\">Dina Bashkirova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Ziliang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akl_J/0/1/0/all/0/1\">James Akl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alladkani_F/0/1/0/all/0/1\">Fadi Alladkani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ablavsky_V/0/1/0/all/0/1\">Vitaly Ablavsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calli_B/0/1/0/all/0/1\">Berk Calli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1\">Sarah Adel Bargal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Less than 35% of recyclable waste is being actually recycled in the US, which\nleads to increased soil and sea pollution and is one of the major concerns of\nenvironmental researchers as well as the common public. At the heart of the\nproblem is the inefficiencies of the waste sorting process (separating paper,\nplastic, metal, glass, etc.) due to the extremely complex and cluttered nature\nof the waste stream. Automated waste detection strategies have a great\npotential to enable more efficient, reliable and safer waste sorting practices,\nbut the literature lacks comprehensive datasets and methodology for the\nindustrial waste sorting solutions. In this paper, we take a step towards\ncomputer-aided waste detection and present the first in-the-wild\nindustrial-grade waste detection and segmentation dataset, ZeroWaste. This\ndataset contains over1800fully segmented video frames collected from a real\nwaste sorting plant along with waste material labels for training and\nevaluation of the segmentation methods, as well as over6000unlabeled frames\nthat can be further used for semi-supervised and self-supervised learning\ntechniques. ZeroWaste also provides frames of the conveyor belt before and\nafter the sorting process, comprising a novel setup that can be used for\nweakly-supervised segmentation. We present baselines for fully-, semi- and\nweakly-supervised segmentation methods. Our experimental results demonstrate\nthat state-of-the-art segmentation methods struggle to correctly detect and\nclassify target objects which suggests the challenging nature of our proposed\nin-the-wild dataset. We believe that ZeroWastewill catalyze research in object\ndetection and semantic segmentation in extreme clutter as well as applications\nin the recycling domain. Our project page can be found\natthis http URL",
          "link": "http://arxiv.org/abs/2106.02740",
          "publishedOn": "2021-06-08T02:20:21.296Z",
          "wordCount": 697,
          "title": "ZeroWaste Dataset: Towards Automated Waste Recycling. (arXiv:2106.02740v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Unsupervised domain adaptation (UDA) involves a supervised loss in a labeled\nsource domain and an unsupervised loss in an unlabeled target domain, which\noften faces more severe overfitting (than classical supervised learning) as the\nsupervised source loss has clear domain gap and the unsupervised target loss is\noften noisy due to the lack of annotations. This paper presents RDA, a robust\ndomain adaptation technique that introduces adversarial attacking to mitigate\noverfitting in UDA. We achieve robust domain adaptation by a novel Fourier\nadversarial attacking (FAA) method that allows large magnitude of perturbation\nnoises but has minimal modification of image semantics, the former is critical\nto the effectiveness of its generated adversarial samples due to the existence\nof 'domain gaps'. Specifically, FAA decomposes images into multiple frequency\ncomponents (FCs) and generates adversarial samples by just perturbating certain\nFCs that capture little semantic information. With FAA-generated samples, the\ntraining can continue the 'random walk' and drift into an area with a flat loss\nlandscape, leading to more robust domain adaptation. Extensive experiments over\nmultiple domain adaptation tasks show that RDA can work with different computer\nvision tasks with superior performance.",
          "link": "http://arxiv.org/abs/2106.02874",
          "publishedOn": "2021-06-08T02:20:21.234Z",
          "wordCount": 618,
          "title": "RDA: Robust Domain Adaptation via Fourier Adversarial Attacking. (arXiv:2106.02874v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yunfei Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1\">Daniel Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_M/0/1/0/all/0/1\">Marcos Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarty_P/0/1/0/all/0/1\">Punarjay Chakravarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1\">Praveen Narayanan</a>",
          "description": "While radar and video data can be readily fused at the detection level,\nfusing them at the pixel level is potentially more beneficial. This is also\nmore challenging in part due to the sparsity of radar, but also because\nautomotive radar beams are much wider than a typical pixel combined with a\nlarge baseline between camera and radar, which results in poor association\nbetween radar pixels and color pixel. A consequence is that depth completion\nmethods designed for LiDAR and video fare poorly for radar and video. Here we\npropose a radar-to-pixel association stage which learns a mapping from radar\nreturns to pixels. This mapping also serves to densify radar returns. Using\nthis as a first stage, followed by a more traditional depth completion method,\nwe are able to achieve image-guided depth completion with radar and video. We\ndemonstrate performance superior to camera and radar alone on the nuScenes\ndataset. Our source code is available at https://github.com/longyunf/rc-pda.",
          "link": "http://arxiv.org/abs/2106.02778",
          "publishedOn": "2021-06-08T02:20:21.190Z",
          "wordCount": 601,
          "title": "Radar-Camera Pixel Depth Association for Depth Completion. (arXiv:2106.02778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Contemporary domain adaptive semantic segmentation aims to address data\nannotation challenges by assuming that target domains are completely\nunannotated. However, annotating a few target samples is usually very\nmanageable and worthwhile especially if it improves the adaptation performance\nsubstantially. This paper presents SSDAS, a Semi-Supervised Domain Adaptive\nimage Segmentation network that employs a few labeled target samples as anchors\nfor adaptive and progressive feature alignment between labeled source samples\nand unlabeled target samples. We position the few labeled target samples as\nreferences that gauge the similarity between source and target features and\nguide adaptive inter-domain alignment for learning more similar source\nfeatures. In addition, we replace the dissimilar source features by\nhigh-confidence target features continuously during the iterative training\nprocess, which achieves progressive intra-domain alignment between confident\nand unconfident target features. Extensive experiments show the proposed SSDAS\ngreatly outperforms a number of baselines, i.e., UDA-based semantic\nsegmentation and SSDA-based image classification. In addition, SSDAS is\ncomplementary and can be easily incorporated into UDA-based methods with\nconsistent improvements in domain adaptive semantic segmentation.",
          "link": "http://arxiv.org/abs/2106.02845",
          "publishedOn": "2021-06-08T02:20:21.174Z",
          "wordCount": 604,
          "title": "Semi-Supervised Domain Adaptation via Adaptive and Progressive Feature Alignment. (arXiv:2106.02845v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shaozuo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>",
          "description": "In this paper, we propose a generic model transfer scheme to make\nConvlutional Neural Networks (CNNs) interpretable, while maintaining their high\nclassification accuracy. We achieve this by building a differentiable decision\nforest on top of CNNs, which enjoys two characteristics: 1) During training,\nthe tree hierarchies of the forest are learned in a top-down manner under the\nguidance from the category semantics embedded in the pre-trained CNN weights;\n2) During inference, a single decision tree is dynamically selected from the\nforest for each input sample, enabling the transferred model to make sequential\ndecisions corresponding to the attributes shared by semantically-similar\ncategories, rather than directly performing flat classification. We name the\ntransferred model deep Dynamic Sequential Decision Forest (dDSDF). Experimental\nresults show that dDSDF not only achieves higher classification accuracy than\nits conuterpart, i.e., the original CNN, but has much better interpretability,\nas qualitatively it has plausible hierarchies and quantitatively it leads to\nmore precise saliency maps.",
          "link": "http://arxiv.org/abs/2106.02824",
          "publishedOn": "2021-06-08T02:20:21.130Z",
          "wordCount": 596,
          "title": "Making CNNs Interpretable by Building Dynamic Sequential Decision Forests with Top-down Hierarchy Learning. (arXiv:2106.02824v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1\">Wamiq Reyaz Para</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1\">Tom Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "Computer-aided design (CAD) is the most widely used modeling approach for\ntechnical design. The typical starting point in these designs is 2D sketches\nwhich can later be extruded and combined to obtain complex three-dimensional\nassemblies. Such sketches are typically composed of parametric primitives, such\nas points, lines, and circular arcs, augmented with geometric constraints\nlinking the primitives, such as coincidence, parallelism, or orthogonality.\nSketches can be represented as graphs, with the primitives as nodes and the\nconstraints as edges. Training a model to automatically generate CAD sketches\ncan enable several novel workflows, but is challenging due to the complexity of\nthe graphs and the heterogeneity of the primitives and constraints. In\nparticular, each type of primitive and constraint may require a record of\ndifferent size and parameter types. We propose SketchGen as a generative model\nbased on a transformer architecture to address the heterogeneity problem by\ncarefully designing a sequential language for the primitives and constraints\nthat allows distinguishing between different primitive or constraint types and\ntheir parameters, while encouraging our model to re-use information across\nrelated parameters, encoding shared structure. A particular highlight of our\nwork is the ability to produce primitives linked via constraints that enables\nthe final output to be further regularized via a constraint solver. We evaluate\nour model by demonstrating constraint prediction for given sets of primitives\nand full sketch generation from scratch, showing that our approach\nsignificantly out performs the state-of-the-art in CAD sketch generation.",
          "link": "http://arxiv.org/abs/2106.02711",
          "publishedOn": "2021-06-08T02:20:21.086Z",
          "wordCount": 688,
          "title": "SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciampi_L/0/1/0/all/0/1\">Luca Ciampi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1\">Claudio Gennaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrara_F/0/1/0/all/0/1\">Fabio Carrara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falchi_F/0/1/0/all/0/1\">Fabrizio Falchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairo_C/0/1/0/all/0/1\">Claudio Vairo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_G/0/1/0/all/0/1\">Giuseppe Amato</a>",
          "description": "This paper presents a novel solution to automatically count vehicles in a\nparking lot using images captured by smart cameras. Unlike most of the\nliterature on this task, which focuses on the analysis of single images, this\npaper proposes the use of multiple visual sources to monitor a wider parking\narea from different perspectives. The proposed multi-camera system is capable\nof automatically estimate the number of cars present in the entire parking lot\ndirectly on board the edge devices. It comprises an on-device deep\nlearning-based detector that locates and counts the vehicles from the captured\nimages and a decentralized geometric-based approach that can analyze the\ninter-camera shared areas and merge the data acquired by all the devices. We\nconduct the experimental evaluation on an extended version of the CNRPark-EXT\ndataset, a collection of images taken from the parking lot on the campus of the\nNational Research Council (CNR) in Pisa, Italy. We show that our system is\nrobust and takes advantage of the redundant information deriving from the\ndifferent cameras, improving the overall performance without requiring any\nextra geometrical information of the monitored scene.",
          "link": "http://arxiv.org/abs/2106.02842",
          "publishedOn": "2021-06-08T02:20:21.079Z",
          "wordCount": 618,
          "title": "Multi-Camera Vehicle Counting Using Edge-AI. (arXiv:2106.02842v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1\">Ivan Sosnovik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moskalev_A/0/1/0/all/0/1\">Artem Moskalev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1\">Arnold Smeulders</a>",
          "description": "Scale is often seen as a given, disturbing factor in many vision tasks. When\ndoing so it is one of the factors why we need more data during learning. In\nrecent work scale equivariance was added to convolutional neural networks. It\nwas shown to be effective for a range of tasks. We aim for accurate\nscale-equivariant convolutional neural networks (SE-CNNs) applicable for\nproblems where high granularity of scale and small filter sizes are required.\nCurrent SE-CNNs rely on weight sharing and filter rescaling, the latter of\nwhich is accurate for integer scales only. To reach accurate scale\nequivariance, we derive general constraints under which scale-convolution\nremains equivariant to discrete rescaling. We find the exact solution for all\ncases where it exists, and compute the approximation for the rest. The discrete\nscale-convolution pays off, as demonstrated in a new state-of-the-art\nclassification on MNIST-scale and improving the results on STL-10. With the\nsame SE scheme, we also improve the computational effort of a scale-equivariant\nSiamese tracker on OTB-13.",
          "link": "http://arxiv.org/abs/2106.02733",
          "publishedOn": "2021-06-08T02:20:21.069Z",
          "wordCount": 588,
          "title": "DISCO: accurate Discrete Scale Convolutions. (arXiv:2106.02733v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhenfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1\">Lianbing Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Tao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiqian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xianwei Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1\">Qing Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiqiang Wang</a>",
          "description": "In this paper, we introduce a challenging global large-scale ship database\n(called GLSD), designed specifically for ship detection tasks. The designed\nGLSD database includes a total of 140,616 annotated instances from 100,729\nimages. Based on the collected images, we propose 13 categories that widely\nexists in international routes. These categories include sailing boat, fishing\nboat, passenger ship, war ship, general cargo ship, container ship, bulk cargo\ncarrier, barge, ore carrier, speed boat, canoe, oil carrier, and tug. The\nmotivations of developing GLSD include the following: 1) providing a refined\nship detection database; 2) providing the worldwide researchers of ship\ndetection and exhaustive label information (bounding box and ship class label)\nin one uniform global database; and 3) providing a large-scale ship database\nwith geographic information (port and country information) that benefits\nmulti-modal analysis. In addition, we discuss the evaluation protocols given\nimage characteristics in GLSD and analyze the performance of selected\nstate-of-the-art object detection algorithms on GSLD, providing baselines for\nfuture studies. More information regarding the designed GLSD can be found at\nhttps://github.com/jiaming-wang/GLSD.",
          "link": "http://arxiv.org/abs/2106.02773",
          "publishedOn": "2021-06-08T02:20:21.051Z",
          "wordCount": 621,
          "title": "GLSD: The Global Large-Scale Ship Database and Baseline Evaluations. (arXiv:2106.02773v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shubin_D/0/1/0/all/0/1\">Dmitrii Shubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eytan_D/0/1/0/all/0/1\">Danny Eytan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodfellow_S/0/1/0/all/0/1\">Sebastian D. Goodfellow</a>",
          "description": "Self-supervised learning methods for computer vision have demonstrated the\neffectiveness of pre-training feature representations, resulting in\nwell-generalizing Deep Neural Networks, even if the annotated data are limited.\nHowever, representation learning techniques require a significant amount of\ntime for model training, with most of it time spent on precise hyper-parameter\noptimization and selection of augmentation techniques. We hypothesized that if\nthe annotated dataset has enough morphological diversity to capture the general\npopulation's as is common in medical imaging, for example, due to conserved\nsimilarities of tissue mythologies, the variance error of the trained model is\nthe prevalent component of the Bias-Variance Trade-off. We propose the Variance\nAware Training (VAT) method that exploits this property by introducing the\nvariance error into the model loss function, i.e., enabling minimizing the\nvariance explicitly. Additionally, we provide the theoretical formulation and\nproof of the proposed method to aid in interpreting the approach. Our method\nrequires selecting only one hyper-parameter and was able to match or improve\nthe state-of-the-art performance of self-supervised methods while achieving an\norder of magnitude reduction in the GPU training time. We validated VAT on\nthree medical imaging datasets from diverse domains and various learning\nobjectives. These included a Magnetic Resonance Imaging (MRI) dataset for the\nheart semantic segmentation (MICCAI 2017 ACDC challenge), fundus photography\ndataset for ordinary regression of diabetic retinopathy progression (Kaggle\n2019 APTOS Blindness Detection challenge), and classification of\nhistopathologic scans of lymph node sections (PatchCamelyon dataset).",
          "link": "http://arxiv.org/abs/2105.14117",
          "publishedOn": "2021-06-07T23:29:40.150Z",
          "wordCount": 702,
          "title": "About Explicit Variance Minimization: Training Neural Networks for Medical Imaging With Limited Data Annotations. (arXiv:2105.14117v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pelosin_F/0/1/0/all/0/1\">Francesco Pelosin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torsello_A/0/1/0/all/0/1\">Andrea Torsello</a>",
          "description": "The design of machines and algorithms capable of learning in a dynamically\nchanging environment has become an increasingly topical problem with the\nincrease of the size and heterogeneity of data available to learning systems.\nAs a consequence, the key issue of Continual Learning has become that of\naddressing the stability-plasticity dilemma of connectionist systems, as they\nneed to adapt their model without forgetting previously acquired knowledge.\nWithin this context, rehearsal-based methods i.e., solutions in where the\nlearner exploits memory to revisit past data, has proven to be very effective,\nleading to performance at the state-of-the-art. In our study, we propose an\nanalysis of the memory quantity/quality trade-off adopting various data\nreduction approaches to increase the number of instances storable in memory. In\nparticular, we investigate complex instance compression techniques such as deep\nencoders, but also trivial approaches such as image resizing and linear\ndimensionality reduction. Our findings suggest that the optimal trade-off is\nseverely skewed toward instance quantity, where rehearsal approaches with\nseveral heavily compressed instances easily outperform state-of-the-art\napproaches with the same amount of memory at their disposal. Further, in high\nmemory configurations, deep approaches extracting spatial structure combined\nwith extreme resizing (of the order of $8\\times8$ images) yield the best\nresults, while in memory-constrained configurations where deep approaches\ncannot be used due to their memory requirement in training, Extreme Learning\nMachines (ELM) offer a clear advantage.",
          "link": "http://arxiv.org/abs/2105.14106",
          "publishedOn": "2021-06-07T23:29:40.127Z",
          "wordCount": 680,
          "title": "More Is Better: An Analysis of Instance Quantity/Quality Trade-off in Rehearsal-based Continual Learning. (arXiv:2105.14106v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhipeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaojiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baigui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "Face recognition has achieved significant progress in deep-learning era due\nto the ultra-large-scale and well-labeled datasets.\n\nHowever, training on ultra-large-scale datasets is time-consuming and takes\nup a lot of hardware resource.\n\nTherefore, designing an efficient training approach is crucial and\nindispensable.\n\nThe heavy computational and memory costs mainly result from the high\ndimensionality of the Fully-Connected (FC) layer.\n\nSpecifically, the dimensionality is determined by the number of face\nidentities, which can be million-level or even more.\n\nTo this end, we propose a novel training approach for ultra-large-scale face\ndatasets, termed Faster Face Classification (F$^2$C).\n\nIn F$^2$C, we first define a Gallery Net and a Probe Net that are used to\ngenerate identities' centers and extract faces' features for face recognition,\nrespectively.\n\nGallery Net has the same structure as Probe Net and inherits the parameters\nfrom Probe Net with a moving average paradigm.\n\nAfter that, to reduce the training time and hardware costs of the FC layer,\nwe propose a Dynamic Class Pool (DCP) that stores the features from Gallery Net\nand calculates the inner product (logits) with positive samples (whose\nidentities are in the DCP) in each mini-batch.\n\nDCP can be regarded as a substitute for the FC layer but it is far smaller,\nthus greatly reducing the computational and memory costs.\n\nFor negative samples (whose identities are not in DCP), we minimize the\ncosine similarities between negative samples and those in DCP.\n\nThen, to improve the update efficiency of DCP's parameters, we design a dual\ndata-loader including identity-based and instance-based loaders to generate a\ncertain of identities and samples in mini-batches.",
          "link": "http://arxiv.org/abs/2105.10375",
          "publishedOn": "2021-06-07T22:33:05.238Z",
          "wordCount": 776,
          "title": "An Efficient Training Approach for Very Large Scale Face Recognition. (arXiv:2105.10375v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jinlong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengkai Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yueyang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yabiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Ying Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiyao Lin</a>",
          "description": "Recently, most siamese network based trackers locate targets via object\nclassification and bounding-box regression. Generally, they select the\nbounding-box with maximum classification confidence as the final prediction.\nThis strategy may miss the right result due to the accuracy misalignment\nbetween classification and regression. In this paper, we propose a novel\nsiamese tracking algorithm called SiamRCR, addressing this problem with a\nsimple, light and effective solution. It builds reciprocal links between\nclassification and regression branches, which can dynamically re-weight their\nlosses for each positive sample. In addition, we add a localization branch to\npredict the localization accuracy, so that it can work as the replacement of\nthe regression assistance link during inference. This branch makes the training\nand inference more consistent. Extensive experimental results demonstrate the\neffectiveness of SiamRCR and its superiority over the state-of-the-art\ncompetitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019.\nMoreover, our SiamRCR runs at 65 FPS, far above the real-time requirement.",
          "link": "http://arxiv.org/abs/2105.11237",
          "publishedOn": "2021-06-07T22:33:05.218Z",
          "wordCount": 646,
          "title": "SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking. (arXiv:2105.11237v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1\">Wassim Hamidouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1\">Olivier Deforges</a>",
          "description": "Salient human detection (SHD) in dynamic 360{\\deg} immersive videos is of\ngreat importance for various applications such as robotics, inter-human and\nhuman-object interaction in augmented reality. However, 360{\\deg} video SHD has\nbeen seldom discussed in the computer vision community due to a lack of\ndatasets with large-scale omnidirectional videos and rich annotations. To this\nend, we propose SHD360, the first 360{\\deg} video SHD dataset containing\nvarious real-life daily scenes borrowed from this http URL, with\nhierarchical annotations for 6,268 key frames uniformly sampled from 37,403\nomnidirectional video frames at 4K resolution. Since so far there is no method\nproposed for 360{\\deg} image/video SHD, we systematically benchmark 11\nrepresentative state-of-the-art salient object detection approaches on our\nSHD360. We hope our proposed dataset and benchmark could serve as a good\nstarting point for advancing human-centric researches towards 360{\\deg}\npanoramic data. Our dataset and benchmark will be publicly available at\nhttps://github.com/PanoAsh/SHD360.",
          "link": "http://arxiv.org/abs/2105.11578",
          "publishedOn": "2021-06-07T22:33:05.198Z",
          "wordCount": 623,
          "title": "SHD360: A Benchmark Dataset for Salient Human Detection in 360{\\deg} Videos. (arXiv:2105.11578v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10762",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1\">Robert A. Murphy</a>",
          "description": "Random field and random cluster theory is used to prove certain mathematical\nresults concerning the probability distribution of images characterized as\ngeneric $2D$ integer arrays during simultaneous learning. Example models in\nimage classification and object segmentation illustrate the mathematical\nresults.",
          "link": "http://arxiv.org/abs/2104.10762",
          "publishedOn": "2021-06-07T22:33:05.164Z",
          "wordCount": 525,
          "title": "Image Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v5 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "In recent years, Generative Adversarial Networks have become ubiquitous in\nboth research and public perception, but how GANs convert an unstructured\nlatent code to a high quality output is still an open question. In this work,\nwe investigate regression into the latent space as a probe to understand the\ncompositional properties of GANs. We find that combining the regressor and a\npretrained generator provides a strong image prior, allowing us to create\ncomposite images from a collage of random image parts at inference time while\nmaintaining global consistency. To compare compositional properties across\ndifferent generators, we measure the trade-offs between reconstruction of the\nunrealistic input and image quality of the regenerated samples. We find that\nthe regression approach enables more localized editing of individual image\nparts compared to direct editing in the latent space, and we conduct\nexperiments to quantify this independence effect. Our method is agnostic to the\nsemantics of edits, and does not require labels or predefined concepts during\ntraining. Beyond image composition, our method extends to a number of related\napplications, such as image inpainting or example-based image editing, which we\ndemonstrate on several GANs and datasets, and because it uses only a single\nforward pass, it can operate in real-time. Code is available on our project\npage: https://chail.github.io/latent-composition/.",
          "link": "http://arxiv.org/abs/2103.10426",
          "publishedOn": "2021-06-07T03:06:13.443Z",
          "wordCount": 687,
          "title": "Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Ella Y. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1\">Anirudh Som</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1\">Ankita Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hongjun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>",
          "description": "Deep neural networks have increasingly been used as an auxiliary tool in\nhealthcare applications, due to their ability to improve performance of several\ndiagnosis tasks. However, these methods are not widely adopted in clinical\nsettings due to the practical limitations in the reliability, generalizability,\nand interpretability of deep learning based systems. As a result, methods have\nbeen developed that impose additional constraints during network training to\ngain more control as well as improve interpretabilty, facilitating their\nacceptance in healthcare community. In this work, we investigate the benefit of\nusing Orthogonal Spheres (OS) constraint for classification of COVID-19 cases\nfrom chest X-ray images. The OS constraint can be written as a simple\northonormality term which is used in conjunction with the standard\ncross-entropy loss during classification network training. Previous studies\nhave demonstrated significant benefits in applying such constraints to deep\nlearning models. Our findings corroborate these observations, indicating that\nthe orthonormality loss function effectively produces improved semantic\nlocalization via GradCAM visualizations, enhanced classification performance,\nand reduced model calibration error. Our approach achieves an improvement in\naccuracy of 1.6% and 4.8% for two- and three-class classification,\nrespectively; similar results are found for models with data augmentation\napplied. In addition to these findings, our work also presents a new\napplication of the OS regularizer in healthcare, increasing the post-hoc\ninterpretability and performance of deep learning models for COVID-19\nclassification to facilitate adoption of these methods in clinical settings. We\nalso identify the limitations of our strategy that can be explored for further\nresearch in future.",
          "link": "http://arxiv.org/abs/2102.08360",
          "publishedOn": "2021-06-07T03:06:13.428Z",
          "wordCount": 769,
          "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xingjia Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiliang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhenjun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bolei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qixiang Ye</a>",
          "description": "Weakly supervised object localization (WSOL) is a challenging problem when\ngiven image category labels but requires to learn object localization models.\nOptimizing a convolutional neural network (CNN) for classification tends to\nactivate local discriminative regions while ignoring complete object extent,\ncausing the partial activation issue. In this paper, we argue that partial\nactivation is caused by the intrinsic characteristics of CNN, where the\nconvolution operations produce local receptive fields and experience difficulty\nto capture long-range feature dependency among pixels. We introduce the token\nsemantic coupled attention map (TS-CAM) to take full advantage of the\nself-attention mechanism in visual transformer for long-range dependency\nextraction. TS-CAM first splits an image into a sequence of patch tokens for\nspatial embedding, which produce attention maps of long-range visual dependency\nto avoid partial activation. TS-CAM then re-allocates category-related\nsemantics for patch tokens, enabling each of them to be aware of object\ncategories. TS-CAM finally couples the patch tokens with the semantic-agnostic\nattention map to achieve semantic-aware localization. Experiments on the\nILSVRC/CUB-200-2011 datasets show that TS-CAM outperforms its CNN-CAM\ncounterparts by 7.1%/27.1% for WSOL, achieving state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2103.14862",
          "publishedOn": "2021-06-07T03:06:13.409Z",
          "wordCount": 674,
          "title": "TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization. (arXiv:2103.14862v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingying Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shifeng Chen</a>",
          "description": "The detection of traffic anomalies is a critical component of the intelligent\ncity transportation management system. Previous works have proposed a variety\nof notable insights and taken a step forward in this field, however, dealing\nwith the complex traffic environment remains a challenge. Moreover, the lack of\nhigh-quality data and the complexity of the traffic scene, motivate us to study\nthis problem from a hand-crafted perspective. In this paper, we propose a\nstraightforward and efficient framework that includes pre-processing, a dynamic\ntrack module, and post-processing. With video stabilization, background\nmodeling, and vehicle detection, the pro-processing phase aims to generate\ncandidate anomalies. The dynamic tracking module seeks and locates the start\ntime of anomalies by utilizing vehicle motion patterns and spatiotemporal\nstatus. Finally, we use post-processing to fine-tune the temporal boundary of\nanomalies. Not surprisingly, our proposed framework was ranked $1^{st}$ in the\nNVIDIA AI CITY 2021 leaderboard for traffic anomaly detection. The code is\navailable at: https://github.com/Endeavour10020/AICity2021-Anomaly-Detection .",
          "link": "http://arxiv.org/abs/2105.03827",
          "publishedOn": "2021-06-07T03:06:13.374Z",
          "wordCount": 642,
          "title": "Good Practices and A Strong Baseline for Traffic Anomaly Detection. (arXiv:2105.03827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fei Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hongxin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krovi_V/0/1/0/all/0/1\">Venkat Krovi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Feng Luo</a>",
          "description": "Knowledge distillation (KD) has become an important technique for model\ncompression and knowledge transfer. In this work, we first perform a\ncomprehensive analysis of the knowledge transferred by different KD methods. We\ndemonstrate that traditional KD methods, which minimize the KL divergence of\nsoftmax outputs between networks, are related to the knowledge alignment of an\nindividual sample only. Meanwhile, recent contrastive learning-based KD methods\nmainly transfer relational knowledge between different samples, namely,\nknowledge correlation. While it is important to transfer the full knowledge\nfrom teacher to student, we introduce the Multi-level Knowledge Distillation\n(MLKD) by effectively considering both knowledge alignment and correlation.\nMLKD is task-agnostic and model-agnostic, and can easily transfer knowledge\nfrom supervised or self-supervised pretrained teachers. We show that MLKD can\nimprove the reliability and transferability of learned representations.\nExperiments demonstrate that MLKD outperforms other state-of-the-art methods on\na large number of experimental settings including different (a) pretraining\nstrategies (b) network architectures (c) datasets (d) tasks.",
          "link": "http://arxiv.org/abs/2012.00573",
          "publishedOn": "2021-06-07T03:06:13.351Z",
          "wordCount": 625,
          "title": "Multi-level Knowledge Distillation via Knowledge Alignment and Correlation. (arXiv:2012.00573v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Steven Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiuming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhoutong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1\">Bryan Russell</a>",
          "description": "A neural radiance field (NeRF) is a scene model supporting high-quality view\nsynthesis, optimized per scene. In this paper, we explore enabling user editing\nof a category-level NeRF - also known as a conditional radiance field - trained\non a shape category. Specifically, we introduce a method for propagating coarse\n2D user scribbles to the 3D space, to modify the color or shape of a local\nregion. First, we propose a conditional radiance field that incorporates new\nmodular network components, including a shape branch that is shared across\nobject instances. Observing multiple instances of the same category, our model\nlearns underlying part semantics without any supervision, thereby allowing the\npropagation of coarse 2D user scribbles to the entire 3D region (e.g., chair\nseat). Next, we propose a hybrid network update strategy that targets specific\nnetwork components, which balances efficiency and accuracy. During user\ninteraction, we formulate an optimization problem that both satisfies the\nuser's constraints and preserves the original object structure. We demonstrate\nour approach on various editing tasks over three shape datasets and show that\nit outperforms prior neural editing approaches. Finally, we edit the appearance\nand shape of a real photograph and show that the edit propagates to\nextrapolated novel views.",
          "link": "http://arxiv.org/abs/2105.06466",
          "publishedOn": "2021-06-07T03:06:13.345Z",
          "wordCount": 682,
          "title": "Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuran Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yitong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng Wu</a>",
          "description": "Data augmentation is widely known as a simple yet surprisingly effective\ntechnique for regularizing deep networks. Conventional data augmentation\nschemes, e.g., flipping, translation or rotation, are low-level,\ndata-independent and class-agnostic operations, leading to limited diversity\nfor augmented samples. To this end, we propose a novel semantic data\naugmentation algorithm to complement traditional approaches. The proposed\nmethod is inspired by the intriguing property that deep networks are effective\nin learning linearized features, i.e., certain directions in the deep feature\nspace correspond to meaningful semantic transformations, e.g., changing the\nbackground or view angle of an object. Based on this observation, translating\ntraining samples along many such directions in the feature space can\neffectively augment the dataset for more diversity. To implement this idea, we\nfirst introduce a sampling based method to obtain semantically meaningful\ndirections efficiently. Then, an upper bound of the expected cross-entropy (CE)\nloss on the augmented training set is derived by assuming the number of\naugmented samples goes to infinity, yielding a highly efficient algorithm. In\nfact, we show that the proposed implicit semantic data augmentation (ISDA)\nalgorithm amounts to minimizing a novel robust CE loss, which adds minimal\nextra computational cost to a normal training procedure. In addition to\nsupervised learning, ISDA can be applied to semi-supervised learning tasks\nunder the consistency regularization framework, where ISDA amounts to\nminimizing the upper bound of the expected KL-divergence between the augmented\nfeatures and the original features. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (e.g., ResNets\nand DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,\nImageNet, and Cityscapes.",
          "link": "http://arxiv.org/abs/2007.10538",
          "publishedOn": "2021-06-07T03:06:13.323Z",
          "wordCount": 781,
          "title": "Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.10130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyan Zhang</a>",
          "description": "Graph Neural Networks (GNNs) are gaining increasing attention on graph data\nlearning tasks in recent years. However, in many applications, graph may be\ncoming in an incomplete form where attributes of graph nodes are partially\nunknown/missing. Existing GNNs are generally designed on complete graphs which\ncan not deal with attribute-incomplete graph data directly. To address this\nproblem, we develop a novel partial aggregation based GNNs, named Partial Graph\nNeural Networks (PaGNNs), for attribute-incomplete graph representation and\nlearning. Our work is motivated by the observation that the neighborhood\naggregation function in standard GNNs can be equivalently viewed as the\nneighborhood reconstruction formulation. Based on it, we define two novel\npartial aggregation (reconstruction) functions on incomplete graph and derive\nPaGNNs for incomplete graph data learning. Extensive experiments on several\ndatasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.",
          "link": "http://arxiv.org/abs/2003.10130",
          "publishedOn": "2021-06-07T03:06:13.317Z",
          "wordCount": 600,
          "title": "Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.02164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tanzila Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Shih-Han Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1\">Leonid Sigal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "We consider the problem of Visual Question Answering (VQA). Given an image\nand a free-form, open-ended, question, expressed in natural language, the goal\nof VQA system is to provide accurate answer to this question with respect to\nthe image. The task is challenging because it requires simultaneous and\nintricate understanding of both visual and textual information. Attention,\nwhich captures intra- and inter-modal dependencies, has emerged as perhaps the\nmost widely used mechanism for addressing these challenges. In this paper, we\npropose an improved attention-based architecture to solve VQA. We incorporate\nan Attention on Attention (AoA) module within encoder-decoder framework, which\nis able to determine the relation between attention results and queries.\nAttention module generates weighted average for each query. On the other hand,\nAoA module first generates an information vector and an attention gate using\nattention results and current context; and then adds another attention to\ngenerate final attended information by multiplying the two. We also propose\nmultimodal fusion module to combine both visual and textual information. The\ngoal of this fusion module is to dynamically decide how much information should\nbe considered from each modality. Extensive experiments on VQA-v2 benchmark\ndataset show that our method achieves the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2011.02164",
          "publishedOn": "2021-06-07T03:06:13.310Z",
          "wordCount": 674,
          "title": "An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-06-07T03:06:13.303Z",
          "wordCount": 695,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhengzheng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_Y/0/1/0/all/0/1\">Yang Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>",
          "description": "RGB-thermal salient object detection (SOD) aims to segment the common\nprominent regions of visible image and corresponding thermal infrared image\nthat we call it RGBT SOD. Existing methods don't fully explore and exploit the\npotentials of complementarity of different modalities and multi-type cues of\nimage contents, which play a vital role in achieving accurate results. In this\npaper, we propose a multi-interactive dual-decoder to mine and model the\nmulti-type interactions for accurate RGBT SOD. In specific, we first encode two\nmodalities into multi-level multi-modal feature representations. Then, we\ndesign a novel dual-decoder to conduct the interactions of multi-level\nfeatures, two modalities and global contexts. With these interactions, our\nmethod works well in diversely challenging scenarios even in the presence of\ninvalid modality. Finally, we carry out extensive experiments on public RGBT\nand RGBD SOD datasets, and the results show that the proposed method achieves\nthe outstanding performance against state-of-the-art algorithms. The source\ncode has been released\nat:https://github.com/lz118/Multi-interactive-Dual-decoder.",
          "link": "http://arxiv.org/abs/2005.02315",
          "publishedOn": "2021-06-07T03:06:13.294Z",
          "wordCount": 631,
          "title": "Multi-interactive Dual-decoder for RGB-thermal Salient Object Detection. (arXiv:2005.02315v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01678",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1\">Rikiya Yamashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1\">Snikitha Banda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1\">Jeanne Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Suboptimal generalization of machine learning models on unseen data is a key\nchallenge which hampers the clinical applicability of such models to medical\nimaging. Although various methods such as domain adaptation and domain\ngeneralization have evolved to combat this challenge, learning robust and\ngeneralizable representations is core to medical image understanding, and\ncontinues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation\nfor histoPathology), a form of data augmentation based on random style transfer\nfrom non-medical style source such as artistic paintings, for learning\ndomain-agnostic visual representations in computational pathology. Style\ntransfer replaces the low-level texture content of an image with the\nuninformative style of randomly selected style source image, while preserving\nthe original high-level semantic content. This improves robustness to domain\nshift and can be used as a simple yet powerful tool for learning\ndomain-agnostic representations. We demonstrate that STRAP leads to\nstate-of-the-art performance, particularly in the presence of domain shifts, on\ntwo particular classification tasks in computational pathology.",
          "link": "http://arxiv.org/abs/2102.01678",
          "publishedOn": "2021-06-07T03:06:13.277Z",
          "wordCount": 633,
          "title": "Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Mart&#xed;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1\">Juli&#xe1;n Fierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>",
          "description": "Convolutional Networks have dominated the field of computer vision for the\nlast ten years, exhibiting extremely powerful feature extraction capabilities\nand outstanding classification performance. The main strategy to prolong this\ntrend relies on further upscaling networks in size. However, costs increase\nrapidly while performance improvements may be marginal. We hypothesise that\nadding heterogeneous sources of information may be more cost-effective to a CNN\nthan building a bigger network. In this paper, an ensemble method is proposed\nfor accurate image classification, fusing automatically detected features\nthrough Convolutional Neural Network architectures with a set of manually\ndefined statistical indicators. Through a combination of the predictions of a\nCNN and a secondary classifier trained on statistical features, better\nclassification performance can be cheaply achieved. We test multiple learning\nalgorithms and CNN architectures on a diverse number of datasets to validate\nour proposal, making public all our code and data via GitHub. According to our\nresults, the inclusion of additional indicators and an ensemble classification\napproach helps to increase the performance in 8 of 9 datasets, with a\nremarkable increase of more than 10% precision in two of them.",
          "link": "http://arxiv.org/abs/2012.11049",
          "publishedOn": "2021-06-07T03:06:13.271Z",
          "wordCount": 651,
          "title": "Fusing CNNs and statistical indicators to improve image classification. (arXiv:2012.11049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.11603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1\">Tetsuya Shioda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1\">Shoichiro Takeda</a>",
          "description": "The rotation prediction (Rotation) is a simple pretext-task for\nself-supervised learning (SSL), where models learn useful representations for\ntarget vision tasks by solving pretext-tasks. Although Rotation captures\ninformation of object shapes, it hardly captures information of textures. To\ntackle this problem, we introduce a novel pretext-task called image enhanced\nrotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and\nanother pretext-task based on image enhancement (e.g., sharpening and\nsolarizing) while maintaining simplicity. Through the simultaneous prediction\nof rotation and image enhancement, models learn representations to capture the\ninformation of not only object shapes but also textures. Our experimental\nresults show that IE-Rot models outperform Rotation on various standard\nbenchmarks including ImageNet classification, PASCAL-VOC detection, and COCO\ndetection/segmentation.",
          "link": "http://arxiv.org/abs/1912.11603",
          "publishedOn": "2021-06-07T03:06:13.256Z",
          "wordCount": 589,
          "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baoquan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xutao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yunming Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhichao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>",
          "description": "Few-shot learning is a challenging task, which aims to learn a classifier for\nnovel classes with few examples. Pre-training based meta-learning methods\neffectively tackle the problem by pre-training a feature extractor and then\nfine-tuning it through the nearest centroid based meta-learning. However,\nresults show that the fine-tuning step makes very marginal improvements. In\nthis paper, 1) we figure out the key reason, i.e., in the pre-trained feature\nspace, the base classes already form compact clusters while novel classes\nspread as groups with large variances, which implies that fine-tuning the\nfeature extractor is less meaningful; 2) instead of fine-tuning the feature\nextractor, we focus on estimating more representative prototypes during\nmeta-learning. Consequently, we propose a novel prototype completion based\nmeta-learning framework. This framework first introduces primitive knowledge\n(i.e., class-level part or attribute annotations) and extracts representative\nattribute features as priors. Then, we design a prototype completion network to\nlearn to complete prototypes with these priors. To avoid the prototype\ncompletion error caused by primitive knowledge noises or class differences, we\nfurther develop a Gaussian based prototype fusion strategy that combines the\nmean-based and completed prototypes by exploiting the unlabeled samples.\nExtensive experiments show that our method: (i) can obtain more accurate\nprototypes; (ii) outperforms state-of-the-art techniques by 2% - 9% in terms of\nclassification accuracy. Our code is available online.",
          "link": "http://arxiv.org/abs/2009.04960",
          "publishedOn": "2021-06-07T03:06:13.249Z",
          "wordCount": 710,
          "title": "Prototype Completion with Primitive Knowledge for Few-Shot Learning. (arXiv:2009.04960v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>",
          "description": "Generative adversarial networks built from deep convolutional neural networks\n(GANs) lack the ability to exactly replicate the high-frequency components of\nnatural images. To alleviate this issue, we introduce two novel training\ntechniques called frequency dropping (F-Drop) and frequency matching (F-Match).\nThe key idea of F-Drop is to filter out unnecessary high-frequency components\nfrom the input images of the discriminators. This simple modification prevents\nthe discriminators from being confused by perturbations of the high-frequency\ncomponents. In addition, F-Drop makes the GANs focus on fitting in the\nlow-frequency domain, in which there are the dominant components of natural\nimages. F-Match minimizes the difference between real and fake images in the\nfrequency domain for generating more realistic images. F-Match is implemented\nas a regularization term in the objective functions of the generators; it\npenalizes the batch mean error in the frequency domain. F-Match helps the\ngenerators to fit in the high-frequency domain filtered out by F-Drop to the\nreal image. We experimentally demonstrate that the combination of F-Drop and\nF-Match improves the generative performance of GANs in both the frequency and\nspatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,\nCelebA, and ImageNet).",
          "link": "http://arxiv.org/abs/2106.02343",
          "publishedOn": "2021-06-07T03:06:13.231Z",
          "wordCount": 634,
          "title": "F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.07189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_A/0/1/0/all/0/1\">Andong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yuqing Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>",
          "description": "RGBT tracking has attracted increasing attention since RGB and thermal\ninfrared data have strong complementary advantages, which could make trackers\nall-day and all-weather work. However, how to effectively represent RGBT data\nfor visual tracking remains unstudied well. Existing works usually focus on\nextracting modality-shared or modality-specific information, but the potentials\nof these two cues are not well explored and exploited in RGBT tracking. In this\npaper, we propose a novel multi-adapter network to jointly perform\nmodality-shared, modality-specific and instance-aware target representation\nlearning for RGBT tracking. To this end, we design three kinds of adapters\nwithin an end-to-end deep learning framework. In specific, we use the modified\nVGG-M as the generality adapter to extract the modality-shared target\nrepresentations.To extract the modality-specific features while reducing the\ncomputational complexity, we design a modality adapter, which adds a small\nblock to the generality adapter in each layer and each modality in a parallel\nmanner. Such a design could learn multilevel modality-specific representations\nwith a modest number of parameters as the vast majority of parameters are\nshared with the generality adapter. We also design instance adapter to capture\nthe appearance properties and temporal variations of a certain target.\nMoreover, to enhance the shared and specific features, we employ the loss of\nmultiple kernel maximum mean discrepancy to measure the distribution divergence\nof different modal features and integrate it into each layer for more robust\nrepresentation learning. Extensive experiments on two RGBT tracking benchmark\ndatasets demonstrate the outstanding performance of the proposed tracker\nagainst the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.07189",
          "publishedOn": "2021-06-07T03:06:13.225Z",
          "wordCount": 729,
          "title": "RGBT Tracking via Multi-Adapter Network with Hierarchical Divergence Loss. (arXiv:2011.07189v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1\">Chris Paxton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1\">Arsalan Mousavian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_Y/0/1/0/all/0/1\">Yu-Wei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cakmak_M/0/1/0/all/0/1\">Maya Cakmak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>",
          "description": "Human-robot object handovers have been an actively studied area of robotics\nover the past decade; however, very few techniques and systems have addressed\nthe challenge of handing over diverse objects with arbitrary appearance, size,\nshape, and rigidity. In this paper, we present a vision-based system that\nenables reactive human-to-robot handovers of unknown objects. Our approach\ncombines closed-loop motion planning with real-time, temporally-consistent\ngrasp generation to ensure reactivity and motion smoothness. Our system is\nrobust to different object positions and orientations, and can grasp both rigid\nand non-rigid objects. We demonstrate the generalizability, usability, and\nrobustness of our approach on a novel benchmark set of 26 diverse household\nobjects, a user study with naive users (N=6) handing over a subset of 15\nobjects, and a systematic evaluation examining different ways of handing\nobjects. More results and videos can be found at\nhttps://sites.google.com/nvidia.com/handovers-of-arbitrary-objects.",
          "link": "http://arxiv.org/abs/2011.08961",
          "publishedOn": "2021-06-07T03:06:13.218Z",
          "wordCount": 615,
          "title": "Reactive Human-to-Robot Handovers of Arbitrary Objects. (arXiv:2011.08961v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:13.212Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiapeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaoguang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>",
          "description": "This paper focuses on the challenging task of learning 3D object surface\nreconstructions from RGB images. Existingmethods achieve varying degrees of\nsuccess by using different surface representations. However, they all have\ntheir own drawbacks,and cannot properly reconstruct the surface shapes of\ncomplex topologies, arguably due to a lack of constraints on the\ntopologicalstructures in their learning frameworks. To this end, we propose to\nlearn and use the topology-preserved, skeletal shape representationto assist\nthe downstream task of object surface reconstruction from RGB images.\nTechnically, we propose the novelSkeletonNetdesign that learns a volumetric\nrepresentation of a skeleton via a bridged learning of a skeletal point set,\nwhere we use paralleldecoders each responsible for the learning of points on 1D\nskeletal curves and 2D skeletal sheets, as well as an efficient module\nofglobally guided subvolume synthesis for a refined, high-resolution skeletal\nvolume; we present a differentiablePoint2Voxellayer tomake SkeletonNet\nend-to-end and trainable. With the learned skeletal volumes, we propose two\nmodels, the Skeleton-Based GraphConvolutional Neural Network (SkeGCNN) and the\nSkeleton-Regularized Deep Implicit Surface Network (SkeDISN), which\nrespectivelybuild upon and improve over the existing frameworks of explicit\nmesh deformation and implicit field learning for the downstream\nsurfacereconstruction task. We conduct thorough experiments that verify the\nefficacy of our proposed SkeletonNet. SkeGCNN and SkeDISNoutperform existing\nmethods as well, and they have their own merits when measured by different\nmetrics. Additional results ingeneralized task settings further demonstrate the\nusefulness of our proposed methods. We have made both our implementation\ncodeand the ShapeNet-Skeleton dataset publicly available at ble at\nhttps://github.com/tangjiapeng/SkeletonNet.",
          "link": "http://arxiv.org/abs/2008.05742",
          "publishedOn": "2021-06-07T03:06:13.206Z",
          "wordCount": 735,
          "title": "SkeletonNet: A Topology-Preserving Solution for Learning Mesh Reconstruction of Object Surfaces from RGB Images. (arXiv:2008.05742v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiangde Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenjun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jieneng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1\">Tao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yinan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shichuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nianyong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guotai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "Gross Target Volume (GTV) segmentation plays an irreplaceable role in\nradiotherapy planning for Nasopharyngeal Carcinoma (NPC). Despite that\nConvolutional Neural Networks (CNN) have achieved good performance for this\ntask, they rely on a large set of labeled images for training, which is\nexpensive and time-consuming to acquire. In this paper, we propose a novel\nframework with Uncertainty Rectified Pyramid Consistency (URPC) regularization\nfor semi-supervised NPC GTV segmentation. Concretely, we extend a backbone\nsegmentation network to produce pyramid predictions at different scales. The\npyramid predictions network (PPNet) is supervised by the ground truth of\nlabeled images and a multi-scale consistency loss for unlabeled images,\nmotivated by the fact that prediction at different scales for the same input\nshould be similar and consistent. However, due to the different resolution of\nthese predictions, encouraging them to be consistent at each pixel directly has\nlow robustness and may lose some fine details. To address this problem, we\nfurther design a novel uncertainty rectifying module to enable the framework to\ngradually learn from meaningful and reliable consensual regions at different\nscales. Experimental results on a dataset with 258 NPC MR images showed that\nwith only 10% or 20% images labeled, our method largely improved the\nsegmentation performance by leveraging the unlabeled images, and it also\noutperformed five state-of-the-art semi-supervised segmentation methods.\nMoreover, when only 50% images labeled, URPC achieved an average Dice score of\n82.74% that was close to fully supervised learning.",
          "link": "http://arxiv.org/abs/2012.07042",
          "publishedOn": "2021-06-07T03:06:13.197Z",
          "wordCount": 745,
          "title": "Efficient Semi-Supervised Gross Target Volume of Nasopharyngeal Carcinoma Segmentation via Uncertainty Rectified Pyramid Consistency. (arXiv:2012.07042v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junguang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yifei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yufeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Domain adaptation (DA) aims at transferring knowledge from a labeled source\ndomain to an unlabeled target domain. Though many DA theories and algorithms\nhave been proposed, most of them are tailored into classification settings and\nmay fail in regression tasks, especially in the practical keypoint detection\ntask. To tackle this difficult but significant task, we present a method of\nregressive domain adaptation (RegDA) for unsupervised keypoint detection.\nInspired by the latest theoretical work, we first utilize an adversarial\nregressor to maximize the disparity on the target domain and train a feature\ngenerator to minimize this disparity. However, due to the high dimension of the\noutput space, this regressor fails to detect samples that deviate from the\nsupport of the source. To overcome this problem, we propose two important\nideas. First, based on our observation that the probability density of the\noutput space is sparse, we introduce a spatial probability distribution to\ndescribe this sparsity and then use it to guide the learning of the adversarial\nregressor. Second, to alleviate the optimization difficulty in the\nhigh-dimensional space, we innovatively convert the minimax game in the\nadversarial training to the minimization of two opposite goals. Extensive\nexperiments show that our method brings large improvement by 8% to 11% in terms\nof PCK on different datasets.",
          "link": "http://arxiv.org/abs/2103.06175",
          "publishedOn": "2021-06-07T03:06:13.180Z",
          "wordCount": 680,
          "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenbin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiabao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>",
          "description": "Shape modeling and reconstruction from raw point clouds of objects stand as a\nfundamental challenge in vision and graphics research. Classical methods\nconsider analytic shape priors; however, their performance degraded when the\nscanned points deviate from the ideal conditions of cleanness and completeness.\nImportant progress has been recently made by data-driven approaches, which\nlearn global and/or local models of implicit surface representations from\nauxiliary sets of training shapes. Motivated from a universal phenomenon that\nself-similar shape patterns of local surface patches repeat across the entire\nsurface of an object, we aim to push forward the data-driven strategies and\npropose to learn a local implicit surface network for a shared, adaptive\nmodeling of the entire surface for a direct surface reconstruction from raw\npoint cloud; we also enhance the leveraging of surface self-similarities by\nimproving correlations among the optimized latent codes of individual surface\npatches. Given that orientations of raw points could be unavailable or noisy,\nwe extend sign agnostic learning into our local implicit model, which enables\nour recovery of signed implicit fields of local surfaces from the unsigned\ninputs. We term our framework as Sign-Agnostic Implicit Learning of Surface\nSelf-Similarities (SAIL-S3). With a global post-optimization of local sign\nflipping, SAIL-S3 is able to directly model raw, un-oriented point clouds and\nreconstruct high-quality object surfaces. Experiments show its superiority over\nexisting methods.",
          "link": "http://arxiv.org/abs/2012.07498",
          "publishedOn": "2021-06-07T03:06:13.173Z",
          "wordCount": 696,
          "title": "Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape Modeling and Reconstruction from Raw Point Clouds. (arXiv:2012.07498v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.04680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1\">Ian Reid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "This paper tackles the problem of training a deep convolutional neural\nnetwork of both low-bitwidth weights and activations. Optimizing a\nlow-precision network is very challenging due to the non-differentiability of\nthe quantizer, which may result in substantial accuracy loss. To address this,\nwe propose three practical approaches, including (i) progressive quantization;\n(ii) stochastic precision; and (iii) joint knowledge distillation to improve\nthe network training. First, for progressive quantization, we propose two\nschemes to progressively find good local minima. Specifically, we propose to\nfirst optimize a net with quantized weights and subsequently quantize\nactivations. This is in contrast to the traditional methods which optimize them\nsimultaneously. Furthermore, we propose a second progressive quantization\nscheme which gradually decreases the bit-width from high-precision to\nlow-precision during training. Second, to alleviate the excessive training\nburden due to the multi-round training stages, we further propose a one-stage\nstochastic precision strategy to randomly sample and quantize sub-networks\nwhile keeping other parts in full-precision. Finally, we adopt a novel learning\nscheme to jointly train a full-precision model alongside the low-precision one.\nBy doing so, the full-precision model provides hints to guide the low-precision\nmodel training and significantly improves the performance of the low-precision\nnetwork. Extensive experiments on various datasets (e.g., CIFAR-100, ImageNet)\nshow the effectiveness of the proposed methods.",
          "link": "http://arxiv.org/abs/1908.04680",
          "publishedOn": "2021-06-07T03:06:13.167Z",
          "wordCount": 709,
          "title": "Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations. (arXiv:1908.04680v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fayolle_P/0/1/0/all/0/1\">Pierre-Alain Fayolle</a>",
          "description": "We describe in this short note a technique to convert an implicit surface\ninto a Signed Distance Function (SDF) while exactly preserving the zero\nlevel-set of the implicit. The proposed approach relies on embedding the input\nimplicit in the final layer of a neural network, which is trained to minimize a\nloss function characterizing the SDF.",
          "link": "http://arxiv.org/abs/2104.08057",
          "publishedOn": "2021-06-07T03:06:13.160Z",
          "wordCount": 512,
          "title": "Signed Distance Function Computation from an Implicit Surface. (arXiv:2104.08057v2 [cs.GR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11958",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hung_A/0/1/0/all/0/1\">Alex Ling Yu Hung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_E/0/1/0/all/0/1\">Edward Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Galeotti_J/0/1/0/all/0/1\">John Galeotti</a>",
          "description": "Ultrasound image quality has continually been improving. However, when\nneedles or other metallic objects are operating inside the tissue, the\nresulting reverberation artifacts can severely corrupt the surrounding image\nquality. Such effects are challenging for existing computer vision algorithms\nfor medical image analysis. Needle reverberation artifacts can be hard to\nidentify at times and affect various pixel values to different degrees. The\nboundaries of such artifacts are ambiguous, leading to disagreement among human\nexperts labeling the artifacts. We propose a weakly- and semi-supervised,\nprobabilistic needle-and-reverberation-artifact segmentation algorithm to\nseparate the desired tissue-based pixel values from the superimposed artifacts.\nOur method models the intensity decay of artifact intensities and is designed\nto minimize the human labeling error. We demonstrate the applicability of the\napproach and compare it against other segmentation algorithms. Our method is\ncapable of differentiating between the reverberations from artifact-free\npatches as well as of modeling the intensity fall-off in the artifacts. Our\nmethod matches state-of-the-art artifact segmentation performance and sets a\nnew standard in estimating the per-pixel contributions of artifact vs\nunderlying anatomy, especially in the immediately adjacent regions between\nreverberation lines. Our algorithm is also able to improve the performance\ndownstream image analysis algorithms.",
          "link": "http://arxiv.org/abs/2011.11958",
          "publishedOn": "2021-06-07T03:06:13.154Z",
          "wordCount": 679,
          "title": "Weakly- and Semi-Supervised Probabilistic Segmentation and Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better AI Understanding of Tissue Beneath Needles. (arXiv:2011.11958v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.10471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaoul_Y/0/1/0/all/0/1\">Yorai Shaoul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Katherine Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ok_K/0/1/0/all/0/1\">Kyel Ok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1\">Nicholas Roy</a>",
          "description": "Object-level data association is central to robotic applications such as\ntracking-by-detection and object-level simultaneous localization and mapping.\nWhile current learned visual data association methods outperform hand-crafted\nalgorithms, many rely on large collections of domain-specific training examples\nthat can be difficult to obtain without prior knowledge. Additionally, such\nmethods often remain fixed during inference-time and do not harness observed\ninformation to better their performance. We propose a self-supervised method\nfor incrementally refining visual descriptors to improve performance in the\ntask of object-level visual data association. Our method optimizes deep\ndescriptor generators online, by continuously training a widely available image\nclassification network pre-trained with domain-independent data. We show that\nearlier layers in the network outperform later-stage layers for the data\nassociation task while also allowing for a 94% reduction in the number of\nparameters, enabling the online optimization. We show that self-labelling\nchallenging triplets--choosing positive examples separated by large temporal\ndistances and negative examples close in the descriptor space--improves the\nquality of the learned descriptors for the multi-object tracking task. Finally,\nwe demonstrate that our approach surpasses other visual data-association\nmethods applied to a tracking-by-detection task, and show that it provides\nbetter performance-gains when compared to other methods that attempt to adapt\nto observed information.",
          "link": "http://arxiv.org/abs/2011.10471",
          "publishedOn": "2021-06-07T03:06:13.136Z",
          "wordCount": 708,
          "title": "Online Descriptor Enhancement via Self-Labelling Triplets for Visual Data Association. (arXiv:2011.10471v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asif_U/0/1/0/all/0/1\">Umar Asif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1\">Deval Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavallar_S/0/1/0/all/0/1\">Stefan von Cavallar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jianbin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrer_S/0/1/0/all/0/1\">Stefan Harrer</a>",
          "description": "Existing action recognition methods mainly focus on joint and bone\ninformation in human body skeleton data due to its robustness to complex\nbackgrounds and dynamic characteristics of the environments. In this paper, we\ncombine body skeleton data with spatial and motion features from face and two\nhands, and present \"Deep Action Stamps (DeepActs)\", a novel data representation\nto encode actions from video sequences. We also present \"DeepActsNet\", a deep\nlearning based ensemble model which learns convolutional and structural\nfeatures from Deep Action Stamps for highly accurate action recognition.\nExperiments on three challenging action recognition datasets (NTU60, NTU120,\nand SYSU) show that the proposed model trained using Deep Action Stamps produce\nconsiderable improvements in the action recognition accuracy with less\ncomputational cost compared to the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2009.09818",
          "publishedOn": "2021-06-07T03:06:13.130Z",
          "wordCount": 620,
          "title": "DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition. (arXiv:2009.09818v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marchetti_F/0/1/0/all/0/1\">Francesco Marchetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becattini_F/0/1/0/all/0/1\">Federico Becattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidenari_L/0/1/0/all/0/1\">Lorenzo Seidenari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1\">Alberto Del Bimbo</a>",
          "description": "Autonomous vehicles are expected to drive in complex scenarios with several\nindependent non cooperating agents. Path planning for safely navigating in such\nenvironments can not just rely on perceiving present location and motion of\nother agents. It requires instead to predict such variables in a far enough\nfuture. In this paper we address the problem of multimodal trajectory\nprediction exploiting a Memory Augmented Neural Network. Our method learns past\nand future trajectory embeddings using recurrent neural networks and exploits\nan associative external memory to store and retrieve such embeddings.\nTrajectory prediction is then performed by decoding in-memory future encodings\nconditioned with the observed past. We incorporate scene knowledge in the\ndecoding state by learning a CNN on top of semantic scene maps. Memory growth\nis limited by learning a writing controller based on the predictive capability\nof existing embeddings. We show that our method is able to natively perform\nmulti-modal trajectory prediction obtaining state-of-the art results on three\ndatasets. Moreover, thanks to the non-parametric nature of the memory module,\nwe show how once trained our system can continuously improve by ingesting novel\npatterns.",
          "link": "http://arxiv.org/abs/2006.03340",
          "publishedOn": "2021-06-07T03:06:13.124Z",
          "wordCount": 647,
          "title": "MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction. (arXiv:2006.03340v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akada_H/0/1/0/all/0/1\">Hiroyasu Akada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhashim_I/0/1/0/all/0/1\">Ibraheem Alhashim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "We tackle the problem of unsupervised synthetic-to-realistic domain\nadaptation for single image depth estimation. An essential building block of\nsingle image depth estimation is an encoder-decoder task network that takes RGB\nimages as input and produces depth maps as output. In this paper, we propose a\nnovel training strategy to force the task network to learn domain invariant\nrepresentations in a self-supervised manner. Specifically, we extend\nself-supervised learning from traditional representation learning, which works\non images from a single domain, to domain invariant representation learning,\nwhich works on images from two different domains by utilizing an image-to-image\ntranslation network. Firstly, we use our bidirectional image-to-image\ntranslation network to transfer domain-specific styles between synthetic and\nreal domains. This style transfer operation allows us to obtain similar images\nfrom the different domains. Secondly, we jointly train our task network and\nSiamese network with the same images from the different domains to obtain\ndomain invariance for the task network. Finally, we fine-tune the task network\nusing labeled synthetic and unlabeled real-world data. Our training strategy\nyields improved generalization capability in the real-world domain. We carry\nout an extensive evaluation on two popular datasets for depth estimation, KITTI\nand Make3D. The results demonstrate that our proposed method outperforms the\nstate-of-the-art both qualitatively and quantitatively. The source code and\nmodel weights will be made available.",
          "link": "http://arxiv.org/abs/2106.02594",
          "publishedOn": "2021-06-07T03:06:13.117Z",
          "wordCount": 656,
          "title": "Self-Supervised Learning of Domain Invariant Features for Depth Estimation. (arXiv:2106.02594v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1\">Tristan Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Suiyi Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1\">Thomas Fr&#xe9;our</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1\">Harold Mouch&#xe8;re</a>",
          "description": "The prevalence of employing attention mechanisms has brought along concerns\non the interpretability of attention distributions. Although it provides\ninsights about how a model is operating, utilizing attention as the explanation\nof model predictions is still highly dubious. The community is still seeking\nmore interpretable strategies for better identifying local active regions that\ncontribute the most to the final decision. To improve the interpretability of\nexisting attention models, we propose a novel Bilinear Representative\nNon-Parametric Attention (BR-NPA) strategy that captures the task-relevant\nhuman-interpretable information. The target model is first distilled to have\nhigher-resolution intermediate feature maps. From which, representative\nfeatures are then grouped based on local pairwise feature similarity, to\nproduce finer-grained, more precise attention maps highlighting task-relevant\nparts of the input. The obtained attention maps are ranked according to the\n`active level' of the compound feature, which provides information regarding\nthe important level of the highlighted regions. The proposed model can be\neasily adapted in a wide variety of modern deep models, where classification is\ninvolved. It is also more accurate, faster, and with a smaller memory footprint\nthan usual neural attention modules. Extensive experiments showcase more\ncomprehensive visual explanations compared to the state-of-the-art\nvisualization model across multiple tasks including few-shot classification,\nperson re-identification, fine-grained image classification. The proposed\nvisualization model sheds imperative light on how neural networks `pay their\nattention' differently in different tasks.",
          "link": "http://arxiv.org/abs/2106.02566",
          "publishedOn": "2021-06-07T03:06:13.109Z",
          "wordCount": 669,
          "title": "Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02106",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_B/0/1/0/all/0/1\">Bardia Yousefi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sharifipour_H/0/1/0/all/0/1\">Hossein Memarzadeh Sharifipour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maldague_X/0/1/0/all/0/1\">Xavier P.V. Maldague</a>",
          "description": "Thermography has been used extensively as a complementary diagnostic tool in\nbreast cancer detection. Among thermographic methods matrix factorization (MF)\ntechniques show an unequivocal capability to detect thermal patterns\ncorresponding to vasodilation in cancer cases. One of the biggest challenges in\nsuch techniques is selecting the best representation of the thermal basis. In\nthis study, an embedding method is proposed to address this problem and\nDeep-semi-nonnegative matrix factorization (Deep-SemiNMF) for thermography is\nintroduced, then tested for 208 breast cancer screening cases. First, we apply\nDeep-SemiNMF to infrared images to extract low-rank thermal representations for\neach case. Then, we embed low-rank bases to obtain one basis for each patient.\nAfter that, we extract 300 thermal imaging features, called thermomics, to\ndecode imaging information for the automatic diagnostic model. We reduced the\ndimensionality of thermomics by spanning them onto Hilbert space using RBF\nkernel and select the three most efficient features using the block Hilbert\nSchmidt Independence Criterion Lasso (block HSIC Lasso). The preserved thermal\nheterogeneity successfully classified asymptomatic versus symptomatic patients\napplying a random forest model (cross-validated accuracy of 71.36%\n(69.42%-73.3%)).",
          "link": "http://arxiv.org/abs/2106.02106",
          "publishedOn": "2021-06-07T03:06:13.084Z",
          "wordCount": 647,
          "title": "Embedded Deep Regularized Block HSIC Thermomics for Early Diagnosis of Breast Cancer. (arXiv:2106.02106v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Capobianco_S/0/1/0/all/0/1\">Samuele Capobianco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Millefiori_L/0/1/0/all/0/1\">Leonardo M. Millefiori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forti_N/0/1/0/all/0/1\">Nicola Forti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braca_P/0/1/0/all/0/1\">Paolo Braca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_P/0/1/0/all/0/1\">Peter Willett</a>",
          "description": "Data-driven methods open up unprecedented possibilities for maritime\nsurveillance using Automatic Identification System (AIS) data. In this work, we\nexplore deep learning strategies using historical AIS observations to address\nthe problem of predicting future vessel trajectories with a prediction horizon\nof several hours. We propose novel sequence-to-sequence vessel trajectory\nprediction models based on encoder-decoder recurrent neural networks (RNNs)\nthat are trained on historical trajectory data to predict future trajectory\nsamples given previous observations. The proposed architecture combines Long\nShort-Term Memory (LSTM) RNNs for sequence modeling to encode the observed data\nand generate future predictions with different intermediate aggregation layers\nto capture space-time dependencies in sequential data. Experimental results on\nvessel trajectories from an AIS dataset made freely available by the Danish\nMaritime Authority show the effectiveness of deep-learning methods for\ntrajectory prediction based on sequence-to-sequence neural networks, which\nachieve better performance than baseline approaches based on linear regression\nor on the Multi-Layer Perceptron (MLP) architecture. The comparative evaluation\nof results shows: i) the superiority of attention pooling over static pooling\nfor the specific application, and ii) the remarkable performance improvement\nthat can be obtained with labeled trajectories, i.e., when predictions are\nconditioned on a low-level context representation encoded from the sequence of\npast observations, as well as on additional inputs (e.g., port of departure or\narrival) about the vessel's high-level intention, which may be available from\nAIS.",
          "link": "http://arxiv.org/abs/2101.02486",
          "publishedOn": "2021-06-07T03:06:13.075Z",
          "wordCount": 714,
          "title": "Deep Learning Methods for Vessel Trajectory Prediction based on Recurrent Neural Networks. (arXiv:2101.02486v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1\">Larissa T. Triess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1\">Mariella Dreissig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1\">Christoph B. Rist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.",
          "link": "http://arxiv.org/abs/2106.02377",
          "publishedOn": "2021-06-07T03:06:13.061Z",
          "wordCount": 642,
          "title": "A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1\">Dyah Adila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1\">Zach Zaiman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1\">Genevieve B. Melton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1\">Nicholas Ingraham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1\">Eric Murray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1\">Daniel Boley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1\">Sean Switzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John L. Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1\">Tadashi Allen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1\">Scott D. Steenburg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1\">Judy Wawira Gichoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1\">Erich Kummerfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1\">Christopher Tignanelli</a>",
          "description": "Importance: An artificial intelligence (AI)-based model to predict COVID-19\nlikelihood from chest x-ray (CXR) findings can serve as an important adjunct to\naccelerate immediate clinical decision making and improve clinical decision\nmaking. Despite significant efforts, many limitations and biases exist in\npreviously developed AI diagnostic models for COVID-19. Utilizing a large set\nof local and international CXR images, we developed an AI model with high\nperformance on temporal and external validation.\n\nConclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,\nbut not replacement, for clinical decision support of COVID-19 diagnosis, which\nlargely hinges on exposure history, signs, and symptoms. While AI-based tools\nhave not yet reached full diagnostic potential in COVID-19, they may still\noffer valuable information to clinicians taken into consideration along with\nclinical signs and symptoms.",
          "link": "http://arxiv.org/abs/2106.02118",
          "publishedOn": "2021-06-07T03:06:13.030Z",
          "wordCount": 670,
          "title": "A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Timm Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1\">Martin Mundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1\">Iuliia Pliushch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1\">Visvanathan Ramesh</a>",
          "description": "Several families of continual learning techniques have been proposed to\nalleviate catastrophic interference in deep neural network training on\nnon-stationary data. However, a comprehensive comparison and analysis of\nlimitations remains largely open due to the inaccessibility to suitable\ndatasets. Empirical examination not only varies immensely between individual\nworks, it further currently relies on contrived composition of benchmarks\nthrough subdivision and concatenation of various prevalent static vision\ndatasets. In this work, our goal is to bridge this gap by introducing a\ncomputer graphics simulation framework that repeatedly renders only upcoming\nurban scene fragments in an endless real-time procedural world generation\nprocess. At its core lies a modular parametric generative model with adaptable\ngenerative factors. The latter can be used to flexibly compose data streams,\nwhich significantly facilitates a detailed analysis and allows for effortless\ninvestigation of various continual learning schemes.",
          "link": "http://arxiv.org/abs/2106.02585",
          "publishedOn": "2021-06-07T03:06:13.009Z",
          "wordCount": 576,
          "title": "A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batra_H/0/1/0/all/0/1\">Himanshu Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1\">Narinder Singh Punn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Sentiment analysis can provide a suitable lead for the tools used in software\nengineering along with the API recommendation systems and relevant libraries to\nbe used. In this context, the existing tools like SentiCR, SentiStrength-SE,\netc. exhibited low f1-scores that completely defeats the purpose of deployment\nof such strategies, thereby there is enough scope of performance improvement.\nRecent advancements show that transformer based pre-trained models (e.g., BERT,\nRoBERTa, ALBERT, etc.) have displayed better results in the text classification\ntask. Following this context, the present research explores different\nBERT-based models to analyze the sentences in GitHub comments, Jira comments,\nand Stack Overflow posts. The paper presents three different strategies to\nanalyse BERT based model for sentiment analysis, where in the first strategy\nthe BERT based pre-trained models are fine-tuned; in the second strategy an\nensemble model is developed from BERT variants; and in the third strategy a\ncompressed model (Distil BERT) is used. The experimental results show that the\nBERT based ensemble approach and the compressed BERT model attain improvements\nby 6-12% over prevailing tools for the F1 measure on all three datasets.",
          "link": "http://arxiv.org/abs/2106.02581",
          "publishedOn": "2021-06-07T03:06:13.003Z",
          "wordCount": 613,
          "title": "BERT based sentiment analysis: A software engineering perspective. (arXiv:2106.02581v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:12.981Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Ratnajit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1\">Haris Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1\">Shabbir Marzban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1\">Ahmed Badar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1\">Terence Brouns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1\">Shruthi Gowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.",
          "link": "http://arxiv.org/abs/2106.02567",
          "publishedOn": "2021-06-07T03:06:12.953Z",
          "wordCount": 575,
          "title": "AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kress_V/0/1/0/all/0/1\">Viktor Kress</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeske_F/0/1/0/all/0/1\">Fabian Jeske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1\">Stefan Zernetsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1\">Konrad Doll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Bernhard Sick</a>",
          "description": "In this article, an approach for probabilistic trajectory forecasting of\nvulnerable road users (VRUs) is presented, which considers past movements and\nthe surrounding scene. Past movements are represented by 3D poses reflecting\nthe posture and movements of individual body parts. The surrounding scene is\nmodeled in the form of semantic maps showing, e.g., the course of streets,\nsidewalks, and the occurrence of obstacles. The forecasts are generated in\ngrids discretizing the space and in the form of arbitrary discrete probability\ndistributions. The distributions are evaluated in terms of their reliability,\nsharpness, and positional accuracy. We compare our method with an approach that\nprovides forecasts in the form of Gaussian distributions and discuss the\nrespective advantages and disadvantages. Thereby, we investigate the impact of\nusing poses and semantic maps. With a technique called spatial label smoothing,\nour approach achieves reliable forecasts. Overall, the poses have a positive\nimpact on the forecasts. The semantic maps offer the opportunity to adapt the\nprobability distributions to the individual situation, although at the\nconsidered forecasted time horizon of 2.52 s they play a minor role compared to\nthe past movements of the VRU. Our method is evaluated on a dataset recorded in\ninner-city traffic using a research vehicle. The dataset is made publicly\navailable.",
          "link": "http://arxiv.org/abs/2106.02598",
          "publishedOn": "2021-06-07T03:06:12.938Z",
          "wordCount": 648,
          "title": "Pose and Semantic Map Based Probabilistic Forecast of Vulnerable Road Users' Trajectories. (arXiv:2106.02598v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02599",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_K/0/1/0/all/0/1\">Kuan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_H/0/1/0/all/0/1\">Haoji Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Philbrick_K/0/1/0/all/0/1\">Kenneth Philbrick</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Conte_G/0/1/0/all/0/1\">Gian Marco Conte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sobek_J/0/1/0/all/0/1\">Joseph D. Sobek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rouzrokh_P/0/1/0/all/0/1\">Pouria Rouzrokh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Erickson_B/0/1/0/all/0/1\">Bradley J. Erickson</a>",
          "description": "There is a growing demand for high-resolution (HR) medical images in both the\nclinical and research applications. Image quality is inevitably traded off with\nthe acquisition time for better patient comfort, lower examination costs, dose,\nand fewer motion-induced artifacts. For many image-based tasks, increasing the\napparent resolution in the perpendicular plane to produce multi-planar\nreformats or 3D images is commonly used. Single image super-resolution (SR) is\na promising technique to provide HR images based on unsupervised learning to\nincrease resolution of a 2D image, but there are few reports on 3D SR. Further,\nperceptual loss is proposed in the literature to better capture the textual\ndetails and edges than using pixel-wise loss functions, by comparing the\nsemantic distances in the high-dimensional feature space of a pre-trained 2D\nnetwork (e.g., VGG). However, it is not clear how one should generalize it to\n3D medical images, and the attendant implications are still unclear. In this\npaper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using\nPerceptual-tuned Generative Adversarial Network (GAN), in order to produce\nthinner slice (e.g., high resolution in the 'Z' plane) medical images with\nanti-aliasing and deblurring. The proposed method outperforms other\nconventional resolution-enhancement methods and previous SR work on medical\nimages upon both qualitative and quantitative comparisons. Specifically, we\nexamine the model in terms of its generalization for various SR ratios and\nimaging modalities. By addressing those limitations, our model shows promise as\na novel 3D SR interpolation technique, providing potential applications in both\nclinical and research settings.",
          "link": "http://arxiv.org/abs/2106.02599",
          "publishedOn": "2021-06-07T03:06:12.928Z",
          "wordCount": 699,
          "title": "SOUP-GAN: Super-Resolution MRI Using Generative Adversarial Networks. (arXiv:2106.02599v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fangqiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fuling Lin</a>",
          "description": "Prior correlation filter (CF)-based tracking methods for unmanned aerial\nvehicles (UAVs) have virtually focused on tracking in the daytime. However,\nwhen the night falls, the trackers will encounter more harsh scenes, which can\neasily lead to tracking failure. In this regard, this work proposes a novel\ntracker with anti-dark function (ADTrack). The proposed method integrates an\nefficient and effective low-light image enhancer into a CF-based tracker.\nBesides, a target-aware mask is simultaneously generated by virtue of image\nillumination variation. The target-aware mask can be applied to jointly train a\ntarget-focused filter that assists the context filter for robust tracking.\nSpecifically, ADTrack adopts dual regression, where the context filter and the\ntarget-focused filter restrict each other for dual filter learning. Exhaustive\nexperiments are conducted on typical dark sceneries benchmark, consisting of 37\ntypical night sequences from authoritative benchmarks, i.e., UAVDark, and our\nnewly constructed benchmark UAVDark70. The results have shown that ADTrack\nfavorably outperforms other state-of-the-art trackers and achieves a real-time\nspeed of 34 frames/s on a single CPU, greatly extending robust UAV tracking to\nnight scenes.",
          "link": "http://arxiv.org/abs/2106.02495",
          "publishedOn": "2021-06-07T03:06:12.845Z",
          "wordCount": 619,
          "title": "ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking. (arXiv:2106.02495v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1\">Marcello Carioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1\">Christian Etmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1\">Soroosh Afyouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1\">Zoe Kourtzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola Bibiane Sch&#xf6;nlieb</a>",
          "description": "We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.",
          "link": "http://arxiv.org/abs/2106.02531",
          "publishedOn": "2021-06-07T03:06:12.818Z",
          "wordCount": 546,
          "title": "CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1\">Chenjie Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yuxin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengrong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chengming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">XiangYang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>",
          "description": "Recently, AutoRegressive (AR) models for the whole image generation empowered\nby transformers have achieved comparable or even better performance to\nGenerative Adversarial Networks (GANs). Unfortunately, directly applying such\nAR models to edit/change local image regions, may suffer from the problems of\nmissing global information, slow inference speed, and information leakage of\nlocal guidance. To address these limitations, we propose a novel model -- image\nLocal Autoregressive Transformer (iLAT), to better facilitate the locally\nguided image synthesis. Our iLAT learns the novel local discrete\nrepresentations, by the newly proposed local autoregressive (LA) transformer of\nthe attention mask and convolution mechanism. Thus iLAT can efficiently\nsynthesize the local image regions by key guidance information. Our iLAT is\nevaluated on various locally guided image syntheses, such as pose-guided person\nimage synthesis and face editing. Both the quantitative and qualitative results\nshow the efficacy of our model.",
          "link": "http://arxiv.org/abs/2106.02514",
          "publishedOn": "2021-06-07T03:06:12.805Z",
          "wordCount": 579,
          "title": "The Image Local Autoregressive Transformer. (arXiv:2106.02514v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Fangyun Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Stephen Lin</a>",
          "description": "Image-level contrastive representation learning has proven to be highly\neffective as a generic model for transfer learning. Such generality for\ntransfer learning, however, sacrifices specificity if we are interested in a\ncertain downstream task. We argue that this could be sub-optimal and thus\nadvocate a design principle which encourages alignment between the\nself-supervised pretext task and the downstream task. In this paper, we follow\nthis principle with a pretraining method specifically designed for the task of\nobject detection. We attain alignment in the following three aspects: 1)\nobject-level representations are introduced via selective search bounding boxes\nas object proposals; 2) the pretraining network architecture incorporates the\nsame dedicated modules used in the detection pipeline (e.g. FPN); 3) the\npretraining is equipped with object detection properties such as object-level\ntranslation invariance and scale invariance. Our method, called Selective\nObject COntrastive learning (SoCo), achieves state-of-the-art results for\ntransfer performance on COCO detection using a Mask R-CNN framework. Code and\nmodels will be made available.",
          "link": "http://arxiv.org/abs/2106.02637",
          "publishedOn": "2021-06-07T03:06:12.731Z",
          "wordCount": 594,
          "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning. (arXiv:2106.02637v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1\">Fangao Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tiancai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yichen Wei</a>",
          "description": "In this paper, we propose an end-to-end framework for instance segmentation.\nBased on the recently introduced DETR [1], our method, termed SOLQ, segments\nobjects by learning unified queries. In SOLQ, each query represents one object\nand has multiple representations: class, location and mask. The object queries\nlearned perform classification, box regression and mask encoding simultaneously\nin an unified vector form. During training phase, the mask vectors encoded are\nsupervised by the compression coding of raw spatial masks. In inference time,\nmask vectors produced can be directly transformed to spatial masks by the\ninverse process of compression coding. Experimental results show that SOLQ can\nachieve state-of-the-art performance, surpassing most of existing approaches.\nMoreover, the joint learning of unified query representation can greatly\nimprove the detection performance of original DETR. We hope our SOLQ can serve\nas a strong baseline for the Transformer-based instance segmentation. Code is\navailable at https://github.com/megvii-research/SOLQ.",
          "link": "http://arxiv.org/abs/2106.02351",
          "publishedOn": "2021-06-07T03:06:12.724Z",
          "wordCount": 587,
          "title": "SOLQ: Segmenting Objects by Learning Queries. (arXiv:2106.02351v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:12.717Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fusen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jun Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>",
          "description": "The existing crowd counting methods usually adopted attention mechanism to\ntackle background noise, or applied multi-level features or multi-scales\ncontext fusion to tackle scale variation. However, these approaches deal with\nthese two problems separately. In this paper, we propose a Hybrid Attention\nNetwork (HAN) by employing Progressive Embedding Scale-context (PES)\ninformation, which enables the network to simultaneously suppress noise and\nadapt head scale variation. We build the hybrid attention mechanism through\nparalleling spatial attention and channel attention module, which makes the\nnetwork to focus more on the human head area and reduce the interference of\nbackground objects. Besides, we embed certain scale-context to the hybrid\nattention along the spatial and channel dimensions for alleviating these\ncounting errors caused by the variation of perspective and head scale. Finally,\nwe propose a progressive learning strategy through cascading multiple hybrid\nattention modules with embedding different scale-context, which can gradually\nintegrate different scale-context information into the current feature map from\nglobal to local. Ablation experiments provides that the network architecture\ncan gradually learn multi-scale features and suppress background noise.\nExtensive experiments demonstrate that HANet obtain state-of-the-art counting\nperformance on four mainstream datasets.",
          "link": "http://arxiv.org/abs/2106.02324",
          "publishedOn": "2021-06-07T03:06:12.699Z",
          "wordCount": 626,
          "title": "Hybrid attention network based on progressive embedding scale-context for crowd counting. (arXiv:2106.02324v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changhao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "GasHisSDB is a New Gastric Histopathology Subsize Image Database with a total\nof 245196 images. GasHisSDB is divided into 160*160 pixels sub-database,\n120*120 pixels sub-database and 80*80 pixels sub-database. GasHisSDB is made to\nrealize the function of valuating image classification. In order to prove that\nthe methods of different periods in the field of image classification have\ndiscrepancies on GasHisSDB, we select a variety of classifiers for evaluation.\nSeven classical machine learning classifiers, three CNN classifiers and a novel\ntransformer-based classifier are selected for testing on image classification\ntasks. GasHisSDB is available at the\nURL:https://github.com/NEUhwm/GasHisSDB.git.",
          "link": "http://arxiv.org/abs/2106.02473",
          "publishedOn": "2021-06-07T03:06:12.678Z",
          "wordCount": 553,
          "title": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for Classification Algorithm Test: from Linear Regression to Visual Transformer. (arXiv:2106.02473v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02385",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_Z/0/1/0/all/0/1\">Zhe Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bianco_F/0/1/0/all/0/1\">Fernando J. Bianco</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1\">Qianye Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rodell_R/0/1/0/all/0/1\">Rachael Rodell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_W/0/1/0/all/0/1\">Wen Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barratt_D/0/1/0/all/0/1\">Dean Barratt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yipeng Hu</a>",
          "description": "Prostate cancer (PCa) is one of the leading causes of death for men\nworldwide. Multi-parametric magnetic resonance (mpMR) imaging has emerged as a\nnon-invasive diagnostic tool for detecting and localising prostate tumours by\nspecialised radiologists. These radiological examinations, for example, for\ndifferentiating malignant lesions from benign prostatic hyperplasia in\ntransition zones and for defining the boundaries of clinically significant\ncancer, remain challenging and highly skill-and-experience-dependent. We first\ninvestigate experimental results in developing object detection neural networks\nthat are trained to predict the radiological assessment, using these\nhigh-variance labels. We further argue that such a computer-assisted diagnosis\n(CAD) system needs to have the ability to control the false-positive rate (FPR)\nor false-negative rate (FNR), in order to be usefully deployed in a clinical\nworkflow, informing clinical decisions without further human intervention. This\nwork proposes a novel PCa detection network that incorporates a lesion-level\ncost-sensitive loss and an additional slice-level loss based on a\nlesion-to-slice mapping function, to manage the lesion- and slice-level costs,\nrespectively. Our experiments based on 290 clinical patients concludes that 1)\nThe lesion-level FNR was effectively reduced from 0.19 to 0.10 and the\nlesion-level FPR was reduced from 1.03 to 0.66 by changing the lesion-level\ncost; 2) The slice-level FNR was reduced from 0.19 to 0.00 by taking into\naccount the slice-level cost; (3) Both lesion-level and slice-level FNRs were\nreduced with lower FP/FPR by changing the lesion-level or slice-level costs,\ncompared with post-training threshold adjustment using networks without the\nproposed cost-aware training.",
          "link": "http://arxiv.org/abs/2106.02385",
          "publishedOn": "2021-06-07T03:06:12.649Z",
          "wordCount": 713,
          "title": "Controlling False Positive/Negative Rates for Deep-Learning-Based Prostate Cancer Detection on Multiparametric MR images. (arXiv:2106.02385v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1\">Sasha Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amanpreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1\">Jose Alberto Lopez Magana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1\">Wojciech Galuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.",
          "link": "http://arxiv.org/abs/2106.02280",
          "publishedOn": "2021-06-07T03:06:12.620Z",
          "wordCount": 575,
          "title": "Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Liying Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_X/0/1/0/all/0/1\">Xin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiangbo Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>",
          "description": "Reference-based image super-resolution (RefSR) has shown promising success in\nrecovering high-frequency details by utilizing an external reference image\n(Ref). In this task, texture details are transferred from the Ref image to the\nlow-resolution (LR) image according to their point- or patch-wise\ncorrespondence. Therefore, high-quality correspondence matching is critical. It\nis also desired to be computationally efficient. Besides, existing RefSR\nmethods tend to ignore the potential large disparity in distributions between\nthe LR and Ref images, which hurts the effectiveness of the information\nutilization. In this paper, we propose the MASA network for RefSR, where two\nnovel modules are designed to address these problems. The proposed Match &\nExtraction Module significantly reduces the computational cost by a\ncoarse-to-fine correspondence matching scheme. The Spatial Adaptation Module\nlearns the difference of distribution between the LR and Ref images, and remaps\nthe distribution of Ref features to that of LR features in a spatially adaptive\nway. This scheme makes the network robust to handle different reference images.\nExtensive quantitative and qualitative experiments validate the effectiveness\nof our proposed model.",
          "link": "http://arxiv.org/abs/2106.02299",
          "publishedOn": "2021-06-07T03:06:12.614Z",
          "wordCount": 616,
          "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution. (arXiv:2106.02299v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Seokju Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sunghwan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1\">Sangryul Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunsung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kwanghoon Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungryong Kim</a>",
          "description": "We propose a novel cost aggregation network, called Cost Aggregation with\nTransformers (CATs), to find dense correspondences between semantically similar\nimages with additional challenges posed by large intra-class appearance and\ngeometric variations. Compared to previous hand-crafted or CNN-based methods\naddressing the cost aggregation stage, which either lack robustness to severe\ndeformations or inherit the limitation of CNNs that fail to discriminate\nincorrect matches due to limited receptive fields, CATs explore global\nconsensus among initial correlation map with the help of some architectural\ndesigns that allow us to exploit full potential of self-attention mechanism.\nSpecifically, we include appearance affinity modelling to disambiguate the\ninitial correlation maps and multi-level aggregation to benefit from\nhierarchical feature representations within Transformer-based aggregator, and\ncombine with swapping self-attention and residual connections not only to\nenforce consistent matching, but also to ease the learning process. We conduct\nexperiments to demonstrate the effectiveness of the proposed model over the\nlatest methods and provide extensive ablation studies. Code and trained models\nwill be made available at https://github.com/SunghwanHong/CATs.",
          "link": "http://arxiv.org/abs/2106.02520",
          "publishedOn": "2021-06-07T03:06:12.593Z",
          "wordCount": 608,
          "title": "Semantic Correspondence with Transformers. (arXiv:2106.02520v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1\">Osman Semih Kayhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1\">Bart Vredebregt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.",
          "link": "http://arxiv.org/abs/2106.02523",
          "publishedOn": "2021-06-07T03:06:12.586Z",
          "wordCount": 570,
          "title": "Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrahamsen_M/0/1/0/all/0/1\">Mikkel Abrahamsen</a>",
          "description": "In the MINIMUM CONVEX COVER (MCC) problem, we are given a simple polygon\n$\\mathcal P$ and an integer $k$, and the question is if there exist $k$ convex\npolygons whose union is $\\mathcal P$. It is known that MCC is\n$\\mathsf{NP}$-hard [Culberson & Reckhow: Covering polygons is hard, FOCS\n1988/Journal of Algorithms 1994] and in $\\exists\\mathbb{R}$ [O'Rourke: The\ncomplexity of computing minimum convex covers for polygons, Allerton 1982]. We\nprove that MCC is $\\exists\\mathbb{R}$-hard, and the problem is thus\n$\\exists\\mathbb{R}$-complete. In other words, the problem is equivalent to\ndeciding whether a system of polynomial equations and inequalities with integer\ncoefficients has a real solution.\n\nIf a cover for our constructed polygon exists, then so does a cover\nconsisting entirely of triangles. As a byproduct, we therefore also establish\nthat it is $\\exists\\mathbb{R}$-complete to decide whether $k$ triangles cover a\ngiven polygon.\n\nThe issue that it was not known if finding a minimum cover is in\n$\\mathsf{NP}$ has repeatedly been raised in the literature, and it was\nmentioned as a \"long-standing open question\" already in 2001 [Eidenbenz &\nWidmayer: An approximation algorithm for minimum convex cover with logarithmic\nperformance guarantee, ESA 2001/SIAM Journal on Computing 2003]. We prove that\nassuming the widespread belief that $\\mathsf{NP}\\neq\\exists\\mathbb{R}$, the\nproblem is not in $\\mathsf{NP}$.\n\nAn implication of the result is that many natural approaches to finding small\ncovers are bound to give suboptimal solutions in some cases, since irrational\ncoordinates of arbitrarily high algebraic degree can be needed for the corners\nof the pieces in an optimal solution.",
          "link": "http://arxiv.org/abs/2106.02335",
          "publishedOn": "2021-06-07T03:06:12.579Z",
          "wordCount": 684,
          "title": "Covering Polygons is Even Harder. (arXiv:2106.02335v1 [cs.CG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tongqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1\">Qing Su</a>",
          "description": "Accurate localization is of crucial importance for autonomous driving tasks.\nNowadays, we have seen a lot of sensor-rich vehicles (e.g. Robo-taxi) driving\non the street autonomously, which rely on high-accurate sensors (e.g. Lidar and\nRTK GPS) and high-resolution map. However, low-cost production cars cannot\nafford such high expenses on sensors and maps. How to reduce costs? How do\nsensor-rich vehicles benefit low-cost cars? In this paper, we proposed a\nlight-weight localization solution, which relies on low-cost cameras and\ncompact visual semantic maps. The map is easily produced and updated by\nsensor-rich vehicles in a crowd-sourced way. Specifically, the map consists of\nseveral semantic elements, such as lane line, crosswalk, ground sign, and stop\nline on the road surface. We introduce the whole framework of on-vehicle\nmapping, on-cloud maintenance, and user-end localization. The map data is\ncollected and preprocessed on vehicles. Then, the crowd-sourced data is\nuploaded to a cloud server. The mass data from multiple vehicles are merged on\nthe cloud so that the semantic map is updated in time. Finally, the semantic\nmap is compressed and distributed to production cars, which use this map for\nlocalization. We validate the performance of the proposed map in real-world\nexperiments and compare it against other algorithms. The average size of the\nsemantic map is $36$ kb/km. We highlight that this framework is a reliable and\npractical localization solution for autonomous driving.",
          "link": "http://arxiv.org/abs/2106.02527",
          "publishedOn": "2021-06-07T03:06:12.572Z",
          "wordCount": 679,
          "title": "RoadMap: A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving. (arXiv:2106.02527v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1\">Thangapavithraa Balaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1\">Patrick Blies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1\">Georg G&#xf6;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1\">Raphael Mitsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1\">Marcel Wasserer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Torsten Sch&#xf6;n</a>",
          "description": "This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.",
          "link": "http://arxiv.org/abs/2106.02328",
          "publishedOn": "2021-06-07T03:06:12.565Z",
          "wordCount": 574,
          "title": "Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keaton_M/0/1/0/all/0/1\">Matthew R. Keaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaveri_R/0/1/0/all/0/1\">Ram J. Zaveri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovur_M/0/1/0/all/0/1\">Meghana Kovur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_C/0/1/0/all/0/1\">Cole Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1\">Donald A. Adjeroh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1\">Gianfranco Doretto</a>",
          "description": "Plant species identification in the wild is a difficult problem in part due\nto the high variability of the input data, but also because of complications\ninduced by the long-tail effects of the datasets distribution. Inspired by the\nmost recent fine-grained visual classification approaches which are based on\nattention to mitigate the effects of data variability, we explore the idea of\nusing object detection as a form of attention. We introduce a bottom-up\napproach based on detecting plant organs and fusing the predictions of a\nvariable number of organ-based species classifiers. We also curate a new\ndataset with a long-tail distribution for evaluating plant organ detection and\norgan-based species identification, which is publicly available.",
          "link": "http://arxiv.org/abs/2106.02141",
          "publishedOn": "2021-06-07T03:06:12.546Z",
          "wordCount": 595,
          "title": "Fine-Grained Visual Classification of Plant Species In The Wild: Object Detection as A Reinforced Means of Attention. (arXiv:2106.02141v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1\">Alex D&#xed;az</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1\">Damian Steele</a>",
          "description": "We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.",
          "link": "http://arxiv.org/abs/2106.02213",
          "publishedOn": "2021-06-07T03:06:12.539Z",
          "wordCount": 524,
          "title": "Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiahui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>",
          "description": "Convolutional neural networks (CNNs) have made great breakthroughs in 2D\ncomputer vision. However, the irregular structure of meshes makes it hard to\nexploit the power of CNNs directly. A subdivision surface provides a\nhierarchical multi-resolution structure, and each face in a closed 2-manifold\ntriangle mesh is exactly adjacent to three faces. Motivated by these two\nproperties, this paper introduces a novel and flexible CNN framework, named\nSubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.\nMaking an analogy between mesh faces and pixels in a 2D image allows us to\npresent a mesh convolution operator to aggregate local features from adjacent\nfaces. By exploiting face neighborhoods, this convolution can support standard\n2D convolutional network concepts, e.g. variable kernel size, stride, and\ndilation. Based on the multi-resolution hierarchy, we propose a spatial uniform\npooling layer which merges four faces into one and an upsampling method which\nsplits one face into four. As a result, many popular 2D CNN architectures can\nbe readily adapted to processing 3D meshes. Meshes with arbitrary connectivity\ncan be remeshed to hold Loop subdivision sequence connectivity via\nself-parameterization, making SubdivNet a general approach. Experiments on mesh\nclassification, segmentation, correspondence, and retrieval from the real-world\ndemonstrate the effectiveness and efficiency of SubdivNet.",
          "link": "http://arxiv.org/abs/2106.02285",
          "publishedOn": "2021-06-07T03:06:12.531Z",
          "wordCount": 651,
          "title": "Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1\">Federica Granese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1\">Marco Romanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1\">Daniele Gorla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Deep neural networks (DNNs) have shown to perform very well on large scale\nobject recognition problems and lead to widespread use for real-world\napplications, including situations where DNN are implemented as \"black boxes\".\nA promising approach to secure their use is to accept decisions that are likely\nto be correct while discarding the others. In this work, we propose DOCTOR, a\nsimple method that aims to identify whether the prediction of a DNN classifier\nshould (or should not) be trusted so that, consequently, it would be possible\nto accept it or to reject it. Two scenarios are investigated: Totally Black Box\n(TBB) where only the soft-predictions are available and Partially Black Box\n(PBB) where gradient-propagation to perform input pre-processing is allowed.\nEmpirically, we show that DOCTOR outperforms all state-of-the-art methods on\nvarious well-known images and sentiment analysis datasets. In particular, we\nobserve a reduction of up to $4\\%$ of the false rejection rate (FRR) in the PBB\nscenario. DOCTOR can be applied to any pre-trained model, it does not require\nprior information about the underlying dataset and is as simple as the simplest\navailable methods in the literature.",
          "link": "http://arxiv.org/abs/2106.02395",
          "publishedOn": "2021-06-07T03:06:12.525Z",
          "wordCount": 624,
          "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "This paper investigates how to realize better and more efficient embedding\nlearning to tackle the semi-supervised video object segmentation under\nchallenging multi-object scenarios. The state-of-the-art methods learn to\ndecode features with a single positive object and thus have to match and\nsegment each target separately under multi-object scenarios, consuming multiple\ntimes computing resources. To solve the problem, we propose an Associating\nObjects with Transformers (AOT) approach to match and decode multiple objects\nuniformly. In detail, AOT employs an identification mechanism to associate\nmultiple targets into the same high-dimensional embedding space. Thus, we can\nsimultaneously process the matching and segmentation decoding of multiple\nobjects as efficiently as processing a single object. For sufficiently modeling\nmulti-object association, a Long Short-Term Transformer is designed for\nconstructing hierarchical matching and propagation. We conduct extensive\nexperiments on both multi-object and single-object benchmarks to examine AOT\nvariant networks with different complexities. Particularly, our AOT-L\noutperforms all the state-of-the-art competitors on three popular benchmarks,\ni.e., YouTube-VOS (83.7% J&F), DAVIS 2017 (83.0%), and DAVIS 2016 (91.0%),\nwhile keeping better multi-object efficiency. Meanwhile, our AOT-T can maintain\nreal-time multi-object speed on above benchmarks. We ranked 1st in the 3rd\nLarge-scale Video Object Segmentation Challenge. The code will be publicly\navailable at https://github.com/z-x-yang/AOT.",
          "link": "http://arxiv.org/abs/2106.02638",
          "publishedOn": "2021-06-07T03:06:12.518Z",
          "wordCount": 640,
          "title": "Associating Objects with Transformers for Video Object Segmentation. (arXiv:2106.02638v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Gengwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Guoliang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Few-shot segmentation aims to train a segmentation model that can fast adapt\nto novel classes with few exemplars. The conventional training paradigm is to\nlearn to make predictions on query images conditioned on the features from\nsupport images. Previous methods only utilized the semantic-level prototypes of\nsupport images as the conditional information. These methods cannot utilize all\npixel-wise support information for the query predictions, which is however\ncritical for the segmentation task. In this paper, we focus on utilizing\npixel-wise relationships between support and target images to facilitate the\nfew-shot semantic segmentation task. We design a novel Cycle-Consistent\nTransformer (CyCTR) module to aggregate pixel-wise support features into query\nones. CyCTR performs cross-attention between features from different images,\ni.e. support and query images. We observe that there may exist unexpected\nirrelevant pixel-level support features. Directly performing cross-attention\nmay aggregate these features from support to query and bias the query features.\nThus, we propose using a novel cycle-consistent attention mechanism to filter\nout possible harmful support features and encourage query features to attend to\nthe most informative pixels from support images. Experiments on all few-shot\nsegmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable\nimprovement compared to previous state-of-the-art methods. Specifically, on\nPascal-$5^i$ and COCO-$20^i$ datasets, we achieve 66.6% and 45.6% mIoU for\n5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1%\nrespectively.",
          "link": "http://arxiv.org/abs/2106.02320",
          "publishedOn": "2021-06-07T03:06:12.511Z",
          "wordCount": 646,
          "title": "Few-Shot Segmentation via Cycle-Consistent Transformer. (arXiv:2106.02320v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zekun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zheng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sixiao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yabiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>",
          "description": "Non-Maximum Suppression (NMS) is essential for object detection and affects\nthe evaluation results by incorporating False Positives (FP) and False\nNegatives (FN), especially in crowd occlusion scenes. In this paper, we raise\nthe problem of weak connection between the training targets and the evaluation\nmetrics caused by NMS and propose a novel NMS-Loss making the NMS procedure can\nbe trained end-to-end without any additional network parameters. Our NMS-Loss\npunishes two cases when FP is not suppressed and FN is wrongly eliminated by\nNMS. Specifically, we propose a pull loss to pull predictions with the same\ntarget close to each other, and a push loss to push predictions with different\ntargets away from each other. Experimental results show that with the help of\nNMS-Loss, our detector, namely NMS-Ped, achieves impressive results with Miss\nRate of 5.92% on Caltech dataset and 10.08% on CityPersons dataset, which are\nboth better than state-of-the-art competitors.",
          "link": "http://arxiv.org/abs/2106.02426",
          "publishedOn": "2021-06-07T03:06:12.494Z",
          "wordCount": 591,
          "title": "NMS-Loss: Learning with Non-Maximum Suppression for Crowded Pedestrian Detection. (arXiv:2106.02426v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qihang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yutong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yongyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>",
          "description": "Recently, there emerges a series of vision Transformers, which show superior\nperformance with a more compact model size than conventional convolutional\nneural networks, thanks to the strong ability of Transformers to model\nlong-range dependencies. However, the advantages of vision Transformers also\ncome with a price: Self-attention, the core part of Transformer, has a\nquadratic complexity to the input sequence length. This leads to a dramatic\nincrease of computation and memory cost with the increase of sequence length,\nthus introducing difficulties when applying Transformers to the vision tasks\nthat require dense predictions based on high-resolution feature maps. In this\npaper, we propose a new vision Transformer, named Glance-and-Gaze Transformer\n(GG-Transformer), to address the aforementioned issues. It is motivated by the\nGlance and Gaze behavior of human beings when recognizing objects in natural\nscenes, with the ability to efficiently model both long-range dependencies and\nlocal context. In GG-Transformer, the Glance and Gaze behavior is realized by\ntwo parallel branches: The Glance branch is achieved by performing\nself-attention on the adaptively-dilated partitions of the input, which leads\nto a linear complexity while still enjoying a global receptive field; The Gaze\nbranch is implemented by a simple depth-wise convolutional layer, which\ncompensates local image context to the features obtained by the Glance\nmechanism. We empirically demonstrate our method achieves consistently superior\nperformance over previous state-of-the-art Transformers on various vision tasks\nand benchmarks. The codes and models will be made available at\nhttps://github.com/yucornetto/GG-Transformer.",
          "link": "http://arxiv.org/abs/2106.02277",
          "publishedOn": "2021-06-07T03:06:12.486Z",
          "wordCount": 676,
          "title": "Glance-and-Gaze Vision Transformer. (arXiv:2106.02277v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yingtao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1\">Chikahiko Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses\non the object and style like other artwork researches. Such study has benefited\nfrom the renewed interest by the machine learning community in culturally\nimportant topics, leading to interdisciplinary works including collections of\nimages, quantitative approaches, and machine learning-based creativities. They,\nhowever, have several drawbacks, and it remains challenging to integrate these\nworks into a comprehensive view. To bridge this gap, we propose a holistic\napproach We first present a large-scale Ukiyo-e dataset with coherent semantic\nlabels and geometric annotations, then show its value in a quantitative study\nof Ukiyo-e paintings' object using these labels and annotations. We further\ndemonstrate the machine learning methods could help style study through soft\ncolor decomposition of Ukiyo-e, and finally provides joint insights into object\nand style by composing sketches and colors using colorization. Dataset\navailable at https://github.com/rois-codh/arc-ukiyoe-faces",
          "link": "http://arxiv.org/abs/2106.02267",
          "publishedOn": "2021-06-07T03:06:12.479Z",
          "wordCount": 584,
          "title": "Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "In this extended abstract, we investigate the design of learning\nrepresentation for human intention inference. In our designed human intention\nprediction task, we propose a history encoding representation that is both\ninterpretable and effective for prediction. Through extensive experiments, we\nshow our prediction framework with a history encoding representation design is\nsuccessful on the human intention prediction problem.",
          "link": "http://arxiv.org/abs/2106.02222",
          "publishedOn": "2021-06-07T03:06:12.437Z",
          "wordCount": 484,
          "title": "History Encoding Representation Design for Human Intention Inference. (arXiv:2106.02222v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1\">Yingjie Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1\">Summer Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>",
          "description": "We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.",
          "link": "http://arxiv.org/abs/2106.02229",
          "publishedOn": "2021-06-07T03:06:12.430Z",
          "wordCount": 585,
          "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "Convolution and self-attention are acting as two fundamental building blocks\nin deep neural networks, where the former extracts local image features in a\nlinear way while the latter non-locally encodes high-order contextual\nrelationships. Though essentially complementary to each other, i.e.,\nfirst-/high-order, stat-of-the-art architectures, i.e., CNNs or transformers\nlack a principled way to simultaneously apply both operations in a single\ncomputational module, due to their heterogeneous computing pattern and\nexcessive burden of global dot-product for visual tasks. In this work, we\ntheoretically derive a global self-attention approximation scheme, which\napproximates a self-attention via the convolution operation on transformed\nfeatures. Based on the approximated scheme, we establish a multi-branch\nelementary module composed of both convolution and self-attention operation,\ncapable of unifying both local and non-local feature interaction. Importantly,\nonce trained, this multi-branch module could be conditionally converted into a\nsingle standard convolution operation via structural re-parameterization,\nrendering a pure convolution styled operator named X-volution, ready to be\nplugged into any modern networks as an atomic operation. Extensive experiments\ndemonstrate that the proposed X-volution, achieves highly competitive visual\nunderstanding improvements (+1.2% top-1 accuracy on ImageNet classification,\n+1.7 box AP and +1.5 mask AP on COCO detection and segmentation).",
          "link": "http://arxiv.org/abs/2106.02253",
          "publishedOn": "2021-06-07T03:06:12.423Z",
          "wordCount": 623,
          "title": "X-volution: On the unification of convolution and self-attention. (arXiv:2106.02253v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02198",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fard_A/0/1/0/all/0/1\">Azin Shokraei Fard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reutens_D/0/1/0/all/0/1\">David C. Reutens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vegh_V/0/1/0/all/0/1\">Viktor Vegh</a>",
          "description": "Cross-modality image estimation involves the generation of images of one\nmedical imaging modality from that of another modality. Convolutional neural\nnetworks (CNNs) have been shown to be useful in identifying, characterising and\nextracting image patterns. Generative adversarial networks (GANs) use CNNs as\ngenerators and estimated images are discriminated as true or false based on an\nadditional network. CNNs and GANs within the image estimation framework may be\nconsidered more generally as deep learning approaches, since imaging data tends\nto be large, leading to a larger number of network weights. Almost all research\nin the CNN/GAN image estimation literature has involved the use of MRI data\nwith the other modality primarily being PET or CT. This review provides an\noverview of the use of CNNs and GANs for MRI-based cross-modality medical image\nestimation. We outline the neural networks implemented, and detail network\nconstructs employed for CNN and GAN image-to-image estimators. Motivations\nbehind cross-modality image estimation are provided as well. GANs appear to\nprovide better utility in cross-modality image estimation in comparison with\nCNNs, a finding drawn based on our analysis involving metrics comparing\nestimated and actual images. Our final remarks highlight key challenges faced\nby the cross-modality medical image estimation field, and suggestions for\nfuture research are outlined.",
          "link": "http://arxiv.org/abs/2106.02198",
          "publishedOn": "2021-06-07T03:06:12.417Z",
          "wordCount": 647,
          "title": "CNNs and GANs in MRI-based cross-modality medical image estimation. (arXiv:2106.02198v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiayi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xilian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.",
          "link": "http://arxiv.org/abs/2106.02257",
          "publishedOn": "2021-06-07T03:06:12.399Z",
          "wordCount": 596,
          "title": "Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Deng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Dongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhihua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangmiao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1\">Errui Ding</a>",
          "description": "We study self-supervised video representation learning, which is a\nchallenging task due to 1) a lack of labels for explicit supervision and 2)\nunstructured and noisy visual information. Existing methods mainly use\ncontrastive loss with video clips as the instances and learn visual\nrepresentation by discriminating instances from each other, but they require\ncareful treatment of negative pairs by relying on large batch sizes, memory\nbanks, extra modalities, or customized mining strategies, inevitably including\nnoisy data. In this paper, we observe that the consistency between positive\nsamples is the key to learn robust video representations. Specifically, we\npropose two tasks to learn the appearance and speed consistency, separately.\nThe appearance consistency task aims to maximize the similarity between two\nclips of the same video with different playback speeds. The speed consistency\ntask aims to maximize the similarity between two clips with the same playback\nspeed but different appearance information. We show that joint optimization of\nthe two tasks consistently improves the performance on downstream tasks, e.g.,\naction recognition and video retrieval. Remarkably, for action recognition on\nthe UCF-101 dataset, we achieve 90.8% accuracy without using any additional\nmodalities or negative pairs for unsupervised pretraining, outperforming the\nImageNet supervised pre-trained model. Codes and models will be available.",
          "link": "http://arxiv.org/abs/2106.02342",
          "publishedOn": "2021-06-07T03:06:12.392Z",
          "wordCount": 648,
          "title": "ASCNet: Self-supervised Video Representation Learning with Appearance-Speed Consistency. (arXiv:2106.02342v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shangfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yanan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_G/0/1/0/all/0/1\">Guozhu Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1\">Bowen Pan</a>",
          "description": "Current works formulate facial action unit (AU) recognition as a supervised\nlearning problem, requiring fully AU-labeled facial images during training. It\nis challenging if not impossible to provide AU annotations for large numbers of\nfacial images. Fortunately, AUs appear on all facial images, whether manually\nlabeled or not, satisfy the underlying anatomic mechanisms and human behavioral\nhabits. In this paper, we propose a deep semi-supervised framework for facial\naction unit recognition from partially AU-labeled facial images. Specifically,\nthe proposed deep semi-supervised AU recognition approach consists of a deep\nrecognition network and a discriminator D. The deep recognition network R\nlearns facial representations from large-scale facial images and AU classifiers\nfrom limited ground truth AU labels. The discriminator D is introduced to\nenforce statistical similarity between the AU distribution inherent in ground\ntruth AU labels and the distribution of the predicted AU labels from labeled\nand unlabeled facial images. The deep recognition network aims to minimize\nrecognition loss from the labeled facial images, to faithfully represent\ninherent AU distribution for both labeled and unlabeled facial images, and to\nconfuse the discriminator. During training, the deep recognition network R and\nthe discriminator D are optimized alternately. Thus, the inherent AU\ndistributions caused by underlying anatomic mechanisms are leveraged to\nconstruct better feature representations and AU classifiers from partially\nAU-labeled data during training. Experiments on two benchmark databases\ndemonstrate that the proposed approach successfully captures AU distributions\nthrough adversarial learning and outperforms state-of-the-art AU recognition\nwork.",
          "link": "http://arxiv.org/abs/2106.02258",
          "publishedOn": "2021-06-07T03:06:12.385Z",
          "wordCount": 677,
          "title": "Exploring Adversarial Learning for Deep Semi-Supervised Facial Action Unit Recognition. (arXiv:2106.02258v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02221",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jimenez_Martin_L/0/1/0/all/0/1\">Lauren Jimenez-Martin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Perez_D/0/1/0/all/0/1\">Daniel A. Vald&#xe9;s P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asteasuainzarra_A/0/1/0/all/0/1\">Ana M. Solares Asteasuainzarra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Leonard_L/0/1/0/all/0/1\">Ludwig Leonard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diaz_Romanach_M/0/1/0/all/0/1\">Marta L. Baguer D&#xed;az-Roma&#xf1;ach</a>",
          "description": "Cervical cancer is a malignant tumor that seriously threatens women's health,\nand is one of the most common that affects women worldwide. For its early\ndetection, colposcopic images of the cervix are used for searching for possible\ninjuries or abnormalities. An inherent characteristic of these images is the\npresence of specular reflections (brightness) that make it difficult to observe\nsome regions, which might imply a misdiagnosis. In this paper, a new strategy\nbased on neural networks is introduced for eliminating specular reflections and\nestimating the unobserved anatomical cervix portion under the bright zones. We\npresent a supervised learning method, despite not knowing the ground truth from\nthe beginning, based on training a neural network to learn how to restore any\nhidden region of colposcopic images. Once the specular reflections are\nidentified, they are removed from the image and the previously trained network\nis used to fulfill these deleted areas. The quality of the processed images was\nevaluated quantitatively and qualitatively. In 21 of the 22 evaluated images,\nthe detected specular reflections were totally eliminated, whereas, in the\nremaining one, these reflections were almost completely eliminated. The\ndistribution of the colors and the content of the restored images are similar\nto those of the originals. The evaluation carried out by a specialist in Cervix\nPathology concluded that, after eliminating the specular reflections, the\nanatomical and physiological elements of the cervix are observable in the\nrestored images, which facilitates the medical diagnosis of cervical\npathologies. Our method has the potential to improve the early detection of\ncervical cancer.",
          "link": "http://arxiv.org/abs/2106.02221",
          "publishedOn": "2021-06-07T03:06:12.330Z",
          "wordCount": 723,
          "title": "Specular reflections removal in colposcopic images based on neural networks: Supervised training with no ground truth previous knowledge. (arXiv:2106.02221v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varga_L/0/1/0/all/0/1\">Leon Amadeus Varga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1\">Andreas Zell</a>",
          "description": "Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging\ntask. The recordings are mostly sparse and contain only small objects. In this\nwork, we propose a simple tiling method that improves the detection capability\nin the remote sensing case without modifying the model itself. By reducing the\nbackground bias and enabling the usage of higher image resolutions during\ntraining, our method can improve the performance of models substantially. The\nprocedure was validated on three different data sets and outperformed similar\napproaches in performance and speed.",
          "link": "http://arxiv.org/abs/2106.02288",
          "publishedOn": "2021-06-07T03:06:12.301Z",
          "wordCount": 523,
          "title": "Tackling the Background Bias in Sparse Object Detection via Cropped Windows. (arXiv:2106.02288v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1\">Daniela Mihai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>",
          "description": "Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.",
          "link": "http://arxiv.org/abs/2106.02067",
          "publishedOn": "2021-06-07T03:06:12.054Z",
          "wordCount": 588,
          "title": "Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jang_R/0/1/0/all/0/1\">Ryoungwoo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minjee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eun_D/0/1/0/all/0/1\">Da-in Eun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyungjin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jiyeon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>",
          "description": "Evaluating the performance of generative models in image synthesis is a\nchallenging task. Although the Fr\\'echet Inception Distance is a widely\naccepted evaluation metric, it integrates different aspects (e.g., fidelity and\ndiversity) of synthesized images into a single score and assumes the normality\nof embedded vectors. Recent methods such as precision-and-recall and its\nvariants such as density-and-coverage have been developed to separate fidelity\nand diversity based on k-nearest neighborhood methods. In this study, we\npropose an algorithm named barcode, which is inspired by the topological data\nanalysis and is almost free of assumption and hyperparameter selections. In\nextensive experiments on real-world datasets as well as theoretical approach on\nhigh-dimensional normal samples, it was found that the 'usual' normality\nassumption of embedded vectors has several drawbacks. The experimental results\ndemonstrate that barcode outperforms other methods in evaluating fidelity and\ndiversity of GAN outputs. Official codes can be found in\nhttps://github.com/minjeekim00/Barcode.",
          "link": "http://arxiv.org/abs/2106.02207",
          "publishedOn": "2021-06-07T03:06:11.936Z",
          "wordCount": 598,
          "title": "Barcode Method for Generative Model Evaluation driven by Topological Data Analysis. (arXiv:2106.02207v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1\">Fakhri Karray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>",
          "description": "This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.",
          "link": "http://arxiv.org/abs/2106.02154",
          "publishedOn": "2021-06-07T03:06:11.929Z",
          "wordCount": 598,
          "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% in various state-of-the-art adversarially trained models on the\nAutoAttack benchmark, where every small margin of improvement is significant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-07T03:06:11.921Z",
          "wordCount": 601,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.05545",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the effective application of deep learning in computer vision,\nbreakthroughs have been made in the research of super-resolution images\nreconstruction. However, many researches have pointed out that the\ninsufficiency of the neural network extraction on image features may bring the\ndeteriorating of newly reconstructed image. On the other hand, the generated\npictures are sometimes too artificial because of over-smoothing. In order to\nsolve the above problems, we propose a novel self-calibrated convolutional\ngenerative adversarial networks. The generator consists of feature extraction\nand image reconstruction. Feature extraction uses self-calibrated convolutions,\nwhich contains four portions, and each portion has specific functions. It can\nnot only expand the range of receptive fields, but also obtain long-range\nspatial and inter-channel dependencies. Then image reconstruction is performed,\nand finally a super-resolution image is reconstructed. We have conducted\nthorough experiments on different datasets including set5, set14 and BSD100\nunder the SSIM evaluation method. The experimental results prove the\neffectiveness of the proposed network.",
          "link": "http://arxiv.org/abs/2106.05545",
          "publishedOn": "2021-06-11T22:07:42.030Z",
          "wordCount": 607,
          "title": "Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05915",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kamal_U/0/1/0/all/0/1\">Uday Kamal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1\">Mohammad Zunaed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nizam_N/0/1/0/all/0/1\">Nusrat Binta Nizam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1\">Taufiq Hasan</a>",
          "description": "Thoracic disease detection from chest radiographs using deep learning methods\nhas been an active area of research in the last decade. Most previous methods\nattempt to focus on the diseased organs of the image by identifying spatial\nregions responsible for significant contributions to the model's prediction. In\ncontrast, expert radiologists first locate the prominent anatomical structures\nbefore determining if those regions are anomalous. Therefore, integrating\nanatomical knowledge within deep learning models could bring substantial\nimprovement in automatic disease classification. This work proposes an\nanatomy-aware attention-based architecture named Anatomy X-Net, that\nprioritizes the spatial features guided by the pre-identified anatomy regions.\nWe leverage a semi-supervised learning method using the JSRT dataset containing\norgan-level annotation to obtain the anatomical segmentation masks (for lungs\nand heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses\nthe pre-trained DenseNet-121 as the backbone network with two corresponding\nstructured modules, the Anatomy Aware Attention (AAA) and Probabilistic\nWeighted Average Pooling (PWAP), in a cohesive framework for anatomical\nattention learning. Our proposed method sets new state-of-the-art performance\non the official NIH test set with an AUC score of 0.8439, proving the efficacy\nof utilizing the anatomy segmentation knowledge to improve the thoracic disease\nclassification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020\non the Stanford CheXpert dataset, improving on existing methods that\ndemonstrate the generalizability of the proposed framework.",
          "link": "http://arxiv.org/abs/2106.05915",
          "publishedOn": "2021-06-11T22:07:42.006Z",
          "wordCount": 679,
          "title": "Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yi-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kaizhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent work on speech self-supervised learning (speech SSL) demonstrated the\nbenefits of scale in learning rich and transferable representations for\nAutomatic Speech Recognition (ASR) with limited parallel data. It is then\nnatural to investigate the existence of sparse and transferrable subnetworks in\npre-trained speech SSL models that can achieve even better low-resource ASR\nperformance. However, directly applying widely adopted pruning methods such as\nthe Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost\nneeded. Moreover, contrary to what LTH predicts, the discovered subnetworks\nyield minimal performance gain compared to the original dense network. In this\nwork, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes\nsubnetworks for much better ASR performance, while only requiring a single\ndownstream finetuning run. PARP is inspired by our surprising observation that\nsubnetworks pruned for pre-training tasks only needed to be slightly adjusted\nto achieve a sizeable performance boost in downstream ASR tasks. Extensive\nexperiments on low-resource English and multi-lingual ASR show (1) sparse\nsubnetworks exist in pre-trained speech SSL, and (2) the computational\nadvantage and performance gain of PARP over baseline pruning methods. On the\n10min Librispeech split without LM decoding, PARP discovers subnetworks from\nwav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full\nmodel. We demonstrate PARP mitigates performance degradation in cross-lingual\nmask transfer, and investigate the possibility of discovering a single\nsubnetwork for 10 spoken languages in one run.",
          "link": "http://arxiv.org/abs/2106.05933",
          "publishedOn": "2021-06-11T01:42:18.059Z",
          "wordCount": 686,
          "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1\">Devaraja Adiga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1\">Rishabh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1\">Amrith Krishna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>",
          "description": "Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the\nvarious linguistic peculiarities present in the language. The Sanskrit language\nis lexically productive, undergoes euphonic assimilation of phones at the word\nboundaries and exhibits variations in spelling conventions and in\npronunciations. In this work, we propose the first large scale study of\nautomatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact\nof unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR\ndataset for Sanskrit, which faithfully captures several of the linguistic\ncharacteristics expressed by the language. We investigate the role of different\nacoustic model and language model units in ASR systems for Sanskrit. We also\npropose a new modelling unit, inspired by the syllable level unit selection,\nthat captures character sequences from one vowel in the word to the next vowel.\nWe also highlight the importance of choosing graphemic representations for\nSanskrit and show the impact of this choice on word error rates (WER). Finally,\nwe extend these insights from Sanskrit ASR for building ASR systems in two\nother Indic languages, Gujarati and Telugu. For both these languages, our\nexperimental results show that the use of phonetic based graphemic\nrepresentations in ASR results in performance improvements as compared to ASR\nsystems that use native scripts.",
          "link": "http://arxiv.org/abs/2106.05852",
          "publishedOn": "2021-06-11T01:42:18.053Z",
          "wordCount": 685,
          "title": "Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1\">Wouter Van Gansbeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1\">Simon Vandenhende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1\">Stamatios Georgoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Contrastive self-supervised learning has outperformed supervised pretraining\non many downstream tasks like segmentation and object detection. However,\ncurrent methods are still primarily applied to curated datasets like ImageNet.\nIn this paper, we first study how biases in the dataset affect existing\nmethods. Our results show that current contrastive approaches work surprisingly\nwell across: (i) object- versus scene-centric, (ii) uniform versus long-tailed\nand (iii) general versus domain-specific datasets. Second, given the generality\nof the approach, we try to realize further gains with minor modifications. We\nshow that learning additional invariances -- through the use of multi-scale\ncropping, stronger augmentations and nearest neighbors -- improves the\nrepresentations. Finally, we observe that MoCo learns spatially structured\nrepresentations when trained with a multi-crop strategy. The representations\ncan be used for semantic segment retrieval and video instance segmentation\nwithout finetuning. Moreover, the results are on par with specialized models.\nWe hope this work will serve as a useful study for other researchers. The code\nand models will be available at\nhttps://github.com/wvangansbeke/Revisiting-Contrastive-SSL.",
          "link": "http://arxiv.org/abs/2106.05967",
          "publishedOn": "2021-06-11T01:42:18.047Z",
          "wordCount": 617,
          "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stanton_S/0/1/0/all/0/1\">Samuel Stanton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1\">Pavel Izmailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirichenko_P/0/1/0/all/0/1\">Polina Kirichenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Knowledge distillation is a popular technique for training a small student\nnetwork to emulate a larger teacher model, such as an ensemble of networks. We\nshow that while knowledge distillation can improve student generalization, it\ndoes not typically work as it is commonly understood: there often remains a\nsurprisingly large discrepancy between the predictive distributions of the\nteacher and the student, even in cases when the student has the capacity to\nperfectly match the teacher. We identify difficulties in optimization as a key\nreason for why the student is unable to match the teacher. We also show how the\ndetails of the dataset used for distillation play a role in how closely the\nstudent matches the teacher -- and that more closely matching the teacher\nparadoxically does not always lead to better student generalization.",
          "link": "http://arxiv.org/abs/2106.05945",
          "publishedOn": "2021-06-11T01:42:18.029Z",
          "wordCount": 561,
          "title": "Does Knowledge Distillation Really Work?. (arXiv:2106.05945v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the Fetoscopic Placental\nVessel Segmentation and Registration (FetReg) challenge, we present a\nlarge-scale multi-centre dataset for the development of generalized and robust\nsemantic segmentation and video mosaicking algorithms for the fetal environment\nwith a focus on creating drift-free mosaics from long duration fetoscopy\nvideos. In this paper, we provide an overview of the FetReg dataset, challenge\ntasks, evaluation metrics and baseline methods for both segmentation and\nregistration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, which can be modelled and competed for\nthrough our crowd-sourcing initiative of the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-11T01:42:18.023Z",
          "wordCount": 682,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2002.05273",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyu Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhenxun Zhuang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>",
          "description": "Stochastic Gradient Descent (SGD) is a popular tool in training large-scale\nmachine learning models. Its performance, however, is highly variable,\ndepending crucially on the choice of the step sizes. Accordingly, a variety of\nstrategies for tuning the step sizes have been proposed, ranging from\ncoordinate-wise approaches (a.k.a. ``adaptive'' step sizes) to sophisticated\nheuristics to change the step size in each iteration. In this paper, we study\ntwo step size schedules whose power has been repeatedly confirmed in practice:\nthe exponential and the cosine step sizes. For the first time, we provide\ntheoretical support for them proving convergence rates for smooth non-convex\nfunctions, with and without the Polyak-\\L{}ojasiewicz (PL) condition. Moreover,\nwe show the surprising property that these two strategies are \\emph{adaptive}\nto the noise level in the stochastic gradients of PL functions. That is,\ncontrary to polynomial step sizes, they achieve almost optimal performance\nwithout needing to know the noise level nor tuning their hyperparameters based\non it. Finally, we conduct a fair and comprehensive empirical evaluation of\nreal-world datasets with deep learning architectures. Results show that, even\nif only requiring at most two hyperparameters to tune, these two strategies\nbest or match the performance of various finely-tuned state-of-the-art\nstrategies.",
          "link": "http://arxiv.org/abs/2002.05273",
          "publishedOn": "2021-06-11T01:42:18.017Z",
          "wordCount": 671,
          "title": "A Second look at Exponential and Cosine Step Sizes: Simplicity, Adaptivity, and Performance. (arXiv:2002.05273v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_F/0/1/0/all/0/1\">Fuqiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sng_W/0/1/0/all/0/1\">Weicong Sng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fangwen Yu</a>",
          "description": "The advantages of event-sensing over conventional sensors (e.g., higher\ndynamic range, lower time latency, and lower power consumption) have spurred\nresearch into machine learning for event data. Unsurprisingly, deep learning\nhas emerged as a competitive methodology for learning with event sensors; in\ntypical setups, discrete and asynchronous events are first converted into\nframe-like tensors on which standard deep networks can be applied. However,\nover-fitting remains a challenge, particularly since event datasets remain\nsmall relative to conventional datasets (e.g., ImageNet). In this paper, we\nintroduce EventDrop, a new method for augmenting asynchronous event data to\nimprove the generalization of deep models. By dropping events selected with\nvarious strategies, we are able to increase the diversity of training data\n(e.g., to simulate various levels of occlusion). From a practical perspective,\nEventDrop is simple to implement and computationally low-cost. Experiments on\ntwo event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can\nsignificantly improve the generalization performance across a variety of deep\nnetworks.",
          "link": "http://arxiv.org/abs/2106.05836",
          "publishedOn": "2021-06-11T01:42:18.010Z",
          "wordCount": 587,
          "title": "EventDrop: data augmentation for event-based learning. (arXiv:2106.05836v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.13040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longkai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Ying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1\">Li Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenhui Li</a>",
          "description": "Meta-learning has proven to be a powerful paradigm for transferring the\nknowledge from previous tasks to facilitate the learning of a novel task.\nCurrent dominant algorithms train a well-generalized model initialization which\nis adapted to each task via the support set. The crux lies in optimizing the\ngeneralization capability of the initialization, which is measured by the\nperformance of the adapted model on the query set of each task. Unfortunately,\nthis generalization measure, evidenced by empirical results, pushes the\ninitialization to overfit the meta-training tasks, which significantly impairs\nthe generalization and adaptation to novel tasks. To address this issue, we\nactively augment a meta-training task with \"more data\" when evaluating the\ngeneralization. Concretely, we propose two task augmentation methods, including\nMetaMix and Channel Shuffle. MetaMix linearly combines features and labels of\nsamples from both the support and query sets. For each class of samples,\nChannel Shuffle randomly replaces a subset of their channels with the\ncorresponding ones from a different class. Theoretical studies show how task\naugmentation improves the generalization of meta-learning. Moreover, both\nMetaMix and Channel Shuffle outperform state-of-the-art results by a large\nmargin across many datasets and are compatible with existing meta-learning\nalgorithms.",
          "link": "http://arxiv.org/abs/2007.13040",
          "publishedOn": "2021-06-11T01:42:17.993Z",
          "wordCount": 674,
          "title": "Improving Generalization in Meta-learning via Task Augmentation. (arXiv:2007.13040v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1901.11351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsuchiya_T/0/1/0/all/0/1\">Taira Tsuchiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charoenphakdee_N/0/1/0/all/0/1\">Nontawat Charoenphakdee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Ordinal regression is aimed at predicting an ordinal class label. In this\npaper, we consider its semi-supervised formulation, in which we have unlabeled\ndata along with ordinal-labeled data to train an ordinal regressor. There are\nseveral metrics to evaluate the performance of ordinal regression, such as the\nmean absolute error, mean zero-one error, and mean squared error. However, the\nexisting studies do not take the evaluation metric into account, have a\nrestriction on the model choice, and have no theoretical guarantee. To overcome\nthese problems, we propose a novel generic framework for semi-supervised\nordinal regression based on the empirical risk minimization principle that is\napplicable to optimizing all of the metrics mentioned above. Besides, our\nframework has flexible choices of models, surrogate losses, and optimization\nalgorithms without the common geometric assumption on unlabeled data such as\nthe cluster assumption or manifold assumption. We further provide an estimation\nerror bound to show that our risk estimator is consistent. Finally, we conduct\nexperiments to show the usefulness of our framework.",
          "link": "http://arxiv.org/abs/1901.11351",
          "publishedOn": "2021-06-11T01:42:17.987Z",
          "wordCount": 640,
          "title": "Semi-Supervised Ordinal Regression Based on Empirical Risk Minimization. (arXiv:1901.11351v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tam Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1\">Makoto Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A Osborne</a>",
          "description": "Neural architecture search (NAS) automates the design of deep neural\nnetworks. One of the main challenges in searching complex and non-continuous\narchitectures is to compare the similarity of networks that the conventional\nEuclidean metric may fail to capture. Optimal transport (OT) is resilient to\nsuch complex structure by considering the minimal cost for transporting a\nnetwork into another. However, the OT is generally not negative definite which\nmay limit its ability to build the positive-definite kernels required in many\nkernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a\nnegative definite variant of OT, we develop a novel discrepancy for neural\narchitectures, and demonstrate it within a Gaussian process surrogate model for\nthe sequential NAS settings. Furthermore, we derive a novel parallel NAS, using\nquality k-determinantal point process on the GP posterior, to select diverse\nand high-performing architectures from a discrete set of candidates.\nEmpirically, we demonstrate that our TW-based approaches outperform other\nbaselines in both sequential and parallel NAS.",
          "link": "http://arxiv.org/abs/2006.07593",
          "publishedOn": "2021-06-11T01:42:17.982Z",
          "wordCount": 644,
          "title": "Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search. (arXiv:2006.07593v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.13827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Image search can be tackled using deep features from pre-trained\nConvolutional Neural Networks (CNN). The feature map from the last\nconvolutional layer of a CNN encodes descriptive information from which a\ndiscriminative global descriptor can be obtained. We propose a new\nrepresentation of co-occurrences from deep convolutional features to extract\nadditional relevant information from this last convolutional layer. Combining\nthis co-occurrence map with the feature map, we achieve an improved image\nrepresentation. We present two different methods to get the co-occurrence\nrepresentation, the first one based on direct aggregation of activations, and\nthe second one, based on a trainable co-occurrence representation. The image\ndescriptors derived from our methodology improve the performance in very\nwell-known image retrieval datasets as we prove in the experiments.",
          "link": "http://arxiv.org/abs/2003.13827",
          "publishedOn": "2021-06-11T01:42:17.976Z",
          "wordCount": 592,
          "title": "Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Filos_A/0/1/0/all/0/1\">Angelos Filos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1\">Clare Lyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaques_N/0/1/0/all/0/1\">Natasha Jaques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1\">Gregory Farquhar</a>",
          "description": "We study reinforcement learning (RL) with no-reward demonstrations, a setting\nin which an RL agent has access to additional data from the interaction of\nother agents with the same environment. However, it has no access to the\nrewards or goals of these agents, and their objectives and levels of expertise\nmay vary widely. These assumptions are common in multi-agent settings, such as\nautonomous driving. To effectively use this data, we turn to the framework of\nsuccessor features. This allows us to disentangle shared features and dynamics\nof the environment from agent-specific rewards and policies. We propose a\nmulti-task inverse reinforcement learning (IRL) algorithm, called \\emph{inverse\ntemporal difference learning} (ITD), that learns shared state features,\nalongside per-agent successor features and preference vectors, purely from\ndemonstrations without reward labels. We further show how to seamlessly\nintegrate ITD with learning from online environment interactions, arriving at a\nnovel algorithm for reinforcement learning with demonstrations, called $\\Psi\n\\Phi$-learning (pronounced `Sci-Fi'). We provide empirical evidence for the\neffectiveness of $\\Psi \\Phi$-learning as a method for improving RL, IRL,\nimitation, and few-shot transfer, and derive worst-case bounds for its\nperformance in zero-shot transfer to new tasks.",
          "link": "http://arxiv.org/abs/2102.12560",
          "publishedOn": "2021-06-11T01:42:17.970Z",
          "wordCount": 673,
          "title": "PsiPhi-Learning: Reinforcement Learning with Demonstrations using Successor Features and Inverse Temporal Difference Learning. (arXiv:2102.12560v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1\">Arpan Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakkunedeth_A/0/1/0/all/0/1\">Abhilash Rakkunedeth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jack Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boora_N/0/1/0/all/0/1\">Naveenjyote Boora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaremko_J/0/1/0/all/0/1\">Jacob Jaremko</a>",
          "description": "Ultrasound examination for detecting fractures is ideally suited for\nEmergency Departments (ED) as it is relatively fast, safe (from ionizing\nradiation), has dynamic imaging capability and is easily portable. High\ninterobserver variability in manual assessment of ultrasound scans has piqued\nresearch interest in automatic assessment techniques using Deep Learning (DL).\nMost DL techniques are supervised and are trained on large numbers of labeled\ndata which is expensive and requires many hours of careful annotation by\nexperts. In this paper, we propose an unsupervised, domain specific transporter\nframework to identify relevant keypoints from wrist ultrasound scans. Our\nframework provides a concise geometric representation highlighting regions with\nhigh structural variation in a 3D ultrasound (3DUS) sequence. We also\nincorporate domain specific information represented by instantaneous local\nphase (LP) which detects bone features from 3DUS. We validate the technique on\n3DUS videos obtained from 30 subjects. Each ultrasound scan was independently\nassessed by three readers to identify fractures along with the corresponding\nx-ray. Saliency of keypoints detected in the image\\ are compared against manual\nassessment based on distance from relevant features.The transporter neural\nnetwork was able to accurately detect 180 out of 250 bone regions sampled from\nwrist ultrasound videos. We expect this technique to increase the applicability\nof ultrasound in fracture detection.",
          "link": "http://arxiv.org/abs/2106.05929",
          "publishedOn": "2021-06-11T01:42:17.964Z",
          "wordCount": 646,
          "title": "Domain Specific Transporter Framework to Detect Fractures in Ultrasound. (arXiv:2106.05929v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.05554",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loper_J/0/1/0/all/0/1\">Jackson Loper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paninski_L/0/1/0/all/0/1\">Liam Paninski</a>",
          "description": "Gaussian Processes (GPs) provide powerful probabilistic frameworks for\ninterpolation, forecasting, and smoothing, but have been hampered by\ncomputational scaling issues. Here we investigate data sampled on one dimension\n(e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals),\nfor which state-space models are popular due to their linearly-scaling\ncomputational costs. It has long been conjectured that state-space models are\ngeneral, able to approximate any one-dimensional GP. We provide the first\ngeneral proof of this conjecture, showing that any stationary GP on one\ndimension with vector-valued observations governed by a Lebesgue-integrable\ncontinuous kernel can be approximated to any desired precision using a\nspecifically-chosen state-space model: the Latent Exponentially Generated (LEG)\nfamily. This new family offers several advantages compared to the general\nstate-space model: it is always stable (no unbounded growth), the covariance\ncan be computed in closed form, and its parameter space is unconstrained\n(allowing straightforward estimation via gradient descent). The theorem's proof\nalso draws connections to Spectral Mixture Kernels, providing insight about\nthis popular family of kernels. We develop parallelized algorithms for\nperforming inference and learning in the LEG model, test the algorithm on real\nand synthetic data, and demonstrate scaling to datasets with billions of\nsamples.",
          "link": "http://arxiv.org/abs/2003.05554",
          "publishedOn": "2021-06-11T01:42:17.950Z",
          "wordCount": 677,
          "title": "Linear-time inference for Gaussian Processes on one dimension. (arXiv:2003.05554v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Representational learning forms the backbone of most deep learning\napplications, and the value of a learned representation is intimately tied to\nits information content regarding different factors of variation. Finding good\nrepresentations depends on the nature of supervision and the learning\nalgorithm. We propose a novel algorithm that relies on a weak form of\nsupervision where the data is partitioned into sets according to certain\ninactive factors of variation. Our key insight is that by seeking approximate\ncorrespondence between elements of different sets, we learn strong\nrepresentations that exclude the inactive factors of variation and isolate the\nactive factors which vary within all sets. We demonstrate that the method can\nwork in a semi-supervised scenario, and that a portion of the unsupervised data\ncan belong to a different domain entirely. Further control over the content of\nthe learned representations is possible by folding in data augmentation to\nsuppress nuisance factors. We outperform competing baselines on the challenging\nproblem of synthetic-to-real object pose transfer.",
          "link": "http://arxiv.org/abs/2103.03240",
          "publishedOn": "2021-06-11T01:42:17.944Z",
          "wordCount": 628,
          "title": "Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1\">Luisa Zintgraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Leo Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igl_M/0/1/0/all/0/1\">Maximilian Igl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1\">Kristian Hartikainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "To rapidly learn a new task, it is often essential for agents to explore\nefficiently -- especially when performance matters from the first timestep. One\nway to learn such behaviour is via meta-learning. Many existing methods however\nrely on dense rewards for meta-training, and can fail catastrophically if the\nrewards are sparse. Without a suitable reward signal, the need for exploration\nduring meta-training is exacerbated. To address this, we propose HyperX, which\nuses novel reward bonuses for meta-training to explore in approximate\nhyper-state space (where hyper-states represent the environment state and the\nagent's task belief). We show empirically that HyperX meta-learns better\ntask-exploration and adapts more successfully to new tasks than existing\nmethods.",
          "link": "http://arxiv.org/abs/2010.01062",
          "publishedOn": "2021-06-11T01:42:17.939Z",
          "wordCount": 605,
          "title": "Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning. (arXiv:2010.01062v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1\">Kanil Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beluch_W/0/1/0/all/0/1\">William Beluch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambach_K/0/1/0/all/0/1\">Kilian Rambach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cozma_A/0/1/0/all/0/1\">Adriana-Eliza Cozma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_M/0/1/0/all/0/1\">Michael Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>",
          "description": "Deep learning (DL) has recently attracted increasing interest to improve\nobject type classification for automotive radar.In addition to high accuracy,\nit is crucial for decision making in autonomous vehicles to evaluate the\nreliability of the predictions; however, decisions of DL networks are\nnon-transparent. Current DL research has investigated how uncertainties of\npredictions can be quantified, and in this article, we evaluate the potential\nof these methods for safe, automotive radar perception. In particular we\nevaluate how uncertainty quantification can support radar perception under (1)\ndomain shift, (2) corruptions of input signals, and (3) in the presence of\nunknown objects. We find that in agreement with phenomena observed in the\nliterature,deep radar classifiers are overly confident, even in their wrong\npredictions. This raises concerns about the use of the confidence values for\ndecision making under uncertainty, as the model fails to notify when it cannot\nhandle an unknown situation. Accurate confidence values would allow optimal\nintegration of multiple information sources, e.g. via sensor fusion. We show\nthat by applying state-of-the-art post-hoc uncertainty calibration, the quality\nof confidence measures can be significantly improved,thereby partially\nresolving the over-confidence problem. Our investigation shows that further\nresearch into training and calibrating DL networks is necessary and offers\ngreat potential for safe automotive object classification with radar sensors.",
          "link": "http://arxiv.org/abs/2106.05870",
          "publishedOn": "2021-06-11T01:42:17.933Z",
          "wordCount": 661,
          "title": "Investigation of Uncertainty of Deep Learning-based Object Classification on Radar Spectra. (arXiv:2106.05870v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.01903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Biggs_M/0/1/0/all/0/1\">Max Biggs</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ettl_M/0/1/0/all/0/1\">Markus Ettl</a>",
          "description": "Data-driven pricing strategies are becoming increasingly common, where\ncustomers are offered a personalized price based on features that are\npredictive of their valuation of a product. It is desirable for this pricing\npolicy to be simple and interpretable, so it can be verified, checked for\nfairness, and easily implemented. However, efforts to incorporate machine\nlearning into a pricing framework often lead to complex pricing policies which\nare not interpretable, resulting in slow adoption in practice. We present a\ncustomized, prescriptive tree-based algorithm that distills knowledge from a\ncomplex black-box machine learning algorithm, segments customers with similar\nvaluations and prescribes prices in such a way that maximizes revenue while\nmaintaining interpretability. We quantify the regret of a resulting policy and\ndemonstrate its efficacy in applications with both synthetic and real-world\ndatasets.",
          "link": "http://arxiv.org/abs/2007.01903",
          "publishedOn": "2021-06-11T01:42:17.928Z",
          "wordCount": 576,
          "title": "Model Distillation for Revenue Optimization: Interpretable Personalized Pricing. (arXiv:2007.01903v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1\">Ramy E. Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1\">Jinhyun So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_A/0/1/0/all/0/1\">A. Salman Avestimehr</a>",
          "description": "Outsourcing neural network inference tasks to an untrusted cloud raises data\nprivacy and integrity concerns. To address these challenges, several\nprivacy-preserving and verifiable inference techniques have been proposed based\non replacing the non-polynomial activation functions such as the rectified\nlinear unit (ReLU) function with polynomial activation functions. Such\ntechniques usually require polynomials with integer coefficients or polynomials\nover finite fields. Motivated by such requirements, several works proposed\nreplacing the ReLU activation function with the square activation function. In\nthis work, we empirically show that the square function is not the best\ndegree-$2$ polynomial that can replace the ReLU function even when restricting\nthe polynomials to have integer coefficients. We instead propose a degree-$2$\npolynomial activation function with a first order term and empirically show\nthat it can lead to much better models. Our experiments on the CIFAR-$10$ and\nCIFAR-$100$ datasets on various architectures show that our proposed activation\nfunction improves the test accuracy by up to $9.4\\%$ compared to the square\nfunction.",
          "link": "http://arxiv.org/abs/2011.05530",
          "publishedOn": "2021-06-11T01:42:17.907Z",
          "wordCount": 631,
          "title": "On Polynomial Approximations for Privacy-Preserving and Verifiable ReLU Networks. (arXiv:2011.05530v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weijian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Understanding classifier decision under novel environments is central to the\ncommunity, and a common practice is evaluating it on labeled test sets.\nHowever, in real-world testing, image annotations are difficult and expensive\nto obtain, especially when the test environment is changing. A natural question\nthen arises: given a trained classifier, can we evaluate its accuracy on\nvarying unlabeled test sets? In this work, we train semantic classification and\nrotation prediction in a multi-task way. On a series of datasets, we report an\ninteresting finding, i.e., the semantic classification accuracy exhibits a\nstrong linear relationship with the accuracy of the rotation prediction task\n(Pearson's Correlation r > 0.88). This finding allows us to utilize linear\nregression to estimate classifier performance from the accuracy of rotation\nprediction which can be obtained on the test set through the freely generated\nrotation labels.",
          "link": "http://arxiv.org/abs/2106.05961",
          "publishedOn": "2021-06-11T01:42:17.901Z",
          "wordCount": 586,
          "title": "What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05934",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1\">Gurtej Kanwar</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Racaniere_S/0/1/0/all/0/1\">S&#xe9;bastien Racani&#xe8;re</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Rezende_D/0/1/0/all/0/1\">Danilo J. Rezende</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Urban_J/0/1/0/all/0/1\">Julian M. Urban</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1\">Denis Boyda</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1\">Kyle Cranmer</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1\">Daniel C. Hackett</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1\">Phiala E. Shanahan</a>",
          "description": "Algorithms based on normalizing flows are emerging as promising machine\nlearning approaches to sampling complicated probability distributions in a way\nthat can be made asymptotically exact. In the context of lattice field theory,\nproof-of-principle studies have demonstrated the effectiveness of this approach\nfor scalar theories, gauge theories, and statistical systems. This work\ndevelops approaches that enable flow-based sampling of theories with dynamical\nfermions, which is necessary for the technique to be applied to lattice field\ntheory studies of the Standard Model of particle physics and many condensed\nmatter systems. As a practical demonstration, these methods are applied to the\nsampling of field configurations for a two-dimensional theory of massless\nstaggered fermions coupled to a scalar field via a Yukawa interaction.",
          "link": "http://arxiv.org/abs/2106.05934",
          "publishedOn": "2021-06-11T01:42:17.895Z",
          "wordCount": 579,
          "title": "Flow-based sampling for fermionic lattice field theories. (arXiv:2106.05934v1 [hep-lat])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01744",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1\">Antoine Dedieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lazaro_Gredilla_M/0/1/0/all/0/1\">Miguel L&#xe1;zaro-Gredilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+George_D/0/1/0/all/0/1\">Dileep George</a>",
          "description": "We consider the problem of learning the underlying graph of a sparse Ising\nmodel with $p$ nodes from $n$ i.i.d. samples. The most recent and best\nperforming approaches combine an empirical loss (the logistic regression loss\nor the interaction screening loss) with a regularizer (an L1 penalty or an L1\nconstraint). This results in a convex problem that can be solved separately for\neach node of the graph. In this work, we leverage the cardinality constraint L0\nnorm, which is known to properly induce sparsity, and further combine it with\nan L2 norm to better model the non-zero coefficients. We show that our proposed\nestimators achieve an improved sample complexity, both (a) theoretically, by\nreaching new state-of-the-art upper bounds for recovery guarantees, and (b)\nempirically, by showing sharper phase transitions between poor and full\nrecovery for graph topologies studied in the literature, when compared to their\nL1-based state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2012.01744",
          "publishedOn": "2021-06-11T01:42:17.884Z",
          "wordCount": 603,
          "title": "Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models. (arXiv:2012.01744v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Groll_A/0/1/0/all/0/1\">Andreas Groll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvattum_L/0/1/0/all/0/1\">Lars Magnus Hvattum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ley_C/0/1/0/all/0/1\">Christophe Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popp_F/0/1/0/all/0/1\">Franziska Popp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schauberger_G/0/1/0/all/0/1\">Gunther Schauberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eetvelde_H/0/1/0/all/0/1\">Hans Van Eetvelde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeileis_A/0/1/0/all/0/1\">Achim Zeileis</a>",
          "description": "Three state-of-the-art statistical ranking methods for forecasting football\nmatches are combined with several other predictors in a hybrid machine learning\nmodel. Namely an ability estimate for every team based on historic matches; an\nability estimate for every team based on bookmaker consensus; average\nplus-minus player ratings based on their individual performances in their home\nclubs and national teams; and further team covariates (e.g., market value, team\nstructure) and country-specific socio-economic factors (population, GDP). The\nproposed combined approach is used for learning the number of goals scored in\nthe matches from the four previous UEFA EUROs 2004-2016 and then applied to\ncurrent information to forecast the upcoming UEFA EURO 2020. Based on the\nresulting estimates, the tournament is simulated repeatedly and winning\nprobabilities are obtained for all teams. A random forest model favors the\ncurrent World Champion France with a winning probability of 14.8% before\nEngland (13.5%) and Spain (12.3%). Additionally, we provide survival\nprobabilities for all teams and at all tournament stages.",
          "link": "http://arxiv.org/abs/2106.05799",
          "publishedOn": "2021-06-11T01:42:17.870Z",
          "wordCount": 621,
          "title": "Hybrid Machine Learning Forecasts for the UEFA EURO 2020. (arXiv:2106.05799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1\">Pingcheng Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "We address the problem of solving complex bimanual robot manipulation tasks\non multiple objects with sparse rewards. Such complex tasks can be decomposed\ninto sub-tasks that are accomplishable by different robots concurrently or\nsequentially for better efficiency. While previous reinforcement learning\napproaches primarily focus on modeling the compositionality of sub-tasks, two\nfundamental issues are largely ignored particularly when learning cooperative\nstrategies for two robots: (i) domination, i.e., one robot may try to solve a\ntask by itself and leaves the other idle; (ii) conflict, i.e., one robot can\neasily interrupt another's workspace when executing different sub-tasks\nsimultaneously. To tackle these two issues, we propose a novel technique called\ndisentangled attention, which provides an intrinsic regularization for two\nrobots to focus on separate sub-tasks and objects. We evaluate our method on\nfour bimanual manipulation tasks. Experimental results show that our proposed\nintrinsic regularization successfully avoids domination and reduces conflicts\nfor the policies, which leads to significantly more effective cooperative\nstrategies than all the baselines. Our project page with videos is at\nhttps://mehooz.github.io/bimanual-attention.",
          "link": "http://arxiv.org/abs/2106.05907",
          "publishedOn": "2021-06-11T01:42:17.864Z",
          "wordCount": 608,
          "title": "Disentangled Attention as Intrinsic Regularization for Bimanual Multi-Object Manipulation. (arXiv:2106.05907v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhuangdi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Junyuan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayu Zhou</a>",
          "description": "Federated Learning (FL) is a decentralized machine-learning paradigm, in\nwhich a global server iteratively averages the model parameters of local users\nwithout accessing their data. User heterogeneity has imposed significant\nchallenges to FL, which can incur drifted global models that are slow to\nconverge. Knowledge Distillation has recently emerged to tackle this issue, by\nrefining the server model using aggregated knowledge from heterogeneous users,\nother than directly averaging their model parameters. This approach, however,\ndepends on a proxy dataset, making it impractical unless such a prerequisite is\nsatisfied. Moreover, the ensemble knowledge is not fully utilized to guide\nlocal model learning, which may in turn affect the quality of the aggregated\nmodel. Inspired by the prior art, we propose a data-free knowledge\ndistillation} approach to address heterogeneous FL, where the server learns a\nlightweight generator to ensemble user information in a data-free manner, which\nis then broadcasted to users, regulating local training using the learned\nknowledge as an inductive bias. Empirical studies powered by theoretical\nimplications show that, our approach facilitates FL with better generalization\nperformance using fewer communication rounds, compared with the\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2105.10056",
          "publishedOn": "2021-06-11T01:42:17.859Z",
          "wordCount": 651,
          "title": "Data-Free Knowledge Distillation for Heterogeneous Federated Learning. (arXiv:2105.10056v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1\">Shruti Jadon</a>",
          "description": "Image Segmentation has been an active field of research as it has a wide\nrange of applications, ranging from automated disease detection to self-driving\ncars. In recent years, various research papers proposed different loss\nfunctions used in case of biased data, sparse segmentation, and unbalanced\ndataset. In this paper, we introduce SemSegLoss, a python package consisting of\nsome of the well-known loss functions widely used for image segmentation. It is\ndeveloped with the intent to help researchers in the development of novel loss\nfunctions and perform an extensive set of experiments on model architectures\nfor various applications. The ease-of-use and flexibility of the presented\npackage have allowed reducing the development time and increased evaluation\nstrategies of machine learning models for semantic segmentation. Furthermore,\ndifferent applications that use image segmentation can use SemSegLoss because\nof the generality of its functions. This wide range of applications will lead\nto the development and growth of AI across all industries.",
          "link": "http://arxiv.org/abs/2106.05844",
          "publishedOn": "2021-06-11T01:42:17.853Z",
          "wordCount": 605,
          "title": "SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1\">Younggyo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lili Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>",
          "description": "Recent exploration methods have proven to be a recipe for improving\nsample-efficiency in deep reinforcement learning (RL). However, efficient\nexploration in high-dimensional observation spaces still remains a challenge.\nThis paper presents Random Encoders for Efficient Exploration (RE3), an\nexploration method that utilizes state entropy as an intrinsic reward. In order\nto estimate state entropy in environments with high-dimensional observations,\nwe utilize a k-nearest neighbor entropy estimator in the low-dimensional\nrepresentation space of a convolutional encoder. In particular, we find that\nthe state entropy can be estimated in a stable and compute-efficient manner by\nutilizing a randomly initialized encoder, which is fixed throughout training.\nOur experiments show that RE3 significantly improves the sample-efficiency of\nboth model-free and model-based RL methods on locomotion and navigation tasks\nfrom DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3\nallows learning diverse behaviors without extrinsic rewards, effectively\nimproving sample-efficiency in downstream tasks. Source code and videos are\navailable at https://sites.google.com/view/re3-rl.",
          "link": "http://arxiv.org/abs/2102.09430",
          "publishedOn": "2021-06-11T01:42:17.847Z",
          "wordCount": 635,
          "title": "State Entropy Maximization with Random Encoders for Efficient Exploration. (arXiv:2102.09430v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Song Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xia He</a>",
          "description": "Feature selection is an important part of building a machine learning model.\nBy eliminating redundant or misleading features from data, the machine learning\nmodel can achieve better performance while reducing the demand on com-puting\nresources. Metaheuristic algorithms are mostly used to implement feature\nselection such as swarm intelligence algorithms and evolutionary algorithms.\nHowever, they suffer from the disadvantage of relative complexity and slowness.\nIn this paper, a concise method is proposed for universal feature selection.\nThe proposed method uses a fusion of the filter method and the wrapper method,\nrather than a combination of them. In the method, one-hoting encoding is used\nto preprocess the dataset, and random forest is utilized as the classifier. The\nproposed method uses normalized frequencies to assign a value to each feature,\nwhich will be used to find the optimal feature subset. Furthermore, we propose\na novel approach to exploit the outputs of mutual information, which allows for\na better starting point for the experiments. Two real-world dataset in the\nfield of intrusion detection were used to evaluate the proposed method. The\nevaluation results show that the proposed method outperformed several\nstate-of-the-art related works in terms of accuracy, precision, recall, F-score\nand AUC.",
          "link": "http://arxiv.org/abs/2106.05814",
          "publishedOn": "2021-06-11T01:42:17.840Z",
          "wordCount": 630,
          "title": "A concise method for feature selection via normalized frequencies. (arXiv:2106.05814v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Challu_C/0/1/0/all/0/1\">Cristian Challu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olivares_K/0/1/0/all/0/1\">Kin G. Olivares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welter_G/0/1/0/all/0/1\">Gus Welter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Neural forecasting has shown significant improvements in the accuracy of\nlarge-scale systems, yet predicting extremely long horizons remains a\nchallenging task. Two common problems are the volatility of the predictions and\ntheir computational complexity; we addressed them by incorporating smoothness\nregularization and mixed data sampling techniques to a well-performing\nmulti-layer perceptron based architecture (NBEATS). We validate our proposed\nmethod, DMIDAS, on high-frequency healthcare and electricity price data with\nlong forecasting horizons (~1000 timestamps) where we improve the prediction\naccuracy by 5% over state-of-the-art models, reducing the number of parameters\nof NBEATS by nearly 70%.",
          "link": "http://arxiv.org/abs/2106.05860",
          "publishedOn": "2021-06-11T01:42:17.824Z",
          "wordCount": 532,
          "title": "DMIDAS: Deep Mixed Data Sampling Regression for Long Multi-Horizon Time Series Forecasting. (arXiv:2106.05860v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.06721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1\">Kathrin Grosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taesung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngja Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1\">Ian Molloy</a>",
          "description": "Backdoor attacks aim to mislead machine-learning models to output an\nattacker-specified class when presented a specific trigger at test time. These\nattacks require poisoning the training data or compromising the learning\nalgorithm, e.g., by injecting poisoning samples containing the trigger into the\ntraining set, along with the desired class label. Despite the increasing number\nof studies on backdoor attacks and defenses, the underlying factors affecting\nthe success of backdoor attacks, along with their impact on the learning\nalgorithm, are not yet well understood. In this work, we aim to shed light on\nthis issue. In particular, we unveil that backdoor attacks work by inducing a\nsmoother decision function around the triggered samples -- a phenomenon which\nwe refer to as \\textit{backdoor smoothing}. We quantify backdoor smoothing by\ndefining a measure that evaluates the uncertainty associated to the predictions\nof a classifier around the input samples.\n\nOur experiments show that smoothness increases when the trigger is added to\nthe input samples, and that the phenomenon is more pronounced for more\nsuccessful attacks.\n\nHowever, our experiments also show that patterns fulfilling backdoor\nsmoothing can be crafted\n\neven without poisoning the training data.\n\nAlthough our measure may not be directly exploited as a defense mechanism, it\nunveils an important phenomenon which may pave the way towards understanding\nthe limitations of current defenses that rely on a smooth decision output for\nbackdoors.",
          "link": "http://arxiv.org/abs/2006.06721",
          "publishedOn": "2021-06-11T01:42:17.818Z",
          "wordCount": 719,
          "title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks. (arXiv:2006.06721v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagner_P/0/1/0/all/0/1\">P.-R. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marelli_S/0/1/0/all/0/1\">S. Marelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papaioannou_I/0/1/0/all/0/1\">I. Papaioannou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Straub_D/0/1/0/all/0/1\">D. Straub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudret_B/0/1/0/all/0/1\">B. Sudret</a>",
          "description": "Estimating the probability of rare failure events is an essential step in the\nreliability assessment of engineering systems. Computing this failure\nprobability for complex non-linear systems is challenging, and has recently\nspurred the development of active-learning reliability methods. These methods\napproximate the limit-state function (LSF) using surrogate models trained with\na sequentially enriched set of model evaluations. A recently proposed method\ncalled stochastic spectral embedding (SSE) aims to improve the local\napproximation accuracy of global, spectral surrogate modelling techniques by\nsequentially embedding local residual expansions in subdomains of the input\nspace. In this work we apply SSE to the LSF, giving rise to a stochastic\nspectral embedding-based reliability (SSER) method. The resulting partition of\nthe input space decomposes the failure probability into a set of\neasy-to-compute domain-wise failure probabilities. We propose a set of\nmodifications that tailor the algorithm to efficiently solve rare event\nestimation problems. These modifications include specialized refinement domain\nselection, partitioning and enrichment strategies. We showcase the algorithm\nperformance on four benchmark problems of various dimensionality and complexity\nin the LSF.",
          "link": "http://arxiv.org/abs/2106.05824",
          "publishedOn": "2021-06-11T01:42:17.811Z",
          "wordCount": 612,
          "title": "Rare event estimation using stochastic spectral embedding. (arXiv:2106.05824v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jimuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1\">Eshed Ohn-Bar</a>",
          "description": "When in a new situation or geographical location, human drivers have an\nextraordinary ability to watch others and learn maneuvers that they themselves\nmay have never performed. In contrast, existing techniques for learning to\ndrive preclude such a possibility as they assume direct access to an\ninstrumented ego-vehicle with fully known observations and expert driver\nactions. However, such measurements cannot be directly accessed for the non-ego\nvehicles when learning by watching others. Therefore, in an application where\ndata is regarded as a highly valuable asset, current approaches completely\ndiscard the vast portion of the training data that can be potentially obtained\nthrough indirect observation of surrounding vehicles. Motivated by this key\ninsight, we propose the Learning by Watching (LbW) framework which enables\nlearning a driving policy without requiring full knowledge of neither the state\nnor expert actions. To increase its data, i.e., with new perspectives and\nmaneuvers, LbW makes use of the demonstrations of other vehicles in a given\nscene by (1) transforming the ego-vehicle's observations to their points of\nview, and (2) inferring their expert actions. Our LbW agent learns more robust\ndriving policies while enabling data-efficient learning, including quick\nadaptation of the policy to rare and novel scenarios. In particular, LbW drives\nrobustly even with a fraction of available driving data required by existing\nmethods, achieving an average success rate of 92% on the original CARLA\nbenchmark with only 30 minutes of total driving data and 82% with only 10\nminutes.",
          "link": "http://arxiv.org/abs/2106.05966",
          "publishedOn": "2021-06-11T01:42:17.806Z",
          "wordCount": 673,
          "title": "Learning by Watching. (arXiv:2106.05966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoedt_P/0/1/0/all/0/1\">Pieter-Jan Hoedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kratzert_F/0/1/0/all/0/1\">Frederik Kratzert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1\">Daniel Klotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halmich_C/0/1/0/all/0/1\">Christina Halmich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzleitner_M/0/1/0/all/0/1\">Markus Holzleitner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nearing_G/0/1/0/all/0/1\">Grey Nearing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1\">G&#xfc;nter Klambauer</a>",
          "description": "The success of Convolutional Neural Networks (CNNs) in computer vision is\nmainly driven by their strong inductive bias, which is strong enough to allow\nCNNs to solve vision-related tasks with random weights, meaning without\nlearning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias\ntowards storing information over time. However, many real-world systems are\ngoverned by conservation laws, which lead to the redistribution of particular\nquantities -- e.g. in physical and economical systems. Our novel\nMass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending\nthe inductive bias of LSTM to model the redistribution of those stored\nquantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at\nlearning arithmetic operations, such as addition tasks, which have a strong\nconservation law, as the sum is constant over time. Further, MC-LSTM is applied\nto traffic forecasting, modelling a pendulum, and a large benchmark dataset in\nhydrology, where it sets a new state-of-the-art for predicting peak flows. In\nthe hydrology example, we show that MC-LSTM states correlate with real-world\nprocesses and are therefore interpretable.",
          "link": "http://arxiv.org/abs/2101.05186",
          "publishedOn": "2021-06-11T01:42:17.800Z",
          "wordCount": 649,
          "title": "MC-LSTM: Mass-Conserving LSTM. (arXiv:2101.05186v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05856",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kuznetsov_M/0/1/0/all/0/1\">Maksim Kuznetsov</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Polykovskiy_D/0/1/0/all/0/1\">Daniil Polykovskiy</a>",
          "description": "We propose a hierarchical normalizing flow model for generating molecular\ngraphs. The model produces new molecular structures from a single-node graph by\nrecursively splitting every node into two. All operations are invertible and\ncan be used as plug-and-play modules. The hierarchical nature of the latent\ncodes allows for precise changes in the resulting graph: perturbations in the\ntop layer cause global structural changes, while perturbations in the\nconsequent layers change the resulting molecule marginally. The proposed model\noutperforms existing generative graph models on the distribution learning task.\nWe also show successful experiments on global and constrained optimization of\nchemical properties using latent codes of the model.",
          "link": "http://arxiv.org/abs/2106.05856",
          "publishedOn": "2021-06-11T01:42:17.781Z",
          "wordCount": 532,
          "title": "MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation. (arXiv:2106.05856v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05958",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gorbunov_E/0/1/0/all/0/1\">Eduard Gorbunov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Danilova_M/0/1/0/all/0/1\">Marina Danilova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shibaev_I/0/1/0/all/0/1\">Innokentiy Shibaev</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1\">Pavel Dvurechensky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "Thanks to their practical efficiency and random nature of the data,\nstochastic first-order methods are standard for training large-scale machine\nlearning models. Random behavior may cause a particular run of an algorithm to\nresult in a highly suboptimal objective value, whereas theoretical guarantees\nare usually proved for the expectation of the objective value. Thus, it is\nessential to theoretically guarantee that algorithms provide small objective\nresidual with high probability. Existing methods for non-smooth stochastic\nconvex optimization have complexity bounds with the dependence on the\nconfidence level that is either negative-power or logarithmic but under an\nadditional assumption of sub-Gaussian (light-tailed) noise distribution that\nmay not hold in practice, e.g., in several NLP tasks. In our paper, we resolve\nthis issue and derive the first high-probability convergence results with\nlogarithmic dependence on the confidence level for non-smooth convex stochastic\noptimization problems with non-sub-Gaussian (heavy-tailed) noise. To derive our\nresults, we propose novel stepsize rules for two stochastic methods with\ngradient clipping. Moreover, our analysis works for generalized smooth\nobjectives with H\\\"older-continuous gradients, and for both methods, we provide\nan extension for strongly convex problems. Finally, our results imply that the\nfirst (accelerated) method we consider also has optimal iteration and oracle\ncomplexity in all the regimes, and the second one is optimal in the non-smooth\nsetting.",
          "link": "http://arxiv.org/abs/2106.05958",
          "publishedOn": "2021-06-11T01:42:17.775Z",
          "wordCount": 667,
          "title": "Near-Optimal High Probability Complexity Bounds for Non-Smooth Stochastic Optimization with Heavy-Tailed Noise. (arXiv:2106.05958v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjik Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Subsampling is used in convolutional neural networks (CNNs) in the form of\npooling or strided convolutions, to reduce the spatial dimensions of feature\nmaps and to allow the receptive fields to grow exponentially with depth.\nHowever, it is known that such subsampling operations are not translation\nequivariant, unlike convolutions that are translation equivariant. Here, we\nfirst introduce translation equivariant subsampling/upsampling layers that can\nbe used to construct exact translation equivariant CNNs. We then generalise\nthese layers beyond translations to general groups, thus proposing group\nequivariant subsampling/upsampling. We use these layers to construct group\nequivariant autoencoders (GAEs) that allow us to learn low-dimensional\nequivariant representations. We empirically verify on images that the\nrepresentations are indeed equivariant to input translations and rotations, and\nthus generalise well to unseen positions and orientations. We further use GAEs\nin models that learn object-centric representations on multi-object datasets,\nand show improved data efficiency and decomposition compared to non-equivariant\nbaselines.",
          "link": "http://arxiv.org/abs/2106.05886",
          "publishedOn": "2021-06-11T01:42:17.769Z",
          "wordCount": 572,
          "title": "Group Equivariant Subsampling. (arXiv:2106.05886v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1\">Arda D&#xfc;z&#xe7;eker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1\">Silvano Galliani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1\">Christoph Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1\">Pablo Speciale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1\">Mihai Dusmanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose an online multi-view depth prediction approach on posed video\nstreams, where the scene geometry information computed in the previous time\nsteps is propagated to the current time step in an efficient and geometrically\nplausible way. The backbone of our approach is a real-time capable, lightweight\nencoder-decoder that relies on cost volumes computed from pairs of images. We\nextend it by placing a ConvLSTM cell at the bottleneck layer, which compresses\nan arbitrary amount of past information in its states. The novelty lies in\npropagating the hidden state of the cell by accounting for the viewpoint\nchanges between time steps. At a given time step, we warp the previous hidden\nstate into the current camera plane using the previous depth prediction. Our\nextension brings only a small overhead of computation time and memory\nconsumption, while improving the depth predictions significantly. As a result,\nwe outperform the existing state-of-the-art multi-view stereo methods on most\nof the evaluated metrics in hundreds of indoor scenes while maintaining a\nreal-time performance. Code available:\nhttps://github.com/ardaduz/deep-video-mvs",
          "link": "http://arxiv.org/abs/2012.02177",
          "publishedOn": "2021-06-11T01:42:17.757Z",
          "wordCount": 645,
          "title": "DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.11667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n\nCode available at this http URL",
          "link": "http://arxiv.org/abs/1906.11667",
          "publishedOn": "2021-06-11T01:42:17.751Z",
          "wordCount": null,
          "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1\">M. Hamed Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1\">Li-Lin Tay</a>",
          "description": "Recently, the combination of robust one-dimensional convolutional neural\nnetworks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid\nidentification of unknown substances with good accuracy. Using this technique,\nresearchers can recognize a pure compound and distinguish it from unknown\nsubstances in a mixture. The novelty of this approach is that the trained\nneural network operates automatically without any pre- or post-processing of\ndata. Some studies have attempted to extend this technique to the\nclassification of pure compounds in an unknown mixture. However, the\napplication of 1-D CNNs has typically been restricted to binary classifications\nof pure compounds. Here we will highlight a new approach in spectral\nrecognition and quantification of chemical components in a multicomponent\nmixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this\npurpose. The former is for rapid classification of components in a mixture\nwhile the latter is for quantitative determination of those constituents. In\nthe proposed method, there is no limit to the number of compounds in a mixture.\nA data augmentation method is also introduced by adding random baselines to the\nRaman spectra. The experimental results revealed that the classification\naccuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at\nthe same time, the RaMixNet II model may achieve a regression accuracy of 88%\nfor the quantification of each component.",
          "link": "http://arxiv.org/abs/2106.05316",
          "publishedOn": "2021-06-11T01:42:17.739Z",
          "wordCount": null,
          "title": "Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-11T01:42:17.738Z",
          "wordCount": null,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05855",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chourasia_R/0/1/0/all/0/1\">Rishav Chourasia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "What is the information leakage of an iterative learning algorithm about its\ntraining data, when the internal state of the algorithm is \\emph{not}\nobservable? How much is the contribution of each specific training epoch to the\nfinal leakage? We study this problem for noisy gradient descent algorithms, and\nmodel the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the\ntraining process. Our analysis traces a provably tight bound on the R\\'enyi\ndivergence between the pair of probability distributions over parameters of\nmodels with neighboring datasets. We prove that the privacy loss converges\nexponentially fast, for smooth and strongly convex loss functions, which is a\nsignificant improvement over composition theorems. For Lipschitz, smooth, and\nstrongly convex loss functions, we prove optimal utility for differential\nprivacy algorithms with a small gradient complexity.",
          "link": "http://arxiv.org/abs/2102.05855",
          "publishedOn": "2021-06-11T01:42:17.737Z",
          "wordCount": null,
          "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mochaourab_R/0/1/0/all/0/1\">Rami Mochaourab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Sugandh Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenstein_S/0/1/0/all/0/1\">Stanley Greenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papapetrou_P/0/1/0/all/0/1\">Panagiotis Papapetrou</a>",
          "description": "We consider counterfactual explanations for private support vector machines\n(SVM), where the privacy mechanism that publicly releases the classifier\nguarantees differential privacy. While privacy preservation is essential when\ndealing with sensitive data, there is a consequent degradation in the\nclassification accuracy due to the introduced perturbations in the classifier\nweights. For such classifiers, counterfactual explanations need to be robust\nagainst the uncertainties in the SVM weights in order to ensure, with high\nconfidence, that the classification of the data instance to be explained is\ndifferent than its explanation. We model the uncertainties in the SVM weights\nthrough a random vector, and formulate the explanation problem as an\noptimization problem with probabilistic constraint. Subsequently, we\ncharacterize the problem's deterministic equivalent and study its solution. For\nlinear SVMs, the problem is a convex second-order cone program. For non-linear\nSVMs, the problem is non-convex. Thus, we propose a sub-optimal solution that\nis based on the bisection method. The results show that, contrary to non-robust\nexplanations, the quality of explanations from the robust solution degrades\nwith increasing privacy in order to guarantee a prespecified confidence level\nfor correct classifications.",
          "link": "http://arxiv.org/abs/2102.03785",
          "publishedOn": "2021-06-11T01:42:17.735Z",
          "wordCount": null,
          "title": "Robust Explanations for Private Support Vector Machines. (arXiv:2102.03785v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:17.734Z",
          "wordCount": null,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Songwei Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_V/0/1/0/all/0/1\">Vasu Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David Jacobs</a>",
          "description": "Shift invariance is a critical property of CNNs that improves performance on\nclassification. However, we show that invariance to circular shifts can also\nlead to greater sensitivity to adversarial attacks. We first characterize the\nmargin between classes when a shift-invariant linear classifier is used. We\nshow that the margin can only depend on the DC component of the signals. Then,\nusing results about infinitely wide networks, we show that in some simple\ncases, fully connected and shift-invariant neural networks produce linear\ndecision boundaries. Using this, we prove that shift invariance in neural\nnetworks produces adversarial examples for the simple case of two classes, each\nconsisting of a single image with a black or white dot on a gray background.\nThis is more than a curiosity; we show empirically that with real datasets and\nrealistic architectures, shift invariance reduces adversarial robustness.\nFinally, we describe initial experiments using synthetic data to probe the\nsource of this connection.",
          "link": "http://arxiv.org/abs/2103.02695",
          "publishedOn": "2021-06-11T01:42:17.733Z",
          "wordCount": null,
          "title": "Shift Invariance Can Reduce Adversarial Robustness. (arXiv:2103.02695v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Liang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yujie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhipeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Wei Pan</a>",
          "description": "This paper presents a deep reinforcement learning (DRL) algorithm for\norientation estimation using inertial sensors combined with magnetometer. The\nLyapunov method in control theory is employed to prove the convergence of\norientation estimation errors. Based on the theoretical results, the estimator\ngains and a Lyapunov function are parametrized by deep neural networks and\nlearned from samples. The DRL estimator is compared with three well-known\norientation estimation methods on both numerical simulations and real datasets\ncollected from commercially available sensors. The results show that the\nproposed algorithm is superior for arbitrary estimation initialization and can\nadapt to very large angular velocities for which other algorithms can be hardly\napplicable. To the best of our knowledge, this is the first DRL-based\norientation estimation method with estimation error boundedness guarantee.",
          "link": "http://arxiv.org/abs/2103.02357",
          "publishedOn": "2021-06-11T01:42:17.732Z",
          "wordCount": null,
          "title": "Reinforcement Learning for Orientation Estimation Using Inertial Sensors with Performance Guarantee. (arXiv:2103.02357v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruoss_A/0/1/0/all/0/1\">Anian Ruoss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Fair representation learning is an attractive approach that promises fairness\nof downstream predictors by encoding sensitive data. Unfortunately, recent work\nhas shown that strong adversarial predictors can still exhibit unfairness by\nrecovering sensitive attributes from these representations. In this work, we\npresent Fair Normalizing Flows (FNF), a new approach offering more rigorous\nfairness guarantees for learned representations. Specifically, we consider a\npractical setting where we can estimate the probability density for sensitive\ngroups. The key idea is to model the encoder as a normalizing flow trained to\nminimize the statistical distance between the latent representations of\ndifferent groups. The main advantage of FNF is that its exact likelihood\ncomputation allows us to obtain guarantees on the maximum unfairness of any\npotentially adversarial downstream predictor. We experimentally demonstrate the\neffectiveness of FNF in enforcing various group fairness notions, as well as\nother attractive properties such as interpretability and transfer learning, on\na variety of challenging real-world datasets.",
          "link": "http://arxiv.org/abs/2106.05937",
          "publishedOn": "2021-06-11T01:42:17.731Z",
          "wordCount": 572,
          "title": "Fair Normalizing Flows. (arXiv:2106.05937v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1\">Julio Hurtado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1\">Alain Raymond-Saez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "When learning tasks over time, artificial neural networks suffer from a\nproblem known as Catastrophic Forgetting (CF). This happens when the weights of\na network are overwritten during the training of a new task causing forgetting\nof old information. To address this issue, we propose MetA Reusable Knowledge\nor MARK, a new method that fosters weight reusability instead of overwriting\nwhen learning a new task. Specifically, MARK keeps a set of shared weights\namong tasks. We envision these shared weights as a common Knowledge Base (KB)\nthat is not only used to learn new tasks, but also enriched with new knowledge\nas the model learns new tasks. Key components behind MARK are two-fold. On the\none hand, a metalearning approach provides the key mechanism to incrementally\nenrich the KB with new knowledge and to foster weight reusability among tasks.\nOn the other hand, a set of trainable masks provides the key mechanism to\nselectively choose from the KB relevant weights to solve each task. By using\nMARK, we achieve state of the art results in several popular benchmarks,\nsurpassing the best performing methods in terms of average accuracy by over 10%\non the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness\nusing 55% of the number of parameters. Furthermore, an ablation study provides\nevidence that, indeed, MARK is learning reusable knowledge that is selectively\nused by each task.",
          "link": "http://arxiv.org/abs/2106.05390",
          "publishedOn": "2021-06-11T01:42:17.725Z",
          "wordCount": null,
          "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Justin D. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1\">Matus Telgarsky</a>",
          "description": "This work studies the behavior of neural networks trained with the logistic\nloss via gradient descent on binary classification data where the underlying\ndata distribution is general, and the (optimal) Bayes risk is not necessarily\nzero. In this setting, it is shown that gradient descent with early stopping\nachieves population risk arbitrarily close to optimal in terms of not just\nlogistic and misclassification losses, but also in terms of calibration,\nmeaning the sigmoid mapping of its outputs approximates the true underlying\nconditional distribution arbitrarily finely. Moreover, the necessary iteration,\nsample, and architectural complexities of this analysis all scale naturally\nwith a certain complexity measure of the true conditional model. Lastly, while\nit is not shown that early stopping is necessary, it is shown that any\nunivariate classifier satisfying a local interpolation property is necessarily\ninconsistent.",
          "link": "http://arxiv.org/abs/2106.05932",
          "publishedOn": "2021-06-11T01:42:17.724Z",
          "wordCount": null,
          "title": "Early-stopped neural networks are consistent. (arXiv:2106.05932v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1\">Kenichi Kumatani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>",
          "description": "In this paper, we propose a unified pre-training approach called UniSpeech to\nlearn speech representations with both unlabeled and labeled data, in which\nsupervised phonetic CTC learning and phonetically-aware contrastive\nself-supervised learning are conducted in a multi-task learning manner. The\nresultant representations can capture information more correlated with phonetic\nstructures and improve the generalization across languages and domains. We\nevaluate the effectiveness of UniSpeech for cross-lingual representation\nlearning on public CommonVoice corpus. The results show that UniSpeech\noutperforms self-supervised pretraining and supervised transfer learning for\nspeech recognition by a maximum of 13.4% and 17.8% relative phone error rate\nreductions respectively (averaged over all testing languages). The\ntransferability of UniSpeech is also demonstrated on a domain-shift speech\nrecognition task, i.e., a relative word error rate reduction of 6% against the\nprevious approach.",
          "link": "http://arxiv.org/abs/2101.07597",
          "publishedOn": "2021-06-11T01:42:17.724Z",
          "wordCount": null,
          "title": "UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ha_H/0/1/0/all/0/1\">Huong Ha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1\">Binxin Ru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A. Osborne</a>",
          "description": "High-dimensional black-box optimisation remains an important yet notoriously\nchallenging problem. Despite the success of Bayesian optimisation methods on\ncontinuous domains, domains that are categorical, or that mix continuous and\ncategorical variables, remain challenging. We propose a novel solution -- we\ncombine local optimisation with a tailored kernel design, effectively handling\nhigh-dimensional categorical and mixed search spaces, whilst retaining sample\nefficiency. We further derive convergence guarantee for the proposed approach.\nFinally, we demonstrate empirically that our method outperforms the current\nbaselines on a variety of synthetic and real-world tasks in terms of\nperformance, computational costs, or both.",
          "link": "http://arxiv.org/abs/2102.07188",
          "publishedOn": "2021-06-11T01:42:17.723Z",
          "wordCount": null,
          "title": "Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces. (arXiv:2102.07188v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specially, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the issue of inconsistency between training and\npredicting as well as improving the mining of dynamic patterns, we (i) propose\nusing a hybrid output as input at next time step, which brings training and\npredicting into alignment; and (ii) further devise a generalized\nauto-regressive strategy that encodes all the historical dependencies at\ncurrent time step. Thereafter, we first investigate the methodological\ncharacteristics of the proposed deep probabilistic sequence model on toy cases,\nand then comprehensively demonstrate the superiority of our model against\nexisting deep probabilistic SSM models through extensive numerical experiments\non eight system identification benchmarks from various dynamic systems.\nFinally, we apply our sequence model to a real-world centrifugal compressor\nsensor data forecasting problem, and again verify its outstanding performance\nby quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2021-06-11T01:42:17.716Z",
          "wordCount": 665,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grand_Clement_J/0/1/0/all/0/1\">Julien Grand-Cl&#xe9;ment</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroer_C/0/1/0/all/0/1\">Christian Kroer</a>",
          "description": "We develop new parameter and scale-free algorithms for solving convex-concave\nsaddle-point problems. Our results are based on a new simple regret minimizer,\nthe Conic Blackwell Algorithm$^+$ (CBA$^+$), which attains $O(1/\\sqrt{T})$\naverage regret. Intuitively, our approach generalizes to other decision sets of\ninterest ideas from the Counterfactual Regret minimization (CFR$^+$) algorithm,\nwhich has very strong practical performance for solving sequential games on\nsimplexes. We show how to implement CBA$^+$ for the simplex, $\\ell_{p}$ norm\nballs, and ellipsoidal confidence regions in the simplex, and we present\nnumerical experiments for solving matrix games and distributionally robust\noptimization problems. Our empirical results show that CBA$^+$ is a simple\nalgorithm that outperforms state-of-the-art methods on synthetic data and real\ndata instances, without the need for any choice of step sizes or other\nalgorithmic parameters.",
          "link": "http://arxiv.org/abs/2105.13203",
          "publishedOn": "2021-06-11T01:42:17.710Z",
          "wordCount": 580,
          "title": "Conic Blackwell Algorithm: Parameter-Free Convex-Concave Saddle-Point Solving. (arXiv:2105.13203v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1\">Ivan Chelombiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1\">Daniel Justus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1\">Douglas Orr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1\">Anastasia Dietrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1\">Frithjof Gressmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1\">Alexandros Koliousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Attention based language models have become a critical component in\nstate-of-the-art natural language processing systems. However, these models\nhave significant computational requirements, due to long training times, dense\noperations and large parameter count. In this work we demonstrate a set of\nmodifications to the structure of a Transformer layer, producing a more\nefficient architecture. First, we add a convolutional module to complement the\nself-attention module, decoupling the learning of local and global\ninteractions. Secondly, we rely on grouped transformations to reduce the\ncomputational cost of dense feed-forward layers and convolutions, while\npreserving the expressivity of the model. We apply the resulting architecture\nto language representation learning and demonstrate its superior performance\ncompared to BERT models of different scales. We further highlight its improved\nefficiency, both in terms of floating-point operations (FLOPs) and\ntime-to-train.",
          "link": "http://arxiv.org/abs/2106.05822",
          "publishedOn": "2021-06-11T01:42:17.704Z",
          "wordCount": 568,
          "title": "GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poyiadzi_R/0/1/0/all/0/1\">Rafael Poyiadzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renard_X/0/1/0/all/0/1\">Xavier Renard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laugel_T/0/1/0/all/0/1\">Thibault Laugel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Detyniecki_M/0/1/0/all/0/1\">Marcin Detyniecki</a>",
          "description": "Local surrogate approaches for explaining machine learning model predictions\nhave appealing properties, such as being model-agnostic and flexible in their\nmodelling. Several methods exist that fit this description and share this goal.\nHowever, despite their shared overall procedure, they set out different\nobjectives, extract different information from the black-box, and consequently\nproduce diverse explanations, that are -- in general -- incomparable. In this\nwork we review the similarities and differences amongst multiple methods, with\na particular focus on what information they extract from the model, as this has\nlarge impact on the output: the explanation. We discuss the implications of the\nlack of agreement, and clarity, amongst the methods' objectives on the research\nand practice of explainability.",
          "link": "http://arxiv.org/abs/2106.05810",
          "publishedOn": "2021-06-11T01:42:17.690Z",
          "wordCount": 558,
          "title": "On the overlooked issue of defining explanation objectives for local-surrogate explainers. (arXiv:2106.05810v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.12301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ito_R/0/1/0/all/0/1\">Rei Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsukada_M/0/1/0/all/0/1\">Mineto Tsukada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsutani_H/0/1/0/all/0/1\">Hiroki Matsutani</a>",
          "description": "Most edge AI focuses on prediction tasks on resource-limited edge devices\nwhile the training is done at server machines. However, retraining or\ncustomizing a model is required at edge devices as the model is becoming\noutdated due to environmental changes over time. To follow such a concept\ndrift, a neural-network based on-device learning approach is recently proposed,\nso that edge devices train incoming data at runtime to update their model. In\nthis case, since a training is done at distributed edge devices, the issue is\nthat only a limited amount of training data can be used for each edge device.\nTo address this issue, one approach is a cooperative learning or federated\nlearning, where edge devices exchange their trained results and update their\nmodel by using those collected from the other devices. In this paper, as an\non-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme\nLearning Machine) to sequentially train a model based on recent samples and\ncombine it with autoencoder for anomaly detection. We extend it for an\non-device federated learning so that edge devices can exchange their trained\nresults and update their model by using those collected from the other edge\ndevices. This cooperative model update is one-shot while it can be repeatedly\napplied to synchronize their model. Our approach is evaluated with anomaly\ndetection tasks generated from a driving dataset of cars, a human activity\ndataset, and MNIST dataset. The results demonstrate that the proposed on-device\nfederated learning can produce a merged model by integrating trained results\nfrom multiple edge devices as accurately as traditional backpropagation based\nneural networks and a traditional federated learning approach with lower\ncomputation or communication cost.",
          "link": "http://arxiv.org/abs/2002.12301",
          "publishedOn": "2021-06-11T01:42:17.684Z",
          "wordCount": null,
          "title": "An On-Device Federated Learning Approach for Cooperative Anomaly Detection. (arXiv:2002.12301v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Refinetti_M/0/1/0/all/0/1\">Maria Refinetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "A recent series of theoretical works showed that the dynamics of neural\nnetworks with a certain initialisation are well-captured by kernel methods.\nConcurrent empirical work demonstrated that kernel methods can come close to\nthe performance of neural networks on some image classification tasks. These\nresults raise the question of whether neural networks only learn successfully\nif kernels also learn successfully, despite neural networks being more\nexpressive. Here, we show theoretically that two-layer neural networks (2LNN)\nwith only a few hidden neurons can beat the performance of kernel learning on a\nsimple Gaussian mixture classification task. We study the high-dimensional\nlimit where the number of samples is linearly proportional to the input\ndimension, and show that while small 2LNN achieve near-optimal performance on\nthis task, lazy training approaches such as random features and kernel methods\ndo not. Our analysis is based on the derivation of a closed set of equations\nthat track the learning dynamics of the 2LNN and thus allow to extract the\nasymptotic performance of the network as a function of signal-to-noise ratio\nand other hyperparameters. We finally illustrate how over-parametrising the\nneural network leads to faster convergence, but does not improve its final\nperformance.",
          "link": "http://arxiv.org/abs/2102.11742",
          "publishedOn": "2021-06-11T01:42:17.683Z",
          "wordCount": null,
          "title": "Classifying high-dimensional Gaussian mixtures: Where kernel methods fail and neural networks succeed. (arXiv:2102.11742v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozerov_A/0/1/0/all/0/1\">Alexey Ozerov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Neural style transfer, allowing to apply the artistic style of one image to\nanother, has become one of the most widely showcased computer vision\napplications shortly after its introduction. In contrast, related tasks in the\nmusic audio domain remained, until recently, largely untackled. While several\nstyle conversion methods tailored to musical signals have been proposed, most\nlack the 'one-shot' capability of classical image style transfer algorithms. On\nthe other hand, the results of existing one-shot audio style transfer methods\non musical inputs are not as compelling. In this work, we are specifically\ninterested in the problem of one-shot timbre transfer. We present a novel\nmethod for this task, based on an extension of the vector-quantized variational\nautoencoder (VQ-VAE), along with a simple self-supervised learning strategy\ndesigned to obtain disentangled representations of timbre and pitch. We\nevaluate the method using a set of objective metrics and show that it is able\nto outperform selected baselines.",
          "link": "http://arxiv.org/abs/2102.05749",
          "publishedOn": "2021-06-11T01:42:17.682Z",
          "wordCount": null,
          "title": "Self-Supervised VQ-VAE for One-Shot Music Style Transfer. (arXiv:2102.05749v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>",
          "description": "Convolutional architectures have proven extremely successful for vision\ntasks. Their hard inductive biases enable sample-efficient learning, but come\nat the cost of a potentially lower performance ceiling. Vision Transformers\n(ViTs) rely on more flexible self-attention layers, and have recently\noutperformed CNNs for image classification. However, they require costly\npre-training on large external datasets or distillation from pre-trained\nconvolutional networks. In this paper, we ask the following question: is it\npossible to combine the strengths of these two architectures while avoiding\ntheir respective limitations? To this end, we introduce gated positional\nself-attention (GPSA), a form of positional self-attention which can be\nequipped with a ``soft\" convolutional inductive bias. We initialise the GPSA\nlayers to mimic the locality of convolutional layers, then give each attention\nhead the freedom to escape locality by adjusting a gating parameter regulating\nthe attention paid to position versus content information. The resulting\nconvolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,\nwhile offering a much improved sample efficiency. We further investigate the\nrole of locality in learning by first quantifying how it is encouraged in\nvanilla self-attention layers, then analysing how it is escaped in GPSA layers.\nWe conclude by presenting various ablations to better understand the success of\nthe ConViT. Our code and models are released publicly at\nhttps://github.com/facebookresearch/convit.",
          "link": "http://arxiv.org/abs/2103.10697",
          "publishedOn": "2021-06-11T01:42:17.679Z",
          "wordCount": null,
          "title": "ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1\">Cameron R. Wolfe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingkang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Arindam Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayer_A/0/1/0/all/0/1\">Artun Bayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>",
          "description": "The graph convolutional network (GCN) is a go-to solution for machine\nlearning on graphs, but its training is notoriously difficult to scale both in\nterms of graph size and the number of model parameters. Although some work has\nexplored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we\npioneer efficient training of large-scale GCN models (i.e., ultra-wide,\noverparameterized models) with the proposal of a novel, distributed training\nframework. Our proposed training methodology, called GIST, disjointly\npartitions the parameters of a GCN model into several, smaller sub-GCNs that\nare trained independently and in parallel. In addition to being compatible with\nany GCN architecture, GIST improves model performance, scales to training on\narbitrarily large graphs, significantly decreases wall-clock training time, and\nenables the training of markedly overparameterized GCN models. Remarkably, with\nGIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which\nexceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on\nthe Amazon2M dataset.",
          "link": "http://arxiv.org/abs/2102.10424",
          "publishedOn": "2021-06-11T01:42:17.677Z",
          "wordCount": null,
          "title": "GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Townshend_R/0/1/0/all/0/1\">Raphael J.L. Townshend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogele_M/0/1/0/all/0/1\">Martin V&#xf6;gele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suriana_P/0/1/0/all/0/1\">Patricia Suriana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derry_A/0/1/0/all/0/1\">Alexander Derry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powers_A/0/1/0/all/0/1\">Alexander Powers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laloudakis_Y/0/1/0/all/0/1\">Yianni Laloudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandar_S/0/1/0/all/0/1\">Sidhika Balachandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_B/0/1/0/all/0/1\">Bowen Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1\">Brandon Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eismann_S/0/1/0/all/0/1\">Stephan Eismann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altman_R/0/1/0/all/0/1\">Russ B. Altman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dror_R/0/1/0/all/0/1\">Ron O. Dror</a>",
          "description": "Computational methods that operate on three-dimensional molecular structure\nhave the potential to solve important questions in biology and chemistry. In\nparticular, deep neural networks have gained significant attention, but their\nwidespread adoption in the biomolecular domain has been limited by a lack of\neither systematic performance benchmarks or a unified toolkit for interacting\nwith molecular data. To address this, we present ATOM3D, a collection of both\nnovel and existing benchmark datasets spanning several key classes of\nbiomolecules. We implement several classes of three-dimensional molecular\nlearning methods for each of these tasks and show that they consistently\nimprove performance relative to methods based on one- and two-dimensional\nrepresentations. The specific choice of architecture proves to be critical for\nperformance, with three-dimensional convolutional networks excelling at tasks\ninvolving complex geometries, graph networks performing well on systems\nrequiring detailed positional information, and the more recently developed\nequivariant networks showing significant promise. Our results indicate that\nmany molecular problems stand to gain from three-dimensional molecular\nlearning, and that there is potential for improvement on many tasks which\nremain underexplored. To lower the barrier to entry and facilitate further\ndevelopments in the field, we also provide a comprehensive suite of tools for\ndataset processing, model training, and evaluation in our open-source atom3d\nPython package. All datasets are available for download from\nhttps://www.atom3d.ai .",
          "link": "http://arxiv.org/abs/2012.04035",
          "publishedOn": "2021-06-11T01:42:17.676Z",
          "wordCount": null,
          "title": "ATOM3D: Tasks On Molecules in Three Dimensions. (arXiv:2012.04035v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rusch_T/0/1/0/all/0/1\">T. Konstantin Rusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Siddhartha Mishra</a>",
          "description": "The design of recurrent neural networks (RNNs) to accurately process\nsequential inputs with long-time dependencies is very challenging on account of\nthe exploding and vanishing gradient problem. To overcome this, we propose a\nnovel RNN architecture which is based on a structure preserving discretization\nof a Hamiltonian system of second-order ordinary differential equations that\nmodels networks of oscillators. The resulting RNN is fast, invertible (in\ntime), memory efficient and we derive rigorous bounds on the hidden state\ngradients to prove the mitigation of the exploding and vanishing gradient\nproblem. A suite of experiments are presented to demonstrate that the proposed\nRNN provides state of the art performance on a variety of learning tasks with\n(very) long-time dependencies.",
          "link": "http://arxiv.org/abs/2103.05487",
          "publishedOn": "2021-06-11T01:42:17.664Z",
          "wordCount": null,
          "title": "UnICORNN: A recurrent model for learning very long time dependencies. (arXiv:2103.05487v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingfeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1\">Vladimir Braverman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>",
          "description": "There is an increasing realization that algorithmic inductive biases are\ncentral in preventing overfitting; empirically, we often see a benign\noverfitting phenomenon in overparameterized settings for natural learning\nalgorithms, such as stochastic gradient descent (SGD), where little to no\nexplicit regularization has been employed. This work considers this issue in\narguably the most basic setting: constant-stepsize SGD (with iterate averaging)\nfor linear regression in the overparameterized regime. Our main result provides\na sharp excess risk bound, stated in terms of the full eigenspectrum of the\ndata covariance matrix, that reveals a bias-variance decomposition\ncharacterizing when generalization is possible: (i) the variance bound is\ncharacterized in terms of an effective dimension (specific for SGD) and (ii)\nthe bias bound provides a sharp geometric characterization in terms of the\nlocation of the initial iterate (and how it aligns with the data covariance\nmatrix). We reflect on a number of notable differences between the algorithmic\nregularization afforded by (unregularized) SGD in comparison to ordinary least\nsquares (minimum-norm interpolation) and ridge regression.",
          "link": "http://arxiv.org/abs/2103.12692",
          "publishedOn": "2021-06-11T01:42:17.627Z",
          "wordCount": null,
          "title": "Benign Overfitting of Constant-Stepsize SGD for Linear Regression. (arXiv:2103.12692v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-output (MIMO)\nwireless radar. Here, the strong clutter due to the reflection of the layered\nstructure's surface often makes the detection of the defects challenging. Thus,\nsophisticated signal separation methods are required for improved defect\ndetection. In many scenarios, the number of defects that we are interested in\nis limited and the signaling response of the layered structure can be modeled\nas a low-rank structure. Therefore, we propose joint rank and sparsity\nminimization for defect detection. In particular, we propose a non-convex\napproach based on the iteratively reweighted nuclear and $\\ell_1-$norm (a\ndouble-reweighted approach) to obtain a higher accuracy compared to the\nconventional nuclear norm and $\\ell_1-$norm minimization. To this end, an\niterative algorithm is designed to estimate the low-rank and sparse\ncontributions. Further, we propose deep learning to learn the parameters of the\nalgorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of\nconvergence of the algorithm. Our numerical results show that the proposed\napproach outperforms the conventional approaches in terms of mean square errors\nof the recovered low-rank and sparse components and the speed of convergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-06-11T01:42:17.627Z",
          "wordCount": null,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1\">Zachary Nado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1\">Justin M. Gilmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shallue_C/0/1/0/all/0/1\">Christopher J. Shallue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1\">George E. Dahl</a>",
          "description": "Recently the LARS and LAMB optimizers have been proposed for training neural\nnetworks faster using large batch sizes. LARS and LAMB add layer-wise\nnormalization to the update rules of Heavy-ball momentum and Adam,\nrespectively, and have become popular in prominent benchmarks and deep learning\nlibraries. However, without fair comparisons to standard optimizers, it remains\nan open question whether LARS and LAMB have any benefit over traditional,\ngeneric algorithms. In this work we demonstrate that standard optimization\nalgorithms such as Nesterov momentum and Adam can match or exceed the results\nof LARS and LAMB at large batch sizes. Our results establish new, stronger\nbaselines for future comparisons at these batch sizes and shed light on the\ndifficulties of comparing optimizers for neural network training more\ngenerally.",
          "link": "http://arxiv.org/abs/2102.06356",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes. (arXiv:2102.06356v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09082",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1\">Yiheng Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_Y/0/1/0/all/0/1\">Yuzhe Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cecchi_N/0/1/0/all/0/1\">Nicholas J. Cecchi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Raymond_S/0/1/0/all/0/1\">Samuel J. Raymond</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhou Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alizadeh_H/0/1/0/all/0/1\">Hossein Vahid Alizadeh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ruan_J/0/1/0/all/0/1\">Jesse Ruan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barbat_S/0/1/0/all/0/1\">Saeed Barbat</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tiernan_S/0/1/0/all/0/1\">Stephen Tiernan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zeineh_M/0/1/0/all/0/1\">Michael M. Zeineh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Grant_G/0/1/0/all/0/1\">Gerald A. Grant</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Camarillo_D/0/1/0/all/0/1\">David B. Camarillo</a>",
          "description": "Traumatic brain injury can be caused by head impacts, but many brain injury\nrisk estimation models are less accurate across the variety of impacts that\npatients may undergo. We investigated the spectral characteristics of different\nhead impact types with kinematics classification. Data was analyzed from 3,262\nhead impacts from lab reconstruction, American football, mixed martial arts,\nand publicly available car crash data. A random forest classifier with spectral\ndensities of linear acceleration and angular velocity was built to classify\nhead impact types (e.g., football), reaching a median accuracy of 96% over\n1,000 random partitions of training and test sets. To test the classifier on\ndata from different measurement devices, another 271 lab-reconstructed impacts\nwere obtained from 5 other instrumented mouthguards with the classifier\nreaching over 96% accuracy. The most important features in the classification\nincluded both low-frequency and high-frequency features, both linear\nacceleration features and angular velocity features. Different head impact\ntypes had different distributions of spectral densities in low-frequency and\nhigh-frequency ranges (e.g., the spectral densities of MMA impacts were higher\nin high-frequency range than in the low-frequency range). Finally, with the\nclassifier, type-specific, nearest-neighbor regression models were built for\n95th percentile maximum principal strain, 95th percentile maximum principal\nstrain in corpus callosum, and cumulative strain damage (15th percentile). This\nshowed a generally higher R2-value than baseline models. The classifier enables\na better understanding of the impact kinematics in different sports, and it can\nbe applied to evaluate the quality of impact-simulation systems and on-field\ndata augmentation. Key words: traumatic brain injury, head impacts,\nclassification, impact kinematics",
          "link": "http://arxiv.org/abs/2104.09082",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Classification of head impacts based on the spectral density of measurable kinematics. (arXiv:2104.09082v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Vision transformer has demonstrated promising performance on challenging\ncomputer vision tasks. However, directly training the vision transformers may\nyield unstable and sub-optimal results. Recent works propose to improve the\nperformance of the vision transformers by modifying the transformer structures,\ne.g., incorporating convolution layers. In contrast, we investigate an\northogonal approach to stabilize the vision transformer training without\nmodifying the networks. We observe the instability of the training can be\nattributed to the significant similarity across the extracted patch\nrepresentations. More specifically, for deep vision transformers, the\nself-attention blocks tend to map different patches into similar latent\nrepresentations, yielding information loss and performance degradation. To\nalleviate this problem, in this work, we introduce novel loss functions in\nvision transformer training to explicitly encourage diversity across patch\nrepresentations for more discriminative feature extraction. We empirically show\nthat our proposed techniques stabilize the training and allow us to train wider\nand deeper vision transformers. We further show the diversified features\nsignificantly benefit the downstream tasks in transfer learning. For semantic\nsegmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and\nADE20k. Our code will be made publicly available soon.",
          "link": "http://arxiv.org/abs/2104.12753",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1\">Michael Laskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1\">Aravind Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>",
          "description": "Model-free deep reinforcement learning (RL) has been successful in a range of\nchallenging domains. However, there are some remaining issues, such as\nstabilizing the optimization of nonlinear function approximators, preventing\nerror propagation due to the Bellman backup in Q-learning, and efficient\nexploration. To mitigate these issues, we present SUNRISE, a simple unified\nensemble method, which is compatible with various off-policy RL algorithms.\nSUNRISE integrates three key ingredients: (a) bootstrap with random\ninitialization which improves the stability of the learning process by training\na diverse ensemble of agents, (b) weighted Bellman backups, which prevent error\npropagation in Q-learning by reweighing sample transitions based on uncertainty\nestimates from the ensembles, and (c) an inference method that selects actions\nusing highest upper-confidence bounds for efficient exploration. Our\nexperiments show that SUNRISE significantly improves the performance of\nexisting off-policy RL algorithms, such as Soft Actor-Critic and Rainbow DQN,\nfor both continuous and discrete control tasks on both low-dimensional and\nhigh-dimensional environments. Our training code is available at\nhttps://github.com/pokaxpoka/sunrise.",
          "link": "http://arxiv.org/abs/2007.04938",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning. (arXiv:2007.04938v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Er_S/0/1/0/all/0/1\">Siawpeng Er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shihao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "The global spread of COVID-19, the disease caused by the novel coronavirus\nSARS-CoV-2, has cast a significant threat to mankind. As the COVID-19 situation\ncontinues to evolve, predicting localized disease severity is crucial for\nadvanced resource allocation. This paper proposes a method named COURAGE\n(COUnty aggRegation mixup AuGmEntation) to generate a short-term prediction of\n2-week-ahead COVID-19 related deaths for each county in the United States,\nleveraging modern deep learning techniques. Specifically, our method adopts a\nself-attention model from Natural Language Processing, known as the transformer\nmodel, to capture both short-term and long-term dependencies within the time\nseries while enjoying computational efficiency. Our model fully utilizes\npublicly available information of COVID-19 related confirmed cases, deaths,\ncommunity mobility trends and demographic information, and can produce\nstate-level prediction as an aggregation of the corresponding county-level\npredictions. Our numerical experiments demonstrate that our model achieves the\nstate-of-the-art performance among the publicly available benchmark models.",
          "link": "http://arxiv.org/abs/2105.00620",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "COUnty aggRegation mixup AuGmEntation (COURAGE) COVID-19 Prediction. (arXiv:2105.00620v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangjun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Junxiao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1\">Penghui Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1\">Peng Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhenkun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pi_X/0/1/0/all/0/1\">Xiongjun Pi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jujie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_H/0/1/0/all/0/1\">Haitao Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1\">Quan Yuan</a>",
          "description": "AlphaStar, the AI that reaches GrandMaster level in StarCraft II, is a\nremarkable milestone demonstrating what deep reinforcement learning can achieve\nin complex Real-Time Strategy (RTS) games. However, the complexities of the\ngame, algorithms and systems, and especially the tremendous amount of\ncomputation needed are big obstacles for the community to conduct further\nresearch in this direction. We propose a deep reinforcement learning agent,\nStarCraft Commander (SCC). With order of magnitude less computation, it\ndemonstrates top human performance defeating GrandMaster players in test\nmatches and top professional players in a live event. Moreover, it shows strong\nrobustness to various human strategies and discovers novel strategies unseen\nfrom human plays. In this paper, we will share the key insights and\noptimizations on efficient imitation learning and reinforcement learning for\nStarCraft II full game.",
          "link": "http://arxiv.org/abs/2012.13169",
          "publishedOn": "2021-06-11T01:42:17.617Z",
          "wordCount": null,
          "title": "SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II. (arXiv:2012.13169v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14163",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1\">Sinho Chewi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gerber_P/0/1/0/all/0/1\">Patrik Gerber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lu_C/0/1/0/all/0/1\">Chen Lu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gouic_T/0/1/0/all/0/1\">Thibaut Le Gouic</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rigollet_P/0/1/0/all/0/1\">Philippe Rigollet</a>",
          "description": "We establish the first tight lower bound of $\\Omega(\\log\\log\\kappa)$ on the\nquery complexity of sampling from the class of strongly log-concave and\nlog-smooth distributions with condition number $\\kappa$ in one dimension.\nWhereas existing guarantees for MCMC-based algorithms scale polynomially in\n$\\kappa$, we introduce a novel algorithm based on rejection sampling that\ncloses this doubly exponential gap.",
          "link": "http://arxiv.org/abs/2105.14163",
          "publishedOn": "2021-06-11T01:42:17.617Z",
          "wordCount": null,
          "title": "The query complexity of sampling from strongly log-concave distributions in one dimension. (arXiv:2105.14163v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Susheel Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1\">Cong Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1\">Jennifer Neville</a>",
          "description": "Self-supervised learning of graph neural networks (GNN) is in great need\nbecause of the widespread label scarcity issue in real-world graph/network\ndata. Graph contrastive learning (GCL), by training GNNs to maximize the\ncorrespondence between the representations of the same graph in its different\naugmented forms, may yield robust and transferable GNNs even without using\nlabels. However, GNNs trained by traditional GCL often risk capturing redundant\ngraph features and thus may be brittle and provide sub-par performance in\ndownstream tasks. Here, we propose a novel principle, termed adversarial-GCL\n(AD-GCL), which enables GNNs to avoid capturing redundant information during\nthe training by optimizing adversarial graph augmentation strategies used in\nGCL. We pair AD-GCL with theoretical explanations and design a practical\ninstantiation based on trainable edge-dropping graph augmentation. We\nexperimentally validate AD-GCL by comparing with the state-of-the-art GCL\nmethods and achieve performance gains of up-to $14\\%$ in unsupervised, $6\\%$ in\ntransfer, and $3\\%$ in semi-supervised learning settings overall with 18\ndifferent benchmark datasets for the tasks of molecule property regression and\nclassification, and social network classification.",
          "link": "http://arxiv.org/abs/2106.05819",
          "publishedOn": "2021-06-11T01:42:17.616Z",
          "wordCount": 600,
          "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning. (arXiv:2106.05819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.08435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>",
          "description": "Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.",
          "link": "http://arxiv.org/abs/2009.08435",
          "publishedOn": "2021-06-11T01:42:17.616Z",
          "wordCount": null,
          "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06489",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mai_V/0/1/0/all/0/1\">Vien V. Mai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Johansson_M/0/1/0/all/0/1\">Mikael Johansson</a>",
          "description": "Stochastic gradient algorithms are often unstable when applied to functions\nthat do not have Lipschitz-continuous and/or bounded gradients. Gradient\nclipping is a simple and effective technique to stabilize the training process\nfor problems that are prone to the exploding gradient problem. Despite its\nwidespread popularity, the convergence properties of the gradient clipping\nheuristic are poorly understood, especially for stochastic problems. This paper\nestablishes both qualitative and quantitative convergence results of the\nclipped stochastic (sub)gradient method (SGD) for non-smooth convex functions\nwith rapidly growing subgradients. Our analyses show that clipping enhances the\nstability of SGD and that the clipped SGD algorithm enjoys finite convergence\nrates in many cases. We also study the convergence of a clipped method with\nmomentum, which includes clipped SGD as a special case, for weakly convex\nproblems under standard assumptions. With a novel Lyapunov analysis, we show\nthat the proposed method achieves the best-known rate for the considered class\nof problems, demonstrating the effectiveness of clipped methods also in this\nregime. Numerical results confirm our theoretical developments.",
          "link": "http://arxiv.org/abs/2102.06489",
          "publishedOn": "2021-06-11T01:42:17.610Z",
          "wordCount": null,
          "title": "Stability and Convergence of Stochastic Gradient Clipping: Beyond Lipschitz Continuity and Smoothness. (arXiv:2102.06489v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leung_R/0/1/0/all/0/1\">Raymond Leung</a>",
          "description": "In the literature, a large body of work advocates the use of log-ratio\ntransformation for multivariate statistical analysis of compositional data. In\ncontrast, few studies have looked at how data transformation changes the\nefficacy of machine learning classifiers within geoscience. This letter\npresents experiment results and empirical observations to further explore this\nissue. The objective is to study the effects of data transformation on geozone\nclassification performance when machine learning (ML) classifiers/estimators\nare trained using geochemical data. The training input consists of exploration\nhole assay samples obtained from a Pilbara iron-ore deposit in Western\nAustralia, and geozone labels assigned based on stratigraphic units, the\nabsence or presence and type of mineralization. The ML techniques considered\nare multinomial logistic regression, Gaussian na\\\"{i}ve Bayes, kNN, linear\nsupport vector classifier, RBF-SVM, gradient boosting and extreme GB, random\nforest (RF) and multi-layer perceptron (MLP). The transformations examined\ninclude isometric log-ratio (ILR), center log-ratio (CLR) coupled with\nprincipal component analysis (PCA) or independent component analysis (ICA), and\na manifold learning approach based on local linear embedding (LLE). The results\nreveal that different ML classifiers exhibit varying sensitivity to these\ntransformations, with some clearly more advantageous or deleterious than\nothers. Overall, the best performing candidate is ILR which is unsurprising\nconsidering the compositional nature of the data. The performance of pairwise\nlog-ratio (PWLR) transformation is better than ILR for ensemble and tree-based\nlearners such as boosting and RF; but worse for MLP, SVM and other classifiers.",
          "link": "http://arxiv.org/abs/2106.05855",
          "publishedOn": "2021-06-11T01:42:17.608Z",
          "wordCount": null,
          "title": "Empirical observations on the effects of data transformation in machine learning classification of geological domains. (arXiv:2106.05855v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1\">Abbavaram Gowtham Reddy</a>",
          "description": "Causal reasoning is the main learning and explanation tool used by humans. AI\nsystems should possess causal reasoning capabilities to be deployed in the real\nworld with trust and reliability. Introducing the ideas of causality to machine\nlearning helps in providing better learning and explainable models.\nExplainability, causal disentanglement are some important aspects of any\nmachine learning model. Causal explanations are required to believe in a\nmodel's decision and causal disentanglement learning is important for transfer\nlearning applications. We exploit the ideas of causality to be used in deep\nlearning models to achieve better and causally explainable models that are\nuseful in fairness, disentangled representation, etc.",
          "link": "http://arxiv.org/abs/2106.05842",
          "publishedOn": "2021-06-11T01:42:17.603Z",
          "wordCount": null,
          "title": "Causality in Neural Networks -- An Extended Abstract. (arXiv:2106.05842v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasa_L/0/1/0/all/0/1\">Luca Pasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navarin_N/0/1/0/all/0/1\">Nicol&#xf2; Navarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erb_W/0/1/0/all/0/1\">Wolfgang Erb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1\">Alessandro Sperduti</a>",
          "description": "Many neural networks for graphs are based on the graph convolution operator,\nproposed more than a decade ago. Since then, many alternative definitions have\nbeen proposed, that tend to add complexity (and non-linearity) to the model. In\nthis paper, we follow the opposite direction by proposing simple graph\nconvolution operators, that can be implemented in single-layer graph\nconvolutional networks. We show that our convolution operators are more\ntheoretically grounded than many proposals in literature, and exhibit\nstate-of-the-art predictive performance on the considered benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.05809",
          "publishedOn": "2021-06-11T01:42:17.600Z",
          "wordCount": 501,
          "title": "Simple Graph Convolutional Networks. (arXiv:2106.05809v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tsuchiya_T/0/1/0/all/0/1\">Taira Tsuchiya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1\">Junya Honda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "We investigate finite stochastic partial monitoring, which is a general model\nfor sequential learning with limited feedback. While Thompson sampling is one\nof the most promising algorithms on a variety of online decision-making\nproblems, its properties for stochastic partial monitoring have not been\ntheoretically investigated, and the existing algorithm relies on a heuristic\napproximation of the posterior distribution. To mitigate these problems, we\npresent a novel Thompson-sampling-based algorithm, which enables us to exactly\nsample the target parameter from the posterior distribution. Besides, we prove\nthat the new algorithm achieves the logarithmic problem-dependent expected\npseudo-regret $\\mathrm{O}(\\log T)$ for a linearized variant of the problem with\nlocal observability. This result is the first regret bound of Thompson sampling\nfor partial monitoring, which also becomes the first logarithmic regret bound\nof Thompson sampling for linear bandits.",
          "link": "http://arxiv.org/abs/2006.09668",
          "publishedOn": "2021-06-11T01:42:17.588Z",
          "wordCount": null,
          "title": "Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring. (arXiv:2006.09668v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1\">Benedikt Hilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which work well for large\ndatasets, but tend to overfit when applied in low resource scenarios. One\nsolution to tackle this issue is to generate synthetic data with a trained\ntext-to-speech system (TTS) if additional text is available. This was\nsuccessfully applied in many publications with AED systems. We present a novel\napproach of silence correction in the data pre-processing for TTS systems which\nincreases the robustness when training on corpora targeted for ASR\napplications. In this work we do not only show the successful application of\nsynthetic data for AED systems, but also test the same method on a highly\noptimized state-of-the-art Hybrid ASR system and a competitive monophone based\nsystem using connectionist-temporal-classification (CTC). We show that for the\nlater systems the addition of synthetic data only has a minor effect, but they\nstill outperform the AED systems by a large margin on LibriSpeech-100h. We\nachieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the\nclean/noisy test-sets, surpassing any previous state-of-the-art systems that do\nnot include unlabeled audio data.",
          "link": "http://arxiv.org/abs/2104.05379",
          "publishedOn": "2021-06-11T01:42:17.515Z",
          "wordCount": null,
          "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_T/0/1/0/all/0/1\">Tung Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trung Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhimkul_S/0/1/0/all/0/1\">Sanzhar Rakhimkul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>",
          "description": "Model agnostic meta-learning (MAML) is a popular state-of-the-art\nmeta-learning algorithm that provides good weight initialization of a model\ngiven a variety of learning tasks. The model initialized by provided weight can\nbe fine-tuned to an unseen task despite only using a small amount of samples\nand within a few adaptation steps. MAML is simple and versatile but requires\ncostly learning rate tuning and careful design of the task distribution which\naffects its scalability and generalization. This paper proposes a more robust\nMAML based on an adaptive learning scheme and a prioritization task buffer(PTB)\nreferred to as Robust MAML (RMAML) for improving scalability of training\nprocess and alleviating the problem of distribution mismatch. RMAML uses\ngradient-based hyper-parameter optimization to automatically find the optimal\nlearning rate and uses the PTB to gradually adjust train-ing task distribution\ntoward testing task distribution over the course of training. Experimental\nresults on meta reinforcement learning environments demonstrate a substantial\nperformance gain as well as being less sensitive to hyper-parameter choice and\nrobust to distribution mismatch.",
          "link": "http://arxiv.org/abs/2103.08233",
          "publishedOn": "2021-06-11T01:42:17.500Z",
          "wordCount": null,
          "title": "Robust MAML: Prioritization task buffer with adaptive learning process for model-agnostic meta-learning. (arXiv:2103.08233v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04298",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1\">Christoph L&#xfc;scher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Acoustic modeling of raw waveform and learning feature extractors as part of\nthe neural network classifier has been the goal of many studies in the area of\nautomatic speech recognition (ASR). Recently, one line of research has focused\non frameworks that can be pre-trained on audio-only data in an unsupervised\nfashion and aim at improving downstream ASR tasks. In this work, we investigate\nthe usefulness of one of these front-end frameworks, namely wav2vec, for hybrid\nASR systems. In addition to deploying a pre-trained feature extractor, we\nexplore how to make use of an existing acoustic model (AM) trained on the same\ntask with different features as well. Another neural front-end which is only\ntrained together with the supervised ASR loss as well as traditional Gammatone\nfeatures are applied for comparison. Moreover, it is shown that the AM can be\nretrofitted with i-vectors for speaker adaptation. Finally, the described\nfeatures are combined in order to further advance the performance. With the\nfinal best system, we obtain a relative improvement of 4% and 6% over our\nprevious best model on the LibriSpeech test-clean and test-other sets.",
          "link": "http://arxiv.org/abs/2104.04298",
          "publishedOn": "2021-06-11T01:42:17.494Z",
          "wordCount": null,
          "title": "Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guansong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>",
          "description": "We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.",
          "link": "http://arxiv.org/abs/2009.06847",
          "publishedOn": "2021-06-11T01:42:17.293Z",
          "wordCount": 650,
          "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Refinetti_M/0/1/0/all/0/1\">Maria Refinetti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ohana_R/0/1/0/all/0/1\">Ruben Ohana</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>",
          "description": "Direct Feedback Alignment (DFA) is emerging as an efficient and biologically\nplausible alternative to the ubiquitous backpropagation algorithm for training\ndeep neural networks. Despite relying on random feedback weights for the\nbackward pass, DFA successfully trains state-of-the-art models such as\nTransformers. On the other hand, it notoriously fails to train convolutional\nnetworks. An understanding of the inner workings of DFA to explain these\ndiverging results remains elusive. Here, we propose a theory for the success of\nDFA. We first show that learning in shallow networks proceeds in two steps: an\nalignment phase, where the model adapts its weights to align the approximate\ngradient with the true gradient of the loss function, is followed by a\nmemorisation phase, where the model focuses on fitting the data. This two-step\nprocess has a degeneracy breaking effect: out of all the low-loss solutions in\nthe landscape, a network trained with DFA naturally converges to the solution\nwhich maximises gradient alignment. We also identify a key quantity underlying\nalignment in deep linear networks: the conditioning of the alignment matrices.\nThe latter enables a detailed understanding of the impact of data structure on\nalignment, and suggests a simple explanation for the well-known failure of DFA\nto train convolutional neural networks. Numerical experiments on MNIST and\nCIFAR10 clearly demonstrate degeneracy breaking in deep non-linear networks and\nshow that the align-then-memorise process occurs sequentially from the bottom\nlayers of the network to the top.",
          "link": "http://arxiv.org/abs/2011.12428",
          "publishedOn": "2021-06-11T01:42:17.287Z",
          "wordCount": 727,
          "title": "Align, then memorise: the dynamics of learning with feedback alignment. (arXiv:2011.12428v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhengyi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1\">Ryo Hachiuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "We propose a method for object-aware 3D egocentric pose estimation that\ntightly integrates kinematics modeling, dynamics modeling, and scene object\ninformation. Unlike prior kinematics or dynamics-based approaches where the two\ncomponents are used disjointly, we synergize the two approaches via\ndynamics-regulated training. At each timestep, a kinematic model is used to\nprovide a target pose using video evidence and simulation state. Then, a\nprelearned dynamics model attempts to mimic the kinematic pose in a physics\nsimulator. By comparing the pose instructed by the kinematic model against the\npose generated by the dynamics model, we can use their misalignment to further\nimprove the kinematic model. By factoring in the 6DoF pose of objects (e.g.,\nchairs, boxes) in the scene, we demonstrate for the first time, the ability to\nestimate physically-plausible 3D human-object interactions using a single\nwearable camera. We evaluate our egocentric pose estimation method in both\ncontrolled laboratory settings and real-world scenarios.",
          "link": "http://arxiv.org/abs/2106.05969",
          "publishedOn": "2021-06-11T01:42:17.275Z",
          "wordCount": 596,
          "title": "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grinsztajn_N/0/1/0/all/0/1\">Nathan Grinsztajn</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1\">Louis Leconte</a> (MLIA, CMAP), <a href=\"http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1\">Philippe Preux</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1\">Edouard Oyallon</a> (MLIA)",
          "description": "We present a new approach for learning unsupervised node representations in\ncommunity graphs. We significantly extend the Interferometric Graph Transform\n(IGT) to community labeling: this non-linear operator iteratively extracts\nfeatures that take advantage of the graph topology through demodulation\noperations. An unsupervised feature extraction step cascades modulus\nnon-linearity with linear operators that aim at building relevant invariants\nfor community labeling. Via a simplified model, we show that the IGT\nconcentrates around the E-IGT: those two representations are related through\nsome ergodicity properties. Experiments on community labeling tasks show that\nthis unsupervised representation achieves performances at the level of the\nstate of the art on the standard and challenging datasets Cora, Citeseer,\nPubmed and WikiCS.",
          "link": "http://arxiv.org/abs/2106.05875",
          "publishedOn": "2021-06-11T01:42:17.212Z",
          "wordCount": 542,
          "title": "Interferometric Graph Transform for Community Labeling. (arXiv:2106.05875v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongwei Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1\">Jingyi Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hang_H/0/1/0/all/0/1\">Hanyuan Hang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiabin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "As an important branch of weakly supervised learning, partial label learning\ndeals with data where each instance is assigned with a set of candidate labels,\nwhereas only one of them is true. Despite many methodology studies on learning\nfrom partial labels, there still lacks theoretical understandings of their risk\nconsistent properties under relatively weak assumptions, especially on the link\nbetween theoretical results and the empirical choice of parameters. In this\npaper, we propose a family of loss functions named \\textit{Leveraged Weighted}\n(LW) loss, which for the first time introduces the leverage parameter $\\beta$\nto consider the trade-off between losses on partial labels and non-partial\nones. From the theoretical side, we derive a generalized result of risk\nconsistency for the LW loss in learning from partial labels, based on which we\nprovide guidance to the choice of the leverage parameter $\\beta$. In\nexperiments, we verify the theoretical guidance, and show the high\neffectiveness of our proposed LW loss on both benchmark and real datasets\ncompared with other state-of-the-art partial label learning algorithms.",
          "link": "http://arxiv.org/abs/2106.05731",
          "publishedOn": "2021-06-11T01:42:17.207Z",
          "wordCount": 604,
          "title": "Leveraged Weighted Loss for Partial Label Learning. (arXiv:2106.05731v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1\">Ou Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Weiyao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yingjun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haixiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1\">Qinghu Hou</a>",
          "description": "A common assumption in machine learning is that samples are independently and\nidentically distributed (i.i.d). However, the contributions of different\nsamples are not identical in training. Some samples are difficult to learn and\nsome samples are noisy. The unequal contributions of samples has a considerable\neffect on training performances. Studies focusing on unequal sample\ncontributions (e.g., easy, hard, noisy) in learning usually refer to these\ncontributions as robust machine learning (RML). Weighing and regularization are\ntwo common techniques in RML. Numerous learning algorithms have been proposed\nbut the strategies for dealing with easy/hard/noisy samples differ or even\ncontradict with different learning algorithms. For example, some strategies\ntake the hard samples first, whereas some strategies take easy first.\nConducting a clear comparison for existing RML algorithms in dealing with\ndifferent samples is difficult due to lack of a unified theoretical framework\nfor RML. This study attempts to construct a mathematical foundation for RML\nbased on the bias-variance trade-off theory. A series of definitions and\nproperties are presented and proved. Several classical learning algorithms are\nalso explained and compared. Improvements of existing methods are obtained\nbased on the comparison. A unified method that combines two classical learning\nstrategies is proposed.",
          "link": "http://arxiv.org/abs/2106.05522",
          "publishedOn": "2021-06-11T01:42:17.201Z",
          "wordCount": 631,
          "title": "A Mathematical Foundation for Robust Machine Learning based on Bias-Variance Trade-off. (arXiv:2106.05522v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1\">Michela Antonelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1\">Annika Reinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1\">Keyvan Farahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1\">AnnetteKopp-Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1\">Geert Litjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1\">Bjoern Menze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1\">Olaf Ronneberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1\">Ronald M.Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1\">Michel Bilello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1\">Patrick Bilic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1\">Patrick F. Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1\">Richard K. G. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1\">Marc J. Gollub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1\">Stephan H. Heckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1\">William R. Jarnagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1\">Maureen K. McHugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1\">Sandy Napel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1\">Jennifer S. Goli Pernicka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1\">Kawal Rhode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1\">Catalina Tobon-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1\">James A. Meakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1\">Sebastien Ourselin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbelaez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1\">Byeonguk Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1\">Laura Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jianjiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Baochun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuanfeng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Fucang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1\">Dorit Merhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Akshay Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Beomhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1\">Mathias Perslev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1\">Ramin Rezaiifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1\">Oliver Rippel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1\">Ignacio Sarasua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jaemin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1\">Christian Wachinger</a>, et al. (9 additional authors not shown)",
          "description": "International challenges have become the de facto standard for comparative\nassessment of image analysis algorithms given a specific task. Segmentation is\nso far the most widely investigated medical image processing task, but the\nvarious segmentation challenges have typically been organized in isolation,\nsuch that algorithm development was driven by the need to tackle a single\nspecific clinical problem. We hypothesized that a method capable of performing\nwell on multiple tasks will generalize well to a previously unseen task and\npotentially outperform a custom-designed solution. To investigate the\nhypothesis, we organized the Medical Segmentation Decathlon (MSD) - a\nbiomedical image analysis challenge, in which algorithms compete in a multitude\nof both tasks and modalities. The underlying data set was designed to explore\nthe axis of difficulties typically encountered when dealing with medical\nimages, such as small data sets, unbalanced labels, multi-site data and small\nobjects. The MSD challenge confirmed that algorithms with a consistent good\nperformance on a set of tasks preserved their good average performance on a\ndifferent set of previously unseen tasks. Moreover, by monitoring the MSD\nwinner for two years, we found that this algorithm continued generalizing well\nto a wide range of other clinical problems, further confirming our hypothesis.\nThree main conclusions can be drawn from this study: (1) state-of-the-art image\nsegmentation algorithms are mature, accurate, and generalize well when\nretrained on unseen tasks; (2) consistent algorithmic performance across\nmultiple tasks is a strong surrogate of algorithmic generalizability; (3) the\ntraining of accurate AI segmentation models is now commoditized to non AI\nexperts.",
          "link": "http://arxiv.org/abs/2106.05735",
          "publishedOn": "2021-06-11T01:42:17.184Z",
          "wordCount": 811,
          "title": "The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1\">Kwei-Herng Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaixiong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>",
          "description": "Supervised regression to demonstrations has been demonstrated to be a stable\nway to train deep policy networks. We are motivated to study how we can take\nfull advantage of supervised loss functions for stably training deep\nreinforcement learning agents. This is a challenging task because it is unclear\nhow the training data could be collected to enable policy improvement. In this\nwork, we propose Self-Supervised Reinforcement Learning (SSRL), a simple\nalgorithm that optimizes policies with purely supervised losses. We demonstrate\nthat, without policy gradient or value estimation, an iterative procedure of\n``labeling\" data and supervised regression is sufficient to drive stable policy\nimprovement. By selecting and imitating trajectories with high episodic\nrewards, SSRL is surprisingly competitive to contemporary algorithms with more\nstable performance and less running time, showing the potential of solving\nreinforcement learning with supervised learning techniques. The code is\navailable at https://github.com/daochenzha/SSRL",
          "link": "http://arxiv.org/abs/2106.05526",
          "publishedOn": "2021-06-11T01:42:17.166Z",
          "wordCount": 566,
          "title": "Simplifying Deep Reinforcement Learning via Self-Supervision. (arXiv:2106.05526v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulikov_I/0/1/0/all/0/1\">Ilia Kulikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite its wide use, recent studies have revealed unexpected and undesirable\nproperties of neural autoregressive sequence models trained with maximum\nlikelihood, such as an unreasonably high affinity to short sequences after\ntraining and to infinitely long sequences at decoding time. We propose to study\nthese phenomena by investigating how the modes, or local maxima, of a\ndistribution are maintained throughout the full learning chain of the\nground-truth, empirical, learned and decoding-induced distributions, via the\nnewly proposed mode recovery cost. We design a tractable testbed where we build\nthree types of ground-truth distributions: (1) an LSTM based structured\ndistribution, (2) an unstructured distribution where probability of a sequence\ndoes not depend on its content, and (3) a product of these two which we call a\nsemi-structured distribution. Our study reveals both expected and unexpected\nfindings. First, starting with data collection, mode recovery cost strongly\nrelies on the ground-truth distribution and is most costly with the\nsemi-structured distribution. Second, after learning, mode recovery cost from\nthe ground-truth distribution may increase or decrease compared to data\ncollection, with the largest cost degradation occurring with the\nsemi-structured ground-truth distribution. Finally, the ability of the\ndecoding-induced distribution to recover modes from the learned distribution is\nhighly impacted by the choices made earlier in the learning chain. We conclude\nthat future research must consider the entire learning chain in order to fully\nunderstand the potentials and perils and to further improve neural\nautoregressive sequence models.",
          "link": "http://arxiv.org/abs/2106.05459",
          "publishedOn": "2021-06-11T01:42:17.131Z",
          "wordCount": 673,
          "title": "Mode recovery in neural autoregressive sequence modeling. (arXiv:2106.05459v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Limin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuangping Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1\">Ning Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Ning Gu</a>",
          "description": "The ultrasound (US) screening of the infant hip is vital for the early\ndiagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH\nrefers to measuring alpha and beta angles that quantify hip joint development.\nThese two angles are calculated from key anatomical landmarks and structures of\nthe hip. However, this measurement process is not trivial for sonographers and\nusually requires a thorough understanding of complex anatomical structures. In\nthis study, we propose a multi-task framework to learn the relationships among\nlandmarks and structures jointly and automatically evaluate DDH. Our multi-task\nnetworks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as\nthe basic framework to detect and segment key anatomical structures and add one\nlandmark detection branch to form a new multi-task framework. Secondly, we\npropose a novel shape similarity loss to refine the incomplete anatomical\nstructure prediction robustly and accurately. Thirdly, we further incorporate\nthe landmark-structure consistent prior to ensure the consistency of the bony\nrim estimated from the segmented structure and the detected landmark. In our\nexperiments, 1,231 US images of the infant hip from 632 patients are collected,\nof which 247 images from 126 patients are tested. The average errors in alpha\nand beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%\nestimates of alpha and beta angles have errors less than 5 degrees,\nrespectively. Experimental results demonstrate that the proposed method can\naccurately and robustly realize the automatic evaluation of DDH, showing great\npotential for clinical application.",
          "link": "http://arxiv.org/abs/2106.05458",
          "publishedOn": "2021-06-11T01:42:17.107Z",
          "wordCount": 733,
          "title": "Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1\">Eun-Soo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1\">HyeongGwan Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Kyusam Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1\">Yongkeun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Soonhwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Min Soo Kim</a>",
          "description": "We present a novel deep neural model for text detection in document images.\nFor robust text detection in noisy scanned documents, the advantages of\nmulti-task learning are adopted by adding an auxiliary task of text\nenhancement. Namely, our proposed model is designed to perform noise reduction\nand text region enhancement as well as text detection. Moreover, we enrich the\ntraining data for the model with synthesized document images that are fully\nlabeled for text detection and enhancement, thus overcome the insufficiency of\nlabeled document image data. For the effective exploitation of the synthetic\nand real data, the training process is separated in two phases. The first phase\nis training only synthetic data in a fully-supervised manner. Then real data\nwith only detection labels are added in the second phase. The enhancement task\nfor the real data is weakly-supervised with information from their detection\nlabels. Our methods are demonstrated in a real document dataset with\nperformances exceeding those of other text detection methods. Moreover,\nablations are conducted and the results confirm the effectiveness of the\nsynthetic data, auxiliary task, and weak-supervision. Whereas the existing text\ndetection studies mostly focus on the text in scenes, our proposed method is\noptimized to the applications for the text in scanned documents.",
          "link": "http://arxiv.org/abs/2106.05542",
          "publishedOn": "2021-06-11T01:42:17.101Z",
          "wordCount": 668,
          "title": "DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1\">Adrian Bulat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1\">Juan-Manuel Perez-Rua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Swathikiran Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>",
          "description": "This paper is on video recognition using Transformers. Very recent attempts\nin this area have demonstrated promising results in terms of recognition\naccuracy, yet they have been also shown to induce, in many cases, significant\ncomputational overheads due to the additional modelling of the temporal\ninformation. In this work, we propose a Video Transformer model the complexity\nof which scales linearly with the number of frames in the video sequence and\nhence induces \\textit{no overhead} compared to an image-based Transformer\nmodel. To achieve this, our model makes two approximations to the full\nspace-time attention used in Video Transformers: (a) It restricts time\nattention to a local temporal window and capitalizes on the Transformer's depth\nto obtain full temporal coverage of the video sequence. (b) It uses efficient\nspace-time mixing to attend \\textit{jointly} spatial and temporal locations\nwithout inducing any additional cost on top of a spatial-only attention model.\nWe also show how to integrate 2 very lightweight mechanisms for global\ntemporal-only attention which provide additional accuracy improvements at\nminimal computational cost. We demonstrate that our model produces very high\nrecognition accuracy on the most popular video recognition datasets while at\nthe same time being significantly more efficient than other Video Transformer\nmodels. Code will be made available.",
          "link": "http://arxiv.org/abs/2106.05968",
          "publishedOn": "2021-06-11T01:42:17.092Z",
          "wordCount": 643,
          "title": "Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pfitzinger_J/0/1/0/all/0/1\">Johann Pfitzinger</a>",
          "description": "Adoption of deep neural networks in fields such as economics or finance has\nbeen constrained by the lack of interpretability of model outcomes. This paper\nproposes a generative neural network architecture - the parameter encoder\nneural network (PENN) - capable of estimating local posterior distributions for\nthe parameters of a regression model. The parameters fully explain predictions\nin terms of the inputs and permit visualization, interpretation and inference\nin the presence of complex heterogeneous effects and feature dependencies. The\nuse of Bayesian inference techniques offers an intuitive mechanism to\nregularize local parameter estimates towards a stable solution, and to reduce\nnoise-fitting in settings of limited data availability. The proposed neural\nnetwork is particularly well-suited to applications in economics and finance,\nwhere parameter inference plays an important role. An application to an asset\npricing problem demonstrates how the PENN can be used to explore nonlinear risk\ndynamics in financial markets, and to compare empirical nonlinear effects to\nbehavior posited by financial theory.",
          "link": "http://arxiv.org/abs/2106.05536",
          "publishedOn": "2021-06-11T01:42:17.086Z",
          "wordCount": 585,
          "title": "An Interpretable Neural Network for Parameter Inference. (arXiv:2106.05536v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05724",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_C/0/1/0/all/0/1\">Chun Wang</a>",
          "description": "In prescriptive analytics, the decision-maker observes historical samples of\n$(X, Y)$, where $Y$ is the uncertain problem parameter and $X$ is the\nconcurrent covariate, without knowing the joint distribution. Given an\nadditional covariate observation $x$, the goal is to choose a decision $z$\nconditional on this observation to minimize the cost $\\mathbb{E}[c(z,Y)|X=x]$.\nThis paper proposes a new distributionally robust approach under Wasserstein\nambiguity sets, in which the nominal distribution of $Y|X=x$ is constructed\nbased on the Nadaraya-Watson kernel estimator concerning the historical data.\nWe show that the nominal distribution converges to the actual conditional\ndistribution under the Wasserstein distance. We establish the out-of-sample\nguarantees and the computational tractability of the framework. Through\nsynthetic and empirical experiments about the newsvendor problem and portfolio\noptimization, we demonstrate the strong performance and practical value of the\nproposed framework.",
          "link": "http://arxiv.org/abs/2106.05724",
          "publishedOn": "2021-06-11T01:42:17.081Z",
          "wordCount": 560,
          "title": "Distributionally Robust Prescriptive Analytics with Wasserstein Distance. (arXiv:2106.05724v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advance in score-based models incorporates the stochastic differential\nequation (SDE), which brings the state-of-the art performance on image\ngeneration tasks. This paper improves such score-based models by analyzing the\nmodel at the zero perturbation noise. In real datasets, the score function\ndiverges as the perturbation noise ($\\sigma$) decreases to zero, and this\nobservation leads an argument that the score estimation fails at $\\sigma=0$\nwith any neural network structure. Subsequently, we introduce Unbounded Noise\nConditional Score Network (UNCSN) that resolves the score diverging problem\nwith an easily applicable modification to any noise conditional score-based\nmodels. Additionally, we introduce a new type of SDE, so the exact log\nlikelihood can be calculated from the newly suggested SDE. On top of that, the\nassociated loss function mitigates the loss imbalance issue in a mini-batch,\nand we present a theoretic analysis on the proposed loss to uncover the behind\nmechanism of the data distribution modeling by the score-based models.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2021-06-11T01:42:17.062Z",
          "wordCount": 594,
          "title": "Score Matching Model for Unbounded Data Score. (arXiv:2106.05527v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1\">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massi_M/0/1/0/all/0/1\">Michela C. Massi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotta_V/0/1/0/all/0/1\">Verena Gotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Timothy M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasella_F/0/1/0/all/0/1\">Flavio Vasella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neidert_M/0/1/0/all/0/1\">Marian C. Neidert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1\">Marc Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Survival analysis has gained significant attention in the medical domain and\nhas many far-reaching applications. Although a variety of machine learning\nmethods have been introduced for tackling time-to-event prediction in\nunstructured data with complex dependencies, clustering of survival data\nremains an under-explored problem. The latter is particularly helpful in\ndiscovering patient subpopulations whose survival is regulated by different\ngenerative mechanisms, a critical problem in precision medicine. To this end,\nwe introduce a novel probabilistic approach to cluster survival data in a\nvariational deep clustering setting. Our proposed method employs a deep\ngenerative model to uncover the underlying distribution of both the explanatory\nvariables and the potentially censored survival times. We compare our model to\nthe related work on survival clustering in comprehensive experiments on a range\nof synthetic, semi-synthetic, and real-world datasets. Our proposed method\nperforms better at identifying clusters and is competitive at predicting\nsurvival times in terms of the concordance index and relative absolute error.\nTo further demonstrate the usefulness of our approach, we show that our method\nidentifies meaningful clusters from an observational cohort of hemodialysis\npatients that are consistent with previous clinical findings.",
          "link": "http://arxiv.org/abs/2106.05763",
          "publishedOn": "2021-06-11T01:42:17.050Z",
          "wordCount": 628,
          "title": "A Deep Variational Approach to Clustering Survival Data. (arXiv:2106.05763v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jing_M/0/1/0/all/0/1\">Mingxuan Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenbing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fuchun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1\">Tao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "It has been a challenge to learning skills for an agent from long-horizon\nunannotated demonstrations. Existing approaches like Hierarchical Imitation\nLearning(HIL) are prone to compounding errors or suboptimal solutions. In this\npaper, we propose Option-GAIL, a novel method to learn skills at long horizon.\nThe key idea of Option-GAIL is modeling the task hierarchy by options and train\nthe policy via generative adversarial optimization. In particular, we propose\nan Expectation-Maximization(EM)-style algorithm: an E-step that samples the\noptions of expert conditioned on the current learned policy, and an M-step that\nupdates the low- and high-level policies of agent simultaneously to minimize\nthe newly proposed option-occupancy measurement between the expert and the\nagent. We theoretically prove the convergence of the proposed algorithm.\nExperiments show that Option-GAIL outperforms other counterparts consistently\nacross a variety of tasks.",
          "link": "http://arxiv.org/abs/2106.05530",
          "publishedOn": "2021-06-11T01:42:17.043Z",
          "wordCount": 564,
          "title": "Adversarial Option-Aware Hierarchical Imitation Learning. (arXiv:2106.05530v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Loi_N/0/1/0/all/0/1\">Nicola Loi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borile_C/0/1/0/all/0/1\">Claudio Borile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ucci_D/0/1/0/all/0/1\">Daniele Ucci</a>",
          "description": "The constant growth in the number of malware - software or code fragment\npotentially harmful for computers and information networks - and the use of\nsophisticated evasion and obfuscation techniques have seriously hindered\nclassic signature-based approaches. On the other hand, malware detection\nsystems based on machine learning techniques started offering a promising\nalternative to standard approaches, drastically reducing analysis time and\nturning out to be more robust against evasion and obfuscation techniques. In\nthis paper, we propose a malware taxonomic classification pipeline able to\nclassify Windows Portable Executable files (PEs). Given an input PE sample, it\nis first classified as either malicious or benign. If malicious, the pipeline\nfurther analyzes it in order to establish its threat type, family, and\nbehavior(s). We tested the proposed pipeline on the open source dataset EMBER,\ncontaining approximately 1 million PE samples, analyzed through static\nanalysis. Obtained malware detection results are comparable to other academic\nworks in the current state of art and, in addition, we provide an in-depth\nclassification of malicious samples. Models used in the pipeline provides\ninterpretable results which can help security analysts in better understanding\ndecisions taken by the automated pipeline.",
          "link": "http://arxiv.org/abs/2106.05625",
          "publishedOn": "2021-06-11T01:42:17.037Z",
          "wordCount": 636,
          "title": "Towards an Automated Pipeline for Detecting and Classifying Malware through Machine Learning. (arXiv:2106.05625v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-11T01:42:17.019Z",
          "wordCount": 611,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1\">Nick Feamster</a>",
          "description": "Data representation plays a critical role in the performance of novelty\ndetection (or ``anomaly detection'') methods in machine learning. The data\nrepresentation of network traffic often determines the effectiveness of these\nmodels as much as the model itself. The wide range of novel events that network\noperators need to detect (e.g., attacks, malware, new applications, changes in\ntraffic demands) introduces the possibility for a broad range of possible\nmodels and data representations. In each scenario, practitioners must spend\nsignificant effort extracting and engineering features that are most predictive\nfor that situation or application. While anomaly detection is well-studied in\ncomputer networking, much existing work develops specific models that presume a\nparticular representation -- often IPFIX/NetFlow. Yet, other representations\nmay result in higher model accuracy, and the rise of programmable networks now\nmakes it more practical to explore a broader range of representations. To\nfacilitate such exploration, we develop a systematic framework, open-source\ntoolkit, and public Python library that makes it both possible and easy to\nextract and generate features from network traffic and perform and end-to-end\nevaluation of these representations across most prevalent modern novelty\ndetection models. We first develop and publicly release an open-source tool, an\naccompanying Python library (NetML), and end-to-end pipeline for novelty\ndetection in network traffic. Second, we apply this tool to five different\nnovelty detection problems in networking, across a range of scenarios from\nattack detection to novel device detection. Our findings general insights and\nguidelines concerning which features appear to be more appropriate for\nparticular situations.",
          "link": "http://arxiv.org/abs/2006.16993",
          "publishedOn": "2021-06-11T01:42:17.013Z",
          "wordCount": 714,
          "title": "Feature Extraction for Novelty Detection in Network Traffic. (arXiv:2006.16993v2 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05767",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gijsbers_P/0/1/0/all/0/1\">Pieter Gijsbers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rijn_J/0/1/0/all/0/1\">Jan N. van Rijn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanschoren_J/0/1/0/all/0/1\">Joaquin Vanschoren</a>",
          "description": "Hyperparameter optimization in machine learning (ML) deals with the problem\nof empirically learning an optimal algorithm configuration from data, usually\nformulated as a black-box optimization problem. In this work, we propose a\nzero-shot method to meta-learn symbolic default hyperparameter configurations\nthat are expressed in terms of the properties of the dataset. This enables a\nmuch faster, but still data-dependent, configuration of the ML algorithm,\ncompared to standard hyperparameter optimization approaches. In the past,\nsymbolic and static default values have usually been obtained as hand-crafted\nheuristics. We propose an approach of learning such symbolic configurations as\nformulas of dataset properties from a large set of prior evaluations on\nmultiple datasets by optimizing over a grammar of expressions using an\nevolutionary algorithm. We evaluate our method on surrogate empirical\nperformance models as well as on real data across 6 ML algorithms on more than\n100 datasets and demonstrate that our method indeed finds viable symbolic\ndefaults.",
          "link": "http://arxiv.org/abs/2106.05767",
          "publishedOn": "2021-06-11T01:42:16.995Z",
          "wordCount": 600,
          "title": "Meta-Learning for Symbolic Hyperparameter Defaults. (arXiv:2106.05767v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "High-quality data is critical to train performant Machine Learning (ML)\nmodels, highlighting the importance of Data Quality Management (DQM). Existing\nDQM schemes often cannot satisfactorily improve ML performance because, by\ndesign, they are oblivious to downstream ML tasks. Besides, they cannot handle\nvarious data quality issues (especially those caused by adversarial attacks)\nand have limited applications to only certain types of ML models. Recently,\ndata valuation approaches (e.g., based on the Shapley value) have been\nleveraged to perform DQM; yet, empirical studies have observed that their\nperformance varies considerably based on the underlying data and training\nprocess. In this paper, we propose a task-driven, multi-purpose, model-agnostic\nDQM framework, DataSifter, which is optimized towards a given downstream ML\ntask, capable of effectively removing data points with various defects, and\napplicable to diverse models. Specifically, we formulate DQM as an optimization\nproblem and devise a scalable algorithm to solve it. Furthermore, we propose a\ntheoretical framework for comparing the worst-case performance of different DQM\nstrategies. Remarkably, our results show that the popular strategy based on the\nShapley value may end up choosing the worst data subset in certain practical\nscenarios. Our evaluation shows that DataSifter achieves and most often\nsignificantly improves the state-of-the-art performance over a wide range of\nDQM tasks, including backdoor, poison, noisy/mislabel data detection, data\nsummarization, and data debiasing.",
          "link": "http://arxiv.org/abs/2106.05484",
          "publishedOn": "2021-06-11T01:42:16.989Z",
          "wordCount": 644,
          "title": "A Unified Framework for Task-Driven Data Quality Management. (arXiv:2106.05484v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05582",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ross_M/0/1/0/all/0/1\">Magnus Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Smith_M/0/1/0/all/0/1\">Michael T. Smith</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1\">Mauricio A. &#xc1;lvarez</a>",
          "description": "This paper introduces a method for the nonparametric Bayesian learning of\nnonlinear operators, through the use of the Volterra series with kernels\nrepresented using Gaussian processes (GPs), which we term the nonparametric\nVolterra kernels model (NVKM). When the input function to the operator is\nunobserved and has a GP prior, the NVKM constitutes a powerful method for both\nsingle and multiple output regression, and can be viewed as a nonlinear and\nnonparametric latent force model. When the input function is observed, the NVKM\ncan be used to perform Bayesian system identification. We use recent advances\nin efficient sampling of explicit functions from GPs to map process\nrealisations through the Volterra series without resorting to numerical\nintegration, allowing scalability through doubly stochastic variational\ninference, and avoiding the need for Gaussian approximations of the output\nprocesses. We demonstrate the performance of the model for both multiple output\nregression and system identification using standard benchmarks.",
          "link": "http://arxiv.org/abs/2106.05582",
          "publishedOn": "2021-06-11T01:42:16.967Z",
          "wordCount": 583,
          "title": "Learning Nonparametric Volterra Kernels with Gaussian Processes. (arXiv:2106.05582v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1\">Jean-Yves Franceschi</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1\">Sylvain Lamprier</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a> (MLIA)",
          "description": "Theoretical analyses for Generative Adversarial Networks (GANs) generally\nassume an arbitrarily large family of discriminators and do not consider the\ncharacteristics of the architectures used in practice. We show that this\nframework of analysis is too simplistic to properly analyze GAN training. To\ntackle this issue, we leverage the theory of infinite-width neural networks to\nmodel neural discriminator training for a wide range of adversarial losses via\nits Neural Tangent Kernel (NTK). Our analytical results show that GAN\ntrainability primarily depends on the discriminator's architecture. We further\nstudy the discriminator for specific architectures and losses, and highlight\nproperties providing a new understanding of GAN training. For example, we find\nthat GANs trained with the integral probability metric loss minimize the\nmaximum mean discrepancy with the NTK as kernel. Our conclusions demonstrate\nthe analysis opportunities provided by the proposed framework, which paves the\nway for better and more principled GAN models. We release a generic GAN\nanalysis toolkit based on our framework that supports the empirical part of our\nstudy.",
          "link": "http://arxiv.org/abs/2106.05566",
          "publishedOn": "2021-06-11T01:42:16.961Z",
          "wordCount": 615,
          "title": "A Neural Tangent Kernel Perspective of GANs. (arXiv:2106.05566v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Graph self-supervised learning has gained increasing attention due to its\ncapacity to learn expressive node representations. Many pretext tasks, or loss\nfunctions have been designed from distinct perspectives. However, we observe\nthat different pretext tasks affect downstream tasks differently cross\ndatasets, which suggests that searching pretext tasks is crucial for graph\nself-supervised learning. Different from existing works focusing on designing\nsingle pretext tasks, this work aims to investigate how to automatically\nleverage multiple pretext tasks effectively. Nevertheless, evaluating\nrepresentations derived from multiple pretext tasks without direct access to\nground truth labels makes this problem challenging. To address this obstacle,\nwe make use of a key principle of many real-world graphs, i.e., homophily, or\nthe principle that ``like attracts like,'' as the guidance to effectively\nsearch various self-supervised pretext tasks. We provide theoretical\nunderstanding and empirical evidence to justify the flexibility of homophily in\nthis search task. Then we propose the AutoSSL framework which can automatically\nsearch over combinations of various self-supervised tasks. By evaluating the\nframework on 7 real-world datasets, our experimental results show that AutoSSL\ncan significantly boost the performance on downstream tasks including node\nclustering and node classification compared with training under individual\ntasks. Code will be released at https://github.com/ChandlerBang/AutoSSL.",
          "link": "http://arxiv.org/abs/2106.05470",
          "publishedOn": "2021-06-11T01:42:16.954Z",
          "wordCount": 630,
          "title": "Automated Self-Supervised Learning for Graphs. (arXiv:2106.05470v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_V/0/1/0/all/0/1\">Vincent Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_I/0/1/0/all/0/1\">Ivey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guilbault_A/0/1/0/all/0/1\">Alexandre Guilbault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatis_J/0/1/0/all/0/1\">Jaime Tatis</a>",
          "description": "Slowly changing variables in a continuous state space constitute an important\ncategory of reinforcement learning and see its application in many domains,\nsuch as modeling a climate control system where temperature, humidity, etc.\nchange slowly over time. However, this subject is less addressed in recent\nstudies. Classical methods with certain variants, such as Dynamic Programming\nwith Tile Coding which discretizes the state space, fail to handle slowly\nchanging variables because those methods cannot capture the tiny changes in\neach transition step, as it is computationally expensive or impossible to\nestablish an extremely granular grid system. In this paper, we introduce a\nHyperspace Neighbor Penetration (HNP) approach that solves the problem. HNP\ncaptures in each transition step the state's partial \"penetration\" into its\nneighboring hyper-tiles in the gridded hyperspace, thus does not require the\ntransition to be inter-tile in order for the change to be captured. Therefore,\nHNP allows for a very coarse grid system, which makes the computation feasible.\nHNP assumes near linearity of the transition function in a local space, which\nis commonly satisfied. In summary, HNP can be orders of magnitude more\nefficient than classical method in handling slowly changing variables in\nreinforcement learning. We have made an industrial implementation of NHP with a\ngreat success.",
          "link": "http://arxiv.org/abs/2106.05497",
          "publishedOn": "2021-06-11T01:42:16.939Z",
          "wordCount": 661,
          "title": "Hyperspace Neighbor Penetration Approach to Dynamic Programming for Model-Based Reinforcement Learning Problems with Slowly Changing Variables in A Continuous State Space. (arXiv:2106.05497v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1\">Ivan Drokin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1\">Elena Ericheva</a>",
          "description": "This paper proposes novel end-to-end framework for detecting suspicious\npulmonary nodules in chest CT scans. The method core idea is a new nodule\nsegmentation architecture with a model-based feature projection block on\nthree-dimensional convolutions. This block acts as a preliminary feature\nextractor for a two-dimensional U-Net-like convolutional network. Using the\nproposed approach along with an axial, coronal, and sagittal projection\nanalysis makes it possible to abandon the widely used false positives reduction\nstep. The proposed method achieves SOTA on LUNA2016 with 0.959 average\nsensitivity, and 0.936 sensitivity if the false-positive level per scan is\n0.25. The paper describes the proposed approach and represents the experimental\nresults on LUNA2016 as well as ablation studies.",
          "link": "http://arxiv.org/abs/2106.05741",
          "publishedOn": "2021-06-11T01:42:16.904Z",
          "wordCount": 557,
          "title": "End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Liang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zijun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>",
          "description": "We introduce a framework for learning from multiple generated graph views,\nnamed graph symbiosis learning (GraphSym). In GraphSym, graph neural networks\n(GNN) developed in multiple generated graph views can adaptively exchange\nparameters with each other and fuse information stored in linkage structures\nand node features. Specifically, we propose a novel adaptive exchange method to\niteratively substitute redundant channels in the weight matrix of one GNN with\ninformative channels of another GNN in a layer-by-layer manner. GraphSym does\nnot rely on specific methods to generate multiple graph views and GNN\narchitectures. Thus, existing GNNs can be seamlessly integrated into our\nframework. On 3 semi-supervised node classification datasets, GraphSym\noutperforms previous single-graph and multiple-graph GNNs without knowledge\ndistillation, and achieves new state-of-the-art results. We also conduct a\nseries of experiments on 15 public benchmarks, 8 popular GNN models, and 3\ngraph tasks -- node classification, graph classification, and edge prediction\n-- and show that GraphSym consistently achieves better performance than\nexisting popular GNNs by 1.9\\%$\\sim$3.9\\% on average and their ensembles.\nExtensive ablation studies and experiments on the few-shot setting also\ndemonstrate the effectiveness of GraphSym.",
          "link": "http://arxiv.org/abs/2106.05455",
          "publishedOn": "2021-06-11T01:42:16.896Z",
          "wordCount": 603,
          "title": "Graph Symbiosis Learning. (arXiv:2106.05455v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frohlich_C/0/1/0/all/0/1\">Christian Fr&#xf6;hlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gessner_A/0/1/0/all/0/1\">Alexandra Gessner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1\">Georgios Arvanitidis</a>",
          "description": "Riemannian manifolds provide a principled way to model nonlinear geometric\nstructure inherent in data. A Riemannian metric on said manifolds determines\ngeometry-aware shortest paths and provides the means to define statistical\nmodels accordingly. However, these operations are typically computationally\ndemanding. To ease this computational burden, we advocate probabilistic\nnumerical methods for Riemannian statistics. In particular, we focus on\nBayesian quadrature (BQ) to numerically compute integrals over normal laws on\nRiemannian manifolds learned from data. In this task, each function evaluation\nrelies on the solution of an expensive initial value problem. We show that by\nleveraging both prior knowledge and an active exploration scheme, BQ\nsignificantly reduces the number of required evaluations and thus outperforms\nMonte Carlo methods on a wide range of integration problems. As a concrete\napplication, we highlight the merits of adopting Riemannian geometry with our\nproposed framework on a nonlinear dataset from molecular dynamics.",
          "link": "http://arxiv.org/abs/2102.06645",
          "publishedOn": "2021-06-11T01:42:16.890Z",
          "wordCount": 603,
          "title": "Bayesian Quadrature on Riemannian Data Manifolds. (arXiv:2102.06645v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Deep Learning's outstanding track record across several domains has stemmed\nfrom the use of error backpropagation (BP). Several studies, however, have\nshown that it is impossible to execute BP in a real brain. Also, BP still\nserves as an important and unsolved bottleneck for memory usage and speed. We\npropose a simple, novel algorithm, the Front-Contribution algorithm, as a\ncompact alternative to BP. The contributions of all weights with respect to the\nfinal layer weights are calculated before training commences and all the\ncontributions are appended to weights of the final layer, i.e., the effective\nfinal layer weights are a non-linear function of themselves. Our algorithm then\nessentially collapses the network, precluding the necessity for weight updation\nof all weights not in the final layer. This reduction in parameters results in\nlower memory usage and higher training speed. We show that our algorithm\nproduces the exact same output as BP, in contrast to several recently proposed\nalgorithms approximating BP. Our preliminary experiments demonstrate the\nefficacy of the proposed algorithm. Our work provides a foundation to\neffectively utilize these presently under-explored \"front contributions\", and\nserves to inspire the next generation of training algorithms.",
          "link": "http://arxiv.org/abs/2106.05569",
          "publishedOn": "2021-06-11T01:42:16.878Z",
          "wordCount": 621,
          "title": "Front Contribution instead of Back Propagation. (arXiv:2106.05569v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05506",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Druce_J/0/1/0/all/0/1\">Jeff Druce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehaus_J/0/1/0/all/0/1\">James Niehaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moody_V/0/1/0/all/0/1\">Vanessa Moody</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_D/0/1/0/all/0/1\">David Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1\">Michael L. Littman</a>",
          "description": "The advances in artificial intelligence enabled by deep learning\narchitectures are undeniable. In several cases, deep neural network driven\nmodels have surpassed human level performance in benchmark autonomy tasks. The\nunderlying policies for these agents, however, are not easily interpretable. In\nfact, given their underlying deep models, it is impossible to directly\nunderstand the mapping from observations to actions for any reasonably complex\nagent. Producing this supporting technology to \"open the black box\" of these AI\nsystems, while not sacrificing performance, was the fundamental goal of the\nDARPA XAI program. In our journey through this program, we have several \"big\npicture\" takeaways: 1) Explanations need to be highly tailored to their\nscenario; 2) many seemingly high performing RL agents are extremely brittle and\nare not amendable to explanation; 3) causal models allow for rich explanations,\nbut how to present them isn't always straightforward; and 4) human subjects\nconjure fantastically wrong mental models for AIs, and these models are often\nhard to break. This paper discusses the origins of these takeaways, provides\namplifying information, and suggestions for future work.",
          "link": "http://arxiv.org/abs/2106.05506",
          "publishedOn": "2021-06-11T01:42:16.869Z",
          "wordCount": 622,
          "title": "Brittle AI, Causal Confusion, and Bad Mental Models: Challenges and Successes in the XAI Program. (arXiv:2106.05506v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiankai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuanshun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aonan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weihao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Junyuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Vertical Federated Learning (vFL) allows multiple parties that own different\nattributes (e.g. features and labels) of the same data entity (e.g. a person)\nto jointly train a model. To prepare the training data, vFL needs to identify\nthe common data entities shared by all parties. It is usually achieved by\nPrivate Set Intersection (PSI) which identifies the intersection of training\nsamples from all parties by using personal identifiable information (e.g.\nemail) as sample IDs to align data instances. As a result, PSI would make\nsample IDs of the intersection visible to all parties, and therefore each party\ncan know that the data entities shown in the intersection also appear in the\nother parties, i.e. intersection membership. However, in many real-world\nprivacy-sensitive organizations, e.g. banks and hospitals, revealing membership\nof their data entities is prohibited. In this paper, we propose a vFL framework\nbased on Private Set Union (PSU) that allows each party to keep sensitive\nmembership information to itself. Instead of identifying the intersection of\nall training samples, our PSU protocol generates the union of samples as\ntraining instances. In addition, we propose strategies to generate synthetic\nfeatures and labels to handle samples that belong to the union but not the\nintersection. Through extensive experiments on two real-world datasets, we show\nour framework can protect the privacy of the intersection membership while\nmaintaining the model utility.",
          "link": "http://arxiv.org/abs/2106.05508",
          "publishedOn": "2021-06-11T01:42:16.852Z",
          "wordCount": 658,
          "title": "Vertical Federated Learning without Revealing Intersection Membership. (arXiv:2106.05508v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_E/0/1/0/all/0/1\">Eric Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1\">Alexander R. Trott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Stephan Zheng</a>",
          "description": "Multi-agent simulations provide a scalable environment for learning policies\nthat interact with rational agents. However, such policies may fail to\ngeneralize to the real-world where agents may differ from simulated\ncounterparts due to unmodeled irrationality and misspecified reward functions.\nWe introduce Epsilon-Robust Multi-Agent Simulation (ERMAS), a robust\noptimization framework for learning AI policies that are robust to such\nmultiagent sim-to-real gaps. While existing notions of multi-agent robustness\nconcern perturbations in the actions of agents, we address a novel robustness\nobjective concerning perturbations in the reward functions of agents. ERMAS\nprovides this robustness by anticipating suboptimal behaviors from other\nagents, formalized as the worst-case epsilon-equilibrium. We show empirically\nthat ERMAS yields robust policies for repeated bimatrix games and optimal\ntaxation problems in economic simulations. In particular, in the two-level RL\nproblem posed by the AI Economist (Zheng et al., 2020) ERMAS learns tax\npolicies that are robust to changes in agent risk aversion, improving social\nwelfare by up to 15% in complex spatiotemporal simulations.",
          "link": "http://arxiv.org/abs/2106.05492",
          "publishedOn": "2021-06-11T01:42:16.840Z",
          "wordCount": 593,
          "title": "ERMAS: Becoming Robust to Reward Function Sim-to-Real Gaps in Multi-Agent Simulations. (arXiv:2106.05492v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Ordinary and partial differential equations (ODEs/PDEs) play a paramount role\nin analyzing and simulating complex dynamic processes across all corners of\nscience and engineering. In recent years machine learning tools are aspiring to\nintroduce new effective ways of simulating PDEs, however existing approaches\nare not able to reliably return stable and accurate predictions across long\ntemporal horizons. We aim to address this challenge by introducing an effective\nframework for learning infinite-dimensional operators that map random initial\nconditions to associated PDE solutions within a short time interval. Such\nlatent operators can be parametrized by deep neural networks that are trained\nin an entirely self-supervised manner without requiring any paired input-output\nobservations. Global long-time predictions across a range of initial conditions\ncan be then obtained by iteratively evaluating the trained model using each\nprediction as the initial condition for the next evaluation step. This\nintroduces a new approach to temporal domain decomposition that is shown to be\neffective in performing accurate long-time simulations for a wide range of\nparametric ODE and PDE systems, from wave propagation, to reaction-diffusion\ndynamics and stiff chemical kinetics, all at a fraction of the computational\ncost needed by classical numerical solvers.",
          "link": "http://arxiv.org/abs/2106.05384",
          "publishedOn": "2021-06-11T01:42:16.826Z",
          "wordCount": 625,
          "title": "Long-time integration of parametric evolution equations with physics-informed DeepONets. (arXiv:2106.05384v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1\">Athanasios Vlontzos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutherland_G/0/1/0/all/0/1\">Gabriel Sutherland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soboczenski_F/0/1/0/all/0/1\">Frank Soboczenski</a>",
          "description": "Future short or long-term space missions require a new generation of\nmonitoring and diagnostic systems due to communication impasses as well as\nlimitations in specialized crew and equipment. Machine learning supported\ndiagnostic systems present a viable solution for medical and technical\napplications. We discuss challenges and applicability of such systems in light\nof upcoming missions and outline an example use case for a next-generation\nmedical diagnostic system for future space operations. Additionally, we present\napproach recommendations and constraints for the successful generation and use\nof machine learning models aboard a spacecraft.",
          "link": "http://arxiv.org/abs/2106.05659",
          "publishedOn": "2021-06-11T01:42:16.811Z",
          "wordCount": 530,
          "title": "Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft. (arXiv:2106.05659v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "This paper proposes a differentiable robust LQR layer for reinforcement\nlearning and imitation learning under model uncertainty and stochastic\ndynamics. The robust LQR layer can exploit the advantages of robust optimal\ncontrol and model-free learning. It provides a new type of inductive bias for\nstochasticity and uncertainty modeling in control systems. In particular, we\npropose an efficient way to differentiate through a robust LQR optimization\nprogram by rewriting it as a convex program (i.e. semi-definite program) of the\nworst-case cost. Based on recent work on using convex optimization inside\nneural network layers, we develop a fully differentiable layer for optimizing\nthis worst-case cost, i.e. we compute the derivative of a performance measure\nw.r.t the model's unknown parameters, model uncertainty and stochasticity\nparameters. We demonstrate the proposed method on imitation learning and\napproximate dynamic programming on stochastic and uncertain domains. The\nexperiment results show that the proposed method can optimize robust policies\nunder uncertain situations, and are able to achieve a significantly better\nperformance than existing methods that do not model uncertainty directly.",
          "link": "http://arxiv.org/abs/2106.05535",
          "publishedOn": "2021-06-11T01:42:16.805Z",
          "wordCount": 589,
          "title": "Differentiable Robust LQR Layers. (arXiv:2106.05535v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_D/0/1/0/all/0/1\">Darshan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John P. Dickerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_S/0/1/0/all/0/1\">Seyed A. Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1\">Aravind Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1\">Leonidas Tsepenekas</a>",
          "description": "Clustering is a fundamental problem in unsupervised machine learning, and\nfair variants of it have recently received significant attention. In this work\nwe introduce a novel definition of fairness for clustering problems.\nSpecifically, in our model each point $j$ has a set of other points\n$\\mathcal{S}_j$ that it perceives as similar to itself, and it feels that it is\nfairly treated, if the quality of service it receives in the solution is\n$\\alpha$-close to that of the points in $\\mathcal{S}_j$. We begin our study by\nanswering questions regarding the structure of the problem, namely for what\nvalues of $\\alpha$ the problem is well-defined, and what the behavior of the\nPrice of Fairness (PoF) for it is. For the well-defined region of $\\alpha$, we\nprovide efficient and easily implementable approximation algorithms for the\n$k$-center objective, which in certain cases also enjoy bounded PoF guarantees.\nWe finally complement our analysis by an extensive suite of experiments that\nvalidates the effectiveness of our theoretical results.",
          "link": "http://arxiv.org/abs/2106.05423",
          "publishedOn": "2021-06-11T01:42:16.799Z",
          "wordCount": 598,
          "title": "A New Notion of Individually Fair Clustering: $\\alpha$-Equitable $k$-Center. (arXiv:2106.05423v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daley_B/0/1/0/all/0/1\">Brett Daley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1\">Christopher Amato</a>",
          "description": "Adam is an adaptive gradient method that has experienced widespread adoption\ndue to its fast and reliable training performance. Recent approaches have not\noffered significant improvement over Adam, often because they do not innovate\nupon one of its core features: normalization by the root mean square (RMS) of\nrecent gradients. However, as noted by Kingma and Ba (2015), any number of\n$L^p$ normalizations are possible, with the RMS corresponding to the specific\ncase of $p=2$. In our work, we theoretically and empirically characterize the\ninfluence of different $L^p$ norms on adaptive gradient methods for the first\ntime. We show mathematically how the choice of $p$ influences the size of the\nsteps taken, while leaving other desirable properties unaffected. We evaluate\nAdam with various $L^p$ norms on a suite of deep learning benchmarks, and find\nthat $p > 2$ consistently leads to improved learning speed and final\nperformance. The choices of $p=3$ or $p=6$ also match or outperform\nstate-of-the-art methods in all of our experiments.",
          "link": "http://arxiv.org/abs/2106.05449",
          "publishedOn": "2021-06-11T01:42:16.793Z",
          "wordCount": 636,
          "title": "Investigating Alternatives to the Root Mean Square for Adaptive Gradient Methods. (arXiv:2106.05449v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05445",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jin_Q/0/1/0/all/0/1\">Qiujiang Jin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1\">Aryan Mokhtari</a>",
          "description": "In this paper, we study the application of quasi-Newton methods for solving\nempirical risk minimization (ERM) problems defined over a large dataset.\nTraditional deterministic and stochastic quasi-Newton methods can be executed\nto solve such problems; however, it is known that their global convergence rate\nmay not be better than first-order methods, and their local superlinear\nconvergence only appears towards the end of the learning process. In this\npaper, we use an adaptive sample size scheme that exploits the superlinear\nconvergence of quasi-Newton methods globally and throughout the entire learning\nprocess. The main idea of the proposed adaptive sample size algorithms is to\nstart with a small subset of data points and solve their corresponding ERM\nproblem within its statistical accuracy, and then enlarge the sample size\ngeometrically and use the optimal solution of the problem corresponding to the\nsmaller set as an initial point for solving the subsequent ERM problem with\nmore samples. We show that if the initial sample size is sufficiently large and\nwe use quasi-Newton methods to solve each subproblem, the subproblems can be\nsolved superlinearly fast (after at most three iterations), as we guarantee\nthat the iterates always stay within a neighborhood that quasi-Newton methods\nconverge superlinearly. Numerical experiments on various datasets confirm our\ntheoretical results and demonstrate the computational advantages of our method.",
          "link": "http://arxiv.org/abs/2106.05445",
          "publishedOn": "2021-06-11T01:42:16.785Z",
          "wordCount": 650,
          "title": "Exploiting Local Convergence of Quasi-Newton Methods Globally: Adaptive Sample Size Approach. (arXiv:2106.05445v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mugunthan_V/0/1/0/all/0/1\">Vaikkunth Mugunthan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1\">Lalana Kagal</a>",
          "description": "Vertical Federated Learning (VFL) refers to the collaborative training of a\nmodel on a dataset where the features of the dataset are split among multiple\ndata owners, while label information is owned by a single data owner. In this\npaper, we propose a novel method, Multi Vertical Federated Learning\n(Multi-VFL), to train VFL models when there are multiple data and label owners.\nOur approach is the first to consider the setting where $D$-data owners (across\nwhich features are distributed) and $K$-label owners (across which labels are\ndistributed) exist. This proposed configuration allows different entities to\ntrain and learn optimal models without having to share their data. Our\nframework makes use of split learning and adaptive federated optimizers to\nsolve this problem. For empirical evaluation, we run experiments on the MNIST\nand FashionMNIST datasets. Our results show that using adaptive optimizers for\nmodel aggregation fastens convergence and improves accuracy.",
          "link": "http://arxiv.org/abs/2106.05468",
          "publishedOn": "2021-06-11T01:42:16.770Z",
          "wordCount": 577,
          "title": "Multi-VFL: A Vertical Federated Learning System for Multiple Data and Label Owners. (arXiv:2106.05468v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zuxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Zejia Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingjing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guo-Jun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu-Gang Jiang</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na fully-labeled source domain to a different unlabeled target domain. Most\nexisting UDA methods learn domain-invariant feature representations by\nminimizing feature distances across domains. In this work, we build upon\ncontrastive self-supervised learning to align features so as to reduce the\ndomain discrepancy between training and testing sets. Exploring the same set of\ncategories shared by both domains, we introduce a simple yet effective\nframework CDCL, for domain alignment. In particular, given an anchor image from\none domain, we minimize its distances to cross-domain samples from the same\nclass relative to those from different categories. Since target labels are\nunavailable, we use a clustering-based approach with carefully initialized\ncenters to produce pseudo labels. In addition, we demonstrate that CDCL is a\ngeneral framework and can be adapted to the data-free setting, where the source\ndata are unavailable during training, with minimal modification. We conduct\nexperiments on two widely used domain adaptation benchmarks, i.e., Office-31\nand VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance\non both datasets.",
          "link": "http://arxiv.org/abs/2106.05528",
          "publishedOn": "2021-06-11T01:42:16.743Z",
          "wordCount": 615,
          "title": "Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Alain-Sam Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cont_R/0/1/0/all/0/1\">Rama Cont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossier_A/0/1/0/all/0/1\">Alain Rossier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renyuan Xu</a>",
          "description": "Residual networks (ResNets) have displayed impressive results in pattern\nrecognition and, recently, have garnered considerable theoretical interest due\nto a perceived link with neural ordinary differential equations (neural ODEs).\nThis link relies on the convergence of network weights to a smooth function as\nthe number of layers increases. We investigate the properties of weights\ntrained by stochastic gradient descent and their scaling with network depth\nthrough detailed numerical experiments. We observe the existence of scaling\nregimes markedly different from those assumed in neural ODE literature.\nDepending on certain features of the network architecture, such as the\nsmoothness of the activation function, one may obtain an alternative ODE limit,\na stochastic differential equation or neither of these. These findings cast\ndoubts on the validity of the neural ODE model as an adequate asymptotic\ndescription of deep ResNets and point to an alternative class of differential\nequations as a better description of the deep network limit.",
          "link": "http://arxiv.org/abs/2105.12245",
          "publishedOn": "2021-06-11T01:42:16.722Z",
          "wordCount": 623,
          "title": "Scaling Properties of Deep Residual Networks. (arXiv:2105.12245v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.10513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehdiyev_N/0/1/0/all/0/1\">Nijat Mehdiyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fettke_P/0/1/0/all/0/1\">Peter Fettke</a>",
          "description": "This study proposes an innovative explainable predictive quality analytics\nsolution to facilitate data-driven decision-making for process planning in\nmanufacturing by combining process mining, machine learning, and explainable\nartificial intelligence (XAI) methods. For this purpose, after integrating the\ntop-floor and shop-floor data obtained from various enterprise information\nsystems, a deep learning model was applied to predict the process outcomes.\nSince this study aims to operationalize the delivered predictive insights by\nembedding them into decision-making processes, it is essential to generate\nrelevant explanations for domain experts. To this end, two complementary local\npost-hoc explanation approaches, Shapley values and Individual Conditional\nExpectation (ICE) plots are adopted, which are expected to enhance the\ndecision-making capabilities by enabling experts to examine explanations from\ndifferent perspectives. After assessing the predictive strength of the applied\ndeep neural network with relevant binary classification evaluation measures, a\ndiscussion of the generated explanations is provided.",
          "link": "http://arxiv.org/abs/2009.10513",
          "publishedOn": "2021-06-11T01:42:16.716Z",
          "wordCount": 632,
          "title": "Local Post-Hoc Explanations for Predictive Process Monitoring in Manufacturing. (arXiv:2009.10513v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05397",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stankewitz_B/0/1/0/all/0/1\">Bernhard Stankewitz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mucke_N/0/1/0/all/0/1\">Nicole M&#xfc;cke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rosasco_L/0/1/0/all/0/1\">Lorenzo Rosasco</a>",
          "description": "Optimization was recently shown to control the inductive bias in a learning\nprocess, a property referred to as implicit, or iterative regularization. The\nestimator obtained iteratively minimizing the training error can generalise\nwell with no need of further penalties or constraints. In this paper, we\ninvestigate this phenomenon in the context of linear models with smooth loss\nfunctions. In particular, we investigate and propose a proof technique\ncombining ideas from inexact optimization and probability theory, specifically\ngradient concentration. The proof is easy to follow and allows to obtain sharp\nlearning bounds. More generally, it highlights a way to develop optimization\nresults into learning guarantees.",
          "link": "http://arxiv.org/abs/2106.05397",
          "publishedOn": "2021-06-11T01:42:16.701Z",
          "wordCount": 536,
          "title": "From inexact optimization to learning via gradient concentration. (arXiv:2106.05397v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1\">Nikoli Dryden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohringer_R/0/1/0/all/0/1\">Roman B&#xf6;hringer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Nun_T/0/1/0/all/0/1\">Tal Ben-Nun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>",
          "description": "I/O is emerging as a major bottleneck for machine learning training,\nespecially in distributed environments. Indeed, at large scale, I/O takes as\nmuch as 85% of training time. Addressing this I/O bottleneck necessitates\ncareful optimization, as optimal data ingestion pipelines differ between\nsystems, and require a delicate balance between access to local storage,\nexternal filesystems, and remote nodes. We introduce NoPFS, a machine learning\nI/O middleware, which provides a scalable, flexible, and easy-to-use solution\nto the I/O bottleneck. NoPFS uses clairvoyance: Given the seed generating the\nrandom access pattern for training with SGD, it can exactly predict when and\nwhere a sample will be accessed. We combine this with an analysis of access\npatterns and a performance model to provide distributed caching policies that\nadapt to different datasets and storage hierarchies. NoPFS reduces I/O times\nand improves end-to-end training by up to 5.4x on the ImageNet-1k,\nImageNet-22k, and CosmoFlow datasets.",
          "link": "http://arxiv.org/abs/2101.08734",
          "publishedOn": "2021-06-11T01:42:16.687Z",
          "wordCount": 617,
          "title": "Clairvoyant Prefetching for Distributed Machine Learning I/O. (arXiv:2101.08734v2 [cs.DC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05797",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Glasserman_P/0/1/0/all/0/1\">Paul Glasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mike Li</a>",
          "description": "We study the behavior of linear discriminant functions for binary\nclassification in the infinite-imbalance limit, where the sample size of one\nclass grows without bound while the sample size of the other remains fixed. The\ncoefficients of the classifier minimize an expected loss specified through a\nweight function. We show that for a broad class of weight functions, the\nintercept diverges but the rest of the coefficient vector has a finite limit\nunder infinite imbalance, extending prior work on logistic regression. The\nlimit depends on the left tail of the weight function, for which we distinguish\nthree cases: bounded, asymptotically polynomial, and asymptotically\nexponential. The limiting coefficient vectors reflect robustness or\nconservatism properties in the sense that they optimize against certain\nworst-case alternatives. In the bounded and polynomial cases, the limit is\nequivalent to an implicit choice of upsampling distribution for the minority\nclass. We apply these ideas in a credit risk setting, with particular emphasis\non performance in the high-sensitivity and high-specificity regions.",
          "link": "http://arxiv.org/abs/2106.05797",
          "publishedOn": "2021-06-11T01:42:16.623Z",
          "wordCount": 589,
          "title": "Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1\">L. Elisa Celis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1\">Anay Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "We study fair classification in the presence of an omniscient adversary that,\ngiven an $\\eta$, is allowed to choose an arbitrary $\\eta$-fraction of the\ntraining samples and arbitrarily perturb their protected attributes. The\nmotivation comes from settings in which protected attributes can be incorrect\ndue to strategic misreporting, malicious actors, or errors in imputation; and\nprior approaches that make stochastic or independence assumptions on errors may\nnot satisfy their guarantees in this adversarial setting. Our main contribution\nis an optimization framework to learn fair classifiers in this adversarial\nsetting that comes with provable guarantees on accuracy and fairness. Our\nframework works with multiple and non-binary protected attributes, is designed\nfor the large class of linear-fractional fairness metrics, and can also handle\nperturbations besides protected attributes. We prove near-tightness of our\nframework's guarantees for natural hypothesis classes: no algorithm can have\nsignificantly better accuracy and any algorithm with better fairness must have\nlower accuracy. Empirically, we evaluate the classifiers produced by our\nframework for statistical rate on real-world and synthetic datasets for a\nfamily of adversaries.",
          "link": "http://arxiv.org/abs/2106.05964",
          "publishedOn": "2021-06-11T01:42:16.618Z",
          "wordCount": 613,
          "title": "Fair Classification with Adversarial Perturbations. (arXiv:2106.05964v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05960",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McDonald_T/0/1/0/all/0/1\">Thomas M. McDonald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1\">Mauricio A. &#xc1;lvarez</a>",
          "description": "Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We present a novel, domain-agnostic\napproach to tackling this problem, using compositions of physics-informed\nrandom features, derived from ordinary differential equations. The architecture\nof our model leverages recent advances in approximate inference for deep\nGaussian processes, such as layer-wise weight-space approximations which allow\nus to incorporate random Fourier features, and stochastic variational inference\nfor approximate Bayesian inference. We provide evidence that our model is\ncapable of capturing highly nonlinear behaviour in real-world multivariate time\nseries data. In addition, we find that our approach achieves comparable\nperformance to a number of other probabilistic models on benchmark regression\ntasks.",
          "link": "http://arxiv.org/abs/2106.05960",
          "publishedOn": "2021-06-11T01:42:16.613Z",
          "wordCount": 556,
          "title": "Compositional Modeling of Nonlinear Dynamical Systems with ODE-based Random Features. (arXiv:2106.05960v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05951",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gandikota_V/0/1/0/all/0/1\">Venkata Gandikota</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>",
          "description": "Recovery of support of a sparse vector from simple measurements is a widely\nstudied problem, considered under the frameworks of compressed sensing, 1-bit\ncompressed sensing, and more general single index models. We consider\ngeneralizations of this problem: mixtures of linear regressions, and mixtures\nof linear classifiers, where the goal is to recover supports of multiple sparse\nvectors using only a small number of possibly noisy linear, and 1-bit\nmeasurements respectively. The key challenge is that the measurements from\ndifferent vectors are randomly mixed. Both of these problems were also\nextensively studied recently. In mixtures of linear classifiers, the\nobservations correspond to the side of queried hyperplane a random unknown\nvector lies in, whereas in mixtures of linear regressions we observe the\nprojection of a random unknown vector on the queried hyperplane. The primary\nstep in recovering the unknown vectors from the mixture is to first identify\nthe support of all the individual component vectors. In this work, we study the\nnumber of measurements sufficient for recovering the supports of all the\ncomponent vectors in a mixture in both these models. We provide algorithms that\nuse a number of measurements polynomial in $k, \\log n$ and quasi-polynomial in\n$\\ell$, to recover the support of all the $\\ell$ unknown vectors in the mixture\nwith high probability when each individual component is a $k$-sparse\n$n$-dimensional vector.",
          "link": "http://arxiv.org/abs/2106.05951",
          "publishedOn": "2021-06-11T01:42:16.597Z",
          "wordCount": 665,
          "title": "Support Recovery of Sparse Signals from a Mixture of Linear Measurements. (arXiv:2106.05951v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhezheng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1\">Leslie Pack Kaelbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer D. Ullman</a>",
          "description": "We present Temporal and Object Quantification Networks (TOQ-Nets), a new\nclass of neuro-symbolic networks with a structural bias that enables them to\nlearn to recognize complex relational-temporal events. This is done by\nincluding reasoning layers that implement finite-domain quantification over\nobjects and time. The structure allows them to generalize directly to input\ninstances with varying numbers of objects in temporal sequences of varying\nlengths. We evaluate TOQ-Nets on input domains that require recognizing\nevent-types in terms of complex temporal relational patterns. We demonstrate\nthat TOQ-Nets can generalize from small amounts of data to scenarios containing\nmore objects than were present during training and to temporal warpings of\ninput sequences.",
          "link": "http://arxiv.org/abs/2106.05891",
          "publishedOn": "2021-06-11T01:42:16.592Z",
          "wordCount": 558,
          "title": "Temporal and Object Quantification Networks. (arXiv:2106.05891v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiongshi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shaobo Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>",
          "description": "Microarray gene expression data are often accompanied by a large number of\ngenes and a small number of samples. However, only a few of these genes are\nrelevant to cancer, resulting in signigicant gene selection challenges. Hence,\nwe propose a two-stage gene selection approach by combining extreme gradient\nboosting (XGBoost) and a multi-objective optimization genetic algorithm\n(XGBoost-MOGA) for cancer classification in microarray datasets. In the first\nstage, the genes are ranked use an ensemble-based feature selection using\nXGBoost. This stage can effectively remove irrelevant genes and yield a group\ncomprising the most relevant genes related to the class. In the second stage,\nXGBoost-MOGA searches for an optimal gene subset based on the most relevant\ngenes's group using a multi-objective optimization genetic algorithm. We\nperformed comprehensive experiments to compare XGBoost-MOGA with other\nstate-of-the-art feature selection methods using two well-known learning\nclassifiers on 13 publicly available microarray expression datasets. The\nexperimental results show that XGBoost-MOGA yields significantly better results\nthan previous state-of-the-art algorithms in terms of various evaluation\ncriteria, such as accuracy, F-score, precision, and recall.",
          "link": "http://arxiv.org/abs/2106.05841",
          "publishedOn": "2021-06-11T01:42:16.585Z",
          "wordCount": 607,
          "title": "Hybrid gene selection approach using XGBoost and multi-objective genetic algorithm for cancer classification. (arXiv:2106.05841v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1\">Mian Arif Shams Adnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1\">H. M. Miraz Mahmud</a>",
          "description": "Unlike previous studies on mixture distributions, a bagging and boosting\nbased convexly combined mixture probabilistic model has been suggested. This\nmodel is a result of iteratively searching for obtaining the optimum\nprobabilistic model that provides the maximum p value.",
          "link": "http://arxiv.org/abs/2106.05840",
          "publishedOn": "2021-06-11T01:42:16.565Z",
          "wordCount": 474,
          "title": "A Bagging and Boosting Based Convexly Combined Optimum Mixture Probabilistic Model. (arXiv:2106.05840v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1\">Mohammad Hossein Samavatian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Saikat Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1\">Kristin Barber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1\">Radu Teodorescu</a>",
          "description": "DNNs are known to be vulnerable to so-called adversarial attacks, in which\ninputs are carefully manipulated to induce misclassification. Existing defenses\nare mostly software-based and come with high overheads or other limitations.\nThis paper presents HASI, a hardware-accelerated defense that uses a process we\ncall stochastic inference to detect adversarial inputs. HASI carefully injects\nnoise into the model at inference time and used the model's response to\ndifferentiate adversarial inputs from benign ones. We show an adversarial\ndetection rate of average 87% which exceeds the detection rate of the\nstate-of-the-art approaches, with a much lower overhead. We demonstrate a\nsoftware/hardware-accelerated co-design, which reduces the performance impact\nof stochastic inference to 1.58X-2X relative to the unprotected baseline,\ncompared to 14X-20X overhead for a software-only GPU implementation.",
          "link": "http://arxiv.org/abs/2106.05825",
          "publishedOn": "2021-06-11T01:42:16.525Z",
          "wordCount": 565,
          "title": "HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks. (arXiv:2106.05825v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Servia_Rodriguez_S/0/1/0/all/0/1\">Sandra Servia-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1\">Cecilia Mascolo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Young D. Kwon</a>",
          "description": "Despite much research targeted at enabling conventional machine learning\nmodels to continually learn tasks and data distributions sequentially without\nforgetting the knowledge acquired, little effort has been devoted to account\nfor more realistic situations where learning some tasks accurately might be\nmore critical than forgetting previous ones. In this paper we propose a\nBayesian inference based framework to continually learn a set of real-world,\nsensing-based analysis tasks that can be tuned to prioritize the remembering of\npreviously learned tasks or the learning of new ones. Our experiments prove the\nrobustness and reliability of the learned models to adapt to the changing\nsensing environment, and show the suitability of using uncertainty of the\npredictions to assess their reliability.",
          "link": "http://arxiv.org/abs/2106.05872",
          "publishedOn": "2021-06-11T01:42:16.483Z",
          "wordCount": 550,
          "title": "Knowing when we do not know: Bayesian continual learning for sensing-based analysis tasks. (arXiv:2106.05872v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1\">Ruoqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1\">Kevin Tian</a>",
          "description": "We give lower bounds on the performance of two of the most popular sampling\nmethods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and\nmulti-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when\napplied to well-conditioned distributions. Our main result is a nearly-tight\nlower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from\nan exponentially warm start, matching a line of algorithmic results up to\nlogarithmic factors and answering an open question of Chewi et. al. We also\nshow that a polynomial dependence on dimension is necessary for the relaxation\ntime of HMC under any number of leapfrog steps, and bound the gains achievable\nby changing the step count. Our HMC analysis draws upon a novel connection\nbetween leapfrog integration and Chebyshev polynomials, which may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2106.05480",
          "publishedOn": "2021-06-11T01:42:16.450Z",
          "wordCount": 585,
          "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions. (arXiv:2106.05480v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1\">David Eisenstat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1\">Jakub &#x141;&#x105;cki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jessica Shi</a>",
          "description": "We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.",
          "link": "http://arxiv.org/abs/2106.05610",
          "publishedOn": "2021-06-11T01:42:16.367Z",
          "wordCount": 628,
          "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koo_H/0/1/0/all/0/1\">Hyungjoon Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soyeon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1\">Daejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesoo Kim</a>",
          "description": "A wide range of binary analysis applications, such as bug discovery, malware\nanalysis and code clone detection, require recovery of contextual meanings on a\nbinary code. Recently, binary analysis techniques based on machine learning\nhave been proposed to automatically reconstruct the code representation of a\nbinary instead of manually crafting specifics of the analysis algorithm.\nHowever, the existing approaches utilizing machine learning are still\nspecialized to solve one domain of problems, rendering recreation of models for\ndifferent types of binary analysis. In this paper, we propose DeepSemantic\nutilizing BERT in producing the semantic-aware code representation of a binary\ncode.\n\nTo this end, we introduce well-balanced instruction normalization that holds\nrich information for each of instructions yet minimizing an out-of-vocabulary\n(OOV) problem. DeepSemantic has been carefully designed based on our study with\nlarge swaths of binaries. Besides, DeepSemantic leverages the essence of the\nBERT architecture into re-purposing a pre-trained generic model that is readily\navailable as a one-time processing, followed by quickly applying specific\ndownstream tasks with a fine-tuning process. We demonstrate DeepSemantic with\ntwo downstream tasks, namely, binary similarity comparison and compiler\nprovenance (i.e., compiler and optimization level) prediction. Our experimental\nresults show that the binary similarity model outperforms two state-of-the-art\nbinary similarity tools, DeepBinDiff and SAFE, 49.84% and 15.83% on average,\nrespectively.",
          "link": "http://arxiv.org/abs/2106.05478",
          "publishedOn": "2021-06-11T01:42:16.336Z",
          "wordCount": 642,
          "title": "Semantic-aware Binary Code Representation with BERT. (arXiv:2106.05478v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grillotti_L/0/1/0/all/0/1\">Luca Grillotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity algorithms refer to a class of evolutionary algorithms\ndesigned to find a collection of diverse and high-performing solutions to a\ngiven problem. In robotics, such algorithms can be used for generating a\ncollection of controllers covering most of the possible behaviours of a robot.\nTo do so, these algorithms associate a behavioural descriptor to each of these\nbehaviours. Each behavioural descriptor is used for estimating the novelty of\none behaviour compared to the others. In most existing algorithms, the\nbehavioural descriptor needs to be hand-coded, thus requiring prior knowledge\nabout the task to solve. In this paper, we introduce: Autonomous Robots\nRealising their Abilities, an algorithm that uses a dimensionality reduction\ntechnique to automatically learn behavioural descriptors based on raw sensory\ndata. The performance of this algorithm is assessed on three robotic tasks in\nsimulation. The experimental results show that it performs similarly to\ntraditional hand-coded approaches without the requirement to provide any\nhand-coded behavioural descriptor. In the collection of diverse and\nhigh-performing solutions, it also manages to find behaviours that are novel\nwith respect to more features than its hand-coded baselines. Finally, we\nintroduce a variant of the algorithm which is robust to the dimensionality of\nthe behavioural descriptor space.",
          "link": "http://arxiv.org/abs/2106.05648",
          "publishedOn": "2021-06-11T01:42:16.320Z",
          "wordCount": 633,
          "title": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation. (arXiv:2106.05648v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05408",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Boes_W/0/1/0/all/0/1\">Wim Boes</a>, <a href=\"http://arxiv.org/find/eess/1/au:+hamme_H/0/1/0/all/0/1\">Hugo Van hamme</a>",
          "description": "We study the merit of transfer learning for two sound recognition problems,\ni.e., audio tagging and sound event detection. Employing feature fusion, we\nadapt a baseline system utilizing only spectral acoustic inputs to also make\nuse of pretrained auditory and visual features, extracted from networks built\nfor different tasks and trained with external data. We perform experiments with\nthese modified models on an audiovisual multi-label data set, of which the\ntraining partition contains a large number of unlabeled samples and a smaller\namount of clips with weak annotations, indicating the clip-level presence of 10\nsound categories without specifying the temporal boundaries of the active\nauditory events. For clip-based audio tagging, this transfer learning method\ngrants marked improvements. Addition of the visual modality on top of audio\nalso proves to be advantageous in this context. When it comes to generating\ntranscriptions of audio recordings, the benefit of pretrained features depends\non the requested temporal resolution: for coarse-grained sound event detection,\ntheir utility remains notable. But when more fine-grained predictions are\nrequired, performance gains are strongly reduced due to a mismatch between the\nproblem at hand and the goals of the models from which the pretrained vectors\nwere obtained.",
          "link": "http://arxiv.org/abs/2106.05408",
          "publishedOn": "2021-06-11T01:42:16.315Z",
          "wordCount": 642,
          "title": "Audiovisual transfer learning for audio tagging and sound event detection. (arXiv:2106.05408v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1\">Tianlin Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1\">Beatrice Acciaio</a>",
          "description": "Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.",
          "link": "http://arxiv.org/abs/2106.05658",
          "publishedOn": "2021-06-11T01:42:16.309Z",
          "wordCount": 585,
          "title": "Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Estimating the data uncertainty in regression tasks is often done by learning\na quantile function or a prediction interval of the true label conditioned on\nthe input. It is frequently observed that quantile regression -- a vanilla\nalgorithm for learning quantiles with asymptotic guarantees -- tends to\n\\emph{under-cover} than the desired coverage level in reality. While various\nfixes have been proposed, a more fundamental understanding of why this\nunder-coverage bias happens in the first place remains elusive.\n\nIn this paper, we present a rigorous theoretical study on the coverage of\nuncertainty estimation algorithms in learning quantiles. We prove that quantile\nregression suffers from an inherent under-coverage bias, in a vanilla setting\nwhere we learn a realizable linear quantile function and there is more data\nthan parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the\n$\\alpha$-quantile learned by quantile regression roughly achieves coverage\n$\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where\n$d$ is the input dimension and $n$ is the number of training data. Our theory\nreveals that this under-coverage bias stems from a certain high-dimensional\nparameter estimation error that is not implied by existing theories on quantile\nregression. Experiments on simulated and real data verify our theory and\nfurther illustrate the effect of various factors such as sample size and model\ncapacity on the under-coverage bias in more practical setups.",
          "link": "http://arxiv.org/abs/2106.05515",
          "publishedOn": "2021-06-11T01:42:16.303Z",
          "wordCount": 655,
          "title": "Understanding the Under-Coverage Bias in Uncertainty Estimation. (arXiv:2106.05515v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mialon_G/0/1/0/all/0/1\">Gr&#xe9;goire Mialon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dexiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selosse_M/0/1/0/all/0/1\">Margot Selosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1\">Julien Mairal</a>",
          "description": "We show that viewing graphs as sets of node features and incorporating\nstructural and positional information into a transformer architecture is able\nto outperform representations learned with classical graph neural networks\n(GNNs). Our model, GraphiT, encodes such information by (i) leveraging relative\npositional encoding strategies in self-attention scores based on positive\ndefinite kernels on graphs, and (ii) enumerating and encoding local\nsub-structures such as paths of short length. We thoroughly evaluate these two\nideas on many classification and regression tasks, demonstrating the\neffectiveness of each of them independently, as well as their combination. In\naddition to performing well on standard benchmarks, our model also admits\nnatural visualization mechanisms for interpreting graph motifs explaining the\npredictions, making it a potentially strong candidate for scientific\napplications where interpretation is important. Code available at\nhttps://github.com/inria-thoth/GraphiT.",
          "link": "http://arxiv.org/abs/2106.05667",
          "publishedOn": "2021-06-11T01:42:16.289Z",
          "wordCount": 553,
          "title": "GraphiT: Encoding Graph Structure in Transformers. (arXiv:2106.05667v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1\">Wei-Fan Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Te-Sheng Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lai_M/0/1/0/all/0/1\">Ming-Chih Lai</a>",
          "description": "In this paper, a new Discontinuity Capturing Shallow Neural Network (DCSNN)\nfor approximating $d$-dimensional piecewise continuous functions and for\nsolving elliptic interface problems is developed. There are three novel\nfeatures in the present network; namely, (i) jump discontinuity is captured\nsharply, (ii) it is completely shallow consisting of only one hidden layer,\n(iii) it is completely mesh-free for solving partial differential equations\n(PDEs). We first continuously extend the $d$-dimensional piecewise continuous\nfunction in $(d+1)$-dimensional space by augmenting one coordinate variable to\nlabel the pieces of discontinuous function, and then construct a shallow neural\nnetwork to express this new augmented function. Since only one hidden layer is\nemployed, the number of training parameters (weights and biases) scales\nlinearly with the dimension and the neurons used in the hidden layer. For\nsolving elliptic interface equations, the network is trained by minimizing the\nmean squared error loss that consists of the residual of governing equation,\nboundary condition, and the interface jump conditions. We perform a series of\nnumerical tests to compare the accuracy and efficiency of the present network.\nOur DCSNN model is comparably efficient due to only moderate number of\nparameters needed to be trained (a few hundreds of parameters used throughout\nall numerical examples here), and the result shows better accuracy (and less\nparameters) than other method using piecewise deep neural network in\nliterature. We also compare the results obtained by the traditional grid-based\nimmersed interface method (IIM) which is designed particularly for elliptic\ninterface problems. Again, the present results show better accuracy than the\nones obtained by IIM. We conclude by solving a six-dimensional problem to show\nthe capability of the present network for high-dimensional applications.",
          "link": "http://arxiv.org/abs/2106.05587",
          "publishedOn": "2021-06-11T01:42:16.284Z",
          "wordCount": 707,
          "title": "A Discontinuity Capturing Shallow Neural Network for Elliptic Interface Problems. (arXiv:2106.05587v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Podobas_A/0/1/0/all/0/1\">Artur Podobas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svedin_M/0/1/0/all/0/1\">Martin Svedin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1\">Steven W. D. Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_I/0/1/0/all/0/1\">Ivy B. Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_N/0/1/0/all/0/1\">Naresh Balaji Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herman_P/0/1/0/all/0/1\">Pawel Herman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lansner_A/0/1/0/all/0/1\">Anders Lansner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markidis_S/0/1/0/all/0/1\">Stefano Markidis</a>",
          "description": "The modern deep learning method based on backpropagation has surged in\npopularity and has been used in multiple domains and application areas. At the\nsame time, there are other -- less-known -- machine learning algorithms with a\nmature and solid theoretical foundation whose performance remains unexplored.\nOne such example is the brain-like Bayesian Confidence Propagation Neural\nNetwork (BCPNN). In this paper, we introduce StreamBrain -- a framework that\nallows neural networks based on BCPNN to be practically deployed in\nHigh-Performance Computing systems. StreamBrain is a domain-specific language\n(DSL), similar in concept to existing machine learning (ML) frameworks, and\nsupports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate\nthat StreamBrain can train the well-known ML benchmark dataset MNIST within\nseconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We\nalso show how StreamBrain can be used to train with custom floating-point\nformats and illustrate the impact of using different bfloat variations on BCPNN\nusing FPGAs.",
          "link": "http://arxiv.org/abs/2106.05373",
          "publishedOn": "2021-06-11T01:42:16.277Z",
          "wordCount": 641,
          "title": "StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs. (arXiv:2106.05373v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mern_J/0/1/0/all/0/1\">John Mern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatch_K/0/1/0/all/0/1\">Kyle Hatch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ryan Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brush_J/0/1/0/all/0/1\">Jeff Brush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "Defending computer networks from cyber attack requires coordinating actions\nacross multiple nodes based on imperfect indicators of compromise while\nminimizing disruptions to network operations. Advanced attacks can progress\nwith few observable signals over several months before execution. The resulting\nsequential decision problem has large observation and action spaces and a long\ntime-horizon, making it difficult to solve with existing methods. In this work,\nwe present techniques to scale deep reinforcement learning to solve the cyber\nsecurity orchestration problem for large industrial control networks. We\npropose a novel attention-based neural architecture with size complexity that\nis invariant to the size of the network under protection. A pre-training\ncurriculum is presented to overcome early exploration difficulty. Experiments\nshow in that the proposed approaches greatly improve both the learning sample\ncomplexity and converged policy performance over baseline methods in\nsimulation.",
          "link": "http://arxiv.org/abs/2106.05332",
          "publishedOn": "2021-06-11T01:42:16.271Z",
          "wordCount": 582,
          "title": "Reinforcement Learning for Industrial Control Network Cyber Security Orchestration. (arXiv:2106.05332v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1\">Mehdi Jafarnia-Jahromi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rahul Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We consider the problem of online reinforcement learning for the Stochastic\nShortest Path (SSP) problem modeled as an unknown MDP with an absorbing state.\nWe propose PSRL-SSP, a simple posterior sampling-based reinforcement learning\nalgorithm for the SSP problem. The algorithm operates in epochs. At the\nbeginning of each epoch, a sample is drawn from the posterior distribution on\nthe unknown model dynamics, and the optimal policy with respect to the drawn\nsample is followed during that epoch. An epoch completes if either the number\nof visits to the goal state in the current epoch exceeds that of the previous\nepoch, or the number of visits to any of the state-action pairs is doubled. We\nestablish a Bayesian regret bound of $O(B_\\star S\\sqrt{AK})$, where $B_\\star$\nis an upper bound on the expected cost of the optimal policy, $S$ is the size\nof the state space, $A$ is the size of the action space, and $K$ is the number\nof episodes. The algorithm only requires the knowledge of the prior\ndistribution, and has no hyper-parameters to tune. It is the first such\nposterior sampling algorithm and outperforms numerically previously proposed\noptimism-based algorithms.",
          "link": "http://arxiv.org/abs/2106.05335",
          "publishedOn": "2021-06-11T01:42:16.266Z",
          "wordCount": 617,
          "title": "Online Learning for Stochastic Shortest Path Model via Posterior Sampling. (arXiv:2106.05335v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Anurag Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1\">Harish YVS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>",
          "description": "Executing computer vision models on streaming visual data, or streaming\nperception is an emerging problem, with applications in self-driving, embodied\nagents, and augmented/virtual reality. The development of such systems is\nlargely governed by the accuracy and latency of the processing pipeline. While\npast work has proposed numerous approximate execution frameworks, their\ndecision functions solely focus on optimizing latency, accuracy, or energy,\netc. This results in sub-optimum decisions, affecting the overall system\nperformance. We argue that the streaming perception systems should holistically\nmaximize the overall system performance (i.e., considering both accuracy and\nlatency simultaneously). To this end, we describe a new approach based on deep\nreinforcement learning to learn these tradeoffs at runtime for streaming\nperception. This tradeoff optimization is formulated as a novel deep contextual\nbandit problem and we design a new reward function that holistically integrates\nlatency and accuracy into a single metric. We show that our agent can learn a\ncompetitive policy across multiple decision dimensions, which outperforms\nstate-of-the-art policies on public datasets.",
          "link": "http://arxiv.org/abs/2106.05665",
          "publishedOn": "2021-06-11T01:42:16.259Z",
          "wordCount": 604,
          "title": "Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hojjati_H/0/1/0/all/0/1\">Hadi Hojjati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Semi-supervised anomaly detection, which aims to detect anomalies from normal\nsamples using a model that is solely trained on normal data, has been an active\nfield of research in the past decade. With recent advancements in deep\nlearning, particularly generative adversarial networks and autoencoders,\nresearchers have designed efficient deep anomaly detection methods. Existing\nworks commonly use neural networks such as an autoencoder to map the data into\na new representation that is easier to work with and then apply an anomaly\ndetection algorithm. In this paper, we propose a method, DASVDD, that jointly\nlearns the parameters of an autoencoder while minimizing the volume of an\nenclosing hyper-sphere on its latent representation. We propose a customized\nanomaly score which is a combination of autoencoder's reconstruction error and\ndistance of the lower-dimensional representation of a sample from the center of\nthe enclosing hyper-sphere. Minimizing this anomaly score on the normal data\nduring training aids us in learning the underlying distribution of normal data.\nIncluding the reconstruction error in the anomaly score ensures that DASVDD\ndoes not suffer from the common hyper-sphere collapse issue since the proposed\nDASVDD model does not converge to the trivial solution of mapping all inputs to\na constant point in the latent representation. Experimental evaluations on\nseveral benchmark datasets from different domains show that the proposed method\noutperforms most of the commonly used state-of-the-art anomaly detection\nalgorithms while maintaining robust and accurate performance across different\nanomaly classes.",
          "link": "http://arxiv.org/abs/2106.05410",
          "publishedOn": "2021-06-11T01:42:16.215Z",
          "wordCount": 667,
          "title": "DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection. (arXiv:2106.05410v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moradipari_A/0/1/0/all/0/1\">Ahmadreza Moradipari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1\">Mahnoosh Alizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study two model selection settings in stochastic linear bandits (LB). In\nthe first setting, the reward parameter of the LB problem is arbitrarily\nselected from $M$ models represented as (possibly) overlapping balls in\n$\\mathbb R^d$. However, the agent only has access to misspecified models, i.e.,\nestimates of the centers and radii of the balls. We refer to this setting as\nparameter selection. In the second setting, which we refer to as feature\nselection, the expected reward of the LB problem is in the linear span of at\nleast one of $M$ feature maps (models). For each setting, we develop and\nanalyze an algorithm that is based on a reduction from bandits to\nfull-information problems. This allows us to obtain regret bounds that are not\nworse (up to a $\\sqrt{\\log M}$ factor) than the case where the true model is\nknown. Our parameter selection algorithm is OFUL-style and the one for feature\nselection is based on the SquareCB algorithm. We also show that the regret of\nour parameter selection algorithm scales logarithmically with model\nmisspecification.",
          "link": "http://arxiv.org/abs/2106.05378",
          "publishedOn": "2021-06-11T01:42:16.201Z",
          "wordCount": 598,
          "title": "Parameter and Feature Selection in Stochastic Linear Bandits. (arXiv:2106.05378v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1\">Georgios Arvanitidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Duque_M/0/1/0/all/0/1\">Miguel Gonz&#xe1;lez-Duque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouplin_A/0/1/0/all/0/1\">Alison Pouplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalatzis_D/0/1/0/all/0/1\">Dimitris Kalatzis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Latent space geometry has shown itself to provide a rich and rigorous\nframework for interacting with the latent variables of deep generative models.\nThe existing theory, however, relies on the decoder being a Gaussian\ndistribution as its simple reparametrization allows us to interpret the\ngenerating process as a random projection of a deterministic manifold.\nConsequently, this approach breaks down when applied to decoders that are not\nas easily reparametrized. We here propose to use the Fisher-Rao metric\nassociated with the space of decoder distributions as a reference metric, which\nwe pull back to the latent space. We show that we can achieve meaningful latent\ngeometries for a wide range of decoder distributions for which the previous\ntheory was not applicable, opening the door to `black box' latent geometries.",
          "link": "http://arxiv.org/abs/2106.05367",
          "publishedOn": "2021-06-11T01:42:16.188Z",
          "wordCount": 550,
          "title": "Pulling back information geometry. (arXiv:2106.05367v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jovanovic_N/0/1/0/all/0/1\">Nikola Jovanovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1\">Maximilian Baader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Certified defenses based on convex relaxations are an established technique\nfor training provably robust models. The key component is the choice of\nrelaxation, varying from simple intervals to tight polyhedra. Paradoxically,\nhowever, training with tighter relaxations can often lead to worse certified\nrobustness. The poor understanding of this paradox has forced recent\nstate-of-the-art certified defenses to focus on designing various heuristics in\norder to mitigate its effects. In contrast, in this paper we study the\nunderlying causes and show that tightness alone may not be the determining\nfactor. Concretely, we identify two key properties of relaxations that impact\ntraining dynamics: continuity and sensitivity. Our extensive experimental\nevaluation demonstrates that these two factors, observed alongside tightness,\nexplain the drop in certified robustness for popular relaxations. Further, we\ninvestigate the possibility of designing and training with relaxations that are\ntight, continuous and not sensitive. We believe the insights of this work can\nhelp drive the principled discovery of new and effective certified defense\nmechanisms.",
          "link": "http://arxiv.org/abs/2102.06700",
          "publishedOn": "2021-06-11T01:42:16.173Z",
          "wordCount": 617,
          "title": "Certified Defenses: Why Tighter Relaxations May Hurt Training. (arXiv:2102.06700v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05359",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Santanam_T/0/1/0/all/0/1\">Tejas Santanam</a>, <a href=\"http://arxiv.org/find/math/1/au:+Trasatti_A/0/1/0/all/0/1\">Anthony Trasatti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1\">Hanyu Zhang</a>",
          "description": "Many special events, including sport games and concerts, often cause surges\nin demand and congestion for transit systems. Therefore, it is important for\ntransit providers to understand their impact on disruptions, delays, and fare\nrevenues. This paper proposes a suite of data-driven techniques that exploit\nAutomated Fare Collection (AFC) data for evaluating, anticipating, and managing\nthe performance of transit systems during recurring congestion peaks due to\nspecial events. This includes an extensive analysis of ridership of the two\nmajor stadiums in downtown Atlanta using rail data from the Metropolitan\nAtlanta Rapid Transit Authority (MARTA). The paper first highlights the\nridership predictability at the aggregate level for each station on both event\nand non-event days. It then presents an unsupervised machine-learning model to\ncluster passengers and identify which train they are boarding. The model makes\nit possible to evaluate system performance in terms of fundamental metrics such\nas the passenger load per train and the wait times of riders. The paper also\npresents linear regression and random forest models for predicting ridership\nthat are used in combination with historical throughput analysis to forecast\ndemand. Finally, simulations are performed that showcase the potential\nimprovements to wait times and demand matching by leveraging proposed\ntechniques to optimize train frequencies based on forecasted demand.",
          "link": "http://arxiv.org/abs/2106.05359",
          "publishedOn": "2021-06-11T01:42:16.167Z",
          "wordCount": 652,
          "title": "Public Transit for Special Events: Ridership Prediction and Train Optimization. (arXiv:2106.05359v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strong_C/0/1/0/all/0/1\">Christopher A. Strong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_S/0/1/0/all/0/1\">Sydney M. Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1\">Anthony L. Corso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "Deep neural networks often lack the safety and robustness guarantees needed\nto be deployed in safety critical systems. Formal verification techniques can\nbe used to prove input-output safety properties of networks, but when\nproperties are difficult to specify, we rely on the solution to various\noptimization problems. In this work, we present an algorithm called ZoPE that\nsolves optimization problems over the output of feedforward ReLU networks with\nlow-dimensional inputs. The algorithm eagerly splits the input space, bounding\nthe objective using zonotope propagation at each step, and improves\ncomputational efficiency compared to existing mixed integer programming\napproaches. We demonstrate how to formulate and solve three types of\noptimization problems: (i) minimization of any convex function over the output\nspace, (ii) minimization of a convex function over the output of two networks\nin series with an adversarial perturbation in the layer between them, and (iii)\nmaximization of the difference in output between two networks. Using ZoPE, we\nobserve a $25\\times$ speedup on property 1 of the ACAS Xu neural network\nverification benchmark and an $85\\times$ speedup on a set of linear\noptimization problems. We demonstrate the versatility of the optimizer in\nanalyzing networks by projecting onto the range of a generative adversarial\nnetwork and visualizing the differences between a compressed and uncompressed\nnetwork.",
          "link": "http://arxiv.org/abs/2106.05325",
          "publishedOn": "2021-06-11T01:42:16.161Z",
          "wordCount": 659,
          "title": "ZoPE: A Fast Optimizer for ReLU Networks with Low-Dimensional Inputs. (arXiv:2106.05325v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Models that top leaderboards often perform unsatisfactorily when deployed in\nreal world applications; this has necessitated rigorous and expensive\npre-deployment model testing. A hitherto unexplored facet of model performance\nis: Are our leaderboards doing equitable evaluation? In this paper, we\nintroduce a task-agnostic method to probe leaderboards by weighting samples\nbased on their `difficulty' level. We find that leaderboards can be\nadversarially attacked and top performing models may not always be the best\nmodels. We subsequently propose alternate evaluation metrics. Our experiments\non 10 models show changes in model ranking and an overall reduction in\npreviously reported performance -- thus rectifying the overestimation of AI\nsystems' capabilities. Inspired by behavioral testing principles, we further\ndevelop a prototype of a visual analytics tool that enables leaderboard\nrevamping through customization, based on an end user's focus area. This helps\nusers analyze models' strengths and weaknesses, and guides them in the\nselection of a model best suited for their application scenario. In a user\nstudy, members of various commercial product development teams, covering 5\nfocus areas, find that our prototype reduces pre-deployment development and\ntesting effort by 41% on average.",
          "link": "http://arxiv.org/abs/2106.05532",
          "publishedOn": "2021-06-11T01:42:16.155Z",
          "wordCount": 632,
          "title": "How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05400",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bagherian_D/0/1/0/all/0/1\">Dawna Bagherian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gornet_J/0/1/0/all/0/1\">James Gornet</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bernstein_J/0/1/0/all/0/1\">Jeremy Bernstein</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1\">Yu-Li Ni</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Meister_M/0/1/0/all/0/1\">Markus Meister</a>",
          "description": "We study the problem of sparse nonlinear model recovery of high dimensional\ncompositional functions. Our study is motivated by emerging opportunities in\nneuroscience to recover fine-grained models of biological neural circuits using\ncollected measurement data. Guided by available domain knowledge in\nneuroscience, we explore conditions under which one can recover the underlying\nbiological circuit that generated the training data. Our results suggest\ninsights of both theoretical and practical interests. Most notably, we find\nthat a sign constraint on the weights is a necessary condition for system\nrecovery, which we establish both theoretically with an identifiability\nguarantee and empirically on simulated biological circuits. We conclude with a\ncase study on retinal ganglion cell circuits using data collected from mouse\nretina, showcasing the practical potential of this approach.",
          "link": "http://arxiv.org/abs/2106.05400",
          "publishedOn": "2021-06-11T01:42:16.150Z",
          "wordCount": 578,
          "title": "Fine-Grained System Identification of Nonlinear Neural Circuits. (arXiv:2106.05400v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1\">Jakob Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1\">Nassir Navab</a>",
          "description": "Volume Rendering is an important technique for visualizing three-dimensional\nscalar data grids and is commonly employed for scientific and medical image\ndata. Direct Volume Rendering (DVR) is a well established and efficient\nrendering algorithm for volumetric data. Neural rendering uses deep neural\nnetworks to solve inverse rendering tasks and applies techniques similar to\nDVR. However, it has not been demonstrated successfully for the rendering of\nscientific volume data.\n\nIn this work, we introduce Deep Direct Volume Rendering (DeepDVR), a\ngeneralization of DVR that allows for the integration of deep neural networks\ninto the DVR algorithm. We conceptualize the rendering in a latent color space,\nthus enabling the use of deep architectures to learn implicit mappings for\nfeature extraction and classification, replacing explicit feature design and\nhand-crafted transfer functions. Our generalization serves to derive novel\nvolume rendering architectures that can be trained end-to-end directly from\nexamples in image space, obviating the need to manually define and fine-tune\nmultidimensional transfer functions while providing superior classification\nstrength. We further introduce a novel stepsize annealing scheme to accelerate\nthe training of DeepDVR models and validate its effectiveness in a set of\nexperiments. We validate our architectures on two example use cases: (1)\nlearning an optimized rendering from manually adjusted reference images for a\nsingle volume and (2) learning advanced visualization concepts like shading and\nsemantic colorization that generalize to unseen volume data.\n\nWe find that deep volume rendering architectures with explicit modeling of\nthe DVR pipeline effectively enable end-to-end learning of scientific volume\nrendering tasks from target images.",
          "link": "http://arxiv.org/abs/2106.05429",
          "publishedOn": "2021-06-11T01:42:16.133Z",
          "wordCount": 681,
          "title": "Deep Direct Volume Rendering: Learning Visual Feature Mappings From Exemplary Images. (arXiv:2106.05429v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1\">Keerthiram Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1\">Subhajit Chaudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1\">Kartik Talamadupula</a>",
          "description": "Text-based games (TBGs) have become a popular proving ground for the\ndemonstration of learning-based agents that make decisions in quasi real-world\nsettings. The crux of the problem for a reinforcement learning agent in such\nTBGs is identifying the objects in the world, and those objects' relations with\nthat world. While the recent use of text-based resources for increasing an\nagent's knowledge and improving its generalization have shown promise, we posit\nin this paper that there is much yet to be learned from visual representations\nof these same worlds. Specifically, we propose to retrieve images that\nrepresent specific instances of text observations from the world and train our\nagents on such images. This improves the agent's overall understanding of the\ngame 'scene' and objects' relationships to the world around them, and the\nvariety of visual representations on offer allow the agent to generate a better\ngeneralization of a relationship. We show that incorporating such images\nimproves the performance of agents in various TBG settings.",
          "link": "http://arxiv.org/abs/2106.05387",
          "publishedOn": "2021-06-11T01:42:16.116Z",
          "wordCount": 598,
          "title": "Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1\">Ilya Tolstikhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1\">Jessica Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1\">Andreas Steiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>",
          "description": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision.\nRecently, attention-based networks, such as the Vision Transformer, have also\nbecome popular. In this paper we show that while convolutions and attention are\nboth sufficient for good performance, neither of them are necessary. We present\nMLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).\nMLP-Mixer contains two types of layers: one with MLPs applied independently to\nimage patches (i.e. \"mixing\" the per-location features), and one with MLPs\napplied across patches (i.e. \"mixing\" spatial information). When trained on\nlarge datasets, or with modern regularization schemes, MLP-Mixer attains\ncompetitive scores on image classification benchmarks, with pre-training and\ninference cost comparable to state-of-the-art models. We hope that these\nresults spark further research beyond the realms of well established CNNs and\nTransformers.",
          "link": "http://arxiv.org/abs/2105.01601",
          "publishedOn": "2021-06-11T01:42:16.111Z",
          "wordCount": 641,
          "title": "MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gerace_F/0/1/0/all/0/1\">Federica Gerace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saglietti_L/0/1/0/all/0/1\">Luca Saglietti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannelli_S/0/1/0/all/0/1\">Stefano Sarao Mannelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1\">Andrew Saxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "Transfer learning can significantly improve the sample efficiency of neural\nnetworks, by exploiting the relatedness between a data-scarce target task and a\ndata-abundant source task. Despite years of successful applications, transfer\nlearning practice often relies on ad-hoc solutions, while theoretical\nunderstanding of these procedures is still limited. In the present work, we\nre-think a solvable model of synthetic data as a framework for modeling\ncorrelation between data-sets. This setup allows for an analytic\ncharacterization of the generalization performance obtained when transferring\nthe learned feature map from the source to the target task. Focusing on the\nproblem of training two-layer networks in a binary classification setting, we\nshow that our model can capture a range of salient features of transfer\nlearning with real data. Moreover, by exploiting parametric control over the\ncorrelation between the two data-sets, we systematically investigate under\nwhich conditions the transfer of features is beneficial for generalization.",
          "link": "http://arxiv.org/abs/2106.05418",
          "publishedOn": "2021-06-11T01:42:16.103Z",
          "wordCount": 588,
          "title": "Probing transfer learning with a model of synthetic correlated datasets. (arXiv:2106.05418v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1\">Dusan Stosic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1\">Darko Stosic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1\">Teresa B. Ludermir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stosic_B/0/1/0/all/0/1\">Borko Stosic</a>",
          "description": "Distance metric learning has attracted a lot of interest for solving machine\nlearning and pattern recognition problems over the last decades. In this work\nwe present a simple approach based on concepts from statistical physics to\nlearn optimal distance metric for a given problem. We formulate the task as a\ntypical statistical physics problem: distances between patterns represent\nconstituents of a physical system and the objective function corresponds to\nenergy. Then we express the problem as a minimization of the free energy of a\ncomplex system, which is equivalent to distance metric learning. Much like for\nmany problems in physics, we propose an approach based on Metropolis Monte\nCarlo to find the best distance metric. This provides a natural way to learn\nthe distance metric, where the learning process can be intuitively seen as\nstretching and rotating the metric space until some heuristic is satisfied. Our\nproposed method can handle a wide variety of constraints including those with\nspurious local minima. The approach works surprisingly well with stochastic\nnearest neighbors from neighborhood component analysis (NCA). Experimental\nresults on artificial and real-world data sets reveal a clear superiority over\na number of state-of-the-art distance metric learning methods for nearest\nneighbors classification.",
          "link": "http://arxiv.org/abs/2106.05495",
          "publishedOn": "2021-06-11T01:42:16.089Z",
          "wordCount": 627,
          "title": "Distance Metric Learning through Minimization of the Free Energy. (arXiv:2106.05495v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianyuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1\">Dimitris Samaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fusheng Wang</a>",
          "description": "Artificial intelligence has transformed the practice of drug discovery in the\npast decade. Various artificial intelligence techniques have been used in a\nwide range of applications. In this perspective, we present major applications\nof AI in drug discovery and discuss the relevant AI techniques, covering most\nrecent progress in AI-driven drug discovery. We expect that the perspective\nwill serve as a guide for researchers who are interested in working at this\nintersected area of artificial intelligence and drug discovery. We also provide\na GitHub repository summarizing the surveyed papers as a learning resource,\nwhich will be regularly updated.",
          "link": "http://arxiv.org/abs/2106.05386",
          "publishedOn": "2021-06-11T01:42:16.072Z",
          "wordCount": 523,
          "title": "Artificial Intelligence in Drug Discovery:Applications and Techniques. (arXiv:2106.05386v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03334",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_W/0/1/0/all/0/1\">Wonjae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Son_B/0/1/0/all/0/1\">Bokyung Son</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>",
          "description": "Vision-and-Language Pre-training (VLP) has improved performance on various\njoint vision-and-language downstream tasks. Current approaches to VLP heavily\nrely on image feature extraction processes, most of which involve region\nsupervision (e.g., object detection) and the convolutional architecture (e.g.,\nResNet). Although disregarded in the literature, we find it problematic in\nterms of both (1) efficiency/speed, that simply extracting input features\nrequires much more computation than the multimodal interaction steps; and (2)\nexpressive power, as it is upper bounded to the expressive power of the visual\nembedder and its predefined visual vocabulary. In this paper, we present a\nminimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the\nsense that the processing of visual inputs is drastically simplified to just\nthe same convolution-free manner that we process textual inputs. We show that\nViLT is up to tens of times faster than previous VLP models, yet with\ncompetitive or better downstream task performance. Our code and pre-trained\nweights are available at https://github.com/dandelin/vilt.",
          "link": "http://arxiv.org/abs/2102.03334",
          "publishedOn": "2021-06-11T01:42:16.066Z",
          "wordCount": 607,
          "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision. (arXiv:2102.03334v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02649",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Padovani_K/0/1/0/all/0/1\">Kleber Padovani</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xavier_R/0/1/0/all/0/1\">Roberto Xavier</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carvalho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Reali_A/0/1/0/all/0/1\">Anna Reali</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chateau_A/0/1/0/all/0/1\">Annie Chateau</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alves_R/0/1/0/all/0/1\">Ronnie Alves</a>",
          "description": "The use of reinforcement learning has proven to be very promising for solving\ncomplex activities without human supervision during their learning process.\nHowever, their successful applications are predominantly focused on fictional\nand entertainment problems - such as games. Based on the above, this work aims\nto shed light on the application of reinforcement learning to solve this\nrelevant real-world problem, the genome assembly. By expanding the only\napproach found in the literature that addresses this problem, we carefully\nexplored the aspects of intelligent agent learning, performed by the Q-learning\nalgorithm, to understand its suitability to be applied in scenarios whose\ncharacteristics are more similar to those faced by real genome projects. The\nimprovements proposed here include changing the previously proposed reward\nsystem and including state space exploration optimization strategies based on\ndynamic pruning and mutual collaboration with evolutionary computing. These\ninvestigations were tried on 23 new environments with larger inputs than those\nused previously. All these environments are freely available on the internet\nfor the evolution of this research by the scientific community. The results\nsuggest consistent performance progress using the proposed improvements,\nhowever, they also demonstrate the limitations of them, especially related to\nthe high dimensionality of state and action spaces. We also present, later, the\npaths that can be traced to tackle genome assembly efficiently in real\nscenarios considering recent, successfully reinforcement learning applications\n- including deep reinforcement learning - from other domains dealing with\nhigh-dimensional inputs.",
          "link": "http://arxiv.org/abs/2102.02649",
          "publishedOn": "2021-06-11T01:42:15.993Z",
          "wordCount": 694,
          "title": "A step towards a reinforcement learning de novo genome assembler. (arXiv:2102.02649v2 [q-bio.GN] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stadler_T/0/1/0/all/0/1\">Theresa Stadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprisanu_B/0/1/0/all/0/1\">Bristena Oprisanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Troncoso_C/0/1/0/all/0/1\">Carmela Troncoso</a>",
          "description": "Synthetic data has been advertised as a silver-bullet solution to\nprivacy-preserving data publishing that addresses the shortcomings of\ntraditional anonymisation techniques. The promise is that synthetic data drawn\nfrom generative models preserves the statistical properties of the original\ndataset but, at the same time, provides perfect protection against privacy\nattacks. In this work, we present the first quantitative evaluation of the\nprivacy gain of synthetic data publishing and compare it to that of previous\nanonymisation techniques.\n\nOur evaluation of a wide range of state-of-the-art generative models\ndemonstrates that synthetic data either does not prevent inference attacks or\ndoes not retain data utility. In other words, we empirically show that\nsynthetic data suffers from the same limitations as traditional anonymisation\ntechniques.\n\nFurthermore, we find that, in contrast to traditional anonymisation, the\nprivacy-utility tradeoff of synthetic data publishing is hard to predict.\nBecause it is impossible to predict what signals a synthetic dataset will\npreserve and what information will be lost, synthetic data leads to a highly\nvariable privacy gain and unpredictable utility loss. In summary, we find that\nsynthetic data is far from the holy grail of privacy-preserving data\npublishing.",
          "link": "http://arxiv.org/abs/2011.07018",
          "publishedOn": "2021-06-11T01:42:15.982Z",
          "wordCount": 653,
          "title": "Synthetic Data -- Anonymisation Groundhog Day. (arXiv:2011.07018v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhuo Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "The wide adoption of smart meters makes residential load data available and\nthus improves the understanding of the energy consumption behavior. Many\nexisting studies have focused on smart-meter data analysis, but the drivers of\nenergy consumption behaviors are not well understood. This paper aims to\ncharacterize and estimate users' load patterns based on their demographic and\nsocioeconomic information. We adopt the symbolic aggregate approximation (SAX)\nmethod to process the load data and use the K-Means method to extract key load\npatterns. We develop a deep neural network (DNN) to analyze the relationship\nbetween users' load patterns and their demographic and socioeconomic features.\nUsing real-world load data, we validate our framework and demonstrate the\nconnections between load patterns and household demographic and socioeconomic\nfeatures. We also take two regression models as benchmarks for comparisons.",
          "link": "http://arxiv.org/abs/2106.05858",
          "publishedOn": "2021-06-11T01:42:15.934Z",
          "wordCount": 569,
          "title": "Characterizing Residential Load Patterns by Household Demographic and Socioeconomic Factors. (arXiv:2106.05858v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05931",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1\">Arash Vahdat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1\">Karsten Kreis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>",
          "description": "Score-based generative models (SGMs) have recently demonstrated impressive\nresults in terms of both sample quality and distribution coverage. However,\nthey are usually applied directly in data space and often require thousands of\nnetwork evaluations for sampling. Here, we propose the Latent Score-based\nGenerative Model (LSGM), a novel approach that trains SGMs in a latent space,\nrelying on the variational autoencoder framework. Moving from data to latent\nspace allows us to train more expressive generative models, apply SGMs to\nnon-continuous data, and learn smoother SGMs in a smaller space, resulting in\nfewer network evaluations and faster sampling. To enable training LSGMs\nend-to-end in a scalable and stable manner, we (i) introduce a new\nscore-matching objective suitable to the LSGM setting, (ii) propose a novel\nparameterization of the score function that allows SGM to focus on the mismatch\nof the target distribution with respect to a simple Normal one, and (iii)\nanalytically derive multiple techniques for variance reduction of the training\nobjective. LSGM obtains a state-of-the-art FID score of 2.10 on CIFAR-10,\noutperforming all existing generative results on this dataset. On\nCelebA-HQ-256, LSGM is on a par with previous SGMs in sample quality while\noutperforming them in sampling time by two orders of magnitude. In modeling\nbinary images, LSGM achieves state-of-the-art likelihood on the binarized\nOMNIGLOT dataset.",
          "link": "http://arxiv.org/abs/2106.05931",
          "publishedOn": "2021-06-11T01:42:15.927Z",
          "wordCount": 637,
          "title": "Score-based Generative Modeling in Latent Space. (arXiv:2106.05931v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05850",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jiayi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1\">Raymond K. W. Wong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1\">Xiaojun Mao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chan_K/0/1/0/all/0/1\">Kwun Chuen Gary Chan</a>",
          "description": "In this paper, we propose a novel method for matrix completion under general\nnon-uniform missing structures. By controlling an upper bound of a novel\nbalancing error, we construct weights that can actively adjust for the\nnon-uniformity in the empirical risk without explicitly modeling the\nobservation probabilities, and can be computed efficiently via convex\noptimization. The recovered matrix based on the proposed weighted empirical\nrisk enjoys appealing theoretical guarantees. In particular, the proposed\nmethod achieves a stronger guarantee than existing work in terms of the scaling\nwith respect to the observation probabilities, under asymptotically\nheterogeneous missing settings (where entry-wise observation probabilities can\nbe of different orders). These settings can be regarded as a better theoretical\nmodel of missing patterns with highly varying probabilities. We also provide a\nnew minimax lower bound under a class of heterogeneous settings. Numerical\nexperiments are also provided to demonstrate the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.05850",
          "publishedOn": "2021-06-11T01:42:15.900Z",
          "wordCount": 597,
          "title": "Matrix Completion with Model-free Weighting. (arXiv:2106.05850v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xuhui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhiping Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrandis_J/0/1/0/all/0/1\">Jose del Aguila Ferrandis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "We develop a new Bayesian framework based on deep neural networks to be able\nto extrapolate in space-time using historical data and to quantify\nuncertainties arising from both noisy and gappy data in physical problems.\nSpecifically, the proposed approach has two stages: (1) prior learning and (2)\nposterior estimation. At the first stage, we employ the physics-informed\nGenerative Adversarial Networks (PI-GAN) to learn a functional prior either\nfrom a prescribed function distribution, e.g., Gaussian process, or from\nhistorical data and physics. At the second stage, we employ the Hamiltonian\nMonte Carlo (HMC) method to estimate the posterior in the latent space of\nPI-GANs. In addition, we use two different approaches to encode the physics:\n(1) automatic differentiation, used in the physics-informed neural networks\n(PINNs) for scenarios with explicitly known partial differential equations\n(PDEs), and (2) operator regression using the deep operator network (DeepONet)\nfor PDE-agnostic scenarios. We then test the proposed method for (1)\nmeta-learning for one-dimensional regression, and forward/inverse PDE problems\n(combined with PINNs); (2) PDE-agnostic physical problems (combined with\nDeepONet), e.g., fractional diffusion as well as saturated stochastic\n(100-dimensional) flows in heterogeneous porous media; and (3) spatial-temporal\nregression problems, i.e., inference of a marine riser displacement field. The\nresults demonstrate that the proposed approach can provide accurate predictions\nas well as uncertainty quantification given very limited scattered and noisy\ndata, since historical data could be available to provide informative priors.\nIn summary, the proposed method is capable of learning flexible functional\npriors, and can be extended to big data problems using stochastic HMC or\nnormalizing flows since the latent space is generally characterized as low\ndimensional.",
          "link": "http://arxiv.org/abs/2106.05863",
          "publishedOn": "2021-06-11T01:42:15.894Z",
          "wordCount": 698,
          "title": "Learning Functional Priors and Posteriors from Data and Physics. (arXiv:2106.05863v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ginart_A/0/1/0/all/0/1\">Antonio Ginart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Martin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "Post-deployment monitoring of the performance of ML systems is critical for\nensuring reliability, especially as new user inputs can differ from the\ntraining distribution. Here we propose a novel approach, MLDemon, for ML\nDEployment MONitoring. MLDemon integrates both unlabeled features and a small\namount of on-demand labeled examples over time to produce a real-time estimate\nof the ML model's current performance on a given data stream. Subject to budget\nconstraints, MLDemon decides when to acquire additional, potentially costly,\nsupervised labels to verify the model. On temporal datasets with diverse\ndistribution drifts and models, MLDemon substantially outperforms existing\nmonitoring approaches. Moreover, we provide theoretical analysis to show that\nMLDemon is minimax rate optimal up to logarithmic factors and is provably\nrobust against broad distribution drifts whereas prior approaches are not.",
          "link": "http://arxiv.org/abs/2104.13621",
          "publishedOn": "2021-06-11T01:42:15.883Z",
          "wordCount": 598,
          "title": "MLDemon: Deployment Monitoring for Machine Learning Systems. (arXiv:2104.13621v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.05701",
          "publishedOn": "2021-06-11T01:42:15.867Z",
          "wordCount": 567,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.05701v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05838",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Meng_C/0/1/0/all/0/1\">Cheng Meng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ke_Y/0/1/0/all/0/1\">Yuan Ke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mengrui Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1\">Ping Ma</a>",
          "description": "This paper studies the estimation of large-scale optimal transport maps\n(OTM), which is a well-known challenging problem owing to the curse of\ndimensionality. Existing literature approximates the large-scale OTM by a\nseries of one-dimensional OTM problems through iterative random projection.\nSuch methods, however, suffer from slow or none convergence in practice due to\nthe nature of randomly selected projection directions. Instead, we propose an\nestimation method of large-scale OTM by combining the idea of projection\npursuit regression and sufficient dimension reduction. The proposed method,\nnamed projection pursuit Monge map (PPMM), adaptively selects the most\n``informative'' projection direction in each iteration. We theoretically show\nthe proposed dimension reduction method can consistently estimate the most\n``informative'' projection direction in each iteration. Furthermore, the PPMM\nalgorithm weakly convergences to the target large-scale OTM in a reasonable\nnumber of steps. Empirically, PPMM is computationally easy and converges fast.\nWe assess its finite sample performance through the applications of Wasserstein\ndistance estimation and generative models.",
          "link": "http://arxiv.org/abs/2106.05838",
          "publishedOn": "2021-06-11T01:42:15.861Z",
          "wordCount": 629,
          "title": "Large-scale optimal transport map estimation using projection pursuit. (arXiv:2106.05838v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2009.07601",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Smith_A/0/1/0/all/0/1\">Alistair W. R. Smith</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gray_J/0/1/0/all/0/1\">Johnnie Gray</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_M/0/1/0/all/0/1\">M. S. Kim</a>",
          "description": "We use a meta-learning neural-network approach to analyse data from a\nmeasured quantum state. Once our neural network has been trained it can be used\nto efficiently sample measurements of the state in measurement bases not\ncontained in the training data. These samples can be used calculate expectation\nvalues and other useful quantities. We refer to this process as \"state sample\ntomography\". We encode the state's measurement outcome distributions using an\nefficiently parameterized generative neural network. This allows each stage in\nthe tomography process to be performed efficiently even for large systems. Our\nscheme is demonstrated on recent IBM Quantum devices, producing a model for a\n6-qubit state's measurement outcomes with a predictive accuracy (classical\nfidelity) > 95% for all test cases using only 100 random measurement settings\nas opposed to the 729 settings required for standard full tomography using\nlocal measurements. This reduction in the required number of measurements\nscales favourably, with training data in 200 measurement settings yielding a\npredictive accuracy > 92% for a 10 qubit state where 59,049 settings are\ntypically required for full local measurement-based quantum state tomography. A\nreduction in number of measurements by a factor, in this case, of almost 600\ncould allow for estimations of expectation values and state fidelities in\npracticable times on current quantum devices.",
          "link": "http://arxiv.org/abs/2009.07601",
          "publishedOn": "2021-06-11T01:42:15.855Z",
          "wordCount": 669,
          "title": "Efficient Quantum State Sample Tomography with Basis-dependent Neural-networks. (arXiv:2009.07601v3 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kloss_A/0/1/0/all/0/1\">Alina Kloss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1\">Georg Martius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>",
          "description": "In many robotic applications, it is crucial to maintain a belief about the\nstate of a system, which serves as input for planning and decision making and\nprovides feedback during task execution. Bayesian Filtering algorithms address\nthis state estimation problem, but they require models of process dynamics and\nsensory observations and the respective noise characteristics of these models.\nRecently, multiple works have demonstrated that these models can be learned by\nend-to-end training through differentiable versions of recursive filtering\nalgorithms. In this work, we investigate the advantages of differentiable\nfilters (DFs) over both unstructured learning approaches and manually-tuned\nfiltering algorithms, and provide practical guidance to researchers interested\nin applying such differentiable filters. For this, we implement DFs with four\ndifferent underlying filtering algorithms and compare them in extensive\nexperiments. Specifically, we (i) evaluate different implementation choices and\ntraining approaches, (ii) investigate how well complex models of uncertainty\ncan be learned in DFs, (iii) evaluate the effect of end-to-end training through\nDFs and (iv) compare the DFs among each other and to unstructured LSTM models.",
          "link": "http://arxiv.org/abs/2012.14313",
          "publishedOn": "2021-06-11T01:42:15.846Z",
          "wordCount": 628,
          "title": "How to Train Your Differentiable Filter. (arXiv:2012.14313v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Justin Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damjakob_D/0/1/0/all/0/1\">Dominik Damjakob</a>",
          "description": "We explore the usage of meta-learning to derive the causal direction between\nvariables by optimizing over a measure of distribution simplicity. We\nincorporate a stochastic graph representation which includes latent variables\nand allows for more generalizability and graph structure expression. Our model\nis able to learn causal direction indicators for complex graph structures\ndespite effects of latent confounders. Further, we explore robustness of our\nmethod with respect to violations of our distributional assumptions and data\nscarcity. Our model is particularly robust to modest data scarcity, but is less\nrobust to distributional changes. By interpreting the model predictions as\nstochastic events, we propose a simple ensemble method classifier to reduce the\noutcome variability as an average of biased events. This methodology\ndemonstrates ability to infer the existence as well as the direction of a\ncausal relationship between data distributions.",
          "link": "http://arxiv.org/abs/2106.05859",
          "publishedOn": "2021-06-11T01:42:15.820Z",
          "wordCount": 563,
          "title": "A Meta Learning Approach to Discerning Causal Graph Structure. (arXiv:2106.05859v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Avik Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_L/0/1/0/all/0/1\">Lawrence Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>",
          "description": "Many robotics domains use some form of nonconvex model predictive control\n(MPC) for planning, which sets a reduced time horizon, performs trajectory\noptimization, and replans at every step. The actual task typically requires a\nmuch longer horizon than is computationally tractable, and is specified via a\ncost function that cumulates over that full horizon. For instance, an\nautonomous car may have a cost function that makes a desired trade-off between\nefficiency, safety, and obeying traffic laws. In this work, we challenge the\ncommon assumption that the cost we optimize using MPC should be the same as the\nground truth cost for the task (plus a terminal cost). MPC solvers can suffer\nfrom short planning horizons, local optima, incorrect dynamics models, and,\nimportantly, fail to account for future replanning ability. Thus, we propose\nthat in many tasks it could be beneficial to purposefully choose a different\ncost function for MPC to optimize: one that results in the MPC rollout having\nlow ground truth cost, rather than the MPC planned trajectory. We formalize\nthis as an optimal cost design problem, and propose a zeroth-order\noptimization-based approach that enables us to design optimal costs for an MPC\nplanning robot in continuous MDPs. We test our approach in an autonomous\ndriving domain where we find costs different from the ground truth that\nimplicitly compensate for replanning, short horizon, incorrect dynamics models,\nand local minima issues. As an example, the learned cost incentivizes MPC to\ndelay its decision until later, implicitly accounting for the fact that it will\nget more information in the future and be able to make a better decision. Code\nand videos available at https://sites.google.com/berkeley.edu/ocd-mpc/.",
          "link": "http://arxiv.org/abs/2104.11353",
          "publishedOn": "2021-06-11T01:42:15.808Z",
          "wordCount": 752,
          "title": "Optimal Cost Design for Model Predictive Control. (arXiv:2104.11353v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haobin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>",
          "description": "In multi-agent reinforcement learning, the inherent non-stationarity of the\nenvironment caused by other agents' actions posed significant difficulties for\nan agent to learn a good policy independently. One way to deal with\nnon-stationarity is agent modeling, by which the agent takes into consideration\nthe influence of other agents' policies. Most existing work relies on\npredicting other agents' actions or goals, or discriminating between their\npolicies. However, such modeling fails to capture the similarities and\ndifferences between policies simultaneously and thus cannot provide useful\ninformation when generalizing to unseen policies. To address this, we propose a\ngeneral method to learn representations of other agents' policies via the\njoint-action distributions sampled in interactions. The similarities and\ndifferences between policies are naturally captured by the policy distance\ninferred from the joint-action distributions and deliberately reflected in the\nlearned representations. Agents conditioned on the policy representations can\nwell generalize to unseen agents. We empirically demonstrate that our method\noutperforms existing work in multi-agent tasks when facing unseen agents.",
          "link": "http://arxiv.org/abs/2106.05802",
          "publishedOn": "2021-06-11T01:42:15.802Z",
          "wordCount": 597,
          "title": "Informative Policy Representations in Multi-Agent Reinforcement Learning via Joint-Action Distributions. (arXiv:2106.05802v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Ruian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_Q/0/1/0/all/0/1\">Quaid Morris</a>",
          "description": "Smooth dynamics interrupted by discontinuities are known as hybrid systems\nand arise commonly in nature. Latent ODEs allow for powerful representation of\nirregularly sampled time series but are not designed to capture trajectories\narising from hybrid systems. Here, we propose the Latent Segmented ODE\n(LatSegODE), which uses Latent ODEs to perform reconstruction and changepoint\ndetection within hybrid trajectories featuring jump discontinuities and\nswitching dynamical modes. Where it is possible to train a Latent ODE on the\nsmooth dynamical flows between discontinuities, we apply the pruned exact\nlinear time (PELT) algorithm to detect changepoints where latent dynamics\nrestart, thereby maximizing the joint probability of a piece-wise continuous\nlatent dynamical representation. We propose usage of the marginal likelihood as\na score function for PELT, circumventing the need for model complexity-based\npenalization. The LatSegODE outperforms baselines in reconstructive and\nsegmentation tasks including synthetic data sets of sine waves, Lotka Volterra\ndynamics, and UCI Character Trajectories.",
          "link": "http://arxiv.org/abs/2105.03835",
          "publishedOn": "2021-06-11T01:42:15.796Z",
          "wordCount": 594,
          "title": "Segmenting Hybrid Trajectories using Latent ODEs. (arXiv:2105.03835v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>",
          "description": "Vision Transformers (ViT) have recently emerged as a powerful alternative to\nconvolutional networks (CNNs). Although hybrid models attempt to bridge the gap\nbetween these two architectures, the self-attention layers they rely on induce\na strong computational bottleneck, especially at large spatial resolutions. In\nthis work, we explore the idea of reducing the time spent training these layers\nby initializing them as convolutional layers. This enables us to transition\nsmoothly from any pre-trained CNN to its functionally identical hybrid model,\ncalled Transformed CNN (T-CNN). With only 50 epochs of fine-tuning, the\nresulting T-CNNs demonstrate significant performance gains over the CNN (+2.2%\ntop-1 on ImageNet-1k for a ResNet50-RS) as well as substantially improved\nrobustness (+11% top-1 on ImageNet-C). We analyze the representations learnt by\nthe T-CNN, providing deeper insights into the fruitful interplay between\nconvolutions and self-attention. Finally, we experiment initializing the T-CNN\nfrom a partially trained CNN, and find that it reaches better performance than\nthe corresponding hybrid model trained from scratch, while reducing training\ntime.",
          "link": "http://arxiv.org/abs/2106.05795",
          "publishedOn": "2021-06-11T01:42:15.790Z",
          "wordCount": 588,
          "title": "Transformed CNNs: recasting pre-trained convolutional layers with self-attention. (arXiv:2106.05795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sorba_O/0/1/0/all/0/1\">Olivier Sorba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geissler_C/0/1/0/all/0/1\">C Geissler</a>",
          "description": "The aim of the present study is to detect abrupt trend changes in the mean of\na multidimensional sequential signal. Directly inspired by papers of Fernhead\nand Liu ([4] and [5]), this work describes the signal in a hierarchical manner\n: the change dates of a time segmentation process trigger the renewal of a\npiece-wise constant emission law. Bayesian posterior information on the change\ndates and emission parameters is obtained. These estimations can be revised\nonline, i.e. as new data arrive. This paper proposes explicit formulations\ncorresponding to various emission laws, as well as a generalization to the case\nwhere only partially observed data are available. Practical applications\ninclude the returns of partially observed multi-asset investment strategies,\nwhen only scant prior knowledge of the movers of the returns is at hand,\nlimited to some statistical assumptions. This situation is different from the\nstudy of trend changes in the returns of individual assets, where fundamental\nexogenous information (news, earnings announcements, controversies, etc.) can\nbe used.",
          "link": "http://arxiv.org/abs/2106.05834",
          "publishedOn": "2021-06-11T01:42:15.773Z",
          "wordCount": 594,
          "title": "Online Bayesian inference for multiple changepoints and risk assessment. (arXiv:2106.05834v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "In many machine learning problems, large-scale datasets have become the\nde-facto standard to train state-of-the-art deep networks at the price of heavy\ncomputation load. In this paper, we focus on condensing large training sets\ninto significantly smaller synthetic sets which can be used to train deep\nneural networks from scratch with minimum drop in performance. Inspired from\nthe recent training set synthesis methods, we propose Differentiable Siamese\nAugmentation that enables effective use of data augmentation to synthesize more\ninformative synthetic images and thus achieves better performance when training\nnetworks with augmentations. Experiments on multiple image classification\nbenchmarks demonstrate that the proposed method obtains substantial gains over\nthe state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show\nwith only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%\nrelative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We\nalso explore the use of our method in continual learning and neural\narchitecture search, and show promising results.",
          "link": "http://arxiv.org/abs/2102.08259",
          "publishedOn": "2021-06-11T01:42:15.768Z",
          "wordCount": 615,
          "title": "Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hadad_V/0/1/0/all/0/1\">Vitor Hadad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hirshberg_D/0/1/0/all/0/1\">David A. Hirshberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "It has become increasingly common for data to be collected adaptively, for\nexample using contextual bandits. Historical data of this type can be used to\nevaluate other treatment assignment policies to guide future innovation or\nexperiments. However, policy evaluation is challenging if the target policy\ndiffers from the one used to collect data, and popular estimators, including\ndoubly robust (DR) estimators, can be plagued by bias, excessive variance, or\nboth. In particular, when the pattern of treatment assignment in the collected\ndata looks little like the pattern generated by the policy to be evaluated, the\nimportance weights used in DR estimators explode, leading to excessive\nvariance.\n\nIn this paper, we improve the DR estimator by adaptively weighting\nobservations to control its variance. We show that a t-statistic based on our\nimproved estimator is asymptotically normal under certain conditions, allowing\nus to form confidence intervals and test hypotheses. Using synthetic data and\npublic benchmarks, we provide empirical evidence for our estimator's improved\naccuracy and inferential properties relative to existing alternatives.",
          "link": "http://arxiv.org/abs/2106.02029",
          "publishedOn": "2021-06-11T01:42:15.762Z",
          "wordCount": 622,
          "title": "Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits. (arXiv:2106.02029v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1\">Chao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1\">Justin Dulay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Gregory Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1\">Duke Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1\">Nadia Shakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Automated high throughput plant phenotyping involves leveraging sensors, such\nas RGB, thermal and hyperspectral cameras (among others), to make large scale\nand rapid measurements of the physical properties of plants for the purpose of\nbetter understanding the difference between crops and facilitating rapid plant\nbreeding programs. One of the most basic phenotyping tasks is to determine the\ncultivar, or species, in a particular sensor product. This simple phenotype can\nbe used to detect errors in planting and to learn the most differentiating\nfeatures between cultivars. It is also a challenging visual recognition task,\nas a large number of highly related crops are grown simultaneously, leading to\na classification problem with low inter-class variance. In this paper, we\nintroduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum\ncaptured by a state-of-the-art gantry system, a multi-resolution network\narchitecture that learns both global and fine-grained features on the crops,\nand a new global pooling strategy called Dynamic Outlier Pooling which\noutperforms standard global pooling strategies on this task.",
          "link": "http://arxiv.org/abs/2106.05748",
          "publishedOn": "2021-06-11T01:42:15.756Z",
          "wordCount": 607,
          "title": "Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05722",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Fresca_S/0/1/0/all/0/1\">Stefania Fresca</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>",
          "description": "Simulating fluid flows in different virtual scenarios is of key importance in\nengineering applications. However, high-fidelity, full-order models relying,\ne.g., on the finite element method, are unaffordable whenever fluid flows must\nbe simulated in almost real-time. Reduced order models (ROMs) relying, e.g., on\nproper orthogonal decomposition (POD) provide reliable approximations to\nparameter-dependent fluid dynamics problems in rapid times. However, they might\nrequire expensive hyper-reduction strategies for handling parameterized\nnonlinear terms, and enriched reduced spaces (or Petrov-Galerkin projections)\nif a mixed velocity-pressure formulation is considered, possibly hampering the\nevaluation of reliable solutions in real-time. Dealing with fluid-structure\ninteractions entails even higher difficulties. The proposed deep learning\n(DL)-based ROMs overcome all these limitations by learning in a non-intrusive\nway both the nonlinear trial manifold and the reduced dynamics. To do so, they\nrely on deep neural networks, after performing a former dimensionality\nreduction through POD enhancing their training times substantially. The\nresulting POD-DL-ROMs are shown to provide accurate results in almost real-time\nfor the flow around a cylinder benchmark, the fluid-structure interaction\nbetween an elastic beam attached to a fixed, rigid block and a laminar\nincompressible flow, and the blood flow in a cerebral aneurysm.",
          "link": "http://arxiv.org/abs/2106.05722",
          "publishedOn": "2021-06-11T01:42:15.750Z",
          "wordCount": 641,
          "title": "Real-time simulation of parameter-dependent fluid flows through deep learning-based reduced order models. (arXiv:2106.05722v1 [physics.flu-dyn])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1\">Linus Gissl&#xe9;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eakins_A/0/1/0/all/0/1\">Andy Eakins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordillo_C/0/1/0/all/0/1\">Camilo Gordillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1\">Joakim Bergdahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tollmar_K/0/1/0/all/0/1\">Konrad Tollmar</a>",
          "description": "We present a new approach ARLPCG: Adversarial Reinforcement Learning for\nProcedural Content Generation, which procedurally generates and tests\npreviously unseen environments with an auxiliary input as a control variable.\nTraining RL agents over novel environments is a notoriously difficult task. One\npopular approach is to procedurally generate different environments to increase\nthe generalizability of the trained agents. ARLPCG instead deploys an\nadversarial model with one PCG RL agent (called Generator) and one solving RL\nagent (called Solver). The Generator receives a reward signal based on the\nSolver's performance, which encourages the environment design to be challenging\nbut not impossible. To further drive diversity and control of the environment\ngeneration, we propose using auxiliary inputs for the Generator. The benefit is\ntwo-fold: Firstly, the Solver achieves better generalization through the\nGenerator's generated challenges. Secondly, the trained Generator can be used\nas a creator of novel environments that, together with the Solver, can be shown\nto be solvable. We create two types of 3D environments to validate our model,\nrepresenting two popular game genres: a third-person platformer and a racing\ngame. In these cases, we shows that ARLPCG has a significantly better solve\nratio, and that the auxiliary inputs renders the levels creation controllable\nto a certain degree. For a video compilation of the results please visit\nhttps://youtu.be/z7q2PtVsT0I.",
          "link": "http://arxiv.org/abs/2103.04847",
          "publishedOn": "2021-06-11T01:42:15.733Z",
          "wordCount": 680,
          "title": "Adversarial Reinforcement Learning for Procedural Content Generation. (arXiv:2103.04847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05737",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_Y/0/1/0/all/0/1\">Yang Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Anwar_T/0/1/0/all/0/1\">Tarique Anwar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wu_J/0/1/0/all/0/1\">Jia Wu</a>",
          "description": "With the rising demand of smart mobility, ride-hailing service is getting\npopular in the urban regions. These services maintain a system for serving the\nincoming trip requests by dispatching available vehicles to the pickup points.\nAs the process should be socially and economically profitable, the task of\nvehicle dispatching is highly challenging, specially due to the time-varying\ntravel demands and traffic conditions. Due to the uneven distribution of travel\ndemands, many idle vehicles could be generated during the operation in\ndifferent subareas. Most of the existing works on vehicle dispatching system,\ndesigned static relocation centers to relocate idle vehicles. However, as\ntraffic conditions and demand distribution dynamically change over time, the\nstatic solution can not fit the evolving situations. In this paper, we propose\na dynamic future demand aware vehicle dispatching system. It can dynamically\nsearch the relocation centers considering both travel demand and traffic\nconditions. We evaluate the system on real-world dataset, and compare with the\nexisting state-of-the-art methods in our experiments in terms of several\nstandard evaluation metrics and operation time. Through our experiments, we\ndemonstrate that the proposed system significantly improves the serving ratio\nand with a very small increase in operation cost.",
          "link": "http://arxiv.org/abs/2106.05737",
          "publishedOn": "2021-06-11T01:42:15.726Z",
          "wordCount": 636,
          "title": "dFDA-VeD: A Dynamic Future Demand Aware Vehicle Dispatching System. (arXiv:2106.05737v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05586",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabarro_S/0/1/0/all/0/1\">Seth Nabarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1\">Stoil Ganev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garriga_Alonso_A/0/1/0/all/0/1\">Adri&#xe0; Garriga-Alonso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>",
          "description": "Data augmentation is a highly effective approach for improving performance in\ndeep neural networks. The standard view is that it creates an enlarged dataset\nby adding synthetic data, which raises a problem when combining it with\nBayesian inference: how much data are we really conditioning on? This question\nis particularly relevant to recent observations linking data augmentation to\nthe cold posterior effect. We investigate various principled ways of finding a\nlog-likelihood for augmented datasets. Our approach prescribes augmenting the\nsame underlying image multiple times, both at test and train-time, and\naveraging either the logits or the predictive probabilities. Empirically, we\nobserve the best performance with averaging probabilities. While there are\ninteractions with the cold posterior effect, neither averaging logits or\naveraging probabilities eliminates it.",
          "link": "http://arxiv.org/abs/2106.05586",
          "publishedOn": "2021-06-11T01:42:15.721Z",
          "wordCount": 564,
          "title": "Data augmentation in Bayesian neural networks and the cold posterior effect. (arXiv:2106.05586v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05565",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lang_Q/0/1/0/all/0/1\">Quanjun Lang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_F/0/1/0/all/0/1\">Fei Lu</a>",
          "description": "We study the identifiability of the interaction kernels in mean-field\nequations for intreacting particle systems. The key is to identify function\nspaces on which a probabilistic loss functional has a unique minimizer. We\nprove that identifiability holds on any subspace of two reproducing kernel\nHilbert spaces (RKHS), whose reproducing kernels are intrinsic to the system\nand are data-adaptive. Furthermore, identifiability holds on two ambient L2\nspaces if and only if the integral operators associated with the reproducing\nkernels are strictly positive. Thus, the inverse problem is ill-posed in\ngeneral. We also discuss the implications of identifiability in computational\npractice.",
          "link": "http://arxiv.org/abs/2106.05565",
          "publishedOn": "2021-06-11T01:42:15.715Z",
          "wordCount": 530,
          "title": "Identifiability of interaction kernels in mean-field equations of interacting particles. (arXiv:2106.05565v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05020",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_Y/0/1/0/all/0/1\">Yiheng Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1\">Yuzhe Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Domel_A/0/1/0/all/0/1\">August G. Domel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Alizadeh_H/0/1/0/all/0/1\">Hossein Vahid Alizadeh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhou Zhou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cecchi_N/0/1/0/all/0/1\">Nicholas J. Cecchi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Raymond_S/0/1/0/all/0/1\">Samuel J. Raymond</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tiernan_S/0/1/0/all/0/1\">Stephen Tiernan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ruan_J/0/1/0/all/0/1\">Jesse Ruan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Barbat_S/0/1/0/all/0/1\">Saeed Barbat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zeineh_M/0/1/0/all/0/1\">Michael M. Zeineh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Grant_G/0/1/0/all/0/1\">Gerald A. Grant</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Camarillo_D/0/1/0/all/0/1\">David B. Camarillo</a>",
          "description": "Brain tissue deformation resulting from head impacts is primarily caused by\nrotation and can lead to traumatic brain injury. To quantify brain injury risk\nbased on measurements of kinematics on the head, finite element (FE) models and\nvarious brain injury criteria based on different factors of these kinematics\nhave been developed, but the contribution of different kinematic factors has\nnot been comprehensively analyzed across different types of head impacts in a\ndata-driven manner. To better design brain injury criteria, the predictive\npower of rotational kinematics factors, which are different in 1) the\nderivative order (angular velocity, angular acceleration, angular jerk), 2) the\ndirection and 3) the power (e.g., square-rooted, squared, cubic) of the angular\nvelocity, were analyzed based on different datasets including laboratory\nimpacts, American football, mixed martial arts (MMA), NHTSA automobile\ncrashworthiness tests and NASCAR crash events. Ordinary least squares\nregressions were built from kinematics factors to the 95\\% maximum principal\nstrain (MPS95), and we compared zero-order correlation coefficients, structure\ncoefficients, commonality analysis, and dominance analysis. The angular\nacceleration, the magnitude, and the first power factors showed the highest\npredictive power for the majority of impacts including laboratory impacts,\nAmerican football impacts, with few exceptions (angular velocity for MMA and\nNASCAR impacts). The predictive power of rotational kinematics in three\ndirections (x: posterior-to-anterior, y: left-to-right, z:\nsuperior-to-inferior) of kinematics varied with different sports and types of\nhead impacts.",
          "link": "http://arxiv.org/abs/2102.05020",
          "publishedOn": "2021-06-11T01:42:15.710Z",
          "wordCount": 729,
          "title": "Predictive Factors of Kinematics in Traumatic Brain Injury from Head Impacts Based on Statistical Interpretation. (arXiv:2102.05020v3 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1\">Sajad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>",
          "description": "Training datasets for semantic parsing are typically small due to the higher\nexpertise required for annotation than most other NLP tasks. As a result,\nmodels for this application usually need additional prior knowledge to be built\ninto the architecture or algorithm. The increased dependency on human experts\nhinders automation and raises the development and maintenance costs in\npractice. This work investigates whether a generic transformer-based seq2seq\nmodel can achieve competitive performance with minimal code-generation-specific\ninductive bias design. By exploiting a relatively sizeable monolingual corpus\nof the target programming language, which is cheap to mine from the web, we\nachieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.\nBoth are SOTA to the best of our knowledge. This positive evidence highlights a\npotentially easier path toward building accurate semantic parsers in practice.",
          "link": "http://arxiv.org/abs/2101.00259",
          "publishedOn": "2021-06-11T01:42:15.694Z",
          "wordCount": 599,
          "title": "Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sibo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zengfeng Huang</a>",
          "description": "Node embedding learns a low-dimensional representation for each node in the\ngraph. Recent progress on node embedding shows that proximity matrix\nfactorization methods gain superb performance and scale to large graphs with\nmillions of nodes. Existing approaches first define a proximity matrix and then\nlearn the embeddings that fit the proximity by matrix factorization. Most\nexisting matrix factorization methods adopt the same proximity for different\ntasks, while it is observed that different tasks and datasets may require\ndifferent proximity, limiting their representation power.\n\nMotivated by this, we propose {\\em Lemane}, a framework with trainable\nproximity measures, which can be learned to best suit the datasets and tasks at\nhand automatically. Our method is end-to-end, which incorporates differentiable\nSVD in the pipeline so that the parameters can be trained via backpropagation.\nHowever, this learning process is still expensive on large graphs. To improve\nthe scalability, we train proximity measures only on carefully subsampled\ngraphs, and then apply standard proximity matrix factorization on the original\ngraph using the learned proximity. Note that, computing the learned proximities\nfor each pair is still expensive for large graphs, and existing techniques for\ncomputing proximities are not applicable to the learned proximities. Thus, we\npresent generalized push techniques to make our solution scalable to large\ngraphs with millions of nodes. Extensive experiments show that our proposed\nsolution outperforms existing solutions on both link prediction and node\nclassification tasks on almost all datasets.",
          "link": "http://arxiv.org/abs/2106.05476",
          "publishedOn": "2021-06-11T01:42:15.690Z",
          "wordCount": 667,
          "title": "Learning Based Proximity Matrix Factorization for Node Embedding. (arXiv:2106.05476v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1\">Erik Goron Endsjo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "In this paper, we propose a new neural architecture search (NAS) problem of\nSymmetric Positive Definite (SPD) manifold networks, aiming to automate the\ndesign of SPD neural architectures. To address this problem, we first introduce\na geometrically rich and diverse SPD neural architecture search space for an\nefficient SPD cell design. Further, we model our new NAS problem with a\none-shot training process of a single supernet. Based on the supernet modeling,\nwe exploit a differentiable NAS algorithm on our relaxed continuous search\nspace for SPD neural architecture search. Statistical evaluation of our method\non drone, action, and emotion recognition tasks mostly provides better results\nthan the state-of-the-art SPD networks and traditional NAS algorithms.\nEmpirical results show that our algorithm excels in discovering better\nperforming SPD network design and provides models that are more than three\ntimes lighter than searched by the state-of-the-art NAS algorithms.",
          "link": "http://arxiv.org/abs/2010.14535",
          "publishedOn": "2021-06-11T01:42:15.678Z",
          "wordCount": 637,
          "title": "Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shih-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.",
          "link": "http://arxiv.org/abs/2105.08399",
          "publishedOn": "2021-06-11T01:42:15.672Z",
          "wordCount": 630,
          "title": "Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05490",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dreifuerst_R/0/1/0/all/0/1\">Ryan Dreifuerst</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heath_R/0/1/0/all/0/1\">Robert W. Heath Jr</a>",
          "description": "The detection and estimation of sinusoids is a fundamental signal processing\ntask for many applications related to sensing and communications. While\nalgorithms have been proposed for this setting, quantization is a critical, but\noften ignored modeling effect. In wireless communications, estimation with low\nresolution data converters is relevant for reduced power consumption in\nwideband receivers. Similarly, low resolution sampling in imaging and spectrum\nsensing allows for efficient data collection. In this work, we propose\nSignalNet, a neural network architecture that detects the number of sinusoids\nand estimates their parameters from quantized in-phase and quadrature samples.\nWe incorporate signal reconstruction internally as domain knowledge within the\nnetwork to enhance learning and surpass traditional algorithms in mean squared\nerror and Chamfer error. We introduce a worst-case learning threshold for\ncomparing the results of our network relative to the underlying data\ndistributions. This threshold provides insight into why neural networks tend to\noutperform traditional methods and into the learned relationships between the\ninput and output distributions. In simulation, we find that our algorithm is\nalways able to surpass the threshold for three-bit data but often cannot exceed\nthe threshold for one-bit data. We use the learning threshold to explain, in\nthe one-bit case, how our estimators learn to minimize the distributional loss,\nrather than learn features from the data.",
          "link": "http://arxiv.org/abs/2106.05490",
          "publishedOn": "2021-06-11T01:42:15.655Z",
          "wordCount": 655,
          "title": "SignalNet: A Low Resolution Sinusoid Decomposition and Estimation Network. (arXiv:2106.05490v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1\">Giovanni Cin&#xe0;</a>",
          "description": "A crucial requirement for reliable deployment of deep learning models for\nsafety-critical applications is the ability to identify out-of-distribution\n(OOD) data points, samples which differ from the training data and on which a\nmodel might underperform. Previous work has attempted to tackle this problem\nusing uncertainty estimation techniques. However, there is empirical evidence\nthat a large family of these techniques do not detect OOD reliably in\nclassification tasks.\n\nThis paper gives a theoretical explanation for said experimental findings and\nillustrates it on synthetic data. We prove that such techniques are not able to\nreliably identify OOD samples in a classification setting, since their level of\nconfidence is generalized to unseen areas of the feature space. This result\nstems from the interplay between the representation of ReLU networks as\npiece-wise affine transformations, the saturating nature of activation\nfunctions like softmax, and the most widely-used uncertainty metrics.",
          "link": "http://arxiv.org/abs/2012.05329",
          "publishedOn": "2021-06-11T01:42:15.649Z",
          "wordCount": 622,
          "title": "Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection. (arXiv:2012.05329v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yatong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Machine learning systems are often used in settings where individuals adapt\ntheir features to obtain a desired outcome. In such settings, strategic\nbehavior leads to a sharp loss in model performance in deployment. In this\nwork, we aim to address this problem by learning classifiers that encourage\ndecision subjects to change their features in a way that leads to improvement\nin both predicted \\emph{and} true outcome. We frame the dynamics of prediction\nand adaptation as a two-stage game, and characterize optimal strategies for the\nmodel designer and its decision subjects. In benchmarks on simulated and\nreal-world datasets, we find that classifiers trained using our method maintain\nthe accuracy of existing approaches while inducing higher levels of improvement\nand less manipulation.",
          "link": "http://arxiv.org/abs/2011.00355",
          "publishedOn": "2021-06-11T01:42:15.643Z",
          "wordCount": 579,
          "title": "Linear Classifiers that Encourage Constructive Adaptation. (arXiv:2011.00355v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dupuis_B/0/1/0/all/0/1\">Benjamin Dupuis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jacot_A/0/1/0/all/0/1\">Arthur Jacot</a>",
          "description": "We study the SIMP method with a density field generated by a fully-connected\nneural network, taking the coordinates as inputs. In the large width limit, we\nshow that the use of DNNs leads to a filtering effect similar to traditional\nfiltering techniques for SIMP, with a filter described by the Neural Tangent\nKernel (NTK). This filter is however not invariant under translation, leading\nto visual artifacts and non-optimal shapes. We propose two embeddings of the\ninput coordinates, which lead to (approximate) spatial invariance of the NTK\nand of the filter. We empirically confirm our theoretical observations and\nstudy how the filter size is affected by the architecture of the network. Our\nsolution can easily be applied to any other coordinates-based generation\nmethod.",
          "link": "http://arxiv.org/abs/2106.05710",
          "publishedOn": "2021-06-11T01:42:15.638Z",
          "wordCount": 547,
          "title": "DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent Kernel. (arXiv:2106.05710v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreau_H/0/1/0/all/0/1\">Hugues Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1\">Andr&#xe9;a Vassilev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>",
          "description": "In Transport Mode Detection, a great diversity of methodologies exist\naccording to the choice made on sensors, preprocessing, model used, etc. In\nthis domain, the comparisons between each option are not always complete.\nExperiments on a public, real-life dataset are led here to evaluate carefully\neach of the choices that were made, with a specific emphasis on data fusion\nmethods. Our most surprising finding is that none of the methods we implemented\nfrom the literature is better than a simple late fusion. Two important\ndecisions are the choice of a sensor and the choice of a representation for the\ndata: we found that using 2D convolutions on spectrograms with a logarithmic\naxis for the frequencies was better than 1-dimensional temporal\nrepresentations.",
          "link": "http://arxiv.org/abs/2106.05876",
          "publishedOn": "2021-06-11T01:42:15.632Z",
          "wordCount": 570,
          "title": "Data Fusion for Deep Learning on Transport Mode Detection: A Case Study. (arXiv:2106.05876v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grupen_N/0/1/0/all/0/1\">Niko A. Grupen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selman_B/0/1/0/all/0/1\">Bart Selman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "We study fairness through the lens of cooperative multi-agent learning. Our\nwork is motivated by empirical evidence that naive maximization of team reward\nyields unfair outcomes for individual team members. To address fairness in\nmulti-agent contexts, we introduce team fairness, a group-based fairness\nmeasure for multi-agent learning. We then incorporate team fairness into policy\noptimization -- introducing Fairness through Equivariance (Fair-E), a novel\nlearning strategy that achieves provably fair reward distributions. We then\nintroduce Fairness through Equivariance Regularization (Fair-ER) as a\nsoft-constraint version of Fair-E and show that Fair-ER reaches higher levels\nof utility than Fair-E and fairer outcomes than policies with no equivariance.\nFinally, we investigate the fairness-utility trade-off in multi-agent settings.",
          "link": "http://arxiv.org/abs/2106.05727",
          "publishedOn": "2021-06-11T01:42:15.617Z",
          "wordCount": 549,
          "title": "Fairness for Cooperative Multi-Agent Learning with Equivariant Policies. (arXiv:2106.05727v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Adversarial algorithms have shown to be effective against neural networks for\na variety of tasks. Some adversarial algorithms perturb all the pixels in the\nimage minimally for the image classification task in image classification. In\ncontrast, some algorithms perturb few pixels strongly. However, very little\ninformation is available regarding why these adversarial samples so diverse\nfrom each other exist. Recently, Vargas et al. showed that the existence of\nthese adversarial samples might be due to conflicting saliency within the\nneural network. We test this hypothesis of conflicting saliency by analysing\nthe Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)\nof original and few different types of adversarial samples. We also analyse how\ndifferent adversarial samples distort the attention of the neural network\ncompared to original samples. We show that in the case of Pixel Attack,\nperturbed pixels either calls the network attention to themselves or divert the\nattention from them. Simultaneously, the Projected Gradient Descent Attack\nperturbs pixels so that intermediate layers inside the neural network lose\nattention for the correct class. We also show that both attacks affect the\nsaliency map and activation maps differently. Thus, shedding light on why some\ndefences successful against some attacks remain vulnerable against other\nattacks. We hope that this analysis will improve understanding of the existence\nand the effect of adversarial samples and enable the community to develop more\nrobust neural networks.",
          "link": "http://arxiv.org/abs/2106.05657",
          "publishedOn": "2021-06-11T01:42:15.600Z",
          "wordCount": 675,
          "title": "Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_J/0/1/0/all/0/1\">Jingyi Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hang_H/0/1/0/all/0/1\">Hanyuan Hang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "In this paper, we propose a density estimation algorithm called\n\\textit{Gradient Boosting Histogram Transform} (GBHT), where we adopt the\n\\textit{Negative Log Likelihood} as the loss function to make the boosting\nprocedure available for the unsupervised tasks. From a learning theory\nviewpoint, we first prove fast convergence rates for GBHT with the smoothness\nassumption that the underlying density function lies in the space\n$C^{0,\\alpha}$. Then when the target density function lies in spaces\n$C^{1,\\alpha}$, we present an upper bound for GBHT which is smaller than the\nlower bound of its corresponding base learner, in the sense of convergence\nrates. To the best of our knowledge, we make the first attempt to theoretically\nexplain why boosting can enhance the performance of its base learners for\ndensity estimation problems. In experiments, we not only conduct performance\ncomparisons with the widely used KDE, but also apply GBHT to anomaly detection\nto showcase a further application of GBHT.",
          "link": "http://arxiv.org/abs/2106.05738",
          "publishedOn": "2021-06-11T01:42:15.594Z",
          "wordCount": 592,
          "title": "GBHT: Gradient Boosting Histogram Transform for Density Estimation. (arXiv:2106.05738v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_D/0/1/0/all/0/1\">David Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruchant_O/0/1/0/all/0/1\">Olivier Cruchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">Cedric Archambeau</a>",
          "description": "In addition to the best model architecture and hyperparameters, a full AutoML\nsolution requires selecting appropriate hardware automatically. This can be\nframed as a multi-objective optimization problem: there is not a single best\nhardware configuration but a set of optimal ones achieving different trade-offs\nbetween cost and runtime. In practice, some choices may be overly costly or\ntake days to train. To lift this burden, we adopt a multi-objective approach\nthat selects and adapts the hardware configuration automatically alongside\nneural architectures and their hyperparameters. Our method builds on Hyperband\nand extends it in two ways. First, we replace the stopping rule used in\nHyperband by a non-dominated sorting rule to preemptively stop unpromising\nconfigurations. Second, we leverage hyperparameter evaluations from related\ntasks via transfer learning by building a probabilistic estimate of the Pareto\nfront that finds promising configurations more efficiently than random search.\nWe show in extensive NAS and HPO experiments that both ingredients bring\nsignificant speed-ups and cost savings, with little to no impact on accuracy.\nIn three benchmarks where hardware is selected in addition to hyperparameters,\nwe obtain runtime and cost reductions of at least 5.8x and 8.8x, respectively.\nFurthermore, when applying our multi-objective method to the tuning of\nhyperparameters only, we obtain a 10\\% improvement in runtime while maintaining\nthe same accuracy on two popular NAS benchmarks.",
          "link": "http://arxiv.org/abs/2106.05680",
          "publishedOn": "2021-06-11T01:42:15.589Z",
          "wordCount": 646,
          "title": "A multi-objective perspective on jointly tuning hardware and hyperparameters. (arXiv:2106.05680v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kose_O/0/1/0/all/0/1\">&#xd6;yk&#xfc; Deniz K&#xf6;se</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanning Shen</a>",
          "description": "Node representation learning has demonstrated its effectiveness for various\napplications on graphs. Particularly, recent developments in contrastive\nlearning have led to promising results in unsupervised node representation\nlearning for a number of tasks. Despite the success of graph contrastive\nlearning and consequent growing interest, fairness is largely under-explored in\nthe field. To this end, this study addresses fairness issues in graph\ncontrastive learning with fairness-aware graph augmentation designs, through\nadaptive feature masking and edge deletion. In the study, different fairness\nnotions on graphs are introduced, which serve as guidelines for the proposed\ngraph augmentations. Furthermore, theoretical analysis is provided to\nquantitatively prove that the proposed feature masking approach can reduce\nintrinsic bias. Experimental results on real social networks are presented to\ndemonstrate that the proposed augmentations can enhance fairness in terms of\nstatistical parity and equal opportunity, while providing comparable\nclassification accuracy to state-of-the-art contrastive methods for node\nclassification.",
          "link": "http://arxiv.org/abs/2106.05391",
          "publishedOn": "2021-06-11T01:42:15.583Z",
          "wordCount": 571,
          "title": "Fairness-Aware Node Representation Learning. (arXiv:2106.05391v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelarescu_P/0/1/0/all/0/1\">Paul Chelarescu</a>",
          "description": "Within the framework of Multi-Agent Reinforcement Learning, Social Learning\nis a new class of algorithms that enables agents to reshape the reward function\nof other agents with the goal of promoting cooperation and achieving higher\nglobal rewards in mixed-motive games. However, this new modification allows\nagents unprecedented access to each other's learning process, which can\ndrastically increase the risk of manipulation when an agent does not realize it\nis being deceived into adopting policies which are not actually in its own best\ninterest. This research review introduces the problem statement, defines key\nconcepts, critically evaluates existing evidence and addresses open problems\nthat should be addressed in future research.",
          "link": "http://arxiv.org/abs/2106.05402",
          "publishedOn": "2021-06-11T01:42:15.567Z",
          "wordCount": 528,
          "title": "Deception in Social Learning: A Multi-Agent Reinforcement Learning Perspective. (arXiv:2106.05402v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1\">Christian Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1\">Grigory Antipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1\">Moez Baccouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1\">Madiha Nadri</a>",
          "description": "Methods for Visual Question Anwering (VQA) are notorious for leveraging\ndataset biases rather than performing reasoning, hindering generalization. It\nhas been recently shown that better reasoning patterns emerge in attention\nlayers of a state-of-the-art VQA model when they are trained on perfect\n(oracle) visual inputs. This provides evidence that deep neural networks can\nlearn to reason when training conditions are favorable enough. However,\ntransferring this learned knowledge to deployable models is a challenge, as\nmuch of it is lost during the transfer. We propose a method for knowledge\ntransfer based on a regularization term in our loss function, supervising the\nsequence of required reasoning operations. We provide a theoretical analysis\nbased on PAC-learning, showing that such program prediction can lead to\ndecreased sample complexity under mild hypotheses. We also demonstrate the\neffectiveness of this approach experimentally on the GQA dataset and show its\ncomplementarity to BERT-like self-supervised pre-training.",
          "link": "http://arxiv.org/abs/2106.05597",
          "publishedOn": "2021-06-11T01:42:15.561Z",
          "wordCount": 584,
          "title": "Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05472",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_Z/0/1/0/all/0/1\">Zengjing Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Epstein_L/0/1/0/all/0/1\">Larry G. Epstein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_G/0/1/0/all/0/1\">Guodong Zhang</a>",
          "description": "This paper establishes a central limit theorem under the assumption that\nconditional variances can vary in a largely unstructured history-dependent way\nacross experiments subject only to the restriction that they lie in a fixed\ninterval. Limits take a novel and tractable form, and are expressed in terms of\noscillating Brownian motion. A second contribution is application of this\nresult to a class of multi-armed bandit problems where the decision-maker is\nloss averse.",
          "link": "http://arxiv.org/abs/2106.05472",
          "publishedOn": "2021-06-11T01:42:15.555Z",
          "wordCount": 505,
          "title": "A Central Limit Theorem, Loss Aversion and Multi-Armed Bandits. (arXiv:2106.05472v1 [math.PR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Joey Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We study Thompson sampling (TS) in online decision-making problems where the\nuncertain environment is sampled from a mixture distribution. This is relevant\nto multi-task settings, where a learning agent is faced with different classes\nof problems. We incorporate this structure in a natural way by initializing TS\nwith a mixture prior -- dubbed MixTS -- and develop a novel, general technique\nfor analyzing the regret of TS with such priors. We apply this technique to\nderive Bayes regret bounds for MixTS in both linear bandits and tabular Markov\ndecision processes (MDPs). Our regret bounds reflect the structure of the\nproblem and depend on the number of components and confidence width of each\ncomponent of the prior. Finally, we demonstrate the empirical effectiveness of\nMixTS in both synthetic and real-world experiments.",
          "link": "http://arxiv.org/abs/2106.05608",
          "publishedOn": "2021-06-11T01:42:15.550Z",
          "wordCount": 565,
          "title": "Thompson Sampling with a Mixture Prior. (arXiv:2106.05608v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gunasekaran_J/0/1/0/all/0/1\">Jashwant Raj Gunasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_C/0/1/0/all/0/1\">Cyan Subhra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thinakaran_P/0/1/0/all/0/1\">Prashanth Thinakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1\">Mahmut Taylan Kandemir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_C/0/1/0/all/0/1\">Chita R. Das</a>",
          "description": "With a growing demand for adopting ML models for a varietyof application\nservices, it is vital that the frameworks servingthese models are capable of\ndelivering highly accurate predic-tions with minimal latency along with reduced\ndeploymentcosts in a public cloud environment. Despite high latency,prior works\nin this domain are crucially limited by the accu-racy offered by individual\nmodels. Intuitively, model ensem-bling can address the accuracy gap by\nintelligently combiningdifferent models in parallel. However, selecting the\nappro-priate models dynamically at runtime to meet the desiredaccuracy with low\nlatency at minimal deployment cost is anontrivial problem. Towards this, we\nproposeCocktail, a costeffective ensembling-based model serving\nframework.Cock-tailcomprises of two key components: (i) a dynamic\nmodelselection framework, which reduces the number of modelsin the ensemble,\nwhile satisfying the accuracy and latencyrequirements; (ii) an adaptive\nresource management (RM)framework that employs a distributed proactive\nautoscalingpolicy combined with importance sampling, to efficiently allo-cate\nresources for the models. The RM framework leveragestransient virtual machine\n(VM) instances to reduce the de-ployment cost in a public cloud. A prototype\nimplementationofCocktailon the AWS EC2 platform and exhaustive evalua-tions\nusing a variety of workloads demonstrate thatCocktailcan reduce deployment cost\nby 1.45x, while providing 2xreduction in latency and satisfying the target\naccuracy for upto 96% of the requests, when compared to\nstate-of-the-artmodel-serving frameworks.",
          "link": "http://arxiv.org/abs/2106.05345",
          "publishedOn": "2021-06-11T01:42:15.545Z",
          "wordCount": 661,
          "title": "Cocktail: Leveraging Ensemble Learning for Optimized Model Serving in Public Cloud. (arXiv:2106.05345v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05285",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Krause_C/0/1/0/all/0/1\">Claudius Krause</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shih_D/0/1/0/all/0/1\">David Shih</a>",
          "description": "We introduce CaloFlow, a fast detector simulation framework based on\nnormalizing flows. For the first time, we demonstrate that normalizing flows\ncan reproduce many-channel calorimeter showers with extremely high fidelity,\nproviding a fresh alternative to computationally expensive GEANT4 simulations,\nas well as other state-of-the-art fast simulation frameworks based on GANs and\nVAEs. Besides the usual histograms of physical features and images of\ncalorimeter showers, we introduce a new metric for judging the quality of\ngenerative modeling: the performance of a classifier trained to differentiate\nreal from generated images. We show that GAN-generated images can be identified\nby the classifier with 100% accuracy, while images generated from CaloFlow are\nable to fool the classifier much of the time. More broadly, normalizing flows\noffer several advantages compared to other state-of-the-art approaches (GANs\nand VAEs), including: tractable likelihoods; stable and convergent training;\nand principled model selection. Normalizing flows also provide a bijective\nmapping between data and the latent space, which could have other applications\nbeyond simulation, for example, to detector unfolding.",
          "link": "http://arxiv.org/abs/2106.05285",
          "publishedOn": "2021-06-11T01:42:15.530Z",
          "wordCount": 629,
          "title": "CaloFlow: Fast and Accurate Generation of Calorimeter Showers with Normalizing Flows. (arXiv:2106.05285v1 [physics.ins-det])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_B/0/1/0/all/0/1\">Ben Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinas_R/0/1/0/all/0/1\">Ramon Vi&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simidjievski_N/0/1/0/all/0/1\">Nikola Simidjievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>",
          "description": "Polythetic classifications, based on shared patterns of features that need\nneither be universal nor constant among members of a class, are common in the\nnatural world and greatly outnumber monothetic classifications over a set of\nfeatures. We show that threshold meta-learners require an embedding dimension\nthat is exponential in the number of features to emulate these functions. In\ncontrast, attentional classifiers are polythetic by default and able to solve\nthese problems with a linear embedding dimension. However, we find that in the\npresence of task-irrelevant features, inherent to meta-learning problems,\nattentional models are susceptible to misclassification. To address this\nchallenge, we further propose a self-attention feature-selection mechanism that\nadaptively dilutes non-discriminative features. We demonstrate the\neffectiveness of our approach in meta-learning Boolean functions, and synthetic\nand real-world few-shot learning tasks.",
          "link": "http://arxiv.org/abs/2106.05317",
          "publishedOn": "2021-06-11T01:42:15.524Z",
          "wordCount": 559,
          "title": "Attentional meta-learners are polythetic classifiers. (arXiv:2106.05317v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1\">Uiwon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Heeseung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1\">Dahuin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyemi Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Generative adversarial networks (GANs) with clustered latent spaces can\nperform conditional generation in a completely unsupervised manner. However,\nthe salient attributes of unlabeled data in the real-world are mostly\nimbalanced. Existing unsupervised conditional GANs cannot properly cluster the\nattributes in their latent spaces because they assume uniform distributions of\nthe attributes. To address this problem, we theoretically derive Stein latent\noptimization that provides reparameterizable gradient estimations of the latent\ndistribution parameters assuming a Gaussian mixture prior in a continuous\nlatent space. Structurally, we introduce an encoder network and a novel\ncontrastive loss to help generated data from a single mixture component to\nrepresent a single attribute. We confirm that the proposed method, named Stein\nLatent Optimization for GANs (SLOGAN), successfully learns the balanced or\nimbalanced attributes and performs unsupervised tasks such as unsupervised\nconditional generation, unconditional generation, and cluster assignment even\nin the absence of information of the attributes (e.g. the imbalance ratio).\nMoreover, we demonstrate that the attributes to be learned can be manipulated\nusing a small amount of probe data.",
          "link": "http://arxiv.org/abs/2106.05319",
          "publishedOn": "2021-06-11T01:42:15.512Z",
          "wordCount": 599,
          "title": "Stein Latent Optimization for GANs. (arXiv:2106.05319v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05275",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>",
          "description": "Normalizing flows are generative models that provide tractable density\nestimation by transforming a simple base distribution into a complex target\ndistribution. However, this technique cannot directly model data supported on\nan unknown low-dimensional manifold, a common occurrence in real-world domains\nsuch as image data. Recent attempts to remedy this limitation have introduced\ngeometric complications that defeat a central benefit of normalizing flows:\nexact density estimation. We recover this benefit with Conformal Embedding\nFlows, a framework for designing flows that learn manifolds with tractable\ndensities. We argue that composing a standard flow with a trainable conformal\nembedding is the most natural way to model manifold-supported data. To this\nend, we present a series of conformal building blocks and apply them in\nexperiments with real-world and synthetic data to demonstrate that flows can\nmodel manifold-supported distributions without sacrificing tractable\nlikelihoods.",
          "link": "http://arxiv.org/abs/2106.05275",
          "publishedOn": "2021-06-11T01:42:15.507Z",
          "wordCount": 568,
          "title": "Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows. (arXiv:2106.05275v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Rongye Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Z/0/1/0/all/0/1\">Zhaobin Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Di_X/0/1/0/all/0/1\">Xuan Di</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qiang Du</a>",
          "description": "Traffic state estimation (TSE) bifurcates into two main categories,\nmodel-driven and data-driven (e.g., machine learning, ML) approaches, while\neach suffers from either deficient physics or small data. To mitigate these\nlimitations, recent studies introduced hybrid methods, such as physics-informed\ndeep learning (PIDL), which contains both model-driven and data-driven\ncomponents. This paper contributes an improved paradigm, called\nphysics-informed deep learning with a fundamental diagram learner (PIDL+FDL),\nwhich integrates ML terms into the model-driven component to learn a functional\nform of a fundamental diagram (FD), i.e., a mapping from traffic density to\nflow or velocity. The proposed PIDL+FDL has the advantages of performing the\nTSE learning, model parameter discovery, and FD discovery simultaneously. This\npaper focuses on highway TSE with observed data from loop detectors, using\ntraffic density or velocity as traffic variables. We demonstrate the use of\nPIDL+FDL to solve popular first-order and second-order traffic flow models and\nreconstruct the FD relation as well as model parameters that are outside the FD\nterm. We then evaluate the PIDL+FDL-based TSE using the Next Generation\nSIMulation (NGSIM) dataset. The experimental results show the superiority of\nthe PIDL+FDL in terms of improved estimation accuracy and data efficiency over\nadvanced baseline TSE methods, and additionally, the capacity to properly learn\nthe unknown underlying FD relation.",
          "link": "http://arxiv.org/abs/2106.03142",
          "publishedOn": "2021-06-11T01:42:15.502Z",
          "wordCount": 671,
          "title": "A Physics-Informed Deep Learning Paradigm for Traffic State Estimation and Fundamental Diagram Discovery. (arXiv:2106.03142v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1\">David Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jankowiak_M/0/1/0/all/0/1\">Martin Jankowiak</a>",
          "description": "Bayesian optimization (BO) is a powerful paradigm for efficient optimization\nof black-box objective functions. High-dimensional BO presents a particular\nchallenge, in part because the curse of dimensionality makes it difficult to\ndefine -- as well as do inference over -- a suitable class of surrogate models.\nWe argue that Gaussian process surrogate models defined on sparse axis-aligned\nsubspaces offer an attractive compromise between flexibility and parsimony. We\ndemonstrate that our approach, which relies on Hamiltonian Monte Carlo for\ninference, can rapidly identify sparse subspaces relevant to modeling the\nunknown objective function, enabling sample-efficient high-dimensional BO. In\nan extensive suite of experiments comparing to existing methods for\nhigh-dimensional BO we demonstrate that our algorithm, Sparse Axis-Aligned\nSubspace BO (SAASBO), achieves excellent performance on several synthetic and\nreal-world problems without the need to set problem-specific hyperparameters.",
          "link": "http://arxiv.org/abs/2103.00349",
          "publishedOn": "2021-06-11T01:42:15.438Z",
          "wordCount": 590,
          "title": "High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces. (arXiv:2103.00349v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1\">Brian Quanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of regression, classification, and control tasks.\nHowever, despite these successes, the field lacks strong theoretical error\nbounds and consistent measures of network generalization and learned\ninvariances. In this work, we introduce two new measures, the Gi-score and\nPal-score, that capture a deep neural network's generalization capabilities.\nInspired by the Gini coefficient and Palma ratio, measures of income\ninequality, our statistics are robust measures of a network's invariance to\nperturbations that accurately predict generalization gaps, i.e., the difference\nbetween accuracy on training and test sets.",
          "link": "http://arxiv.org/abs/2104.03469",
          "publishedOn": "2021-06-11T01:42:15.433Z",
          "wordCount": 567,
          "title": "Gi and Pal Scores: Deep Neural Network Generalization Statistics. (arXiv:2104.03469v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1\">David Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taly_A/0/1/0/all/0/1\">Ankur Taly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floridi_L/0/1/0/all/0/1\">Luciano Floridi</a>",
          "description": "Necessity and sufficiency are the building blocks of all successful\nexplanations. Yet despite their importance, these notions have been\nconceptually underdeveloped and inconsistently applied in explainable\nartificial intelligence (XAI), a fast-growing research area that is so far\nlacking in firm theoretical foundations. Building on work in logic,\nprobability, and causality, we establish the central role of necessity and\nsufficiency in XAI, unifying seemingly disparate methods in a single formal\nframework. We provide a sound and complete algorithm for computing explanatory\nfactors with respect to a given context, and demonstrate its flexibility and\ncompetitive performance against state of the art alternatives on various tasks.",
          "link": "http://arxiv.org/abs/2103.14651",
          "publishedOn": "2021-06-11T01:42:15.426Z",
          "wordCount": 574,
          "title": "Local Explanations via Necessity and Sufficiency: Unifying Theory and Practice. (arXiv:2103.14651v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bice_N/0/1/0/all/0/1\">Noah Bice</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhreddine_M/0/1/0/all/0/1\">Mohamad Fakhreddine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabat_C/0/1/0/all/0/1\">Christopher Kabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_P/0/1/0/all/0/1\">Pamela Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papanikolaou_N/0/1/0/all/0/1\">Niko Papanikolaou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirby_N/0/1/0/all/0/1\">Neil Kirby</a>",
          "description": "Volumetric modulated arc therapy planning is a challenging problem in\nhigh-dimensional, non-convex optimization. Traditionally, heuristics such as\nfluence-map-optimization-informed segment initialization use locally optimal\nsolutions to begin the search of the full arc therapy plan space from a\nreasonable starting point. These routines facilitate arc therapy optimization\nsuch that clinically satisfactory radiation treatment plans can be created in\nabout 10 minutes. However, current optimization algorithms favor solutions near\ntheir initialization point and are slower than necessary due to plan\noverparameterization. In this work, arc therapy overparameterization is\naddressed by reducing the effective dimension of treatment plans with\nunsupervised deep learning. An optimization engine is then built based on\nlow-dimensional arc representations which facilitates faster planning times.",
          "link": "http://arxiv.org/abs/2106.05846",
          "publishedOn": "2021-06-11T01:42:15.396Z",
          "wordCount": 540,
          "title": "Latent Space Arc Therapy Optimization. (arXiv:2106.05846v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1\">Tarun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1\">Anuj Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1\">Wendelin B&#xf6;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "VDN and QMIX are two popular value-based algorithms for cooperative MARL that\nlearn a centralized action value function as a monotonic mixing of per-agent\nutilities. While this enables easy decentralization of the learned policy, the\nrestricted joint action value function can prevent them from solving tasks that\nrequire significant coordination between agents at a given timestep. We show\nthat this problem can be overcome by improving the joint exploration of all\nagents during training. Specifically, we propose a novel MARL approach called\nUniversal Value Exploration (UneVEn) that learns a set of related tasks\nsimultaneously with a linear decomposition of universal successor features.\nWith the policies of already solved related tasks, the joint exploration\nprocess of all agents can be improved to help them achieve better coordination.\nEmpirical results on a set of exploration games, challenging cooperative\npredator-prey tasks requiring significant coordination among agents, and\nStarCraft II micromanagement benchmarks show that UneVEn can solve tasks where\nother state-of-the-art MARL methods fail.",
          "link": "http://arxiv.org/abs/2010.02974",
          "publishedOn": "2021-06-11T01:42:15.390Z",
          "wordCount": 638,
          "title": "UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning. (arXiv:2010.02974v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.09671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "We review the current literature concerned with information plane analyses of\nneural network classifiers. While the underlying information bottleneck theory\nand the claim that information-theoretic compression is causally linked to\ngeneralization are plausible, empirical evidence was found to be both\nsupporting and conflicting. We review this evidence together with a detailed\nanalysis of how the respective information quantities were estimated. Our\nsurvey suggests that compression visualized in information planes is not\nnecessarily information-theoretic, but is rather often compatible with\ngeometric compression of the latent representations. This insight gives the\ninformation plane a renewed justification.\n\nAside from this, we shed light on the problem of estimating mutual\ninformation in deterministic neural networks and its consequences.\nSpecifically, we argue that even in feed-forward neural networks the data\nprocessing inequality need not hold for estimates of mutual information.\nSimilarly, while a fitting phase, in which the mutual information between the\nlatent representation and the target increases, is necessary (but not\nsufficient) for good classification performance, depending on the specifics of\nmutual information estimation such a fitting phase need not be visible in the\ninformation plane.",
          "link": "http://arxiv.org/abs/2003.09671",
          "publishedOn": "2021-06-11T01:42:15.384Z",
          "wordCount": 682,
          "title": "On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seongbin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seongjin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>",
          "description": "End-to-end approaches open a new way for more accurate and efficient spoken\nlanguage understanding (SLU) systems by alleviating the drawbacks of\ntraditional pipeline systems. Previous works exploit textual information for an\nSLU model via pre-training with automatic speech recognition or fine-tuning\nwith knowledge distillation. To utilize textual information more effectively,\nthis work proposes a two-stage textual knowledge distillation method that\nmatches utterance-level representations and predicted logits of two modalities\nduring pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a\nspeech encoder because it captures general and rich features. Furthermore, we\nimprove the performance, especially in a low-resource scenario, with data\naugmentation methods by randomly masking spans of discrete audio tokens and\ncontextualized hidden representations. Consequently, we push the\nstate-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy\nin the full dataset setting and 99.5% in the 10% subset setting. Throughout the\nablation studies, we empirically verify that all used methods are crucial to\nthe final performance, providing the best practice for spoken language\nunderstanding. Code is available at https://github.com/clovaai/textual-kd-slu.",
          "link": "http://arxiv.org/abs/2010.13105",
          "publishedOn": "2021-06-11T01:42:15.378Z",
          "wordCount": 649,
          "title": "Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.08405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1\">Nihal Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Soumya Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1\">Sanjay Shakkottai</a>",
          "description": "We study a variant of the multi-armed bandit problem where side information\nin the form of bounds on the mean of each arm is provided. We develop the novel\nnon-optimistic Global Under-Explore (GLUE) algorithm which uses the provided\nmean bounds (across all the arms) to infer pseudo-variances for each arm, which\nin turn decide the rate of exploration for the arms. We analyze the regret of\nGLUE and prove regret upper bounds that are never worse than that of the\nstandard UCB algorithm. Furthermore, we show that GLUE improves upon regret\nguarantees that exists in literature for structured bandit problems (both\ntheoretically and empirically). Finally, we study the practical setting of\nlearning adaptive interventions using prior data that has been confounded by\nunrecorded variables that affect rewards. We show that mean bounds can be\ninferred naturally from such logs and can thus be used to improve the learning\nprocess. We validate our findings through semi-synthetic experiments on data\nderived from real data sets.",
          "link": "http://arxiv.org/abs/2002.08405",
          "publishedOn": "2021-06-11T01:42:15.373Z",
          "wordCount": 642,
          "title": "On Under-exploration in Bandits with Mean Bounds from Confounded Data. (arXiv:2002.08405v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05466",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hie_B/0/1/0/all/0/1\">Brian L. Hie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_K/0/1/0/all/0/1\">Kevin K. Yang</a>",
          "description": "Machine-learning models that learn from data to predict how protein sequence\nencodes function are emerging as a useful protein engineering tool. However,\nwhen using these models to suggest new protein designs, one must deal with the\nvast combinatorial complexity of protein sequences. Here, we review how to use\na sequence-to-function machine-learning surrogate model to select sequences for\nexperimental measurement. First, we discuss how to select sequences through a\nsingle round of machine-learning optimization. Then, we discuss sequential\noptimization, where the goal is to discover optimized sequences and improve the\nmodel across multiple rounds of training, optimization, and experimental\nmeasurement.",
          "link": "http://arxiv.org/abs/2106.05466",
          "publishedOn": "2021-06-11T01:42:15.346Z",
          "wordCount": 529,
          "title": "Adaptive machine learning for protein engineering. (arXiv:2106.05466v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>",
          "description": "Inspired by BatchNorm, there has been an explosion of normalization layers in\ndeep learning. Recent works have identified a multitude of beneficial\nproperties in BatchNorm to explain its success. However, given the pursuit of\nalternative normalization techniques, these properties need to be generalized\nso that any given layer's success/failure can be accurately predicted. In this\nwork, we take a first step towards this goal by extending known properties of\nBatchNorm in randomly initialized deep neural networks (DNNs) to nine recently\nproposed normalization layers. Our primary findings follow: (i) Similar to\nBatchNorm, activations-based normalization layers can avoid exploding\nactivations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at\nleast $\\Omega(\\sqrt{\\frac{\\text{width}}{\\text{Group Size}}})$, thus explaining\nwhy LayerNorm witnesses slow optimization speed; (iii) Small group sizes result\nin large gradient norm in earlier layers, hence justifying training instability\nissues in Instance Normalization and illustrating a speed-stability tradeoff in\nGroupNorm. Overall, our analysis reveals several general mechanisms that\nexplain the success of normalization techniques in deep learning, providing us\nwith a compass to systematically explore the vast design space of DNN\nnormalization layers.",
          "link": "http://arxiv.org/abs/2106.05956",
          "publishedOn": "2021-06-11T01:42:15.336Z",
          "wordCount": 619,
          "title": "Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neary_C/0/1/0/all/0/1\">Cyrus Neary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verginis_C/0/1/0/all/0/1\">Christos Verginis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cubuktepe_M/0/1/0/all/0/1\">Murat Cubuktepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "We propose a novel framework for verifiable and compositional reinforcement\nlearning (RL) in which a collection of RL sub-systems, each of which learns to\naccomplish a separate sub-task, are composed to achieve an overall task. The\nframework consists of a high-level model, represented as a parametric Markov\ndecision process (pMDP) which is used to plan and to analyze compositions of\nsub-systems, and of the collection of low-level sub-systems themselves. By\ndefining interfaces between the sub-systems, the framework enables automatic\ndecompositons of task specifications, e.g., reach a target set of states with a\nprobability of at least 0.95, into individual sub-task specifications, i.e.\nachieve the sub-system's exit conditions with at least some minimum\nprobability, given that its entry conditions are met. This in turn allows for\nthe independent training and testing of the sub-systems; if they each learn a\npolicy satisfying the appropriate sub-task specification, then their\ncomposition is guaranteed to satisfy the overall task specification.\nConversely, if the sub-task specifications cannot all be satisfied by the\nlearned policies, we present a method, formulated as the problem of finding an\noptimal set of parameters in the pMDP, to automatically update the sub-task\nspecifications to account for the observed shortcomings. The result is an\niterative procedure for defining sub-task specifications, and for training the\nsub-systems to meet them. As an additional benefit, this procedure allows for\nparticularly challenging or important components of an overall task to be\ndetermined automatically, and focused on, during training. Experimental results\ndemonstrate the presented framework's novel capabilities.",
          "link": "http://arxiv.org/abs/2106.05864",
          "publishedOn": "2021-06-11T01:42:15.284Z",
          "wordCount": 675,
          "title": "Verifiable and Compositional Reinforcement Learning Systems. (arXiv:2106.05864v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1\">Oleksandr Polozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>",
          "description": "We introduce a new type of programming challenge called programming puzzles,\nas an objective and comprehensive evaluation of program synthesis, and release\nan open-source dataset of Python Programming Puzzles (P3). Each puzzle is\ndefined by a short Python program $f$, and the goal is to find an input $x$\nwhich makes $f$ output \"True\". The puzzles are objective in that each one is\nspecified entirely by the source code of its verifier $f$, so evaluating $f(x)$\nis all that is needed to test a candidate solution $x$. They do not require an\nanswer key or input/output examples, nor do they depend on natural language\nunderstanding. The dataset is comprehensive in that it spans problems of a\nrange of difficulties and domains, ranging from trivial string manipulation\nproblems that are immediately obvious to human programmers (but not necessarily\nto AI), to classic programming puzzles (e.g., Towers of Hanoi), to\ninterview/competitive-programming problems (e.g., dynamic programming), to\nlongstanding open problems in algorithms and mathematics (e.g., factoring). The\nobjective nature of P3 readily supports self-supervised bootstrapping. We\ndevelop baseline enumerative program synthesis and GPT-3 solvers that are\ncapable of solving easy puzzles -- even without access to any reference\nsolutions -- by learning from their own past solutions. Based on a small user\nstudy, we find puzzle difficulty to correlate between human programmers and the\nbaseline AI solvers.",
          "link": "http://arxiv.org/abs/2106.05784",
          "publishedOn": "2021-06-11T01:42:15.273Z",
          "wordCount": 661,
          "title": "Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Babay_A/0/1/0/all/0/1\">Amy Babay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1\">Michael Dinitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sambaturu_P/0/1/0/all/0/1\">Prathyush Sambaturu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1\">Aravind Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1\">Leonidas Tsepenekas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1\">Anil Vullikanti</a>",
          "description": "Graph cut problems form a fundamental problem type in combinatorial\noptimization, and are a central object of study in both theory and practice. In\naddition, the study of fairness in Algorithmic Design and Machine Learning has\nrecently received significant attention, with many different notions proposed\nand analyzed in a variety of contexts. In this paper we initiate the study of\nfairness for graph cut problems by giving the first fair definitions for them,\nand subsequently we demonstrate appropriate algorithmic techniques that yield a\nrigorous theoretical analysis. Specifically, we incorporate two different\ndefinitions of fairness, namely demographic and probabilistic individual\nfairness, in a particular cut problem modeling disaster containment scenarios.\nOur results include a variety of approximation algorithms with provable\ntheoretical guarantees.",
          "link": "http://arxiv.org/abs/2106.05424",
          "publishedOn": "2021-06-11T01:42:15.267Z",
          "wordCount": 554,
          "title": "Fair Disaster Containment via Graph-Cut Problems. (arXiv:2106.05424v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1\">Maciej Wo&#x142;czyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1\">Bartosz W&#xf3;jcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1\">Klaudia Ba&#x142;azy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podolak_I/0/1/0/all/0/1\">Igor Podolak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1\">Marek &#x15a;mieja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1\">Tomasz Trzci&#x144;ski</a>",
          "description": "The problem of reducing processing time of large deep learning models is a\nfundamental challenge in many real-world applications. Early exit methods\nstrive towards this goal by attaching additional Internal Classifiers (ICs) to\nintermediate layers of a neural network. ICs can quickly return predictions for\neasy examples and, as a result, reduce the average inference time of the whole\nmodel. However, if a particular IC does not decide to return an answer early,\nits predictions are discarded, with its computations effectively being wasted.\nTo solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in\nwhich each IC reuses predictions returned by its predecessors by (1) adding\ndirect connections between ICs and (2) combining previous outputs in an\nensemble-like manner. We conduct extensive experiments across various datasets\nand architectures to demonstrate that ZTW achieves a significantly better\naccuracy vs. inference time trade-off than other recently proposed early exit\nmethods.",
          "link": "http://arxiv.org/abs/2106.05409",
          "publishedOn": "2021-06-11T01:42:15.251Z",
          "wordCount": 584,
          "title": "Zero Time Waste: Recycling Predictions in Early Exit Neural Networks. (arXiv:2106.05409v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1\">Matthias Fey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenssen_J/0/1/0/all/0/1\">Jan E. Lenssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weichert_F/0/1/0/all/0/1\">Frank Weichert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>",
          "description": "We present GNNAutoScale (GAS), a framework for scaling arbitrary\nmessage-passing GNNs to large graphs. GAS prunes entire sub-trees of the\ncomputation graph by utilizing historical embeddings from prior training\niterations, leading to constant GPU memory consumption in respect to input node\nsize without dropping any data. While existing solutions weaken the expressive\npower of message passing due to sub-sampling of edges or non-trainable\npropagations, our approach is provably able to maintain the expressive power of\nthe original GNN. We achieve this by providing approximation error bounds of\nhistorical embeddings and show how to tighten them in practice. Empirically, we\nshow that the practical realization of our framework, PyGAS, an easy-to-use\nextension for PyTorch Geometric, is both fast and memory-efficient, learns\nexpressive node representations, closely resembles the performance of their\nnon-scaling counterparts, and reaches state-of-the-art performance on\nlarge-scale graphs.",
          "link": "http://arxiv.org/abs/2106.05609",
          "publishedOn": "2021-06-11T01:42:15.228Z",
          "wordCount": 575,
          "title": "GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings. (arXiv:2106.05609v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1\">Julia Rosenzweig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1\">Eduardo Brito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1\">Hans-Ulrich Kobialka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1\">Nico M. Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1\">Peter Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jan David Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1\">Fabian H&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1\">Sebastian Houben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1\">Tim Wirtz</a>",
          "description": "Many machine learning applications can benefit from simulated data for\nsystematic validation - in particular if real-life data is difficult to obtain\nor annotate. However, since simulations are prone to domain shift w.r.t.\nreal-life data, it is crucial to verify the transferability of the obtained\nresults. We propose a novel framework consisting of a generative label-to-image\nsynthesis model together with different transferability measures to inspect to\nwhat extent we can transfer testing results of semantic segmentation models\nfrom synthetic data to equivalent real-life data. With slight modifications,\nour approach is extendable to, e.g., general multi-class classification tasks.\nGrounded on the transferability analysis, our approach additionally allows for\nextensive testing by incorporating controlled simulations. We validate our\napproach empirically on a semantic segmentation task on driving scenes.\nTransferability is tested using correlation analysis of IoU and a learned\ndiscriminator. Although the latter can distinguish between real-life and\nsynthetic tests, in the former we observe surprisingly strong correlations of\n0.7 for both cars and pedestrians.",
          "link": "http://arxiv.org/abs/2106.05549",
          "publishedOn": "2021-06-11T01:42:15.218Z",
          "wordCount": 642,
          "title": "Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05739",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1\">Carles Domingo-Enrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1\">Youssef Mroueh</a>",
          "description": "Several works in implicit and explicit generative modeling empirically\nobserved that feature-learning discriminators outperform fixed-kernel\ndiscriminators in terms of the sample quality of the models. We provide\nseparation results between probability metrics with fixed-kernel and\nfeature-learning discriminators using the function classes $\\mathcal{F}_2$ and\n$\\mathcal{F}_1$ respectively, which were developed to study overparametrized\ntwo-layer neural networks. In particular, we construct pairs of distributions\nover hyper-spheres that can not be discriminated by fixed kernel\n$(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)\nin high dimensions, but that can be discriminated by their feature learning\n($\\mathcal{F}_1$) counterparts. To further study the separation we provide\nlinks between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced\nWasserstein distances. Our work suggests that fixed-kernel discriminators\nperform worse than their feature learning counterparts because their\ncorresponding metrics are weaker.",
          "link": "http://arxiv.org/abs/2106.05739",
          "publishedOn": "2021-06-11T01:42:15.197Z",
          "wordCount": 569,
          "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Graph neural networks have been widely used on modeling graph data, achieving\nimpressive results on node classification and link prediction tasks. Yet,\nobtaining an accurate representation for a graph further requires a pooling\nfunction that maps a set of node representations into a compact form. A simple\nsum or average over all node representations considers all node features\nequally without consideration of their task relevance, and any structural\ndependencies among them. Recently proposed hierarchical graph pooling methods,\non the other hand, may yield the same representation for two different graphs\nthat are distinguished by the Weisfeiler-Lehman test, as they suboptimally\npreserve information from the node features. To tackle these limitations of\nexisting graph pooling methods, we first formulate the graph pooling problem as\na multiset encoding problem with auxiliary information about the graph\nstructure, and propose a Graph Multiset Transformer (GMT) which is a multi-head\nattention based global pooling layer that captures the interaction between\nnodes according to their structural dependencies. We show that GMT satisfies\nboth injectiveness and permutation invariance, such that it is at most as\npowerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods\ncan be easily extended to the previous node clustering approaches for\nhierarchical graph pooling. Our experimental results show that GMT\nsignificantly outperforms state-of-the-art graph pooling methods on graph\nclassification benchmarks with high memory and time efficiency, and obtains\neven larger performance gain on graph reconstruction and generation tasks.",
          "link": "http://arxiv.org/abs/2102.11533",
          "publishedOn": "2021-06-11T01:42:15.191Z",
          "wordCount": 701,
          "title": "Accurate Learning of Graph Representations with Graph Multiset Pooling. (arXiv:2102.11533v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.14061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harada_S/0/1/0/all/0/1\">Shonosuke Harada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Outcome estimation of treatments for target individuals is an important\nfoundation for decision making based on causal relations. Most existing outcome\nestimation methods deal with binary or multiple-choice treatments; however, in\nsome applications, the number of treatments can be significantly large, while\nthe treatments themselves have rich information. In this study, we considered\none important instance of such cases: the outcome estimation problem of\ngraph-structured treatments such as drugs. Owing to the large number of\npossible treatments, the counterfactual nature of observational data that\nappears in conventional treatment effect estimation becomes more of a concern\nfor this problem. Our proposed method, GraphITE (pronounced \"graphite\") learns\nthe representations of graph-structured treatments using graph neural networks\nwhile mitigating observation biases using Hilbert-Schmidt Independence\nCriterion regularization, which increases the independence of the\nrepresentations of the targets and treatments. Experiments on two real-world\ndatasets show that GraphITE outperforms baselines, especially in cases with a\nlarge number of treatments.",
          "link": "http://arxiv.org/abs/2009.14061",
          "publishedOn": "2021-06-11T01:42:15.171Z",
          "wordCount": 604,
          "title": "GraphITE: Estimating Individual Effects of Graph-structured Treatments. (arXiv:2009.14061v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Youngtaek Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "The capability of the traditional semi-supervised learning (SSL) methods is\nfar from real-world application since they do not consider (1) class imbalance\nand (2) class distribution mismatch between labeled and unlabeled data. This\npaper addresses such a relatively under-explored problem, imbalanced\nsemi-supervised learning, where heavily biased pseudo-labels can harm the model\nperformance. Interestingly, we find that the semantic pseudo-labels from a\nsimilarity-based classifier in feature space and the traditional pseudo-labels\nfrom the linear classifier show the complementary property. To this end, we\npropose a general pseudo-labeling framework to address the bias motivated by\nthis observation. The key idea is to class-adaptively blend the semantic\npseudo-label to the linear one, depending on the current pseudo-label\ndistribution. Thereby, the increased semantic pseudo-label component suppresses\nthe false positives in the majority classes and vice versa. We term the novel\npseudo-labeling framework for imbalanced SSL as Distribution-Aware\nSemantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT\nand STL10-LT shows that DASO consistently outperforms both recently proposed\nre-balancing methods for label and pseudo-label. Moreover, we demonstrate that\ntypical SSL algorithms can effectively benefit from unlabeled data with DASO,\nespecially when (1) class imbalance and (2) class distribution mismatch exist\nand even on recent real-world Semi-Aves benchmark.",
          "link": "http://arxiv.org/abs/2106.05682",
          "publishedOn": "2021-06-11T01:42:15.076Z",
          "wordCount": 638,
          "title": "Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Ankit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1\">Hei Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1\">Alejandro Newell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>",
          "description": "Processing point cloud data is an important component of many real-world\nsystems. As such, a wide variety of point-based approaches have been proposed,\nreporting steady benchmark improvements over time. We study the key ingredients\nof this progress and uncover two critical results. First, we find that\nauxiliary factors like different evaluation schemes, data augmentation\nstrategies, and loss functions, which are independent of the model\narchitecture, make a large difference in performance. The differences are large\nenough that they obscure the effect of architecture. When these factors are\ncontrolled for, PointNet++, a relatively older network, performs competitively\nwith recent methods. Second, a very simple projection-based method, which we\nrefer to as SimpleView, performs surprisingly well. It achieves on par or\nbetter results than sophisticated state-of-the-art methods on ModelNet40 while\nbeing half the size of PointNet++. It also outperforms state-of-the-art methods\non ScanObjectNN, a real-world point cloud benchmark, and demonstrates better\ncross-dataset generalization. Code is available at\nhttps://github.com/princeton-vl/SimpleView.",
          "link": "http://arxiv.org/abs/2106.05304",
          "publishedOn": "2021-06-11T01:42:15.047Z",
          "wordCount": 605,
          "title": "Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1\">Jonathan Crabb&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "How can we explain the predictions of a machine learning model? When the data\nis structured as a multivariate time series, this question induces additional\ndifficulties such as the necessity for the explanation to embody the time\ndependency and the large number of inputs. To address these challenges, we\npropose dynamic masks (Dynamask). This method produces instance-wise importance\nscores for each feature at each time step by fitting a perturbation mask to the\ninput sequence. In order to incorporate the time dependency of the data,\nDynamask studies the effects of dynamic perturbation operators. In order to\ntackle the large number of inputs, we propose a scheme to make the feature\nselection parsimonious (to select no more feature than necessary) and legible\n(a notion that we detail by making a parallel with information theory). With\nsynthetic and real-world data, we demonstrate that the dynamic underpinning of\nDynamask, together with its parsimony, offer a neat improvement in the\nidentification of feature importance over time. The modularity of Dynamask\nmakes it ideal as a plug-in to increase the transparency of a wide range of\nmachine learning models in areas such as medicine and finance, where time\nseries are abundant.",
          "link": "http://arxiv.org/abs/2106.05303",
          "publishedOn": "2021-06-11T01:42:15.041Z",
          "wordCount": 635,
          "title": "Explaining Time Series Predictions with Dynamic Masks. (arXiv:2106.05303v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>",
          "description": "Cloth simulation has wide applications including computer animation, garment\ndesign, and robot-assisted dressing. In this work, we present a differentiable\ncloth simulator whose additional gradient information facilitates cloth-related\napplications. Our differentiable simulator extends the state-of-the-art cloth\nsimulator based on Projective Dynamics and with dry frictional contact governed\nby the Signorini-Coulomb law. We derive gradients with contact in this forward\nsimulation framework and speed up the computation with Jacobi iteration\ninspired by previous differentiable simulation work. To our best knowledge, we\npresent the first differentiable cloth simulator with the Coulomb law of\nfriction. We demonstrate the efficacy of our simulator in various applications,\nincluding system identification, manipulation, inverse design, and a\nreal-to-sim task. Many of our applications have not been demonstrated in\nprevious differentiable cloth simulators. The gradient information from our\nsimulator enables efficient gradient-based task solvers from which we observe a\nsubstantial speedup over standard gradient-free methods.",
          "link": "http://arxiv.org/abs/2106.05306",
          "publishedOn": "2021-06-11T01:42:15.007Z",
          "wordCount": 574,
          "title": "DiffCloth: Differentiable Cloth Simulation with Dry Frictional Contact. (arXiv:2106.05306v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix G. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-10T22:40:40.687Z",
          "wordCount": 609,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bucher_J/0/1/0/all/0/1\">Julian B&#xfc;cher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faber_F/0/1/0/all/0/1\">Fynn Faber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muir_D/0/1/0/all/0/1\">Dylan R. Muir</a>",
          "description": "Neuromorphic neural network processors, in the form of compute-in-memory\ncrossbar arrays of memristors, or in the form of subthreshold analog and\nmixed-signal ASICs, promise enormous advantages in compute density and energy\nefficiency for NN-based ML tasks. However, these technologies are prone to\ncomputational non-idealities, due to process variation and intrinsic device\nphysics. This degrades the task performance of networks deployed to the\nprocessor, by introducing parameter noise into the deployed model. While it is\npossible to calibrate each device, or train networks individually for each\nprocessor, these approaches are expensive and impractical for commercial\ndeployment. Alternative methods are therefore needed to train networks that are\ninherently robust against parameter variation, as a consequence of network\narchitecture and parameters. We present a new adversarial network optimisation\nalgorithm that attacks network parameters during training, and promotes robust\nperformance during inference in the face of parameter variation. Our approach\nintroduces a regularization term penalising the susceptibility of a network to\nweight perturbation. We compare against previous approaches for producing\nparameter insensitivity such as dropout, weight smoothing and introducing\nparameter noise during training. We show that our approach produces models that\nare more robust to targeted parameter variation, and equally robust to random\nparameter variation. Our approach finds minima in flatter locations in the\nweight-loss landscape compared with other approaches, highlighting that the\nnetworks found by our technique are less sensitive to parameter perturbation.\nOur work provides an approach to deploy neural network architectures to\ninference devices that suffer from computational non-idealities, with minimal\nloss of performance. ...",
          "link": "http://arxiv.org/abs/2106.05009",
          "publishedOn": "2021-06-10T01:56:49.632Z",
          "wordCount": 676,
          "title": "Network insensitivity to parameter noise via adversarial regularization. (arXiv:2106.05009v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.08573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1\">Sheheryar Zaidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1\">Arber Zela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1\">Thomas Elsken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Ensembles of neural networks achieve superior performance compared to\nstand-alone networks in terms of accuracy, uncertainty calibration and\nrobustness to dataset shift. \\emph{Deep ensembles}, a state-of-the-art method\nfor uncertainty estimation, only ensemble random initializations of a\n\\emph{fixed} architecture. Instead, we propose two methods for automatically\nconstructing ensembles with \\emph{varying} architectures, which implicitly\ntrade-off individual architectures' strengths against the ensemble's diversity\nand exploit architectural variation as a source of diversity. On a variety of\nclassification tasks and modern architecture search spaces, we show that the\nresulting ensembles outperform deep ensembles not only in terms of accuracy but\nalso uncertainty calibration and robustness to dataset shift. Our further\nanalysis and ablation studies provide evidence of higher ensemble diversity due\nto architectural variation, resulting in ensembles that can outperform deep\nensembles, even when having weaker average base learners.",
          "link": "http://arxiv.org/abs/2006.08573",
          "publishedOn": "2021-06-10T01:56:49.616Z",
          "wordCount": 624,
          "title": "Neural Ensemble Search for Uncertainty Estimation and Dataset Shift. (arXiv:2006.08573v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Laura Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>",
          "description": "Conveying complex objectives to reinforcement learning (RL) agents can often\nbe difficult, involving meticulous design of reward functions that are\nsufficiently informative yet easy enough to provide. Human-in-the-loop RL\nmethods allow practitioners to instead interactively teach agents through\ntailored feedback; however, such approaches have been challenging to scale\nsince human feedback is very expensive. In this work, we aim to make this\nprocess more sample- and feedback-efficient. We present an off-policy,\ninteractive RL algorithm that capitalizes on the strengths of both feedback and\noff-policy learning. Specifically, we learn a reward model by actively querying\na teacher's preferences between two clips of behavior and use it to train an\nagent. To enable off-policy learning, we relabel all the agent's past\nexperience when its reward model changes. We additionally show that\npre-training our agents with unsupervised exploration substantially increases\nthe mileage of its queries. We demonstrate that our approach is capable of\nlearning tasks of higher complexity than previously considered by\nhuman-in-the-loop methods, including a variety of locomotion and robotic\nmanipulation skills. We also show that our method is able to utilize real-time\nhuman feedback to effectively prevent reward exploitation and learn new\nbehaviors that are difficult to specify with standard reward functions.",
          "link": "http://arxiv.org/abs/2106.05091",
          "publishedOn": "2021-06-10T01:56:49.610Z",
          "wordCount": 649,
          "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training. (arXiv:2106.05091v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinyu Rachel Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "We describe a new approach to estimating relative risks in time-to-event\nprediction problems with censored data in a fully parametric manner. Our\napproach does not require making strong assumptions of constant proportional\nhazard of the underlying survival distribution, as required by the\nCox-proportional hazard model. By jointly learning deep nonlinear\nrepresentations of the input covariates, we demonstrate the benefits of our\napproach when used to estimate survival risks through extensive experimentation\non multiple real world datasets with different levels of censoring. We further\ndemonstrate advantages of our model in the competing risks scenario. To the\nbest of our knowledge, this is the first work involving fully parametric\nestimation of survival times with competing risks in the presence of censoring.",
          "link": "http://arxiv.org/abs/2003.01176",
          "publishedOn": "2021-06-10T01:56:49.592Z",
          "wordCount": 626,
          "title": "Deep Survival Machines: Fully Parametric Survival Regression and Representation Learning for Censored Data with Competing Risks. (arXiv:2003.01176v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1\">Mijung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinaroz_M/0/1/0/all/0/1\">Margarita Vinaroz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charusaie_M/0/1/0/all/0/1\">Mohammad-Amin Charusaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harder_F/0/1/0/all/0/1\">Frederik Harder</a>",
          "description": "Kernel mean embedding is a useful tool to compare probability measures.\nDespite its usefulness, kernel mean embedding considers infinite-dimensional\nfeatures, which are challenging to handle in the context of differentially\nprivate data generation. A recent work proposes to approximate the kernel mean\nembedding of data distribution using finite-dimensional random features, where\nthe sensitivity of the features becomes analytically tractable. More\nimportantly, this approach significantly reduces the privacy cost, compared to\nother known privatization methods (e.g., DP-SGD), as the approximate kernel\nmean embedding of the data distribution is privatized only once and can then be\nrepeatedly used during training of a generator without incurring any further\nprivacy cost. However, the required number of random features is excessively\nhigh, often ten thousand to a hundred thousand, which worsens the sensitivity\nof the approximate kernel mean embedding. To improve the sensitivity, we\npropose to replace random features with Hermite polynomial features. Unlike the\nrandom features, the Hermite polynomial features are ordered, where the\nfeatures at the low orders contain more information on the distribution than\nthose at the high orders. Hence, a relatively low order of Hermite polynomial\nfeatures can more accurately approximate the mean embedding of the data\ndistribution compared to a significantly higher number of random features. As a\nresult, using the Hermite polynomial features, we significantly improve the\nprivacy-accuracy trade-off, reflected in the high quality and diversity of the\ngenerated data, when tested on several heterogeneous tabular datasets, as well\nas several image benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.05042",
          "publishedOn": "2021-06-10T01:56:49.585Z",
          "wordCount": 679,
          "title": "Polynomial magic! Hermite polynomials for private data generation. (arXiv:2106.05042v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Houfeng Wang</a>",
          "description": "In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the\nonline inference efficiency of the Transformer for instantaneous Grammatical\nError Correction (GEC). SAD optimizes the online inference efficiency for GEC\nby two innovations: 1) it aggressively decodes as many tokens as possible in\nparallel instead of always decoding only one token in each step to improve\ncomputational parallelism; 2) it uses a shallow decoder instead of the\nconventional Transformer architecture with balanced encoder-decoder depth to\nreduce the computational cost during inference. Experiments in both English and\nChinese GEC benchmarks show that aggressive decoding could yield the same\npredictions as greedy decoding but with a significant speedup for online\ninference. Its combination with the shallow decoder could offer an even higher\nonline inference speedup over the powerful Transformer baseline without quality\nloss. Not only does our approach allow a single model to achieve the\nstate-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14\nand 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference\nspeedup over the Transformer-big model, but also it is easily adapted to other\nlanguages. Our code is available at\nhttps://github.com/AutoTemp/Shallow-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2106.04970",
          "publishedOn": "2021-06-10T01:56:49.569Z",
          "wordCount": 627,
          "title": "Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13632",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bodin_E/0/1/0/all/0/1\">Erik Bodin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenwen Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Campbell_N/0/1/0/all/0/1\">Neill D. F. Campbell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ek_C/0/1/0/all/0/1\">Carl Henrik Ek</a>",
          "description": "We present a novel approach to Bayesian inference and general Bayesian\ncomputation that is defined through a sequential decision loop. Our method\ndefines a recursive partitioning of the sample space. It neither relies on\ngradients nor requires any problem-specific tuning, and is asymptotically exact\nfor any density function with a bounded domain. The output is an approximation\nto the whole density function including the normalisation constant, via\npartitions organised in efficient data structures. Such approximations may be\nused for evidence estimation or fast posterior sampling, but also as building\nblocks to treat a larger class of estimation problems. The algorithm shows\ncompetitive performance to recent state-of-the-art methods on synthetic and\nreal-world problems including parameter inference for gravitational-wave\nphysics.",
          "link": "http://arxiv.org/abs/2010.13632",
          "publishedOn": "2021-06-10T01:56:49.562Z",
          "wordCount": 572,
          "title": "Black-box density function estimation using recursive partitioning. (arXiv:2010.13632v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04975",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Qian_Y/0/1/0/all/0/1\">Yang Qian</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1\">Xinbiao Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1\">Yuxuan Du</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1\">Xingyao Wu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "The core of quantum machine learning is to devise quantum models with good\ntrainability and low generalization error bound than their classical\ncounterparts to ensure better reliability and interpretability. Recent studies\nconfirmed that quantum neural networks (QNNs) have the ability to achieve this\ngoal on specific datasets. With this regard, it is of great importance to\nunderstand whether these advantages are still preserved on real-world tasks.\nThrough systematic numerical experiments, we empirically observe that current\nQNNs fail to provide any benefit over classical learning models. Concretely,\nour results deliver two key messages. First, QNNs suffer from the severely\nlimited effective model capacity, which incurs poor generalization on\nreal-world datasets. Second, the trainability of QNNs is insensitive to\nregularization techniques, which sharply contrasts with the classical scenario.\nThese empirical results force us to rethink the role of current QNNs and to\ndesign novel protocols for solving real-world problems with quantum advantages.",
          "link": "http://arxiv.org/abs/2106.04975",
          "publishedOn": "2021-06-10T01:56:49.556Z",
          "wordCount": 574,
          "title": "The dilemma of quantum neural networks. (arXiv:2106.04975v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1\">Lele Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Distilling analytical models from data has the potential to advance our\nunderstanding and prediction of nonlinear dynamics. Although discovery of\ngoverning equations based on observed system states (e.g., trajectory time\nseries) has revealed success in a wide range of nonlinear dynamics, uncovering\nthe closed-form equations directly from raw videos still remains an open\nchallenge. To this end, we introduce a novel end-to-end unsupervised deep\nlearning framework to uncover the mathematical structure of equations that\ngoverns the dynamics of moving objects in videos. Such an architecture consists\nof (1) an encoder-decoder network that learns low-dimensional spatial/pixel\ncoordinates of the moving object, (2) a learnable Spatial-Physical\nTransformation component that creates mapping between the extracted\nspatial/pixel coordinates and the latent physical states of dynamics, and (3) a\nnumerical integrator-based sparse regression module that uncovers the\nparsimonious closed-form governing equations of learned physical states and,\nmeanwhile, serves as a constraint to the autoencoder. The efficacy of the\nproposed method is demonstrated by uncovering the governing equations of a\nvariety of nonlinear dynamical systems depicted by moving objects in videos.\nThe resulting computational framework enables discovery of parsimonious\ninterpretable model in a flexible and accessible sensing environment where only\nvideos are available.",
          "link": "http://arxiv.org/abs/2106.04776",
          "publishedOn": "2021-06-10T01:56:49.550Z",
          "wordCount": 635,
          "title": "Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celikkanat_A/0/1/0/all/0/1\">Abdulkadir Celikkanat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanning Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1\">Fragkiskos D. Malliaros</a>",
          "description": "Learning representations of nodes in a low dimensional space is a crucial\ntask with numerous interesting applications in network analysis, including link\nprediction, node classification, and visualization. Two popular approaches for\nthis problem are matrix factorization and random walk-based models. In this\npaper, we aim to bring together the best of both worlds, towards learning node\nrepresentations. In particular, we propose a weighted matrix factorization\nmodel that encodes random walk-based information about nodes of the network.\nThe benefit of this novel formulation is that it enables us to utilize kernel\nfunctions without realizing the exact proximity matrix so that it enhances the\nexpressiveness of existing matrix decomposition methods with kernels and\nalleviates their computational complexities. We extend the approach with a\nmultiple kernel learning formulation that provides the flexibility of learning\nthe kernel as the linear combination of a dictionary of kernels in data-driven\nfashion. We perform an empirical evaluation on real-world networks, showing\nthat the proposed model outperforms baseline node embedding algorithms in\ndownstream machine learning tasks.",
          "link": "http://arxiv.org/abs/2106.05057",
          "publishedOn": "2021-06-10T01:56:49.528Z",
          "wordCount": 618,
          "title": "Multiple Kernel Representation Learning on Networks. (arXiv:2106.05057v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04088",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1\">Avishek Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chung_J/0/1/0/all/0/1\">Jichan Chung</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yin_D/0/1/0/all/0/1\">Dong Yin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>",
          "description": "We address the problem of federated learning (FL) where users are distributed\nand partitioned into clusters. This setup captures settings where different\ngroups of users have their own objectives (learning tasks) but by aggregating\ntheir data with others in the same cluster (same learning task), they can\nleverage the strength in numbers in order to perform more efficient federated\nlearning. For this new framework of clustered federated learning, we propose\nthe Iterative Federated Clustering Algorithm (IFCA), which alternately\nestimates the cluster identities of the users and optimizes model parameters\nfor the user clusters via gradient descent. We analyze the convergence rate of\nthis algorithm first in a linear model with squared loss and then for generic\nstrongly convex and smooth loss functions. We show that in both settings, with\ngood initialization, IFCA is guaranteed to converge, and discuss the optimality\nof the statistical error rate. In particular, for the linear model with two\nclusters, we can guarantee that our algorithm converges as long as the\ninitialization is slightly better than random. When the clustering structure is\nambiguous, we propose to train the models by combining IFCA with the weight\nsharing technique in multi-task learning. In the experiments, we show that our\nalgorithm can succeed even if we relax the requirements on initialization with\nrandom initialization and multiple restarts. We also present experimental\nresults showing that our algorithm is efficient in non-convex problems such as\nneural networks. We demonstrate the benefits of IFCA over the baselines on\nseveral clustered FL benchmarks.",
          "link": "http://arxiv.org/abs/2006.04088",
          "publishedOn": "2021-06-10T01:56:49.522Z",
          "wordCount": 700,
          "title": "An Efficient Framework for Clustered Federated Learning. (arXiv:2006.04088v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1\">Ida Momennejad</a>",
          "description": "Consider a prosthetic arm, learning to adapt to its user's control signals.\nWe propose Interaction-Grounded Learning for this novel setting, in which a\nlearner's goal is to interact with the environment with no grounding or\nexplicit reward to optimize its policies. Such a problem evades common RL\nsolutions which require an explicit reward. The learning agent observes a\nmultidimensional context vector, takes an action, and then observes a\nmultidimensional feedback vector. This multidimensional feedback vector has no\nexplicit reward information. In order to succeed, the algorithm must learn how\nto evaluate the feedback vector to discover a latent reward signal, with which\nit can ground its policies without supervision. We show that in an\nInteraction-Grounded Learning setting, with certain natural assumptions, a\nlearner can discover the latent reward and ground its policy for successful\ninteraction. We provide theoretical guarantees and a proof-of-concept empirical\nevaluation to demonstrate the effectiveness of our proposed approach.",
          "link": "http://arxiv.org/abs/2106.04887",
          "publishedOn": "2021-06-10T01:56:49.517Z",
          "wordCount": 578,
          "title": "Interaction-Grounded Learning. (arXiv:2106.04887v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Folke_T/0/1/0/all/0/1\">Tomas Folke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Scott Cheng-Hsin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_S/0/1/0/all/0/1\">Sean Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafto_P/0/1/0/all/0/1\">Patrick Shafto</a>",
          "description": "Limited expert time is a key bottleneck in medical imaging. Due to advances\nin image classification, AI can now serve as decision-support for medical\nexperts, with the potential for great gains in radiologist productivity and, by\nextension, public health. However, these gains are contingent on building and\nmaintaining experts' trust in the AI agents. Explainable AI may build such\ntrust by helping medical experts to understand the AI decision processes behind\ndiagnostic judgements. Here we introduce and evaluate explanations based on\nBayesian Teaching, a formal account of explanation rooted in the cognitive\nscience of human learning. We find that medical experts exposed to explanations\ngenerated by Bayesian Teaching successfully predict the AI's diagnostic\ndecisions and are more likely to certify the AI for cases when the AI is\ncorrect than when it is wrong, indicating appropriate trust. These results show\nthat Explainable AI can be used to support human-AI collaboration in medical\nimaging.",
          "link": "http://arxiv.org/abs/2106.04684",
          "publishedOn": "2021-06-10T01:56:49.506Z",
          "wordCount": 609,
          "title": "Explainable AI for medical imaging: Explaining pneumothorax diagnoses with Bayesian Teaching. (arXiv:2106.04684v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on\ndialog systems and found that improvement on individual components (e.g., NLU,\npolicy) in prior work may not necessarily bring benefit to pipeline systems in\nsystem-wise evaluation. To improve the system-wise performance, in this paper,\nwe propose new joint system-wise optimization techniques for the pipeline\ndialog system. First, we propose a new data augmentation approach which\nautomates the labeling process for NLU training. Second, we propose a novel\nstochastic policy parameterization with Poisson distribution that enables\nbetter exploration and offers a principled way to compute policy gradient.\nThird, we propose a reward bonus to help policy explore successful dialogs. Our\napproaches outperform the competitive pipeline systems from Takanobu et al.\n(2020) by big margins of 12% success rate in automatic system-wise evaluation\nand of 16% success rate in human evaluation on the standard multi-domain\nbenchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art\nend-to-end trained model from DSTC9.",
          "link": "http://arxiv.org/abs/2106.04835",
          "publishedOn": "2021-06-10T01:56:49.489Z",
          "wordCount": 594,
          "title": "Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04881",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1\">George Deligiannidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>",
          "description": "Understanding generalization in deep learning has been one of the major\nchallenges in statistical learning theory over the last decade. While recent\nwork has illustrated that the dataset and the training algorithm must be taken\ninto account in order to obtain meaningful generalization bounds, it is still\ntheoretically not clear which properties of the data and the algorithm\ndetermine the generalization performance. In this study, we approach this\nproblem from a dynamical systems theory perspective and represent stochastic\noptimization algorithms as random iterated function systems (IFS). Well studied\nin the dynamical systems literature, under mild assumptions, such IFSs can be\nshown to be ergodic with an invariant measure that is often supported on sets\nwith a fractal structure. As our main contribution, we prove that the\ngeneralization error of a stochastic optimization algorithm can be bounded\nbased on the `complexity' of the fractal structure that underlies its invariant\nmeasure. Leveraging results from dynamical systems theory, we show that the\ngeneralization error can be explicitly linked to the choice of the algorithm\n(e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g.,\nstep-size, batch-size), and the geometry of the problem (e.g., Hessian of the\nloss). We further specialize our results to specific problems (e.g.,\nlinear/logistic regression, one hidden-layered neural networks) and algorithms\n(e.g., SGD and preconditioned variants), and obtain analytical estimates for\nour bound.For modern neural networks, we develop an efficient algorithm to\ncompute the developed bound and support our theory with various experiments on\nneural networks.",
          "link": "http://arxiv.org/abs/2106.04881",
          "publishedOn": "2021-06-10T01:56:49.483Z",
          "wordCount": 686,
          "title": "Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms. (arXiv:2106.04881v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Putta_S/0/1/0/all/0/1\">Sudeep Raja Putta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Shipra Agrawal</a>",
          "description": "We consider the Scale-Free Adversarial Multi Armed Bandit(MAB) problem, where\nthe player only knows the number of arms $n$ and not the scale or magnitude of\nthe losses. It sees bandit feedback about the loss vectors $l_1,\\dots, l_T \\in\n\\mathbb{R}^n$. The goal is to bound its regret as a function of $n$ and\n$l_1,\\dots, l_T$. We design a Follow The Regularized Leader(FTRL) algorithm,\nwhich comes with the first scale-free regret guarantee for MAB. It uses the log\nbarrier regularizer, the importance weighted estimator, an adaptive learning\nrate, and an adaptive exploration parameter. In the analysis, we introduce a\nsimple, unifying technique for obtaining regret inequalities for FTRL and\nOnline Mirror Descent(OMD) on the probability simplex using Potential Functions\nand Mixed Bregmans. We also develop a new technique for obtaining local-norm\nlower bounds for Bregman Divergences, which are crucial in bandit regret\nbounds. These tools could be of independent interest.",
          "link": "http://arxiv.org/abs/2106.04700",
          "publishedOn": "2021-06-10T01:56:49.478Z",
          "wordCount": 571,
          "title": "Scale Free Adversarial Multi Armed Bandits. (arXiv:2106.04700v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Z/0/1/0/all/0/1\">Zhigang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Feng Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>",
          "description": "Combinatorial Optimization (CO) has been a long-standing challenging research\ntopic featured by its NP-hard nature. Traditionally such problems are\napproximately solved with heuristic algorithms which are usually fast but may\nsacrifice the solution quality. Currently, machine learning for combinatorial\noptimization (MLCO) has become a trending research topic, but most existing\nMLCO methods treat CO as a single-level optimization by directly learning the\nend-to-end solutions, which are hard to scale up and mostly limited by the\ncapacity of ML models given the high complexity of CO. In this paper, we\npropose a hybrid approach to combine the best of the two worlds, in which a\nbi-level framework is developed with an upper-level learning method to optimize\nthe graph (e.g. add, delete or modify edges in a graph), fused with a\nlower-level heuristic algorithm solving on the optimized graph. Such a bi-level\napproach simplifies the learning on the original hard CO and can effectively\nmitigate the demand for model capacity. The experiments and results on several\npopular CO problems like Directed Acyclic Graph scheduling, Graph Edit Distance\nand Hamiltonian Cycle Problem show its effectiveness over manually designed\nheuristics and single-level learning methods.",
          "link": "http://arxiv.org/abs/2106.04927",
          "publishedOn": "2021-06-10T01:56:49.472Z",
          "wordCount": 634,
          "title": "A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs. (arXiv:2106.04927v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1\">Sara Meftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1\">Nasredine Semmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1\">Youssef Tamaazousti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1\">Hassane Essafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1\">Fatiha Sadat</a>",
          "description": "Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.",
          "link": "http://arxiv.org/abs/2106.04935",
          "publishedOn": "2021-06-10T01:56:49.467Z",
          "wordCount": 657,
          "title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1\">Hady Elsahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>",
          "description": "Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.",
          "link": "http://arxiv.org/abs/2106.04985",
          "publishedOn": "2021-06-10T01:56:49.455Z",
          "wordCount": 578,
          "title": "Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jinke He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suau_M/0/1/0/all/0/1\">Miguel Suau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1\">Frans A. Oliehoek</a>",
          "description": "How can we plan efficiently in real time to control an agent in a complex\nenvironment that may involve many other agents? While existing sample-based\nplanners have enjoyed empirical success in large POMDPs, their performance\nheavily relies on a fast simulator. However, real-world scenarios are complex\nin nature and their simulators are often computationally demanding, which\nseverely limits the performance of online planners. In this work, we propose\ninfluence-augmented online planning, a principled method to transform a\nfactored simulator of the entire environment into a local simulator that\nsamples only the state variables that are most relevant to the observation and\nreward of the planning agent and captures the incoming influence from the rest\nof the environment using machine learning methods. Our main experimental\nresults show that planning on this less accurate but much faster local\nsimulator with POMCP leads to higher real-time planning performance than\nplanning on the simulator that models the entire environment.",
          "link": "http://arxiv.org/abs/2010.11038",
          "publishedOn": "2021-06-10T01:56:49.428Z",
          "wordCount": 619,
          "title": "Influence-Augmented Online Planning for Complex Environments. (arXiv:2010.11038v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sanghyun Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alexey Kurakin</a>",
          "description": "Deep neural networks (DNNs), while accurate, are expensive to train. Many\npractitioners, therefore, outsource the training process to third parties or\nuse pre-trained DNNs. This practice makes DNNs vulnerable to $backdoor$\n$attacks$: the third party who trains the model may act maliciously to inject\nhidden behaviors into the otherwise accurate model. Until now, the mechanism to\ninject backdoors has been limited to $poisoning$.\n\nWe argue that such a supply-chain attacker has more attack techniques\navailable. To study this hypothesis, we introduce a handcrafted attack that\ndirectly manipulates the parameters of a pre-trained model to inject backdoors.\nOur handcrafted attacker has more degrees of freedom in manipulating model\nparameters than poisoning. This makes it difficult for a defender to identify\nor remove the manipulations with straightforward methods, such as statistical\nanalysis, adding random noises to model parameters, or clipping their values\nwithin a certain range. Further, our attacker can combine the handcrafting\nprocess with additional techniques, $e.g.$, jointly optimizing a trigger\npattern, to inject backdoors into complex networks effectively$-$the\nmeet-in-the-middle attack.\n\nIn evaluations, our handcrafted backdoors remain effective across four\ndatasets and four network architectures with a success rate above 96%. Our\nbackdoored models are resilient to both parameter-level backdoor removal\ntechniques and can evade existing defenses by slightly changing the backdoor\nattack configurations. Moreover, we demonstrate the feasibility of suppressing\nunwanted behaviors otherwise caused by poisoning. Our results suggest that\nfurther research is needed for understanding the complete space of supply-chain\nbackdoor attacks.",
          "link": "http://arxiv.org/abs/2106.04690",
          "publishedOn": "2021-06-10T01:56:49.413Z",
          "wordCount": 674,
          "title": "Handcrafted Backdoors in Deep Neural Networks. (arXiv:2106.04690v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05010",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Futami_F/0/1/0/all/0/1\">Futoshi Futami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1\">Naonori Ueda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Bayesian model averaging, obtained as the expectation of a likelihood\nfunction by a posterior distribution, has been widely used for prediction,\nevaluation of uncertainty, and model selection. Various approaches have been\ndeveloped to efficiently capture the information in the posterior distribution;\none such approach is the optimization of a set of models simultaneously with\ninteraction to ensure the diversity of the individual models in the same way as\nensemble learning. A representative approach is particle variational inference\n(PVI), which uses an ensemble of models as an empirical approximation for the\nposterior distribution. PVI iteratively updates each model with a repulsion\nforce to ensure the diversity of the optimized models. However, despite its\npromising performance, a theoretical understanding of this repulsion and its\nassociation with the generalization ability remains unclear. In this paper, we\ntackle this problem in light of PAC-Bayesian analysis. First, we provide a new\nsecond-order Jensen inequality, which has the repulsion term based on the loss\nfunction. Thanks to the repulsion term, it is tighter than the standard Jensen\ninequality. Then, we derive a novel generalization error bound and show that it\ncan be reduced by enhancing the diversity of models. Finally, we derive a new\nPVI that optimizes the generalization error bound directly. Numerical\nexperiments demonstrate that the performance of the proposed PVI compares\nfavorably with existing methods in the experiment.",
          "link": "http://arxiv.org/abs/2106.05010",
          "publishedOn": "2021-06-10T01:56:49.406Z",
          "wordCount": 664,
          "title": "Loss function based second-order Jensen inequality and its application to particle variational inference. (arXiv:2106.05010v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1\">Tim Pearce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1\">Alexandra Brintrup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "It is often remarked that neural networks fail to increase their uncertainty\nwhen predicting on data far from the training distribution. Yet naively using\nsoftmax confidence as a proxy for uncertainty achieves modest success in tasks\nexclusively testing for this, e.g., out-of-distribution (OOD) detection. This\npaper investigates this contradiction, identifying two implicit biases that do\nencourage softmax confidence to correlate with epistemic uncertainty: 1)\nApproximately optimal decision boundary structure, and 2) Filtering effects of\ndeep networks. It describes why low-dimensional intuitions about softmax\nconfidence are misleading. Diagnostic experiments quantify reasons softmax\nconfidence can fail, finding that extrapolations are less to blame than overlap\nbetween training and OOD data in final-layer representations.\nPre-trained/fine-tuned networks reduce this overlap.",
          "link": "http://arxiv.org/abs/2106.04972",
          "publishedOn": "2021-06-10T01:56:49.400Z",
          "wordCount": 541,
          "title": "Understanding Softmax Confidence and Uncertainty. (arXiv:2106.04972v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Vianney Perchet</a>",
          "description": "The objective of offline RL is to learn optimal policies when a fixed\nexploratory demonstrations data-set is available and sampling additional\nobservations is impossible (typically if this operation is either costly or\nrises ethical questions). In order to solve this problem, off the shelf\napproaches require a properly defined cost function (or its evaluation on the\nprovided data-set), which are seldom available in practice. To circumvent this\nissue, a reasonable alternative is to query an expert for few optimal\ndemonstrations in addition to the exploratory data-set. The objective is then\nto learn an optimal policy w.r.t. the expert's latent cost function. Current\nsolutions either solve a behaviour cloning problem (which does not leverage the\nexploratory data) or a reinforced imitation learning problem (using a fixed\ncost function that discriminates available exploratory trajectories from expert\nones). Inspired by the success of IRL techniques in achieving state of the art\nimitation performances in online settings, we exploit GAN based data\naugmentation procedures to construct the first offline IRL algorithm. The\nobtained policies outperformed the aforementioned solutions on multiple OpenAI\ngym environments.",
          "link": "http://arxiv.org/abs/2106.05068",
          "publishedOn": "2021-06-10T01:56:49.393Z",
          "wordCount": 591,
          "title": "Offline Inverse Reinforcement Learning. (arXiv:2106.05068v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "A central challenge in training classification models in the real-world\nfederated system is learning with non-IID data. To cope with this, most of the\nexisting works involve enforcing regularization in local optimization or\nimproving the model aggregation scheme at the server. Other works also share\npublic datasets or synthesized samples to supplement the training of\nunder-represented classes or introduce a certain level of personalization.\nThough effective, they lack a deep understanding of how the data heterogeneity\naffects each layer of a deep classification model. In this paper, we bridge\nthis gap by performing an experimental analysis of the representations learned\nby different layers. Our observations are surprising: (1) there exists a\ngreater bias in the classifier than other layers, and (2) the classification\nperformance can be significantly improved by post-calibrating the classifier\nafter federated training. Motivated by the above findings, we propose a novel\nand simple algorithm called Classifier Calibration with Virtual Representations\n(CCVR), which adjusts the classifier using virtual representations sampled from\nan approximated gaussian mixture model. Experimental results demonstrate that\nCCVR achieves state-of-the-art performance on popular federated learning\nbenchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple\nyet effective method can shed some light on the future research of federated\nlearning with non-IID data.",
          "link": "http://arxiv.org/abs/2106.05001",
          "publishedOn": "2021-06-10T01:56:49.387Z",
          "wordCount": 666,
          "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Proper initialization is crucial to the optimization and the generalization\nof neural networks. However, most existing neural recommendation systems\ninitialize the user and item embeddings randomly. In this work, we propose a\nnew initialization scheme for user and item embeddings called Laplacian\nEigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).\nLEPORID endows the embeddings with information regarding multi-scale\nneighborhood structures on the data manifold and performs adaptive\nregularization to compensate for high embedding variance on the tail of the\ndata distribution. Exploiting matrix sparsity, LEPORID embeddings can be\ncomputed efficiently. We evaluate LEPORID in a wide range of neural\nrecommendation models. In contrast to the recent surprising finding that the\nsimple K-nearest-neighbor (KNN) method often outperforms neural recommendation\nsystems, we show that existing neural systems initialized with LEPORID often\nperform on par or better than KNN. To maximize the effects of the\ninitialization, we propose the Dual-Loss Residual Recommendation (DLR2)\nnetwork, which, when initialized with LEPORID, substantially outperforms both\ntraditional and state-of-the-art neural recommender systems.",
          "link": "http://arxiv.org/abs/2106.04993",
          "publishedOn": "2021-06-10T01:56:49.382Z",
          "wordCount": 597,
          "title": "Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1\">Shashanka Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1\">Bill Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1\">Ewa Kijak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1\">Laurent Amsaleg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1\">Konstantinos Karantzalos</a>",
          "description": "Metric learning involves learning a discriminative representation such that\nembeddings of similar classes are encouraged to be close, while embeddings of\ndissimilar classes are pushed far apart. State-of-the-art methods focus mostly\non sophisticated loss functions or mining strategies. On the one hand, metric\nlearning losses consider two or more examples at a time. On the other hand,\nmodern data augmentation methods for classification consider two or more\nexamples at a time. The combination of the two ideas is under-studied.\n\nIn this work, we aim to bridge this gap and improve representations using\nmixup, which is a powerful data augmentation approach interpolating two or more\nexamples and corresponding target labels at a time. This task is challenging\nbecause, unlike classification, the loss functions used in metric learning are\nnot additive over examples, so the idea of interpolating target labels is not\nstraightforward. To the best of our knowledge, we are the first to investigate\nmixing examples and target labels for deep metric learning. We develop a\ngeneralized formulation that encompasses existing metric learning loss\nfunctions and modify it to accommodate for mixup, introducing Metric Mix, or\nMetrix. We show that mixing inputs, intermediate representations or embeddings\nalong with target labels significantly improves representations and outperforms\nstate-of-the-art metric learning methods on four benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.04990",
          "publishedOn": "2021-06-10T01:56:49.375Z",
          "wordCount": 651,
          "title": "It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menghan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Tien-Tsin Wong</a>",
          "description": "As a generic modeling tool, Convolutional Neural Networks (CNNs) have been\nwidely employed in image generation and translation tasks. However, when fed\nwith a flat input, current CNN models may fail to generate vivid results due to\nthe spatially shared convolution kernels. We call it the flatness degradation\nof CNNs. Unfortunately, such degradation is the greatest obstacles to generate\na spatially-variant output from a flat input, which has been barely discussed\nin the previous literature. To tackle this problem, we propose a model agnostic\nsolution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in\nfor any CNN generation model. The key idea is to break the flat input condition\nwhile keeping the intactness of the original information. Specifically, the NIB\nperturbs the input data symmetrically with a noise map and reassembles them in\nthe feature domain as driven by the objective function. Extensive experiments\nshow that existing CNN models equipped with NIB survive from the flatness\ndegradation and are able to generate visually better results with richer\ndetails in some specific image generation tasks given flat inputs, e.g.\nsemantic image synthesis, data-hidden image generation, and deep neural\ndithering.",
          "link": "http://arxiv.org/abs/2012.12109",
          "publishedOn": "2021-06-10T01:56:49.370Z",
          "wordCount": 650,
          "title": "Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1\">Stefanos Laskaridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouris_A/0/1/0/all/0/1\">Alexandros Kouris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "DNNs are becoming less and less over-parametrised due to recent advances in\nefficient model design, through careful hand-crafted or NAS-based methods.\nRelying on the fact that not all inputs require the same amount of computation\nto yield a confident prediction, adaptive inference is gaining attention as a\nprominent approach for pushing the limits of efficient deployment.\nParticularly, early-exit networks comprise an emerging direction for tailoring\nthe computation depth of each input sample at runtime, offering complementary\nperformance gains to other efficiency optimisations. In this paper, we\ndecompose the design methodology of early-exit networks to its key components\nand survey the recent advances in each one of them. We also position\nearly-exiting against other efficient inference solutions and provide our\ninsights on the current challenges and most promising future directions for\nresearch in the field.",
          "link": "http://arxiv.org/abs/2106.05022",
          "publishedOn": "2021-06-10T01:56:49.352Z",
          "wordCount": 577,
          "title": "Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions. (arXiv:2106.05022v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1\">Matthew Fellows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1\">Kristian Hartikainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We introduce a novel perspective on Bayesian reinforcement learning (RL);\nwhereas existing approaches infer a posterior over the transition distribution\nor Q-function, we characterise the uncertainty in the Bellman operator. Our\nBayesian Bellman operator (BBO) framework is motivated by the insight that when\nbootstrapping is introduced, model-free approaches actually infer a posterior\nover Bellman operators, not value functions. In this paper, we use BBO to\nprovide a rigorous theoretical analysis of model-free Bayesian RL to better\nunderstand its relationshipto established frequentist RL methodologies. We\nprove that Bayesian solutions are consistent with frequentist RL solutions,\neven when approximate inference isused, and derive conditions for which\nconvergence properties hold. Empirically, we demonstrate that algorithms\nderived from the BBO framework have sophisticated deep exploration properties\nthat enable them to solve continuous control tasks at which state-of-the-art\nregularised actor-critic algorithms fail catastrophically",
          "link": "http://arxiv.org/abs/2106.05012",
          "publishedOn": "2021-06-10T01:56:49.342Z",
          "wordCount": 550,
          "title": "Bayesian Bellman Operators. (arXiv:2106.05012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqing Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1\">Jiansheng Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwu Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1\">Risa Higashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiang Liu</a>",
          "description": "Cataract is one of the leading causes of reversible visual impairment and\nblindness globally. Over the years, researchers have achieved significant\nprogress in developing state-of-the-art artificial intelligence techniques for\nautomatic cataract classification and grading, helping clinicians prevent and\ntreat cataract in time. This paper provides a comprehensive survey of recent\nadvances in machine learning for cataract classification and grading based on\nophthalmic images. We summarize existing literature from two research\ndirections: conventional machine learning techniques and deep learning\ntechniques. This paper also provides insights into existing works of both\nmerits and limitations. In addition, we discuss several challenges of automatic\ncataract classification and grading based on machine learning techniques and\npresent possible solutions to these challenges for future research.",
          "link": "http://arxiv.org/abs/2012.04830",
          "publishedOn": "2021-06-10T01:56:49.317Z",
          "wordCount": 597,
          "title": "Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1\">Relja Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "Neural radiance fields (NeRF) methods have demonstrated impressive novel view\nsynthesis performance. The core approach is to render individual rays by\nquerying a neural network at points sampled along the ray to obtain the density\nand colour of the sampled points, and integrating this information using the\nrendering equation. Since dense sampling is computationally prohibitive, a\ncommon solution is to perform coarse-to-fine sampling.\n\nIn this work we address a clear limitation of the vanilla coarse-to-fine\napproach -- that it is based on a heuristic and not trained end-to-end for the\ntask at hand. We introduce a differentiable module that learns to propose\nsamples and their importance for the fine network, and consider and compare\nmultiple alternatives for its neural architecture. Training the proposal module\nfrom scratch can be unstable due to lack of supervision, so an effective\npre-training strategy is also put forward. The approach, named `NeRF in detail'\n(NeRF-ID), achieves superior view synthesis quality over NeRF and the\nstate-of-the-art on the synthetic Blender benchmark and on par or better\nperformance on the real LLFF-NeRF scenes. Furthermore, by leveraging the\npredicted sample importance, a 25% saving in computation can be achieved\nwithout significantly sacrificing the rendering quality.",
          "link": "http://arxiv.org/abs/2106.05264",
          "publishedOn": "2021-06-10T01:56:49.293Z",
          "wordCount": 632,
          "title": "NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozdayi_M/0/1/0/all/0/1\">Mustafa Safa Ozdayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1\">Murat Kantarcioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Prior studies have shown that, training machine learning models via empirical\nloss minimization to maximize a utility metric (e.g., accuracy), might yield\nmodels that make discriminatory predictions. To alleviate this issue, we\ndevelop a new training algorithm, named BiFair, which jointly minimizes for a\nutility, and a fairness loss of interest. Crucially, we do so without directly\nmodifying the training objective, e.g., by adding regularization terms. Rather,\nwe learn a set of weights on the training dataset, such that, training on the\nweighted dataset ensures both good utility, and fairness. The dataset weights\nare learned in concurrence to the model training, which is done by solving a\nbilevel optimization problem using a held-out validation dataset. Overall, this\napproach yields models with better fairness-utility trade-offs. Particularly,\nwe compare our algorithm with three other state-of-the-art fair training\nalgorithms over three real-world datasets, and demonstrate that, BiFair\nconsistently performs better, i.e., we reach to better values of a given\nfairness metric under same, or higher accuracy. Further, our algorithm is\nscalable. It is applicable both to simple models, such as logistic regression,\nas well as more complex models, such as deep neural networks, as evidenced by\nour experimental analysis.",
          "link": "http://arxiv.org/abs/2106.04757",
          "publishedOn": "2021-06-10T01:56:49.114Z",
          "wordCount": 621,
          "title": "BiFair: Training Fair Models with Bilevel Optimization. (arXiv:2106.04757v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>",
          "description": "Overparametrized neural networks, where the number of active parameters is\nlarger than the sample size, prove remarkably effective in modern deep learning\npractice. From the classical perspective, however, much fewer parameters are\nsufficient for optimal estimation and prediction, whereas overparametrization\ncan be harmful even in the presence of explicit regularization. To reconcile\nthis conflict, we present a generalization theory for overparametrized ReLU\nnetworks by incorporating an explicit regularizer based on the scaled variation\nnorm. Interestingly, this regularizer is equivalent to the ridge from the angle\nof gradient-based optimization, but is similar to the group lasso in terms of\ncontrolling model complexity. By exploiting this ridge-lasso duality, we show\nthat overparametrization is generally harmless to two-layer ReLU networks. In\nparticular, the overparametrized estimators are minimax optimal up to a\nlogarithmic factor. By contrast, we show that overparametrized random feature\nmodels suffer from the curse of dimensionality and thus are suboptimal.",
          "link": "http://arxiv.org/abs/2106.04795",
          "publishedOn": "2021-06-10T01:56:49.108Z",
          "wordCount": 581,
          "title": "Harmless Overparametrization in Two-layer Neural Networks. (arXiv:2106.04795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spiridonoff_A/0/1/0/all/0/1\">Artin Spiridonoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olshevsky_A/0/1/0/all/0/1\">Alex Olshevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We consider speeding up stochastic gradient descent (SGD) by parallelizing it\nacross multiple workers. We assume the same data set is shared among $N$\nworkers, who can take SGD steps and coordinate with a central server. While it\nis possible to obtain a linear reduction in the variance by averaging all the\nstochastic gradients at every step, this requires a lot of communication\nbetween the workers and the server, which can dramatically reduce the gains\nfrom parallelism. The Local SGD method, proposed and analyzed in the earlier\nliterature, suggests machines should make many local steps between such\ncommunications. While the initial analysis of Local SGD showed it needs $\\Omega\n( \\sqrt{T} )$ communications for $T$ local gradient steps in order for the\nerror to scale proportionately to $1/(NT)$, this has been successively improved\nin a string of papers, with the state-of-the-art requiring $\\Omega \\left( N\n\\left( \\mbox{ polynomial in log } (T) \\right) \\right)$ communications. In this\npaper, we suggest a Local SGD scheme that communicates less overall by\ncommunicating less frequently as the number of iterations grows. Our analysis\nshows that this can achieve an error that scales as $1/(NT)$ with a number of\ncommunications that is completely independent of $T$. In particular, we show\nthat $\\Omega(N)$ communications are sufficient. Empirical evidence suggests\nthis bound is close to tight as we further show that $\\sqrt{N}$ or $N^{3/4}$\ncommunications fail to achieve linear speed-up in simulations. Moreover, we\nshow that under mild assumptions, the main of which is twice differentiability\non any neighborhood of the optimal solution, one-shot averaging which only uses\na single round of communication can also achieve the optimal convergence rate\nasymptotically.",
          "link": "http://arxiv.org/abs/2106.04759",
          "publishedOn": "2021-06-10T01:56:49.103Z",
          "wordCount": 723,
          "title": "Communication-efficient SGD: From Local SGD to One-Shot Averaging. (arXiv:2106.04759v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zengfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengzhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chong Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Min Zhou</a>",
          "description": "Scalability of graph neural networks remains one of the major challenges in\ngraph machine learning. Since the representation of a node is computed by\nrecursively aggregating and transforming representation vectors of its\nneighboring nodes from previous layers, the receptive fields grow\nexponentially, which makes standard stochastic optimization techniques\nineffective. Various approaches have been proposed to alleviate this issue,\ne.g., sampling-based methods and techniques based on pre-computation of graph\nfilters.\n\nIn this paper, we take a different approach and propose to use graph\ncoarsening for scalable training of GNNs, which is generic, extremely simple\nand has sublinear memory and time costs during training. We present extensive\ntheoretical analysis on the effect of using coarsening operations and provides\nuseful guidance on the choice of coarsening methods. Interestingly, our\ntheoretical analysis shows that coarsening can also be considered as a type of\nregularization and may improve the generalization. Finally, empirical results\non real world datasets show that, simply applying off-the-shelf coarsening\nmethods, we can reduce the number of nodes by up to a factor of ten without\ncausing a noticeable downgrade in classification accuracy.",
          "link": "http://arxiv.org/abs/2106.05150",
          "publishedOn": "2021-06-10T01:56:49.048Z",
          "wordCount": 616,
          "title": "Scaling Up Graph Neural Networks Via Graph Coarsening. (arXiv:2106.05150v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.03957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geneva_N/0/1/0/all/0/1\">Nicholas Geneva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabaras_N/0/1/0/all/0/1\">Nicholas Zabaras</a>",
          "description": "Transformers are widely used in natural language processing due to their\nability to model longer-term dependencies in text. Although these models\nachieve state-of-the-art performance for many language related tasks, their\napplicability outside of the natural language processing field has been\nminimal. In this work, we propose the use of transformer models for the\nprediction of dynamical systems representative of physical phenomena. The use\nof Koopman based embeddings provide a unique and powerful method for projecting\nany dynamical system into a vector representation which can then be predicted\nby a transformer model. The proposed model is able to accurately predict\nvarious dynamical systems and outperform classical methods that are commonly\nused in the scientific machine learning literature.",
          "link": "http://arxiv.org/abs/2010.03957",
          "publishedOn": "2021-06-10T01:56:49.042Z",
          "wordCount": 596,
          "title": "Transformers for Modeling Physical Systems. (arXiv:2010.03957v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sontakke_S/0/1/0/all/0/1\">Sumedh A. Sontakke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1\">Arash Mehrjou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1\">Laurent Itti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Animals exhibit an innate ability to learn regularities of the world through\ninteraction. By performing experiments in their environment, they are able to\ndiscern the causal factors of variation and infer how they affect the world's\ndynamics. Inspired by this, we attempt to equip reinforcement learning agents\nwith the ability to perform experiments that facilitate a categorization of the\nrolled-out trajectories, and to subsequently infer the causal factors of the\nenvironment in a hierarchical manner. We introduce {\\em causal curiosity}, a\nnovel intrinsic reward, and show that it allows our agents to learn optimal\nsequences of actions and discover causal factors in the dynamics of the\nenvironment. The learned behavior allows the agents to infer a binary quantized\nrepresentation for the ground-truth causal factors in every environment.\nAdditionally, we find that these experimental behaviors are semantically\nmeaningful (e.g., our agents learn to lift blocks to categorize them by\nweight), and are learnt in a self-supervised manner with approximately 2.5\ntimes less data than conventional supervised planners. We show that these\nbehaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or\nother downstream tasks). Finally, we show that the knowledge of causal factor\nrepresentations aids zero-shot learning for more complex tasks. Visit\nhttps://sites.google.com/usc.edu/causal-curiosity/home for website.",
          "link": "http://arxiv.org/abs/2010.03110",
          "publishedOn": "2021-06-10T01:56:49.034Z",
          "wordCount": 691,
          "title": "Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning. (arXiv:2010.03110v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1\">Jesse A. Livezey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1\">Ahyeon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jacob Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1\">Kristofer E. Bouchard</a>",
          "description": "Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.",
          "link": "http://arxiv.org/abs/1905.13308",
          "publishedOn": "2021-06-10T01:56:49.028Z",
          "wordCount": 732,
          "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yanchao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Ruijie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yongyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>",
          "description": "Evaluating the worst-case performance of a reinforcement learning (RL) agent\nunder the strongest/optimal adversarial perturbations on state observations\n(within some constraints) is crucial for understanding the robustness of RL\nagents. However, finding the optimal adversary is challenging, in terms of both\nwhether we can find the optimal attack and how efficiently we can find it.\nExisting works on adversarial RL either use heuristics-based methods that may\nnot find the strongest adversary, or directly train an RL-based adversary by\ntreating the agent as a part of the environment, which can find the optimal\nadversary but may become intractable in a large state space. In this paper, we\npropose a novel attacking algorithm which has an RL-based \"director\" searching\nfor the optimal policy perturbation, and an \"actor\" crafting state\nperturbations following the directions from the director (i.e. the actor\nexecutes targeted attacks). Our proposed algorithm, PA-AD, is theoretically\noptimal against an RL agent and significantly improves the efficiency compared\nwith prior RL-based works in environments with large or pixel state spaces.\nEmpirical results show that our proposed PA-AD universally outperforms\nstate-of-the-art attacking methods in a wide range of environments. Our method\ncan be easily applied to any RL algorithms to evaluate and improve their\nrobustness.",
          "link": "http://arxiv.org/abs/2106.05087",
          "publishedOn": "2021-06-10T01:56:49.022Z",
          "wordCount": null,
          "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL. (arXiv:2106.05087v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.10259",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wei_X/0/1/0/all/0/1\">Xue-Xin Wei</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Understanding how grid cells perform path integration calculations remains a\nfundamental problem. In this paper, we conduct theoretical analysis of a\ngeneral representation model of path integration by grid cells, where the 2D\nself-position is encoded as a higher dimensional vector, and the 2D self-motion\nis represented by a general transformation of the vector. We identify two\nconditions on the transformation. One is a group representation condition that\nis necessary for path integration. The other is an isotropic scaling condition\nthat ensures locally conformal embedding, so that the error in the vector\nrepresentation translates proportionally to the error in the 2D self-position.\nThen we investigate the simplest transformation, i.e., the linear\ntransformation, uncover its explicit algebraic and geometric structure as\nmatrix Lie group of rotation, and establish the connection between the\nisotropic scaling condition and hexagon grid patterns of grid cells under the\nlinear transformation. Finally, with our optimization-based approach, we manage\nto learn hexagon grid patterns that share similar properties of the grid cells\nin the rodent brain. The learned model is capable of accurate long distance\npath integration.",
          "link": "http://arxiv.org/abs/2006.10259",
          "publishedOn": "2021-06-10T01:56:49.022Z",
          "wordCount": null,
          "title": "On Path Integration of Grid Cells: Group Representation and Isotropic Scaling. (arXiv:2006.10259v5 [q-bio.NC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1804.06679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kairen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.",
          "link": "http://arxiv.org/abs/1804.06679",
          "publishedOn": "2021-06-10T01:56:49.008Z",
          "wordCount": 698,
          "title": "Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.00009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyuan Li</a>",
          "description": "Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.",
          "link": "http://arxiv.org/abs/1912.00009",
          "publishedOn": "2021-06-10T01:56:48.992Z",
          "wordCount": 606,
          "title": "MSTDP: A More Biologically Plausible Learning. (arXiv:1912.00009v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Boxi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Heng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jindong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "It is well known that adversarial attacks can fool deep neural networks with\nimperceptible perturbations. Although adversarial training significantly\nimproves model robustness, failure cases of defense still broadly exist. In\nthis work, we find that the adversarial attacks can also be vulnerable to small\nperturbations. Namely, on adversarially-trained models, perturbing adversarial\nexamples with a small random noise may invalidate their misled predictions.\nAfter carefully examining state-of-the-art attacks of various kinds, we find\nthat all these attacks have this deficiency to different extents. Enlightened\nby this finding, we propose to counter attacks by crafting more effective\ndefensive perturbations. Our defensive perturbations leverage the advantage\nthat adversarial training endows the ground-truth class with smaller local\nLipschitzness. By simultaneously attacking all the classes, the misled\npredictions with larger Lipschitzness can be flipped into correct ones. We\nverify our defensive perturbation with both empirical experiments and\ntheoretical analyses on a linear model. On CIFAR10, it boosts the\nstate-of-the-art model from 66.16% to 72.66% against the four attacks of\nAutoAttack, including 71.76% to 83.30% against the Square attack. On ImageNet,\nthe top-1 robust accuracy of FastAT is improved from 33.18% to 38.54% under the\n100-step PGD attack.",
          "link": "http://arxiv.org/abs/2106.04938",
          "publishedOn": "2021-06-10T01:56:48.984Z",
          "wordCount": 627,
          "title": "Attacking Adversarial Attacks as A Defense. (arXiv:2106.04938v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1\">Caglar Demir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1\">Axel-Cyrille Ngonga Ngomo</a>",
          "description": "In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.",
          "link": "http://arxiv.org/abs/2008.03130",
          "publishedOn": "2021-06-10T01:56:48.979Z",
          "wordCount": 587,
          "title": "Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1\">Maxwell Horton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1\">Carlos Guestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>",
          "description": "Recent observations have advanced our understanding of the neural network\noptimization landscape, revealing the existence of (1) paths of high accuracy\ncontaining diverse solutions and (2) wider minima offering improved\nperformance. Previous methods observing diverse paths require multiple training\nruns. In contrast we aim to leverage both property (1) and (2) with a single\nmethod and in a single training run. With a similar computational cost as\ntraining one model, we learn lines, curves, and simplexes of high-accuracy\nneural networks. These neural network subspaces contain diverse solutions that\ncan be ensembled, approaching the ensemble performance of independently trained\nnetworks without the training cost. Moreover, using the subspace midpoint\nboosts accuracy, calibration, and robustness to label noise, outperforming\nStochastic Weight Averaging.",
          "link": "http://arxiv.org/abs/2102.10472",
          "publishedOn": "2021-06-10T01:56:48.969Z",
          "wordCount": null,
          "title": "Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1\">Narjes Nikzad-Khasmakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1\">Meysam Asgari-Chenaghlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1\">Mohammad-Ali Balafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1\">Ali-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1\">Taymaz Rahkar-Farshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Majid Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1\">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1\">Elnaz Zafarani-Moattar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar-Khadivi</a>",
          "description": "Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n\nMethods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n\nResults: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n\nConclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.",
          "link": "http://arxiv.org/abs/2106.04939",
          "publishedOn": "2021-06-10T01:56:48.967Z",
          "wordCount": null,
          "title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05200",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stimper_V/0/1/0/all/0/1\">Vincent Stimper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>",
          "description": "Independent component analysis provides a principled framework for\nunsupervised representation learning, with solid theory on the identifiability\nof the latent code that generated the data, given only observations of mixtures\nthereof. Unfortunately, when the mixing is nonlinear, the model is provably\nnonidentifiable, since statistical independence alone does not sufficiently\nconstrain the problem. Identifiability can be recovered in settings where\nadditional, typically observed variables are included in the generative\nprocess. We investigate an alternative path and consider instead including\nassumptions reflecting the principle of independent causal mechanisms exploited\nin the field of causality. Specifically, our approach is motivated by thinking\nof each source as independently influencing the mixing process. This gives rise\nto a framework which we term independent mechanism analysis. We provide\ntheoretical and empirical evidence that our approach circumvents a number of\nnonidentifiability issues arising in nonlinear blind source separation.",
          "link": "http://arxiv.org/abs/2106.05200",
          "publishedOn": "2021-06-10T01:56:48.966Z",
          "wordCount": null,
          "title": "Independent mechanism analysis, a new concept?. (arXiv:2106.05200v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wah_S/0/1/0/all/0/1\">Sebastien Wah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spielberg_A/0/1/0/all/0/1\">Andrew Spielberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>",
          "description": "We present a novel, fast differentiable simulator for soft-body learning and\ncontrol applications. Existing differentiable soft-body simulators can be\nclassified into two categories based on their time integration methods:\nSimulators using explicit time-stepping scheme require tiny time steps to avoid\nnumerical instabilities in gradient computation, and simulators using implicit\ntime integration typically compute gradients by employing the adjoint method\nand solving the expensive linearized dynamics. Inspired by Projective Dynamics\n(PD), we present Differentiable Projective Dynamics (DiffPD), an efficient\ndifferentiable soft-body simulator based on PD with implicit time integration.\nThe key idea in DiffPD is to speed up backpropagation by exploiting the\nprefactorized Cholesky decomposition in forward PD simulation. In terms of\ncontact handling, DiffPD supports two types of contacts: a penalty-based model\ndescribing contact and friction forces and a complementarity-based model\nenforcing non-penetration conditions and static friction. We evaluate the\nperformance of DiffPD and observe it is 4-19 times faster compared to the\nstandard Newton's method in various applications including system\nidentification, inverse design problems, trajectory optimization, and\nclosed-loop control. We also apply DiffPD in a real-to-sim example with contact\nand collisions and show its capability of reconstructing a digital twin of\nreal-world scenes.",
          "link": "http://arxiv.org/abs/2101.05917",
          "publishedOn": "2021-06-10T01:56:48.966Z",
          "wordCount": null,
          "title": "DiffPD: Differentiable Projective Dynamics. (arXiv:2101.05917v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tamali Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>",
          "description": "Recent advances in Unsupervised Neural Machine Translation (UNMT) have\nminimized the gap between supervised and unsupervised machine translation\nperformance for closely related language pairs. However, the situation is very\ndifferent for distant language pairs. Lack of lexical overlap and low syntactic\nsimilarities such as between English and Indo-Aryan languages leads to poor\ntranslation quality in existing UNMT systems. In this paper, we show that\ninitializing the embedding layer of UNMT models with cross-lingual embeddings\nshows significant improvements in BLEU score over existing approaches with\nembeddings randomly initialized. Further, static embeddings (freezing the\nembedding layer weights) lead to better gains compared to updating the\nembedding layer weights during training (non-static). We experimented using\nMasked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT\napproaches for three distant language pairs. The proposed cross-lingual\nembedding initialization yields BLEU score improvement of as much as ten times\nover the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our\nanalysis shows the importance of cross-lingual embedding, comparisons between\napproaches, and the scope of improvements in these systems.",
          "link": "http://arxiv.org/abs/2106.04995",
          "publishedOn": "2021-06-10T01:56:48.964Z",
          "wordCount": null,
          "title": "Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1\">Hangtian Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yujing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhipeng Hu</a>",
          "description": "Measuring and promoting policy diversity is critical for solving games with\nstrong non-transitive dynamics where strategic cycles exist, and there is no\nconsistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a\npool of diverse policies via open-ended learning is an attractive solution,\nwhich can generate auto-curricula to avoid being exploited. However, in\nconventional open-ended learning algorithms, there are no widely accepted\ndefinitions for diversity, making it hard to construct and evaluate the diverse\npolicies. In this work, we summarize previous concepts of diversity and work\ntowards offering a unified measure of diversity in multi-agent open-ended\nlearning to include all elements in Markov games, based on both Behavioral\nDiversity (BD) and Response Diversity (RD). At the trajectory distribution\nlevel, we re-define BD in the state-action space as the discrepancies of\noccupancy measures. For the reward dynamics, we propose RD to characterize\ndiversity through the responses of policies when encountering different\nopponents. We also show that many current diversity measures fall in one of the\ncategories of BD or RD but not both. With this unified diversity measure, we\ndesign the corresponding diversity-promoting objective and population\neffectivity when seeking the best responses in open-ended learning. We validate\nour methods in both relatively simple games like matrix game, non-transitive\nmixture model, and the complex \\textit{Google Research Football} environment.\nThe population found by our methods reveals the lowest exploitability, highest\npopulation effectivity in matrix game and non-transitive mixture model, as well\nas the largest goal difference when interacting with opponents of various\nlevels in \\textit{Google Research Football}.",
          "link": "http://arxiv.org/abs/2106.04958",
          "publishedOn": "2021-06-10T01:56:48.959Z",
          "wordCount": 732,
          "title": "Unifying Behavioral and Response Diversity for Open-ended Learning in Zero-sum Games. (arXiv:2106.04958v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurri_G/0/1/0/all/0/1\">Gowtham R. Kurri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sypherd_T/0/1/0/all/0/1\">Tyler Sypherd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_L/0/1/0/all/0/1\">Lalitha Sankar</a>",
          "description": "We introduce a tunable GAN, called $\\alpha$-GAN, parameterized by $\\alpha \\in\n(0,\\infty]$, which interpolates between various $f$-GANs and Integral\nProbability Metric based GANs (under constrained discriminator set). We\nconstruct $\\alpha$-GAN using a supervised loss function, namely, $\\alpha$-loss,\nwhich is a tunable loss function capturing several canonical losses. We show\nthat $\\alpha$-GAN is intimately related to the Arimoto divergence, which was\nfirst proposed by \\\"{O}sterriecher (1996), and later studied by Liese and Vajda\n(2006). We posit that the holistic understanding that $\\alpha$-GAN introduces\nwill have practical benefits of addressing both the issues of vanishing\ngradients and mode collapse.",
          "link": "http://arxiv.org/abs/2106.05232",
          "publishedOn": "2021-06-10T01:56:48.954Z",
          "wordCount": 536,
          "title": "Realizing GANs via a Tunable Loss Function. (arXiv:2106.05232v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1\">Tommaso R. Cesari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vecchia_R/0/1/0/all/0/1\">Riccardo Della Vecchia</a>",
          "description": "In this preliminary (and unpolished) version of the paper, we study an\nasynchronous online learning setting with a network of agents. At each time\nstep, some of the agents are activated, requested to make a prediction, and pay\nthe corresponding loss. Some feedback is then revealed to these agents and is\nlater propagated through the network. We consider the case of full, bandit, and\nsemi-bandit feedback. In particular, we construct a reduction to delayed\nsingle-agent learning that applies to both the full and the bandit feedback\ncase and allows to obtain regret guarantees for both settings. We complement\nthese results with a near-matching lower bound.",
          "link": "http://arxiv.org/abs/2106.04982",
          "publishedOn": "2021-06-10T01:56:48.939Z",
          "wordCount": 523,
          "title": "Cooperative Online Learning. (arXiv:2106.04982v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02404",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Krock_M/0/1/0/all/0/1\">Mitchell Krock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kleiber_W/0/1/0/all/0/1\">William Kleiber</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerling_D/0/1/0/all/0/1\">Dorit Hammerling</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Becker_S/0/1/0/all/0/1\">Stephen Becker</a>",
          "description": "We propose a new modeling framework for highly-multivariate spatial processes\nthat synthesizes ideas from recent multiscale and spectral approaches with\ngraphical models. The basis graphical lasso writes a univariate Gaussian\nprocess as a linear combination of basis functions weighted with entries of a\nGaussian graphical vector whose graph is estimated from optimizing an $\\ell_1$\npenalized likelihood. This paper extends the setting to a multivariate Gaussian\nprocess where the basis functions are weighted with Gaussian graphical vectors.\nWe motivate a model where the basis functions represent different levels of\nresolution and the graphical vectors for each level are assumed to be\nindependent. Using an orthogonal basis grants linear complexity and memory\nusage in the number of spatial locations, the number of basis functions, and\nthe number of realizations. An additional fusion penalty encourages a\nparsimonious conditional independence structure in the multilevel graphical\nmodel. We illustrate our method on a large climate ensemble from the National\nCenter for Atmospheric Research's Community Atmosphere Model that involves 40\nspatial processes.",
          "link": "http://arxiv.org/abs/2101.02404",
          "publishedOn": "2021-06-10T01:56:48.934Z",
          "wordCount": 618,
          "title": "Modeling massive highly-multivariate nonstationary spatial data with the basis graphical lasso. (arXiv:2101.02404v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.02511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Carolin Lawrence</a>",
          "description": "Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.",
          "link": "http://arxiv.org/abs/2011.02511",
          "publishedOn": "2021-06-10T01:56:48.929Z",
          "wordCount": 577,
          "title": "Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper considers the single-server Private Linear Transformation (PLT)\nproblem with individual privacy guarantees. In this problem, there is a user\nthat wishes to obtain $L$ independent linear combinations of a $D$-subset of\nmessages belonging to a dataset of $K$ messages stored on a single server. The\ngoal is to minimize the download cost while keeping the identity of each\nmessage required for the computation individually private. The individual\nprivacy requirement ensures that the identity of each individual message\nrequired for the computation is kept private. This is in contrast to the\nstricter notion of joint privacy that protects the entire set of identities of\nall messages used for the computation, including the correlations between these\nidentities. The notion of individual privacy captures a broad set of practical\napplications. For example, such notion is relevant when the dataset contains\ninformation about individuals, each of them requires privacy guarantees for\ntheir data access patterns. We focus on the setting in which the required\nlinear transformation is associated with a maximum distance separable (MDS)\nmatrix. In particular, we require that the matrix of coefficients pertaining to\nthe required linear combinations is the generator matrix of an MDS code. We\nestablish lower and upper bounds on the capacity of PLT with individual\nprivacy, where the capacity is defined as the supremum of all achievable\ndownload rates. We show that our bounds are tight under certain conditions.",
          "link": "http://arxiv.org/abs/2106.05222",
          "publishedOn": "2021-06-10T01:56:48.924Z",
          "wordCount": 678,
          "title": "Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kratsios_A/0/1/0/all/0/1\">Anastasis Kratsios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamanlooy_B/0/1/0/all/0/1\">Behnoosh Zamanlooy</a>",
          "description": "Most $L^p$-type universal approximation theorems guarantee that a given\nmachine learning model class $\\mathscr{F}\\subseteq\nC(\\mathbb{R}^d,\\mathbb{R}^D)$ is dense in\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$ for any suitable finite Borel measure\n$\\mu$ on $\\mathbb{R}^d$. Unfortunately, this means that the model's\napproximation quality can rapidly degenerate outside some compact subset of\n$\\mathbb{R}^d$, as any such measure is largely concentrated on some bounded\nsubset of $\\mathbb{R}^d$. This paper proposes a generic solution to this\napproximation theoretic problem by introducing a canonical transformation which\n\"upgrades $\\mathscr{F}$'s approximation property\" in the following sense. The\ntransformed model class, denoted by $\\mathscr{F}\\text{-tope}$, is shown to be\ndense in $L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$ which is a\ntopological space whose elements are locally $p$-integrable functions and whose\ntopology is much finer than usual norm topology on\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$; here $\\mu$ is any suitable\n$\\sigma$-finite Borel measure $\\mu$ on $\\mathbb{R}^d$. Next, we show that if\n$\\mathscr{F}$ is any family of analytic functions then there is always a strict\n\"gap\" between $\\mathscr{F}\\text{-tope}$'s expressibility and that of\n$\\mathscr{F}$, since we find that $\\mathscr{F}$ can never dense in\n$L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$. In the general case,\nwhere $\\mathscr{F}$ may contain non-analytic functions, we provide an abstract\nform of these results guaranteeing that there always exists some function space\nin which $\\mathscr{F}\\text{-tope}$ is dense but $\\mathscr{F}$ is not, while,\nthe converse is never possible. Applications to feedforward networks,\nconvolutional neural networks, and polynomial bases are explored.",
          "link": "http://arxiv.org/abs/2006.14378",
          "publishedOn": "2021-06-10T01:56:48.918Z",
          "wordCount": 717,
          "title": "A Canonical Transform for Strengthening the Local $L^p$-Type Universal Approximation Property. (arXiv:2006.14378v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05214",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1\">Sergio Naval Marimont</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1\">Giacomo Tarroni</a>",
          "description": "We propose a novel unsupervised out-of-distribution detection method for\nmedical images based on implicit fields image representations. In our approach,\nan auto-decoder feed-forward neural network learns the distribution of healthy\nimages in the form of a mapping between spatial coordinates and probabilities\nover a proxy for tissue types. At inference time, the learnt distribution is\nused to retrieve, from a given test image, a restoration, i.e. an image\nmaximally consistent with the input one but belonging to the healthy\ndistribution. Anomalies are localized using the voxel-wise probability\npredicted by our model for the restored image. We tested our approach in the\ntask of unsupervised localization of gliomas on brain MR images and compared it\nto several other VAE-based anomaly detection methods. Results show that the\nproposed technique substantially outperforms them (average DICE 0.640 vs 0.518\nfor the best performing VAE-based alternative) while also requiring\nconsiderably less computing time.",
          "link": "http://arxiv.org/abs/2106.05214",
          "publishedOn": "2021-06-10T01:56:48.912Z",
          "wordCount": 603,
          "title": "Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andreis_B/0/1/0/all/0/1\">Bruno Andreis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">A. Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seanie Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Current machine learning algorithms are designed to work with huge volumes of\nhigh dimensional data such as images. However, these algorithms are being\nincreasingly deployed to resource constrained systems such as mobile devices\nand embedded systems. Even in cases where large computing infrastructure is\navailable, the size of each data instance, as well as datasets, can be a\nbottleneck in data transfer across communication channels. Also, there is a\nhuge incentive both in energy and monetary terms in reducing both the\ncomputational and memory requirements of these algorithms. For nonparametric\nmodels that require to leverage the stored training data at inference time, the\nincreased cost in memory and computation could be even more problematic. In\nthis work, we aim to reduce the volume of data these algorithms must process\nthrough an end-to-end two-stage neural subset selection model. We first\nefficiently obtain a subset of candidate elements by sampling a mask from a\nconditionally independent Bernoulli distribution, and then autoregressivley\nconstruct a subset consisting of the most task relevant elements via sampling\nthe elements from a conditional Categorical distribution. We validate our\nmethod on set reconstruction and classification tasks with feature selection as\nwell as the selection of representative samples from a given dataset, on which\nour method outperforms relevant baselines. We also show in our experiments that\nour method enhances scalability of nonparametric models such as Neural\nProcesses.",
          "link": "http://arxiv.org/abs/2006.14222",
          "publishedOn": "2021-06-10T01:56:48.893Z",
          "wordCount": 712,
          "title": "Stochastic Subset Selection for Efficient Training and Inference of Neural Networks. (arXiv:2006.14222v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.01419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungyul Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Youngchul Sung</a>",
          "description": "In this paper, sample-aware policy entropy regularization is proposed to\nenhance the conventional policy entropy regularization for better exploration.\nExploiting the sample distribution obtainable from the replay buffer, the\nproposed sample-aware entropy regularization maximizes the entropy of the\nweighted sum of the policy action distribution and the sample action\ndistribution from the replay buffer for sample-efficient exploration. A\npractical algorithm named diversity actor-critic (DAC) is developed by applying\npolicy iteration to the objective function with the proposed sample-aware\nentropy regularization. Numerical results show that DAC significantly\noutperforms existing recent algorithms for reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.01419",
          "publishedOn": "2021-06-10T01:56:48.887Z",
          "wordCount": 561,
          "title": "Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration. (arXiv:2006.01419v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "Zero-shot intent detection (ZSID) aims to deal with the continuously emerging\nintents without annotated training data. However, existing ZSID systems suffer\nfrom two limitations: 1) They are not good at modeling the relationship between\nseen and unseen intents. 2) They cannot effectively recognize unseen intents\nunder the generalized intent detection (GZSID) setting. A critical problem\nbehind these limitations is that the representations of unseen intents cannot\nbe learned in the training stage. To address this problem, we propose a novel\nframework that utilizes unseen class labels to learn Class-Transductive Intent\nRepresentations (CTIR). Specifically, we allow the model to predict unseen\nintents during training, with the corresponding label names serving as input\nutterances. On this basis, we introduce a multi-task learning objective, which\nencourages the model to learn the distinctions among intents, and a similarity\nscorer, which estimates the connections among intents more accurately. CTIR is\neasy to implement and can be integrated with existing methods. Experiments on\ntwo real-world datasets show that CTIR brings considerable improvement to the\nbaseline systems.",
          "link": "http://arxiv.org/abs/2012.01721",
          "publishedOn": "2021-06-10T01:56:48.882Z",
          "wordCount": 636,
          "title": "Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05241",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1\">Fabian Falck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Haoting Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1\">George Nicholson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1\">Christopher Yau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Christopher C Holmes</a>",
          "description": "Work in deep clustering focuses on finding a single partition of data.\nHowever, high-dimensional data, such as images, typically feature multiple\ninteresting characteristics one could cluster over. For example, images of\nobjects against a background could be clustered over the shape of the object\nand separately by the colour of the background. In this paper, we introduce\nMulti-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of\nvariational autoencoders with a hierarchy of latent variables, each with a\nMixture-of-Gaussians prior, that learns multiple clusterings simultaneously,\nand is trained fully unsupervised and end-to-end. MFCVAE uses a\nprogressively-trained ladder architecture which leads to highly stable\nperformance. We provide novel theoretical results for optimising the ELBO\nanalytically with respect to the categorical variational posterior\ndistribution, and corrects earlier influential theoretical work. On image\nbenchmarks, we demonstrate that our approach separates out and clusters over\ndifferent aspects of the data in a disentangled manner. We also show other\nadvantages of our model: the compositionality of its latent space and that it\nprovides controlled generation of samples.",
          "link": "http://arxiv.org/abs/2106.05241",
          "publishedOn": "2021-06-10T01:56:48.866Z",
          "wordCount": 616,
          "title": "Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Bruno Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulin_P/0/1/0/all/0/1\">Pierre Poulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paquette_E/0/1/0/all/0/1\">Eric Paquette</a>",
          "description": "We present a novel up-resing technique for generating high-resolution liquids\nbased on scene flow estimation using deep neural networks. Our approach infers\nand synthesizes small- and large-scale details solely from a low-resolution\nparticle-based liquid simulation. The proposed network leverages neighborhood\ncontributions to encode inherent liquid properties throughout convolutions. We\nalso propose a particle-based approach to interpolate between liquids generated\nfrom varying simulation discretizations using a state-of-the-art bidirectional\noptical flow solver method for fluids in addition to a novel key-event\ntopological alignment constraint. In conjunction with the neighborhood\ncontributions, our loss formulation allows the inference model throughout\nepochs to reward important differences in regard to significant gaps in\nsimulation discretizations. Even when applied in an untested simulation setup,\nour approach is able to generate plausible high-resolution details. Using this\ninterpolation approach and the predicted displacements, our approach combines\nthe input liquid properties with the predicted motion to infer semi-Lagrangian\nadvection. We furthermore showcase how the proposed interpolation approach can\nfacilitate generating large simulation datasets with a subset of initial\ncondition parameters.",
          "link": "http://arxiv.org/abs/2106.05143",
          "publishedOn": "2021-06-10T01:56:48.860Z",
          "wordCount": 615,
          "title": "Neural UpFlow: A Scene Flow Learning Approach to Increase the Apparent Resolution of Particle-Based Liquids. (arXiv:2106.05143v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1\">Javier Barbero-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pedro-Antonio Guti&#xe9;rrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1\">V&#xed;ctor-Manuel Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1\">Juan-Antonio Vallejo-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1\">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>",
          "description": "3D image scans are an assessment tool for neurological damage in Parkinson's\ndisease (PD) patients. This diagnosis process can be automatized to help\nmedical staff through Decision Support Systems (DSSs), and Convolutional Neural\nNetworks (CNNs) are good candidates, because they are effective when applied to\nspatial data. This paper proposes a 3D CNN ordinal model for assessing the\nlevel or neurological damage in PD patients. Given that CNNs need large\ndatasets to achieve acceptable performance, a data augmentation method is\nadapted to work with spatial data. We consider the Ordinal Graph-based\nOversampling via Shortest Paths (OGO-SP) method, which applies a gamma\nprobability distribution for inter-class data generation. A modification of\nOGO-SP is proposed, the OGO-SP-$\\beta$ algorithm, which applies the beta\ndistribution for generating synthetic samples in the inter-class region, a\nbetter suited distribution when compared to gamma. The evaluation of the\ndifferent methods is based on a novel 3D image dataset provided by the Hospital\nUniversitario 'Reina Sof\\'ia' (C\\'ordoba, Spain). We show how the ordinal\nmethodology improves the performance with respect to the nominal one, and how\nOGO-SP-$\\beta$ yields better performance than OGO-SP.",
          "link": "http://arxiv.org/abs/2106.05230",
          "publishedOn": "2021-06-10T01:56:48.845Z",
          "wordCount": 645,
          "title": "An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients. (arXiv:2106.05230v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1\">Wang Yifan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1\">Lukas Rahmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1\">Olga Sorkine-Hornung</a>",
          "description": "We present implicit displacement fields, a novel representation for detailed\n3D geometry. Inspired by a classic surface deformation technique, displacement\nmapping, our method represents a complex surface as a smooth base surface plus\na displacement along the base's normal directions, resulting in a\nfrequency-based shape decomposition, where the high frequency signal is\nconstrained geometrically by the low frequency signal. Importantly, this\ndisentanglement is unsupervised thanks to a tailored architectural design that\nhas an innate frequency hierarchy by construction. We explore implicit\ndisplacement field surface reconstruction and detail transfer and demonstrate\nsuperior representational power, training stability and generalizability.",
          "link": "http://arxiv.org/abs/2106.05187",
          "publishedOn": "2021-06-10T01:56:48.839Z",
          "wordCount": 539,
          "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xinjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.",
          "link": "http://arxiv.org/abs/2106.05251",
          "publishedOn": "2021-06-10T01:56:48.833Z",
          "wordCount": 596,
          "title": "Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05114",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Daudel_K/0/1/0/all/0/1\">Kam&#xe9;lia Daudel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Douc_R/0/1/0/all/0/1\">Randal Douc</a>",
          "description": "This paper focuses on $\\alpha$-divergence minimisation methods for\nVariational Inference. More precisely, we are interested in algorithms\noptimising the mixture weights of any given mixture model, without any\ninformation on the underlying distribution of its mixture components\nparameters. The Power Descent, defined for all $\\alpha \\neq 1$, is one such\nalgorithm and we establish in our work the full proof of its convergence\ntowards the optimal mixture weights when $\\alpha <1$. Since the\n$\\alpha$-divergence recovers the widely-used forward Kullback-Leibler when\n$\\alpha \\to 1$, we then extend the Power Descent to the case $\\alpha = 1$ and\nshow that we obtain an Entropic Mirror Descent. This leads us to investigate\nthe link between Power Descent and Entropic Mirror Descent: first-order\napproximations allow us to introduce the Renyi Descent, a novel algorithm for\nwhich we prove an $O(1/N)$ convergence rate. Lastly, we compare numerically the\nbehavior of the unbiased Power Descent and of the biased Renyi Descent and we\ndiscuss the potential advantages of one algorithm over the other.",
          "link": "http://arxiv.org/abs/2106.05114",
          "publishedOn": "2021-06-10T01:56:48.828Z",
          "wordCount": 590,
          "title": "Mixture weights optimisation for Alpha-Divergence Variational Inference. (arXiv:2106.05114v1 [math.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalia_M/0/1/0/all/0/1\">Manu Kalia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1\">Steven L. Brunton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meijer_H/0/1/0/all/0/1\">Hil G.E. Meijer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brune_C/0/1/0/all/0/1\">Christoph Brune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Complex systems manifest a small number of instabilities and bifurcations\nthat are canonical in nature, resulting in universal pattern forming\ncharacteristics as a function of some parametric dependence. Such parametric\ninstabilities are mathematically characterized by their universal un-foldings,\nor normal form dynamics, whereby a parsimonious model can be used to represent\nthe dynamics. Although center manifold theory guarantees the existence of such\nlow-dimensional normal forms, finding them has remained a long standing\nchallenge. In this work, we introduce deep learning autoencoders to discover\ncoordinate transformations that capture the underlying parametric dependence of\na dynamical system in terms of its canonical normal form, allowing for a simple\nrepresentation of the parametric dependence and bifurcation structure. The\nautoencoder constrains the latent variable to adhere to a given normal form,\nthus allowing it to learn the appropriate coordinate transformation. We\ndemonstrate the method on a number of example problems, showing that it can\ncapture a diverse set of normal forms associated with Hopf, pitchfork,\ntranscritical and/or saddle node bifurcations. This method shows how normal\nforms can be leveraged as canonical and universal building blocks in deep\nlearning approaches for model discovery and reduced-order modeling.",
          "link": "http://arxiv.org/abs/2106.05102",
          "publishedOn": "2021-06-10T01:56:48.822Z",
          "wordCount": 639,
          "title": "Learning normal form autoencoders for data-driven discovery of universal,parameter-dependent governing equations. (arXiv:2106.05102v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjik Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1\">George Papamakarios</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mnih_A/0/1/0/all/0/1\">Andriy Mnih</a>",
          "description": "Lipschitz constants of neural networks have been explored in various contexts\nin deep learning, such as provable adversarial robustness, estimating\nWasserstein distance, stabilising training of GANs, and formulating invertible\nneural networks. Such works have focused on bounding the Lipschitz constant of\nfully connected or convolutional networks, composed of linear maps and\npointwise non-linearities. In this paper, we investigate the Lipschitz constant\nof self-attention, a non-linear neural network module widely used in sequence\nmodelling. We prove that the standard dot-product self-attention is not\nLipschitz for unbounded input domain, and propose an alternative L2\nself-attention that is Lipschitz. We derive an upper bound on the Lipschitz\nconstant of L2 self-attention and provide empirical evidence for its asymptotic\ntightness. To demonstrate the practical relevance of our theoretical work, we\nformulate invertible self-attention and use it in a Transformer-based\narchitecture for a character-level language modelling task.",
          "link": "http://arxiv.org/abs/2006.04710",
          "publishedOn": "2021-06-10T01:56:48.808Z",
          "wordCount": 579,
          "title": "The Lipschitz Constant of Self-Attention. (arXiv:2006.04710v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1\">Semih Cayci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yilin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eryilmaz_A/0/1/0/all/0/1\">Atilla Eryilmaz</a>",
          "description": "In a wide variety of applications including online advertising, contractual\nhiring, and wireless scheduling, the controller is constrained by a stringent\nbudget constraint on the available resources, which are consumed in a random\namount by each action, and a stochastic feasibility constraint that may impose\nimportant operational limitations on decision-making. In this work, we consider\na general model to address such problems, where each action returns a random\nreward, cost, and penalty from an unknown joint distribution, and the\ndecision-maker aims to maximize the total reward under a budget constraint $B$\non the total cost and a stochastic constraint on the time-average penalty. We\npropose a novel low-complexity algorithm based on Lyapunov optimization\nmethodology, named ${\\tt LyOn}$, and prove that it achieves $O(\\sqrt{B\\log B})$\nregret and $O(\\log B/B)$ constraint-violation. The low computational cost and\nsharp performance bounds of ${\\tt LyOn}$ suggest that Lyapunov-based algorithm\ndesign methodology can be effective in solving constrained bandit optimization\nproblems.",
          "link": "http://arxiv.org/abs/2106.05165",
          "publishedOn": "2021-06-10T01:56:48.802Z",
          "wordCount": 590,
          "title": "A Lyapunov-Based Methodology for Constrained Optimization with Bandit Feedback. (arXiv:2106.05165v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>",
          "description": "Knowledge distillation constitutes a simple yet effective way to improve the\nperformance of a compact student network by exploiting the knowledge of a more\npowerful teacher. Nevertheless, the knowledge distillation literature remains\nlimited to the scenario where the student and the teacher tackle the same task.\nHere, we investigate the problem of transferring knowledge not only across\narchitectures but also across tasks. To this end, we study the case of object\ndetection and, instead of following the standard detector-to-detector\ndistillation approach, introduce a classifier-to-detector knowledge transfer\nframework. In particular, we propose strategies to exploit the classification\nteacher to improve both the detector's recognition accuracy and localization\nperformance. Our experiments on several detectors with different backbones\ndemonstrate the effectiveness of our approach, allowing us to outperform the\nstate-of-the-art detector-to-detector distillation methods.",
          "link": "http://arxiv.org/abs/2106.05209",
          "publishedOn": "2021-06-10T01:56:48.796Z",
          "wordCount": 562,
          "title": "Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1\">Benjamin Walter</a>",
          "description": "Image classification is considered, and a hierarchical max-pooling model with\nadditional local pooling is introduced. Here the additional local pooling\nenables the hierachical model to combine parts of the image which have a\nvariable relative distance towards each other. Various convolutional neural\nnetwork image classifiers are introduced and compared in view of their rate of\nconvergence. The finite sample size performance of the estimates is analyzed by\napplying them to simulated and real data.",
          "link": "http://arxiv.org/abs/2106.05233",
          "publishedOn": "2021-06-10T01:56:48.791Z",
          "wordCount": 529,
          "title": "Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.04861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abeyrathna_K/0/1/0/all/0/1\">K. Darshana Abeyrathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1\">Bimal Bhattarai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1\">Morten Goodwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorji_S/0/1/0/all/0/1\">Saeed Gorji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Lei Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rupsa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_R/0/1/0/all/0/1\">Rohan K. Yadav</a>",
          "description": "Using logical clauses to represent patterns, Tsetlin Machines (TMs) have\nrecently obtained competitive performance in terms of accuracy, memory\nfootprint, energy, and learning speed on several benchmarks. Each TM clause\nvotes for or against a particular class, with classification resolved using a\nmajority vote. While the evaluation of clauses is fast, being based on binary\noperators, the voting makes it necessary to synchronize the clause evaluation,\nimpeding parallelization. In this paper, we propose a novel scheme for\ndesynchronizing the evaluation of clauses, eliminating the voting bottleneck.\nIn brief, every clause runs in its own thread for massive native parallelism.\nFor each training example, we keep track of the class votes obtained from the\nclauses in local voting tallies. The local voting tallies allow us to detach\nthe processing of each clause from the rest of the clauses, supporting\ndecentralized learning. This means that the TM most of the time will operate on\noutdated voting tallies. We evaluated the proposed parallelization across\ndiverse learning tasks and it turns out that our decentralized TM learning\nalgorithm copes well with working on outdated data, resulting in no significant\nloss in learning accuracy. Furthermore, we show that the proposed approach\nprovides up to 50 times faster learning. Finally, learning time is almost\nconstant for reasonable clause amounts (employing from 20 to 7,000 clauses on a\nTesla V100 GPU). For sufficiently large clause numbers, computation time\nincreases approximately proportionally. Our parallel and asynchronous\narchitecture thus allows processing of massive datasets and operating with more\nclauses for higher accuracy.",
          "link": "http://arxiv.org/abs/2009.04861",
          "publishedOn": "2021-06-10T01:56:48.782Z",
          "wordCount": 750,
          "title": "Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling. (arXiv:2009.04861v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.07063",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Coulombe_P/0/1/0/all/0/1\">Philippe Goulet Coulombe</a>",
          "description": "It is notoriously difficult to build a bad Random Forest (RF). Concurrently,\nRF blatantly overfits in-sample without any apparent consequence out-of-sample.\nStandard arguments, like the classic bias-variance trade-off or double descent,\ncannot rationalize this paradox. I propose a new explanation: bootstrap\naggregation and model perturbation as implemented by RF automatically prune a\nlatent \"true\" tree. More generally, randomized ensembles of greedily optimized\nlearners implicitly perform optimal early stopping out-of-sample. So there is\nno need to tune the stopping point. By construction, novel variants of Boosting\nand MARS are also eligible for automatic tuning. I empirically demonstrate the\nproperty, with simulated and real data, by reporting that these new completely\noverfitting ensembles perform similarly to their tuned counterparts -- or\nbetter.",
          "link": "http://arxiv.org/abs/2008.07063",
          "publishedOn": "2021-06-10T01:56:48.766Z",
          "wordCount": 594,
          "title": "To Bag is to Prune. (arXiv:2008.07063v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1\">Michel Pl&#xfc;ss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1\">Lukas Neukom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1\">Christian Scheller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1\">Manfred Vogel</a>",
          "description": "We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss\nGerman speech to Standard German text corpus. This first version of the corpus\nis based on publicly available data of the Bernese cantonal parliament and\nconsists of 293 hours of data. It was created using a novel forced sentence\nalignment procedure and an alignment quality estimator, which can be used to\ntrade off corpus size and quality. We trained Automatic Speech Recognition\n(ASR) models as baselines on different subsets of the data and achieved a Word\nError Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The\ncorpus is freely available for download.",
          "link": "http://arxiv.org/abs/2010.02810",
          "publishedOn": "2021-06-10T01:56:48.761Z",
          "wordCount": 581,
          "title": "Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1\">Arrasy Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hopner_N/0/1/0/all/0/1\">Niklas H&#xf6;pner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Ad hoc teamwork is the challenging problem of designing an autonomous agent\nwhich can adapt quickly to collaborate with teammates without prior\ncoordination mechanisms, including joint training. Prior work in this area has\nfocused on closed teams in which the number of agents is fixed. In this work,\nwe consider open teams by allowing agents with different fixed policies to\nenter and leave the environment without prior notification. Our solution builds\non graph neural networks to learn agent models and joint-action value models\nunder varying team compositions. We contribute a novel action-value computation\nthat integrates the agent model and joint-action value model to produce\naction-value estimates. We empirically demonstrate that our approach\nsuccessfully models the effects other agents have on the learner, leading to\npolicies that robustly adapt to dynamic team compositions and significantly\noutperform several alternative methods.",
          "link": "http://arxiv.org/abs/2006.10412",
          "publishedOn": "2021-06-10T01:56:48.755Z",
          "wordCount": 634,
          "title": "Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning. (arXiv:2006.10412v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Cunxiao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.",
          "link": "http://arxiv.org/abs/2106.05093",
          "publishedOn": "2021-06-10T01:56:48.750Z",
          "wordCount": 590,
          "title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolov_I/0/1/0/all/0/1\">Igor Sokolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fatkhullin_I/0/1/0/all/0/1\">Ilyas Fatkhullin</a>",
          "description": "Error feedback (EF), also known as error compensation, is an immensely\npopular convergence stabilization mechanism in the context of distributed\ntraining of supervised machine learning models enhanced by the use of\ncontractive communication compression mechanisms, such as Top-$k$. First\nproposed by Seide et al (2014) as a heuristic, EF resisted any theoretical\nunderstanding until recently [Stich et al., 2018, Alistarh et al., 2018].\nHowever, all existing analyses either i) apply to the single node setting only,\nii) rely on very strong and often unreasonable assumptions, such global\nboundedness of the gradients, or iterate-dependent assumptions that cannot be\nchecked a-priori and may not hold in practice, or iii) circumvent these issues\nvia the introduction of additional unbiased compressors, which increase the\ncommunication cost. In this work we fix all these deficiencies by proposing and\nanalyzing a new EF mechanism, which we call EF21, which consistently and\nsubstantially outperforms EF in practice. Our theoretical analysis relies on\nstandard assumptions only, works in the distributed heterogeneous data setting,\nand leads to better and more meaningful rates. In particular, we prove that\nEF21 enjoys a fast $O(1/T)$ convergence rate for smooth nonconvex problems,\nbeating the previous bound of $O(1/T^{2/3})$, which was shown a bounded\ngradients assumption. We further improve this to a fast linear rate for PL\nfunctions, which is the first linear convergence result for an EF-type method\nnot relying on unbiased compressors. Since EF has a large number of\napplications where it reigns supreme, we believe that our 2021 variant, EF21,\ncan a large impact on the practice of communication efficient distributed\nlearning.",
          "link": "http://arxiv.org/abs/2106.05203",
          "publishedOn": "2021-06-10T01:56:48.744Z",
          "wordCount": 711,
          "title": "EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback. (arXiv:2106.05203v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1\">Julien P&#xe9;rolat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauriere_M/0/1/0/all/0/1\">Mathieu Lauri&#xe8;re</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrin_S/0/1/0/all/0/1\">Sarah Perrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>",
          "description": "Concave Utility Reinforcement Learning (CURL) extends RL from linear to\nconcave utilities in the occupancy measure induced by the agent's policy. This\nencompasses not only RL but also imitation learning and exploration, among\nothers. Yet, this more general paradigm invalidates the classical Bellman\nequations, and calls for new algorithms. Mean-field Games (MFGs) are a\ncontinuous approximation of many-agent RL. They consider the limit case of a\ncontinuous distribution of identical agents, anonymous with symmetric\ninterests, and reduce the problem to the study of a single representative agent\nin interaction with the full population. Our core contribution consists in\nshowing that CURL is a subclass of MFGs. We think this important to bridge\ntogether both communities. It also allows to shed light on aspects of both\nfields: we show the equivalence between concavity in CURL and monotonicity in\nthe associated MFG, between optimality conditions in CURL and Nash equilibrium\nin MFG, or that Fictitious Play (FP) for this class of MFGs is simply\nFrank-Wolfe, bringing the first convergence rate for discrete-time FP for MFGs.\nWe also experimentally demonstrate that, using algorithms recently introduced\nfor solving MFGs, we can address the CURL problem more efficiently.",
          "link": "http://arxiv.org/abs/2106.03787",
          "publishedOn": "2021-06-10T01:56:48.730Z",
          "wordCount": 645,
          "title": "Concave Utility Reinforcement Learning: the Mean-field Game viewpoint. (arXiv:2106.03787v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeche_H/0/1/0/all/0/1\">Hugo Y&#xe8;che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dresdner_G/0/1/0/all/0/1\">Gideon Dresdner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huser_M/0/1/0/all/0/1\">Matthias H&#xfc;ser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>",
          "description": "Intensive care units (ICU) are increasingly looking towards machine learning\nfor methods to provide online monitoring of critically ill patients. In machine\nlearning, online monitoring is often formulated as a supervised learning\nproblem. Recently, contrastive learning approaches have demonstrated promising\nimprovements over competitive supervised benchmarks. These methods rely on\nwell-understood data augmentation techniques developed for image data which do\nnot apply to online monitoring. In this work, we overcome this limitation by\nsupplementing time-series data augmentation techniques with a novel contrastive\nlearning objective which we call neighborhood contrastive learning (NCL). Our\nobjective explicitly groups together contiguous time segments from each patient\nwhile maintaining state-specific information. Our experiments demonstrate a\nmarked improvement over existing work applying contrastive methods to medical\ntime-series.",
          "link": "http://arxiv.org/abs/2106.05142",
          "publishedOn": "2021-06-10T01:56:48.724Z",
          "wordCount": 549,
          "title": "Neighborhood Contrastive Learning Applied to Online Patient Monitoring. (arXiv:2106.05142v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1\">Naoya Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>",
          "description": "Tasks that involve high-resolution dense prediction require a modeling of\nboth local and global patterns in a large input field. Although the local and\nglobal structures often depend on each other and their simultaneous modeling is\nimportant, many convolutional neural network (CNN)-based approaches interchange\nrepresentations in different resolutions only a few times. In this paper, we\nclaim the importance of a dense simultaneous modeling of multiresolution\nrepresentation and propose a novel CNN architecture called densely connected\nmultidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution\nthat has different dilation factors in a single layer to model different\nresolutions simultaneously. By combining the multidilated convolution with the\nDenseNet architecture, D3Net incorporates multiresolution learning with an\nexponentially growing receptive field in almost all layers, while avoiding the\naliasing problem that occurs when we naively incorporate the dilated\nconvolution in DenseNet. Experiments on the image semantic segmentation task\nusing Cityscapes and the audio source separation task using MUSDB18 show that\nthe proposed method has superior performance over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.11844",
          "publishedOn": "2021-06-10T01:56:48.719Z",
          "wordCount": 636,
          "title": "Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hottung_A/0/1/0/all/0/1\">Andr&#xe9; Hottung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Yeong-Dae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tierney_K/0/1/0/all/0/1\">Kevin Tierney</a>",
          "description": "Recently numerous machine learning based methods for combinatorial\noptimization problems have been proposed that learn to construct solutions in a\nsequential decision process via reinforcement learning. While these methods can\nbe easily combined with search strategies like sampling and beam search, it is\nnot straightforward to integrate them into a high-level search procedure\noffering strong search guidance. Bello et al. (2016) propose active search,\nwhich adjusts the weights of a (trained) model with respect to a single\ninstance at test time using reinforcement learning. While active search is\nsimple to implement, it is not competitive with state-of-the-art methods\nbecause adjusting all model weights for each test instance is very time and\nmemory intensive. Instead of updating all model weights, we propose and\nevaluate three efficient active search strategies that only update a subset of\nparameters during the search. The proposed methods offer a simple way to\nsignificantly improve the search performance of a given model and outperform\nstate-of-the-art machine learning based methods on combinatorial problems, even\nsurpassing the well-known heuristic solver LKH3 on the capacitated vehicle\nrouting problem. Finally, we show that (efficient) active search enables\nlearned models to effectively solve instances that are much larger than those\nseen during training.",
          "link": "http://arxiv.org/abs/2106.05126",
          "publishedOn": "2021-06-10T01:56:48.710Z",
          "wordCount": 631,
          "title": "Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08578",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Pata_J/0/1/0/all/0/1\">Joosep Pata</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Duarte_J/0/1/0/all/0/1\">Javier Duarte</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vlimant_J/0/1/0/all/0/1\">Jean-Roch Vlimant</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1\">Maurizio Pierini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Spiropulu_M/0/1/0/all/0/1\">Maria Spiropulu</a>",
          "description": "In general-purpose particle detectors, the particle-flow algorithm may be\nused to reconstruct a comprehensive particle-level view of the event by\ncombining information from the calorimeters and the trackers, significantly\nimproving the detector resolution for jets and the missing transverse momentum.\nIn view of the planned high-luminosity upgrade of the CERN Large Hadron\nCollider (LHC), it is necessary to revisit existing reconstruction algorithms\nand ensure that both the physics and computational performance are sufficient\nin an environment with many simultaneous proton-proton interactions (pileup).\nMachine learning may offer a prospect for computationally efficient event\nreconstruction that is well-suited to heterogeneous computing platforms, while\nsignificantly improving the reconstruction quality over rule-based algorithms\nfor granular detectors. We introduce MLPF, a novel, end-to-end trainable,\nmachine-learned particle-flow algorithm based on parallelizable,\ncomputationally efficient, and scalable graph neural networks optimized using a\nmulti-task objective on simulated events. We report the physics and\ncomputational performance of the MLPF algorithm on a Monte Carlo dataset of top\nquark-antiquark pairs produced in proton-proton collisions in conditions\nsimilar to those expected for the high-luminosity LHC. The MLPF algorithm\nimproves the physics response with respect to a rule-based benchmark algorithm\nand demonstrates computationally scalable particle-flow reconstruction in a\nhigh-pileup environment.",
          "link": "http://arxiv.org/abs/2101.08578",
          "publishedOn": "2021-06-10T01:56:48.701Z",
          "wordCount": null,
          "title": "MLPF: Efficient machine-learned particle-flow reconstruction using graph neural networks. (arXiv:2101.08578v3 [physics.data-an] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11884",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Tran_T/0/1/0/all/0/1\">Trang H. Tran</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1\">Quoc Tran-Dinh</a>",
          "description": "We combine two advanced ideas widely used in optimization for machine\nlearning: shuffling strategy and momentum technique to develop a novel\nshuffling gradient-based method with momentum, coined Shuffling Momentum\nGradient (SMG), for non-convex finite-sum optimization problems. While our\nmethod is inspired by momentum techniques, its update is fundamentally\ndifferent from existing momentum-based methods. We establish state-of-the-art\nconvergence rates of SMG for any shuffling strategy using either constant or\ndiminishing learning rate under standard assumptions (i.e.$L$-smoothness and\nbounded variance). When the shuffling strategy is fixed, we develop another new\nalgorithm that is similar to existing momentum methods, and prove the same\nconvergence rates for this algorithm under the $L$-smoothness and bounded\ngradient assumptions. We demonstrate our algorithms via numerical simulations\non standard datasets and compare them with existing shuffling methods. Our\ntests have shown encouraging performance of the new algorithms.",
          "link": "http://arxiv.org/abs/2011.11884",
          "publishedOn": "2021-06-10T01:56:48.698Z",
          "wordCount": 608,
          "title": "SMG: A Shuffling Gradient-Based Method with Momentum. (arXiv:2011.11884v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1\">Peter Macgregor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">He Sun</a>",
          "description": "Local graph clustering is an important algorithmic technique for analysing\nmassive graphs, and has been widely applied in many research fields of data\nscience. While the objective of most (local) graph clustering algorithms is to\nfind a vertex set of low conductance, there has been a sequence of recent\nstudies that highlight the importance of the inter-connection between clusters\nwhen analysing real-world datasets. Following this line of research, in this\nwork we study local algorithms for finding a pair of vertex sets defined with\nrespect to their inter-connection and their relationship with the rest of the\ngraph. The key to our analysis is a new reduction technique that relates the\nstructure of multiple sets to a single vertex set in the reduced graph. Among\nmany potential applications, we show that our algorithms successfully recover\ndensely connected clusters in the Interstate Disputes Dataset and the US\nMigration Dataset.",
          "link": "http://arxiv.org/abs/2106.05245",
          "publishedOn": "2021-06-10T01:56:48.691Z",
          "wordCount": 590,
          "title": "Local Algorithms for Finding Densely Connected Clusters. (arXiv:2106.05245v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mina Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivatsa_P/0/1/0/all/0/1\">P Srivatsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rane_A/0/1/0/all/0/1\">Advait Rane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chenniappa_S/0/1/0/all/0/1\">Shriram Chenniappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_R/0/1/0/all/0/1\">Rishabh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1\">Sherjil Ozair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maes_P/0/1/0/all/0/1\">Pattie Maes</a>",
          "description": "Data-efficiency and generalization are key challenges in deep learning and\ndeep reinforcement learning as many models are trained on large-scale,\ndomain-specific, and expensive-to-label datasets. Self-supervised models\ntrained on large-scale uncurated datasets have shown successful transfer to\ndiverse settings. We investigate using pretrained image representations and\nspatio-temporal attention for state representation learning in Atari. We also\nexplore fine-tuning pretrained representations with self-supervised techniques,\ni.e., contrastive predictive coding, spatio-temporal contrastive learning, and\naugmentations. Our results show that pretrained representations are at par with\nstate-of-the-art self-supervised methods trained on domain-specific data.\nPretrained representations, thus, yield data and compute-efficient state\nrepresentations. https://github.com/PAL-ML/PEARL_v1",
          "link": "http://arxiv.org/abs/2106.05139",
          "publishedOn": "2021-06-10T01:56:48.681Z",
          "wordCount": 526,
          "title": "Pretrained Encoders are All You Need. (arXiv:2106.05139v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1\">Am&#xe9;lie Royer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1\">Larisa Markeeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>",
          "description": "There is a growing discrepancy in computer vision between large-scale models\nthat achieve state-of-the-art performance and models that are affordable in\npractical applications. In this paper we address this issue and significantly\nbridge the gap between these two types of models. Throughout our empirical\ninvestigation we do not aim to necessarily propose a new method, but strive to\nidentify a robust and effective recipe for making state-of-the-art large scale\nmodels affordable in practice. We demonstrate that, when performed correctly,\nknowledge distillation can be a powerful tool for reducing the size of large\nmodels without compromising their performance. In particular, we uncover that\nthere are certain implicit design choices, which may drastically affect the\neffectiveness of distillation. Our key contribution is the explicit\nidentification of these design choices, which were not previously articulated\nin the literature. We back up our findings by a comprehensive empirical study,\ndemonstrate compelling results on a wide range of vision datasets and, in\nparticular, obtain a state-of-the-art ResNet-50 model for ImageNet, which\nachieves 82.8\\% top-1 accuracy.",
          "link": "http://arxiv.org/abs/2106.05237",
          "publishedOn": "2021-06-10T01:56:48.664Z",
          "wordCount": 623,
          "title": "Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05152",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Hengyue Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Transfer learning (TL) with deep convolutional neural networks (DCNNs) has\nproved successful in medical image classification (MIC). However, the current\npractice is puzzling, as MIC typically relies only on low- and/or mid-level\nfeatures that are learned in the bottom layers of DCNNs. Following this\nintuition, we question the current strategies of TL in MIC. In this paper, we\nperform careful experimental comparisons between shallow and deep networks for\nclassification on two chest x-ray datasets, using different TL strategies. We\nfind that deep models are not always favorable, and finetuning truncated deep\nmodels almost always yields the best performance, especially in data-poor\nregimes.\n\nProject webpage:\nhttps://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging\n\nKeywords: Transfer learning, Medical image classification, Feature hierarchy,\nMedical imaging, Evaluation metrics, Imbalanced data",
          "link": "http://arxiv.org/abs/2106.05152",
          "publishedOn": "2021-06-10T01:56:48.658Z",
          "wordCount": 567,
          "title": "Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>",
          "description": "In many online learning or multi-armed bandit problems, the taken actions or\npulled arms are ordinal and required to be monotone over time. Examples include\ndynamic pricing, in which the firms use markup pricing policies to please early\nadopters and deter strategic waiting, and clinical trials, in which the dose\nallocation usually follows the dose escalation principle to prevent dose\nlimiting toxicities. We consider the continuum-armed bandit problem when the\narm sequence is required to be monotone. We show that when the unknown\nobjective function is Lipschitz continuous, the regret is $O(T)$. When in\naddition the objective function is unimodal or quasiconcave, the regret is\n$\\tilde O(T^{3/4})$ under the proposed algorithm, which is also shown to be the\noptimal rate. This deviates from the optimal rate $\\tilde O(T^{2/3})$ in the\ncontinuous-armed bandit literature and demonstrates the cost to the learning\nefficiency brought by the monotonicity requirement.",
          "link": "http://arxiv.org/abs/2106.03790",
          "publishedOn": "2021-06-10T01:56:48.652Z",
          "wordCount": 582,
          "title": "Multi-armed Bandit Requiring Monotone Arm Sequences. (arXiv:2106.03790v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xuebin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bingxin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Guang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Lio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Montufar</a>",
          "description": "This paper presents a new approach for assembling graph neural networks based\non framelet transforms. The latter provides a multi-scale representation for\ngraph-structured data. We decompose an input graph into low-pass and high-pass\nfrequencies coefficients for network training, which then defines a\nframelet-based graph convolution. The framelet decomposition naturally induces\na graph pooling strategy by aggregating the graph feature into low-pass and\nhigh-pass spectra, which considers both the feature values and geometry of the\ngraph data and conserves the total information. The graph neural networks with\nthe proposed framelet convolution and pooling achieve state-of-the-art\nperformance in many node and graph prediction tasks. Moreover, we propose\nshrinkage as a new activation for the framelet convolution, which thresholds\nhigh-frequency information at different scales. Compared to ReLU, shrinkage\nactivation improves model performance on denoising and signal compression:\nnoises in both node and structure can be significantly reduced by accurately\ncutting off the high-pass coefficients from framelet decomposition, and the\nsignal can be compressed to less than half its original size with\nwell-preserved prediction performance.",
          "link": "http://arxiv.org/abs/2102.06986",
          "publishedOn": "2021-06-10T01:56:48.638Z",
          "wordCount": 656,
          "title": "How Framelets Enhance Graph Neural Networks. (arXiv:2102.06986v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1\">Chengxuan Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shengjie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1\">Guolin Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "The Transformer architecture has become a dominant choice in many domains,\nsuch as natural language processing and computer vision. Yet, it has not\nachieved competitive performance on popular leaderboards of graph-level\nprediction compared to mainstream GNN variants. Therefore, it remains a mystery\nhow Transformers could perform well for graph representation learning. In this\npaper, we solve this mystery by presenting Graphormer, which is built upon the\nstandard Transformer architecture, and could attain excellent results on a\nbroad range of graph representation learning tasks, especially on the recent\nOGB Large-Scale Challenge. Our key insight to utilizing Transformer in the\ngraph is the necessity of effectively encoding the structural information of a\ngraph into the model. To this end, we propose several simple yet effective\nstructural encoding methods to help Graphormer better model graph-structured\ndata. Besides, we mathematically characterize the expressive power of\nGraphormer and exhibit that with our ways of encoding the structural\ninformation of graphs, many popular GNN variants could be covered as the\nspecial cases of Graphormer.",
          "link": "http://arxiv.org/abs/2106.05234",
          "publishedOn": "2021-06-10T01:56:48.632Z",
          "wordCount": 603,
          "title": "Do Transformers Really Perform Bad for Graph Representation?. (arXiv:2106.05234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hanyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peizhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>",
          "description": "In this paper, we focus on the fairness issues regarding unsupervised outlier\ndetection. Traditional algorithms, without a specific design for algorithmic\nfairness, could implicitly encode and propagate statistical bias in data and\nraise societal concerns. To correct such unfairness and deliver a fair set of\npotential outlier candidates, we propose Deep Clustering based Fair Outlier\nDetection (DCFOD) that learns a good representation for utility maximization\nwhile enforcing the learnable representation to be subgroup-invariant on the\nsensitive attribute. Considering the coupled and reciprocal nature between\nclustering and outlier detection, we leverage deep clustering to discover the\nintrinsic cluster structure and out-of-structure instances. Meanwhile, an\nadversarial training erases the sensitive pattern for instances for fairness\nadaptation. Technically, we propose an instance-level weighted representation\nlearning strategy to enhance the joint deep clustering and outlier detection,\nwhere the dynamic weight module re-emphasizes contributions of likely-inliers\nwhile mitigating the negative impact from outliers. Demonstrated by experiments\non eight datasets comparing to 17 outlier detection algorithms, our DCFOD\nmethod consistently achieves superior performance on both the outlier detection\nvalidity and two types of fairness notions in outlier detection.",
          "link": "http://arxiv.org/abs/2106.05127",
          "publishedOn": "2021-06-10T01:56:48.627Z",
          "wordCount": 609,
          "title": "Deep Clustering based Fair Outlier Detection. (arXiv:2106.05127v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Adversarial learning has emerged as one of the successful techniques to\ncircumvent the susceptibility of existing methods against adversarial\nperturbations. However, the majority of existing defense methods are tailored\nto defend against a single category of adversarial perturbation (e.g.\n$\\ell_\\infty$-attack). In safety-critical applications, this makes these\nmethods extraneous as the attacker can adopt diverse adversaries to deceive the\nsystem. Moreover, training on multiple perturbations simultaneously\nsignificantly increases the computational overhead during training. To address\nthese challenges, we propose a novel meta-learning framework that explicitly\nlearns to generate noise to improve the model's robustness against multiple\ntypes of attacks. Its key component is Meta Noise Generator (MNG) that outputs\noptimal noise to stochastically perturb a given sample, such that it helps\nlower the error on diverse adversarial perturbations. By utilizing samples\ngenerated by MNG, we train a model by enforcing the label consistency across\nmultiple perturbations. We validate the robustness of models trained by our\nscheme on various datasets and against a wide variety of perturbations,\ndemonstrating that it significantly outperforms the baselines across multiple\nperturbations with a marginal computational cost.",
          "link": "http://arxiv.org/abs/2006.12135",
          "publishedOn": "2021-06-10T01:56:48.619Z",
          "wordCount": 657,
          "title": "Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1\">Takahiro Shinozaki</a>",
          "description": "End-to-end automatic speech recognition (ASR) can achieve promising\nperformance with large-scale training data. However, it is known that domain\nmismatch between training and testing data often leads to a degradation of\nrecognition accuracy. In this work, we focus on the unsupervised domain\nadaptation for ASR and propose CMatch, a Character-level distribution matching\nmethod to perform fine-grained adaptation between each character in two\ndomains. First, to obtain labels for the features belonging to each character,\nwe achieve frame-level label assignment using the Connectionist Temporal\nClassification (CTC) pseudo labels. Then, we match the character-level\ndistributions using Maximum Mean Discrepancy. We train our algorithm using the\nself-training technique. Experiments on the Libri-Adapt dataset show that our\nproposed approach achieves 14.39% and 16.50% relative Word Error Rate (WER)\nreduction on both cross-device and cross-environment ASR. We also\ncomprehensively analyze the different strategies for frame-level label\nassignment and Transformer adaptations.",
          "link": "http://arxiv.org/abs/2104.07491",
          "publishedOn": "2021-06-10T01:56:48.613Z",
          "wordCount": 628,
          "title": "Cross-domain Speech Recognition with Unsupervised Character-level Distribution Matching. (arXiv:2104.07491v3 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Haeri Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Youngkyu Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hye Won Chung</a>",
          "description": "Despite remarkable performance in producing realistic samples, Generative\nAdversarial Networks (GANs) often produce low-quality samples near low-density\nregions of the data manifold, especially for samples with minor features. Many\ntechniques have been developed to improve the quality of generated samples,\neither by post-processing generated samples or by pre-processing the empirical\ndata distribution, but at the cost of reduced diversity. To promote diversity\nin sample generation without degrading the overall quality, we propose a simple\nyet effective method to diagnose and emphasize underrepresented samples during\ntraining of a GAN. The main idea is to use the statistics of the discrepancy\nbetween the data distribution and the model distribution at each data instance.\nBased on the observation that the underrepresented samples have a high average\ndiscrepancy or high variability in discrepancy, we propose a method to\nemphasize those samples during training of a GAN. Our experimental results\ndemonstrate that the proposed method improves GAN performance on various\ndatasets, and it is especially effective in improving the quality and diversity\nof generated samples with minor features.",
          "link": "http://arxiv.org/abs/2102.12033",
          "publishedOn": "2021-06-10T01:56:48.606Z",
          "wordCount": 628,
          "title": "Self-Diagnosing GAN: Diagnosing Underrepresented Samples in Generative Adversarial Networks. (arXiv:2102.12033v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.00101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hye Won Chung</a>",
          "description": "We consider crowdsourced labeling under a $d$-type worker-task specialization\nmodel, where each worker and task is associated with one particular type among\na finite set of types and a worker provides a more reliable answer to tasks of\nthe matched type than to tasks of unmatched types. We design an inference\nalgorithm that recovers binary task labels (up to any given recovery accuracy)\nby using worker clustering, worker skill estimation and weighted majority\nvoting. The designed inference algorithm does not require any information about\nworker/task types, and achieves any targeted recovery accuracy with the best\nknown performance (minimum number of queries per task).",
          "link": "http://arxiv.org/abs/2004.00101",
          "publishedOn": "2021-06-10T01:56:48.577Z",
          "wordCount": 571,
          "title": "Crowdsourced Labeling for Worker-Task Specialization Model. (arXiv:2004.00101v2 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_T/0/1/0/all/0/1\">Tushar Sarkar</a>",
          "description": "Neural networks have proved to be very robust at processing unstructured data\nlike images, text, videos, and audio. However, it has been observed that their\nperformance is not up to the mark in tabular data; hence tree-based models are\npreferred in such scenarios. A popular model for tabular data is boosted trees,\na highly efficacious and extensively used machine learning method, and it also\nprovides good interpretability compared to neural networks. In this paper, we\ndescribe a novel architecture XBNet, which tries to combine tree-based models\nwith that of neural networks to create a robust architecture trained by using a\nnovel optimization technique, Boosted Gradient Descent for Tabular Data which\nincreases its interpretability and performance.",
          "link": "http://arxiv.org/abs/2106.05239",
          "publishedOn": "2021-06-10T01:56:48.571Z",
          "wordCount": 530,
          "title": "XBNet : An Extremely Boosted Neural Network. (arXiv:2106.05239v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.05683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yixi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1\">Shruti Tople</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "In this work, we formally study the membership privacy risk of generative\nmodels and propose a membership privacy estimation framework. We formulate the\nmembership privacy risk as a statistical divergence between training samples\nand hold-out samples, and propose sample-based methods to estimate this\ndivergence. Unlike previous works, our proposed metric and estimators make\nrealistic and flexible assumptions. First, we offer a generalizable metric as\nan alternative to accuracy for imbalanced datasets. Second, our estimators are\ncapable of estimating the membership privacy risk given any scalar or vector\nvalued attributes from the learned model, while prior work require access to\nspecific attributes. This allows our framework to provide data-driven\ncertificates for trained generative models in terms of membership privacy risk.\nFinally, we show a connection to differential privacy, which allows our\nproposed estimators to be used to understand the privacy budget 'epsilon'\nneeded for differentially private generative models. We demonstrate the utility\nof our framework through experimental demonstrations on different generative\nmodels using various model attributes yielding some new insights about\nmembership leakage and vulnerabilities of models.",
          "link": "http://arxiv.org/abs/2009.05683",
          "publishedOn": "2021-06-10T01:56:48.512Z",
          "wordCount": 653,
          "title": "MACE: A Flexible Framework for Membership Privacy Estimation in Generative Models. (arXiv:2009.05683v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To address these challenges, we\npropose the use of Deep Learning and Word Embeddings for identifying sixteen\nmorbidity types within textual descriptions of clinical records. For this\npurpose, we have used a Deep Learning model based on Bidirectional Long-Short\nTerm Memory (LSTM) layers which can exploit state-of-the-art vector\nrepresentations of data such as Word Embeddings. We have employed pre-trained\nWord Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained\non the target domain. Furthermore, we have compared the performances of the\ndeep learning approaches against the traditional tf-idf using Support Vector\nMachine and Multilayer perceptron (our baselines). From the obtained results it\nseems that the latter outperforms the combination of Deep Learning approaches\nusing any word embeddings. Our preliminary results indicate that there are\nspecific features that make the dataset biased in favour of traditional machine\nlearning approaches.",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-06-10T01:56:48.496Z",
          "wordCount": 711,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09769",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1\">Marc Goerigk</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1\">Jannis Kurtz</a>",
          "description": "Robust optimization has been established as a leading methodology to approach\ndecision problems under uncertainty. To derive a robust optimization model, a\ncentral ingredient is to identify a suitable model for uncertainty, which is\ncalled the uncertainty set, containing all scenarios against which we wish to\nprotect. An ongoing challenge in the recent literature is to derive uncertainty\nsets from given historical data.\n\nIn this paper we use an unsupervised deep learning method to construct\nnon-convex uncertainty sets from data, which have a more complex structure than\nthe typically considered sets. We prove that most of the classical uncertainty\nclasses are special cases of our derived sets and that optimizing over it is\nstrongly NP-hard. Nevertheless we show that the trained neural networks can be\nintegrated into a robust optimization model by formulating the adversarial\nproblem as a convex quadratic mixed-integer program. This allows us to derive\nrobust solutions through an iterative scenario generation process. We prove\nthat our class of uncertainty sets contains In extensive computational\nexperiments, we compare this approach to a similar approach, which derives\nuncertainty sets by kernel-based support vector clustering. We find that\nuncertainty sets derived by the unsupervised deep learning method can give a\nbetter description of data, leading to robust solutions that often outperform\nthe comparison method both with respect to objective value and feasibility.",
          "link": "http://arxiv.org/abs/2011.09769",
          "publishedOn": "2021-06-10T01:56:48.472Z",
          "wordCount": 663,
          "title": "Data-Driven Robust Optimization using Unsupervised Deep Learning. (arXiv:2011.09769v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tai-Yu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faye_S/0/1/0/all/0/1\">S&#xe9;bastien Faye</a>",
          "description": "Public charging station occupancy prediction plays key importance in\ndeveloping a smart charging strategy to reduce electric vehicle (EV) operator\nand user inconvenience. However, existing studies are mainly based on\nconventional econometric or time series methodologies with limited accuracy. We\npropose a new mixed long short-term memory neural network incorporating both\nhistorical charging state sequences and time-related features for multistep\ndiscrete charging occupancy state prediction. Unlike the existing LSTM\nnetworks, the proposed model separates different types of features and handles\nthem differently with mixed neural network architecture. The model is compared\nto a number of state-of-the-art machine learning and deep learning approaches\nbased on the EV charging data obtained from the open data portal of the city of\nDundee, UK. The results show that the proposed method produces very accurate\npredictions (99.99% and 81.87% for 1 step (10 minutes) and 6 step (1 hour)\nahead, respectively, and outperforms the benchmark approaches significantly\n(+22.4% for one-step-ahead prediction and +6.2% for 6 steps ahead). A\nsensitivity analysis is conducted to evaluate the impact of the model\nparameters on prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.04986",
          "publishedOn": "2021-06-10T01:56:48.443Z",
          "wordCount": 611,
          "title": "Multistep Electric Vehicle Charging Station Occupancy Prediction using Mixed LSTM Neural Networks. (arXiv:2106.04986v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1\">Danial Dervovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanzadeh_P/0/1/0/all/0/1\">Parisa Hassanzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assefa_S/0/1/0/all/0/1\">Samuel Assefa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_P/0/1/0/all/0/1\">Prashant Reddy</a>",
          "description": "We consider a problem wherein jobs arrive at random times and assume random\nvalues. Upon each job arrival, the decision-maker must decide immediately\nwhether or not to accept the job and gain the value on offer as a reward, with\nthe constraint that they may only accept at most $n$ jobs over some reference\ntime period. The decision-maker only has access to $M$ independent realisations\nof the job arrival process. We propose an algorithm, Non-Parametric Sequential\nAllocation (NPSA), for solving this problem. Moreover, we prove that the\nexpected reward returned by the NPSA algorithm converges in probability to\noptimality as $M$ grows large. We demonstrate the effectiveness of the\nalgorithm empirically on synthetic data and on public fraud-detection datasets,\nfrom where the motivation for this work is derived.",
          "link": "http://arxiv.org/abs/2106.04944",
          "publishedOn": "2021-06-10T01:56:48.438Z",
          "wordCount": 571,
          "title": "Non-Parametric Stochastic Sequential Assignment With Random Arrival Times. (arXiv:2106.04944v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Demi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>",
          "description": "While task-specific finetuning of pretrained networks has led to significant\nempirical advances in NLP, the large size of networks makes finetuning\ndifficult to deploy in multi-task, memory-constrained settings. We propose diff\npruning as a simple approach to enable parameter-efficient transfer learning\nwithin the pretrain-finetune framework. This approach views finetuning as\nlearning a task-specific diff vector that is applied on top of the pretrained\nparameter vector, which remains fixed and is shared across different tasks. The\ndiff vector is adaptively pruned during training with a differentiable\napproximation to the L0-norm penalty to encourage sparsity. Diff pruning\nbecomes parameter-efficient as the number of tasks increases, as it requires\nstoring only the nonzero positions and weights of the diff vector for each\ntask, while the cost of storing the shared pretrained model remains constant.\nIt further does not require access to all tasks during training, which makes it\nattractive in settings where tasks arrive in stream or the set of tasks is\nunknown. We find that models finetuned with diff pruning can match the\nperformance of fully finetuned baselines on the GLUE benchmark while only\nmodifying 0.5% of the pretrained model's parameters per task.",
          "link": "http://arxiv.org/abs/2012.07463",
          "publishedOn": "2021-06-10T01:56:48.432Z",
          "wordCount": 647,
          "title": "Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Katsuma Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1\">Soh Ohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1\">Kohei Nakajima</a>",
          "description": "Language is an outcome of our complex and dynamic human-interactions and the\ntechnique of natural language processing (NLP) is hence built on human\nlinguistic activities. Bidirectional Encoder Representations from Transformers\n(BERT) has recently gained its popularity by establishing the state-of-the-art\nscores in several NLP benchmarks. A Lite BERT (ALBERT) is literally\ncharacterized as a lightweight version of BERT, in which the number of BERT\nparameters is reduced by repeatedly applying the same neural network called\nTransformer's encoder layer. By pre-training the parameters with a massive\namount of natural language data, ALBERT can convert input sentences into\nversatile high-dimensional vectors potentially capable of solving multiple NLP\ntasks. In that sense, ALBERT can be regarded as a well-designed\nhigh-dimensional dynamical system whose operator is the Transformer's encoder,\nand essential structures of human language are thus expected to be encapsulated\nin its dynamics. In this study, we investigated the embedded properties of\nALBERT to reveal how NLP tasks are effectively solved by exploiting its\ndynamics. We thereby aimed to explore the nature of human language from the\ndynamical expressions of the NLP model. Our short-term analysis clarified that\nthe pre-trained model stably yields trajectories with higher dimensionality,\nwhich would enhance the expressive capacity required for NLP tasks. Also, our\nlong-term analysis revealed that ALBERT intrinsically shows transient chaos, a\ntypical nonlinear phenomenon showing chaotic dynamics only in its transient,\nand the pre-trained ALBERT model tends to produce the chaotic trajectory for a\nsignificantly longer time period compared to a randomly-initialized one. Our\nresults imply that local chaoticity would contribute to improving NLP\nperformance, uncovering a novel aspect in the role of chaotic dynamics in human\nlanguage behaviors.",
          "link": "http://arxiv.org/abs/2106.03181",
          "publishedOn": "2021-06-10T01:56:48.417Z",
          "wordCount": 731,
          "title": "Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1\">Sirisha Rambhatla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Vast amount of data generated from networks of sensors, wearables, and the\nInternet of Things (IoT) devices underscores the need for advanced modeling\ntechniques that leverage the spatio-temporal structure of decentralized data\ndue to the need for edge computation and licensing (data access) issues. While\nfederated learning (FL) has emerged as a framework for model training without\nrequiring direct data sharing and exchange, effectively modeling the complex\nspatio-temporal dependencies to improve forecasting capabilities still remains\nan open problem. On the other hand, state-of-the-art spatio-temporal\nforecasting models assume unfettered access to the data, neglecting constraints\non data sharing. To bridge this gap, we propose a federated spatio-temporal\nmodel -- Cross-Node Federated Graph Neural Network (CNFGNN) -- which explicitly\nencodes the underlying graph structure using graph neural network (GNN)-based\narchitecture under the constraint of cross-node federated learning, which\nrequires that data in a network of nodes is generated locally on each node and\nremains decentralized. CNFGNN operates by disentangling the temporal dynamics\nmodeling on devices and spatial dynamics on the server, utilizing alternating\noptimization to reduce the communication cost, facilitating computations on the\nedge devices. Experiments on the traffic flow forecasting task show that CNFGNN\nachieves the best forecasting performance in both transductive and inductive\nlearning settings with no extra computation cost on edge devices, while\nincurring modest communication cost.",
          "link": "http://arxiv.org/abs/2106.05223",
          "publishedOn": "2021-06-10T01:56:48.411Z",
          "wordCount": 663,
          "title": "Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling. (arXiv:2106.05223v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1\">Theresa Eimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Reinforcement learning (RL) has made a lot of advances for solving a single\nproblem in a given environment; but learning policies that generalize to unseen\nvariations of a problem remains challenging. To improve sample efficiency for\nlearning on such instances of a problem domain, we present Self-Paced Context\nEvaluation (SPaCE). Based on self-paced learning, \\spc automatically generates\n\\task curricula online with little computational overhead. To this end, SPaCE\nleverages information contained in state values during training to accelerate\nand improve training performance as well as generalization capabilities to new\ninstances from the same problem domain. Nevertheless, SPaCE is independent of\nthe problem domain at hand and can be applied on top of any RL agent with\nstate-value function approximation. We demonstrate SPaCE's ability to speed up\nlearning of different value-based RL agents on two environments, showing better\ngeneralization capabilities and up to 10x faster learning compared to naive\napproaches such as round robin or SPDRL, as the closest state-of-the-art\napproach.",
          "link": "http://arxiv.org/abs/2106.05110",
          "publishedOn": "2021-06-10T01:56:48.405Z",
          "wordCount": 582,
          "title": "Self-Paced Context Evaluation for Contextual Reinforcement Learning. (arXiv:2106.05110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03786",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Wen Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hung_K/0/1/0/all/0/1\">Kuo-Hsuan Hung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chuang_S/0/1/0/all/0/1\">Shang-Yi Chuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sherman_J/0/1/0/all/0/1\">Jonathan Sherman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wen-Chin Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_X/0/1/0/all/0/1\">Xugang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Synthesized speech from articulatory movements can have real-world use for\npatients with vocal cord disorders, situations requiring silent speech, or in\nhigh-noise environments. In this work, we present EMA2S, an end-to-end\nmultimodal articulatory-to-speech system that directly converts articulatory\nmovements to speech signals. We use a neural-network-based vocoder combined\nwith multimodal joint-training, incorporating spectrogram, mel-spectrogram, and\ndeep features. The experimental results confirm that the multimodal approach of\nEMA2S outperforms the baseline system in terms of both objective evaluation and\nsubjective evaluation metrics. Moreover, results demonstrate that joint\nmel-spectrogram and deep feature loss training can effectively improve system\nperformance.",
          "link": "http://arxiv.org/abs/2102.03786",
          "publishedOn": "2021-06-10T01:56:48.400Z",
          "wordCount": 559,
          "title": "EMA2S: An End-to-End Multimodal Articulatory-to-Speech System. (arXiv:2102.03786v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11654",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1\">Marco Mondelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Montufar</a>",
          "description": "A recent line of work has analyzed the theoretical properties of deep neural\nnetworks via the Neural Tangent Kernel (NTK). In particular, the smallest\neigenvalue of the NTK has been related to the memorization capacity, the global\nconvergence of gradient descent algorithms and the generalization of deep nets.\nHowever, existing results either provide bounds in the two-layer setting or\nassume that the spectrum of the NTK matrices is bounded away from 0 for\nmulti-layer networks. In this paper, we provide tight bounds on the smallest\neigenvalue of NTK matrices for deep ReLU nets, both in the limiting case of\ninfinite widths and for finite widths. In the finite-width setting, the network\narchitectures we consider are fairly general: we require the existence of a\nwide layer with roughly order of $N$ neurons, $N$ being the number of data\nsamples; and the scaling of the remaining layer widths is arbitrary (up to\nlogarithmic factors). To obtain our results, we analyze various quantities of\nindependent interest: we give lower bounds on the smallest singular value of\nhidden feature matrices, and upper bounds on the Lipschitz constant of\ninput-output feature maps.",
          "link": "http://arxiv.org/abs/2012.11654",
          "publishedOn": "2021-06-10T01:56:48.376Z",
          "wordCount": 656,
          "title": "Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks. (arXiv:2012.11654v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1\">Andrea Apicella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1\">Francesco Isgr&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1\">Roberto Prevete</a>",
          "description": "Nowadays, it is growing interest to make Machine Learning (ML) systems more\nunderstandable and trusting to general users. Thus, generating explanations for\nML system behaviours that are understandable to human beings is a central\nscientific and technological issue addressed by the rapidly growing research\narea of eXplainable Artificial Intelligence (XAI). Recently, it is becoming\nmore and more evident that new directions to create better explanations should\ntake into account what a good explanation is to a human user, and consequently,\ndevelop XAI solutions able to provide user-centred explanations. This paper\nsuggests taking advantage of developing an XAI general approach that allows\nproducing explanations for an ML system behaviour in terms of different and\nuser-selected input features, i.e., explanations composed of input properties\nthat the human user can select according to his background knowledge and goals.\nTo this end, we propose an XAI general approach which is able: 1) to construct\nexplanations in terms of input features that represent more salient and\nunderstandable input properties for a user, which we call here Middle-Level\ninput Features (MLFs), 2) to be applied to different types of MLFs. We\nexperimentally tested our approach on two different datasets and using three\ndifferent types of MLFs. The results seem encouraging.",
          "link": "http://arxiv.org/abs/2106.05037",
          "publishedOn": "2021-06-10T01:56:48.368Z",
          "wordCount": 650,
          "title": "A general approach for Explanations in terms of Middle Level Features. (arXiv:2106.05037v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05206",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Deyo_S/0/1/0/all/0/1\">Sean Deyo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Elser_V/0/1/0/all/0/1\">Veit Elser</a>",
          "description": "Iterative projection methods may become trapped at non-solutions when the\nconstraint sets are nonconvex. Two kinds of parameters are available to help\navoid this behavior and this study gives examples of both. The first kind of\nparameter, called a hyperparameter, includes any kind of parameter that appears\nin the definition of the iteration rule itself. The second kind comprises\nmetric parameters in the definition of the constraint sets, a feature that\narises when the problem to be solved has two or more kinds of variables.\nThrough examples we show the importance of properly tuning both kinds of\nparameters and offer heuristic interpretations of the observed behavior.",
          "link": "http://arxiv.org/abs/2106.05206",
          "publishedOn": "2021-06-10T01:56:48.307Z",
          "wordCount": 530,
          "title": "Avoiding Traps in Nonconvex Problems. (arXiv:2106.05206v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2011.07248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1\">T. Anderson Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jorn W.T. Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaini_P/0/1/0/all/0/1\">Priyank Jaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Efficient gradient computation of the Jacobian determinant term is a core\nproblem in many machine learning settings, and especially so in the normalizing\nflow framework. Most proposed flow models therefore either restrict to a\nfunction class with easy evaluation of the Jacobian determinant, or an\nefficient estimator thereof. However, these restrictions limit the performance\nof such density models, frequently requiring significant depth to reach desired\nperformance levels. In this work, we propose Self Normalizing Flows, a flexible\nframework for training normalizing flows by replacing expensive terms in the\ngradient by learned approximate inverses at each layer. This reduces the\ncomputational complexity of each layer's exact update from $\\mathcal{O}(D^3)$\nto $\\mathcal{O}(D^2)$, allowing for the training of flow architectures which\nwere otherwise computationally infeasible, while also providing efficient\nsampling. We show experimentally that such models are remarkably stable and\noptimize to similar data likelihood values as their exact gradient\ncounterparts, while training more quickly and surpassing the performance of\nfunctionally constrained counterparts.",
          "link": "http://arxiv.org/abs/2011.07248",
          "publishedOn": "2021-06-10T01:56:48.302Z",
          "wordCount": 625,
          "title": "Self Normalizing Flows. (arXiv:2011.07248v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1\">Imon Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1\">Kavi Arya</a>",
          "description": "A user's eyes provide means for Human Computer Interaction (HCI) research as\nan important modal. The time to time scientific explorations of the eye has\nalready seen an upsurge of the benefits in HCI applications from gaze\nestimation to the measure of attentiveness of a user looking at a screen for a\ngiven time period. The eye tracking system as an assisting, interactive tool\ncan be incorporated by physically disabled individuals, fitted best for those\nwho have eyes as only a limited set of communication. The threefold objective\nof this paper is - 1. To introduce a neural network based architecture to\npredict users' gaze at 9 positions displayed in the 11.31{\\deg} visual range on\nthe screen, through a low resolution based system such as a webcam in real time\nby learning various aspects of eyes as an ocular feature set. 2.A collection of\ncoarsely supervised feature set obtained in real time which is also validated\nthrough the user case study presented in the paper for 21 individuals ( 17 men\nand 4 women ) from whom a 35k set of instances was derived with an accuracy\nscore of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability\nand underlying challenges of such systems. The experimental results verify the\nfeasibility and validity of the proposed eye gaze tracking model.",
          "link": "http://arxiv.org/abs/2106.05106",
          "publishedOn": "2021-06-10T01:56:48.297Z",
          "wordCount": 674,
          "title": "An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper introduces the problem of Private Linear Transformation (PLT)\nwhich generalizes the problems of private information retrieval and private\nlinear computation. The PLT problem includes one or more remote server(s)\nstoring (identical copies of) $K$ messages and a user who wants to compute $L$\nindependent linear combinations of a $D$-subset of messages. The objective of\nthe user is to perform the computation by downloading minimum possible amount\nof information from the server(s), while protecting the identities of the $D$\nmessages required for the computation. In this work, we focus on the\nsingle-server setting of the PLT problem when the identities of the $D$\nmessages required for the computation must be protected jointly. We consider\ntwo different models, depending on whether the coefficient matrix of the\nrequired $L$ linear combinations generates a Maximum Distance Separable (MDS)\ncode. We prove that the capacity for both models is given by $L/(K-D+L)$, where\nthe capacity is defined as the supremum of all achievable download rates. Our\nconverse proofs are based on linear-algebraic and information-theoretic\narguments that establish connections between PLT schemes and linear codes. We\nalso present an achievability scheme for each of the models being considered.",
          "link": "http://arxiv.org/abs/2106.05220",
          "publishedOn": "2021-06-10T01:56:48.257Z",
          "wordCount": 638,
          "title": "Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1\">Guy Gaziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1\">Michal Irani</a>",
          "description": "In the past few years, significant advancements were made in reconstruction\nof observed natural images from fMRI brain recordings using deep-learning\ntools. Here, for the first time, we show that dense 3D depth maps of observed\n2D natural images can also be recovered directly from fMRI brain recordings. We\nuse an off-the-shelf method to estimate the unknown depth maps of natural\nimages. This is applied to both: (i) the small number of images presented to\nsubjects in an fMRI scanner (images for which we have fMRI recordings -\nreferred to as \"paired\" data), and (ii) a very large number of natural images\nwith no fMRI recordings (\"unpaired data\"). The estimated depth maps are then\nused as an auxiliary reconstruction criterion to train for depth reconstruction\ndirectly from fMRI. We propose two main approaches: Depth-only recovery and\njoint image-depth RGBD recovery. Because the number of available \"paired\"\ntraining data (images with fMRI) is small, we enrich the training data via\nself-supervised cycle-consistent training on many \"unpaired\" data (natural\nimages & depth maps without fMRI). This is achieved using our newly defined and\ntrained Depth-based Perceptual Similarity metric as a reconstruction criterion.\nWe show that predicting the depth map directly from fMRI outperforms its\nindirect sequential recovery from the reconstructed images. We further show\nthat activations from early cortical visual areas dominate our depth\nreconstruction results, and propose means to characterize fMRI voxels by their\ndegree of depth-information tuning. This work adds an important layer of\ndecoded information, extending the current envelope of visual brain decoding\ncapabilities.",
          "link": "http://arxiv.org/abs/2106.05113",
          "publishedOn": "2021-06-10T01:56:48.250Z",
          "wordCount": 696,
          "title": "More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04985",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dai_B/0/1/0/all/0/1\">Ben Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_X/0/1/0/all/0/1\">Xiaotong Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pan_W/0/1/0/all/0/1\">Wei Pan</a>",
          "description": "An exciting recent development is the uptake of deep learning in many\nscientific fields, where the objective is seeking novel scientific insights and\ndiscoveries. To interpret a learning outcome, researchers perform hypothesis\ntesting for explainable features to advance scientific domain knowledge. In\nsuch a situation, testing for a blackbox learner poses a severe challenge\nbecause of intractable models, unknown limiting distributions of parameter\nestimates, and high computational constraints. In this article, we derive two\nconsistent tests for the feature relevance of a blackbox learner. The first one\nevaluates a loss difference with perturbation on an inference sample, which is\nindependent of an estimation sample used for parameter estimation in model\nfitting. The second further splits the inference sample into two but does not\nrequire data perturbation. Also, we develop their combined versions by\naggregating the order statistics of the $p$-values based on repeated sample\nsplitting. To estimate the splitting ratio and the perturbation size, we\ndevelop adaptive splitting schemes for suitably controlling the Type \\rom{1}\nerror subject to computational constraints. By deflating the\n\\textit{bias-sd-ratio}, we establish asymptotic null distributions of the test\nstatistics and their consistency in terms of statistical power. Our theoretical\npower analysis and simulations indicate that the one-split test is more\npowerful than the two-split test, though the latter is easier to apply for\nlarge datasets. Moreover, the combined tests are more stable while compensating\nfor a power loss by repeated sample splitting. Numerically, we demonstrate the\nutility of the proposed tests on two benchmark examples. Accompanying this\npaper is our Python library {\\tt dnn-inference}\nhttps://dnn-inference.readthedocs.io/en/latest/ that implements the proposed\ntests.",
          "link": "http://arxiv.org/abs/2103.04985",
          "publishedOn": "2021-06-10T01:56:48.211Z",
          "wordCount": 713,
          "title": "Significance tests of feature relevance for a blackbox learner. (arXiv:2103.04985v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimerman_I/0/1/0/all/0/1\">Itamar Zimerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1\">Eliya Nachmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Cold boot attacks inspect the corrupted random access memory soon after the\npower has been shut down. While most of the bits have been corrupted, many\nbits, at random locations, have not. Since the keys in many encryption schemes\nare being expanded in memory into longer keys with fixed redundancies, the keys\ncan often be restored. In this work, we combine a novel cryptographic variant\nof a deep error correcting code technique with a modified SAT solver scheme to\napply the attack on AES keys. Even though AES consists of Rijndael S-box\nelements, that are specifically designed to be resistant to linear and\ndifferential cryptanalysis, our method provides a novel formalization of the\nAES key scheduling as a computational graph, which is implemented by a neural\nmessage passing network. Our results show that our methods outperform the state\nof the art attack methods by a very large margin.",
          "link": "http://arxiv.org/abs/2106.04876",
          "publishedOn": "2021-06-10T01:56:48.205Z",
          "wordCount": 588,
          "title": "Recovering AES Keys with a Deep Cold Boot Attack. (arXiv:2106.04876v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11802",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kirschner_J/0/1/0/all/0/1\">Johannes Kirschner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>",
          "description": "We consider Bayesian optimization in settings where observations can be\nadversarially biased, for example by an uncontrolled hidden confounder. Our\nfirst contribution is a reduction of the confounded setting to the dueling\nbandit model. Then we propose a novel approach for dueling bandits based on\ninformation-directed sampling (IDS). Thereby, we obtain the first efficient\nkernelized algorithm for dueling bandits that comes with cumulative regret\nguarantees. Our analysis further generalizes a previously proposed\nsemi-parametric linear bandit model to non-linear reward functions, and\nuncovers interesting links to doubly-robust estimation.",
          "link": "http://arxiv.org/abs/2105.11802",
          "publishedOn": "2021-06-10T01:56:48.182Z",
          "wordCount": 524,
          "title": "Bias-Robust Bayesian Optimization via Dueling Bandits. (arXiv:2105.11802v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yue Ning</a>",
          "description": "Electronic Health Records (EHR) have been heavily used in modern healthcare\nsystems for recording patients' admission information to hospitals. Many\ndata-driven approaches employ temporal features in EHR for predicting specific\ndiseases, readmission times, or diagnoses of patients. However, most existing\npredictive models cannot fully utilize EHR data, due to an inherent lack of\nlabels in supervised training for some temporal events. Moreover, it is hard\nfor existing works to simultaneously provide generic and personalized\ninterpretability. To address these challenges, we first propose a hyperbolic\nembedding method with information flow to pre-train medical code\nrepresentations in a hierarchical structure. We incorporate these pre-trained\nrepresentations into a graph neural network to detect disease complications,\nand design a multi-level attention method to compute the contributions of\nparticular diseases and admissions, thus enhancing personalized\ninterpretability. We present a new hierarchy-enhanced historical prediction\nproxy task in our self-supervised learning framework to fully utilize EHR data\nand exploit medical domain knowledge. We conduct a comprehensive set of\nexperiments and case studies on widely used publicly available EHR datasets to\nverify the effectiveness of our model. The results demonstrate our model's\nstrengths in both predictive tasks and interpretable abilities.",
          "link": "http://arxiv.org/abs/2106.04751",
          "publishedOn": "2021-06-10T01:56:48.177Z",
          "wordCount": 652,
          "title": "Self-Supervised Graph Learning with Hyperbolic Embedding for Temporal Health Event Prediction. (arXiv:2106.04751v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1\">Noam Wies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1\">Daniel Jannai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>",
          "description": "After their successful debut in natural language processing, Transformer\narchitectures are now becoming the de-facto standard in many domains. An\nobstacle for their deployment over new modalities is the architectural\nconfiguration: the optimal depth-to-width ratio has been shown to dramatically\nvary across data types (e.g., $10$x larger over images than over language). We\ntheoretically predict the existence of an embedding rank bottleneck that limits\nthe contribution of self-attention width to the Transformer expressivity. We\nthus directly tie the input vocabulary size and rank to the optimal\ndepth-to-width ratio, since a small vocabulary size or rank dictates an added\nadvantage of depth over width. We empirically demonstrate the existence of this\nbottleneck and its implications on the depth-to-width interplay of Transformer\narchitectures, linking the architecture variability across domains to the often\nglossed-over usage of different vocabulary sizes or embedding ranks in\ndifferent domains. As an additional benefit, our rank bottlenecking framework\nallows us to identify size redundancies of $25\\%-50\\%$ in leading NLP models\nsuch as ALBERT and T5.",
          "link": "http://arxiv.org/abs/2105.03928",
          "publishedOn": "2021-06-10T01:56:48.168Z",
          "wordCount": 632,
          "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingale_V/0/1/0/all/0/1\">Vaishali Ingale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1\">Anush Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adlakha_D/0/1/0/all/0/1\">Divit Adlakha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Krishan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Mohit Gupta</a>",
          "description": "This paper explores the idea of utilising Long Short-Term Memory neural\nnetworks (LSTMNN) for the generation of musical sequences in ABC notation. The\nproposed approach takes ABC notations from the Nottingham dataset and encodes\nit to be fed as input for the neural networks. The primary objective is to\ninput the neural networks with an arbitrary note, let the network process and\naugment a sequence based on the note until a good piece of music is produced.\nMultiple calibrations have been done to amend the parameters of the network for\noptimal generation. The output is assessed on the basis of rhythm, harmony, and\ngrammar accuracy.",
          "link": "http://arxiv.org/abs/2105.09046",
          "publishedOn": "2021-06-10T01:56:48.163Z",
          "wordCount": 573,
          "title": "Music Generation using Three-layered LSTM. (arXiv:2105.09046v3 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chaochao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhuai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jo&#x15b;e Miguel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Due to spurious correlations, machine learning systems often fail to\ngeneralize to environments whose distributions differ from the ones used at\ntraining time. Prior work addressing this, either explicitly or implicitly,\nattempted to find a data representation that has an invariant relationship with\nthe target. This is done by leveraging a diverse set of training environments\nto reduce the effect of spurious features and build an invariant predictor.\nHowever, these methods have generalization guarantees only when both data\nrepresentation and classifiers come from a linear model class. We propose\ninvariant Causal Representation Learning (iCaRL), an approach that enables\nout-of-distribution (OOD) generalization in the nonlinear setting (i.e.,\nnonlinear representations and nonlinear classifiers). It builds upon a\npractical and general assumption: the prior over the data representation (i.e.,\na set of latent variables encoding the data) given the target and the\nenvironment belongs to general exponential family distributions. Based on this,\nwe show that it is possible to identify the data representation up to simple\ntransformations. We also prove that all direct causes of the target can be\nfully discovered, which further enables us to obtain generalization guarantees\nin the nonlinear setting. Extensive experiments on both synthetic and\nreal-world datasets show that our approach outperforms a variety of baseline\nmethods. Finally, in the discussion, we further explore the aforementioned\nassumption and propose a more general hypothesis, called the Agnostic\nHypothesis: there exist a set of hidden causal factors affecting both inputs\nand outcomes. The Agnostic Hypothesis can provide a unifying view of machine\nlearning. More importantly, it can inspire a new direction to explore a general\ntheory for identifying hidden causal factors, which is key to enabling the OOD\ngeneralization guarantees.",
          "link": "http://arxiv.org/abs/2102.12353",
          "publishedOn": "2021-06-10T01:56:48.156Z",
          "wordCount": 737,
          "title": "Nonlinear Invariant Risk Minimization: A Causal Approach. (arXiv:2102.12353v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hengrui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1\">Zhihao Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_L/0/1/0/all/0/1\">Ling Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rui Song</a>",
          "description": "We consider the sequential decision optimization on the periodic environment,\nthat occurs in a wide variety of real-world applications when the data involves\nseasonality, such as the daily demand of drivers in ride-sharing and dynamic\ntraffic patterns in transportation. In this work, we focus on learning the\nstochastic periodic world by leveraging this seasonal law. To deal with the\ngeneral action space, we use the bandit based on Gaussian process (GP) as the\nbase model due to its flexibility and generality, and propose the Periodic-GP\nmethod with a temporal periodic kernel based on the upper confidence bound.\nTheoretically, we provide a new regret bound of the proposed method, by\nexplicitly characterizing the periodic kernel in the periodic stationary model.\nEmpirically, the proposed algorithm significantly outperforms the existing\nmethods in both synthetic data experiments and a real data application on\nMadrid traffic pollution.",
          "link": "http://arxiv.org/abs/2105.14422",
          "publishedOn": "2021-06-10T01:56:48.139Z",
          "wordCount": 602,
          "title": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits. (arXiv:2105.14422v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bokun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zhuoning Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "Recently, model-agnostic meta-learning (MAML) has garnered tremendous\nattention. However, stochastic optimization of MAML is still immature. Existing\nalgorithms for MAML are based on the ``episode\" idea by sampling a number of\ntasks and a number of data points for each sampled task at each iteration for\nupdating the meta-model. However, they either do not necessarily guarantee\nconvergence with a constant mini-batch size or require processing a larger\nnumber of tasks at every iteration, which is not viable for continual learning\nor cross-device federated learning where only a small number of tasks are\navailable per-iteration or per-round. This paper addresses these issues by (i)\nproposing efficient memory-based stochastic algorithms for MAML with a\ndiminishing convergence error, which only requires sampling a constant number\nof tasks and a constant number of examples per-task per-iteration; (ii)\nproposing communication-efficient distributed memory-based MAML algorithms for\npersonalized federated learning in both the cross-device (w/ client sampling)\nand the cross-silo (w/o client sampling) settings. The key novelty of the\nproposed algorithms is to maintain an individual personalized model (aka\nmemory) for each task besides the meta-model and only update them for the\nsampled tasks by a momentum method that incorporates historical updates at each\niteration. The theoretical results significantly improve the optimization\ntheory for MAML and the empirical results also corroborate the theory.",
          "link": "http://arxiv.org/abs/2106.04911",
          "publishedOn": "2021-06-10T01:56:48.128Z",
          "wordCount": 635,
          "title": "Memory-based Optimization Methods for Model-Agnostic Meta-Learning. (arXiv:2106.04911v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1\">Mehdi Cherti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>",
          "description": "Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws pointing to improvement of generalization and transfer with\nincreasing model and data size are incomplete and should be revised by taking\ninto account the type and proximity of the source and target data, to correctly\npredict the effect of model and data scale during pre-training on transfer.\nRemarkably, in full shot transfer to a large X-Ray chest imaging target\n(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms\nbest models pre-trained on large X-Ray chest imaging data. This indicates\npossibility to obtain high quality models for domain-specific transfer even\nwithout access to large domain-specific data, by pre-training instead on\ncomparably very large, generic source data.",
          "link": "http://arxiv.org/abs/2106.00116",
          "publishedOn": "2021-06-10T01:56:48.121Z",
          "wordCount": 742,
          "title": "Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_R/0/1/0/all/0/1\">Raghu Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Reinforcement learning is a powerful approach to learn behaviour through\ninteractions with an environment. However, behaviours are usually learned in a\npurely reactive fashion, where an appropriate action is selected based on an\nobservation. In this form, it is challenging to learn when it is necessary to\nexecute new decisions. This makes learning inefficient, especially in\nenvironments that need various degrees of fine and coarse control. To address\nthis, we propose a proactive setting in which the agent not only selects an\naction in a state but also for how long to commit to that action. Our TempoRL\napproach introduces skip connections between states and learns a skip-policy\nfor repeating the same action along these skips. We demonstrate the\neffectiveness of TempoRL on a variety of traditional and deep RL environments,\nshowing that our approach is capable of learning successful policies up to an\norder of magnitude faster than vanilla Q-learning.",
          "link": "http://arxiv.org/abs/2106.05262",
          "publishedOn": "2021-06-10T01:56:48.115Z",
          "wordCount": 573,
          "title": "TempoRL: Learning When to Act. (arXiv:2106.05262v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1\">Imanol Schlag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "We show the formal equivalence of linearised self-attention mechanisms and\nfast weight controllers from the early '90s, where a ``slow\" neural net learns\nby gradient descent to program the ``fast weights\" of another net through\nsequences of elementary programming instructions which are additive outer\nproducts of self-invented activation patterns (today called keys and values).\nSuch Fast Weight Programmers (FWPs) learn to manipulate the contents of a\nfinite memory and dynamically interact with it. We infer a memory capacity\nlimitation of recent linearised softmax attention variants, and replace the\npurely additive outer products by a delta rule-like programming instruction,\nsuch that the FWP can more easily learn to correct the current mapping from\nkeys to values. The FWP also learns to compute dynamically changing learning\nrates. We also propose a new kernel function to linearise attention which\nbalances simplicity and effectiveness. We conduct experiments on synthetic\nretrieval problems as well as standard machine translation and language\nmodelling tasks which demonstrate the benefits of our methods.",
          "link": "http://arxiv.org/abs/2102.11174",
          "publishedOn": "2021-06-10T01:56:48.101Z",
          "wordCount": 620,
          "title": "Linear Transformers Are Secretly Fast Weight Programmers. (arXiv:2102.11174v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_J/0/1/0/all/0/1\">Jens Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohler_G/0/1/0/all/0/1\">Gregor K&#xf6;hler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmerer_D/0/1/0/all/0/1\">David Zimmerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jager_P/0/1/0/all/0/1\">Paul F. J&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1\">Klaus H. Maier-Hein</a>",
          "description": "Neural Processes (NPs) are a family of conditional generative models that are\nable to model a distribution over functions, in a way that allows them to\nperform predictions at test time conditioned on a number of context points. A\nrecent addition to this family, Convolutional Conditional Neural Processes\n(ConvCNP), have shown remarkable improvement in performance over prior art, but\nwe find that they sometimes struggle to generalize when applied to time series\ndata. In particular, they are not robust to distribution shifts and fail to\nextrapolate observed patterns into the future. By incorporating a Gaussian\nProcess into the model, we are able to remedy this and at the same time improve\nperformance within distribution. As an added benefit, the Gaussian Process\nreintroduces the possibility to sample from the model, a key feature of other\nmembers in the NP family.",
          "link": "http://arxiv.org/abs/2106.04967",
          "publishedOn": "2021-06-10T01:56:48.079Z",
          "wordCount": 588,
          "title": "GP-ConvCNP: Better Generalization for Convolutional Conditional Neural Processes on Time Series Data. (arXiv:2106.04967v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose mRASP2, a\ntraining method to obtain a single unified multilingual translation model.\nmRASP2 is empowered by two techniques: a) a contrastive learning scheme to\nclose the gap among representations of different languages, and b) data\naugmentation on both multiple parallel and monolingual data to further align\ntoken representations. For English-centric directions, mRASP2 outperforms\nexisting best unified model and achieves competitive or even better performance\nthan the pre-trained and fine-tuned model mBART on tens of WMT's translation\ndirections. For non-English directions, mRASP2 achieves an improvement of\naverage 10+ BLEU compared with the multilingual Transformer baseline. Code,\ndata and trained models are available at https://github.com/PANXiao1994/mRASP2.",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-06-10T01:56:48.073Z",
          "wordCount": 627,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1\">Sourav De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hoang-Hiep Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_B/0/1/0/all/0/1\">Bo-Han Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baig_M/0/1/0/all/0/1\">Md. Aftab Baig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_P/0/1/0/all/0/1\">Po-Jung Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chung Jun Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yao-Jen Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Darsen D. Lu</a>",
          "description": "A synergistic approach for optimizing devices, circuits, and neural network\narchitectures was used to abate junction-temperature-change-induced performance\ndegradation of a Fe-FinFET-based artificial neural network. We demonstrated\nthat the digital nature of the binarized neural network, with the \"0\" state\nprogrammed deep in the subthreshold and the \"1\" state in strong inversion, is\ncrucial for robust DNN inference. The performance of a purely software-based\nbinary neural network (BNN), with 96.1% accuracy for Modified National\nInstitute of Standards and Technology (MNIST) handwritten digit recognition,\nwas used as a baseline. The Fe-FinFET-based BNN (including device-to-device\nvariation at 300 K) achieved 95.7% inference accuracy on the MNIST dataset.\nAlthough substantial inference accuracy degradation with temperature change was\nobserved in a nonbinary neural network, the BNN with optimized Fe-FinFETs as\nsynaptic devices had excellent resistance to temperature change effects and\nmaintained a minimum inference accuracy of 95.2% within a temperature range of\n-233K to 398K after gate stack and bias optimization. However, reprogramming to\nadjust device conductance was necessary for temperatures higher than 398K.",
          "link": "http://arxiv.org/abs/2103.03111",
          "publishedOn": "2021-06-10T01:56:48.067Z",
          "wordCount": 669,
          "title": "Robust Binary Neural Network Operation from 233 K to 398 K via Gate Stack and Bias Optimization of Ferroelectric FinFET Synapses. (arXiv:2103.03111v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thiede_E/0/1/0/all/0/1\">Erik Henning Thiede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenda Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We introduce Automorphism-based graph neural networks (Autobahn), a new\nfamily of graph neural networks. In an Autobahn, we decompose the graph into a\ncollection of subgraphs and apply local convolutions that are equivariant to\neach subgraph's automorphism group. Specific choices of local neighborhoods and\nsubgraphs recover existing architectures such as message passing neural\nnetworks. Our formalism also encompasses novel architectures: as an example, we\nintroduce a graph neural network that decomposes the graph into paths and\ncycles. The resulting convolutions reflect the natural way that parts of the\ngraph can transform, preserving the intuitive meaning of convolution without\nsacrificing global permutation equivariance. We validate our approach by\napplying Autobahn to molecular graphs, where it achieves state-of-the-art\nresults.",
          "link": "http://arxiv.org/abs/2103.01710",
          "publishedOn": "2021-06-10T01:56:48.061Z",
          "wordCount": 566,
          "title": "Autobahn: Automorphism-based Graph Neural Nets. (arXiv:2103.01710v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05134",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1\">Rajdeep Kumar Nath</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1\">Himanshu Thapliyal</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1\">Travis S. Humble</a>",
          "description": "We present a novel methodology for automated feature subset selection from a\npool of physiological signals using Quantum Annealing (QA). As a case study, we\nwill investigate the effectiveness of QA-based feature selection techniques in\nselecting the optimal feature subset for stress detection. Features are\nextracted from four signal sources: foot EDA, hand EDA, ECG, and respiration.\nThe proposed method embeds the feature variables extracted from the\nphysiological signals in a binary quadratic model. The bias of the feature\nvariable is calculated using the Pearson correlation coefficient between the\nfeature variable and the target variable. The weight of the edge connecting the\ntwo feature variables is calculated using the Pearson correlation coefficient\nbetween two feature variables in the binary quadratic model. Subsequently,\nD-Wave's clique sampler is used to sample cliques from the binary quadratic\nmodel. The underlying solution is then re-sampled to obtain multiple good\nsolutions and the clique with the lowest energy is returned as the optimal\nsolution. The proposed method is compared with commonly used feature selection\ntechniques for stress detection. Results indicate that QA-based feature subset\nselection performed equally as that of classical techniques. However, under\ndata uncertainty conditions such as limited training data, the performance of\nquantum annealing for selecting optimum features remained unaffected, whereas a\nsignificant decrease in performance is observed with classical feature\nselection techniques. Preliminary results show the promise of quantum annealing\nin optimizing the training phase of a machine learning classifier, especially\nunder data uncertainty conditions.",
          "link": "http://arxiv.org/abs/2106.05134",
          "publishedOn": "2021-06-10T01:56:48.044Z",
          "wordCount": 693,
          "title": "Quantum Annealing for Automated Feature Selection in Stress Detection. (arXiv:2106.05134v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04929",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_D/0/1/0/all/0/1\">Diptesh Das</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1\">Vo Nguyen Le Duy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanada_H/0/1/0/all/0/1\">Hiroyuki Hanada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tsuda_K/0/1/0/all/0/1\">Koji Tsuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "Automated high-stake decision-making such as medical diagnosis requires\nmodels with high interpretability and reliability. As one of the interpretable\nand reliable models with good prediction ability, we consider Sparse High-order\nInteraction Model (SHIM) in this study. However, finding statistically\nsignificant high-order interactions is challenging due to the intrinsic high\ndimensionality of the combinatorial effects. Another problem in data-driven\nmodeling is the effect of \"cherry-picking\" a.k.a. selection bias. Our main\ncontribution is to extend the recently developed parametric programming\napproach for selective inference to high-order interaction models. Exhaustive\nsearch over the cherry tree (all possible interactions) can be daunting and\nimpractical even for a small-sized problem. We introduced an efficient pruning\nstrategy and demonstrated the computational efficiency and statistical power of\nthe proposed method using both synthetic and real data.",
          "link": "http://arxiv.org/abs/2106.04929",
          "publishedOn": "2021-06-10T01:56:48.038Z",
          "wordCount": 567,
          "title": "Fast and More Powerful Selective Inference for Sparse High-order Interaction Model. (arXiv:2106.04929v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1\">Lukas Tuggener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1\">Thilo Stadelmann</a>",
          "description": "An implicit but pervasive hypothesis of modern computer vision research is\nthat convolutional neural network (CNN) architectures that perform better on\nImageNet will also perform better on other vision datasets. We challenge this\nhypothesis through an extensive empirical study for which we train 500 sampled\nCNN architectures on ImageNet as well as 8 other image classification datasets\nfrom a wide array of application domains. The relationship between architecture\nand performance varies wildly, depending on the datasets. For some of them, the\nperformance correlation with ImageNet is even negative. Clearly, it is not\nenough to optimize architectures solely for ImageNet when aiming for progress\nthat is relevant for all applications. Therefore, we identify two\ndataset-specific performance indicators: the cumulative width across layers as\nwell as the total depth of the network. Lastly, we show that the range of\ndataset variability covered by ImageNet can be significantly extended by adding\nImageNet subsets restricted to few classes.",
          "link": "http://arxiv.org/abs/2103.09108",
          "publishedOn": "2021-06-10T01:56:48.032Z",
          "wordCount": 615,
          "title": "Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03452",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tran_Dinh_Q/0/1/0/all/0/1\">Quoc Tran-Dinh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pham_N/0/1/0/all/0/1\">Nhan H. Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Phan_D/0/1/0/all/0/1\">Dzung T. Phan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>",
          "description": "We develop two new algorithms, called, FedDR and asyncFedDR, for solving a\nfundamental nonconvex composite optimization problem in federated learning. Our\nalgorithms rely on a novel combination between a nonconvex Douglas-Rachford\nsplitting method, randomized block-coordinate strategies, and asynchronous\nimplementation. They can also handle convex regularizers. Unlike recent methods\nin the literature, e.g., FedSplit and FedPD, our algorithms update only a\nsubset of users at each communication round, and possibly in an asynchronous\nmanner, making them more practical. These new algorithms also achieve\ncommunication efficiency and more importantly can handle statistical and system\nheterogeneity, which are the two main challenges in federated learning. Our\nconvergence analysis shows that the new algorithms match the communication\ncomplexity lower bound up to a constant factor under standard assumptions. Our\nnumerical experiments illustrate the advantages of our methods compared to\nexisting ones on several datasets.",
          "link": "http://arxiv.org/abs/2103.03452",
          "publishedOn": "2021-06-10T01:56:48.027Z",
          "wordCount": 610,
          "title": "FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization. (arXiv:2103.03452v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herbert_T/0/1/0/all/0/1\">Tobias Herbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangler_J/0/1/0/all/0/1\">Juergen Mangler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1\">Stefanie Rinderle-Ma</a>",
          "description": "Domains such as manufacturing and medicine crave for continuous monitoring\nand analysis of their processes, especially in combination with time series as\nproduced by sensors. Time series data can be exploited to, for example, explain\nand predict concept drifts during runtime. Generally, a certain data volume is\nrequired in order to produce meaningful analysis results. However, reliable\ndata sets are often missing, for example, if event streams and times series\ndata are collected separately, in case of a new process, or if it is too\nexpensive to obtain a sufficient data volume. Additional challenges arise with\npreparing time series data from multiple event sources, variations in data\ncollection frequency, and concept drift. This paper proposes the GENLOG\napproach to generate reliable event and time series data that follows the\ndistribution of the underlying input data set. GENLOG employs data resampling\nand enables the user to select different parts of the log data to orchestrate\nthe training of a recurrent neural network for stream generation. The generated\ndata is sampled back to its original sample rate and is embedded into the\noriginating log data file. Overall, GENLOG can boost small data sets and\nconsequently the application of online process mining.",
          "link": "http://arxiv.org/abs/2103.05462",
          "publishedOn": "2021-06-10T01:56:48.021Z",
          "wordCount": 669,
          "title": "Generating Reliable Process Event Streams and Time Series Data based on Neural Networks. (arXiv:2103.05462v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1\">Jack Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langosco_L/0/1/0/all/0/1\">Lauro Langosco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfau_J/0/1/0/all/0/1\">Jacob Pfau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_J/0/1/0/all/0/1\">James Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharkey_L/0/1/0/all/0/1\">Lee Sharkey</a>",
          "description": "We study objective robustness failures, a type of out-of-distribution\nrobustness failure in reinforcement learning (RL). Objective robustness\nfailures occur when an RL agent retains its capabilities out-of-distribution\nyet pursues the wrong objective. This kind of failure presents different risks\nthan the robustness problems usually considered in the literature, since it\ninvolves agents that leverage their capabilities to pursue the wrong objective\nrather than simply failing to do anything useful. We provide the first explicit\nempirical demonstrations of objective robustness failures and present a partial\ncharacterization of its causes.",
          "link": "http://arxiv.org/abs/2105.14111",
          "publishedOn": "2021-06-10T01:56:48.015Z",
          "wordCount": 537,
          "title": "Objective Robustness in Deep Reinforcement Learning. (arXiv:2105.14111v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramabathiran_A/0/1/0/all/0/1\">Amuthan A. Ramabathiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1\">Prabhu Ramachandran</a>",
          "description": "We introduce a class of Sparse, Physics-based, and Interpretable Neural\nNetworks (SPINN) for solving ordinary and partial differential equations\n(PDEs). By reinterpreting a traditional meshless representation of solutions of\nPDEs we develop a class of sparse neural network architectures that are\ninterpretable. The SPINN model we propose here serves as a seamless bridge\nbetween two extreme modeling tools for PDEs, namely dense neural network based\nmethods like Physics Informed Neural Networks (PINNs) and traditional mesh-free\nnumerical methods, thereby providing a novel means to develop a new class of\nhybrid algorithms that build on the best of both these viewpoints. A unique\nfeature of the SPINN model that distinguishes it from other neural network\nbased approximations proposed earlier is that it is (i) interpretable, and (ii)\nsparse in the sense that it has much fewer connections than typical dense\nneural networks used for PDEs. Further, the SPINN algorithm implicitly encodes\nmesh adaptivity and is able to handle discontinuities in the solutions. In\naddition, we demonstrate that Fourier series representations can also be\nexpressed as a special class of SPINN and propose generalized neural network\nanalogues of Fourier representations. We illustrate the utility of the proposed\nmethod with a variety of examples involving ordinary differential equations,\nelliptic, parabolic, hyperbolic and nonlinear partial differential equations,\nand an example in fluid dynamics.",
          "link": "http://arxiv.org/abs/2102.13037",
          "publishedOn": "2021-06-10T01:56:47.998Z",
          "wordCount": 688,
          "title": "SPINN: Sparse, Physics-based, and Interpretable Neural Networks for PDEs. (arXiv:2102.13037v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04886",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Both_G/0/1/0/all/0/1\">Gert-Jan Both</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kusters_R/0/1/0/all/0/1\">Remy Kusters</a>",
          "description": "Model discovery aims at autonomously discovering differential equations\nunderlying a dataset. Approaches based on Physics Informed Neural Networks\n(PINNs) have shown great promise, but a fully-differentiable model which\nexplicitly learns the equation has remained elusive. In this paper we propose\nsuch an approach by combining neural network based surrogates with Sparse\nBayesian Learning (SBL). We start by reinterpreting PINNs as multitask models,\napplying multitask learning using uncertainty, and show that this leads to a\nnatural framework for including Bayesian regression techniques. We then\nconstruct a robust model discovery algorithm by using SBL, which we showcase on\nvarious datasets. Concurrently, the multitask approach allows the use of\nprobabilistic approximators, and we show a proof of concept using normalizing\nflows to directly learn a density model from single particle data. Our work\nexpands PINNs to various types of neural network architectures, and connects\nneural network-based surrogates to the rich field of Bayesian parameter\ninference.",
          "link": "http://arxiv.org/abs/2106.04886",
          "publishedOn": "2021-06-10T01:56:47.992Z",
          "wordCount": 568,
          "title": "Fully differentiable model discovery. (arXiv:2106.04886v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1\">Albert No</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1\">TaeHo Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Sehyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_E/0/1/0/all/0/1\">Ernest K. Ryu</a>",
          "description": "Generative adversarial networks (GAN) are a widely used class of deep\ngenerative models, but their minimax training dynamics are not understood very\nwell. In this work, we show that GANs with a 2-layer infinite-width generator\nand a 2-layer finite-width discriminator trained with stochastic gradient\nascent-descent have no spurious stationary points. We then show that when the\nwidth of the generator is finite but wide, there are no spurious stationary\npoints within a ball whose radius becomes arbitrarily large (to cover the\nentire parameter space) as the width goes to infinity.",
          "link": "http://arxiv.org/abs/2102.07541",
          "publishedOn": "2021-06-10T01:56:47.983Z",
          "wordCount": 559,
          "title": "WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points. (arXiv:2102.07541v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1\">Dylan R. Ashley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning and supervised learning\nliterature to (1) provide evidence that the choice of which modern\ngradient-based optimization algorithm is used to train an ANN has a significant\nimpact on the amount of catastrophic forgetting and show that-surprisingly-in\nmany instances classical algorithms such as vanilla SGD experience less\ncatastrophic forgetting than the more modern algorithms such as Adam. We\nempirically compare four different existing metrics for quantifying\ncatastrophic forgetting and (2) show that the degree to which the learning\nsystems experience catastrophic forgetting is sufficiently sensitive to the\nmetric used that a change from one principled metric to another is enough to\nchange the conclusions of a study dramatically. Our results suggest that a much\nmore rigorous experimental methodology is required when looking at catastrophic\nforgetting. Based on our results, we recommend inter-task forgetting in\nsupervised learning must be measured with both retention and relearning metrics\nconcurrently, and intra-task forgetting in reinforcement learning must-at the\nvery least-be measured with pairwise interference.",
          "link": "http://arxiv.org/abs/2102.07686",
          "publishedOn": "2021-06-10T01:56:47.976Z",
          "wordCount": 753,
          "title": "Does the Adam Optimizer Exacerbate Catastrophic Forgetting?. (arXiv:2102.07686v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wilkinson_W/0/1/0/all/0/1\">William J. Wilkinson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1\">Arno Solin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Adam_V/0/1/0/all/0/1\">Vincent Adam</a>",
          "description": "Approximate Bayesian inference methods that scale to very large datasets are\ncrucial in leveraging probabilistic models for real-world time series. Sparse\nMarkovian Gaussian processes combine the use of inducing variables with\nefficient Kalman filter-like recursions, resulting in algorithms whose\ncomputational and memory requirements scale linearly in the number of inducing\npoints, whilst also enabling parallel parameter updates and stochastic\noptimisation. Under this paradigm, we derive a general site-based approach to\napproximate inference, whereby we approximate the non-Gaussian likelihood with\nlocal Gaussian terms, called sites. Our approach results in a suite of novel\nsparse extensions to algorithms from both the machine learning and signal\nprocessing literature, including variational inference, expectation\npropagation, and the classical nonlinear Kalman smoothers. The derived methods\nare suited to large time series, and we also demonstrate their applicability to\nspatio-temporal data, where the model has separate inducing points in both time\nand space.",
          "link": "http://arxiv.org/abs/2103.10710",
          "publishedOn": "2021-06-10T01:56:47.970Z",
          "wordCount": 609,
          "title": "Sparse Algorithms for Markovian Gaussian Processes. (arXiv:2103.10710v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04923",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Andeol_L/0/1/0/all/0/1\">L&#xe9;o And&#xe9;ol</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kawakami_Y/0/1/0/all/0/1\">Yusei Kawakami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wada_Y/0/1/0/all/0/1\">Yuichiro Wada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanamori_T/0/1/0/all/0/1\">Takafumi Kanamori</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montavon_G/0/1/0/all/0/1\">Gr&#xe9;goire Montavon</a>",
          "description": "Domain shifts in the training data are common in practical applications of\nmachine learning, they occur for instance when the data is coming from\ndifferent sources. Ideally, a ML model should work well independently of these\nshifts, for example, by learning a domain-invariant representation. Moreover,\nprivacy concerns regarding the source also require a domain-invariant\nrepresentation. In this work, we provide theoretical results that link domain\ninvariant representations -- measured by the Wasserstein distance on the joint\ndistributions -- to a practical semi-supervised learning objective based on a\ncross-entropy classifier and a novel domain critic. Quantitative experiments\ndemonstrate that the proposed approach is indeed able to practically learn such\nan invariant representation (between two domains), and the latter also supports\nmodels with higher predictive accuracy on both domains, comparing favorably to\nexisting techniques.",
          "link": "http://arxiv.org/abs/2106.04923",
          "publishedOn": "2021-06-10T01:56:47.955Z",
          "wordCount": 573,
          "title": "Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization. (arXiv:2106.04923v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_Z/0/1/0/all/0/1\">Zi-Qiang Lang</a>",
          "description": "An Orthogonal Least Squares (OLS) based feature selection method is proposed\nfor both binomial and multinomial classification. The novel Squared Orthogonal\nCorrelation Coefficient (SOCC) is defined based on Error Reduction Ratio (ERR)\nin OLS and used as the feature ranking criterion. The equivalence between the\ncanonical correlation coefficient, Fisher's criterion, and the sum of the SOCCs\nis revealed, which unveils the statistical implication of ERR in OLS for the\nfirst time. It is also shown that the OLS based feature selection method has\nspeed advantages when applied for greedy search. The proposed method is\ncomprehensively compared with the mutual information based feature selection\nmethods in 2 synthetic and 7 real world datasets. The results show that the\nproposed method is always in the top 5 among the 10 candidate methods. Besides,\nthe proposed method can be directly applied to continuous features without\ndiscretisation, which is another significant advantage over mutual information\nbased methods.",
          "link": "http://arxiv.org/abs/2101.08539",
          "publishedOn": "2021-06-10T01:56:47.944Z",
          "wordCount": 608,
          "title": "Orthogonal Least Squares Based Fast Feature Selection for Linear Classification. (arXiv:2101.08539v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quyu Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Cheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Hawkes processes are a class of point processes that have the ability to\nmodel the self- and mutual-exciting phenomena. Although the classic Hawkes\nprocesses cover a wide range of applications, their expressive ability is\nlimited due to three key hypotheses: parametric, linear and homogeneous. Recent\nwork has attempted to address these limitations separately. This work aims to\novercome all three assumptions simultaneously by proposing the flexible\nstate-switching Hawkes processes: a flexible, nonlinear and nonhomogeneous\nvariant where a state process is incorporated to interact with the point\nprocesses. The proposed model empowers Hawkes processes to be applied to\ntime-varying systems. For inference, we utilize the latent variable\naugmentation technique to design two efficient Bayesian inference algorithms:\nGibbs sampler and mean-field variational inference, with analytical iterative\nupdates to estimate the posterior. In experiments, our model achieves superior\nperformance compared to the state-of-the-art competitors.",
          "link": "http://arxiv.org/abs/2106.04844",
          "publishedOn": "2021-06-10T01:56:47.938Z",
          "wordCount": 568,
          "title": "Nonlinear Hawkes Processes in Time-Varying System. (arXiv:2106.04844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreu_J/0/1/0/all/0/1\">Jos&#xe9; M. Moreu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Annaswamy_A/0/1/0/all/0/1\">Anuradha M. Annaswamy</a>",
          "description": "Iterative gradient-based algorithms have been increasingly applied for the\ntraining of a broad variety of machine learning models including large\nneural-nets. In particular, momentum-based methods, with accelerated learning\nguarantees, have received a lot of attention due to their provable guarantees\nof fast learning in certain classes of problems and multiple algorithms have\nbeen derived. However, properties for these methods hold only for constant\nregressors. When time-varying regressors occur, which is commonplace in dynamic\nsystems, many of these momentum-based methods cannot guarantee stability.\nRecently, a new High-order Tuner (HT) was developed for linear regression\nproblems and shown to have 1) stability and asymptotic convergence for\ntime-varying regressors and 2) non-asymptotic accelerated learning guarantees\nfor constant regressors. In this paper, we extend and discuss the results of\nthis same HT for general convex loss functions. Through the exploitation of\nconvexity and smoothness definitions, we establish similar stability and\nasymptotic convergence guarantees. Finally, we provide numerical simulations\nsupporting the satisfactory behavior of the HT algorithm as well as an\naccelerated learning property.",
          "link": "http://arxiv.org/abs/2011.09996",
          "publishedOn": "2021-06-10T01:56:47.930Z",
          "wordCount": 653,
          "title": "A Stable High-order Tuner for General Convex Functions. (arXiv:2011.09996v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1\">Kevin D. McCay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1\">Dimitrios Sakkos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1\">Claire Marcroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1\">Patricia Dulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1\">Nicholas D. Embleton</a>",
          "description": "Providing early diagnosis of cerebral palsy (CP) is key to enhancing the\ndevelopmental outcomes for those affected. Diagnostic tools such as the General\nMovements Assessment (GMA), have produced promising results in early diagnosis,\nhowever these manual methods can be laborious.\n\nIn this paper, we propose a new framework for the automated classification of\ninfant body movements, based upon the GMA, which unlike previous methods, also\nincorporates a visualization framework to aid with interpretability. Our\nproposed framework segments extracted features to detect the presence of\nFidgety Movements (FMs) associated with the GMA spatiotemporally. These\nfeatures are then used to identify the body-parts with the greatest\ncontribution towards a classification decision and highlight the related\nbody-part segment providing visual feedback to the user.\n\nWe quantitatively compare the proposed framework's classification performance\nwith several other methods from the literature and qualitatively evaluate the\nvisualization's veracity. Our experimental results show that the proposed\nmethod performs more robustly than comparable techniques in this setting whilst\nsimultaneously providing relevant visual interpretability.",
          "link": "http://arxiv.org/abs/2106.04966",
          "publishedOn": "2021-06-10T01:56:47.924Z",
          "wordCount": 645,
          "title": "Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1\">Matej Grci&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Normalizing flows are bijective mappings between inputs and latent\nrepresentations with a fully factorized distribution. They are very attractive\ndue to exact likelihood evaluation and efficient sampling. However, their\neffective capacity is often insufficient since the bijectivity constraint\nlimits the model width. We address this issue by incrementally padding\nintermediate representations with noise. We precondition the noise in\naccordance with previous invertible units, which we describe as cross-unit\ncoupling. Our invertible glow-like modules express intra-unit affine coupling\nas a fusion of a densely connected block and Nystr\\\"om self-attention. We refer\nto our architecture as DenseFlow since both cross-unit and intra-unit couplings\nrely on dense connectivity. Experiments show significant improvements due to\nthe proposed contributions, and reveal state-of-the-art density estimation\namong all generative models under moderate computing budgets.",
          "link": "http://arxiv.org/abs/2106.04627",
          "publishedOn": "2021-06-10T01:56:47.907Z",
          "wordCount": 551,
          "title": "Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We consider tracking adversarial targets in a delayed time-varying linear\nsystem with adversarial disturbances and loss functions, which significantly\ngeneralizes earlier work. To this end, we develop three techniques that each\ncould be of independent interest. First, we propose a black-box reduction from\nadversarial tracking control to strongly adaptive online learning with memory.\nAny solution to the latter translates to a tracking controller that pursues the\nbest action on any time interval. Second, for the resulting online learning\nproblem we develop a novel approach that further adapts to the observed\ngradients. Third, we propose a new algorithm for unconstrained online linear\noptimization: for all (unknown) $T\\in\\mathbb{N}_+$, the cumulative loss and\nmovement on the time horizon $[1:T]$ is upper-bounded by a user-specified\nconstant. Combining these individual techniques, we propose a tracking\ncontroller with a sensible performance guarantee even when the adversarial\ntarget has a large range of movement.",
          "link": "http://arxiv.org/abs/2102.01623",
          "publishedOn": "2021-06-10T01:56:47.902Z",
          "wordCount": 609,
          "title": "Adversarial Tracking Control via Strongly Adaptive Online Learning with Memory. (arXiv:2102.01623v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1\">Sameera Ramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_K/0/1/0/all/0/1\">Kasun Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>",
          "description": "Modeling real-world distributions can often be challenging due to sample data\nthat are subjected to perturbations, e.g., instrumentation errors, or added\nrandom noise. Since flow models are typically nonlinear algorithms, they\namplify these initial errors, leading to poor generalizations. This paper\nproposes a framework to construct Normalizing Flows (NF), which demonstrates\nhigher robustness against such initial errors. To this end, we utilize\nBernstein-type polynomials inspired by the optimal stability of the Bernstein\nbasis. Further, compared to the existing NF frameworks, our method provides\ncompelling advantages like theoretical upper bounds for the approximation\nerror, higher interpretability, suitability for compactly supported densities,\nand the ability to employ higher degree polynomials without training\ninstability. We conduct a thorough theoretical analysis and empirically\ndemonstrate the efficacy of the proposed technique using experiments on both\nreal-world and synthetic datasets.",
          "link": "http://arxiv.org/abs/2102.03509",
          "publishedOn": "2021-06-10T01:56:47.896Z",
          "wordCount": 588,
          "title": "Robust normalizing flows using Bernstein-type polynomials. (arXiv:2102.03509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Recent theoretical work studies sample-efficient reinforcement learning (RL)\nextensively in two settings: learning interactively in the environment (online\nRL), or learning from an offline dataset (offline RL). However, existing\nalgorithms and theories for learning near-optimal policies in these two\nsettings are rather different and disconnected. Towards bridging this gap, this\npaper initiates the theoretical study of policy finetuning, that is, online RL\nwhere the learner has additional access to a \"reference policy\" $\\mu$ close to\nthe optimal policy $\\pi_\\star$ in a certain sense. We consider the policy\nfinetuning problem in episodic Markov Decision Processes (MDPs) with $S$\nstates, $A$ actions, and horizon length $H$. We first design a sharp offline\nreduction algorithm -- which simply executes $\\mu$ and runs offline policy\noptimization on the collected dataset -- that finds an $\\varepsilon$\nnear-optimal policy within $\\widetilde{O}(H^3SC^\\star/\\varepsilon^2)$ episodes,\nwhere $C^\\star$ is the single-policy concentrability coefficient between $\\mu$\nand $\\pi_\\star$. This offline result is the first that matches the sample\ncomplexity lower bound in this setting, and resolves a recent open question in\noffline RL. We then establish an $\\Omega(H^3S\\min\\{C^\\star, A\\}/\\varepsilon^2)$\nsample complexity lower bound for any policy finetuning algorithm, including\nthose that can adaptively explore the environment. This implies that -- perhaps\nsurprisingly -- the optimal policy finetuning algorithm is either offline\nreduction or a purely online RL algorithm that does not use $\\mu$. Finally, we\ndesign a new hybrid offline/online algorithm for policy finetuning that\nachieves better sample complexity than both vanilla offline reduction and\npurely online RL algorithms, in a relaxed setting where $\\mu$ only satisfies\nconcentrability partially up to a certain time step.",
          "link": "http://arxiv.org/abs/2106.04895",
          "publishedOn": "2021-06-10T01:56:47.890Z",
          "wordCount": 698,
          "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning. (arXiv:2106.04895v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1\">Max Schwarzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajkumar_N/0/1/0/all/0/1\">Nitarshan Rajkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noukhovitch_M/0/1/0/all/0/1\">Michael Noukhovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Ankesh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charlin_L/0/1/0/all/0/1\">Laurent Charlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1\">Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1\">Philip Bachman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Data efficiency is a key challenge for deep reinforcement learning. We\naddress this problem by using unlabeled data to pretrain an encoder which is\nthen finetuned on a small amount of task-specific data. To encourage learning\nrepresentations which capture diverse aspects of the underlying MDP, we employ\na combination of latent dynamics modelling and unsupervised goal-conditioned\nRL. When limited to 100k steps of interaction on Atari games (equivalent to two\nhours of human experience), our approach significantly surpasses prior work\ncombining offline representation pretraining with task-specific finetuning, and\ncompares favourably with other pretraining methods that require orders of\nmagnitude more data. Our approach shows particular promise when combined with\nlarger models as well as more diverse, task-aligned observational data --\napproaching human-level performance and data-efficiency on Atari in our best\nsetting. We provide code associated with this work at\nhttps://github.com/mila-iqia/SGI.",
          "link": "http://arxiv.org/abs/2106.04799",
          "publishedOn": "2021-06-10T01:56:47.884Z",
          "wordCount": 570,
          "title": "Pretraining Representations for Data-Efficient Reinforcement Learning. (arXiv:2106.04799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1\">Muhammad Bilal Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1\">Michele Donini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">C&#xe9;dric Archambeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sanjiv Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1\">Krishnaram Kenthapadi</a>",
          "description": "With the ever-increasing complexity of neural language models, practitioners\nhave turned to methods for understanding the predictions of these models. One\nof the most well-adopted approaches for model interpretability is feature-based\ninterpretability, i.e., ranking the features in terms of their impact on model\npredictions. Several prior studies have focused on assessing the fidelity of\nfeature-based interpretability methods, i.e., measuring the impact of dropping\nthe top-ranked features on the model output. However, relatively little work\nhas been conducted on quantifying the robustness of interpretations. In this\nwork, we assess the robustness of interpretations of neural text classifiers,\nspecifically, those based on pretrained Transformer encoders, using two\nrandomization tests. The first compares the interpretations of two models that\nare identical except for their initializations. The second measures whether the\ninterpretations differ between a model with trained parameters and a model with\nrandom parameters. Both tests show surprising deviations from expected\nbehavior, raising questions about the extent of insights that practitioners may\ndraw from interpretations.",
          "link": "http://arxiv.org/abs/2106.04631",
          "publishedOn": "2021-06-10T01:56:47.868Z",
          "wordCount": 608,
          "title": "On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "In ordinary distillation, student networks are trained with soft labels (SLs)\ngiven by pretrained teacher networks, and students are expected to improve upon\nteachers since SLs are stronger supervision than the original hard labels.\nHowever, when considering adversarial robustness, teachers may become\nunreliable and adversarial distillation may not work: teachers are pretrained\non their own adversarial data, and it is too demanding to require that teachers\nare also good at every adversarial data queried by students. Therefore, in this\npaper, we propose reliable introspective adversarial distillation (IAD) where\nstudents partially instead of fully trust their teachers. Specifically, IAD\ndistinguishes between three cases given a query of a natural data (ND) and the\ncorresponding adversarial data (AD): (a) if a teacher is good at AD, its SL is\nfully trusted; (b) if a teacher is good at ND but not AD, its SL is partially\ntrusted and the student also takes its own SL into account; (c) otherwise, the\nstudent only relies on its own SL. Experiments demonstrate the effectiveness of\nIAD for improving upon teachers in terms of adversarial robustness.",
          "link": "http://arxiv.org/abs/2106.04928",
          "publishedOn": "2021-06-10T01:56:47.861Z",
          "wordCount": 610,
          "title": "Reliable Adversarial Distillation with Unreliable Teachers. (arXiv:2106.04928v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Daniel T. Chang</a>",
          "description": "Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixture density networks (for probabilistic neural\nnetworks), and variational autoencoders, deep Gaussian processes and deep mixed\neffects models (for deep probabilistic models). TensorFlow Probability is a\nlibrary for probabilistic modeling and inference which can be used for both\napproaches of probabilistic deep learning. We include its code examples for\nillustration.",
          "link": "http://arxiv.org/abs/2106.00120",
          "publishedOn": "2021-06-10T01:56:47.856Z",
          "wordCount": 608,
          "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models. (arXiv:2106.00120v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungsoo Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hankook Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Retrosynthetic planning is a fundamental problem in chemistry for finding a\npathway of reactions to synthesize a target molecule. Recently, search\nalgorithms have shown promising results for solving this problem by using deep\nneural networks (DNNs) to expand their candidate solutions, i.e., adding new\nreactions to reaction pathways. However, the existing works on this line are\nsuboptimal; the retrosynthetic planning problem requires the reaction pathways\nto be (a) represented by real-world reactions and (b) executable using\n\"building block\" molecules, yet the DNNs expand reaction pathways without fully\nincorporating such requirements. Motivated by this, we propose an end-to-end\nframework for directly training the DNNs towards generating reaction pathways\nwith the desirable properties. Our main idea is based on a self-improving\nprocedure that trains the model to imitate successful trajectories found by\nitself. We also propose a novel reaction augmentation scheme based on a forward\nreaction model. Our experiments demonstrate that our scheme significantly\nimproves the success rate of solving the retrosynthetic problem from 86.84% to\n96.32% while maintaining the performance of DNN for predicting valid reactions.",
          "link": "http://arxiv.org/abs/2106.04880",
          "publishedOn": "2021-06-10T01:56:47.850Z",
          "wordCount": 599,
          "title": "Self-Improved Retrosynthetic Planning. (arXiv:2106.04880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maschler_B/0/1/0/all/0/1\">Benjamin Maschler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knodel_T/0/1/0/all/0/1\">Tim Knodel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1\">Michael Weyrich</a>",
          "description": "Deep learning promises performant anomaly detection on time-variant datasets,\nbut greatly suffers from low availability of suitable training datasets and\nfrequently changing tasks. Deep transfer learning offers mitigation by letting\nalgorithms built upon previous knowledge from different tasks or locations. In\nthis article, a modular deep learning algorithm for anomaly detection on time\nseries datasets is presented that allows for an easy integration of such\ntransfer learning capabilities. It is thoroughly tested on a dataset from a\ndiscrete manufacturing process in order to prove its fundamental adequacy\ntowards deep industrial transfer learning - the transfer of knowledge in\nindustrial applications' special environment.",
          "link": "http://arxiv.org/abs/2106.04920",
          "publishedOn": "2021-06-10T01:56:47.836Z",
          "wordCount": 549,
          "title": "Towards Deep Industrial Transfer Learning for Anomaly Detection on Time Series Data. (arXiv:2106.04920v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lino_M/0/1/0/all/0/1\">Mario Lino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cantwell_C/0/1/0/all/0/1\">Chris Cantwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bharath_A/0/1/0/all/0/1\">Anil A. Bharath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fotiadis_S/0/1/0/all/0/1\">Stathi Fotiadis</a>",
          "description": "Continuum mechanics simulators, numerically solving one or more partial\ndifferential equations, are essential tools in many areas of science and\nengineering, but their performance often limits application in practice. Recent\nmodern machine learning approaches have demonstrated their ability to\naccelerate spatio-temporal predictions, although, with only moderate accuracy\nin comparison. Here we introduce MultiScaleGNN, a novel multi-scale graph\nneural network model for learning to infer unsteady continuum mechanics.\nMultiScaleGNN represents the physical domain as an unstructured set of nodes,\nand it constructs one or more graphs, each of them encoding different scales of\nspatial resolution. Successive learnt message passing between these graphs\nimproves the ability of GNNs to capture and forecast the system state in\nproblems encompassing a range of length scales. Using graph representations,\nMultiScaleGNN can impose periodic boundary conditions as an inductive bias on\nthe edges in the graphs, and achieve independence to the nodes' positions. We\ndemonstrate this method on advection problems and incompressible fluid\ndynamics. Our results show that the proposed model can generalise from uniform\nadvection fields to high-gradient fields on complex domains at test time and\ninfer long-term Navier-Stokes solutions within a range of Reynolds numbers.\nSimulations obtained with MultiScaleGNN are between two and four orders of\nmagnitude faster than the ones on which it was trained.",
          "link": "http://arxiv.org/abs/2106.04900",
          "publishedOn": "2021-06-10T01:56:47.826Z",
          "wordCount": 641,
          "title": "Simulating Continuum Mechanics with Multi-Scale Graph Neural Networks. (arXiv:2106.04900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reichelt_T/0/1/0/all/0/1\">Tim Reichelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golinski_A/0/1/0/all/0/1\">Adam Goli&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1\">Luke Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "Building on ideas from probabilistic programming, we introduce the concept of\nan expectation programming framework (EPF) that automates the calculation of\nexpectations. Analogous to a probabilistic program, an expectation program is\ncomprised of a mix of probabilistic constructs and deterministic calculations\nthat define a conditional distribution over its variables. However, the focus\nof the inference engine in an EPF is to directly estimate the resulting\nexpectation of the program return values, rather than approximate the\nconditional distribution itself. This distinction allows us to achieve\nsubstantial performance improvements over the standard probabilistic\nprogramming pipeline by tailoring the inference to the precise expectation we\ncare about. We realize a particular instantiation of our EPF concept by\nextending the probabilistic programming language Turing to allow so-called\ntarget-aware inference to be run automatically, and show that this leads to\nsignificant empirical gains compared to conventional posterior-based inference.",
          "link": "http://arxiv.org/abs/2106.04953",
          "publishedOn": "2021-06-10T01:56:47.795Z",
          "wordCount": 558,
          "title": "Expectation Programming. (arXiv:2106.04953v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1\">David Berthelot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alex Kurakin</a>",
          "description": "We extend semi-supervised learning to the problem of domain adaptation to\nlearn significantly higher-accuracy models that train on one data distribution\nand test on a different one. With the goal of generality, we introduce\nAdaMatch, a method that unifies the tasks of unsupervised domain adaptation\n(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation\n(SSDA). In an extensive experimental study, we compare its behavior with\nrespective state-of-the-art techniques from SSL, SSDA, and UDA on vision\nclassification tasks. We find AdaMatch either matches or significantly exceeds\nthe state-of-the-art in each case using the same hyper-parameters regardless of\nthe dataset or task. For example, AdaMatch nearly doubles the accuracy compared\nto that of the prior state-of-the-art on the UDA task for DomainNet and even\nexceeds the accuracy of the prior state-of-the-art obtained with pre-training\nby 6.4% when AdaMatch is trained completely from scratch. Furthermore, by\nproviding AdaMatch with just one labeled example per class from the target\ndomain (i.e., the SSDA setting), we increase the target accuracy by an\nadditional 6.1%, and with 5 labeled examples, by 13.6%.",
          "link": "http://arxiv.org/abs/2106.04732",
          "publishedOn": "2021-06-10T01:56:47.788Z",
          "wordCount": 616,
          "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1\">Marco Bressan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1\">Silvio Lattanzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>",
          "description": "We study an active cluster recovery problem where, given a set of $n$ points\nand an oracle answering queries like \"are these two points in the same\ncluster?\", the task is to recover exactly all clusters using as few queries as\npossible. We begin by introducing a simple but general notion of margin between\nclusters that captures, as special cases, the margins used in previous work,\nthe classic SVM margin, and standard notions of stability for center-based\nclusterings. Then, under our margin assumptions we design algorithms that, in a\nvariety of settings, recover all clusters exactly using only $O(\\log n)$\nqueries. For the Euclidean case, $\\mathbb{R}^m$, we give an algorithm that\nrecovers arbitrary convex clusters, in polynomial time, and with a number of\nqueries that is lower than the best existing algorithm by $\\Theta(m^m)$\nfactors. For general pseudometric spaces, where clusters might not be convex or\nmight not have any notion of shape, we give an algorithm that achieves the\n$O(\\log n)$ query bound, and is provably near-optimal as a function of the\npacking number of the space. Finally, for clusterings realized by binary\nconcept classes, we give a combinatorial characterization of recoverability\nwith $O(\\log n)$ queries, and we show that, for many concept classes in\nEuclidean spaces, this characterization is equivalent to our margin condition.\nOur results show a deep connection between cluster margins and active cluster\nrecoverability.",
          "link": "http://arxiv.org/abs/2106.04913",
          "publishedOn": "2021-06-10T01:56:47.781Z",
          "wordCount": 657,
          "title": "On Margin-Based Cluster Recovery with Oracle Queries. (arXiv:2106.04913v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinlei Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuxian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lihua Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1\">Tianyou Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "This paper considers online convex optimization with long term constraints,\nwhere constraints can be violated in intermediate rounds, but need to be\nsatisfied in the long run. The cumulative constraint violation is used as the\nmetric to measure constraint violations, which excludes the situation that\nstrictly feasible constraints can compensate the effects of violated\nconstraints. A novel algorithm is first proposed and it achieves an\n$\\mathcal{O}(T^{\\max\\{c,1-c\\}})$ bound for static regret and an\n$\\mathcal{O}(T^{(1-c)/2})$ bound for cumulative constraint violation, where\n$c\\in(0,1)$ is a user-defined trade-off parameter, and thus has improved\nperformance compared with existing results. Both static regret and cumulative\nconstraint violation bounds are reduced to $\\mathcal{O}(\\log(T))$ when the loss\nfunctions are strongly convex, which also improves existing results. %In order\nto bound the regret with respect to any comparator sequence, In order to\nachieve the optimal regret with respect to any comparator sequence, another\nalgorithm is then proposed and it achieves the optimal\n$\\mathcal{O}(\\sqrt{T(1+P_T)})$ regret and an $\\mathcal{O}(\\sqrt{T})$ cumulative\nconstraint violation, where $P_T$ is the path-length of the comparator\nsequence. Finally, numerical simulations are provided to illustrate the\neffectiveness of the theoretical results.",
          "link": "http://arxiv.org/abs/2106.05135",
          "publishedOn": "2021-06-10T01:56:47.764Z",
          "wordCount": 631,
          "title": "Regret and Cumulative Constraint Violation Analysis for Online Convex Optimization with Long Term Constraints. (arXiv:2106.05135v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1\">Nicolai Pogrebnyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1\">Shohreh Shaghaghian</a>",
          "description": "Transfer learning methods, and in particular domain adaptation, help exploit\nlabeled data in one domain to improve the performance of a certain task in\nanother domain. However, it is still not clear what factors affect the success\nof domain adaptation. This paper models adaptation success and selection of the\nmost suitable source domains among several candidates in text similarity. We\nuse descriptive domain information and cross-domain similarity metrics as\npredictive features. While mostly positive, the results also point to some\ndomains where adaptation success was difficult to predict.",
          "link": "http://arxiv.org/abs/2106.04641",
          "publishedOn": "2021-06-10T01:56:47.731Z",
          "wordCount": 520,
          "title": "Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1\">Qi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sujit K. Ghosh</a>",
          "description": "High dimensional incomplete data can be found in a wide range of systems. Due\nto the fact that most of the data mining techniques and machine learning\nalgorithms require complete observations, data imputation is vital for\ndown-stream analysis. In this work, we introduce an imputation approach, called\nEMFlow, that performs imputation in an latent space via an online version of\nExpectation-Maximization (EM) algorithm and connects the latent space and the\ndata space via the normalizing flow (NF). The inference of EMFlow is iterative,\ninvolving updating the parameters of online EM and NF alternatively. Extensive\nexperimental results on multivariate and image datasets show that the proposed\nEMFlow has superior performance to competing methods in terms of both\nimputation quality and convergence speed.",
          "link": "http://arxiv.org/abs/2106.04804",
          "publishedOn": "2021-06-10T01:56:47.714Z",
          "wordCount": 549,
          "title": "EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models. (arXiv:2106.04804v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopez_F/0/1/0/all/0/1\">Federico L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozzetti_B/0/1/0/all/0/1\">Beatrice Pozzetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trettel_S/0/1/0/all/0/1\">Steve Trettel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strube_M/0/1/0/all/0/1\">Michael Strube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wienhard_A/0/1/0/all/0/1\">Anna Wienhard</a>",
          "description": "Learning faithful graph representations as sets of vertex embeddings has\nbecome a fundamental intermediary step in a wide range of machine learning\napplications. We propose the systematic use of symmetric spaces in\nrepresentation learning, a class encompassing many of the previously used\nembedding targets. This enables us to introduce a new method, the use of\nFinsler metrics integrated in a Riemannian optimization scheme, that better\nadapts to dissimilar structures in the graph. We develop a tool to analyze the\nembeddings and infer structural properties of the data sets. For\nimplementation, we choose Siegel spaces, a versatile family of symmetric\nspaces. Our approach outperforms competitive baselines for graph reconstruction\ntasks on various synthetic and real-world datasets. We further demonstrate its\napplicability on two downstream tasks, recommender systems and node\nclassification.",
          "link": "http://arxiv.org/abs/2106.04941",
          "publishedOn": "2021-06-10T01:56:47.676Z",
          "wordCount": 568,
          "title": "Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach. (arXiv:2106.04941v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tayal_K/0/1/0/all/0/1\">Kshitij Tayal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manekar_R/0/1/0/all/0/1\">Raunak Manekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhong Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">David Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vipin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_F/0/1/0/all/0/1\">Felix Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Several deep learning methods for phase retrieval exist, but most of them\nfail on realistic data without precise support information. We propose a novel\nmethod based on single-instance deep generative prior that works well on\ncomplex-valued crystal data.",
          "link": "http://arxiv.org/abs/2106.04812",
          "publishedOn": "2021-06-10T01:56:47.670Z",
          "wordCount": 472,
          "title": "Phase Retrieval using Single-Instance Deep Generative Prior. (arXiv:2106.04812v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1\">Aaron Ferber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jialin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1\">Bistra Dilkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "We propose a machine learning approach for quickly solving Mixed Integer\nPrograms (MIP) by learning to prioritize a set of decision variables, which we\ncall pseudo-backdoors, for branching that results in faster solution times.\nLearning-based approaches have seen success in the area of solving\ncombinatorial optimization problems by being able to flexibly leverage common\nstructures in a given distribution of problems. Our approach takes inspiration\nfrom the concept of strong backdoors, which corresponds to a small set of\nvariables such that only branching on these variables yields an optimal\nintegral solution and a proof of optimality. Our notion of pseudo-backdoors\ncorresponds to a small set of variables such that only branching on them leads\nto faster solve time (which can be solver dependent). A key advantage of\npseudo-backdoors over strong backdoors is that they are much amenable to\ndata-driven identification or prediction. Our proposed method learns to\nestimate the solver performance of a proposed pseudo-backdoor, using a labeled\ndataset collected on a set of training MIP instances. This model can then be\nused to identify high-quality pseudo-backdoors on new MIP instances from the\nsame distribution. We evaluate our method on the generalized independent set\nproblems and find that our approach can efficiently identify high-quality\npseudo-backdoors. In addition, we compare our learned approach against Gurobi,\na state-of-the-art MIP solver, demonstrating that our method can be used to\nimprove solver performance.",
          "link": "http://arxiv.org/abs/2106.05080",
          "publishedOn": "2021-06-10T01:56:47.665Z",
          "wordCount": 665,
          "title": "Learning Pseudo-Backdoors for Mixed Integer Programs. (arXiv:2106.05080v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "The recent advanced deep learning techniques have shown the promising results\nin various domains such as computer vision and natural language processing. The\nsuccess of deep neural networks in supervised learning heavily relies on a\nlarge amount of labeled data. However, obtaining labeled data with target\nlabels is often challenging due to various reasons such as cost of labeling and\nprivacy issues, which challenges existing deep models. In spite of that, it is\nrelatively easy to obtain data with \\textit{inexact supervision}, i.e., having\nlabels/tags related to the target task. For example, social media platforms are\noverwhelmed with billions of posts and images with self-customized tags, which\nare not the exact labels for target classification tasks but are usually\nrelated to the target labels. It is promising to leverage these tags (inexact\nsupervision) and their relations with target classes to generate labeled data\nto facilitate the downstream classification tasks. However, the work on this is\nrather limited. Therefore, we study a novel problem of labeled data generation\nwith inexact supervision. We propose a novel generative framework named as\nADDES which can synthesize high-quality labeled data for target classification\ntasks by learning from data with inexact supervision and the relations between\ninexact supervision and target classes. Experimental results on image and text\ndatasets demonstrate the effectiveness of the proposed ADDES for generating\nrealistic labeled data from inexact supervision to facilitate the target\nclassification task.",
          "link": "http://arxiv.org/abs/2106.04716",
          "publishedOn": "2021-06-10T01:56:47.628Z",
          "wordCount": 652,
          "title": "Labeled Data Generation with Inexact Supervision. (arXiv:2106.04716v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1\">Sebastian Cygert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1\">Andrzej Czy&#x17c;ewski</a>",
          "description": "Model compression techniques allow to significantly reduce the computational\ncost associated with data processing by deep neural networks with only a minor\ndecrease in average accuracy. Simultaneously, reducing the model size may have\na large effect on noisy cases or objects belonging to less frequent classes. It\nis a crucial problem from the perspective of the models' safety, especially for\nobject detection in the autonomous driving setting, which is considered in this\nwork. It was shown in the paper that the sensitivity of compressed models to\ndifferent distortion types is nuanced, and some of the corruptions are heavily\nimpacted by the compression methods (i.e., additive noise), while others (blur\neffect) are only slightly affected. A common way to improve the robustness of\nmodels is to use data augmentation, which was confirmed to positively affect\nmodels' robustness, also for highly compressed models. It was further shown\nthat while data imbalance methods brought only a slight increase in accuracy\nfor the baseline model (without compression), the impact was more striking at\nhigher compression rates for the structured pruning. Finally, methods for\nhandling data imbalance brought a significant improvement of the pruned models'\nworst-detected class accuracy.",
          "link": "http://arxiv.org/abs/2102.05509",
          "publishedOn": "2021-06-10T01:56:47.537Z",
          "wordCount": 647,
          "title": "Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Tracking-by-detection is a very popular framework for single object tracking\nwhich attempts to search the target object within a local search window for\neach frame. Although such local search mechanism works well on simple videos,\nhowever, it makes the trackers sensitive to extremely challenging scenarios,\nsuch as heavy occlusion and fast motion. In this paper, we propose a novel and\ngeneral target-aware attention mechanism (termed TANet) and integrate it with\ntracking-by-detection framework to conduct joint local and global search for\nrobust tracking. Specifically, we extract the features of target object patch\nand continuous video frames, then we concatenate and feed them into a decoder\nnetwork to generate target-aware global attention maps. More importantly, we\nresort to adversarial training for better attention prediction. The appearance\nand motion discriminator networks are designed to ensure its consistency in\nspatial and temporal views. In the tracking procedure, we integrate the\ntarget-aware attention with multiple trackers by exploring candidate search\nregions for robust tracking. Extensive experiments on both short-term and\nlong-term tracking benchmark datasets all validated the effectiveness of our\nalgorithm. The project page of this paper can be found at\n\\url{https://sites.google.com/view/globalattentiontracking/home/extend}.",
          "link": "http://arxiv.org/abs/2106.04840",
          "publishedOn": "2021-06-10T01:56:47.520Z",
          "wordCount": 641,
          "title": "Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1\">Tsun-An Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_K/0/1/0/all/0/1\">Kuo-Hsuan Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garudadri_H/0/1/0/all/0/1\">Harinath Garudadri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1\">Tei-Wei Kuo</a>",
          "description": "A large number of Internet of Things (IoT) devices today are powered by\nbatteries, which are often expensive to maintain and may cause serious\nenvironmental pollution. To avoid these problems, researchers have begun to\nconsider the use of energy systems based on energy-harvesting units for such\ndevices. However, the power harvested from an ambient source is fundamentally\nsmall and unstable, resulting in frequent power failures during the operation\nof IoT applications involving, for example, intermittent speech signals and the\nstreaming of videos. This paper presents a deep-learning-based speech recovery\nsystem that reconstructs intermittent speech signals from self-powered IoT\ndevices. Our intermittent speech recovery system (ISR) consists of three\nstages: interpolation, recovery, and combination. The experimental results show\nthat our recovery system increases speech quality by up to 707.1%, while\nincreasing speech intelligibility by up to 92.1%. Most importantly, our ISR\nsystem also enhances the WER scores by up to 65.6%. To the best of our\nknowledge, this study is one of the first to reconstruct intermittent speech\nsignals from self-powered-sensing IoT devices. These promising results suggest\nthat even though self powered microphone devices function with weak energy\nsources, our ISR system can still maintain the performance of most\nspeech-signal-based applications.",
          "link": "http://arxiv.org/abs/2106.05229",
          "publishedOn": "2021-06-10T01:56:47.506Z",
          "wordCount": 629,
          "title": "Intermittent Speech Recovery. (arXiv:2106.05229v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine Reinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>",
          "description": "Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.",
          "link": "http://arxiv.org/abs/2106.05194",
          "publishedOn": "2021-06-10T01:56:47.489Z",
          "wordCount": 593,
          "title": "DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05190",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1\">Thu Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Duy_K/0/1/0/all/0/1\">Khoi Minh Nguyen-Duy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_D/0/1/0/all/0/1\">Duy Ho Minh Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wade_B/0/1/0/all/0/1\">Bruce Alan Wade</a>",
          "description": "The missing data problem has been broadly studied in the last few decades and\nhas various applications in different areas such as statistics or\nbioinformatics. Even though many methods have been developed to tackle this\nchallenge, most of those are imputation techniques that require multiple\niterations through the data before yielding convergence. In addition, such\napproaches may introduce extra biases and noises to the estimated parameters.\nIn this work, we propose novel algorithms to find the maximum likelihood\nestimates (MLEs) for a one-class/multiple-class randomly missing data set under\nsome mild assumptions. As the computation is direct without any imputation, our\nalgorithms do not require multiple iterations through the data, thus promising\nto be less time-consuming than other methods while maintaining superior\nestimation performance. We validate these claims by empirical results on\nvarious data sets of different sizes and release all codes in a GitHub\nrepository to contribute to the research community related to this problem.",
          "link": "http://arxiv.org/abs/2106.05190",
          "publishedOn": "2021-06-10T01:56:47.470Z",
          "wordCount": 605,
          "title": "DPER: Efficient Parameter Estimation for Randomly Missing Data. (arXiv:2106.05190v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>",
          "description": "In this work we introduce a new approach for identifiable non-linear ICA\nmodels. Recently there has been a renaissance in identifiability results in\ndeep generative models, not least for non-linear ICA. These prior works,\nhowever, have assumed access to a sufficiently-informative auxiliary set of\nobservations, denoted $\\mathbf{u}$. We show here how identifiability can be\nobtained in the absence of this side-information, rendering possible\nfully-unsupervised identifiable non-linear ICA. While previous theoretical\nresults have established the impossibility of identifiable non-linear ICA in\nthe presence of infinitely-flexible universal function approximators, here we\nrely on the intrinsically-finite modelling capacity of any particular chosen\nparameterisation of a deep generative model. In particular, we focus on\ngenerative models which perform clustering in their latent space -- a model\nstructure which matches previous identifiable models, but with the learnt\nclustering providing a synthetic form of auxiliary information. We evaluate our\nproposals using VAEs, on synthetic and image datasets, and find that the\nlearned clusterings function effectively: deep generative models with latent\nclusterings are empirically identifiable, to the same degree as models which\nrely on side information.",
          "link": "http://arxiv.org/abs/2106.05238",
          "publishedOn": "2021-06-10T01:56:47.464Z",
          "wordCount": 620,
          "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Razin_N/0/1/0/all/0/1\">Noam Razin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maman_A/0/1/0/all/0/1\">Asaf Maman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1\">Nadav Cohen</a>",
          "description": "Recent efforts to unravel the mystery of implicit regularization in deep\nlearning have led to a theoretical focus on matrix factorization -- matrix\ncompletion via linear neural network. As a step further towards practical deep\nlearning, we provide the first theoretical analysis of implicit regularization\nin tensor factorization -- tensor completion via certain type of non-linear\nneural network. We circumvent the notorious difficulty of tensor problems by\nadopting a dynamical systems perspective, and characterizing the evolution\ninduced by gradient descent. The characterization suggests a form of greedy low\ntensor rank search, which we rigorously prove under certain conditions, and\nempirically demonstrate under others. Motivated by tensor rank capturing the\nimplicit regularization of a non-linear neural network, we empirically explore\nit as a measure of complexity, and find that it captures the essence of\ndatasets on which neural networks generalize. This leads us to believe that\ntensor rank may pave way to explaining both implicit regularization in deep\nlearning, and the properties of real-world data translating this implicit\nregularization to generalization.",
          "link": "http://arxiv.org/abs/2102.09972",
          "publishedOn": "2021-06-10T01:56:47.458Z",
          "wordCount": 641,
          "title": "Implicit Regularization in Tensor Factorization. (arXiv:2102.09972v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05170",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_L/0/1/0/all/0/1\">Licong Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Modern machine learning methods are often overparametrized, allowing\nadaptation to the data at a fine level. This can seem puzzling; in the worst\ncase, such models do not need to generalize. This puzzle inspired a great\namount of work, arguing when overparametrization reduces test error, in a\nphenomenon called \"double descent\". Recent work aimed to understand in greater\ndepth why overparametrization is helpful for generalization. This leads to\ndiscovering the unimodality of variance as a function of the level of\nparametrization, and to decomposing the variance into that arising from label\nnoise, initialization, and randomness in the training data to understand the\nsources of the error.\n\nIn this work we develop a deeper understanding of this area. Specifically, we\npropose using the analysis of variance (ANOVA) to decompose the variance in the\ntest error in a symmetric way, for studying the generalization performance of\ncertain two-layer linear and non-linear networks. The advantage of the analysis\nof variance is that it reveals the effects of initialization, label noise, and\ntraining data more clearly than prior approaches. Moreover, we also study the\nmonotonicity and unimodality of the variance components. While prior work\nstudied the unimodality of the overall variance, we study the properties of\neach term in variance decomposition.\n\nOne key insight is that in typical settings, the interaction between training\nsamples and initialization can dominate the variance; surprisingly being larger\nthan their marginal effect. Also, we characterize \"phase transitions\" where the\nvariance changes from unimodal to monotone. On a technical level, we leverage\nadvanced deterministic equivalent techniques for Haar random matrices, that --\nto our knowledge -- have not yet been used in the area. We also verify our\nresults in numerical simulations and on empirical data examples.",
          "link": "http://arxiv.org/abs/2010.05170",
          "publishedOn": "2021-06-10T01:56:47.452Z",
          "wordCount": 747,
          "title": "What causes the test error? Going beyond bias-variance via ANOVA. (arXiv:2010.05170v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xutong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1\">Jinhang Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaowei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>",
          "description": "Multi-layered network exploration (MuLaNE) problem is an important problem\nabstracted from many applications. In MuLaNE, there are multiple network layers\nwhere each node has an importance weight and each layer is explored by a random\nwalk. The MuLaNE task is to allocate total random walk budget $B$ into each\nnetwork layer so that the total weights of the unique nodes visited by random\nwalks are maximized. We systematically study this problem from offline\noptimization to online learning. For the offline optimization setting where the\nnetwork structure and node weights are known, we provide greedy based\nconstant-ratio approximation algorithms for overlapping networks, and greedy or\ndynamic-programming based optimal solutions for non-overlapping networks. For\nthe online learning setting, neither the network structure nor the node weights\nare known initially. We adapt the combinatorial multi-armed bandit framework\nand design algorithms to learn random walk related parameters and node weights\nwhile optimizing the budget allocation in multiple rounds, and prove that they\nachieve logarithmic regret bounds. Finally, we conduct experiments on a\nreal-world social network dataset to validate our theoretical results.",
          "link": "http://arxiv.org/abs/2106.05065",
          "publishedOn": "2021-06-10T01:56:47.446Z",
          "wordCount": 616,
          "title": "Multi-layered Network Exploration via Random Walks: From Offline Optimization to Online Learning. (arXiv:2106.05065v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qitian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaofeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "Recommendation models can effectively estimate underlying user interests and\npredict one's future behaviors by factorizing an observed user-item rating\nmatrix into products of two sets of latent factors. However, the user-specific\nembedding factors can only be learned in a transductive way, making it\ndifficult to handle new users on-the-fly. In this paper, we propose an\ninductive collaborative filtering framework that contains two representation\nmodels. The first model follows conventional matrix factorization which\nfactorizes a group of key users' rating matrix to obtain meta latents. The\nsecond model resorts to attention-based structure learning that estimates\nhidden relations from query to key users and learns to leverage meta latents to\ninductively compute embeddings for query users via neural message passing. Our\nmodel enables inductive representation learning for users and meanwhile\nguarantees equivalent representation capacity as matrix factorization.\nExperiments demonstrate that our model achieves promising results for\nrecommendation on few-shot users with limited training ratings and new unseen\nusers which are commonly encountered in open-world recommender systems.",
          "link": "http://arxiv.org/abs/2007.04833",
          "publishedOn": "2021-06-10T01:56:47.428Z",
          "wordCount": 626,
          "title": "Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.09417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marvasti_A/0/1/0/all/0/1\">Amir Emad Marvasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marvasti_E/0/1/0/all/0/1\">Ehsan Emad Marvasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroosh_H/0/1/0/all/0/1\">Hassan Foroosh</a>",
          "description": "We present a theoretical framework of probabilistic learning derived by\nMaximum Probability (MP) Theorem shown in the current paper. In this\nprobabilistic framework, a model is defined as an event in the probability\nspace, and a model or the associated event - either the true underlying model\nor the parameterized model - have a quantified probability measure. This\nquantification of a model's probability measure is derived by the MP Theorem,\nin which we have shown that an event's probability measure has an upper-bound\ngiven its conditional distribution on an arbitrary random variable. Through\nthis alternative framework, the notion of model parameters is encompassed in\nthe definition of the model or the associated event. Therefore, this framework\ndeviates from the conventional approach of assuming a prior on the model\nparameters. Instead, the regularizing effects of assuming prior over parameters\nis seen through maximizing probabilities of models or according to information\ntheory, minimizing the information content of a model. The probability of a\nmodel in our framework is invariant to reparameterization and is solely\ndependent on the model's likelihood function. Also, rather than maximizing the\nposterior in a conventional Bayesian setting, the objective function in our\nalternative framework is defined as the probability of set operations (e.g.\nintersection) on the event of the true underlying model and the event of the\nmodel at hand. Our theoretical framework, as a derivation of MP theorem, adds\nclarity to probabilistic learning through solidifying the definition of\nprobabilistic models, quantifying their probabilities, and providing a visual\nunderstanding of objective functions.",
          "link": "http://arxiv.org/abs/1910.09417",
          "publishedOn": "2021-06-10T01:56:47.423Z",
          "wordCount": 736,
          "title": "Maximum Probability Theorem: A Framework for Probabilistic Learning. (arXiv:1910.09417v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasui_S/0/1/0/all/0/1\">Shota Yasui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAlinn_K/0/1/0/all/0/1\">Kenichiro McAlinn</a>",
          "description": "The doubly robust (DR) estimator, which consists of two nuisance parameters,\nthe conditional mean outcome and the logging policy (the probability of\nchoosing an action), is crucial in causal inference. This paper proposes a DR\nestimator for dependent samples obtained from adaptive experiments. To obtain\nan asymptotically normal semiparametric estimator from dependent samples with\nnon-Donsker nuisance estimators, we propose adaptive-fitting as a variant of\nsample-splitting. We also report an empirical paradox that our proposed DR\nestimator tends to show better performances compared to other estimators\nutilizing the true logging policy. While a similar phenomenon is known for\nestimators with i.i.d. samples, traditional explanations based on asymptotic\nefficiency cannot elucidate our case with dependent samples. We confirm this\nhypothesis through simulation studies.",
          "link": "http://arxiv.org/abs/2010.03792",
          "publishedOn": "2021-06-10T01:56:47.417Z",
          "wordCount": 617,
          "title": "The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive Experiments and a Paradox Concerning Logging Policy. (arXiv:2010.03792v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Viannet Perchet</a>",
          "description": "We consider the quickest change detection problem where both the parameters\nof pre- and post- change distributions are unknown, which prevents the use of\nclassical simple hypothesis testing. Without additional assumptions, optimal\nsolutions are not tractable as they rely on some minimax and robust variant of\nthe objective. As a consequence, change points might be detected too late for\npractical applications (in economics, health care or maintenance for instance).\nAvailable constant complexity techniques typically solve a relaxed version of\nthe problem, deeply relying on very specific probability distributions and/or\nsome very precise additional knowledge. We consider a totally different\napproach that leverages the theoretical asymptotic properties of optimal\nsolutions to derive a new scalable approximate algorithm with near optimal\nperformance that runs~in~$\\mathcal{O}(1)$, adapted to even more complex\nMarkovian settings.",
          "link": "http://arxiv.org/abs/2106.05061",
          "publishedOn": "2021-06-10T01:56:47.411Z",
          "wordCount": 560,
          "title": "Quickest change detection with unknown parameters: Constant complexity and near optimality. (arXiv:2106.05061v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1909.12038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qimai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Quanyu Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>",
          "description": "Graph convolutional neural networks (GCN) have been the model of choice for\ngraph representation learning, which is mainly due to the effective design of\ngraph convolution that computes the representation of a node by aggregating\nthose of its neighbors. However, existing GCN variants commonly use 1-D graph\nconvolution that solely operates on the object link graph without exploring\ninformative relational information among object attributes. This significantly\nlimits their modeling capability and may lead to inferior performance on noisy\nand sparse real-world networks. In this paper, we explore 2-D graph convolution\nto jointly model object links and attribute relations for graph representation\nlearning. Specifically, we propose a computationally efficient dimensionwise\nseparable 2-D graph convolution (DSGC) for filtering node features.\nTheoretically, we show that DSGC can reduce intra-class variance of node\nfeatures on both the object dimension and the attribute dimension to learn more\neffective representations. Empirically, we demonstrate that by modeling\nattribute relations, DSGC achieves significant performance gain over\nstate-of-the-art methods for node classification and clustering on a variety of\nreal-world networks. The source code for reproducing the experimental results\nis available at https://github.com/liqimai/DSGC.",
          "link": "http://arxiv.org/abs/1909.12038",
          "publishedOn": "2021-06-10T01:56:47.405Z",
          "wordCount": 698,
          "title": "Dimensionwise Separable 2-D Graph Convolution for Unsupervised and Semi-Supervised Learning on Graphs. (arXiv:1909.12038v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawkins_Q/0/1/0/all/0/1\">Quinlan Dawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haifeng Xu</a>",
          "description": "Diffusion source identification on networks is a problem of fundamental\nimportance in a broad class of applications, including rumor controlling and\nvirus identification. Though this problem has received significant recent\nattention, most studies have focused only on very restrictive settings and lack\ntheoretical guarantees for more realistic networks. We introduce a statistical\nframework for the study of diffusion source identification and develop a\nconfidence set inference approach inspired by hypothesis testing. Our method\nefficiently produces a small subset of nodes, which provably covers the source\nnode with any pre-specified confidence level without restrictive assumptions on\nnetwork structures. Moreover, we propose multiple Monte Carlo strategies for\nthe inference procedure based on network topology and the probabilistic\nproperties that significantly improve the scalability. To our knowledge, this\nis the first diffusion source identification method with a practically useful\ntheoretical guarantee on general networks. We demonstrate our approach via\nextensive synthetic experiments on well-known random network models and a\nmobility network between cities concerning the COVID-19 spreading.",
          "link": "http://arxiv.org/abs/2106.04800",
          "publishedOn": "2021-06-10T01:56:47.388Z",
          "wordCount": 644,
          "title": "Diffusion Source Identification on Networks with Statistical Confidence. (arXiv:2106.04800v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deshwal_A/0/1/0/all/0/1\">Aryan Deshwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belakaria_S/0/1/0/all/0/1\">Syrine Belakaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1\">Janardhan Rao Doppa</a>",
          "description": "We consider the problem of optimizing hybrid structures (mixture of discrete\nand continuous input variables) via expensive black-box function evaluations.\nThis problem arises in many real-world applications. For example, in materials\ndesign optimization via lab experiments, discrete and continuous variables\ncorrespond to the presence/absence of primitive elements and their relative\nconcentrations respectively. The key challenge is to accurately model the\ncomplex interactions between discrete and continuous variables. In this paper,\nwe propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by\nutilizing diffusion kernels, which are naturally defined over continuous and\ndiscrete variables. We develop a principled approach for constructing diffusion\nkernels over hybrid spaces by utilizing the additive kernel formulation, which\nallows additive interactions of all orders in a tractable manner. We\ntheoretically analyze the modeling strength of additive hybrid kernels and\nprove that it has the universal approximation property. Our experiments on\nsynthetic and six diverse real-world benchmarks show that HyBO significantly\noutperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04682",
          "publishedOn": "2021-06-10T01:56:47.371Z",
          "wordCount": 595,
          "title": "Bayesian Optimization over Hybrid Spaces. (arXiv:2106.04682v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1\">Ting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1\">Desheng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1\">Bingyu Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruifei Zhang</a>",
          "description": "Transformer-based models have made tremendous impacts in natural language\ngeneration. However the inference speed is a bottleneck due to large model size\nand intensive computing involved in auto-regressive decoding process. We\ndevelop FastSeq framework to accelerate sequence generation without accuracy\nloss. The proposed optimization techniques include an attention cache\noptimization, an efficient algorithm for detecting repeated n-grams, and an\nasynchronous generation pipeline with parallel I/O. These optimizations are\ngeneral enough to be applicable to Transformer-based models (e.g., T5, GPT2,\nand UniLM). Our benchmark results on a set of widely used and diverse models\ndemonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use\nwith a simple one-line code change. The source code is available at\nhttps://github.com/microsoft/fastseq.",
          "link": "http://arxiv.org/abs/2106.04718",
          "publishedOn": "2021-06-10T01:56:47.365Z",
          "wordCount": 560,
          "title": "FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14139",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ketkov_S/0/1/0/all/0/1\">Sergey S. Ketkov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shilov_A/0/1/0/all/0/1\">Andrei S. Shilov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Prokopyev_O/0/1/0/all/0/1\">Oleg A. Prokopyev</a>",
          "description": "In this study we analyze linear combinatorial optimization problems where the\ncost vector is not known a priori, but is only observable through a finite data\nset. In contrast to the related studies, we presume that the number of\nobservations with respect to particular components of the cost vector may vary.\nThe goal is to find a procedure that transforms the data set into an estimate\nof the expected value of the objective function (which is referred to as a\nprediction rule) and a procedure that retrieves a candidate decision (which is\nreferred to as a prescription rule). We aim at finding the least conservative\nprediction and prescription rules, which satisfy some specified asymptotic\nguarantees. We demonstrate that the resulting vector optimization problems\nadmit a weakly optimal solution, which can be obtained by solving a particular\ndistributionally robust optimization problem. Specifically, the decision-maker\nmay optimize the worst-case expected loss across all probability distributions\nwith given component-wise relative entropy distances from the empirical\nmarginal distributions. Finally, we perform numerical experiments to analyze\nthe out-of-sample performance of the proposed solution approach.",
          "link": "http://arxiv.org/abs/2105.14139",
          "publishedOn": "2021-06-10T01:56:47.357Z",
          "wordCount": 642,
          "title": "On a class of data-driven combinatorial optimization problems under uncertainty: a distributionally robust approach. (arXiv:2105.14139v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1\">Erdem B&#x131;y&#x131;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazar_D/0/1/0/all/0/1\">Daniel A. Lazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedarsani_R/0/1/0/all/0/1\">Ramtin Pedarsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>",
          "description": "Traffic congestion has large economic and social costs. The introduction of\nautonomous vehicles can potentially reduce this congestion by increasing road\ncapacity via vehicle platooning and by creating an avenue for influencing\npeople's choice of routes. We consider a network of parallel roads with two\nmodes of transportation: (i) human drivers, who will choose the quickest route\navailable to them, and (ii) a ride hailing service, which provides an array of\nautonomous vehicle route options, each with different prices, to users. We\nformalize a model of vehicle flow in mixed autonomy and a model of how\nautonomous service users make choices between routes with different prices and\nlatencies. Developing an algorithm to learn the preferences of the users, we\nformulate a planning optimization that chooses prices to maximize a social\nobjective. We demonstrate the benefit of the proposed scheme by comparing the\nresults to theoretical benchmarks which we show can be efficiently calculated.",
          "link": "http://arxiv.org/abs/2106.04678",
          "publishedOn": "2021-06-10T01:56:47.351Z",
          "wordCount": 617,
          "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed Autonomy. (arXiv:2106.04678v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhilu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1\">Vianne R. Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1\">Mert R. Sabuncu</a>",
          "description": "Monte Carlo (MC) dropout is a simple and efficient ensembling method that can\nimprove the accuracy and confidence calibration of high-capacity deep neural\nnetwork models. However, MC dropout is not as effective as more\ncompute-intensive methods such as deep ensembles. This performance gap can be\nattributed to the relatively poor quality of individual models in the MC\ndropout ensemble and their lack of diversity. These issues can in turn be\ntraced back to the coupled training and substantial parameter sharing of the\ndropout models. Motivated by this perspective, we propose a strategy to compute\nan ensemble of subnetworks, each corresponding to a non-overlapping dropout\nmask computed via a pruning strategy and trained independently. We show that\nthe proposed subnetwork ensembling method can perform as well as standard deep\nensembles in both accuracy and uncertainty estimates, yet with a computational\nefficiency similar to MC dropout. Lastly, using several computer vision\ndatasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally\ndemonstrate that subnetwork ensembling also consistently outperforms recently\nproposed approaches that efficiently ensemble neural networks.",
          "link": "http://arxiv.org/abs/2106.04767",
          "publishedOn": "2021-06-10T01:56:47.331Z",
          "wordCount": 609,
          "title": "Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07826",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1\">Junpei Komiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abe_M/0/1/0/all/0/1\">Masaya Abe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nakagawa_K/0/1/0/all/0/1\">Kei Nakagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McAlinn_K/0/1/0/all/0/1\">Kenichiro McAlinn</a>",
          "description": "We consider controlling the false discovery rate for testing many time series\nwith an unknown cross-sectional correlation structure. Given a large number of\nhypotheses, false and missing discoveries can plague an analysis. While many\nprocedures have been proposed to control false discovery, most of them either\nassume independent hypotheses or lack statistical power. A problem of\nparticular interest is in financial asset pricing, where the goal is to\ndetermine which ``factors\" lead to excess returns out of a large number of\npotential factors. Our contribution is two-fold. First, we show the consistency\nof Fama and French's prominent method under multiple testing. Second, we\npropose a novel method for false discovery control using double bootstrapping.\nWe achieve superior statistical power to existing methods and prove that the\nfalse discovery rate is controlled. Simulations and a real data application\nillustrate the efficacy of our method over existing methods.",
          "link": "http://arxiv.org/abs/2102.07826",
          "publishedOn": "2021-06-10T01:56:47.271Z",
          "wordCount": 595,
          "title": "Controlling False Discovery Rates under Cross-Sectional Correlations. (arXiv:2102.07826v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1\">Joost van Amersfoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Lewis Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1\">Oscar Key</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "Gaussian processes are often considered a gold standard in uncertainty\nestimation with low dimensional data, but they have difficulty scaling to high\ndimensional inputs. Deep Kernel Learning (DKL) was introduced as a solution to\nthis problem: a deep feature extractor is used to transform the inputs over\nwhich a Gaussian process' kernel is defined. However, DKL has been shown to\nprovide unreliable uncertainty estimates in practice. We study why, and show\nthat for certain feature extractors, \"far-away\" data points are mapped to the\nsame features as those of training-set points. With this insight we propose to\nconstrain DKL's feature extractor to approximately preserve distances through a\nbi-Lipschitz constraint, resulting in a feature space favorable to DKL. We\nobtain a model, DUE, which demonstrates uncertainty quality outperforming\nprevious DKL and single forward pass uncertainty methods, while maintaining the\nspeed and accuracy of softmax neural networks.",
          "link": "http://arxiv.org/abs/2102.11409",
          "publishedOn": "2021-06-10T01:56:47.242Z",
          "wordCount": 615,
          "title": "On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty. (arXiv:2102.11409v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04741",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gilboa_D/0/1/0/all/0/1\">Dar Gilboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pakman_A/0/1/0/all/0/1\">Ari Pakman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vatter_T/0/1/0/all/0/1\">Thibault Vatter</a>",
          "description": "Probability density models based on deep networks have achieved remarkable\nsuccess in modeling complex high-dimensional datasets. However, unlike kernel\ndensity estimators, modern neural models do not yield marginals or conditionals\nin closed form, as these quantities require the evaluation of seldom tractable\nintegrals. In this work, we present the Marginalizable Density Model\nApproximator (MDMA), a novel deep network architecture which provides closed\nform expressions for the probabilities, marginals and conditionals of any\nsubset of the variables. The MDMA learns deep scalar representations for each\nindividual variable and combines them via learned hierarchical tensor\ndecompositions into a tractable yet expressive CDF, from which marginals and\nconditional densities are easily obtained. We illustrate the advantage of exact\nmarginalizability in several tasks that are out of reach of previous deep\nnetwork-based density estimation models, such as estimating mutual information\nbetween arbitrary subsets of variables, inferring causality by testing for\nconditional independence, and inference with missing data without the need for\ndata imputation, outperforming state-of-the-art models on these tasks. The\nmodel also allows for parallelized sampling with only a logarithmic dependence\nof the time complexity on the number of variables.",
          "link": "http://arxiv.org/abs/2106.04741",
          "publishedOn": "2021-06-10T01:56:47.225Z",
          "wordCount": 604,
          "title": "Marginalizable Density Models. (arXiv:2106.04741v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10611",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1\">Diptodip Deb</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1\">Zhenfei Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1\">Alex B. Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1\">Misha B. Ahrens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1\">Kaspar Podgorski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1\">Srinivas C. Turaga</a>",
          "description": "3D snapshot microscopy enables fast volumetric imaging by capturing a 3D\nvolume in a single 2D camera image, and has found a variety of biological\napplications such as whole brain imaging of fast neural activity in larval\nzebrafish. The optimal microscope design for this optical 3D-to-2D encoding is\nboth sample- and task-dependent, with no general solution known. Highly\nprogrammable optical elements create new possibilities for sample-specific\ncomputational optimization of microscope parameters, e.g. tuning the collection\nof light for a given sample structure. We perform such optimization with deep\nlearning, using a differentiable wave-optics simulation of light propagation\nthrough a programmable microscope and a neural network to reconstruct volumes\nfrom the microscope image. We introduce a class of global kernel Fourier\nconvolutional neural networks which can efficiently decode information from\nmultiple depths in the volume, globally encoded across a 3D snapshot image. We\nshow that our proposed networks succeed in large field of view volume\nreconstruction and microscope parameter optimization where traditional networks\nfail. We also show that our networks outperform the state-of-the-art learned\nreconstruction algorithms for lensless computational photography.",
          "link": "http://arxiv.org/abs/2104.10611",
          "publishedOn": "2021-06-10T01:56:47.217Z",
          "wordCount": 656,
          "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazimeh_H/0/1/0/all/0/1\">Hussein Hazimeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathiamoorthy_M/0/1/0/all/0/1\">Maheswaran Sathiamoorthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yihua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "The Mixture-of-experts (MoE) architecture is showing promising results in\nmulti-task learning (MTL) and in scaling high-capacity neural networks.\nState-of-the-art MoE models use a trainable sparse gate to select a subset of\nthe experts for each input example. While conceptually appealing, existing\nsparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to\nconvergence and statistical performance issues when training with\ngradient-based methods. In this paper, we develop DSelect-k: the first,\ncontinuously differentiable and sparse gate for MoE, based on a novel binary\nencoding formulation. Our gate can be trained using first-order methods, such\nas stochastic gradient descent, and offers explicit control over the number of\nexperts to select. We demonstrate the effectiveness of DSelect-k in the context\nof MTL, on both synthetic and real datasets with up to 128 tasks. Our\nexperiments indicate that MoE models based on DSelect-k can achieve\nstatistically significant improvements in predictive and expert selection\nperformance. Notably, on a real-world large-scale recommender system, DSelect-k\nachieves over 22% average improvement in predictive performance compared to the\nTop-k gate. We provide an open-source TensorFlow implementation of our gate.",
          "link": "http://arxiv.org/abs/2106.03760",
          "publishedOn": "2021-06-10T01:56:47.211Z",
          "wordCount": 655,
          "title": "DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong C. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1\">Thanh-Toan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>",
          "description": "We propose probabilistic task modelling -- a generative probabilistic model\nfor collections of tasks used in meta-learning. The proposed model combines\nvariational auto-encoding and latent Dirichlet allocation to model each task as\na mixture of Gaussian distribution in an embedding space. Such modelling\nprovides an explicit representation of a task through its task-theme mixture.\nWe present an efficient approximation inference technique based on variational\ninference method for empirical Bayes parameter estimation. We perform empirical\nevaluations to validate the task uncertainty and task distance produced by the\nproposed method through correlation diagrams of the prediction accuracy on\ntesting tasks. We also carry out experiments of task selection in meta-learning\nto demonstrate how the task relatedness inferred from the proposed model help\nto facilitate meta-learning algorithms.",
          "link": "http://arxiv.org/abs/2106.04802",
          "publishedOn": "2021-06-10T01:56:47.187Z",
          "wordCount": 546,
          "title": "Probabilistic task modelling for meta-learning. (arXiv:2106.04802v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "Overparametrization has been remarkably successful for deep learning studies.\nThis study investigates an overlooked but important aspect of overparametrized\nneural networks, that is, the null components in the parameters of neural\nnetworks, or the ghosts. Since deep learning is not explicitly regularized,\ntypical deep learning solutions contain null components. In this paper, we\npresent a structure theorem of the null space for a general class of neural\nnetworks. Specifically, we show that any null element can be uniquely written\nby the linear combination of ridgelet transforms. In general, it is quite\ndifficult to fully characterize the null space of an arbitrarily given\noperator. Therefore, the structure theorem is a great advantage for\nunderstanding a complicated landscape of neural network parameters. As\napplications, we discuss the roles of ghosts on the generalization performance\nof deep learning.",
          "link": "http://arxiv.org/abs/2106.04770",
          "publishedOn": "2021-06-10T01:56:47.181Z",
          "wordCount": 571,
          "title": "Ghosts in Neural Networks: Existence, Structure and Role of Infinite-Dimensional Null Space. (arXiv:2106.04770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1\">David S. Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ricardo Silva</a>",
          "description": "We examine the problem of causal response estimation for complex objects\n(e.g., text, images, genomics). In this setting, classical \\emph{atomic}\ninterventions are often not available (e.g., changes to characters, pixels, DNA\nbase-pairs). Instead, we only have access to indirect or \\emph{crude}\ninterventions (e.g., enrolling in a writing program, modifying a scene,\napplying a gene therapy). In this work, we formalize this problem and provide\nan initial solution. Given a collection of candidate mediators, we propose (a)\na two-step method for predicting the causal responses of crude interventions;\nand (b) a testing procedure to identify mediators of crude interventions. We\ndemonstrate, on a range of simulated and real-world-inspired examples, that our\napproach allows us to efficiently estimate the effect of crude interventions\nwith limited data from new treatment regimes.",
          "link": "http://arxiv.org/abs/2106.05074",
          "publishedOn": "2021-06-10T01:56:47.176Z",
          "wordCount": 559,
          "title": "Operationalizing Complex Causes:A Pragmatic View of Mediation. (arXiv:2106.05074v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheung_Y/0/1/0/all/0/1\">Yun Kuen Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1\">Georgios Piliouras</a>",
          "description": "We present a novel control-theoretic understanding of online optimization and\nlearning in games, via the notion of passivity. Passivity is a fundamental\nconcept in control theory, which abstracts energy conservation and dissipation\nin physical systems. It has become a standard tool in analysis of general\nfeedback systems, to which game dynamics belong. Our starting point is to show\nthat all continuous-time Follow-the-Regularized-Leader (FTRL) dynamics, which\nincludes the well-known Replicator Dynamic, are lossless, i.e. it is passive\nwith no energy dissipation. Interestingly, we prove that passivity implies\nbounded regret, connecting two fundamental primitives of control theory and\nonline optimization.\n\nThe observation of energy conservation in FTRL inspires us to present a\nfamily of lossless learning dynamics, each of which has an underlying energy\nfunction with a simple gradient structure. This family is closed under convex\ncombination; as an immediate corollary, any convex combination of FTRL dynamics\nis lossless and thus has bounded regret. This allows us to extend the framework\nof Fox and Shamma (Games, 2013) to prove not just global asymptotic stability\nresults for game dynamics, but Poincar\\'e recurrence results as well.\nIntuitively, when a lossless game (e.g. graphical constant-sum game) is coupled\nwith lossless learning dynamic, their interconnection is also lossless, which\nresults in a pendulum-like energy-preserving recurrent behavior, generalizing\nthe results of Piliouras and Shamma (SODA, 2014) and Mertikopoulos,\nPapadimitriou and Piliouras (SODA, 2018).",
          "link": "http://arxiv.org/abs/2106.04748",
          "publishedOn": "2021-06-10T01:56:47.170Z",
          "wordCount": 680,
          "title": "Online Optimization in Games via Control Theory: Connecting Regret, Passivity and Poincar\\'e Recurrence. (arXiv:2106.04748v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1\">Danqi Liao</a>",
          "description": "Sentence embeddings encode sentences in fixed dense vectors and have played\nan important role in various NLP tasks and systems. Methods for building\nsentence embeddings include unsupervised learning such as Quick-Thoughts and\nsupervised learning such as InferSent. With the success of pretrained NLP\nmodels, recent research shows that fine-tuning pretrained BERT on SNLI and\nMulti-NLI data creates state-of-the-art sentence embeddings, outperforming\nprevious sentence embeddings methods on various evaluation benchmarks. In this\npaper, we propose a new method to build sentence embeddings by doing supervised\ncontrastive learning. Specifically our method fine-tunes pretrained BERT on\nSNLI data, incorporating both supervised crossentropy loss and supervised\ncontrastive loss. Compared with baseline where fine-tuning is only done with\nsupervised cross-entropy loss similar to current state-of-the-art method SBERT,\nour supervised contrastive method improves 2.8% in average on Semantic Textual\nSimilarity (STS) benchmarks and 1.05% in average on various sentence transfer\ntasks.",
          "link": "http://arxiv.org/abs/2106.04791",
          "publishedOn": "2021-06-10T01:56:47.147Z",
          "wordCount": 565,
          "title": "Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romac_C/0/1/0/all/0/1\">Cl&#xe9;ment Romac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1\">R&#xe9;my Portelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>",
          "description": "Training autonomous agents able to generalize to multiple tasks is a key\ntarget of Deep Reinforcement Learning (DRL) research. In parallel to improving\nDRL algorithms themselves, Automatic Curriculum Learning (ACL) study how\nteacher algorithms can train DRL agents more efficiently by adapting task\nselection to their evolving abilities. While multiple standard benchmarks exist\nto compare DRL agents, there is currently no such thing for ACL algorithms.\nThus, comparing existing approaches is difficult, as too many experimental\nparameters differ from paper to paper. In this work, we identify several key\nchallenges faced by ACL algorithms. Based on these, we present TeachMyAgent\n(TA), a benchmark of current ACL algorithms leveraging procedural task\ngeneration. It includes 1) challenge-specific unit-tests using variants of a\nprocedural Box2D bipedal walker environment, and 2) a new procedural Parkour\nenvironment combining most ACL challenges, making it ideal for global\nperformance assessment. We then use TeachMyAgent to conduct a comparative study\nof representative existing approaches, showcasing the competitiveness of some\nACL algorithms that do not use expert knowledge. We also show that the Parkour\nenvironment remains an open problem. We open-source our environments, all\nstudied ACL algorithms (collected from open-source code or re-implemented), and\nDRL students in a Python package available at\nhttps://github.com/flowersteam/TeachMyAgent.",
          "link": "http://arxiv.org/abs/2103.09815",
          "publishedOn": "2021-06-10T01:56:47.141Z",
          "wordCount": 662,
          "title": "TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL. (arXiv:2103.09815v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1\">Sreenivas Gollapudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guruganesh_G/0/1/0/all/0/1\">Guru Guruganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1\">Kostas Kollias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1\">Pasin Manurangsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1\">Renato Paes Leme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jon Schneider</a>",
          "description": "We consider the following variant of contextual linear bandits motivated by\nrouting applications in navigational engines and recommendation systems. We\nwish to learn a hidden $d$-dimensional value $w^*$. Every round, we are\npresented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible\nactions. If we choose (i.e. recommend to the user) action $x_t$, we obtain\nutility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best\naction $\\arg\\max_{x \\in \\mathcal{X}_t} \\langle x, w^* \\rangle$. We design\nalgorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d\n\\log d))$. To accomplish this, we design novel cutting-plane algorithms with\nlow \"regret\" -- the total distance between the true point $w^*$ and the\nhyperplanes the separation oracle returns. We also consider the variant where\nwe are allowed to provide a list of several recommendations. In this variant,\nwe give an algorithm with $O(d^2 \\log d)$ regret and list size\n$\\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker\nvariant of this problem where the learner only learns the identity of an action\nthat is better than the recommendation. Our results rely on new algorithmic\ntechniques in convex geometry (including a variant of Steiner's formula for the\ncentroid of a convex set) which may be of independent interest.",
          "link": "http://arxiv.org/abs/2106.04819",
          "publishedOn": "2021-06-10T01:56:47.135Z",
          "wordCount": 644,
          "title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms. (arXiv:2106.04819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1\">Sherjil Ozair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yazhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razavi_A/0/1/0/all/0/1\">Ali Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1\">Ioannis Antonoglou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1\">A&#xe4;ron van den Oord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "Recent developments in the field of model-based RL have proven successful in\na range of environments, especially ones where planning is essential. However,\nsuch successes have been limited to deterministic fully-observed environments.\nWe present a new approach that handles stochastic and partially-observable\nenvironments. Our key insight is to use discrete autoencoders to capture the\nmultiple possible effects of an action in a stochastic environment. We use a\nstochastic variant of \\emph{Monte Carlo tree search} to plan over both the\nagent's actions and the discrete latent variables representing the\nenvironment's response. Our approach significantly outperforms an offline\nversion of MuZero on a stochastic interpretation of chess where the opponent is\nconsidered part of the environment. We also show that our approach scales to\n\\emph{DeepMind Lab}, a first-person 3D environment with large visual\nobservations and partial observability.",
          "link": "http://arxiv.org/abs/2106.04615",
          "publishedOn": "2021-06-10T01:56:47.120Z",
          "wordCount": 570,
          "title": "Vector Quantized Models for Planning. (arXiv:2106.04615v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04862",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1\">Boyao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Griesbach_C/0/1/0/all/0/1\">Colin Griesbach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_C/0/1/0/all/0/1\">Cora Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_Voggel_N/0/1/0/all/0/1\">Nadia M&#xfc;ller-Voggel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bergherr_E/0/1/0/all/0/1\">Elisabeth Bergherr</a>",
          "description": "Boosting methods are widely used in statistical learning to deal with\nhigh-dimensional data due to their variable selection feature. However, those\nmethods lack straightforward ways to construct estimators for the precision of\nthe parameters such as variance or confidence interval, which can be achieved\nby conventional statistical methods like Bayesian inference. In this paper, we\npropose a new inference method \"BayesBoost\" that combines boosting and Bayesian\nfor linear mixed models to make the uncertainty estimation for the random\neffects possible on the one hand. On the other hand, the new method overcomes\nthe shortcomings of Bayesian inference in giving precise and unambiguous\nguidelines for the selection of covariates by benefiting from boosting\ntechniques. The implementation of Bayesian inference leads to the randomness of\nmodel selection criteria like the conditional AIC (cAIC), so we also propose a\ncAIC-based model selection criteria that focus on the stabilized regions\ninstead of the global minimum. The effectiveness of the new approach can be\nobserved via simulation and in a data example from the field of neurophysiology\nfocussing on the mechanisms in the brain while listening to unpleasant sounds.",
          "link": "http://arxiv.org/abs/2106.04862",
          "publishedOn": "2021-06-10T01:56:47.114Z",
          "wordCount": 613,
          "title": "Bayesian Boosting for Linear Mixed Models. (arXiv:2106.04862v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isik_B/0/1/0/all/0/1\">Berivan Isik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1\">Albert No</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissman_T/0/1/0/all/0/1\">Tsachy Weissman</a>",
          "description": "We study the neural network (NN) compression problem, viewing the tension\nbetween the compression ratio and NN performance through the lens of\nrate-distortion theory. We choose a distortion metric that reflects the effect\nof NN compression on the model output and then derive the tradeoff between rate\n(compression ratio) and distortion. In addition to characterizing theoretical\nlimits of NN compression, this formulation shows that \\emph{pruning},\nimplicitly or explicitly, must be a part of a good compression algorithm. This\nobservation bridges a gap between parts of the literature pertaining to NN and\ndata compression, respectively, providing insight into the empirical success of\npruning for NN compression. Finally, we propose a novel pruning strategy\nderived from our information-theoretic formulation and show that it outperforms\nthe relevant baselines on CIFAR-10 and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2102.08329",
          "publishedOn": "2021-06-10T01:56:47.106Z",
          "wordCount": 602,
          "title": "Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning. (arXiv:2102.08329v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Han Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wentao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenbiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Anil Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Recent studies suggest that ``memorization'' is one important factor for\noverparameterized deep neural networks (DNNs) to achieve optimal performance.\nSpecifically, the perfectly fitted DNNs can memorize the labels of many\natypical samples, generalize their memorization to correctly classify test\natypical samples and enjoy better test performance. While, DNNs which are\noptimized via adversarial training algorithms can also achieve perfect training\nperformance by memorizing the labels of atypical samples, as well as the\nadversarially perturbed atypical samples. However, adversarially trained models\nalways suffer from poor generalization, with both relatively low clean accuracy\nand robustness on the test set. In this work, we study the effect of\nmemorization in adversarial trained DNNs and disclose two important findings:\n(a) Memorizing atypical samples is only effective to improve DNN's accuracy on\nclean atypical samples, but hardly improve their adversarial robustness and (b)\nMemorizing certain atypical samples will even hurt the DNN's performance on\ntypical samples. Based on these two findings, we propose Benign Adversarial\nTraining (BAT) which can facilitate adversarial training to avoid fitting\n``harmful'' atypical samples and fit as more ``benign'' atypical samples as\npossible. In our experiments, we validate the effectiveness of BAT, and show it\ncan achieve better clean accuracy vs. robustness trade-off than baseline\nmethods, in benchmark datasets such as CIFAR100 and Tiny~ImageNet.",
          "link": "http://arxiv.org/abs/2106.04794",
          "publishedOn": "2021-06-10T01:56:47.081Z",
          "wordCount": 653,
          "title": "Towards the Memorization Effect of Neural Networks in Adversarial Training. (arXiv:2106.04794v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mostafa_S/0/1/0/all/0/1\">Sakib Mostafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1\">Debajyoti Mondal</a>",
          "description": "Deep learning techniques are increasingly being adopted for classification\ntasks over the past decade, yet explaining how deep learning architectures can\nachieve state-of-the-art performance is still an elusive goal. While all the\ntraining information is embedded deeply in a trained model, we still do not\nunderstand much about its performance by only analyzing the model. This paper\nexamines the neuron activation patterns of deep learning-based classification\nmodels and explores whether the models' performances can be explained through\nneurons' activation behavior. We propose two approaches: one that models\nneurons' activation behavior as a graph and examines whether the neurons form\nmeaningful communities, and the other examines the predictability of neurons'\nbehavior using entropy. Our comprehensive experimental study reveals that both\nthe community quality (modularity) and entropy are closely related to the deep\nlearning models' performances, thus paves a novel way of explaining deep\nlearning models directly from the neurons' activation pattern.",
          "link": "http://arxiv.org/abs/2106.04693",
          "publishedOn": "2021-06-10T01:56:47.075Z",
          "wordCount": 588,
          "title": "On the Evolution of Neuron Communities in a Deep Learning Architecture. (arXiv:2106.04693v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_C/0/1/0/all/0/1\">Chengping Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Modeling nonlinear spatiotemporal dynamical systems has primarily relied on\npartial differential equations (PDEs) that are typically derived from first\nprinciples. However, the explicit formulation of PDEs for many underexplored\nprocesses, such as climate systems, biochemical reaction and epidemiology,\nremains uncertain or partially unknown, where very sparse measurement data is\nyet available. To tackle this challenge, we propose a novel deep learning\narchitecture that forcibly embedded known physics knowledge in a\nresidual-recurrent $\\Pi$-block network, to facilitate the learning of the\nspatiotemporal dynamics in a data-driven manner. The coercive embedding\nmechanism of physics, fundamentally different from physics-informed neural\nnetworks based on loss penalty, ensures the network to rigorously obey given\nphysics. Numerical experiments demonstrate that the resulting learning paradigm\nthat embeds physics possesses remarkable accuracy, robustness, interpretability\nand generalizability for learning spatiotemporal dynamics.",
          "link": "http://arxiv.org/abs/2106.04781",
          "publishedOn": "2021-06-10T01:56:47.069Z",
          "wordCount": 577,
          "title": "Embedding Physics to Learn Spatiotemporal Dynamics from Sparse Data. (arXiv:2106.04781v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1\">Sina Mohseni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadawa_J/0/1/0/all/0/1\">Jay Yadawa</a>",
          "description": "The open-world deployment of Machine Learning (ML) algorithms in\nsafety-critical applications such as autonomous vehicles needs to address a\nvariety of ML vulnerabilities such as interpretability, verifiability, and\nperformance limitations. Research explores different approaches to improve ML\ndependability by proposing new models and training techniques to reduce\ngeneralization error, achieve domain adaptation, and detect outlier examples\nand adversarial attacks. In this paper, we review and organize practical ML\ntechniques that can improve the safety and dependability of ML algorithms and\ntherefore ML-based software. Our organization maps state-of-the-art ML\ntechniques to safety strategies in order to enhance the dependability of the ML\nalgorithm from different aspects, and discuss research gaps as well as\npromising solutions.",
          "link": "http://arxiv.org/abs/2106.04823",
          "publishedOn": "2021-06-10T01:56:47.064Z",
          "wordCount": 546,
          "title": "Practical Machine Learning Safety: A Survey and Primer. (arXiv:2106.04823v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04707",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Choudhury_T/0/1/0/all/0/1\">Tuhinangshu Choudhury</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Weina Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shakkottai_S/0/1/0/all/0/1\">Sanjay Shakkottai</a>",
          "description": "In multi-server queueing systems where there is no central queue holding all\nincoming jobs, job dispatching policies are used to assign incoming jobs to the\nqueue at one of the servers. Classic job dispatching policies such as\njoin-the-shortest-queue and shortest expected delay assume that the service\nrates and queue lengths of the servers are known to the dispatcher. In this\nwork, we tackle the problem of job dispatching without the knowledge of service\nrates and queue lengths, where the dispatcher can only obtain noisy estimates\nof the service rates by observing job departures. This problem presents a novel\nexploration-exploitation trade-off between sending jobs to all the servers to\nestimate their service rates, and exploiting the currently known fastest\nservers to minimize the expected queueing delay. We propose a bandit-based\nexploration policy that learns the service rates from observed job departures.\nUnlike the standard multi-armed bandit problem where only one out of a finite\nset of actions is optimal, here the optimal policy requires identifying the\noptimal fraction of incoming jobs to be sent to each server. We present a\nregret analysis and simulations to demonstrate the effectiveness of the\nproposed bandit-based exploration policy.",
          "link": "http://arxiv.org/abs/2106.04707",
          "publishedOn": "2021-06-10T01:56:47.058Z",
          "wordCount": 631,
          "title": "Job Dispatching Policies for Queueing Systems with Unknown Service Rates. (arXiv:2106.04707v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04769",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mitra_S/0/1/0/all/0/1\">Siddharth Mitra</a>, <a href=\"http://arxiv.org/find/math/1/au:+Feldman_M/0/1/0/all/0/1\">Moran Feldman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Karbasi_A/0/1/0/all/0/1\">Amin Karbasi</a>",
          "description": "It has been well established that first order optimization methods can\nconverge to the maximal objective value of concave functions and provide\nconstant factor approximation guarantees for (non-convex/non-concave)\ncontinuous submodular functions. In this work, we initiate the study of the\nmaximization of functions of the form $F(x) = G(x) +C(x)$ over a solvable\nconvex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a\nsmooth concave function. This class of functions is a strict extension of both\nconcave and continuous DR-submodular functions for which no theoretical\nguarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,\ndepending on the nature of the objective function (i.e., if $G$ and $C$ are\nmonotone or not, and non-negative or not) and on the nature of the set $P$\n(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$\napproximation guarantees. We then use our algorithms to get a framework to\nsmoothly interpolate between choosing a diverse set of elements from a given\nground set (corresponding to the mode of a determinantal point process) and\nchoosing a clustered set of elements (corresponding to the maxima of a suitable\nconcave function). Additionally, we apply our algorithms to various functions\nin the above class (DR-submodular + concave) in both constrained and\nunconstrained settings, and show that our algorithms consistently outperform\nnatural baselines.",
          "link": "http://arxiv.org/abs/2106.04769",
          "publishedOn": "2021-06-10T01:56:47.043Z",
          "wordCount": 650,
          "title": "Submodular + Concave. (arXiv:2106.04769v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04729",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Asadi_A/0/1/0/all/0/1\">Amin Asadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pinkley_S/0/1/0/all/0/1\">Sarah Nurre Pinkley</a>",
          "description": "We consider the problem of optimizing the distribution operations of a hub\nusing drones to deliver medical supplies to different geographic regions.\nDrones are an innovative method with many benefits including low-contact\ndelivery thereby reducing the spread of pandemic and vaccine-preventable\ndiseases. While we focus on medical supply delivery for this work, it is\napplicable to drone delivery for many other applications, including food,\npostal items, and e-commerce delivery. In this paper, our goal is to address\ndrone delivery challenges by optimizing the distribution operations at a drone\nhub that dispatch drones to different geographic locations generating\nstochastic demands for medical supplies. By considering different geographic\nlocations, we consider different classes of demand that require different\nflight ranges, which is directly related to the amount of charge held in a\ndrone battery. We classify the stochastic demands based on their distance from\nthe drone hub, use a Markov decision process to model the problem, and perform\ncomputational tests using realistic data representing a prominent drone\ndelivery company. We solve the problem using a reinforcement learning method\nand show its high performance compared with the exact solution found using\ndynamic programming. Finally, we analyze the results and provide insights for\nmanaging the drone hub operations.",
          "link": "http://arxiv.org/abs/2106.04729",
          "publishedOn": "2021-06-10T01:56:47.037Z",
          "wordCount": 658,
          "title": "Drones for Medical Delivery Considering Different Demands Classes: A Markov Decision Process Approach for Managing Health Centers Dispatching Medical Products. (arXiv:2106.04729v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liyanage_Y/0/1/0/all/0/1\">Yasitha Warahena Liyanage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zois_D/0/1/0/all/0/1\">Daphney-Stavroula Zois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chelmis_C/0/1/0/all/0/1\">Charalampos Chelmis</a>",
          "description": "In a typical supervised machine learning setting, the predictions on all test\ninstances are based on a common subset of features discovered during model\ntraining. However, using a different subset of features that is most\ninformative for each test instance individually may not only improve prediction\naccuracy, but also the overall interpretability of the model. At the same time,\nfeature selection methods for classification have been known to be the most\neffective when many features are irrelevant and/or uncorrelated. In fact,\nfeature selection ignoring correlations between features can lead to poor\nclassification performance. In this work, a Bayesian network is utilized to\nmodel feature dependencies. Using the dependency network, a new method is\nproposed that sequentially selects the best feature to evaluate for each test\ninstance individually, and stops the selection process to make a prediction\nonce it determines that no further improvement can be achieved with respect to\nclassification accuracy. The optimum number of features to acquire and the\noptimum classification strategy are derived for each test instance. The\ntheoretical properties of the optimum solution are analyzed, and a new\nalgorithm is proposed that takes advantage of these properties to implement a\nrobust and scalable solution for high dimensional settings. The effectiveness,\ngeneralizability, and scalability of the proposed method is illustrated on a\nvariety of real-world datasets from diverse application domains.",
          "link": "http://arxiv.org/abs/2106.04668",
          "publishedOn": "2021-06-10T01:56:47.025Z",
          "wordCount": 647,
          "title": "Dynamic Instance-Wise Classification in Correlated Feature Spaces. (arXiv:2106.04668v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karami_F/0/1/0/all/0/1\">Farzad Karami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kehtarnavaz_N/0/1/0/all/0/1\">Nasser Kehtarnavaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rotea_M/0/1/0/all/0/1\">Mario Rotea</a>",
          "description": "Each year a growing number of wind farms are being added to power grids to\ngenerate electricity. The power curve of a wind turbine, which exhibits the\nrelationship between generated power and wind speed, plays a major role in\nassessing the performance of a wind farm. Neural networks have been used for\npower curve estimation. However, they do not produce a confidence measure for\ntheir output, unless computationally prohibitive Bayesian methods are used. In\nthis paper, a probabilistic neural network with Monte Carlo dropout is\nconsidered to quantify the model (epistemic) uncertainty of the power curve\nestimation. This approach offers a minimal increase in computational complexity\nover deterministic approaches. Furthermore, by incorporating a probabilistic\nloss function, the noise or aleatoric uncertainty in the data is estimated. The\ndeveloped network captures both model and noise uncertainty which is found to\nbe useful tools in assessing performance. Also, the developed network is\ncompared with existing ones across a public domain dataset showing superior\nperformance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.04656",
          "publishedOn": "2021-06-10T01:56:47.019Z",
          "wordCount": 606,
          "title": "Probabilistic Neural Network to Quantify Uncertainty of Wind Power Estimation. (arXiv:2106.04656v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dai Hai Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Canh Hao Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamitsuka_H/0/1/0/all/0/1\">Hiroshi Mamitsuka</a>",
          "description": "Graph is an usual representation of relational data, which are ubiquitous in\nmanydomains such as molecules, biological and social networks. A popular\napproach to learningwith graph structured data is to make use of graph kernels,\nwhich measure the similaritybetween graphs and are plugged into a kernel\nmachine such as a support vector machine.Weisfeiler-Lehman (WL) based graph\nkernels, which employ WL labeling scheme to extract subtree patterns and\nperform node embedding, are demonstrated to achieve great performance while\nbeing efficiently computable. However, one of the main drawbacks of ageneral\nkernel is the decoupling of kernel construction and learning process. For\nmoleculargraphs, usual kernels such as WL subtree, based on substructures of\nthe molecules, consider all available substructures having the same importance,\nwhich might not be suitable inpractice. In this paper, we propose a method to\nlearn the weights of subtree patterns in the framework of WWL kernels, the\nstate of the art method for graph classification task [14]. To overcome the\ncomputational issue on large scale data sets, we present an efficient learning\nalgorithm and also derive a generalization gap bound to show its convergence.\nFinally, through experiments on synthetic and real-world data sets, we\ndemonstrate the effectiveness of our proposed method for learning the weights\nof subtree patterns.",
          "link": "http://arxiv.org/abs/2106.04739",
          "publishedOn": "2021-06-10T01:56:47.004Z",
          "wordCount": 638,
          "title": "Learning subtree pattern importance for Weisfeiler-Lehmanbased graph kernels. (arXiv:2106.04739v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04805",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yuchen Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bateni_M/0/1/0/all/0/1\">MohammadHossein Bateni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Linhares_A/0/1/0/all/0/1\">Andre Linhares</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almeida_F/0/1/0/all/0/1\">Filipe Miguel Goncalves de Almeida</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montanari_A/0/1/0/all/0/1\">Andrea Montanari</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Norouzi_Fard_A/0/1/0/all/0/1\">Ashkan Norouzi-Fard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tardos_J/0/1/0/all/0/1\">Jakab Tardos</a>",
          "description": "The community detection problem requires to cluster the nodes of a network\ninto a small number of well-connected \"communities\". There has been substantial\nrecent progress in characterizing the fundamental statistical limits of\ncommunity detection under simple stochastic block models. However, in\nreal-world applications, the network structure is typically dynamic, with nodes\nthat join over time. In this setting, we would like a detection algorithm to\nperform only a limited number of updates at each node arrival. While standard\nvoting approaches satisfy this constraint, it is unclear whether they exploit\nthe network information optimally. We introduce a simple model for networks\ngrowing over time which we refer to as streaming stochastic block model\n(StSBM). Within this model, we prove that voting algorithms have fundamental\nlimitations. We also develop a streaming belief-propagation (StreamBP)\napproach, for which we prove optimality in certain regimes. We validate our\ntheoretical findings on synthetic and real data.",
          "link": "http://arxiv.org/abs/2106.04805",
          "publishedOn": "2021-06-10T01:56:46.998Z",
          "wordCount": 598,
          "title": "Streaming Belief Propagation for Community Detection. (arXiv:2106.04805v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mani_A/0/1/0/all/0/1\">A. Mani</a>",
          "description": "In this research, a general theoretical framework for clustering is proposed\nover specific partial algebraic systems by the present author. Her theory helps\nin isolating minimal assumptions necessary for different concepts of clustering\ninformation in any form to be realized in a situation (and therefore in a\nsemantics). \\emph{It is well-known that of the limited number of proofs in the\ntheory of hard and soft clustering that are known to exist, most involve\nstatistical assumptions}. Many methods seem to work because they seem to work\nin specific empirical practice. A new general rough method of analyzing\nclusterings is invented, and this opens the subject to clearer conceptions and\ncontamination-free theoretical proofs. Numeric ideas of validation are also\nproposed to be replaced by those based on general rough approximation. The\nessence of the approach is explained in brief and supported by an example.",
          "link": "http://arxiv.org/abs/2106.04683",
          "publishedOn": "2021-06-10T01:56:46.992Z",
          "wordCount": 579,
          "title": "General Rough Modeling of Cluster Analysis. (arXiv:2106.04683v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1\">Brian Quanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of prediction tasks. However, despite these successes,\nthe recent Predicting Generalization in Deep Learning (PGDL) NeurIPS 2020\ncompetition suggests that there is a need for more robust and efficient\nmeasures of network generalization. In this work, we propose a new framework\nfor evaluating the generalization capabilities of trained networks. We use\nperturbation response (PR) curves that capture the accuracy change of a given\nnetwork as a function of varying levels of training sample perturbation. From\nthese PR curves, we derive novel statistics that capture generalization\ncapability. Specifically, we introduce two new measures for accurately\npredicting generalization gaps: the Gi-score and Pal-score, that are inspired\nby the Gini coefficient and Palma ratio (measures of income inequality), that\naccurately predict generalization gaps. Using our framework applied to intra\nand inter class sample mixup, we attain better predictive scores than the\ncurrent state-of-the-art measures on a majority of tasks in the PGDL\ncompetition. In addition, we show that our framework and the proposed\nstatistics can be used to capture to what extent a trained network is invariant\nto a given parametric input transformation, such as rotation or translation.\nTherefore, these generalization gap prediction statistics also provide a useful\nmeans for selecting the optimal network architectures and hyperparameters that\nare invariant to a certain perturbation.",
          "link": "http://arxiv.org/abs/2106.04765",
          "publishedOn": "2021-06-10T01:56:46.986Z",
          "wordCount": 666,
          "title": "Predicting Deep Neural Network Generalization with Perturbation Response Curves. (arXiv:2106.04765v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shangdi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiqiu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1\">Julian Shun</a>",
          "description": "This paper studies the hierarchical clustering problem, where the goal is to\nproduce a dendrogram that represents clusters at varying scales of a data set.\nWe propose the ParChain framework for designing parallel hierarchical\nagglomerative clustering (HAC) algorithms, and using the framework we obtain\nnovel parallel algorithms for the complete linkage, average linkage, and Ward's\nlinkage criteria. Compared to most previous parallel HAC algorithms, which\nrequire quadratic memory, our new algorithms require only linear memory, and\nare scalable to large data sets. ParChain is based on our parallelization of\nthe nearest-neighbor chain algorithm, and enables multiple clusters to be\nmerged on every round. We introduce two key optimizations that are critical for\nefficiency: a range query optimization that reduces the number of distance\ncomputations required when finding nearest neighbors of clusters, and a caching\noptimization that stores a subset of previously computed distances, which are\nlikely to be reused.\n\nExperimentally, we show that our highly-optimized implementations using 48\ncores with two-way hyper-threading achieve 5.8--110.1x speedup over\nstate-of-the-art parallel HAC algorithms and achieve 13.75--54.23x\nself-relative speedup. Compared to state-of-the-art algorithms, our algorithms\nrequire up to 237.3x less space. Our algorithms are able to scale to data set\nsizes with tens of millions of points, which existing algorithms are not able\nto handle.",
          "link": "http://arxiv.org/abs/2106.04727",
          "publishedOn": "2021-06-10T01:56:46.979Z",
          "wordCount": 661,
          "title": "ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain. (arXiv:2106.04727v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingxing Tan</a>",
          "description": "Transformers have attracted increasing interests in computer vision, but they\nstill fall behind state-of-the-art convolutional networks. In this work, we\nshow that while Transformers tend to have larger model capacity, their\ngeneralization can be worse than convolutional networks due to the lack of the\nright inductive bias. To effectively combine the strengths from both\narchitectures, we present CoAtNets(pronounced \"coat\" nets), a family of hybrid\nmodels built from two key insights:(1) depthwise Convolution and self-Attention\ncan be naturally unified via simple relative attention; (2) vertically stacking\nconvolution layers and attention layers in a principled way is surprisingly\neffective in improving generalization, capacity and efficiency. Experiments\nshow that our CoAtNets achieve state-of-the-art performance under different\nresource constraints across various datasets. For example, CoAtNet achieves\n86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT\ndata, outperforming prior arts of both convolutional networks and Transformers.\nNotably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet\nachieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images\nfrom JFT while using 23x less data.",
          "link": "http://arxiv.org/abs/2106.04803",
          "publishedOn": "2021-06-10T01:56:46.958Z",
          "wordCount": 607,
          "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_M/0/1/0/all/0/1\">Marco Rossi</a>",
          "description": "We propose the ChaCha (Champion-Challengers) algorithm for making an online\nchoice of hyperparameters in online learning settings. ChaCha handles the\nprocess of determining a champion and scheduling a set of `live' challengers\nover time based on sample complexity bounds. It is guaranteed to have sublinear\nregret after the optimal configuration is added into consideration by an\napplication-dependent oracle based on the champions. Empirically, we show that\nChaCha provides good performance across a wide array of datasets when\noptimizing over featurization and hyperparameter decisions.",
          "link": "http://arxiv.org/abs/2106.04815",
          "publishedOn": "2021-06-10T01:56:46.951Z",
          "wordCount": 514,
          "title": "ChaCha for Online AutoML. (arXiv:2106.04815v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:46.943Z",
          "wordCount": 704,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1\">Byunggook Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1\">Jisoo Mok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1\">Hyeokjun Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Despite the increasing interest in neural architecture search (NAS), the\nsignificant computational cost of NAS is a hindrance to researchers. Hence, we\npropose to reduce the cost of NAS using proxy data, i.e., a representative\nsubset of the target data, without sacrificing search performance. Even though\ndata selection has been used across various fields, our evaluation of existing\nselection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that\nthey are not always appropriate for NAS and a new selection method is\nnecessary. By analyzing proxy data constructed using various selection methods\nthrough data entropy, we propose a novel proxy data selection method tailored\nfor NAS. To empirically demonstrate the effectiveness, we conduct thorough\nexperiments across diverse datasets, search spaces, and NAS algorithms.\nConsequently, NAS algorithms with the proposed selection discover architectures\nthat are competitive with those obtained using the entire dataset. It\nsignificantly reduces the search cost: executing DARTS with the proposed\nselection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a\nsingle GPU. Additionally, when the architecture searched on ImageNet using the\nproposed selection is inversely transferred to CIFAR-10, a state-of-the-art\ntest error of 2.4\\% is yielded. Our code is available at\nhttps://github.com/nabk89/NAS-with-Proxy-data.",
          "link": "http://arxiv.org/abs/2106.04784",
          "publishedOn": "2021-06-10T01:56:46.937Z",
          "wordCount": 633,
          "title": "Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_D/0/1/0/all/0/1\">Duc P. Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1\">Erik Skau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desantis_D/0/1/0/all/0/1\">Derek Desantis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1\">Boian Alexandrov</a>",
          "description": "A novel approach to Boolean matrix factorization (BMF) is presented. Instead\nof solving the BMF problem directly, this approach solves a nonnegative\noptimization problem with the constraint over an auxiliary matrix whose Boolean\nstructure is identical to the initial Boolean data. Then the solution of the\nnonnegative auxiliary optimization problem is thresholded to provide a solution\nfor the BMF problem. We provide the proofs for the equivalencies of the two\nsolution spaces under the existence of an exact solution. Moreover, the\nnonincreasing property of the algorithm is also proven. Experiments on\nsynthetic and real datasets are conducted to show the effectiveness and\ncomplexity of the algorithm compared to other current methods.",
          "link": "http://arxiv.org/abs/2106.04708",
          "publishedOn": "2021-06-10T01:56:46.931Z",
          "wordCount": 548,
          "title": "Boolean Matrix Factorization via Nonnegative Auxiliary Optimization. (arXiv:2106.04708v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1\">Charu Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph Neural Networks (GNNs) have achieved promising results for\nsemi-supervised learning tasks on graphs such as node classification. Despite\nthe great success of GNNs, many real-world graphs are often sparsely and\nnoisily labeled, which could significantly degrade the performance of GNNs, as\nthe noisy information could propagate to unlabeled nodes via graph structure.\nThus, it is important to develop a label noise-resistant GNN for\nsemi-supervised node classification. Though extensive studies have been\nconducted to learn neural networks with noisy labels, they mostly focus on\nindependent and identically distributed data and assume a large number of noisy\nlabels are available, which are not directly applicable for GNNs. Thus, we\ninvestigate a novel problem of learning a robust GNN with noisy and limited\nlabels. To alleviate the negative effects of label noise, we propose to link\nthe unlabeled nodes with labeled nodes of high feature similarity to bring more\nclean label information. Furthermore, accurate pseudo labels could be obtained\nby this strategy to provide more supervision and further reduce the effects of\nlabel noise. Our theoretical and empirical analysis verify the effectiveness of\nthese two strategies under mild conditions. Extensive experiments on real-world\ndatasets demonstrate the effectiveness of the proposed method in learning a\nrobust GNN with noisy and limited labels.",
          "link": "http://arxiv.org/abs/2106.04714",
          "publishedOn": "2021-06-10T01:56:46.925Z",
          "wordCount": 643,
          "title": "NRGNN: Learning a Label Noise-Resistant Graph Neural Network on Sparsely and Noisily Labeled Graphs. (arXiv:2106.04714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>",
          "description": "Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.",
          "link": "http://arxiv.org/abs/2106.04619",
          "publishedOn": "2021-06-10T01:56:46.909Z",
          "wordCount": 637,
          "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study the problem of best-arm identification (BAI) in contextual bandits\nin the fixed-budget setting. We propose a general successive elimination\nalgorithm that proceeds in stages and eliminates a fixed fraction of suboptimal\narms in each stage. This design takes advantage of the strengths of static and\nadaptive allocations. We analyze the algorithm in linear models and obtain a\nbetter error bound than prior work. We also apply it to generalized linear\nmodels (GLMs) and bound its error. This is the first BAI algorithm for GLMs in\nthe fixed-budget setting. Our extensive numerical experiments show that our\nalgorithm outperforms the state of art.",
          "link": "http://arxiv.org/abs/2106.04763",
          "publishedOn": "2021-06-10T01:56:46.903Z",
          "wordCount": 532,
          "title": "Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yengera_G/0/1/0/all/0/1\">Gaurav Yengera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devidze_R/0/1/0/all/0/1\">Rati Devidze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1\">Parameswaran Kamalaruban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1\">Adish Singla</a>",
          "description": "We consider the problem of teaching via demonstrations in sequential\ndecision-making settings. In particular, we study how to design a personalized\ncurriculum over demonstrations to speed up the learner's convergence. We\nprovide a unified curriculum strategy for two popular learner models: Maximum\nCausal Entropy Inverse Reinforcement Learning (MaxEnt-IRL) and Cross-Entropy\nBehavioral Cloning (CrossEnt-BC). Our unified strategy induces a ranking over\ndemonstrations based on a notion of difficulty scores computed w.r.t. the\nteacher's optimal policy and the learner's current policy. Compared to the\nstate of the art, our strategy doesn't require access to the learner's internal\ndynamics and still enjoys similar convergence guarantees under mild technical\nconditions. Furthermore, we adapt our curriculum strategy to teach a learner\nusing domain knowledge in the form of task-specific difficulty scores when the\nteacher's optimal policy is unknown. Experiments on a car driving simulator\nenvironment and shortest path problems in a grid-world environment demonstrate\nthe effectiveness of our proposed curriculum strategy.",
          "link": "http://arxiv.org/abs/2106.04696",
          "publishedOn": "2021-06-10T01:56:46.895Z",
          "wordCount": 586,
          "title": "Curriculum Design for Teaching via Demonstrations: Theory and Applications. (arXiv:2106.04696v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1\">Renato Paes Leme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivan_B/0/1/0/all/0/1\">Balasubramanian Sivan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yifeng Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worah_P/0/1/0/all/0/1\">Pratik Worah</a>",
          "description": "In the Learning to Price setting, a seller posts prices over time with the\ngoal of maximizing revenue while learning the buyer's valuation. This problem\nis very well understood when values are stationary (fixed or iid). Here we\nstudy the problem where the buyer's value is a moving target, i.e., they change\nover time either by a stochastic process or adversarially with bounded\nvariation. In either case, we provide matching upper and lower bounds on the\noptimal revenue loss. Since the target is moving, any information learned soon\nbecomes out-dated, which forces the algorithms to keep switching between\nexploring and exploiting phases.",
          "link": "http://arxiv.org/abs/2106.04689",
          "publishedOn": "2021-06-10T01:56:46.888Z",
          "wordCount": 538,
          "title": "Learning to Price Against a Moving Target. (arXiv:2106.04689v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1\">Ioannis Panopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1\">Iakovos S. Venieris</a>",
          "description": "Radical progress in the field of deep learning (DL) has led to unprecedented\naccuracy in diverse inference tasks. As such, deploying DL models across mobile\nplatforms is vital to enable the development and broad availability of the\nnext-generation intelligent apps. Nevertheless, the wide and optimised\ndeployment of DL models is currently hindered by the vast system heterogeneity\nof mobile devices, the varying computational cost of different DL models and\nthe variability of performance needs across DL applications. This paper\nproposes OODIn, a framework for the optimised deployment of DL apps across\nheterogeneous mobile devices. OODIn comprises a novel DL-specific software\narchitecture together with an analytical framework for modelling DL\napplications that: (1) counteract the variability in device resources and DL\nmodels by means of a highly parametrised multi-layer design; and (2) perform a\nprincipled optimisation of both model- and system-level parameters through a\nmulti-objective formulation, designed for DL inference apps, in order to adapt\nthe deployment to the user-specified performance requirements and device\ncapabilities. Quantitative evaluation shows that the proposed framework\nconsistently outperforms status-quo designs across heterogeneous devices and\ndelivers up to 4.3x and 3.5x performance gain over highly optimised platform-\nand model-aware designs respectively, while effectively adapting execution to\ndynamic changes in resource availability.",
          "link": "http://arxiv.org/abs/2106.04723",
          "publishedOn": "2021-06-10T01:56:46.867Z",
          "wordCount": 653,
          "title": "OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1\">Kaiyi Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>",
          "description": "Bilevel optimization has been widely applied in many important machine\nlearning applications such as hyperparameter optimization and meta-learning.\nRecently, several momentum-based algorithms have been proposed to solve bilevel\noptimization problems faster. However, those momentum-based algorithms do not\nachieve provably better computational complexity than\n$\\mathcal{O}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we\npropose two new algorithms for bilevel optimization, where the first algorithm\nadopts momentum-based recursive iterations, and the second algorithm adopts\nrecursive gradient estimations in nested loops to decrease the variance. We\nshow that both algorithms achieve the complexity of\n$\\mathcal{O}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by\nthe order of magnitude. Our experiments validate our theoretical results and\ndemonstrate the superior empirical performance of our algorithms in\nhyperparameter applications. Our codes for MRBO, VRBO and other benchmarks are\navailable $\\text{online}^1$.",
          "link": "http://arxiv.org/abs/2106.04692",
          "publishedOn": "2021-06-10T01:56:46.854Z",
          "wordCount": 570,
          "title": "Provably Faster Algorithms for Bilevel Optimization. (arXiv:2106.04692v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qin Yang</a>",
          "description": "Distributed artificial intelligence (DAI) studies artificial intelligence\nentities working together to reason, plan, solve problems, organize behaviors\nand strategies, make collective decisions and learn. This Ph.D. research\nproposes a principled Multi-Agent Systems (MAS) cooperation framework,\nSelf-Adaptive Swarm System (SASS), to bridge the fourth level automation gap\nbetween perception, communication, planning, execution, decision-making, and\nlearning.",
          "link": "http://arxiv.org/abs/2106.04679",
          "publishedOn": "2021-06-10T01:56:46.837Z",
          "wordCount": 494,
          "title": "Self-Adaptive Swarm System (SASS). (arXiv:2106.04679v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liew_S/0/1/0/all/0/1\">Seng Pei Liew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1\">Tsubasa Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueno_M/0/1/0/all/0/1\">Michihiko Ueno</a>",
          "description": "We propose a new framework of synthesizing data using deep generative models\nin a differentially private manner. Within our framework, sensitive data are\nsanitized with rigorous privacy guarantees in a one-shot fashion, such that\ntraining deep generative models is possible without re-using the original data.\nHence, no extra privacy costs or model constraints are incurred, in contrast to\npopular approaches such as Differentially Private Stochastic Gradient Descent\n(DP-SGD), which, among other issues, causes degradation in privacy guarantees\nas the training iteration increases. We demonstrate a realization of our\nframework by making use of the characteristic function and an adversarial\nre-weighting objective, which are of independent interest as well. Our proposal\nhas theoretical guarantees of performance, and empirical evaluations on\nmultiple datasets show that our approach outperforms other methods at\nreasonable levels of privacy.",
          "link": "http://arxiv.org/abs/2106.04590",
          "publishedOn": "2021-06-10T01:56:46.832Z",
          "wordCount": 572,
          "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning. (arXiv:2106.04590v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04624",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Plantinga_P/0/1/0/all/0/1\">Peter Plantinga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rouhe_A/0/1/0/all/0/1\">Aku Rouhe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cornell_S/0/1/0/all/0/1\">Samuele Cornell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lugosch_L/0/1/0/all/0/1\">Loren Lugosch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Subakan_C/0/1/0/all/0/1\">Cem Subakan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dawalatabad_N/0/1/0/all/0/1\">Nauman Dawalatabad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdelwahab Heba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhong_J/0/1/0/all/0/1\">Jianyuan Zhong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chou_J/0/1/0/all/0/1\">Ju-Chieh Chou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yeh_S/0/1/0/all/0/1\">Sung-Lin Yeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1\">Szu-Wei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_C/0/1/0/all/0/1\">Chien-Feng Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rastorgueva_E/0/1/0/all/0/1\">Elena Rastorgueva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grondin_F/0/1/0/all/0/1\">Fran&#xe7;ois Grondin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aris_W/0/1/0/all/0/1\">William Aris</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Na_H/0/1/0/all/0/1\">Hwidong Na</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_Y/0/1/0/all/0/1\">Yan Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mori_R/0/1/0/all/0/1\">Renato De Mori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed\nto facilitate the research and development of neural speech processing\ntechnologies by being simple, flexible, user-friendly, and well-documented.\nThis paper describes the core architecture designed to support several tasks of\ncommon interest, allowing users to naturally conceive, compare and share novel\nspeech processing pipelines. SpeechBrain achieves competitive or\nstate-of-the-art performance in a wide range of speech benchmarks. It also\nprovides training recipes, pretrained models, and inference scripts for popular\nspeech datasets, as well as tutorials which allow anyone with basic Python\nproficiency to familiarize themselves with speech technologies.",
          "link": "http://arxiv.org/abs/2106.04624",
          "publishedOn": "2021-06-10T01:56:46.799Z",
          "wordCount": 573,
          "title": "SpeechBrain: A General-Purpose Speech Toolkit. (arXiv:2106.04624v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bliek_L/0/1/0/all/0/1\">Laurens Bliek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guijt_A/0/1/0/all/0/1\">Arthur Guijt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1\">Rickard Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1\">Sicco Verwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerdt_M/0/1/0/all/0/1\">Mathijs de Weerdt</a>",
          "description": "Surrogate algorithms such as Bayesian optimisation are especially designed\nfor black-box optimisation problems with expensive objectives, such as\nhyperparameter tuning or simulation-based optimisation. In the literature,\nthese algorithms are usually evaluated with synthetic benchmarks which are well\nestablished but have no expensive objective, and only on one or two real-life\napplications which vary wildly between papers. There is a clear lack of\nstandardisation when it comes to benchmarking surrogate algorithms on\nreal-life, expensive, black-box objective functions. This makes it very\ndifficult to draw conclusions on the effect of algorithmic contributions. A new\nbenchmark library, EXPObench, provides first steps towards such a\nstandardisation. The library is used to provide an extensive comparison of six\ndifferent surrogate algorithms on four expensive optimisation problems from\ndifferent real-life applications. This has led to new insights regarding the\nrelative importance of exploration, the evaluation time of the objective, and\nthe used model. A further contribution is that we make the algorithms and\nbenchmark problem instances publicly available, contributing to more uniform\nanalysis of surrogate algorithms. Most importantly, we include the performance\nof the six algorithms on all evaluated problem instances. This results in a\nunique new dataset that lowers the bar for researching new methods as the\nnumber of expensive evaluations required for comparison is significantly\nreduced.",
          "link": "http://arxiv.org/abs/2106.04618",
          "publishedOn": "2021-06-10T01:56:46.788Z",
          "wordCount": 655,
          "title": "EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on Expensive Black-box Functions. (arXiv:2106.04618v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barth_Maron_G/0/1/0/all/0/1\">Gabriel Barth-Maron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczyk_P/0/1/0/all/0/1\">Piotr Sta&#x144;czyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1\">Matthew Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroiss_M/0/1/0/all/0/1\">Manuel Kroiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1\">Aedan Pope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rrustemi_A/0/1/0/all/0/1\">Alban Rrustemi</a>",
          "description": "A major driver behind the success of modern machine learning algorithms has\nbeen their ability to process ever-larger amounts of data. As a result, the use\nof distributed systems in both research and production has become increasingly\nprevalent as a means to scale to this growing data. At the same time, however,\ndistributing the learning process can drastically complicate the implementation\nof even simple algorithms. This is especially problematic as many machine\nlearning practitioners are not well-versed in the design of distributed\nsystems, let alone those that have complicated communication topologies. In\nthis work we introduce Launchpad, a programming model that simplifies the\nprocess of defining and launching distributed systems that is specifically\ntailored towards a machine learning audience. We describe our framework, its\ndesign philosophy and implementation, and give a number of examples of common\nlearning algorithms whose designs are greatly simplified by this approach.",
          "link": "http://arxiv.org/abs/2106.04516",
          "publishedOn": "2021-06-10T00:27:39.761Z",
          "wordCount": 595,
          "title": "Launchpad: A Programming Model for Distributed Machine Learning Research. (arXiv:2106.04516v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1\">Sajad Khodadadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nafea_M/0/1/0/all/0/1\">Mohamed Nafea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1\">AmirEmad Ghassami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1\">Negar Kiyavash</a>",
          "description": "Machine learning algorithms are increasingly used for consequential decision\nmaking regarding individuals based on their relevant features. Features that\nare relevant for accurate decisions may however lead to either explicit or\nimplicit forms of discrimination against unprivileged groups, such as those of\ncertain race or gender. This happens due to existing biases in the training\ndata, which are often replicated or even exacerbated by the learning algorithm.\nIdentifying and measuring these biases at the data level is a challenging\nproblem due to the interdependence among the features, and the decision\noutcome. In this work, we develop a framework for fairness-aware feature\nselection which takes into account the correlation among the features and the\ndecision outcome, and is based on information theoretic measures for the\naccuracy and discriminatory impacts of features. In particular, we first\npropose information theoretic measures which quantify the impact of different\nsubsets of features on the accuracy and discrimination of the decision\noutcomes. We then deduce the marginal impact of each feature using Shapley\nvalue function; a solution concept in cooperative game theory used to estimate\nmarginal contributions of players in a coalitional game. Finally, we design a\nfairness utility score for each feature (for feature selection) which\nquantifies how this feature influences accurate as well as nondiscriminatory\ndecisions. Our framework depends on the joint statistics of the data rather\nthan a particular classifier design. We examine our proposed framework on real\nand synthetic data to evaluate its performance.",
          "link": "http://arxiv.org/abs/2106.00772",
          "publishedOn": "2021-06-09T22:43:50.610Z",
          "wordCount": 696,
          "title": "Information Theoretic Measures for Fairness-aware Feature Selection. (arXiv:2106.00772v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-09T22:43:50.598Z",
          "wordCount": 599,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1\">Diogo Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1\">Clemens Winter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1\">Wojciech Zaremba</a>",
          "description": "A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.",
          "link": "http://arxiv.org/abs/2106.00958",
          "publishedOn": "2021-06-09T22:43:50.588Z",
          "wordCount": 544,
          "title": "A Generalizable Approach to Learning Optimizers. (arXiv:2106.00958v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Understanding and creating mathematics using natural mathematical language -\nthe mixture of symbolic and natural language used by humans - is a challenging\nand important problem for driving progress in machine learning. As a step in\nthis direction, we develop NaturalProofs, a multi-domain corpus of mathematical\nstatements and their proofs, written in natural mathematical language.\nNaturalProofs unifies broad coverage, deep coverage, and low-resource\nmathematical sources, allowing for evaluating both in-distribution and\nzero-shot generalization. Using NaturalProofs, we benchmark strong neural\nmethods on mathematical reference retrieval and generation tasks which test a\nsystem's ability to determine key results that appear in a proof. Large-scale\nsequence models show promise compared to classical information retrieval\nmethods, yet their performance and out-of-domain generalization leave\nsubstantial room for improvement. NaturalProofs opens many avenues for research\non challenging mathematical tasks.",
          "link": "http://arxiv.org/abs/2104.01112",
          "publishedOn": "2021-06-09T02:01:51.890Z",
          "wordCount": 595,
          "title": "NaturalProofs: Mathematical Theorem Proving in Natural Language. (arXiv:2104.01112v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1\">Brijen Thananjeyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1\">Kirthevasan Kandasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>",
          "description": "We study $(\\epsilon, \\delta)$-PAC best arm identification, where a\ndecision-maker must identify an $\\epsilon$-optimal arm with probability at\nleast $1 - \\delta$, while minimizing the number of arm pulls (samples). Most of\nthe work on this topic is in the sequential setting, where there is no\nconstraint on the time taken to identify such an arm; this allows the\ndecision-maker to pull one arm at a time. In this work, the decision-maker is\ngiven a deadline of $T$ rounds, where, on each round, it can adaptively choose\nwhich arms to pull and how many times to pull them; this distinguishes the\nnumber of decisions made (i.e., time or number of rounds) from the number of\nsamples acquired (cost). Such situations occur in clinical trials, where one\nmay need to identify a promising treatment under a deadline while minimizing\nthe number of test subjects, or in simulation-based studies run on the cloud,\nwhere we can elastically scale up or down the number of virtual machines to\nconduct as many experiments as we wish, but need to pay for the resource-time\nused. As the decision-maker can only make $T$ decisions, she may need to pull\nsome arms excessively relative to a sequential algorithm in order to perform\nwell on all possible problems. We formalize this added difficulty with two\nhardness results that indicate that unlike sequential settings, the ability to\nadapt to the problem difficulty is constrained by the finite deadline. We\npropose Elastic Batch Racing (EBR), a novel algorithm for this setting and\nbound its sample complexity, showing that EBR is optimal with respect to both\nhardness results. We present simulations evaluating EBR in this setting, where\nit outperforms baselines by several orders of magnitude.",
          "link": "http://arxiv.org/abs/2106.03221",
          "publishedOn": "2021-06-09T02:01:51.875Z",
          "wordCount": 741,
          "title": "PAC Best Arm Identification Under a Deadline. (arXiv:2106.03221v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nezhadarya_E/0/1/0/all/0/1\">Ehsan Nezhadarya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fashandi_H/0/1/0/all/0/1\">Homa Fashandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiayi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graham_D/0/1/0/all/0/1\">Darin Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mohak Shah</a>",
          "description": "Batch Normalization (BN) is a popular technique for training Deep Neural\nNetworks (DNNs). BN uses scaling and shifting to normalize activations of\nmini-batches to accelerate convergence and improve generalization. The recently\nproposed Iterative Normalization (IterNorm) method improves these properties by\nwhitening the activations iteratively using Newton's method. However, since\nNewton's method initializes the whitening matrix independently at each training\nstep, no information is shared between consecutive steps. In this work, instead\nof exact computation of whitening matrix at each time step, we estimate it\ngradually during training in an online fashion, using our proposed Stochastic\nWhitening Batch Normalization (SWBN) algorithm. We show that while SWBN\nimproves the convergence rate and generalization of DNNs, its computational\noverhead is less than that of IterNorm. Due to the high efficiency of the\nproposed method, it can be easily employed in most DNN architectures with a\nlarge number of layers. We provide comprehensive experiments and comparisons\nbetween BN, IterNorm, and SWBN layers to demonstrate the effectiveness of the\nproposed technique in conventional (many-shot) image classification and\nfew-shot classification tasks.",
          "link": "http://arxiv.org/abs/2106.04413",
          "publishedOn": "2021-06-09T02:01:51.869Z",
          "wordCount": 613,
          "title": "Stochastic Whitening Batch Normalization. (arXiv:2106.04413v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-09T02:01:51.864Z",
          "wordCount": 701,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04463",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1\">Sharib Ali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1\">Debesh Jha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghatwary_N/0/1/0/all/0/1\">Noha Ghatwary</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Realdon_S/0/1/0/all/0/1\">Stefano Realdon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cannizzaro_R/0/1/0/all/0/1\">Renato Cannizzaro</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Salem_O/0/1/0/all/0/1\">Osama E. Salem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lamarque_D/0/1/0/all/0/1\">Dominique Lamarque</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Daul_C/0/1/0/all/0/1\">Christian Daul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anonsen_K/0/1/0/all/0/1\">Kim V. Anonsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1\">Michael A. Riegler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1\">P&#xe5;l Halvorsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rittscher_J/0/1/0/all/0/1\">Jens Rittscher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1\">Thomas de Lange</a>, <a href=\"http://arxiv.org/find/eess/1/au:+East_J/0/1/0/all/0/1\">James E. East</a>",
          "description": "Polyps in the colon are widely known as cancer precursors identified by\ncolonoscopy either related to diagnostic work-up for symptoms, colorectal\ncancer screening or systematic surveillance of certain diseases. Whilst most\npolyps are benign, the number, size and the surface structure of the polyp are\ntightly linked to the risk of colon cancer. There exists a high missed\ndetection rate and incomplete removal of colon polyps due to the variable\nnature, difficulties to delineate the abnormality, high recurrence rates and\nthe anatomical topography of the colon. In the past, several methods have been\nbuilt to automate polyp detection and segmentation. However, the key issue of\nmost methods is that they have not been tested rigorously on a large\nmulti-center purpose-built dataset. Thus, these methods may not generalise to\ndifferent population datasets as they overfit to a specific population and\nendoscopic surveillance. To this extent, we have curated a dataset from 6\ndifferent centers incorporating more than 300 patients. The dataset includes\nboth single frame and sequence data with 3446 annotated polyp labels with\nprecise delineation of polyp boundaries verified by six senior\ngastroenterologists. To our knowledge, this is the most comprehensive detection\nand pixel-level segmentation dataset curated by a team of computational\nscientists and expert gastroenterologists. This dataset has been originated as\nthe part of the Endocv2021 challenge aimed at addressing generalisability in\npolyp detection and segmentation. In this paper, we provide comprehensive\ninsight into data construction and annotation strategies, annotation quality\nassurance and technical validation for our extended EndoCV2021 dataset which we\nrefer to as PolypGen.",
          "link": "http://arxiv.org/abs/2106.04463",
          "publishedOn": "2021-06-09T02:01:51.853Z",
          "wordCount": 734,
          "title": "PolypGen: A multi-center polyp detection and segmentation dataset for generalisability assessment. (arXiv:2106.04463v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aubret_A/0/1/0/all/0/1\">Arthur Aubret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+matignon_L/0/1/0/all/0/1\">Laetitia matignon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassas_S/0/1/0/all/0/1\">Salima Hassas</a>",
          "description": "The optimal way for a deep reinforcement learning (DRL) agent to explore is\nto learn a set of skills that achieves a uniform distribution of states.\nFollowing this,we introduce DisTop, a new model that simultaneously learns\ndiverse skills and focuses on improving rewarding skills. DisTop progressively\nbuilds a discrete topology of the environment using an unsupervised contrastive\nloss, a growing network and a goal-conditioned policy. Using this topology, a\nstate-independent hierarchical policy can select where the agent has to keep\ndiscovering skills in the state space. In turn, the newly visited states allows\nan improved learnt representation and the learning loop continues. Our\nexperiments emphasize that DisTop is agnostic to the ground state\nrepresentation and that the agent can discover the topology of its environment\nwhether the states are high-dimensional binary data, images, or proprioceptive\ninputs. We demonstrate that this paradigm is competitiveon MuJoCo benchmarks\nwith state-of-the-art algorithms on both single-task dense rewards and diverse\nskill discovery. By combining these two aspects, we showthat DisTop achieves\nstate-of-the-art performance in comparison with hierarchical reinforcement\nlearning (HRL) when rewards are sparse. We believe DisTop opens new\nperspectives by showing that bottom-up skill discovery combined with\nrepresentation learning can unlock the exploration challenge in DRL.",
          "link": "http://arxiv.org/abs/2106.03853",
          "publishedOn": "2021-06-09T02:01:51.847Z",
          "wordCount": 630,
          "title": "DisTop: Discovering a Topological representation to learn diverse and rewarding skills. (arXiv:2106.03853v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alipov_V/0/1/0/all/0/1\">Vyacheslav Alipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1\">Riley Simmons-Edler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putintsev_N/0/1/0/all/0/1\">Nikita Putintsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinin_P/0/1/0/all/0/1\">Pavel Kalinin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "Credit assignment is a fundamental problem in reinforcement learning, the\nproblem of measuring an action's influence on future rewards. Improvements in\ncredit assignment methods have the potential to boost the performance of RL\nalgorithms on many tasks, but thus far have not seen widespread adoption.\nRecently, a family of methods called Hindsight Credit Assignment (HCA) was\nproposed, which explicitly assign credit to actions in hindsight based on the\nprobability of the action having led to an observed outcome. This approach is\nappealing as a means to more efficient data usage, but remains a largely\ntheoretical idea applicable to a limited set of tabular RL tasks, and it is\nunclear how to extend HCA to Deep RL environments. In this work, we explore the\nuse of HCA-style credit in a deep RL context. We first describe the limitations\nof existing HCA algorithms in deep RL, then propose several\ntheoretically-justified modifications to overcome them. Based on this\nexploration, we present a new algorithm, Credit-Constrained Advantage\nActor-Critic (C2A2C), which ignores policy updates for actions which don't\naffect future outcomes based on credit in hindsight, while updating the policy\nas normal for those that do. We find that C2A2C outperforms Advantage\nActor-Critic (A2C) on the Arcade Learning Environment (ALE) benchmark, showing\nbroad improvements over A2C and motivating further work on credit-constrained\nupdate rules for deep RL methods.",
          "link": "http://arxiv.org/abs/2106.04499",
          "publishedOn": "2021-06-09T02:01:51.840Z",
          "wordCount": 660,
          "title": "Towards Practical Credit Assignment for Deep Reinforcement Learning. (arXiv:2106.04499v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Badong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yunfei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengju Ren</a>",
          "description": "A novel model called error loss network (ELN) is proposed to build an error\nloss function for supervised learning. The ELN is in structure similar to a\nradial basis function (RBF) neural network, but its input is an error sample\nand output is a loss corresponding to that error sample. That means the\nnonlinear input-output mapper of ELN creates an error loss function. The\nproposed ELN provides a unified model for a large class of error loss\nfunctions, which includes some information theoretic learning (ITL) loss\nfunctions as special cases. The activation function, weight parameters and\nnetwork size of the ELN can be predetermined or learned from the error samples.\nOn this basis, we propose a new machine learning paradigm where the learning\nprocess is divided into two stages: first, learning a loss function using an\nELN; second, using the learned loss function to continue to perform the\nlearning. Experimental results are presented to demonstrate the desirable\nperformance of the new method.",
          "link": "http://arxiv.org/abs/2106.03722",
          "publishedOn": "2021-06-09T02:01:51.829Z",
          "wordCount": 591,
          "title": "Error Loss Networks. (arXiv:2106.03722v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1\">Daniel Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>",
          "description": "Deep learning algorithms have shown promising results in visual question\nanswering (VQA) tasks, but a more careful look reveals that they often do not\nunderstand the rich signal they are being fed with. To understand and better\nmeasure the generalization capabilities of VQA systems, we look at their\nrobustness to counterfactually augmented data. Our proposed augmentations are\ndesigned to make a focused intervention on a specific property of the question\nsuch that the answer changes. Using these augmentations, we propose a new\nrobustness measure, Robustness to Augmented Data (RAD), which measures the\nconsistency of model predictions between original and augmented examples.\nThrough extensive experimentation, we show that RAD, unlike classical accuracy\nmeasures, can quantify when state-of-the-art systems are not robust to\ncounterfactuals. We find substantial failure cases which reveal that current\nVQA systems are still brittle. Finally, we connect between robustness and\ngeneralization, demonstrating the predictive power of RAD for performance on\nunseen augmentations.",
          "link": "http://arxiv.org/abs/2106.04484",
          "publishedOn": "2021-06-09T02:01:51.810Z",
          "wordCount": 614,
          "title": "Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1\">Tiancheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We consider the best-of-both-worlds problem for learning an episodic Markov\nDecision Process through $T$ episodes, with the goal of achieving\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret when the losses are adversarial and\nsimultaneously $\\mathcal{O}(\\text{polylog}(T))$ regret when the losses are\n(almost) stochastic. Recent work by [Jin and Luo, 2020] achieves this goal when\nthe fixed transition is known, and leaves the case of unknown transition as a\nmajor open question. In this work, we resolve this open problem by using the\nsame Follow-the-Regularized-Leader ($\\text{FTRL}$) framework together with a\nset of new techniques. Specifically, we first propose a loss-shifting trick in\nthe $\\text{FTRL}$ analysis, which greatly simplifies the approach of [Jin and\nLuo, 2020] and already improves their results for the known transition case.\nThen, we extend this idea to the unknown transition case and develop a novel\nanalysis which upper bounds the transition estimation error by (a fraction of)\nthe regret itself in the stochastic setting, a key property to ensure\n$\\mathcal{O}(\\text{polylog}(T))$ regret.",
          "link": "http://arxiv.org/abs/2106.04117",
          "publishedOn": "2021-06-09T02:01:51.800Z",
          "wordCount": 597,
          "title": "The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition. (arXiv:2106.04117v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1\">Michael Poli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massaroli_S/0/1/0/all/0/1\">Stefano Massaroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scimeca_L/0/1/0/all/0/1\">Luca Scimeca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1\">Sanghyuk Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_A/0/1/0/all/0/1\">Atsushi Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asama_H/0/1/0/all/0/1\">Hajime Asama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jinkyoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>",
          "description": "Effective control and prediction of dynamical systems often require\nappropriate handling of continuous-time and discrete, event-triggered\nprocesses. Stochastic hybrid systems (SHSs), common across engineering domains,\nprovide a formalism for dynamical systems subject to discrete, possibly\nstochastic, state jumps and multi-modal continuous-time flows. Despite the\nversatility and importance of SHSs across applications, a general procedure for\nthe explicit learning of both discrete events and multi-mode continuous\ndynamics remains an open problem. This work introduces Neural Hybrid Automata\n(NHAs), a recipe for learning SHS dynamics without a priori knowledge on the\nnumber of modes and inter-modal transition dynamics. NHAs provide a systematic\ninference method based on normalizing flows, neural differential equations and\nself-supervision. We showcase NHAs on several tasks, including mode recovery\nand flow learning in systems with stochastic transitions, and end-to-end\nlearning of hierarchical robot controllers.",
          "link": "http://arxiv.org/abs/2106.04165",
          "publishedOn": "2021-06-09T02:01:51.793Z",
          "wordCount": 594,
          "title": "Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions. (arXiv:2106.04165v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04330",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Peng_H/0/1/0/all/0/1\">Hankui Peng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pavlidis_N/0/1/0/all/0/1\">Nicos G. Pavlidis</a>",
          "description": "Spectral-based subspace clustering methods have proved successful in many\nchallenging applications such as gene sequencing, image recognition, and motion\nsegmentation. In this work, we first propose a novel spectral-based subspace\nclustering algorithm that seeks to represent each point as a sparse convex\ncombination of a few nearby points. We then extend the algorithm to constrained\nclustering and active learning settings. Our motivation for developing such a\nframework stems from the fact that typically either a small amount of labelled\ndata is available in advance; or it is possible to label some points at a cost.\nThe latter scenario is typically encountered in the process of validating a\ncluster assignment. Extensive experiments on simulated and real data sets show\nthat the proposed approach is effective and competitive with state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2106.04330",
          "publishedOn": "2021-06-09T02:01:51.771Z",
          "wordCount": 568,
          "title": "Weighted Sparse Subspace Representation: A Unified Framework for Subspace Clustering, Constrained Clustering, and Active Learning. (arXiv:2106.04330v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1\">J&#xe9;r&#xf4;me Bolte</a> (TSE), <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tam Le</a> (TSE), <a href=\"http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1\">Edouard Pauwels</a> (IRIT), <a href=\"http://arxiv.org/find/cs/1/au:+Silveti_Falls_A/0/1/0/all/0/1\">Antonio Silveti-Falls</a> (TSE)",
          "description": "In view of training increasingly complex learning architectures, we establish\na nonsmooth implicit function theorem with an operational calculus. Our result\napplies to most practical problems (i.e., definable problems) provided that a\nnonsmooth form of the classical invertibility condition is fulfilled. This\napproach allows for formal subdifferentiation: for instance, replacing\nderivatives by Clarke Jacobians in the usual differentiation formulas is fully\njustified for a wide class of nonsmooth problems. Moreover this calculus is\nentirely compatible with algorithmic differentiation (e.g., backpropagation).\nWe provide several applications such as training deep equilibrium networks,\ntraining neural nets with conic optimization layers, or hyperparameter-tuning\nfor nonsmooth Lasso-type models. To show the sharpness of our assumptions, we\npresent numerical experiments showcasing the extremely pathological gradient\ndynamics one can encounter when applying implicit algorithmic differentiation\nwithout any hypothesis.",
          "link": "http://arxiv.org/abs/2106.04350",
          "publishedOn": "2021-06-09T02:01:51.760Z",
          "wordCount": 568,
          "title": "Nonsmooth Implicit Differentiation for Machine Learning and Optimization. (arXiv:2106.04350v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldhahn_R/0/1/0/all/0/1\">Ryan Goldhahn</a>",
          "description": "To tackle the susceptibility of deep neural networks to adversarial examples,\nthe adversarial training has been proposed which provides a notion of security\nthrough an inner maximization problem presenting the first-order adversaries\nembedded within the outer minimization of the training loss. To generalize the\nadversarial robustness over different perturbation types, the adversarial\ntraining method has been augmented with the improved inner maximization\npresenting a union of multiple perturbations e.g., various $\\ell_p$\nnorm-bounded perturbations. However, the improved inner maximization only\nenjoys limited flexibility in terms of the allowable perturbation types. In\nthis work, through a gating mechanism, we assemble a set of expert networks,\neach one either adversarially trained to deal with a particular perturbation\ntype or normally trained for boosting accuracy on clean data. The gating module\nassigns weights dynamically to each expert to achieve superior accuracy under\nvarious data types e.g., adversarial examples, adverse weather perturbations,\nand clean input. In order to deal with the obfuscated gradients issue, the\ntraining of the gating module is conducted together with fine-tuning of the\nlast fully connected layers of expert networks through adversarial training\napproach. Using extensive experiments, we show that our Mixture of Robust\nExperts (MoRE) approach enables flexible integration of a broad range of robust\nexperts with superior performance.",
          "link": "http://arxiv.org/abs/2104.10586",
          "publishedOn": "2021-06-09T02:01:51.747Z",
          "wordCount": 679,
          "title": "Mixture of Robust Experts (MoRE): A Flexible Defense Against Multiple Perturbations. (arXiv:2104.10586v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "Transformer networks are able to capture patterns in data coming from many\ndomains (text, images, videos, proteins, etc.) with little or no change to\narchitecture components. We perform a theoretical analysis of the core\ncomponent responsible for signal propagation between elements, i.e. the\nself-attention matrix. In practice, this matrix typically exhibits two\nproperties: (1) it is sparse, meaning that each token only attends to a small\nsubset of other tokens; and (2) it changes dynamically depending on the input\nto the module. With these considerations in mind, we ask the following\nquestion: Can a fixed self-attention module approximate arbitrary sparse\npatterns depending on the input? How small is the hidden size $d$ required for\nsuch approximation? We make progress in answering this question and show that\nthe self-attention matrix can provably approximate sparse matrices, where\nsparsity is in terms of a bounded number of nonzero elements in each row and\ncolumn. While the parameters of self-attention are fixed, various sparse\nmatrices can be approximated by only modifying the inputs. Our proof is based\non the random projection technique and uses the seminal Johnson-Lindenstrauss\nlemma. Our proof is constructive, enabling us to propose an algorithm for\nfinding adaptive inputs and fixed self-attention parameters in order to\napproximate a given matrix. In particular, we show that, in order to\napproximate any sparse matrix up to a given precision defined in terms of\npreserving matrix element ratios, $d$ grows only logarithmically with the\nsequence length $L$ (i.e. $d = O(\\log L)$).",
          "link": "http://arxiv.org/abs/2106.03764",
          "publishedOn": "2021-06-09T02:01:51.734Z",
          "wordCount": 685,
          "title": "On the Expressive Power of Self-Attention Matrices. (arXiv:2106.03764v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04469",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kovalev_D/0/1/0/all/0/1\">Dmitry Kovalev</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasanov_E/0/1/0/all/0/1\">Elnur Gasanov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "We consider the task of minimizing the sum of smooth and strongly convex\nfunctions stored in a decentralized manner across the nodes of a communication\nnetwork whose links are allowed to change in time. We solve two fundamental\nproblems for this task. First, we establish the first lower bounds on the\nnumber of decentralized communication rounds and the number of local\ncomputations required to find an $\\epsilon$-accurate solution. Second, we\ndesign two optimal algorithms that attain these lower bounds: (i) a variant of\nthe recently proposed algorithm ADOM (Kovalev et al., 2021) enhanced via a\nmulti-consensus subroutine, which is optimal in the case when access to the\ndual gradients is assumed, and (ii) a novel algorithm, called ADOM+, which is\noptimal in the case when access to the primal gradients is assumed. We\ncorroborate the theoretical efficiency of these algorithms by performing an\nexperimental comparison with existing state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04469",
          "publishedOn": "2021-06-09T02:01:51.729Z",
          "wordCount": 593,
          "title": "Lower Bounds and Optimal Algorithms for Smooth and Strongly Convex Decentralized Optimization Over Time-Varying Networks. (arXiv:2106.04469v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yu Guo</a>",
          "description": "We introduce an NLP toolkit based on object-oriented knowledge base and\nmulti-level grammar base. This toolkit focuses on semantic parsing, it also has\nabilities to discover new knowledge and grammar automatically, new discovered\nknowledge and grammar will be identified by human, and will be used to update\nthe knowledge base and grammar base. This process can be iterated many times to\nimprove the toolkit continuously.",
          "link": "http://arxiv.org/abs/2105.05227",
          "publishedOn": "2021-06-09T02:01:51.713Z",
          "wordCount": 542,
          "title": "Doing Natural Language Processing in A Natural Way: An NLP toolkit based on object-oriented knowledge base and multi-level grammar base. (arXiv:2105.05227v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1\">Fan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Guoqiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>",
          "description": "Recently, the (gradient-based) bilevel programming framework is widely used\nin hyperparameter optimization and has achieved excellent performance\nempirically. Previous theoretical work mainly focuses on its optimization\nproperties, while leaving the analysis on generalization largely open. This\npaper attempts to address the issue by presenting an expectation bound w.r.t.\nthe validation set based on uniform stability. Our results can explain some\nmysterious behaviours of the bilevel programming in practice, for instance,\noverfitting to the validation set. We also present an expectation bound for the\nclassical cross-validation algorithm. Our results suggest that gradient-based\nalgorithms can be better than cross-validation under certain conditions in a\ntheoretical perspective. Furthermore, we prove that regularization terms in\nboth the outer and inner levels can relieve the overfitting problem in\ngradient-based algorithms. In experiments on feature learning and data\nreweighting for noisy labels, we corroborate our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.04188",
          "publishedOn": "2021-06-09T02:01:51.708Z",
          "wordCount": 575,
          "title": "Stability and Generalization of Bilevel Programming in Hyperparameter Optimization. (arXiv:2106.04188v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baisero_A/0/1/0/all/0/1\">Andrea Baisero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1\">Christopher Amato</a>",
          "description": "Predictive state representations (PSRs) are models of controlled non-Markov\nobservation sequences which exhibit the same generative process governing POMDP\nobservations without relying on an underlying latent state. In that respect, a\nPSR is indistinguishable from the corresponding POMDP. However, PSRs\nnotoriously ignore the notion of rewards, which undermines the general utility\nof PSR models for control, planning, or reinforcement learning. Therefore, we\ndescribe a sufficient and necessary accuracy condition which determines whether\na PSR is able to accurately model POMDP rewards, we show that rewards can be\napproximated even when the accuracy condition is not satisfied, and we find\nthat a non-trivial number of POMDPs taken from a well-known third-party\nrepository do not satisfy the accuracy condition. We propose reward-predictive\nstate representations (R-PSRs), a generalization of PSRs which accurately\nmodels both observations and rewards, and develop value iteration for R-PSRs.\nWe show that there is a mismatch between optimal POMDP policies and the optimal\nPSR policies derived from approximate rewards. On the other hand, optimal R-PSR\npolicies perfectly match optimal POMDP policies, reconfirming R-PSRs as\naccurate state-less generative models of observations and rewards.",
          "link": "http://arxiv.org/abs/2106.03926",
          "publishedOn": "2021-06-09T02:01:51.703Z",
          "wordCount": 606,
          "title": "Reconciling Rewards with Predictive State Representations. (arXiv:2106.03926v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yueyao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>",
          "description": "We propose a new architecture for artificial neural networks called\nHouseholder-absolute neural layers, or Han-layers for short, that use\nHouseholder reflectors as weight matrices and the absolute-value function for\nactivation. Han-layers, functioning as fully connected layers, are motivated by\nrecent results on neural-network variability and are designed to increase\nactivation ratio and reduce the chance of Collapse to Constants. Neural\nnetworks constructed chiefly from Han-layers are called HanNets. By\nconstruction, HanNets enjoy a theoretical guarantee that vanishing or exploding\ngradient never occurs. We conduct several proof-of-concept experiments. Some\nsurprising results obtained on styled test problems suggest that, under certain\nconditions, HanNets exhibit an unusual ability to produce nearly perfect\nsolutions unattainable by fully connected networks. Experiments on regression\ndatasets show that HanNets can significantly reduce the number of model\nparameters while maintaining or improving the level of generalization accuracy.\nIn addition, by adding a few Han-layers into the pre-classification FC-layer of\na convolutional neural network, we are able to quickly improve a\nstate-of-the-art result on CIFAR10 dataset. These proof-of-concept results are\nsufficient to necessitate further studies on HanNets to understand their\ncapacities and limits, and to exploit their potentials in real-world\napplications.",
          "link": "http://arxiv.org/abs/2106.04088",
          "publishedOn": "2021-06-09T02:01:51.697Z",
          "wordCount": 615,
          "title": "Householder-Absolute Neural Layers For High Variability and Deep Trainability. (arXiv:2106.04088v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05599",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sheikh_S/0/1/0/all/0/1\">Shakeel A. Sheikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sahidullah_M/0/1/0/all/0/1\">Md Sahidullah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hirsch_F/0/1/0/all/0/1\">Fabrice Hirsch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ouni_S/0/1/0/all/0/1\">Slim Ouni</a>",
          "description": "This paper introduces StutterNet, a novel deep learning based stuttering\ndetection capable of detecting and identifying various types of disfluencies.\nMost of the existing work in this domain uses automatic speech recognition\n(ASR) combined with language models for stuttering detection. Compared to the\nexisting work, which depends on the ASR module, our method relies solely on the\nacoustic signal. We use a time-delay neural network (TDNN) suitable for\ncapturing contextual aspects of the disfluent utterances. We evaluate our\nsystem on the UCLASS stuttering dataset consisting of more than 100 speakers.\nOur method achieves promising results and outperforms the state-of-the-art\nresidual neural network based method. The number of trainable parameters of the\nproposed method is also substantially less due to the parameter sharing scheme\nof TDNN.",
          "link": "http://arxiv.org/abs/2105.05599",
          "publishedOn": "2021-06-09T02:01:51.692Z",
          "wordCount": 591,
          "title": "StutterNet: Stuttering Detection Using Time Delay Neural Network. (arXiv:2105.05599v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1\">Ovishake Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Mohtasim Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">MD. Nazrul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1\">Jakaria Rabbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">MD. Kamrul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baz_M/0/1/0/all/0/1\">Mohammed Baz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masud_M/0/1/0/all/0/1\">Mehedi Masud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awal_M/0/1/0/all/0/1\">Md. Abdul Awal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1\">Awal Ahmed Fime</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Md. Tahmid Hasan Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1\">Delowar Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1\">MD. Akil Raihan Iftee</a>",
          "description": "The Bangla language is the seventh most spoken language, with 265 million\nnative and non-native speakers worldwide. However, English is the predominant\nlanguage for online resources and technical knowledge, journals, and\ndocumentation. Consequently, many Bangla-speaking people, who have limited\ncommand of English, face hurdles to utilize English resources. To bridge the\ngap between limited support and increasing demand, researchers conducted many\nexperiments and developed valuable tools and techniques to create and process\nBangla language materials. Many efforts are also ongoing to make it easy to use\nthe Bangla language in the online and technical domains. There are some review\npapers to understand the past, previous, and future Bangla Natural Language\nProcessing (BNLP) trends. The studies are mainly concentrated on the specific\ndomains of BNLP, such as sentiment analysis, speech recognition, optical\ncharacter recognition, and text summarization. There is an apparent scarcity of\nresources that contain a comprehensive study of the recent BNLP tools and\nmethods. Therefore, in this paper, we present a thorough review of 71 BNLP\nresearch papers and categorize them into 11 categories, namely Information\nExtraction, Machine Translation, Named Entity Recognition, Parsing, Parts of\nSpeech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake\nDetection, Text Summarization, Word Sense Disambiguation, and Speech Processing\nand Recognition. We study articles published between 1999 to 2021, and 50% of\nthe papers were published after 2015. We discuss Classical, Machine Learning\nand Deep Learning approaches with different datasets while addressing the\nlimitations and current and future trends of the BNLP.",
          "link": "http://arxiv.org/abs/2105.14875",
          "publishedOn": "2021-06-09T02:01:51.675Z",
          "wordCount": 756,
          "title": "Bangla Natural Language Processing: A Comprehensive Review of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers\nthrough reducing their costs of trial and error for discovering the optimal\nadvertising strategies is crucial for the long-term prosperity of online\nadvertising. To achieve this goal, the advertising platform needs to identify\nthe advertisers' marketing objectives, and then recommend the corresponding\nstrategies to fulfill this objective. In this work, we first deploy a prototype\nof strategy recommender system on Taobao display advertising platform,\nrecommending bid prices and targeted users to advertisers. We further augment\nthis prototype system by directly revealing the advertising performance, and\nthen infer the advertisers' marketing objectives through their adoptions of\ndifferent recommending advertising performance. We use the techniques from\ncontext bandit to jointly learn the advertisers' marketing objectives and the\nrecommending strategies. Online evaluations show that the designed advertising\nstrategy recommender system can optimize the advertisers' advertising\nperformance and increase the platform's revenue. Simulation experiments based\non Taobao online bidding data show that the designed contextual bandit\nalgorithm can effectively optimize the strategy adoption rate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-09T02:01:51.669Z",
          "wordCount": 664,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Alex J. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bica_I/0/1/0/all/0/1\">Ioana Bica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1\">Alihan Huyuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Understanding decision-making in clinical environments is of paramount\nimportance if we are to bring the strengths of machine learning to ultimately\nimprove patient outcomes. Several factors including the availability of public\ndata, the intrinsically offline nature of the problem, and the complexity of\nhuman decision making, has meant that the mainstream development of algorithms\nis often geared towards optimal performance in tasks that do not necessarily\ntranslate well into the medical regime; often overlooking more niche issues\ncommonly associated with the area. We therefore present a new benchmarking\nsuite designed specifically for medical sequential decision making: the\nMedkit-Learn(ing) Environment, a publicly available Python package providing\nsimple and easy access to high-fidelity synthetic medical data. While providing\na standardised way to compare algorithms in a realistic medical setting we\nemploy a generating process that disentangles the policy and environment\ndynamics to allow for a range of customisations, thus enabling systematic\nevaluation of algorithms' robustness against specific challenges prevalent in\nhealthcare.",
          "link": "http://arxiv.org/abs/2106.04240",
          "publishedOn": "2021-06-09T02:01:51.657Z",
          "wordCount": 587,
          "title": "The Medkit-Learn(ing) Environment: Medical Decision Modelling through Simulation. (arXiv:2106.04240v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1\">Roberto Dess&#xec;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1\">Eugene Kharitonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1\">Marco Baroni</a>",
          "description": "As deep networks begin to be deployed as autonomous agents, the issue of how\nthey can communicate with each other becomes important. Here, we train two deep\nnets from scratch to perform realistic referent identification through\nunsupervised emergent communication. We show that the largely interpretable\nemergent protocol allows the nets to successfully communicate even about object\ntypes they did not see at training time. The visual representations induced as\na by-product of our training regime, moreover, show comparable quality, when\nre-used as generic visual features, to a recent self-supervised learning model.\nOur results provide concrete evidence of the viability of (interpretable)\nemergent deep net communication in a more realistic scenario than previously\nconsidered, as well as establishing an intriguing link between this field and\nself-supervised visual learning.",
          "link": "http://arxiv.org/abs/2106.04258",
          "publishedOn": "2021-06-09T02:01:51.652Z",
          "wordCount": 580,
          "title": "Interpretable agent communication from scratch(with a generic visual processor emerging on the side). (arXiv:2106.04258v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boix_Adsera_E/0/1/0/all/0/1\">Enric Boix-Adsera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bresler_G/0/1/0/all/0/1\">Guy Bresler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1\">Frederic Koehler</a>",
          "description": "We consider the problem of learning a tree-structured Ising model from data,\nsuch that subsequent predictions computed using the model are accurate.\nConcretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small\nsets of variables $S$ are accurate. Since its introduction more than 50 years\nago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood\ntree, has been the benchmark algorithm for learning tree-structured graphical\nmodels. A bound on the sample complexity of the Chow-Liu algorithm with respect\nto the prediction-centric local total variation loss was shown in [BK19]. While\nthose results demonstrated that it is possible to learn a useful model even\nwhen recovering the true underlying graph is impossible, their bound depends on\nthe maximum strength of interactions and thus does not achieve the\ninformation-theoretic optimum. In this paper, we introduce a new algorithm that\ncarefully combines elements of the Chow-Liu algorithm with tree metric\nreconstruction methods to efficiently and optimally learn tree Ising models\nunder a prediction-centric loss. Our algorithm is robust to model\nmisspecification and adversarial corruptions. In contrast, we show that the\ncelebrated Chow-Liu algorithm can be arbitrarily suboptimal.",
          "link": "http://arxiv.org/abs/2106.03969",
          "publishedOn": "2021-06-09T02:01:51.635Z",
          "wordCount": 632,
          "title": "Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models. (arXiv:2106.03969v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minami_K/0/1/0/all/0/1\">Kentaro Minami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imajo_K/0/1/0/all/0/1\">Kentaro Imajo</a>",
          "description": "The main task we consider is portfolio construction in a speculative market,\na fundamental problem in modern finance. While various empirical works now\nexist to explore deep learning in finance, the theory side is almost\nnon-existent. In this work, we focus on developing a theoretical framework for\nunderstanding the use of data augmentation for deep-learning-based approaches\nto quantitative finance. The proposed theory clarifies the role and necessity\nof data augmentation for finance; moreover, our theory motivates a simple\nalgorithm of injecting a random noise of strength $\\sqrt{|r_{t-1}|}$ to the\nobserved return $r_{t}$. This algorithm is shown to work well in practice.",
          "link": "http://arxiv.org/abs/2106.04114",
          "publishedOn": "2021-06-09T02:01:51.629Z",
          "wordCount": 536,
          "title": "What Data Augmentation Do We Need for Deep-Learning-Based Finance?. (arXiv:2106.04114v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1\">Victor Garcia Satorras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuchs_F/0/1/0/all/0/1\">Fabian B. Fuchs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1\">Ingmar Posner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This paper introduces a generative model equivariant to Euclidean symmetries:\nE(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the\ndiscriminative E(n) graph neural networks and integrate them as a differential\nequation to obtain an invertible equivariant function: a continuous-time\nnormalizing flow. We demonstrate that E-NFs considerably outperform baselines\nand existing methods from the literature on particle systems such as DW4 and\nLJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our\nknowledge, this is the first flow that jointly generates molecule features and\npositions in 3D.",
          "link": "http://arxiv.org/abs/2105.09016",
          "publishedOn": "2021-06-09T02:01:51.623Z",
          "wordCount": 555,
          "title": "E(n) Equivariant Normalizing Flows. (arXiv:2105.09016v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Chenzhuang Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zihui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>",
          "description": "The world provides us with data of multiple modalities. Intuitively, models\nfusingdata from different modalities outperform unimodal models, since more\ninformationis aggregated. Recently, joining the success of deep learning, there\nis an influentialline of work on deep multimodal learning, which has remarkable\nempirical resultson various applications. However, theoretical justifications\nin this field are notablylacking.Can multimodal provably perform better than\nunimodal? In this paper, we answer this question under a most popular\nmultimodal learningframework, which firstly encodes features from different\nmodalities into a commonlatent space and seamlessly maps the latent\nrepresentations into the task space. Weprove that learning with multiple\nmodalities achieves a smaller population risk thanonly using its subset of\nmodalities. The main intuition is that the former has moreaccurate estimate of\nthe latent space representation. To the best of our knowledge,this is the first\ntheoretical treatment to capture important qualitative phenomenaobserved in\nreal multimodal applications. Combining with experiment results, weshow that\nmultimodal learning does possess an appealing formal guarantee.",
          "link": "http://arxiv.org/abs/2106.04538",
          "publishedOn": "2021-06-09T02:01:51.618Z",
          "wordCount": 597,
          "title": "What Makes Multimodal Learning Better than Single (Provably). (arXiv:2106.04538v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1\">Masatoshi Yoshikawa</a>",
          "description": "Federated learning (FL) is an emerging paradigm for machine learning, in\nwhich data owners can collaboratively train a model by sharing gradients\ninstead of their raw data. Two fundamental research problems in FL are\nincentive mechanism and privacy protection. The former focuses on how to\nincentivize data owners to participate in FL. The latter studies how to protect\ndata owners' privacy while maintaining high utility of trained models. However,\nincentive mechanism and privacy protection in FL have been studied separately\nand no work solves both problems at the same time. In this work, we address the\ntwo problems simultaneously by an FL-Market that incentivizes data owners'\nparticipation by providing appropriate payments and privacy protection.\nFL-Market enables data owners to obtain compensation according to their privacy\nloss quantified by local differential privacy (LDP). Our insight is that, by\nmeeting data owners' personalized privacy preferences and providing appropriate\npayments, we can (1) incentivize privacy risk-tolerant data owners to set\nlarger privacy parameters (i.e., gradients with less noise) and (2) provide\npreferred privacy protection for privacy risk-averse data owners. To achieve\nthis, we design a personalized LDP-based FL framework with a deep\nlearning-empowered auction mechanism for incentivizing trading gradients with\nless noise and optimal aggregation mechanisms for model updates. Our\nexperiments verify the effectiveness of the proposed framework and mechanisms.",
          "link": "http://arxiv.org/abs/2106.04384",
          "publishedOn": "2021-06-09T02:01:51.613Z",
          "wordCount": 638,
          "title": "Incentive Mechanism for Privacy-Preserving Federated Learning. (arXiv:2106.04384v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dereventsov_A/0/1/0/all/0/1\">Anton Dereventsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daws_J/0/1/0/all/0/1\">Joseph D. Daws Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webster_C/0/1/0/all/0/1\">Clayton Webster</a>",
          "description": "We address the challenge of policy evaluation in real-world applications of\nreinforcement learning systems where the available historical data is limited\ndue to ethical, practical, or security considerations. This constrained\ndistribution of data samples often leads to biased policy evaluation estimates.\nTo remedy this, we propose that instead of policy evaluation, one should\nperform policy comparison, i.e. to rank the policies of interest in terms of\ntheir value based on available historical data. In addition we present the\nLimited Data Estimator (LDE) as a simple method for evaluating and comparing\npolicies from a small number of interactions with the environment. According to\nour theoretical analysis, the LDE is shown to be statistically reliable on\npolicy comparison tasks under mild assumptions on the distribution of the\nhistorical data. Additionally, our numerical experiments compare the LDE to\nother policy evaluation methods on the task of policy ranking and demonstrate\nits advantage in various settings.",
          "link": "http://arxiv.org/abs/2106.03934",
          "publishedOn": "2021-06-09T02:01:51.606Z",
          "wordCount": 580,
          "title": "Offline Policy Comparison under Limited Historical Agent-Environment Interactions. (arXiv:2106.03934v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fotakis_D/0/1/0/all/0/1\">Dimitris Fotakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1\">Georgios Piliouras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skoulakis_S/0/1/0/all/0/1\">Stratis Skoulakis</a>",
          "description": "We study dynamic clustering problems from the perspective of online learning.\nWe consider an online learning problem, called \\textit{Dynamic $k$-Clustering},\nin which $k$ centers are maintained in a metric space over time (centers may\nchange positions) such as a dynamically changing set of $r$ clients is served\nin the best possible way. The connection cost at round $t$ is given by the\n\\textit{$p$-norm} of the vector consisting of the distance of each client to\nits closest center at round $t$, for some $p\\geq 1$ or $p = \\infty$. We present\na \\textit{$\\Theta\\left( \\min(k,r) \\right)$-regret} polynomial-time online\nlearning algorithm and show that, under some well-established computational\ncomplexity conjectures, \\textit{constant-regret} cannot be achieved in\npolynomial-time. In addition to the efficient solution of Dynamic\n$k$-Clustering, our work contributes to the long line of research on\ncombinatorial online learning.",
          "link": "http://arxiv.org/abs/2106.04336",
          "publishedOn": "2021-06-09T02:01:51.590Z",
          "wordCount": 552,
          "title": "Efficient Online Learning for Dynamic k-Clustering. (arXiv:2106.04336v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1\">Serguei Barannikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1\">Ilya Trofimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotnikov_G/0/1/0/all/0/1\">Grigorii Sotnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trimbach_E/0/1/0/all/0/1\">Ekaterina Trimbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1\">Alexander Filippov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "We develop a framework for comparing data manifolds, aimed, in particular,\ntowards the evaluation of deep generative models. We describe a novel tool,\nCross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional\nspace, tracks multiscale topology spacial discrepancies between manifolds on\nwhich the distributions are concentrated. Based on the Cross-Barcode, we\nintroduce the Manifold Topology Divergence score (MTop-Divergence) and apply it\nto assess the performance of deep generative models in various domains: images,\n3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN,\nCIFAR10, FFHQ, chest X-ray images, market stock data, ShapeNet. We demonstrate\nthat the MTop-Divergence accurately detects various degrees of mode-dropping,\nintra-mode collapse, mode invention, and image disturbance. Our algorithm\nscales well (essentially linearly) with the increase of the dimension of the\nambient high-dimensional space. It is one of the first TDA-based practical\nmethodologies that can be applied universally to datasets of different sizes\nand dimensions, including the ones on which the most recent GANs in the visual\ndomain are trained. The proposed method is domain agnostic and does not rely on\npre-trained networks.",
          "link": "http://arxiv.org/abs/2106.04024",
          "publishedOn": "2021-06-09T02:01:51.583Z",
          "wordCount": 615,
          "title": "Manifold Topology Divergence: a Framework for Comparing Data Manifolds. (arXiv:2106.04024v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1\">Oleksandr Shchur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turkmen_A/0/1/0/all/0/1\">Ali Caner T&#xfc;rkmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Januschowski_T/0/1/0/all/0/1\">Tim Januschowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasthaus_J/0/1/0/all/0/1\">Jan Gasthaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Automatically detecting anomalies in event data can provide substantial value\nin domains such as healthcare, DevOps, and information security. In this paper,\nwe frame the problem of detecting anomalous continuous-time event sequences as\nout-of-distribution (OoD) detection for temporal point processes (TPPs). First,\nwe show how this problem can be approached using goodness-of-fit (GoF) tests.\nWe then demonstrate the limitations of popular GoF statistics for TPPs and\npropose a new test that addresses these shortcomings. The proposed method can\nbe combined with various TPP models, such as neural TPPs, and is easy to\nimplement. In our experiments, we show that the proposed statistic excels at\nboth traditional GoF testing, as well as at detecting anomalies in simulated\nand real-world data.",
          "link": "http://arxiv.org/abs/2106.04465",
          "publishedOn": "2021-06-09T02:01:51.578Z",
          "wordCount": 546,
          "title": "Detecting Anomalous Event Sequences with Temporal Point Processes. (arXiv:2106.04465v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.08834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Shih-Po Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Cun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Hsiao Peng</a>",
          "description": "This paper addresses fast semantic segmentation on video.Video segmentation\noften calls for real-time, or even fasterthan real-time, processing. One common\nrecipe for conserving computation arising from feature extraction is to\npropagate features of few selected keyframes. However, recent advances in fast\nimage segmentation make these solutions less attractive. To leverage fast image\nsegmentation for furthering video segmentation, we propose a simple yet\nefficient propagation framework. Specifically, we perform lightweight flow\nestimation in 1/8-downscaled image space for temporal warping in segmentation\noutpace space. Moreover, we introduce a guided spatially-varying convolution\nfor fusing segmentations derived from the previous and current frames, to\nmitigate propagation error and enable lightweight feature extraction on\nnon-keyframes. Experimental results on Cityscapes and CamVid show that our\nscheme achieves the state-of-the-art accuracy-throughput trade-off on video\nsegmentation.",
          "link": "http://arxiv.org/abs/2103.08834",
          "publishedOn": "2021-06-09T02:01:51.572Z",
          "wordCount": 589,
          "title": "GSVNet: Guided Spatially-Varying Convolution for Fast Semantic Segmentation on Video. (arXiv:2103.08834v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Makkunda Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_N/0/1/0/all/0/1\">Nikhil Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_J/0/1/0/all/0/1\">Jigar Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagad_P/0/1/0/all/0/1\">Piyush Bagad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_A/0/1/0/all/0/1\">Aman Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhamare_P/0/1/0/all/0/1\">Parag Bhamare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahale_A/0/1/0/all/0/1\">Amrita Mahale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rane_S/0/1/0/all/0/1\">Saurabh Rane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_N/0/1/0/all/0/1\">Neeraj Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panicker_R/0/1/0/all/0/1\">Rahul Panicker</a>",
          "description": "Rapidly scaling screening, testing and quarantine has shown to be an\neffective strategy to combat the COVID-19 pandemic. We consider the application\nof deep learning techniques to distinguish individuals with COVID from\nnon-COVID by using data acquirable from a phone. Using cough and context\n(symptoms and meta-data) represent such a promising approach. Several\nindependent works in this direction have shown promising results. However, none\nof them report performance across clinically relevant data splits.\nSpecifically, the performance where the development and test sets are split in\ntime (retrospective validation) and across sites (broad validation). Although\nthere is meaningful generalization across these splits the performance\nsignificantly varies (up to 0.1 AUC score). In addition, we study the\nperformance of symptomatic and asymptomatic individuals across these three\nsplits. Finally, we show that our model focuses on meaningful features of the\ninput, cough bouts for cough and relevant symptoms for context. The code and\ncheckpoints are available at https://github.com/WadhwaniAI/cough-against-covid",
          "link": "http://arxiv.org/abs/2106.03851",
          "publishedOn": "2021-06-09T02:01:51.567Z",
          "wordCount": 677,
          "title": "Impact of data-splits on generalization: Identifying COVID-19 from cough and context. (arXiv:2106.03851v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grinsztajn_N/0/1/0/all/0/1\">Nathan Grinsztajn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferret_J/0/1/0/all/0/1\">Johan Ferret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1\">Philippe Preux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>",
          "description": "We propose to learn to distinguish reversible from irreversible actions for\nbetter informed decision-making in Reinforcement Learning (RL). From\ntheoretical considerations, we show that approximate reversibility can be\nlearned through a simple surrogate task: ranking randomly sampled trajectory\nevents in chronological order. Intuitively, pairs of events that are always\nobserved in the same order are likely to be separated by an irreversible\nsequence of actions. Conveniently, learning the temporal order of events can be\ndone in a fully self-supervised way, which we use to estimate the reversibility\nof actions from experience, without any priors. We propose two different\nstrategies that incorporate reversibility in RL agents, one strategy for\nexploration (RAE) and one strategy for control (RAC). We demonstrate the\npotential of reversibility-aware agents in several environments, including the\nchallenging Sokoban game. In synthetic tasks, we show that we can learn control\npolicies that never fail and reduce to zero the side-effects of interactions,\neven without access to the reward function.",
          "link": "http://arxiv.org/abs/2106.04480",
          "publishedOn": "2021-06-09T02:01:51.552Z",
          "wordCount": 597,
          "title": "There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning. (arXiv:2106.04480v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Reeve_H/0/1/0/all/0/1\">Henry W. J. Reeve</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cannings_T/0/1/0/all/0/1\">Timothy I. Cannings</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Samworth_R/0/1/0/all/0/1\">Richard J. Samworth</a>",
          "description": "In transfer learning, we wish to make inference about a target population\nwhen we have access to data both from the distribution itself, and from a\ndifferent but related source distribution. We introduce a flexible framework\nfor transfer learning in the context of binary classification, allowing for\ncovariate-dependent relationships between the source and target distributions\nthat are not required to preserve the Bayes decision boundary. Our main\ncontributions are to derive the minimax optimal rates of convergence (up to\npoly-logarithmic factors) in this problem, and show that the optimal rate can\nbe achieved by an algorithm that adapts to key aspects of the unknown transfer\nrelationship, as well as the smoothness and tail parameters of our\ndistributional classes. This optimal rate turns out to have several regimes,\ndepending on the interplay between the relative sample sizes and the strength\nof the transfer relationship, and our algorithm achieves optimality by careful,\ndecision tree-based calibration of local nearest-neighbour procedures.",
          "link": "http://arxiv.org/abs/2106.04455",
          "publishedOn": "2021-06-09T02:01:51.541Z",
          "wordCount": 580,
          "title": "Adaptive transfer learning. (arXiv:2106.04455v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.16547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse\ntrainable subnetworks, or winning tickets, of training, which can be trained in\nisolation to achieve similar or even better performance compared to the full\nmodels. Despite many efforts being made, the most effective method to identify\nsuch winning tickets is still Iterative Magnitude-based Pruning (IMP), which is\ncomputationally expensive and has to be run thoroughly for every different\nnetwork. A natural question that comes in is: can we \"transform\" the winning\nticket found in one network to another with a different architecture, yielding\na winning ticket for the latter at the beginning, without re-doing the\nexpensive IMP? Answering this question is not only practically relevant for\nefficient \"once-for-all\" winning ticket finding, but also theoretically\nappealing for uncovering inherently scalable sparse patterns in networks. We\nconduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety\nof strategies to tweak the winning tickets found from different networks of the\nsame model family (e.g., ResNets). Based on these results, we articulate the\nElastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or\ndropping) and re-ordering layers for one network, its corresponding winning\nticket could be stretched (or squeezed) into a subnetwork for another deeper\n(or shallower) network from the same family, whose performance is nearly the\nsame competitive as the latter's winning ticket directly found by IMP. We have\nalso thoroughly compared E-LTH with pruning-at-initialization and dynamic\nsparse training methods, and discuss the generalizability of E-LTH to different\nmodel families, layer types, or across datasets. Code is available at\nhttps://github.com/VITA-Group/ElasticLTH.",
          "link": "http://arxiv.org/abs/2103.16547",
          "publishedOn": "2021-06-09T02:01:51.536Z",
          "wordCount": 731,
          "title": "The Elastic Lottery Ticket Hypothesis. (arXiv:2103.16547v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1\">Ameya D. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuttle_M/0/1/0/all/0/1\">Michael Tuttle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanbhag_N/0/1/0/all/0/1\">Naresh R. Shanbhag</a>",
          "description": "Classical adversarial training (AT) frameworks are designed to achieve high\nadversarial accuracy against a single attack type, typically $\\ell_\\infty$\nnorm-bounded perturbations. Recent extensions in AT have focused on defending\nagainst the union of multiple perturbations but this benefit is obtained at the\nexpense of a significant (up to $10\\times$) increase in training complexity\nover single-attack $\\ell_\\infty$ AT. In this work, we expand the capabilities\nof widely popular single-attack $\\ell_\\infty$ AT frameworks to provide\nrobustness to the union of ($\\ell_\\infty, \\ell_2, \\ell_1$) perturbations while\npreserving their training efficiency. Our technique, referred to as Shaped\nNoise Augmented Processing (SNAP), exploits a well-established byproduct of\nsingle-attack AT frameworks -- the reduction in the curvature of the decision\nboundary of networks. SNAP prepends a given deep net with a shaped noise\naugmentation layer whose distribution is learned along with network parameters\nusing any standard single-attack AT. As a result, SNAP enhances adversarial\naccuracy of ResNet-18 on CIFAR-10 against the union of ($\\ell_\\infty, \\ell_2,\n\\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)\nsingle-attack $\\ell_\\infty$ AT frameworks, and, for the first time, establishes\na benchmark for ResNet-50 and ResNet-101 on ImageNet.",
          "link": "http://arxiv.org/abs/2105.14710",
          "publishedOn": "2021-06-09T02:01:51.520Z",
          "wordCount": 637,
          "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of Perturbation Models. (arXiv:2105.14710v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabinovitz_C/0/1/0/all/0/1\">Carmel Rabinovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grupen_N/0/1/0/all/0/1\">Niko Grupen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1\">Aviv Tamar</a>",
          "description": "Robotic tasks such as manipulation with visual inputs require image features\nthat capture the physical properties of the scene, e.g., the position and\nconfiguration of objects. Recently, it has been suggested to learn such\nfeatures in an unsupervised manner from simulated, self-supervised, robot\ninteraction; the idea being that high-level physical properties are well\ncaptured by modern physical simulators, and their representation from visual\ninputs may transfer well to the real world. In particular, learning methods\nbased on noise contrastive estimation have shown promising results. To\nrobustify the simulation-to-real transfer, domain randomization (DR) was\nsuggested for learning features that are invariant to irrelevant visual\nproperties such as textures or lighting. In this work, however, we show that a\nnaive application of DR to unsupervised learning based on contrastive\nestimation does not promote invariance, as the loss function maximizes mutual\ninformation between the features and both the relevant and irrelevant visual\nproperties. We propose a simple modification of the contrastive loss to fix\nthis, exploiting the fact that we can control the simulated randomization of\nvisual properties. Our approach learns physical features that are significantly\nmore robust to visual domain variation, as we demonstrate using both rigid and\nnon-rigid objects.",
          "link": "http://arxiv.org/abs/2103.11144",
          "publishedOn": "2021-06-09T02:01:51.515Z",
          "wordCount": 668,
          "title": "Unsupervised Feature Learning for Manipulation with Contrastive Domain Randomization. (arXiv:2103.11144v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takeishi_N/0/1/0/all/0/1\">Naoya Takeishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1\">Alexandros Kalousis</a>",
          "description": "Integrating physics models within machine learning models holds considerable\npromise toward learning robust models with improved interpretability and\nabilities to extrapolate. In this work, we focus on the integration of\nincomplete physics models into deep generative models. In particular, we\nintroduce an architecture of variational autoencoders (VAEs) in which a part of\nthe latent space is grounded by physics. A key technical challenge is to strike\na balance between the incomplete physics and trainable components such as\nneural networks for ensuring that the physics part is used in a meaningful\nmanner. To this end, we propose a regularized learning method that controls the\neffect of the trainable components and preserves the semantics of the\nphysics-based latent variables as intended. We not only demonstrate generative\nperformance improvements over a set of synthetic and real-world datasets, but\nwe also show that we learn robust models that can consistently extrapolate\nbeyond the training distribution in a meaningful manner. Moreover, we show that\nwe can control the generative process in an interpretable manner.",
          "link": "http://arxiv.org/abs/2102.13156",
          "publishedOn": "2021-06-09T02:01:51.509Z",
          "wordCount": 622,
          "title": "Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling. (arXiv:2102.13156v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04646",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1\">Chengchun Shi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wan_R/0/1/0/all/0/1\">Runzhe Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1\">Victor Chernozhukov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_R/0/1/0/all/0/1\">Rui Song</a>",
          "description": "Off-policy evaluation learns a target policy's value with a historical\ndataset generated by a different behavior policy. In addition to a point\nestimate, many applications would benefit significantly from having a\nconfidence interval (CI) that quantifies the uncertainty of the point estimate.\nIn this paper, we propose a novel deeply-debiasing procedure to construct an\nefficient, robust, and flexible CI on a target policy's value. Our method is\njustified by theoretical results and numerical experiments. A Python\nimplementation of the proposed procedure is available at\nhttps://github.com/RunzheStat/D2OPE.",
          "link": "http://arxiv.org/abs/2105.04646",
          "publishedOn": "2021-06-09T02:01:51.504Z",
          "wordCount": 528,
          "title": "Deeply-Debiased Off-Policy Interval Estimation. (arXiv:2105.04646v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhaozhuo Xu</a>",
          "description": "We present the first provable Least-Squares Value Iteration (LSVI) algorithms\nthat have runtime complexity sublinear in the number of actions. We formulate\nthe value function estimation procedure in value iteration as an approximate\nmaximum inner product search problem and propose a locality sensitive hashing\n(LSH) [Indyk and Motwani STOC'98, Andoni and Razenshteyn STOC'15, Andoni,\nLaarhoven, Razenshteyn and Waingarten SODA'17] type data structure to solve\nthis problem with sublinear time complexity. Moreover, we build the connections\nbetween the theory of approximate maximum inner product search and the regret\nanalysis of reinforcement learning. We prove that, with our choice of\napproximation factor, our Sublinear LSVI algorithms maintain the same regret as\nthe original LSVI algorithms while reducing the runtime complexity to sublinear\nin the number of actions. To the best of our knowledge, this is the first work\nthat combines LSH with reinforcement learning resulting in provable\nimprovements. We hope that our novel way of combining data-structures and\niterative algorithm will open the door for further study into cost reduction in\noptimization.",
          "link": "http://arxiv.org/abs/2105.08285",
          "publishedOn": "2021-06-09T02:01:51.499Z",
          "wordCount": 632,
          "title": "Sublinear Least-Squares Value Iteration via Locality Sensitive Hashing. (arXiv:2105.08285v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04228",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sentenac_F/0/1/0/all/0/1\">Flore Sentenac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1\">Etienne Boursier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perchet_V/0/1/0/all/0/1\">Vianney Perchet</a>",
          "description": "Motivated by packet routing in computer networks, online queuing systems are\ncomposed of queues receiving packets at different rates. Repeatedly, they send\npackets to servers, each of them treating only at most one packet at a time. In\nthe centralized case, the number of accumulated packets remains bounded (i.e.,\nthe system is \\textit{stable}) as long as the ratio between service rates and\narrival rates is larger than $1$. In the decentralized case, individual\nno-regret strategies ensures stability when this ratio is larger than $2$. Yet,\nmyopically minimizing regret disregards the long term effects due to the\ncarryover of packets to further rounds. On the other hand, minimizing long term\ncosts leads to stable Nash equilibria as soon as the ratio exceeds\n$\\frac{e}{e-1}$. Stability with decentralized learning strategies with a ratio\nbelow $2$ was a major remaining question. We first argue that for ratios up to\n$2$, cooperation is required for stability of learning strategies, as selfish\nminimization of policy regret, a \\textit{patient} notion of regret, might\nindeed still be unstable in this case. We therefore consider cooperative queues\nand propose the first learning decentralized algorithm guaranteeing stability\nof the system as long as the ratio of rates is larger than $1$, thus reaching\nperformances comparable to centralized strategies.",
          "link": "http://arxiv.org/abs/2106.04228",
          "publishedOn": "2021-06-09T02:01:51.484Z",
          "wordCount": 644,
          "title": "Decentralized Learning in Online Queuing Systems. (arXiv:2106.04228v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04506",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Md Faisal Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_Z/0/1/0/all/0/1\">Zalish Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biash_Z/0/1/0/all/0/1\">Zarin Tasnim Biash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryen_A/0/1/0/all/0/1\">Ahmed Ann Noor Ryen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_A/0/1/0/all/0/1\">Arman Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashraf_F/0/1/0/all/0/1\">Faisal Bin Ashraf</a>",
          "description": "Cyberbullying or Online harassment detection on social media for various\nmajor languages is currently being given a good amount of focus by researchers\nworldwide. Being the seventh most speaking language in the world and increasing\nusage of online platform among the Bengali speaking people urge to find\neffective detection technique to handle the online harassment. In this paper,\nwe have proposed binary and multiclass classification model using hybrid neural\nnetwork for bully expression detection in Bengali language. We have used 44,001\nusers comments from popular public Facebook pages, which fall into five classes\n- Non-bully, Sexual, Threat, Troll and Religious. We have examined the\nperformance of our proposed models from different perspective. Our binary\nclassification model gives 87.91% accuracy, whereas introducing ensemble\ntechnique after neural network for multiclass classification, we got 85%\naccuracy.",
          "link": "http://arxiv.org/abs/2106.04506",
          "publishedOn": "2021-06-09T02:01:51.468Z",
          "wordCount": null,
          "title": "Cyberbullying Detection Using Deep Neural Network from Social Media Comments in Bangla Language. (arXiv:2106.04506v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vrbanec_T/0/1/0/all/0/1\">Tedo Vrbanec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mestrovic_A/0/1/0/all/0/1\">Ana Mestrovic</a>",
          "description": "Academic plagiarism is a serious problem nowadays. Due to the existence of\ninexhaustible sources of digital information, today it is easier to plagiarize\nmore than ever before. The good thing is that plagiarism detection techniques\nhave improved and are powerful enough to detect attempts of plagiarism in\neducation. We are now witnessing efficient plagiarism detection software in\naction, such as Turnitin, iThenticate or SafeAssign. In the introduction we\nexplore software that is used within the Croatian academic community for\nplagiarism detection in universities and/or in scientific journals. The\nquestion is: is this enough? Current software has proven to be successful,\nhowever the problem of identifying paraphrasing or obfuscation plagiarism\nremains unresolved. In this paper we present a report of how semantic\nsimilarity measures can be used in the plagiarism detection task.",
          "link": "http://arxiv.org/abs/2106.04404",
          "publishedOn": "2021-06-09T02:01:51.443Z",
          "wordCount": null,
          "title": "The Struggle with Academic Plagiarism: Approaches based on Semantic Similarity. (arXiv:2106.04404v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garello_L/0/1/0/all/0/1\">Luca Garello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastrico_L/0/1/0/all/0/1\">Linda Lastrico</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rea_F/0/1/0/all/0/1\">Francesco Rea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastrogiovanni_F/0/1/0/all/0/1\">Fulvio Mastrogiovanni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noceti_N/0/1/0/all/0/1\">Nicoletta Noceti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sciutti_A/0/1/0/all/0/1\">Alessandra Sciutti</a>",
          "description": "When transporting an object, we unconsciously adapt our movement to its\nproperties, for instance by slowing down when the item is fragile. The most\nrelevant features of an object are immediately revealed to a human observer by\nthe way the handling occurs, without any need for verbal description. It would\ngreatly facilitate collaboration to enable humanoid robots to perform movements\nthat convey similar intuitive cues to the observers. In this work, we focus on\nhow to generate robot motion adapted to the hidden properties of the\nmanipulated objects, such as their weight and fragility. We explore the\npossibility of leveraging Generative Adversarial Networks to synthesize new\nactions coherent with the properties of the object. The use of a generative\napproach allows us to create new and consistent motion patterns, without the\nneed of collecting a large number of recorded human-led demonstrations.\nBesides, the informative content of the actions is preserved. Our results show\nthat Generative Adversarial Nets can be a powerful tool for the generation of\nnovel and meaningful transportation actions, which result effectively modulated\nas a function of the object weight and the carefulness required in its\nhandling.",
          "link": "http://arxiv.org/abs/2106.04385",
          "publishedOn": "2021-06-09T02:01:51.315Z",
          "wordCount": 642,
          "title": "Property-Aware Robot Object Manipulation: a Generative Approach. (arXiv:2106.04385v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hart_K/0/1/0/all/0/1\">Kyle M. Hart</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_A/0/1/0/all/0/1\">Ari B. Goodman</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+OShea_R/0/1/0/all/0/1\">Ryan P. O&#x27;Shea</a> (1) ((1) Naval Air Warfare Center - Aircraft Division - Lakehurst)",
          "description": "Data labeling is a time intensive process. As such, many data scientists use\nvarious tools to aid in the data generation and labeling process. While these\ntools help automate labeling, many still require user interaction throughout\nthe process. Additionally, most target only a few network frameworks. Any\nresearchers exploring multiple frameworks must find additional tools orwrite\nconversion scripts. This paper presents an automated tool for generating\nsynthetic data in arbitrary network formats. It uses Robot Operating System\n(ROS) and Gazebo, which are common tools in the robotics community. Through ROS\nparadigms, it allows extensive user customization of the simulation environment\nand data generation process. Additionally, a plugin-like framework allows the\ndevelopment of arbitrary data format writers without the need to change the\nmain body of code. Using this tool, the authors were able to generate an\narbitrarily large image dataset for three unique training formats using\napproximately 15 min of user setup time and a variable amount of hands-off run\ntime, depending on the dataset size. The source code for this data generation\ntool is available at https://github.com/Navy-RISE-Lab/nn_data_collection",
          "link": "http://arxiv.org/abs/2106.04547",
          "publishedOn": "2021-06-09T02:01:51.309Z",
          "wordCount": 652,
          "title": "Automatic Generation of Machine Learning Synthetic Data Using ROS. (arXiv:2106.04547v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.14906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1\">Fernando Gama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingbiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolstaya_E/0/1/0/all/0/1\">Ekaterina Tolstaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prorok_A/0/1/0/all/0/1\">Amanda Prorok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Dynamical systems consisting of a set of autonomous agents face the challenge\nof having to accomplish a global task, relying only on local information. While\ncentralized controllers are readily available, they face limitations in terms\nof scalability and implementation, as they do not respect the distributed\ninformation structure imposed by the network system of agents. Given the\ndifficulties in finding optimal decentralized controllers, we propose a novel\nframework using graph neural networks (GNNs) to \\emph{learn} these controllers.\nGNNs are well-suited for the task since they are naturally distributed\narchitectures and exhibit good scalability and transferability properties. The\nproblems of flocking and multi-agent path planning are explored to illustrate\nthe potential of GNNs in learning decentralized controllers.",
          "link": "http://arxiv.org/abs/2012.14906",
          "publishedOn": "2021-06-09T02:01:51.166Z",
          "wordCount": 579,
          "title": "Decentralized Control with Graph Neural Networks. (arXiv:2012.14906v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04170",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_T/0/1/0/all/0/1\">Tiangang Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dolgov_S/0/1/0/all/0/1\">Sergey Dolgov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zahm_O/0/1/0/all/0/1\">Olivier Zahm</a>",
          "description": "We present a novel offline-online method to mitigate the computational burden\nof the characterization of conditional beliefs in statistical learning. In the\noffline phase, the proposed method learns the joint law of the belief random\nvariables and the observational random variables in the tensor-train (TT)\nformat. In the online phase, it utilizes the resulting order-preserving\nconditional transport map to issue real-time characterization of the\nconditional beliefs given new observed information. Compared with the\nstate-of-the-art normalizing flows techniques, the proposed method relies on\nfunction approximation and is equipped with thorough performance analysis. This\nalso allows us to further extend the capability of transport maps in\nchallenging problems with high-dimensional observations and high-dimensional\nbelief variables. On the one hand, we present novel heuristics to reorder\nand/or reparametrize the variables to enhance the approximation power of TT. On\nthe other, we integrate the TT-based transport maps and the parameter\nreordering/reparametrization into layered compositions to further improve the\nperformance of the resulting transport maps. We demonstrate the efficiency of\nthe proposed method on various statistical learning tasks in ordinary\ndifferential equations (ODEs) and partial differential equations (PDEs).",
          "link": "http://arxiv.org/abs/2106.04170",
          "publishedOn": "2021-06-09T02:01:51.160Z",
          "wordCount": 609,
          "title": "Conditional Deep Inverse Rosenblatt Transports. (arXiv:2106.04170v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2004.03959",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Baskerville_N/0/1/0/all/0/1\">Nicholas P. Baskerville</a>, <a href=\"http://arxiv.org/find/math/1/au:+Keating_J/0/1/0/all/0/1\">Jonathan P. Keating</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mezzadri_F/0/1/0/all/0/1\">Francesco Mezzadri</a>, <a href=\"http://arxiv.org/find/math/1/au:+Najnudel_J/0/1/0/all/0/1\">Joseph Najnudel</a>",
          "description": "The loss surfaces of deep neural networks have been the subject of several\nstudies, theoretical and experimental, over the last few years. One strand of\nwork considers the complexity, in the sense of local optima, of high\ndimensional random functions with the aim of informing how local optimisation\nmethods may perform in such complicated settings. Prior work of Choromanska et\nal (2015) established a direct link between the training loss surfaces of deep\nmulti-layer perceptron networks and spherical multi-spin glass models under\nsome very strong assumptions on the network and its data. In this work, we test\nthe validity of this approach by removing the undesirable restriction to ReLU\nactivation functions. In doing so, we chart a new path through the spin glass\ncomplexity calculations using supersymmetric methods in Random Matrix Theory\nwhich may prove useful in other contexts. Our results shed new light on both\nthe strengths and the weaknesses of spin glass models in this context.",
          "link": "http://arxiv.org/abs/2004.03959",
          "publishedOn": "2021-06-09T02:01:51.146Z",
          "wordCount": 647,
          "title": "The Loss Surfaces of Neural Networks with General Activation Functions. (arXiv:2004.03959v3 [math.PR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukhoti_J/0/1/0/all/0/1\">Jishnu Mukhoti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirsch_A/0/1/0/all/0/1\">Andreas Kirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1\">Joost van Amersfoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "We show that a single softmax neural net with minimal changes can beat the\nuncertainty predictions of Deep Ensembles and other more complex\nsingle-forward-pass uncertainty approaches. Standard softmax neural nets suffer\nfrom feature collapse and extrapolate arbitrarily for OoD points. This results\nin arbitrary softmax entropies for OoD points which can have high entropy, low,\nor anything in between, thus cannot capture epistemic uncertainty reliably. We\nprove that this failure lies at the core of \"why\" Deep Ensemble Uncertainty\nworks well. Instead of using softmax entropy, we show that with appropriate\ninductive biases softmax neural nets trained with maximum likelihood reliably\ncapture epistemic uncertainty through their feature-space density. This density\nis obtained using simple Gaussian Discriminant Analysis, but it cannot\nrepresent aleatoric uncertainty reliably. We show that it is necessary to\ncombine feature-space density with softmax entropy to disentangle uncertainties\nwell. We evaluate the epistemic uncertainty quality on active learning and OoD\ndetection, achieving SOTA ~98 AUROC on CIFAR-10 vs SVHN without fine-tuning on\nOoD data.",
          "link": "http://arxiv.org/abs/2102.11582",
          "publishedOn": "2021-06-09T02:01:51.140Z",
          "wordCount": 638,
          "title": "Deterministic Neural Networks with Inductive Biases Capture Epistemic and Aleatoric Uncertainty. (arXiv:2102.11582v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">A. Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1\">H. N. Mhaskar</a>",
          "description": "Many applications such as election forecasting, environmental monitoring,\nhealth policy, and graph based machine learning require taking expectation of\nfunctions defined on the vertices of a graph. We describe a construction of a\nsampling scheme analogous to the so called Leja points in complex potential\ntheory that can be proved to give low discrepancy estimates for the\napproximation of the expected value by the impirical expected value based on\nthese points. In contrast to classical potential theory where the kernel is\nfixed and the equilibrium distribution depends upon the kernel, we fix a\nprobability distribution and construct a kernel (which represents the graph\nstructure) for which the equilibrium distribution is the given probability\ndistribution. Our estimates do not depend upon the size of the graph.",
          "link": "http://arxiv.org/abs/2010.04227",
          "publishedOn": "2021-06-09T02:01:51.135Z",
          "wordCount": 585,
          "title": "A low discrepancy sequence on graphs. (arXiv:2010.04227v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.06566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mangla_P/0/1/0/all/0/1\">Puneet Mangla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1\">Vedant Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1\">Shreyas Jayant Havaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "The vicinal risk minimization (VRM) principle is an empirical risk\nminimization (ERM) variant that replaces Dirac masses with vicinal functions.\nThere is strong numerical and theoretical evidence showing that VRM outperforms\nERM in terms of generalization if appropriate vicinal functions are chosen.\nMixup Training (MT), a popular choice of vicinal distribution, improves the\ngeneralization performance of models by introducing globally linear behavior in\nbetween training examples. Apart from generalization, recent works have shown\nthat mixup trained models are relatively robust to input\nperturbations/corruptions and at the same time are calibrated better than their\nnon-mixup counterparts. In this work, we investigate the benefits of defining\nthese vicinal distributions like mixup in latent space of generative models\nrather than in input space itself. We propose a new approach - \\textit{VarMixup\n(Variational Mixup)} - to better sample mixup images by using the latent\nmanifold underlying the data. Our empirical studies on CIFAR-10, CIFAR-100, and\nTiny-ImageNet demonstrate that models trained by performing mixup in the latent\nmanifold learned by VAEs are inherently more robust to various input\ncorruptions/perturbations, are significantly better calibrated, and exhibit\nmore local-linear loss landscapes.",
          "link": "http://arxiv.org/abs/2003.06566",
          "publishedOn": "2021-06-09T02:01:51.129Z",
          "wordCount": 699,
          "title": "On the benefits of defining vicinal distributions in latent space. (arXiv:2003.06566v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1703.01610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qinshi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "We study combinatorial multi-armed bandit with probabilistically triggered\narms (CMAB-T) and semi-bandit feedback. We resolve a serious issue in the prior\nCMAB-T studies where the regret bounds contain a possibly exponentially large\nfactor of $1/p^*$, where $p^*$ is the minimum positive probability that an arm\nis triggered by any action. We address this issue by introducing a triggering\nprobability modulated (TPM) bounded smoothness condition into the general\nCMAB-T framework, and show that many applications such as influence\nmaximization bandit and combinatorial cascading bandit satisfy this TPM\ncondition. As a result, we completely remove the factor of $1/p^*$ from the\nregret bounds, achieving significantly better regret bounds for influence\nmaximization and cascading bandits than before. Finally, we provide lower bound\nresults showing that the factor $1/p^*$ is unavoidable for general CMAB-T\nproblems, suggesting that the TPM condition is crucial in removing this factor.",
          "link": "http://arxiv.org/abs/1703.01610",
          "publishedOn": "2021-06-09T02:01:51.124Z",
          "wordCount": 644,
          "title": "Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications. (arXiv:1703.01610v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cowen_Rivers_A/0/1/0/all/0/1\">Alexander I. Cowen-Rivers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1\">Wenlong Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1\">Rasul Tutunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosnit_A/0/1/0/all/0/1\">Antoine Grosnit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1\">Ryan Rhys Griffiths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jianye_H/0/1/0/all/0/1\">Hao Jianye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ammar_H/0/1/0/all/0/1\">Haitham Bou Ammar</a>",
          "description": "Inspired by the increasing desire to efficiently tune machine learning\nhyper-parameters, in this work we rigorously analyse conventional and\nnon-conventional assumptions inherent to Bayesian optimisation. Across an\nextensive set of experiments we conclude that: 1) the majority of\nhyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity,\n2) multi-objective acquisition ensembles with Pareto-front solutions\nsignificantly improve queried configurations, and 3) robust acquisition\nmaximisation affords empirical advantages relative to its non-robust\ncounterparts. We hope these findings may serve as guiding principles, both for\npractitioners and for further research in the field.",
          "link": "http://arxiv.org/abs/2012.03826",
          "publishedOn": "2021-06-09T02:01:51.108Z",
          "wordCount": 584,
          "title": "An Empirical Study of Assumptions in Bayesian Optimisation. (arXiv:2012.03826v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Simiao Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minshuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>",
          "description": "The Lottery Ticket Hypothesis suggests that an over-parametrized network\nconsists of ``lottery tickets'', and training a certain collection of them\n(i.e., a subnetwork) can match the performance of the full model. In this\npaper, we study such a collection of tickets, which is referred to as ``winning\ntickets'', in extremely over-parametrized models, e.g., pre-trained language\nmodels. We observe that at certain compression ratios, the generalization\nperformance of the winning tickets can not only match but also exceed that of\nthe full model. In particular, we observe a phase transition phenomenon: As the\ncompression ratio increases, generalization performance of the winning tickets\nfirst improves then deteriorates after a certain threshold. We refer to the\ntickets on the threshold as ``super tickets''. We further show that the phase\ntransition is task and model dependent -- as the model size becomes larger and\nthe training data set becomes smaller, the transition becomes more pronounced.\nOur experiments on the GLUE benchmark show that the super tickets improve\nsingle task fine-tuning by $0.9$ points on BERT-base and $1.0$ points on\nBERT-large, in terms of task-average score. We also demonstrate that adaptively\nsharing the super tickets across tasks benefits multi-task learning.",
          "link": "http://arxiv.org/abs/2105.12002",
          "publishedOn": "2021-06-09T02:01:51.102Z",
          "wordCount": 684,
          "title": "Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization. (arXiv:2105.12002v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00351",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chung_M/0/1/0/all/0/1\">Moo K. Chung</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ombao_H/0/1/0/all/0/1\">Hernando Ombao</a>",
          "description": "Topological data analysis, including persistent homology, has undergone\nsignificant development in recent years. However, one outstanding challenge is\nto build a coherent statistical inference procedure on persistent diagrams. The\npaired dependent data structure, as birth and death in persistent diagrams,\nadds additional complexity to the development. In this paper, we present a new\nlattice path representation for persistent diagrams. A new exact statistical\ninference procedure is developed for lattice paths via combinatorial\nenumerations. The proposed lattice path method is applied to the topological\ncharacterization of the protein structures of COVID-19 viruse. We demonstrate\nthat there are topological changes during the conformation change of spike\nproteins that are needed to initiate the infection of host cells.",
          "link": "http://arxiv.org/abs/2105.00351",
          "publishedOn": "2021-06-09T02:01:51.070Z",
          "wordCount": 614,
          "title": "Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus Spike Proteins. (arXiv:2105.00351v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1\">Nikola Konstantinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1\">Christoph H. Lampert</a>",
          "description": "Given the abundance of applications of ranking in recent years, addressing\nfairness concerns around automated ranking systems becomes necessary for\nincreasing the trust among end-users. Previous work on fair ranking has mostly\nfocused on application-specific fairness notions, often tailored to online\nadvertising, and it rarely considers learning as part of the process. In this\nwork, we show how to transfer numerous fairness notions from binary\nclassification to a learning to rank setting. Our formalism allows us to design\nmethods for incorporating fairness objectives with provable generalization\nguarantees. An extensive experimental evaluation shows that our method can\nimprove ranking fairness substantially with no or only little loss of model\nquality.",
          "link": "http://arxiv.org/abs/2102.05996",
          "publishedOn": "2021-06-09T02:01:51.064Z",
          "wordCount": 568,
          "title": "Fairness Through Regularization for Learning to Rank. (arXiv:2102.05996v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1\">Yu-Liang Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1\">Catarina Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruza_P/0/1/0/all/0/1\">Peter Bruza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1\">Chun Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorge_J/0/1/0/all/0/1\">Joaquim Jorge</a>",
          "description": "There has been a growing interest in model-agnostic methods that can make\ndeep learning models more transparent and explainable to a user. Some\nresearchers recently argued that for a machine to achieve a certain degree of\nhuman-level explainability, this machine needs to provide human causally\nunderstandable explanations, also known as causability. A specific class of\nalgorithms that have the potential to provide causability are counterfactuals.\nThis paper presents an in-depth systematic review of the diverse existing body\nof literature on counterfactuals and causability for explainable artificial\nintelligence. We performed an LDA topic modelling analysis under a PRISMA\nframework to find the most relevant literature articles. This analysis resulted\nin a novel taxonomy that considers the grounding theories of the surveyed\nalgorithms, together with their underlying properties and applications in\nreal-world data. This research suggests that current model-agnostic\ncounterfactual algorithms for explainable AI are not grounded on a causal\ntheoretical formalism and, consequently, cannot promote causability to a human\ndecision-maker. Our findings suggest that the explanations derived from major\nalgorithms in the literature provide spurious correlations rather than\ncause/effects relationships, leading to sub-optimal, erroneous or even biased\nexplanations. This paper also advances the literature with new directions and\nchallenges on promoting causability in model-agnostic approaches for\nexplainable artificial intelligence.",
          "link": "http://arxiv.org/abs/2103.04244",
          "publishedOn": "2021-06-09T02:01:51.058Z",
          "wordCount": 672,
          "title": "Counterfactuals and Causability in Explainable Artificial Intelligence: Theory, Algorithms, and Applications. (arXiv:2103.04244v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1\">S&#xe9;bastien Bubeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1\">Mark Sellke</a>",
          "description": "Classically, data interpolation with a parametrized model class is possible\nas long as the number of parameters is larger than the number of equations to\nbe satisfied. A puzzling phenomenon in deep learning is that models are trained\nwith many more parameters than what this classical theory would suggest. We\npropose a theoretical explanation for this phenomenon. We prove that for a\nbroad class of data distributions and model classes, overparametrization is\nnecessary if one wants to interpolate the data smoothly. Namely we show that\nsmooth interpolation requires $d$ times more parameters than mere\ninterpolation, where $d$ is the ambient data dimension. We prove this universal\nlaw of robustness for any smoothly parametrized function class with polynomial\nsize weights, and any covariate distribution verifying isoperimetry. In the\ncase of two-layers neural networks and Gaussian covariates, this law was\nconjectured in prior work by Bubeck, Li and Nagaraj. We also give an\ninterpretation of our result as an improved generalization bound for model\nclasses consisting of smooth functions.",
          "link": "http://arxiv.org/abs/2105.12806",
          "publishedOn": "2021-06-09T02:01:51.041Z",
          "wordCount": 617,
          "title": "A Universal Law of Robustness via Isoperimetry. (arXiv:2105.12806v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiaoyang Tan</a>",
          "description": "Efficiently propagating credit to responsible actions is a central and\nchallenging task in reinforcement learning. To accelerate information\npropagation, this paper presents a new method that bridges a highway that\nallows unimpeded information to flow across long horizons. The key to our\nmethod is a newly proposed Bellman equation, called Greedy-Step Bellman\nOptimality Equation, through which the high-credit information can fast\npropagate across a long horizon. We theoretically show that the solution of the\nnew equation is exactly the optimal value function and the corresponding\noperator converges faster than the classical operator. Besides, it leads to a\nnew multi-step off-policy algorithm, which is capable of safely utilizing any\noff-policy data collected by the arbitrary policy. Experiments reveal that the\nproposed method is reliable, easy to implement. Moreover, without employing\nadditional components of Rainbow except Double DQN, our method achieves\ncompetitive performance with Rainbow on the benchmark tasks.",
          "link": "http://arxiv.org/abs/2102.11717",
          "publishedOn": "2021-06-09T02:01:51.036Z",
          "wordCount": 620,
          "title": "A Novel Greedy-Step Bellman Optimality Equation for Efficient Value Propagation. (arXiv:2102.11717v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuezhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiding Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "We study the problem of robust reinforcement learning under adversarial\ncorruption on both rewards and transitions. Our attack model assumes an\n\\textit{adaptive} adversary who can arbitrarily corrupt the reward and\ntransition at every step within an episode, for at most $\\epsilon$-fraction of\nthe learning episodes. Our attack model is strictly stronger than those\nconsidered in prior works. Our first result shows that no algorithm can find a\nbetter than $O(\\epsilon)$-optimal policy under our attack model. Next, we show\nthat surprisingly the natural policy gradient (NPG) method retains a natural\nrobustness property if the reward corruption is bounded, and can find an\n$O(\\sqrt{\\epsilon})$-optimal policy. Consequently, we develop a Filtered Policy\nGradient (FPG) algorithm that can tolerate even unbounded reward corruption and\ncan find an $O(\\epsilon^{1/4})$-optimal policy. We emphasize that FPG is the\nfirst that can achieve a meaningful learning guarantee when a constant fraction\nof episodes are corrupted. Complimentary to the theoretical results, we show\nthat a neural implementation of FPG achieves strong robust learning performance\non the MuJoCo continuous control benchmarks.",
          "link": "http://arxiv.org/abs/2102.05800",
          "publishedOn": "2021-06-09T02:01:51.030Z",
          "wordCount": 630,
          "title": "Robust Policy Gradient against Strong Data Corruption. (arXiv:2102.05800v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daniely_A/0/1/0/all/0/1\">Amit Daniely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1\">Gal Vardi</a>",
          "description": "We prove hardness-of-learning results under a well-studied assumption on the\nexistence of local pseudorandom generators. As we show, this assumption allows\nus to surpass the current state of the art, and prove hardness of various basic\nproblems, with no hardness results to date.\n\nOur results include: hardness of learning shallow ReLU neural networks under\nthe Gaussian distribution and other distributions; hardness of learning\nintersections of $\\omega(1)$ halfspaces, DNF formulas with $\\omega(1)$ terms,\nand ReLU networks with $\\omega(1)$ hidden neurons; hardness of weakly learning\ndeterministic finite automata under the uniform distribution; hardness of\nweakly learning depth-$3$ Boolean circuits under the uniform distribution, as\nwell as distribution-specific hardness results for learning DNF formulas and\nintersections of halfspaces. We also establish lower bounds on the complexity\nof learning intersections of a constant number of halfspaces, and ReLU networks\nwith a constant number of hidden neurons. Moreover, our results imply the\nhardness of virtually all improper PAC-learning problems (both\ndistribution-free and distribution-specific) that were previously shown hard\nunder other assumptions.",
          "link": "http://arxiv.org/abs/2101.08303",
          "publishedOn": "2021-06-09T02:01:51.024Z",
          "wordCount": 619,
          "title": "From Local Pseudorandom Generators to Hardness of Learning. (arXiv:2101.08303v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1\">Mikhail Khodak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1\">Renbo Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liam Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Virginia Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>",
          "description": "Tuning hyperparameters is a crucial but arduous part of the machine learning\npipeline. Hyperparameter optimization is even more challenging in federated\nlearning, where models are learned over a distributed network of heterogeneous\ndevices; here, the need to keep data on device and perform local training makes\nit difficult to efficiently train and evaluate configurations. In this work, we\ninvestigate the problem of federated hyperparameter tuning. We first identify\nkey challenges and show how standard approaches may be adapted to form\nbaselines for the federated setting. Then, by making a novel connection to the\nneural architecture search technique of weight-sharing, we introduce a new\nmethod, FedEx, to accelerate federated hyperparameter tuning that is applicable\nto widely-used federated optimization methods such as FedAvg and recent\nvariants. Theoretically, we show that a FedEx variant correctly tunes the\non-device learning rate in the setting of online convex optimization across\ndevices. Empirically, we show that FedEx can outperform natural baselines for\nfederated hyperparameter tuning by several percentage points on the\nShakespeare, FEMNIST, and CIFAR-10 benchmarks, obtaining higher accuracy using\nthe same training budget.",
          "link": "http://arxiv.org/abs/2106.04502",
          "publishedOn": "2021-06-09T02:01:51.018Z",
          "wordCount": 626,
          "title": "Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing. (arXiv:2106.04502v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1\">Gal Vardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "Understanding the implicit regularization (or implicit bias) of gradient\ndescent has recently been a very active research area. However, the implicit\nregularization in nonlinear neural networks is still poorly understood,\nespecially for regression losses such as the square loss. Perhaps surprisingly,\nwe prove that even for a single ReLU neuron, it is impossible to characterize\nthe implicit regularization with the square loss by any explicit function of\nthe model parameters (although on the positive side, we show it can be\ncharacterized approximately). For one hidden-layer networks, we prove a similar\nresult, where in general it is impossible to characterize implicit\nregularization properties in this manner, except for the \"balancedness\"\nproperty identified in Du et al. [2018]. Our results suggest that a more\ngeneral framework than the one considered so far may be needed to understand\nimplicit regularization for nonlinear predictors, and provides some clues on\nwhat this framework should be.",
          "link": "http://arxiv.org/abs/2012.05156",
          "publishedOn": "2021-06-09T02:01:51.002Z",
          "wordCount": 619,
          "title": "Implicit Regularization in ReLU Networks with the Square Loss. (arXiv:2012.05156v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoxuan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Erjin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "Graph Neural Network (GNN) has been demonstrated its effectiveness in dealing\nwith non-Euclidean structural data. Both spatial-based and spectral-based GNNs\nare relying on adjacency matrix to guide message passing among neighbors during\nfeature aggregation. Recent works have mainly focused on powerful message\npassing modules, however, in this paper, we show that none of the message\npassing modules is necessary. Instead, we propose a pure\nmultilayer-perceptron-based framework, Graph-MLP with the supervision signal\nleveraging graph structure, which is sufficient for learning discriminative\nnode representation. In model-level, Graph-MLP only includes multi-layer\nperceptrons, activation function, and layer normalization. In the loss level,\nwe design a neighboring contrastive (NContrast) loss to bridge the gap between\nGNNs and MLPs by utilizing the adjacency information implicitly. This design\nallows our model to be lighter and more robust when facing large-scale graph\ndata and corrupted adjacency information. Extensive experiments prove that even\nwithout adjacency information in testing phase, our framework can still reach\ncomparable and even superior performance against the state-of-the-art models in\nthe graph node classification task.",
          "link": "http://arxiv.org/abs/2106.04051",
          "publishedOn": "2021-06-09T02:01:50.997Z",
          "wordCount": 620,
          "title": "Graph-MLP: Node Classification without Message Passing in Graph. (arXiv:2106.04051v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.01666",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zahid_M/0/1/0/all/0/1\">Muhammad Uzair Zahid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1\">Serkan Kiranyaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ince_T/0/1/0/all/0/1\">Turker Ince</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Devecioglu_O/0/1/0/all/0/1\">Ozer Can Devecioglu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1\">Muhammad E. H. Chowdhury</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khandakar_A/0/1/0/all/0/1\">Amith Khandakar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tahir_A/0/1/0/all/0/1\">Anas Tahir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Noise and low quality of ECG signals acquired from Holter or wearable devices\ndeteriorate the accuracy and robustness of R-peak detection algorithms. This\npaper presents a generic and robust system for R-peak detection in Holter ECG\nsignals. While many proposed algorithms have successfully addressed the problem\nof ECG R-peak detection, there is still a notable gap in the performance of\nthese detectors on such low-quality ECG records. Therefore, in this study, a\nnovel implementation of the 1D Convolutional Neural Network (CNN) is used\nintegrated with a verification model to reduce the number of false alarms. This\nCNN architecture consists of an encoder block and a corresponding decoder block\nfollowed by a sample-wise classification layer to construct the 1D segmentation\nmap of R- peaks from the input ECG signal. Once the proposed model has been\ntrained, it can solely be used to detect R-peaks possibly in a single channel\nECG data stream quickly and accurately, or alternatively, such a solution can\nbe conveniently employed for real-time monitoring on a lightweight portable\ndevice. The model is tested on two open-access ECG databases: The China\nPhysiological Signal Challenge (2020) database (CPSC-DB) with more than one\nmillion beats, and the commonly used MIT-BIH Arrhythmia Database (MIT-DB).\nExperimental results demonstrate that the proposed systematic approach achieves\n99.30% F1-score, 99.69% recall, and 98.91% precision in CPSC-DB, which is the\nbest R-peak detection performance ever achieved. Compared to all competing\nmethods, the proposed approach can reduce the false-positives and\nfalse-negatives in Holter ECG signals by more than 54% and 82%, respectively.\nResults also demonstrate similar or better performance than most competing\nalgorithms on MIT-DB with 99.83% F1-score, 99.85% recall, and 99.82% precision.",
          "link": "http://arxiv.org/abs/2101.01666",
          "publishedOn": "2021-06-09T02:01:50.991Z",
          "wordCount": 750,
          "title": "Robust R-Peak Detection in Low-Quality Holter ECGs using 1D Convolutional Neural Network. (arXiv:2101.01666v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangfan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Cheng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1\">Amir Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>",
          "description": "AdaBelief, one of the current best optimizers, demonstrates superior\ngeneralization ability compared to the popular Adam algorithm by viewing the\nexponential moving average of observed gradients. AdaBelief is theoretically\nappealing in that it has a data-dependent $O(\\sqrt{T})$ regret bound when\nobjective functions are convex, where $T$ is a time horizon. It remains however\nan open problem whether the convergence rate can be further improved without\nsacrificing its generalization ability. %on how to exploit strong convexity to\nfurther improve the convergence rate of AdaBelief. To this end, we make a first\nattempt in this work and design a novel optimization algorithm called\nFastAdaBelief that aims to exploit its strong convexity in order to achieve an\neven faster convergence rate. In particular, by adjusting the step size that\nbetter considers strong convexity and prevents fluctuation, our proposed\nFastAdaBelief demonstrates excellent generalization ability as well as superior\nconvergence. As an important theoretical contribution, we prove that\nFastAdaBelief attains a data-dependant $O(\\log T)$ regret bound, which is\nsubstantially lower than AdaBelief. On the empirical side, we validate our\ntheoretical analysis with extensive experiments in both scenarios of strong and\nnon-strong convexity on three popular baseline models. Experimental results are\nvery encouraging: FastAdaBelief converges the quickest in comparison to all\nmainstream algorithms while maintaining an excellent generalization ability, in\ncases of both strong or non-strong convexity. FastAdaBelief is thus posited as\na new benchmark model for the research community.",
          "link": "http://arxiv.org/abs/2104.13790",
          "publishedOn": "2021-06-09T02:01:50.986Z",
          "wordCount": 704,
          "title": "FastAdaBelief: Improving Convergence Rate for Belief-based Adaptive Optimizers by Exploiting Strong Convexity. (arXiv:2104.13790v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havtorn_J/0/1/0/all/0/1\">Jakob D. Havtorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maaloe_L/0/1/0/all/0/1\">Lars Maal&#xf8;e</a>",
          "description": "Deep generative models have been demonstrated as state-of-the-art density\nestimators. Yet, recent work has found that they often assign a higher\nlikelihood to data from outside the training distribution. This seemingly\nparadoxical behavior has caused concerns over the quality of the attained\ndensity estimates. In the context of hierarchical variational autoencoders, we\nprovide evidence to explain this behavior by out-of-distribution data having\nin-distribution low-level features. We argue that this is both expected and\ndesirable behavior. With this insight in hand, we develop a fast, scalable and\nfully unsupervised likelihood-ratio score for OOD detection that requires data\nto be in-distribution across all feature-levels. We benchmark the method on a\nvast set of data and model combinations and achieve state-of-the-art results on\nout-of-distribution detection.",
          "link": "http://arxiv.org/abs/2102.08248",
          "publishedOn": "2021-06-09T02:01:50.980Z",
          "wordCount": 631,
          "title": "Hierarchical VAEs Know What They Don't Know. (arXiv:2102.08248v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>",
          "description": "Attention-based neural networks such as the Vision Transformer (ViT) have\nrecently attained state-of-the-art results on many computer vision benchmarks.\nScale is a primary ingredient in attaining excellent results, therefore,\nunderstanding a model's scaling properties is a key to designing future\ngenerations effectively. While the laws for scaling Transformer language models\nhave been studied, it is unknown how Vision Transformers scale. To address\nthis, we scale ViT models and data, both up and down, and characterize the\nrelationships between error rate, data, and compute. Along the way, we refine\nthe architecture and training of ViT, reducing memory consumption and\nincreasing accuracy the resulting models. As a result, we successfully train a\nViT model with two billion parameters, which attains a new state-of-the-art on\nImageNet of 90.45% top-1 accuracy. The model also performs well on few-shot\nlearning, for example, attaining 84.86% top-1 accuracy on ImageNet with only 10\nexamples per class.",
          "link": "http://arxiv.org/abs/2106.04560",
          "publishedOn": "2021-06-09T02:01:50.974Z",
          "wordCount": 584,
          "title": "Scaling Vision Transformers. (arXiv:2106.04560v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.09385",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Little_A/0/1/0/all/0/1\">Anna Little</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McKenzie_D/0/1/0/all/0/1\">Daniel McKenzie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murphy_J/0/1/0/all/0/1\">James Murphy</a>",
          "description": "New geometric and computational analyses of power-weighted shortest-path\ndistances (PWSPDs) are presented. By illuminating the way these metrics balance\ndensity and geometry in the underlying data, we clarify their key parameters\nand discuss how they may be chosen in practice. Comparisons are made with\nrelated data-driven metrics, which illustrate the broader role of density in\nkernel-based unsupervised and semi-supervised machine learning.\nComputationally, we relate PWSPDs on complete weighted graphs to their\nanalogues on weighted nearest neighbor graphs, providing high probability\nguarantees on their equivalence that are near-optimal. Connections with\npercolation theory are developed to establish estimates on the bias and\nvariance of PWSPDs in the finite sample setting. The theoretical results are\nbolstered by illustrative experiments, demonstrating the versatility of PWSPDs\nfor a wide range of data settings. Throughout the paper, our results require\nonly that the underlying data is sampled from a low-dimensional manifold, and\ndepend crucially on the intrinsic dimension of this manifold, rather than its\nambient dimension.",
          "link": "http://arxiv.org/abs/2012.09385",
          "publishedOn": "2021-06-09T02:01:50.958Z",
          "wordCount": 617,
          "title": "Balancing Geometry and Density: Path Distances on High-Dimensional Data. (arXiv:2012.09385v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Sourya Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magesh_A/0/1/0/all/0/1\">Akshayaa Magesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_H/0/1/0/all/0/1\">Harshit Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_L/0/1/0/all/0/1\">Lav R. Varshney</a>",
          "description": "Recent works show that group equivariance as an inductive bias improves\nneural network performance for both classification and generation. However,\ndesigning group-equivariant neural networks is challenging when the group of\ninterest is large and is unknown. Moreover, inducing equivariance can\nsignificantly reduce the number of independent parameters in a network with\nfixed feature size, affecting its overall performance. We address these\nproblems by proving a new group-theoretic result in the context of equivariant\nneural networks that shows that a network is equivariant to a large group if\nand only if it is equivariant to smaller groups from which it is constructed.\nUsing this result, we design a novel fast group equivariant construction\nalgorithm, and a deep Q-learning-based search algorithm in a reduced search\nspace, yielding what we call autoequivariant networks (AENs). AENs find the\nright balance between equivariance and network size when tested on new\nbenchmark datasets, G-MNIST and G-Fashion-MNIST, obtained via group\ntransformations on MNIST and Fashion-MNIST respectively that we release.\nExtending these results to group convolutional neural networks, where we\noptimize between equivariances, augmentations, and network sizes, we find group\nequivariance to be the most dominating factor in all high-performing GCNNs on\nseveral datasets like CIFAR10, SVHN, RotMNIST, ASL, EMNIST, and KMNIST.",
          "link": "http://arxiv.org/abs/2104.04848",
          "publishedOn": "2021-06-09T02:01:50.952Z",
          "wordCount": 652,
          "title": "Autoequivariant Network Search via Group Decomposition. (arXiv:2104.04848v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1\">Munawar Hayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>",
          "description": "Vision transformers (ViT) have demonstrated impressive performance across\nvarious machine vision problems. These models are based on multi-head\nself-attention mechanisms that can flexibly attend to a sequence of image\npatches to encode contextual cues. An important question is how such\nflexibility in attending image-wide context conditioned on a given patch can\nfacilitate handling nuisances in natural images e.g., severe occlusions, domain\nshifts, spatial permutations, adversarial and natural perturbations. We\nsystematically study this question via an extensive set of experiments\nencompassing three ViT families and comparisons with a high-performing\nconvolutional neural network (CNN). We show and analyze the following\nintriguing properties of ViT: (a) Transformers are highly robust to severe\nocclusions, perturbations and domain shifts, e.g., retain as high as 60% top-1\naccuracy on ImageNet even after randomly occluding 80% of the image content.\n(b) The robust performance to occlusions is not due to a bias towards local\ntextures, and ViTs are significantly less biased towards textures compared to\nCNNs. When properly trained to encode shape-based features, ViTs demonstrate\nshape recognition capability comparable to that of human visual system,\npreviously unmatched in the literature. (c) Using ViTs to encode shape\nrepresentation leads to an interesting consequence of accurate semantic\nsegmentation without pixel-level supervision. (d) Off-the-shelf features from a\nsingle ViT model can be combined to create a feature ensemble, leading to high\naccuracy rates across a range of classification datasets in both traditional\nand few-shot learning paradigms. We show effective features of ViTs are due to\nflexible and dynamic receptive fields possible via the self-attention\nmechanism.",
          "link": "http://arxiv.org/abs/2105.10497",
          "publishedOn": "2021-06-09T02:01:50.946Z",
          "wordCount": 730,
          "title": "Intriguing Properties of Vision Transformers. (arXiv:2105.10497v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1\">Nicolae-Catalin Ristea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "Combining multiple machine learning models into an ensemble is known to\nprovide superior performance levels compared to the individual components\nforming the ensemble. This is because models can complement each other in\ntaking better decisions. Instead of just combining the models, we propose a\nself-paced ensemble learning scheme in which models learn from each other over\nseveral iterations. During the self-paced learning process based on\npseudo-labeling, in addition to improving the individual models, our ensemble\nalso gains knowledge about the target domain. To demonstrate the generality of\nour self-paced ensemble learning (SPEL) scheme, we conduct experiments on three\naudio tasks. Our empirical results indicate that SPEL significantly outperforms\nthe baseline ensemble models. We also show that applying self-paced learning on\nindividual models is less effective, illustrating the idea that models in the\nensemble actually learn from each other.",
          "link": "http://arxiv.org/abs/2103.11988",
          "publishedOn": "2021-06-09T02:01:50.931Z",
          "wordCount": 606,
          "title": "Self-paced ensemble learning for speech and audio classification. (arXiv:2103.11988v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03817",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shaghaghi_A/0/1/0/all/0/1\">Amirhossein Shaghaghi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zakeri_A/0/1/0/all/0/1\">Abolfazl Zakeri</a> (Student Member, IEEE), <a href=\"http://arxiv.org/find/eess/1/au:+Mokari_N/0/1/0/all/0/1\">Nader Mokari</a> (Senior Member, IEEE), <a href=\"http://arxiv.org/find/eess/1/au:+Javan_M/0/1/0/all/0/1\">Mohammad Reza Javan</a> (Senior Member, IEEE), <a href=\"http://arxiv.org/find/eess/1/au:+Behdadfar_M/0/1/0/all/0/1\">Mohammad Behdadfar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jorswieck_E/0/1/0/all/0/1\">Eduard A Jorswieck</a> (Fellow, IEEE)",
          "description": "In this paper, we propose a Zero-Touch, deep reinforcement learning\n(DRL)-based Proactive Failure Recovery framework called ZT-PFR for stateful\nnetwork function virtualization (NFV)-enabled networks. To this end, we\nformulate a resource-efficient optimization problem minimizing the network cost\nfunction including resource cost and wrong decision penalty. As a solution, we\npropose state-of-the-art DRL-based methods such as soft-actor-critic (SAC) and\nproximal-policy-optimization (PPO). In addition, to train and test our DRL\nagents, we propose a novel impending failure model. Moreover, to keep network\nstatus information at an acceptable freshness level for appropriate\ndecision-making, we apply the concept of age of information to strike a balance\nbetween the event and scheduling-based monitoring. Several key systems and DRL\nalgorithm design insights for ZT-PFR are drawn from our analysis and simulation\nresults. For example, we use a hybrid neural network, consisting long\nshort-term memory layers in the DRL agents",
          "link": "http://arxiv.org/abs/2103.03817",
          "publishedOn": "2021-06-09T02:01:50.919Z",
          "wordCount": 626,
          "title": "Proactive and AoI-aware Failure Recovery for Stateful NFV-enabled Zero-Touch 6G Networks: Model-Free DRL Approach. (arXiv:2103.03817v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dovrat_S/0/1/0/all/0/1\">Shaked Dovrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1\">Eliya Nachmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Single channel speech separation has experienced great progress in the last\nfew years. However, training neural speech separation for a large number of\nspeakers (e.g., more than 10 speakers) is out of reach for the current methods,\nwhich rely on the Permutation Invariant Loss (PIT). In this work, we present a\npermutation invariant training that employs the Hungarian algorithm in order to\ntrain with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in\ncomparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified\narchitecture that can handle the increased number of speakers. Our approach\nseparates up to $20$ speakers and improves the previous results for large $C$\nby a wide margin.",
          "link": "http://arxiv.org/abs/2104.08955",
          "publishedOn": "2021-06-09T02:01:50.907Z",
          "wordCount": 584,
          "title": "Many-Speakers Single Channel Speech Separation with Optimal Permutation Training. (arXiv:2104.08955v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dagaev_N/0/1/0/all/0/1\">Nikolay Dagaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roads_B/0/1/0/all/0/1\">Brett D. Roads</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiaoliang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barry_D/0/1/0/all/0/1\">Daniel N. Barry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1\">Kaustubh R. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Love_B/0/1/0/all/0/1\">Bradley C. Love</a>",
          "description": "Despite their impressive performance in object recognition and other tasks\nunder standard testing conditions, deep networks often fail to generalize to\nout-of-distribution (o.o.d.) samples. One cause for this shortcoming is that\nmodern architectures tend to rely on \"shortcuts\" - superficial features that\ncorrelate with categories without capturing deeper invariants that hold across\ncontexts. Real-world concepts often possess a complex structure that can vary\nsuperficially across contexts, which can make the most intuitive and promising\nsolutions in one context not generalize to others. One potential way to improve\no.o.d. generalization is to assume simple solutions are unlikely to be valid\nacross contexts and avoid them, which we refer to as the too-good-to-be-true\nprior. A low-capacity network (LCN) with a shallow architecture should only be\nable to learn surface relationships, including shortcuts. We find that LCNs can\nserve as shortcut detectors. Furthermore, an LCN's predictions can be used in a\ntwo-stage approach to encourage a high-capacity network (HCN) to rely on deeper\ninvariant features that should generalize broadly. In particular, items that\nthe LCN can master are downweighted when training the HCN. Using a modified\nversion of the CIFAR-10 dataset in which we introduced shortcuts, we found that\nthe two-stage LCN-HCN approach reduced reliance on shortcuts and facilitated\no.o.d. generalization.",
          "link": "http://arxiv.org/abs/2102.06406",
          "publishedOn": "2021-06-09T02:01:50.901Z",
          "wordCount": 684,
          "title": "A Too-Good-to-be-True Prior to Reduce Shortcut Reliance. (arXiv:2102.06406v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schymura_C/0/1/0/all/0/1\">Christopher Schymura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonninghoff_B/0/1/0/all/0/1\">Benedikt B&#xf6;nninghoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochiai_T/0/1/0/all/0/1\">Tsubasa Ochiai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delcroix_M/0/1/0/all/0/1\">Marc Delcroix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kinoshita_K/0/1/0/all/0/1\">Keisuke Kinoshita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakatani_T/0/1/0/all/0/1\">Tomohiro Nakatani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araki_S/0/1/0/all/0/1\">Shoko Araki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1\">Dorothea Kolossa</a>",
          "description": "Sound event localization aims at estimating the positions of sound sources in\nthe environment with respect to an acoustic receiver (e.g. a microphone array).\nRecent advances in this domain most prominently focused on utilizing deep\nrecurrent neural networks. Inspired by the success of transformer architectures\nas a suitable alternative to classical recurrent neural networks, this paper\nintroduces a novel transformer-based sound event localization framework, where\ntemporal dependencies in the received multi-channel audio signals are captured\nvia self-attention mechanisms. Additionally, the estimated sound event\npositions are represented as multivariate Gaussian variables, yielding an\nadditional notion of uncertainty, which many previously proposed deep\nlearning-based systems designed for this application do not provide. The\nframework is evaluated on three publicly available multi-source sound event\nlocalization datasets and compared against state-of-the-art methods in terms of\nlocalization error and event detection accuracy. It outperforms all competing\nsystems on all datasets with statistical significant differences in\nperformance.",
          "link": "http://arxiv.org/abs/2106.03903",
          "publishedOn": "2021-06-09T02:01:50.895Z",
          "wordCount": 597,
          "title": "PILOT: Introducing Transformers for Probabilistic Sound Event Localization. (arXiv:2106.03903v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1\">Samuele Tosatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Jo&#xe3;o Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>",
          "description": "Off-policy Reinforcement Learning (RL) holds the promise of better data\nefficiency as it allows sample reuse and potentially enables safe interaction\nwith the environment. Current off-policy policy gradient methods either suffer\nfrom high bias or high variance, delivering often unreliable estimates. The\nprice of inefficiency becomes evident in real-world scenarios such as\ninteraction-driven robot learning, where the success of RL has been rather\nlimited, and a very high sample cost hinders straightforward application. In\nthis paper, we propose a nonparametric Bellman equation, which can be solved in\nclosed form. The solution is differentiable w.r.t the policy parameters and\ngives access to an estimation of the policy gradient. In this way, we avoid the\nhigh variance of importance sampling approaches, and the high bias of\nsemi-gradient methods. We empirically analyze the quality of our gradient\nestimate against state-of-the-art methods, and show that it outperforms the\nbaselines in terms of sample efficiency on classical control tasks.",
          "link": "http://arxiv.org/abs/2010.14771",
          "publishedOn": "2021-06-09T02:01:50.884Z",
          "wordCount": 627,
          "title": "Batch Reinforcement Learning with a Nonparametric Off-Policy Policy Gradient. (arXiv:2010.14771v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sannigrahi_S/0/1/0/all/0/1\">Srikanta Sannigrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_B/0/1/0/all/0/1\">Bidroha Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Arunima Sarkar Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilla_F/0/1/0/all/0/1\">Francesco Pilla</a>",
          "description": "The increasing level of marine plastic pollution poses severe threats to the\nmarine ecosystem and biodiversity. The present study attempted to explore the\nfull functionality of open Sentinel satellite data and ML models for detecting\nand classifying floating plastic debris in Mytilene (Greece), Limassol\n(Cyprus), Calabria (Italy), and Beirut (Lebanon). Two ML models, i.e. Support\nVector Machine (SVM) and Random Forest (RF) were utilized to carry out the\nclassification analysis. In-situ plastic location data was collected from the\ncontrol experiment conducted in Mytilene, Greece and Limassol, Cyprus, and the\nsame was considered for training the models. Both remote sensing bands and\nspectral indices were used for developing the ML models. A spectral signature\nprofile for plastic was created for discriminating the floating plastic from\nother marine debris. A newly developed index, kernel Normalized Difference\nVegetation Index (kNDVI), was incorporated into the modelling to examine its\ncontribution to model performances. Both SVM and RF were performed well in five\nmodels and test case combinations. Among the two ML models, the highest\nperformance was measured for the RF. The inclusion of kNDVI was found effective\nand increased the model performances, reflected by high balanced accuracy\nmeasured for model 2 (~80% to ~98 % for SVM and ~87% to ~97 % for RF). Using\nthe best-performed model, an automated floating plastic detection system was\ndeveloped and tested in Calabria and Beirut. For both sites, the trained model\nhad detected the floating plastic with ~99% accuracy. Among the six predictors,\nthe FDI was found the most important variable for detecting marine floating\nplastic. These findings collectively suggest that high-resolution remote\nsensing imagery and the automated ML models can be an effective alternative for\nthe cost-effective detection of marine floating plastic.",
          "link": "http://arxiv.org/abs/2106.03694",
          "publishedOn": "2021-06-09T02:01:50.835Z",
          "wordCount": 747,
          "title": "Detection of marine floating plastic using Sentinel-2 imagery and machine learning models. (arXiv:2106.03694v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Real world applications such as economics and policy making often involve\nsolving multi-agent games with two unique features: (1) The agents are\ninherently asymmetric and partitioned into leaders and followers; (2) The\nagents have different reward functions, thus the game is general-sum. The\nmajority of existing results in this field focuses on either symmetric solution\nconcepts (e.g. Nash equilibrium) or zero-sum games. It remains vastly open how\nto learn the Stackelberg equilibrium -- an asymmetric analog of the Nash\nequilibrium -- in general-sum games efficiently from samples.\n\nThis paper initiates the theoretical study of sample-efficient learning of\nthe Stackelberg equilibrium, in the bandit feedback setting where we only\nobserve noisy samples of the reward. We consider three representative\ntwo-player general-sum games: bandit games, bandit-reinforcement learning\n(bandit-RL) games, and linear bandit games. In all these games, we identify a\nfundamental gap between the exact value of the Stackelberg equilibrium and its\nestimated version using finitely many noisy samples, which can not be closed\ninformation-theoretically regardless of the algorithm. We then establish sharp\npositive results on sample-efficient learning of Stackelberg equilibrium with\nvalue optimal up to the gap identified above, with matching lower bounds in the\ndependency on the gap, error tolerance, and the size of the action spaces.\nOverall, our results unveil unique challenges in learning Stackelberg\nequilibria under noisy bandit feedback, which we hope could shed light on\nfuture research on this topic.",
          "link": "http://arxiv.org/abs/2102.11494",
          "publishedOn": "2021-06-09T02:01:50.821Z",
          "wordCount": 702,
          "title": "Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games. (arXiv:2102.11494v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sangalli_S/0/1/0/all/0/1\">Sara Sangalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdil_E/0/1/0/all/0/1\">Ertunc Erdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoetker_A/0/1/0/all/0/1\">Andreas Hoetker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donati_O/0/1/0/all/0/1\">Olivio Donati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Deep neural networks (DNNs) are notorious for making more mistakes for the\nclasses that have substantially fewer samples than the others during training.\nSuch class imbalance is ubiquitous in clinical applications and very crucial to\nhandle because the classes with fewer samples most often correspond to critical\ncases (e.g., cancer) where misclassifications can have severe consequences. Not\nto miss such cases, binary classifiers need to be operated at high True\nPositive Rates (TPR) by setting a higher threshold but this comes at the cost\nof very high False Positive Rates (FPR) for problems with class imbalance.\nExisting methods for learning under class imbalance most often do not take this\ninto account. We argue that prediction accuracy should be improved by\nemphasizing reducing FPRs at high TPRs for problems where misclassification of\nthe positive, i.e., critical, class samples are associated with higher cost. To\nthis end, we pose the training of a DNN for binary classification as a\nconstrained optimization problem and introduce a novel constraint that can be\nused with existing loss functions to enforce maximal area under the ROC curve\n(AUC) through prioritizing FPR reduction at high TPR. We solve the resulting\nconstrained optimization problem using an Augmented Lagrangian method (ALM).\nGoing beyond binary, we also propose two possible extensions of the proposed\nconstraint for multi-class classification problems. We present experimental\nresults for image-based binary and multi-class classification applications\nusing an in-house medical imaging dataset, CIFAR10, and CIFAR100. Our results\ndemonstrate that the proposed method improves the baselines in majority of the\ncases by attaining higher accuracy on critical classes while reducing the\nmisclassification rate for the non-critical class samples.",
          "link": "http://arxiv.org/abs/2102.12894",
          "publishedOn": "2021-06-09T02:01:50.804Z",
          "wordCount": 737,
          "title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes. (arXiv:2102.12894v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1\">Edward Johns</a>",
          "description": "We introduce a simple new method for visual imitation learning, which allows\na novel robot manipulation task to be learned from a single human\ndemonstration, without requiring any prior knowledge of the object being\ninteracted with. Our method models imitation learning as a state estimation\nproblem, with the state defined as the end-effector's pose at the point where\nobject interaction begins, as observed from the demonstration. By modelling a\nmanipulation task as a coarse, approach trajectory followed by a fine,\ninteraction trajectory, this state estimator can be trained in a\nself-supervised manner, by automatically moving the end-effector's camera\naround the object. At test time, the end-effector is moved to the estimated\nstate through a linear path, at which point the demonstration's end-effector\nvelocities are simply repeated, enabling convenient acquisition of a complex\ninteraction trajectory without actually needing to explicitly learn a policy.\nReal-world experiments on 8 everyday tasks show that our method can learn a\ndiverse range of skills from just a single human demonstration, whilst also\nyielding a stable and interpretable controller.",
          "link": "http://arxiv.org/abs/2105.06411",
          "publishedOn": "2021-06-09T02:01:50.790Z",
          "wordCount": 614,
          "title": "Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration. (arXiv:2105.06411v1 [cs.RO] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takeno_S/0/1/0/all/0/1\">Shion Takeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamura_T/0/1/0/all/0/1\">Tomoyuki Tamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shitara_K/0/1/0/all/0/1\">Kazuki Shitara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karasuyama_M/0/1/0/all/0/1\">Masayuki Karasuyama</a>",
          "description": "Bayesian optimization (BO) is known as a powerful tool for optimizing an\nunknown, expensive function through querying the function values sequentially.\nOn the other hand, in many practical problems, additional unknown constraints\nalso need to be considered. In this paper, we propose an information-theoretic\napproach called Constrained Max-value Entropy Search via Information lower\nBOund (CMES-IBO) for the constrained BO (CBO). Although information-theoretic\nmethods have been studied in CBO literature, they have not revealed any\nrelation between their acquisition functions and the original mutual\ninformation. In contrast, our acquisition function is an unbiased consistent\nestimator of a lower bound of mutual information. We show that our CMES-IBO has\nseveral advantageous properties such as non-negativity, estimation error bounds\nof the acquisition function, and well-definedness of the criterion, none of\nwhich have been shown for the existing information-theoretic CBO. Furthermore,\nby using conditional mutual information, we extend CMES-IBO to the parallel\nsetting in which multiple queries can be issued simultaneously. We demonstrate\nthe effectiveness of CMES-IBO by several benchmark functions.",
          "link": "http://arxiv.org/abs/2102.09788",
          "publishedOn": "2021-06-09T02:01:50.783Z",
          "wordCount": 629,
          "title": "Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound. (arXiv:2102.09788v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1\">Tal Reiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1\">Yedid Hoshen</a>",
          "description": "Deep anomaly detection methods learn representations that separate between\nnormal and anomalous samples. Very effective representations are obtained when\npowerful externally trained feature extractors (e.g. ResNets pre-trained on\nImageNet) are fine-tuned on the training data which consists of normal samples\nand no anomalies. However, this is a difficult task that can suffer from\ncatastrophic collapse, i.e. it is prone to learning trivial and non-specific\nfeatures. In this paper, we propose a new loss function which can overcome\nfailure modes of both center-loss and contrastive-loss methods. Furthermore, we\ncombine it with a confidence-invariant angular center loss, which replaces the\nEuclidean distance used in previous work, that was sensitive to prediction\nconfidence. Our improvements yield a new anomaly detection approach, based on\n$\\textit{Mean-Shifted Contrastive Loss}$, which is both more accurate and less\nsensitive to catastrophic collapse than previous methods. Our method achieves\nstate-of-the-art anomaly detection performance on multiple benchmarks including\n$97.5\\%$ ROC-AUC on the CIFAR-10 dataset.",
          "link": "http://arxiv.org/abs/2106.03844",
          "publishedOn": "2021-06-09T02:01:50.764Z",
          "wordCount": 580,
          "title": "Mean-Shifted Contrastive Loss for Anomaly Detection. (arXiv:2106.03844v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Woojeong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khanna_R/0/1/0/all/0/1\">Rahul Khanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dong-Ho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1\">Aram Galstyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Event forecasting is a challenging, yet important task, as humans seek to\nconstantly plan for the future. Existing automated forecasting studies rely\nmostly on structured data, such as time-series or event-based knowledge graphs,\nto help predict future events. In this work, we aim to formulate a task,\nconstruct a dataset, and provide benchmarks for developing methods for event\nforecasting with large volumes of unstructured text data. To simulate the\nforecasting scenario on temporal news documents, we formulate the problem as a\nrestricted-domain, multiple-choice, question-answering (QA) task. Unlike\nexisting QA tasks, our task limits accessible information, and thus a model has\nto make a forecasting judgement. To showcase the usefulness of this task\nformulation, we introduce ForecastQA, a question-answering dataset consisting\nof 10,392 event forecasting questions, which have been collected and verified\nvia crowdsourcing efforts. We present our experiments on ForecastQA using\nBERT-based models and find that our best model achieves 60.1% accuracy on the\ndataset, which still lags behind human performance by about 19%. We hope\nForecastQA will support future research efforts in bridging this gap.",
          "link": "http://arxiv.org/abs/2005.00792",
          "publishedOn": "2021-06-09T02:01:50.758Z",
          "wordCount": 674,
          "title": "ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data. (arXiv:2005.00792v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05356",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vakili_S/0/1/0/all/0/1\">Sattar Vakili</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moss_H/0/1/0/all/0/1\">Henry Moss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Artemev_A/0/1/0/all/0/1\">Artem Artemev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Picheny_V/0/1/0/all/0/1\">Victor Picheny</a>",
          "description": "Thompson Sampling (TS) from Gaussian Process (GP) models is a powerful tool\nfor the optimization of black-box functions. Although TS enjoys strong\ntheoretical guarantees and convincing empirical performance, it incurs a large\ncomputational overhead that scales polynomially with the optimization budget.\nRecently, scalable TS methods based on sparse GP models have been proposed to\nincrease the scope of TS, enabling its application to problems that are\nsufficiently multi-modal, noisy or combinatorial to require more than a few\nhundred evaluations to be solved. However, the approximation error introduced\nby sparse GPs invalidates all existing regret bounds. In this work, we perform\na theoretical and empirical analysis of scalable TS. We provide theoretical\nguarantees and show that the drastic reduction in computational complexity of\nscalable TS can be enjoyed without loss in the regret performance over the\nstandard TS. These conceptual claims are validated for practical\nimplementations of scalable TS on synthetic benchmarks and as part of a\nreal-world high-throughput molecular design task.",
          "link": "http://arxiv.org/abs/2006.05356",
          "publishedOn": "2021-06-09T02:01:50.752Z",
          "wordCount": 616,
          "title": "Scalable Thompson Sampling using Sparse Gaussian Process Models. (arXiv:2006.05356v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Erwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">James J. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_D/0/1/0/all/0/1\">Daniele Moro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zielinski_P/0/1/0/all/0/1\">Piotr Zielinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coelho_C/0/1/0/all/0/1\">Claudionor Coelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1\">Satrajit Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_P/0/1/0/all/0/1\">Peter Y. K. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constantinides_G/0/1/0/all/0/1\">George A. Constantinides</a>",
          "description": "The ever-growing computational demands of increasingly complex machine\nlearning models frequently necessitate the use of powerful cloud-based\ninfrastructure for their training. Binary neural networks are known to be\npromising candidates for on-device inference due to their extreme compute and\nmemory savings over higher-precision alternatives. However, their existing\ntraining methods require the concurrent storage of high-precision activations\nfor all layers, generally making learning on memory-constrained devices\ninfeasible. In this paper, we demonstrate that the backward propagation\noperations needed for binary neural network training are strongly robust to\nquantization, thereby making on-the-edge learning with modern models a\npractical proposition. We introduce a low-cost binary neural network training\nstrategy exhibiting sizable memory footprint and energy reductions while\ninducing little to no accuracy loss vs Courbariaux & Bengio's standard\napproach. These resource decreases are primarily enabled through the retention\nof activations exclusively in binary format. Against the latter algorithm, our\ndrop-in replacement sees coincident memory requirement and energy consumption\ndrops of 2--6$\\times$, while reaching similar test accuracy in comparable time,\nacross a range of small-scale models trained to classify popular datasets. We\nalso demonstrate from-scratch ImageNet training of binarized ResNet-18,\nachieving a 3.12$\\times$ memory reduction. Such savings will allow for\nunnecessary cloud offloading to be avoided, reducing latency, increasing energy\nefficiency and safeguarding privacy.",
          "link": "http://arxiv.org/abs/2102.04270",
          "publishedOn": "2021-06-09T02:01:50.736Z",
          "wordCount": 702,
          "title": "Enabling Binary Neural Network Training on the Edge. (arXiv:2102.04270v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04509",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Sun_M/0/1/0/all/0/1\">Mengying Sun</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Xing_J/0/1/0/all/0/1\">Jing Xing</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_H/0/1/0/all/0/1\">Huijun Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1\">Bin Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayu Zhou</a>",
          "description": "Recent years have seen a rapid growth of utilizing graph neural networks\n(GNNs) in the biomedical domain for tackling drug-related problems. However,\nlike any other deep architectures, GNNs are data hungry. While requiring labels\nin real world is often expensive, pretraining GNNs in an unsupervised manner\nhas been actively explored. Among them, graph contrastive learning, by\nmaximizing the mutual information between paired graph augmentations, has been\nshown to be effective on various downstream tasks. However, the current graph\ncontrastive learning framework has two limitations. First, the augmentations\nare designed for general graphs and thus may not be suitable or powerful enough\nfor certain domains. Second, the contrastive scheme only learns representations\nthat are invariant to local perturbations and thus does not consider the global\nstructure of the dataset, which may also be useful for downstream tasks.\nTherefore, in this paper, we study graph contrastive learning in the context of\nbiomedical domain, where molecular graphs are present. We propose a novel\nframework called MoCL, which utilizes domain knowledge at both local- and\nglobal-level to assist representation learning. The local-level domain\nknowledge guides the augmentation process such that variation is introduced\nwithout changing graph semantics. The global-level knowledge encodes the\nsimilarity information between graphs in the entire dataset and helps to learn\nrepresentations with richer semantics. The entire model is learned through a\ndouble contrast objective. We evaluate MoCL on various molecular datasets under\nboth linear and semi-supervised settings and results show that MoCL achieves\nstate-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.04509",
          "publishedOn": "2021-06-09T02:01:50.730Z",
          "wordCount": 681,
          "title": "MoCL: Contrastive Learning on Molecular Graphs with Multi-level Domain Knowledge. (arXiv:2106.04509v1 [physics.bio-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Priyank Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jinglin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>",
          "description": "This paper studies regret minimization with randomized value functions in\nreinforcement learning. In tabular finite-horizon Markov Decision Processes, we\nintroduce a clipping variant of one classical Thompson Sampling (TS)-like\nalgorithm, randomized least-squares value iteration (RLSVI). Our\n$\\tilde{\\mathrm{O}}(H^2S\\sqrt{AT})$ high-probability worst-case regret bound\nimproves the previous sharpest worst-case regret bounds for RLSVI and matches\nthe existing state-of-the-art worst-case TS-based regret bounds.",
          "link": "http://arxiv.org/abs/2010.12163",
          "publishedOn": "2021-06-09T02:01:50.723Z",
          "wordCount": null,
          "title": "Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration. (arXiv:2010.12163v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuting Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1\">Yuejie Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuantao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "The softmax policy gradient (PG) method, which performs gradient ascent under\nsoftmax policy parameterization, is arguably one of the de facto\nimplementations of policy optimization in modern reinforcement learning. For\n$\\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs),\nremarkable progress has recently been achieved towards establishing global\nconvergence of softmax PG methods in finding a near-optimal policy. However,\nprior results fall short of delineating clear dependencies of convergence rates\non salient parameters such as the cardinality of the state space $\\mathcal{S}$\nand the effective horizon $\\frac{1}{1-\\gamma}$, both of which could be\nexcessively large. In this paper, we deliver a pessimistic message regarding\nthe iteration complexity of softmax PG methods, despite assuming access to\nexact gradient computation. Specifically, we demonstrate that the softmax PG\nmethod with stepsize $\\eta$ can take \\[\n\n\\frac{1}{\\eta} |\\mathcal{S}|^{2^{\\Omega\\big(\\frac{1}{1-\\gamma}\\big)}}\n~\\text{iterations} \\] to converge, even in the presence of a benign policy\ninitialization and an initial state distribution amenable to exploration (so\nthat the distribution mismatch coefficient is not exceedingly large). This is\naccomplished by characterizing the algorithmic dynamics over a\ncarefully-constructed MDP containing only three actions. Our exponential lower\nbound hints at the necessity of carefully adjusting update rules or enforcing\nproper regularization in accelerating PG methods.",
          "link": "http://arxiv.org/abs/2102.11270",
          "publishedOn": "2021-06-09T02:01:50.723Z",
          "wordCount": null,
          "title": "Softmax Policy Gradient Methods Can Take Exponential Time to Converge. (arXiv:2102.11270v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10032",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>",
          "description": "The empirical success of deep convolutional networks on tasks involving\nhigh-dimensional data such as images or audio suggests that they can\nefficiently approximate certain functions that are well-suited for such tasks.\nIn this paper, we study this through the lens of kernel methods, by considering\nsimple hierarchical kernels with two or three convolution and pooling layers,\ninspired by convolutional kernel networks. These achieve good empirical\nperformance on standard vision datasets, while providing a simple enough\ndescription of the functional space to shed light on their inductive bias. We\nshow that the RKHS consists of additive models of interaction terms between\npatches, and that its norm encourages structured spatial similarities between\nthese terms through pooling layers. We then provide generalization bounds which\nillustrate how pooling yields improved sample complexity guarantees when the\ntarget function presents such regularities.",
          "link": "http://arxiv.org/abs/2102.10032",
          "publishedOn": "2021-06-09T02:01:50.713Z",
          "wordCount": 579,
          "title": "Approximation and Learning with Deep Convolutional Models: a Kernel Perspective. (arXiv:2102.10032v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marinescu_R/0/1/0/all/0/1\">Razvan V Marinescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1\">Daniel Moyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golland_P/0/1/0/all/0/1\">Polina Golland</a>",
          "description": "Machine learning models are commonly trained end-to-end and in a supervised\nsetting, using paired (input, output) data. Examples include recent\nsuper-resolution methods that train on pairs of (low-resolution,\nhigh-resolution) images. However, these end-to-end approaches require\nre-training every time there is a distribution shift in the inputs (e.g., night\nimages vs daylight) or relevant latent variables (e.g., camera blur or hand\nmotion). In this work, we leverage state-of-the-art (SOTA) generative models\n(here StyleGAN2) for building powerful image priors, which enable application\nof Bayes' theorem for many downstream reconstruction tasks. Our method,\nBayesian Reconstruction through Generative Models (BRGM), uses a single\npre-trained generator model to solve different image restoration tasks, i.e.,\nsuper-resolution and in-painting, by combining it with different forward\ncorruption models. We keep the weights of the generator model fixed, and\nreconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)\nestimate over the input latent vector that generated the reconstructed image.\nWe further use variational inference to approximate the posterior distribution\nover the latent vectors, from which we sample multiple solutions. We\ndemonstrate BRGM on three large and diverse datasets: (i) 60,000 images from\nthe Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III\nand (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.\nAcross all three datasets and without any dataset-specific hyperparameter\ntuning, our simple approach yields performance competitive with current\ntask-specific state-of-the-art methods on super-resolution and in-painting,\nwhile being more generalisable and without requiring any training. Our source\ncode and pre-trained models are available online:\nhttps://razvanmarinescu.github.io/brgm/.",
          "link": "http://arxiv.org/abs/2012.04567",
          "publishedOn": "2021-06-09T02:01:50.701Z",
          "wordCount": null,
          "title": "Bayesian Image Reconstruction using Deep Generative Models. (arXiv:2012.04567v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trujillo_L/0/1/0/all/0/1\">Leonardo Trujillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contreras_J/0/1/0/all/0/1\">Jose Manuel Mu&#xf1;oz Contreras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1\">Daniel E Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castelli_M/0/1/0/all/0/1\">Mauro Castelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tapia_J/0/1/0/all/0/1\">Juan J Tapia</a>",
          "description": "Geometric Semantic Genetic Programming (GSGP) is a state-of-the-art machine\nlearning method based on evolutionary computation. GSGP performs search\noperations directly at the level of program semantics, which can be done more\nefficiently then operating at the syntax level like most GP systems. Efficient\nimplementations of GSGP in C++ exploit this fact, but not to its full\npotential. This paper presents GSGP-CUDA, the first CUDA implementation of GSGP\nand the most efficient, which exploits the intrinsic parallelism of GSGP using\nGPUs. Results show speedups greater than 1,000X relative to the\nstate-of-the-art sequential implementation.",
          "link": "http://arxiv.org/abs/2106.04034",
          "publishedOn": "2021-06-09T02:01:50.700Z",
          "wordCount": null,
          "title": "GSGP-CUDA -- a CUDA framework for Geometric Semantic Genetic Programming. (arXiv:2106.04034v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruocheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "We present Language-mediated, Object-centric Representation Learning (LORL),\na paradigm for learning disentangled, object-centric scene representations from\nvision and language. LORL builds upon recent advances in unsupervised object\ndiscovery and segmentation, notably MONet and Slot Attention. While these\nalgorithms learn an object-centric representation just by reconstructing the\ninput image, LORL enables them to further learn to associate the learned\nrepresentations to concepts, i.e., words for object categories, properties, and\nspatial relationships, from language input. These object-centric concepts\nderived from language facilitate the learning of object-centric\nrepresentations. LORL can be integrated with various unsupervised object\ndiscovery algorithms that are language-agnostic. Experiments show that the\nintegration of LORL consistently improves the performance of unsupervised\nobject discovery methods on two datasets via the help of language. We also show\nthat concepts learned by LORL, in conjunction with object discovery methods,\naid downstream tasks such as referring expression comprehension.",
          "link": "http://arxiv.org/abs/2012.15814",
          "publishedOn": "2021-06-09T02:01:50.700Z",
          "wordCount": null,
          "title": "Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1\">Ekin Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_A/0/1/0/all/0/1\">Afra Feyza Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Flexible neural sequence models outperform grammar- and automaton-based\ncounterparts on a variety of tasks. However, neural models perform poorly in\nsettings requiring compositional generalization beyond the training data --\nparticularly to rare or unseen subsequences. Past work has found symbolic\nscaffolding (e.g. grammars or automata) essential in these settings. We\ndescribe R&R, a learned data augmentation scheme that enables a large category\nof compositional generalizations without appeal to latent symbolic structure.\nR&R has two components: recombination of original training examples via a\nprototype-based generative model and resampling of generated examples to\nencourage extrapolation. Training an ordinary neural sequence model on a\ndataset augmented with recombined and resampled examples significantly improves\ngeneralization in two language processing problems -- instruction following\n(SCAN) and morphological analysis (SIGMORPHON 2018) -- where R&R enables\nlearning of new constructions and tenses from as few as eight initial examples.",
          "link": "http://arxiv.org/abs/2010.03706",
          "publishedOn": "2021-06-09T02:01:50.689Z",
          "wordCount": null,
          "title": "Learning to Recombine and Resample Data for Compositional Generalization. (arXiv:2010.03706v6 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1\">Junbum Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1\">Sanghyuk Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyungjae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Han-Cheol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunsung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungrae Park</a>",
          "description": "Domain generalization (DG) methods aim to achieve generalizability to an\nunseen target domain by using only training data from the source domains.\nAlthough a variety of DG methods have been proposed, a recent study shows that\nunder a fair evaluation protocol, called DomainBed, the simple empirical risk\nminimization (ERM) approach works comparable to or even outperforms previous\nmethods. Unfortunately, simply solving ERM on a complex, non-convex loss\nfunction can easily lead to sub-optimal generalizability by seeking sharp\nminima. In this paper, we theoretically show that finding flat minima results\nin a smaller domain generalization gap. We also propose a simple yet effective\nmethod, named Stochastic Weight Averaging Densely (SWAD), to find flat minima.\nSWAD finds flatter minima and suffers less from overfitting than does the\nvanilla SWA by a dense and overfit-aware stochastic weight sampling strategy.\nSWAD shows state-of-the-art performances on five DG benchmarks, namely PACS,\nVLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large\nmargins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with\nconventional generalization methods, such as data augmentation and consistency\nregularization methods, to verify that the remarkable performance improvements\nare originated from by seeking flat minima, not from better in-domain\ngeneralizability. Last but not least, SWAD is readily adaptable to existing DG\nmethods without modification; the combination of SWAD and an existing DG method\nfurther improves DG performances.",
          "link": "http://arxiv.org/abs/2102.08604",
          "publishedOn": "2021-06-09T02:01:50.686Z",
          "wordCount": null,
          "title": "SWAD: Domain Generalization by Seeking Flat Minima. (arXiv:2102.08604v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Shapira_N/0/1/0/all/0/1\">Noy Cohen-Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1\">Lior Rokach</a>",
          "description": "The widespread adoption of machine learning (ML) techniques and the extensive\nexpertise required to apply them have led to increased interest in automated ML\nsolutions that reduce the need for human intervention. One of the main\nchallenges in applying ML to previously unseen problems is algorithm selection\n- the identification of high-performing algorithm(s) for a given dataset, task,\nand evaluation measure. This study addresses the algorithm selection challenge\nfor data clustering, a fundamental task in data mining that is aimed at\ngrouping similar objects. We present MARCO-GE, a novel meta-learning approach\nfor the automated recommendation of clustering algorithms. MARCO-GE first\ntransforms datasets into graphs and then utilizes a graph convolutional neural\nnetwork technique to extract their latent representation. Using the embedding\nrepresentations obtained, MARCO-GE trains a ranking meta-model capable of\naccurately recommending top-performing algorithms for a new dataset and\nclustering evaluation measure. Extensive evaluation on 210 datasets, 13\nclustering algorithms, and 10 clustering measures demonstrates the\neffectiveness of our approach and its superiority in terms of predictive and\ngeneralization performance over state-of-the-art clustering meta-learning\napproaches.",
          "link": "http://arxiv.org/abs/2011.08225",
          "publishedOn": "2021-06-09T02:01:50.685Z",
          "wordCount": null,
          "title": "Automatic selection of clustering algorithms using supervised graph embedding. (arXiv:2011.08225v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bailin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>",
          "description": "Despite success in many domains, neural models struggle in settings where\ntrain and test examples are drawn from different distributions. In particular,\nin contrast to humans, conventional sequence-to-sequence (seq2seq) models fail\nto generalize systematically, i.e., interpret sentences representing novel\ncombinations of concepts (e.g., text segments) seen in training. Traditional\ngrammar formalisms excel in such settings by implicitly encoding alignments\nbetween input and output segments, but are hard to scale and maintain. Instead\nof engineering a grammar, we directly model segment-to-segment alignments as\ndiscrete structured latent variables within a neural seq2seq model. To\nefficiently explore the large space of alignments, we introduce a reorder-first\nalign-later framework whose central component is a neural reordering module\nproducing {\\it separable} permutations. We present an efficient dynamic\nprogramming algorithm performing exact marginal inference of separable\npermutations, and, thus, enabling end-to-end differentiable training of our\nmodel. The resulting seq2seq model exhibits better systematic generalization\nthan standard models on synthetic problems and NLP tasks (i.e., semantic\nparsing and machine translation).",
          "link": "http://arxiv.org/abs/2106.03257",
          "publishedOn": "2021-06-09T02:01:50.683Z",
          "wordCount": 612,
          "title": "Structured Reordering for Modeling Latent Alignments in Sequence Transduction. (arXiv:2106.03257v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skvara_V/0/1/0/all/0/1\">V&#xed;t &#x160;kv&#xe1;ra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franc%5Cr%7Bu%7D_J/0/1/0/all/0/1\">Jan Franc&#x16f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zorek_M/0/1/0/all/0/1\">Mat&#x11b;j Zorek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1\">Tom&#xe1;&#x161; Pevn&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smidl_V/0/1/0/all/0/1\">V&#xe1;clav &#x160;m&#xed;dl</a>",
          "description": "Deep generative models are challenging the classical methods in the field of\nanomaly detection nowadays. Every new method provides evidence of outperforming\nits predecessors, often with contradictory results. The objective of this\ncomparison is twofold: to compare anomaly detection methods of various\nparadigms with focus on deep generative models, and identification of sources\nof variability that can yield different results. The methods were compared on\npopular tabular and image datasets. We identified the main sources of\nvariability to be experimental conditions: i) the type data set (tabular or\nimage) and the nature of anomalies (statistical or semantic), and ii) strategy\nof selection of hyperparameters, especially the number of available anomalies\nin the validation set. Different methods perform the best in different\ncontexts, i.e. combination of experimental conditions together with\ncomputational time. This explains the variability of the previous results and\nhighlights the importance of careful specification of the context in the\npublication of a new method. All our code and results are available for\ndownload.",
          "link": "http://arxiv.org/abs/2012.06260",
          "publishedOn": "2021-06-09T02:01:50.678Z",
          "wordCount": null,
          "title": "Comparison of Anomaly Detectors: Context Matters. (arXiv:2012.06260v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "We present Meta Learning for Knowledge Distillation (MetaDistil), a simple\nyet effective alternative to traditional knowledge distillation (KD) methods\nwhere the teacher model is fixed during training. We show the teacher network\ncan learn to better transfer knowledge to the student network (i.e., learning\nto teach) with the feedback from the performance of the distilled student\nnetwork in a meta learning framework. Moreover, we introduce a pilot update\nmechanism to improve the alignment between the inner-learner and meta-learner\nin meta learning algorithms that focus on an improved inner-learner.\nExperiments on various benchmarks show that MetaDistil can yield significant\nimprovements compared with traditional KD algorithms and is less sensitive to\nthe choice of different student capacity and hyperparameters, facilitating the\nuse of KD on different tasks and models. The code is available at\nhttps://github.com/JetRunner/MetaDistil",
          "link": "http://arxiv.org/abs/2106.04570",
          "publishedOn": "2021-06-09T02:01:50.666Z",
          "wordCount": null,
          "title": "Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.08831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1\">Sirisha Rambhatla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Modeling the dynamics of real-world physical systems is critical for\nspatiotemporal prediction tasks, but challenging when data is limited. The\nscarcity of real-world data and the difficulty in reproducing the data\ndistribution hinder directly applying meta-learning techniques. Although the\nknowledge of governing partial differential equations (PDE) of data can be\nhelpful for the fast adaptation to few observations, it is mostly infeasible to\nexactly find the equation for observations in real-world physical systems. In\nthis work, we propose a framework, physics-aware meta-learning with auxiliary\ntasks, whose spatial modules incorporate PDE-independent knowledge and temporal\nmodules utilize the generalized features from the spatial modules to be adapted\nto the limited data, respectively. The framework is inspired by a local\nconservation law expressed mathematically as a continuity equation and does not\nrequire the exact form of governing equation to model the spatiotemporal\nobservations. The proposed method mitigates the need for a large number of\nreal-world tasks for meta-learning by leveraging spatial information in\nsimulated data to meta-initialize the spatial modules. We apply the proposed\nframework to both synthetic and real-world spatiotemporal prediction tasks and\ndemonstrate its superior performance with limited observations.",
          "link": "http://arxiv.org/abs/2006.08831",
          "publishedOn": "2021-06-09T02:01:50.650Z",
          "wordCount": 663,
          "title": "Physics-aware Spatiotemporal Modules with Auxiliary Tasks for Meta-Learning. (arXiv:2006.08831v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.11223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1\">Ghada Zamzmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajaraman_S/0/1/0/all/0/1\">Sivaramakrishnan Rajaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antani_S/0/1/0/all/0/1\">Sameer Antani</a>",
          "description": "Medical image analysis typically includes several tasks such as enhancement,\nsegmentation, and classification. Traditionally, these tasks are implemented\nusing separate deep learning models for separate tasks, which is not efficient\nbecause it involves unnecessary training repetitions, demands greater\ncomputational resources, and requires a relatively large amount of labeled\ndata. In this paper, we propose a multi-task training approach for medical\nimage analysis, where individual tasks are fine-tuned simultaneously through\nrelevant knowledge transfer using a unified modality-specific feature\nrepresentation (UMS-Rep). We explore different fine-tuning strategies to\ndemonstrate the impact of the strategy on the performance of target medical\nimage tasks. We experiment with different visual tasks (e.g., image denoising,\nsegmentation, and classification) to highlight the advantages offered with our\napproach for two imaging modalities, chest X-ray and Doppler echocardiography.\nOur results demonstrate that the proposed approach reduces the overall demand\nfor computational resources and improves target task generalization and\nperformance. Further, our results prove that the performance of target tasks in\nmedical images is highly influenced by the utilized fine-tuning strategy.",
          "link": "http://arxiv.org/abs/2006.11223",
          "publishedOn": "2021-06-09T02:01:50.644Z",
          "wordCount": 634,
          "title": "Unified Representation Learning for Efficient Medical Image Analysis. (arXiv:2006.11223v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "In real-time forecasting in public health, data collection is a non-trivial\nand demanding task. Often after initially released, it undergoes several\nrevisions later (maybe due to human or technical constraints) - as a result, it\nmay take weeks until the data reaches to a stable value. This so-called\n'backfill' phenomenon and its effect on model performance has been barely\nstudied in the prior literature. In this paper, we introduce the multi-variate\nbackfill problem using COVID-19 as the motivating example. We construct a\ndetailed dataset composed of relevant signals over the past year of the\npandemic. We then systematically characterize several patterns in backfill\ndynamics and leverage our observations for formulating a novel problem and\nneural framework Back2Future that aims to refines a given model's predictions\nin real-time. Our extensive experiments demonstrate that our method refines the\nperformance of top models for COVID-19 forecasting, in contrast to non-trivial\nbaselines, yielding 18% improvement over baselines, enabling us obtain a new\nSOTA performance. In addition, we show that our model improves model evaluation\ntoo; hence policy-makers can better understand the true accuracy of forecasting\nmodels in real-time.",
          "link": "http://arxiv.org/abs/2106.04420",
          "publishedOn": "2021-06-09T02:01:50.639Z",
          "wordCount": 669,
          "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future. (arXiv:2106.04420v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.06529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimi_A/0/1/0/all/0/1\">Amir-Hossein Karimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_U/0/1/0/all/0/1\">Umang Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1\">Isabel Valera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Algorithmic fairness is typically studied from the perspective of\npredictions. Instead, here we investigate fairness from the perspective of\nrecourse actions suggested to individuals to remedy an unfavourable\nclassification. We propose two new fairness criteria at the group and\nindividual level, which -- unlike prior work on equalising the average\ngroup-wise distance from the decision boundary -- explicitly account for causal\nrelationships between features, thereby capturing downstream effects of\nrecourse actions performed in the physical world. We explore how our criteria\nrelate to others, such as counterfactual fairness, and show that fairness of\nrecourse is complementary to fairness of prediction. We study theoretically and\nempirically how to enforce fair causal recourse by altering the classifier and\nperform a case study on the Adult dataset. Finally, we discuss whether fairness\nviolations in the data generating process revealed by our criteria may be\nbetter addressed by societal interventions as opposed to constraints on the\nclassifier.",
          "link": "http://arxiv.org/abs/2010.06529",
          "publishedOn": "2021-06-09T02:01:50.623Z",
          "wordCount": 653,
          "title": "On the Fairness of Causal Algorithmic Recourse. (arXiv:2010.06529v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.13034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingfeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1\">Vladimir Braverman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>",
          "description": "In this paper we consider multi-objective reinforcement learning where the\nobjectives are balanced using preferences. In practice, the preferences are\noften given in an adversarial manner, e.g., customers can be picky in many\napplications. We formalize this problem as an episodic learning problem on a\nMarkov decision process, where transitions are unknown and a reward function is\nthe inner product of a preference vector with pre-specified multi-objective\nreward functions. We consider two settings. In the online setting, the agent\nreceives a (adversarial) preference every episode and proposes policies to\ninteract with the environment. We provide a model-based algorithm that achieves\na nearly minimax optimal regret bound\n$\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{\\min\\{d,S\\}\\cdot H^2 SAK}\\bigr)$, where $d$\nis the number of objectives, $S$ is the number of states, $A$ is the number of\nactions, $H$ is the length of the horizon, and $K$ is the number of episodes.\nFurthermore, we consider preference-free exploration, i.e., the agent first\ninteracts with the environment without specifying any preference and then is\nable to accommodate arbitrary preference vector up to $\\epsilon$ error. Our\nproposed algorithm is provably efficient with a nearly optimal trajectory\ncomplexity $\\widetilde{\\mathcal{O}}\\bigl({\\min\\{d,S\\}\\cdot H^3\nSA}/{\\epsilon^2}\\bigr)$. This result partly resolves an open problem raised by\n\\citet{jin2020reward}.",
          "link": "http://arxiv.org/abs/2011.13034",
          "publishedOn": "2021-06-09T02:01:50.617Z",
          "wordCount": 662,
          "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning. (arXiv:2011.13034v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>",
          "description": "Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.",
          "link": "http://arxiv.org/abs/2106.04554",
          "publishedOn": "2021-06-09T02:01:50.552Z",
          "wordCount": null,
          "title": "A Survey of Transformers. (arXiv:2106.04554v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.12855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Mingyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasanbeig_M/0/1/0/all/0/1\">Mohammadhosein Hasanbeig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shaoping Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1\">Alessandro Abate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1\">Zhen Kan</a>",
          "description": "This paper investigates the motion planning of autonomous dynamical systems\nmodeled by Markov decision processes (MDP) with unknown transition\nprobabilities over continuous state and action spaces. Linear temporal logic\n(LTL) is used to specify high-level tasks over infinite horizon, which can be\nconverted into a limit deterministic generalized B\\\"uchi automaton (LDGBA) with\nseveral accepting sets. The novelty is to design an embedded product MDP\n(EP-MDP) between the LDGBA and the MDP by incorporating a synchronous\ntracking-frontier function to record unvisited accepting sets of the automaton,\nand to facilitate the satisfaction of the accepting conditions. The proposed\nLDGBA-based reward shaping and discounting schemes for the model-free\nreinforcement learning (RL) only depend on the EP-MDP states and can overcome\nthe issues of sparse rewards. Rigorous analysis shows that any RL method that\noptimizes the expected discounted return is guaranteed to find an optimal\npolicy whose traces maximize the satisfaction probability. A modular deep\ndeterministic policy gradient (DDPG) is then developed to generate such\npolicies over continuous state and action spaces. The performance of our\nframework is evaluated via an array of OpenAI gym environments.",
          "link": "http://arxiv.org/abs/2102.12855",
          "publishedOn": "2021-06-09T02:01:50.431Z",
          "wordCount": 667,
          "title": "Modular Deep Reinforcement Learning for Continuous Motion Planning with Temporal Logic. (arXiv:2102.12855v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1\">Semih Cayci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satpathi_S/0/1/0/all/0/1\">Siddhartha Satpathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1\">R. Srikant</a>",
          "description": "In this paper, we study the dynamics of temporal difference learning with\nneural network-based value function approximation over a general state space,\nnamely, \\emph{Neural TD learning}. We consider two practically used algorithms,\nprojection-free and max-norm regularized Neural TD learning, and establish the\nfirst convergence bounds for these algorithms. An interesting observation from\nour results is that max-norm regularization can dramatically improve the\nperformance of TD learning algorithms, both in terms of sample complexity and\noverparameterization. In particular, we prove that max-norm regularization\nappears to be more effective than $\\ell_2$-regularization, again both in terms\nof sample complexity and overparameterization. The results in this work rely on\na novel Lyapunov drift analysis of the network parameters as a stopped and\ncontrolled random process.",
          "link": "http://arxiv.org/abs/2103.01391",
          "publishedOn": "2021-06-09T02:01:50.403Z",
          "wordCount": 600,
          "title": "Sample Complexity and Overparameterization Bounds for Temporal Difference Learning with Neural Network Approximation. (arXiv:2103.01391v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Songcan Chen</a>",
          "description": "In reality, learning from multi-view multi-label data inevitably confronts\nthree challenges: missing labels, incomplete views, and non-aligned views.\nExisting methods mainly concern the first two and commonly need multiple\nassumptions to attack them, making even state-of-the-arts involve at least two\nexplicit hyper-parameters such that model selection is quite difficult. More\nroughly, they will fail in handling the third challenge, let alone addressing\nthe three jointly. In this paper, we aim at meeting these under the least\nassumption by building a concise yet effective model with just one\nhyper-parameter. To ease insufficiency of available labels, we exploit not only\nthe consensus of multiple views but also the global and local structures hidden\namong multiple labels. Specifically, we introduce an indicator matrix to tackle\nthe first two challenges in a regression form while aligning the same\nindividual labels and all labels of different views in a common label space to\nbattle the third challenge. In aligning, we characterize the global and local\nstructures of multiple labels to be high-rank and low-rank, respectively.\nSubsequently, an efficient algorithm with linear time complexity in the number\nof samples is established. Finally, even without view-alignment, our method\nsubstantially outperforms state-of-the-arts with view-alignment on five real\ndatasets.",
          "link": "http://arxiv.org/abs/2005.00976",
          "publishedOn": "2021-06-09T02:01:50.377Z",
          "wordCount": 680,
          "title": "A Concise yet Effective model for Non-Aligned Incomplete Multi-view and Missing Multi-label Learning. (arXiv:2005.00976v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.02631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_H/0/1/0/all/0/1\">Harsh Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rachuri_R/0/1/0/all/0/1\">Rahul Rachuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ajith Suresh</a>",
          "description": "Machine learning has started to be deployed in fields such as healthcare and\nfinance, which propelled the need for and growth of privacy-preserving machine\nlearning (PPML). We propose an actively secure four-party protocol (4PC), and a\nframework for PPML, showcasing its applications on four of the most\nwidely-known machine learning algorithms -- Linear Regression, Logistic\nRegression, Neural Networks, and Convolutional Neural Networks. Our 4PC\nprotocol tolerating at most one malicious corruption is practically efficient\nas compared to the existing works. We use the protocol to build an efficient\nmixed-world framework (Trident) to switch between the Arithmetic, Boolean, and\nGarbled worlds. Our framework operates in the offline-online paradigm over\nrings and is instantiated in an outsourced setting for machine learning. Also,\nwe propose conversions especially relevant to privacy-preserving machine\nlearning. The highlights of our framework include using a minimal number of\nexpensive circuits overall as compared to ABY3. This can be seen in our\ntechnique for truncation, which does not affect the online cost of\nmultiplication and removes the need for any circuits in the offline phase. Our\nB2A conversion has an improvement of $\\mathbf{7} \\times$ in rounds and\n$\\mathbf{18} \\times$ in the communication complexity. The practicality of our\nframework is argued through improvements in the benchmarking of the\naforementioned algorithms when compared with ABY3. All the protocols are\nimplemented over a 64-bit ring in both LAN and WAN settings. Our improvements\ngo up to $\\mathbf{187} \\times$ for the training phase and $\\mathbf{158} \\times$\nfor the prediction phase when observed over LAN and WAN.",
          "link": "http://arxiv.org/abs/1912.02631",
          "publishedOn": "2021-06-09T02:01:50.352Z",
          "wordCount": 740,
          "title": "Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning. (arXiv:1912.02631v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04271",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pan_M/0/1/0/all/0/1\">Mengjie Pan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1\">Tyler H. McCormick</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fosdick_B/0/1/0/all/0/1\">Bailey K. Fosdick</a>",
          "description": "Network regression models, where the outcome comprises the valued edge in a\nnetwork and the predictors are actor or dyad-level covariates, are used\nextensively in the social and biological sciences. Valid inference relies on\naccurately modeling the residual dependencies among the relations. Frequently\nhomogeneity assumptions are placed on the errors which are commonly incorrect\nand ignore critical, natural clustering of the actors. In this work, we present\na novel regression modeling framework that models the errors as resulting from\na community-based dependence structure and exploits the subsequent\nexchangeability properties of the error distribution to obtain parsimonious\nstandard errors for regression parameters.",
          "link": "http://arxiv.org/abs/2106.04271",
          "publishedOn": "2021-06-09T02:01:50.340Z",
          "wordCount": 539,
          "title": "Inference for Network Regression Models with Community Structure. (arXiv:2106.04271v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1\">Avi Schwarzschild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arjun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiasi_A/0/1/0/all/0/1\">Amin Ghiasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>",
          "description": "It is widely believed that deep neural networks contain layer specialization,\nwherein networks extract hierarchical features representing edges and patterns\nin shallow layers and complete objects in deeper layers. Unlike common\nfeed-forward models that have distinct filters at each layer, recurrent\nnetworks reuse the same parameters at various depths. In this work, we observe\nthat recurrent models exhibit the same hierarchical behaviors and the same\nperformance benefits as depth despite reusing the same filters at every\nrecurrence. By training models of various feed-forward and recurrent\narchitectures on several datasets for image classification as well as maze\nsolving, we show that recurrent networks have the ability to closely emulate\nthe behavior of non-recurrent deep models, often doing so with far fewer\nparameters.",
          "link": "http://arxiv.org/abs/2102.11011",
          "publishedOn": "2021-06-09T02:01:50.335Z",
          "wordCount": null,
          "title": "The Uncanny Similarity of Recurrence and Depth. (arXiv:2102.11011v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "The advent of contextual word embeddings -- representations of words which\nincorporate semantic and syntactic information from their context -- has led to\ntremendous improvements on a wide variety of NLP tasks. However, recent\ncontextual models have prohibitively high computational cost in many use-cases\nand are often hard to interpret. In this work, we demonstrate that our proposed\ndistillation method, which is a simple extension of CBOW-based training, allows\nto significantly improve computational efficiency of NLP applications, while\noutperforming the quality of existing static embeddings trained from scratch as\nwell as those distilled from previously proposed methods. As a side-effect, our\napproach also allows a fair comparison of both contextual and static embeddings\nvia standard lexical evaluation tasks.",
          "link": "http://arxiv.org/abs/2106.04302",
          "publishedOn": "2021-06-09T02:01:50.334Z",
          "wordCount": 553,
          "title": "Obtaining Better Static Word Embeddings Using Contextual Embedding Models. (arXiv:2106.04302v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2002.07676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1\">Claire Lazar Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijaykumar_S/0/1/0/all/0/1\">Suhas Vijaykumar</a>",
          "description": "Decision makers increasingly rely on algorithmic risk scores to determine\naccess to binary treatments including bail, loans, and medical interventions.\nIn these settings, we reconcile two fairness criteria that were previously\nshown to be in conflict: calibration and error rate equality. In particular, we\nderive necessary and sufficient conditions for the existence of calibrated\nscores that yield classifications achieving equal error rates at any given\ngroup-blind threshold. We then present an algorithm that searches for the most\naccurate score subject to both calibration and minimal error rate disparity.\nApplied to the COMPAS criminal risk assessment tool, we show that our method\ncan eliminate error disparities while maintaining calibration. In a separate\napplication to credit lending, we compare our procedure to the omission of\nsensitive features and show that it raises both profit and the probability that\ncreditworthy individuals receive loans.",
          "link": "http://arxiv.org/abs/2002.07676",
          "publishedOn": "2021-06-09T02:01:50.328Z",
          "wordCount": 625,
          "title": "A Possibility in Algorithmic Fairness: Can Calibration and Equal Error Rates Be Reconciled?. (arXiv:2002.07676v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "Accurate and trustworthy epidemic forecasting is an important problem that\nhas impact on public health planning and disease mitigation. Most existing\nepidemic forecasting models disregard uncertainty quantification, resulting in\nmis-calibrated predictions. Recent works in deep neural models for\nuncertainty-aware time-series forecasting also have several limitations; e.g.\nit is difficult to specify meaningful priors in Bayesian NNs, while methods\nlike deep ensembling are computationally expensive in practice. In this paper,\nwe fill this important gap. We model the forecasting task as a probabilistic\ngenerative process and propose a functional neural process model called EPIFNP,\nwhich directly models the probability density of the forecast value. EPIFNP\nleverages a dynamic stochastic correlation graph to model the correlations\nbetween sequences in a non-parametric way, and designs different stochastic\nlatent variables to capture functional uncertainty from different perspectives.\nOur extensive experiments in a real-time flu forecasting setting show that\nEPIFNP significantly outperforms previous state-of-the-art models in both\naccuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in\ncalibration. Additionally, due to properties of its generative process,EPIFNP\nlearns the relations between the current season and similar patterns of\nhistorical seasons,enabling interpretable forecasts. Beyond epidemic\nforecasting, the EPIFNP can be of independent interest for advancing principled\nuncertainty quantification in deep sequential models for predictive analytics",
          "link": "http://arxiv.org/abs/2106.03904",
          "publishedOn": "2021-06-09T02:01:50.304Z",
          "wordCount": 649,
          "title": "When in Doubt: Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting. (arXiv:2106.03904v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.03735",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1\">Wei Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Martagan_T/0/1/0/all/0/1\">Tugce Martagan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akcay_A/0/1/0/all/0/1\">Alp Akcay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ravenstein_B/0/1/0/all/0/1\">Bram van Ravenstein</a>",
          "description": "In the biopharmaceutical manufacturing, fermentation process plays a critical\nrole impacting on productivity and profit. Since biotherapeutics are\nmanufactured in living cells whose biological mechanisms are complex and have\nhighly variable outputs, in this paper, we introduce a model-based\nreinforcement learning framework accounting for model risk to support\nbioprocess online learning and guide the optimal reliable customized stopping\npolicy for fermentation process. Specifically, built on the dynamic mechanisms\nof protein and impurity generation, we first construct a probabilistic model\ncharacterizing the impact of underlying bioprocess stochastic uncertainty on\nimpurity and protein growth rates. Since biopharmaceutical manufacturing often\nhas very limited batch data during the development and early stage of\nproduction, we derive the posterior distribution quantifying the process model\nrisk, and further develop the Bayesian rule based knowledge update to support\nbioprocess online learning. With the prediction risk accounting for both\nbioprocess stochastic uncertainty and model risk, the proposed reinforcement\nlearning framework can provide the optimal and reliable decision making. We\nconduct the structural analysis of optimal policy and study the impact of model\nrisk on the policy selection. We can show that it asymptotically converges to\nthe optimal policy obtained under perfect information of underlying stochastic\nprocess. Our case studies demonstrate that the proposed framework can greatly\nimprove the biomanufacturing industrial practice.",
          "link": "http://arxiv.org/abs/2101.03735",
          "publishedOn": "2021-06-09T02:01:50.295Z",
          "wordCount": null,
          "title": "Optimizing Biomanufacturing Harvesting Decisions under Limited Historical Data. (arXiv:2101.03735v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Changlin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Wei Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Sha Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>",
          "description": "Hypergraph offers a framework to depict the multilateral relationships in\nreal-world complex data. Predicting higher-order relationships, i.e hyperedge,\nbecomes a fundamental problem for the full understanding of complicated\ninteractions. The development of graph neural network (GNN) has greatly\nadvanced the analysis of ordinary graphs with pair-wise relations. However,\nthese methods could not be easily extended to the case of hypergraph. In this\npaper, we generalize the challenges of GNN in representing higher-order data in\nprinciple, which are edge- and node-level ambiguities. To overcome the\nchallenges, we present \\textbf{SNALS} that utilizes bipartite graph neural\nnetwork with structural features to collectively tackle the two ambiguity\nissues. SNALS captures the joint interactions of a hyperedge by its local\nenvironment, which is retrieved by collecting the spectrum information of their\nconnections. As a result, SNALS achieves nearly 30% performance increase\ncompared with most recent GNN-based models. In addition, we applied SNALS to\npredict genetic higher-order interactions on 3D genome organization data. SNALS\nshowed consistently high prediction accuracy across different chromosomes, and\ngenerated novel findings on 4-way gene interaction, which is further validated\nby existing literature.",
          "link": "http://arxiv.org/abs/2106.04292",
          "publishedOn": "2021-06-09T02:01:50.291Z",
          "wordCount": null,
          "title": "Principled Hyperedge Prediction with Structural Spectral Features and Neural Networks. (arXiv:2106.04292v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2011.06806",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1\">Fabio Bonassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farina_M/0/1/0/all/0/1\">Marcello Farina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1\">Riccardo Scattolini</a>",
          "description": "The goal of this paper is to provide sufficient conditions for guaranteeing\nthe Input-to-State Stability (ISS) and the Incremental Input-to-State Stability\n({\\delta}ISS) of Gated Recurrent Units (GRUs) neural networks. These\nconditions, devised for both single-layer and multi-layer architectures,\nconsist of nonlinear inequalities on network's weights. They can be employed to\ncheck the stability of trained networks, or can be enforced as constraints\nduring the training procedure of a GRU. The resulting training procedure is\ntested on a Quadruple Tank nonlinear benchmark system, showing satisfactory\nmodeling performances.",
          "link": "http://arxiv.org/abs/2011.06806",
          "publishedOn": "2021-06-09T02:01:50.291Z",
          "wordCount": null,
          "title": "On the stability properties of Gated Recurrent Units neural networks. (arXiv:2011.06806v4 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dapeng Li</a>",
          "description": "We study the problem of stochastic bandits with adversarial corruptions in\nthe cooperative multi-agent setting, where $V$ agents interact with a common\n$K$-armed bandit problem, and each pair of agents can communicate with each\nother to expedite the learning process. In the problem, the rewards are\nindependently sampled from distributions across all agents and rounds, but they\nmay be corrupted by an adversary. Our goal is to minimize both the overall\nregret and communication cost across all agents. We first show that an additive\nterm of corruption is unavoidable for any algorithm in this problem. Then, we\npropose a new algorithm that is agnostic to the level of corruption. Our\nalgorithm not only achieves near-optimal regret in the stochastic setting, but\nalso obtains a regret with an additive term of corruption in the corrupted\nsetting, while maintaining efficient communication. The algorithm is also\napplicable for the single-agent corruption problem, and achieves a high\nprobability regret that removes the multiplicative dependence of $K$ on\ncorruption level. Our result of the single-agent case resolves an open question\nfrom Gupta et al. [2019].",
          "link": "http://arxiv.org/abs/2106.04207",
          "publishedOn": "2021-06-09T02:01:50.290Z",
          "wordCount": null,
          "title": "Cooperative Stochastic Multi-agent Multi-armed Bandits Robust to Adversarial Corruptions. (arXiv:2106.04207v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1\">Megha Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>",
          "description": "Intelligent and adaptive online education systems aim to make high-quality\neducation available for a diverse range of students. However, existing systems\nusually depend on a pool of hand-made questions, limiting how fine-grained and\nopen-ended they can be in adapting to individual students. We explore targeted\nquestion generation as a controllable sequence generation task. We first show\nhow to fine-tune pre-trained language models for deep knowledge tracing\n(LM-KT). This model accurately predicts the probability of a student answering\na question correctly, and generalizes to questions not seen in training. We\nthen use LM-KT to specify the objective and data for training a model to\ngenerate questions conditioned on the student and target difficulty. Our\nresults show we succeed at generating novel, well-calibrated language\ntranslation questions for second language learners from a real online education\nplatform.",
          "link": "http://arxiv.org/abs/2106.04262",
          "publishedOn": "2021-06-09T02:01:50.290Z",
          "wordCount": null,
          "title": "Question Generation for Adaptive Education. (arXiv:2106.04262v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1\">Nishant Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1\">Rajat Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1\">Daniel N. Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S. Dhillon</a>",
          "description": "Query auto-completion (QAC) is a fundamental feature in search engines where\nthe task is to suggest plausible completions of a prefix typed in the search\nbar. Previous queries in the user session can provide useful context for the\nuser's intent and can be leveraged to suggest auto-completions that are more\nrelevant while adhering to the user's prefix. Such session-aware QACs can be\ngenerated by recent sequence-to-sequence deep learning models; however, these\ngenerative approaches often do not meet the stringent latency requirements of\nresponding to each user keystroke. Moreover, these generative approaches pose\nthe risk of showing nonsensical queries.\n\nIn this paper, we provide a solution to this problem: we take the novel\napproach of modeling session-aware QAC as an eXtreme Multi-Label Ranking (XMR)\nproblem where the input is the previous query in the session and the user's\ncurrent prefix, while the output space is the set of tens of millions of\nqueries entered by users in the recent past. We adapt a popular XMR algorithm\nfor this purpose by proposing several modifications to the key steps in the\nalgorithm. The proposed modifications yield a 10x improvement in terms of Mean\nReciprocal Rank (MRR) over the baseline XMR approach on a public search logs\ndataset. We are able to maintain an inference latency of less than 10 ms while\nstill using session context. When compared against baseline models of\nacceptable latency, we observed a 33% improvement in MRR for short prefixes of\nup to 3 characters. Moreover, our model yielded a statistically significant\nimprovement of 2.81% over a production QAC system in terms of suggestion\nacceptance rate, when deployed on the search bar of an online shopping store as\npart of an A/B test.",
          "link": "http://arxiv.org/abs/2012.07654",
          "publishedOn": "2021-06-09T02:01:50.290Z",
          "wordCount": null,
          "title": "Session-Aware Query Auto-completion using Extreme Multi-label Ranking. (arXiv:2012.07654v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.06197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arumugam_D/0/1/0/all/0/1\">Dilip Arumugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Agents that learn to select optimal actions represent a prominent focus of\nthe sequential decision-making literature. In the face of a complex environment\nor constraints on time and resources, however, aiming to synthesize such an\noptimal policy can become infeasible. These scenarios give rise to an important\ntrade-off between the information an agent must acquire to learn and the\nsub-optimality of the resulting policy. While an agent designer has a\npreference for how this trade-off is resolved, existing approaches further\nrequire that the designer translate these preferences into a fixed learning\ntarget for the agent. In this work, leveraging rate-distortion theory, we\nautomate this process such that the designer need only express their\npreferences via a single hyperparameter and the agent is endowed with the\nability to compute its own learning targets that best achieve the desired\ntrade-off. We establish a general bound on expected discounted regret for an\nagent that decides what to learn in this manner along with computational\nexperiments that illustrate the expressiveness of designer preferences and even\nshow improvements over Thompson sampling in identifying an optimal policy.",
          "link": "http://arxiv.org/abs/2101.06197",
          "publishedOn": "2021-06-09T02:01:50.290Z",
          "wordCount": null,
          "title": "Deciding What to Learn: A Rate-Distortion Approach. (arXiv:2101.06197v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.07365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resende_A/0/1/0/all/0/1\">Amanda Resende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Railsback_D/0/1/0/all/0/1\">Davis Railsback</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1\">Rafael Dowsley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1\">Anderson C. A. Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aranha_D/0/1/0/all/0/1\">Diego F. Aranha</a>",
          "description": "We propose a privacy-preserving Naive Bayes classifier and apply it to the\nproblem of private text classification. In this setting, a party (Alice) holds\na text message, while another party (Bob) holds a classifier. At the end of the\nprotocol, Alice will only learn the result of the classifier applied to her\ntext input and Bob learns nothing. Our solution is based on Secure Multiparty\nComputation (SMC). Our Rust implementation provides a fast and secure solution\nfor the classification of unstructured text. Applying our solution to the case\nof spam detection (the solution is generic, and can be used in any other\nscenario in which the Naive Bayes classifier can be employed), we can classify\nan SMS as spam or ham in less than 340ms in the case where the dictionary size\nof Bob's model includes all words (n = 5200) and Alice's SMS has at most m =\n160 unigrams. In the case with n = 369 and m = 8 (the average of a spam SMS in\nthe database), our solution takes only 21ms.",
          "link": "http://arxiv.org/abs/2101.07365",
          "publishedOn": "2021-06-09T02:01:50.290Z",
          "wordCount": null,
          "title": "Fast Privacy-Preserving Text Classification based on Secure Multiparty Computation. (arXiv:2101.07365v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopuklu_O/0/1/0/all/0/1\">Okan K&#xf6;p&#xfc;kl&#xfc;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taseska_M/0/1/0/all/0/1\">Maja Taseska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Successful active speaker detection requires a three-stage pipeline: (i)\naudio-visual encoding for all speakers in the clip, (ii) inter-speaker relation\nmodeling between a reference speaker and the background speakers within each\nframe, and (iii) temporal modeling for the reference speaker. Each stage of\nthis pipeline plays an important role for the final performance of the created\narchitecture. Based on a series of controlled experiments, this work presents\nseveral practical guidelines for audio-visual active speaker detection.\nCorrespondingly, we present a new architecture called ASDNet, which achieves a\nnew state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5%\noutperforming the second best with a large margin of 4.7%. Our code and\npretrained models are publicly available.",
          "link": "http://arxiv.org/abs/2106.03932",
          "publishedOn": "2021-06-09T02:01:50.289Z",
          "wordCount": null,
          "title": "How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild. (arXiv:2106.03932v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mama_R/0/1/0/all/0/1\">Rayhane Mama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyndel_M/0/1/0/all/0/1\">Marc S. Tyndel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadhim_H/0/1/0/all/0/1\">Hashiam Kadhim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifford_C/0/1/0/all/0/1\">Cole Clifford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thurairatnam_R/0/1/0/all/0/1\">Ragavan Thurairatnam</a>",
          "description": "In this work we introduce NWT, an expressive speech-to-video model. Unlike\napproaches that use domain-specific intermediate representations such as pose\nkeypoints, NWT learns its own latent representations, with minimal assumptions\nabout the audio and video content. To this end, we propose a novel discrete\nvariational autoencoder with adversarial loss, dVAE-Adv, which learns a new\ndiscrete latent representation we call Memcodes. Memcodes are straightforward\nto implement, require no additional loss terms, are stable to train compared\nwith other approaches, and show evidence of interpretability. To predict on the\nMemcode space, we use an autoregressive encoder-decoder model conditioned on\naudio. Additionally, our model can control latent attributes in the generated\nvideo that are not annotated in the data. We train NWT on clips from HBO's Last\nWeek Tonight with John Oliver. NWT consistently scores above other approaches\nin Mean Opinion Score (MOS) on tests of overall video naturalness, facial\nnaturalness and expressiveness, and lipsync quality. This work sets a strong\nbaseline for generalized audio-to-video synthesis. Samples are available at\nhttps://next-week-tonight.github.io/NWT/.",
          "link": "http://arxiv.org/abs/2106.04283",
          "publishedOn": "2021-06-09T02:01:50.289Z",
          "wordCount": null,
          "title": "NWT: Towards natural audio-to-video generation with representation learning. (arXiv:2106.04283v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2009.04441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Padh_K/0/1/0/all/0/1\">Kirtan Padh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1\">Diego Antognini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaude_E/0/1/0/all/0/1\">Emma Lejal Glaude</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1\">Boi Faltings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musat_C/0/1/0/all/0/1\">Claudiu Musat</a>",
          "description": "The goal of fairness in classification is to learn a classifier that does not\ndiscriminate against groups of individuals based on sensitive attributes, such\nas race and gender. One approach to designing fair algorithms is to use\nrelaxations of fairness notions as regularization terms or in a constrained\noptimization problem. We observe that the hyperbolic tangent function can\napproximate the indicator function. We leverage this property to define a\ndifferentiable relaxation that approximates fairness notions provably better\nthan existing relaxations. In addition, we propose a model-agnostic\nmulti-objective architecture that can simultaneously optimize for multiple\nfairness notions and multiple sensitive attributes and supports all statistical\nparity-based notions of fairness. We use our relaxation with the\nmulti-objective architecture to learn fair classifiers. Experiments on public\ndatasets show that our method suffers a significantly lower loss of accuracy\nthan current debiasing algorithms relative to the unconstrained model.",
          "link": "http://arxiv.org/abs/2009.04441",
          "publishedOn": "2021-06-09T02:01:50.289Z",
          "wordCount": null,
          "title": "Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm. (arXiv:2009.04441v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04873",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ruszczynski_A/0/1/0/all/0/1\">Andrzej Ruszczy&#x144;ski</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Landi Zhu</a>",
          "description": "We consider a distributionally robust formulation of stochastic optimization\nproblems arising in statistical learning, where robustness is with respect to\nuncertainty in the underlying data distribution. Our formulation builds on\nrisk-averse optimization techniques and the theory of coherent risk measures.\nIt uses semi-deviation risk for quantifying uncertainty, allowing us to compute\nsolutions that are robust against perturbations in the population data\ndistribution. We consider a large family of loss functions that can be\nnon-convex and non-smooth and develop an efficient stochastic subgradient\nmethod. We prove that it converges to a point satisfying the optimality\nconditions. To our knowledge, this is the first method with rigorous\nconvergence guarantees in the context of non-convex non-smooth distributionally\nrobust stochastic optimization. Our method can achieve any desired level of\nrobustness with little extra computational cost compared to population risk\nminimization. We also illustrate the performance of our algorithm on real\ndatasets arising in convex and non-convex supervised learning problems.",
          "link": "http://arxiv.org/abs/2006.04873",
          "publishedOn": "2021-06-09T02:01:50.280Z",
          "wordCount": null,
          "title": "A Stochastic Subgradient Method for Distributionally Robust Non-Convex Learning. (arXiv:2006.04873v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peilin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1\">Tiffany Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>",
          "description": "Programmatic weak supervision creates models without hand-labeled training\ndata by combining the outputs of noisy, user-written rules and other heuristic\nlabelers. Existing frameworks make the restrictive assumption that labelers\noutput a single class label. Enabling users to create partial labelers that\noutput subsets of possible class labels would greatly expand the expressivity\nof programmatic weak supervision. We introduce this capability by defining a\nprobabilistic generative model that can estimate the underlying accuracies of\nmultiple noisy partial labelers without ground truth labels. We prove that this\nclass of models is generically identifiable up to label swapping under mild\nconditions. We also show how to scale up learning to 100k examples in one\nminute, a 300X speed up compared to a naive implementation. We evaluate our\nframework on three text classification and six object classification tasks. On\ntext tasks, adding partial labels increases average accuracy by 9.6 percentage\npoints. On image tasks, we show that partial labels allow us to approach some\nzero-shot object classification problems with programmatic weak supervision by\nusing class attributes as partial labelers. Our framework is able to achieve\naccuracy comparable to recent embedding-based zero-shot learning methods using\nonly pre-trained attribute detectors",
          "link": "http://arxiv.org/abs/2106.04530",
          "publishedOn": "2021-06-09T02:01:50.279Z",
          "wordCount": null,
          "title": "Learning from Multiple Noisy Partial Labelers. (arXiv:2106.04530v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreuzer_D/0/1/0/all/0/1\">Devin Kreuzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1\">Dominique Beaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Letourneau_V/0/1/0/all/0/1\">Vincent L&#xe9;tourneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tossou_P/0/1/0/all/0/1\">Prudencio Tossou</a>",
          "description": "In recent years, the Transformer architecture has proven to be very\nsuccessful in sequence processing, but its application to other data\nstructures, such as graphs, has remained limited due to the difficulty of\nproperly defining positions. Here, we present the $\\textit{Spectral Attention\nNetwork}$ (SAN), which uses a learned positional encoding (LPE) that can take\nadvantage of the full Laplacian spectrum to learn the position of each node in\na given graph. This LPE is then added to the node features of the graph and\npassed to a fully-connected Transformer. By leveraging the full spectrum of the\nLaplacian, our model is theoretically powerful in distinguishing graphs, and\ncan better detect similar sub-structures from their resonance. Further, by\nfully connecting the graph, the Transformer does not suffer from\nover-squashing, an information bottleneck of most GNNs, and enables better\nmodeling of physical phenomenons such as heat transfer and electric\ninteraction. When tested empirically on a set of 4 standard datasets, our model\nperforms on par or better than state-of-the-art GNNs, and outperforms any\nattention-based model by a wide margin, becoming the first fully-connected\narchitecture to perform well on graph benchmarks.",
          "link": "http://arxiv.org/abs/2106.03893",
          "publishedOn": "2021-06-09T02:01:50.277Z",
          "wordCount": null,
          "title": "Rethinking Graph Transformers with Spectral Attention. (arXiv:2106.03893v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1\">Piotr Pi&#x119;kos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1\">Henryk Michalewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>",
          "description": "Imagine you are in a supermarket. You have two bananas in your basket and\nwant to buy four apples. How many fruits do you have in total? This seemingly\nstraightforward question can be challenging for data-driven language models,\neven if trained at scale. However, we would expect such generic language models\nto possess some mathematical abilities in addition to typical linguistic\ncompetence. Towards this goal, we investigate if a commonly used language\nmodel, BERT, possesses such mathematical abilities and, if so, to what degree.\nFor that, we fine-tune BERT on a popular dataset for word math problems,\nAQuA-RAT, and conduct several tests to understand learned representations\nbetter. Since we teach models trained on natural language to do formal\nmathematics, we hypothesize that such models would benefit from training on\nsemi-formal steps that explain how math results are derived. To better\naccommodate such training, we also propose new pretext tasks for learning\nmathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or\nNROP). With this new model, we achieve significantly better outcomes than\ndata-driven baselines and even on-par with more tailored models. We also show\nhow to reduce positional bias in such models.",
          "link": "http://arxiv.org/abs/2106.03921",
          "publishedOn": "2021-06-09T02:01:50.276Z",
          "wordCount": null,
          "title": "Measuring and Improving BERT's Mathematical Abilities by Predicting the Order of Reasoning. (arXiv:2106.03921v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "A common optimization tool used in deep reinforcement learning is momentum,\nwhich consists in accumulating and discounting past gradients, reapplying them\nat each iteration. We argue that, unlike in supervised learning, momentum in\nTemporal Difference (TD) learning accumulates gradients that become doubly\nstale: not only does the gradient of the loss change due to parameter updates,\nthe loss itself changes due to bootstrapping. We first show that this\nphenomenon exists, and then propose a first-order correction term to momentum.\nWe show that this correction term improves sample efficiency in policy\nevaluation by correcting target value drift. An important insight of this work\nis that deep RL methods are not always best served by directly importing\ntechniques from the supervised setting.",
          "link": "http://arxiv.org/abs/2106.03955",
          "publishedOn": "2021-06-09T02:01:50.275Z",
          "wordCount": null,
          "title": "Correcting Momentum in Temporal Difference Learning. (arXiv:2106.03955v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04377",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sarkar_A/0/1/0/all/0/1\">Aditya Sarkar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bhavsar_A/0/1/0/all/0/1\">Arnav Bhavsar</a>",
          "description": "In silico prediction of cardiotoxicity with high sensitivity and specificity\nfor potential drug molecules can be of immense value. Hence, building machine\nlearning classification models, based on some features extracted from the\nmolecular structure of drugs, which are capable of efficiently predicting\ncardiotoxicity is critical. In this paper, we consider the application of\nvarious machine learning approaches, and then propose an ensemble classifier\nfor the prediction of molecular activity on a Drug Discovery Hackathon (DDH)\n(1st reference) dataset. We have used only 2-D descriptors of SMILE notations\nfor our prediction. Our ensemble classification uses 5 classifiers (2 Random\nForest Classifiers, 2 Support Vector Machines and a Dense Neural Network) and\nuses Max-Voting technique and Weighted-Average technique for final decision.",
          "link": "http://arxiv.org/abs/2106.04377",
          "publishedOn": "2021-06-09T02:01:50.271Z",
          "wordCount": null,
          "title": "Virtual Screening of Pharmaceutical Compounds with hERG Inhibitory Activity (Cardiotoxicity) using Ensemble Learning. (arXiv:2106.04377v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02383",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1\">Fabio Bonassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Silva_C/0/1/0/all/0/1\">Caio Fabio Oliveira da Silva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1\">Riccardo Scattolini</a>",
          "description": "The use of Recurrent Neural Networks (RNNs) for system identification has\nrecently gathered increasing attention, thanks to their black-box modeling\ncapabilities.Albeit RNNs have been fruitfully adopted in many applications,\nonly few works are devoted to provide rigorous theoretical foundations that\njustify their use for control purposes. The aim of this paper is to describe\nhow stable Gated Recurrent Units (GRUs), a particular RNN architecture, can be\ntrained and employed in a Nonlinear MPC framework to perform offset-free\ntracking of constant references with guaranteed closed-loop stability. The\nproposed approach is tested on a pH neutralization process benchmark, showing\nremarkable performances.",
          "link": "http://arxiv.org/abs/2103.02383",
          "publishedOn": "2021-06-09T02:01:50.260Z",
          "wordCount": null,
          "title": "Nonlinear MPC for Offset-Free Tracking of systems learned by GRU Neural Networks. (arXiv:2103.02383v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xinran Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>",
          "description": "Federated Learning (FL) coordinates with numerous heterogeneous devices to\ncollaboratively train a shared model while preserving user privacy. Despite its\nmultiple advantages, FL faces new challenges. One challenge arises when devices\ndrop out of the training process beyond the control of the central server. In\nthis case, the convergence of popular FL algorithms such as FedAvg is severely\ninfluenced by the straggling devices. To tackle this challenge, we study\nfederated learning algorithms under arbitrary device unavailability and propose\nan algorithm named Memory-augmented Impatient Federated Averaging (MIFA). Our\nalgorithm efficiently avoids excessive latency induced by inactive devices, and\ncorrects the gradient bias using the memorized latest updates from the devices.\nWe prove that MIFA achieves minimax optimal convergence rates on non-i.i.d.\ndata for both strongly convex and non-convex smooth functions. We also provide\nan explicit characterization of the improvement over baseline algorithms\nthrough a case study, and validate the results by numerical experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2106.04159",
          "publishedOn": "2021-06-09T02:01:50.254Z",
          "wordCount": null,
          "title": "Fast Federated Learning in the Presence of Arbitrary Device Unavailability. (arXiv:2106.04159v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Byeonggeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Simyung Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinkyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_D/0/1/0/all/0/1\">Dooyong Sung</a>",
          "description": "Keyword spotting is an important research field because it plays a key role\nin device wake-up and user interaction on smart devices. However, it is\nchallenging to minimize errors while operating efficiently in devices with\nlimited resources such as mobile phones. We present a broadcasted residual\nlearning method to achieve high accuracy with small model size and\ncomputational load. Our method configures most of the residual functions as 1D\ntemporal convolution while still allows 2D convolution together using a\nbroadcasted-residual connection that expands temporal output to\nfrequency-temporal dimension. This residual mapping enables the network to\neffectively represent useful audio features with much less computation than\nconventional convolutional neural networks. We also propose a novel network\narchitecture, Broadcasting-residual network (BC-ResNet), based on broadcasted\nresidual learning and describe how to scale up the model according to the\ntarget device's resources. BC-ResNets achieve state-of-the-art 98.0% and 98.7%\ntop-1 accuracy on Google speech command datasets v1 and v2, respectively, and\nconsistently outperform previous approaches, using fewer computations and\nparameters.",
          "link": "http://arxiv.org/abs/2106.04140",
          "publishedOn": "2021-06-09T02:01:50.211Z",
          "wordCount": null,
          "title": "Broadcasted Residual Learning for Efficient Keyword Spotting. (arXiv:2106.04140v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03970",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Daneshmand_H/0/1/0/all/0/1\">Hadi Daneshmand</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Joudaki_A/0/1/0/all/0/1\">Amir Joudaki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1\">Francis Bach</a>",
          "description": "This paper underlines a subtle property of batch-normalization (BN):\nSuccessive batch normalizations with random linear transformations make hidden\nrepresentations increasingly orthogonal across layers of a deep neural network.\nWe establish a non-asymptotic characterization of the interplay between depth,\nwidth, and the orthogonality of deep representations. More precisely, under a\nmild assumption, we prove that the deviation of the representations from\northogonality rapidly decays with depth up to a term inversely proportional to\nthe network width. This result has two main implications: 1) Theoretically, as\nthe depth grows, the distribution of the representation -- after the linear\nlayers -- contracts to a Wasserstein-2 ball around an isotropic Gaussian\ndistribution. Furthermore, the radius of this Wasserstein ball shrinks with the\nwidth of the network. 2) In practice, the orthogonality of the representations\ndirectly influences the performance of stochastic gradient descent (SGD). When\nrepresentations are initially aligned, we observe SGD wastes many iterations to\northogonalize representations before the classification. Nevertheless, we\nexperimentally show that starting optimization from orthogonal representations\nis sufficient to accelerate SGD, with no need for BN.",
          "link": "http://arxiv.org/abs/2106.03970",
          "publishedOn": "2021-06-09T02:01:50.210Z",
          "wordCount": null,
          "title": "Batch Normalization Orthogonalizes Representations in Deep Random Networks. (arXiv:2106.03970v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kortylewski_A/0/1/0/all/0/1\">Adam Kortylewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1\">Weichao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cihang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1\">Sarah Adel Bargal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1\">Stan Sclaroff</a>",
          "description": "Most machine learning models are validated and tested on fixed datasets. This\ncan give an incomplete picture of the capabilities and weaknesses of the model.\nSuch weaknesses can be revealed at test time in the real world. The risks\ninvolved in such failures can be loss of profits, loss of time or even loss of\nlife in certain critical applications. In order to alleviate this issue,\nsimulators can be controlled in a fine-grained manner using interpretable\nparameters to explore the semantic image manifold. In this work, we propose a\nframework for learning how to test machine learning algorithms using simulators\nin an adversarial manner in order to find weaknesses in the model before\ndeploying it in critical scenarios. We apply this model in a face recognition\nscenario. We are the first to show that weaknesses of models trained on real\ndata can be discovered using simulated samples. Using our proposed method, we\ncan find adversarial synthetic faces that fool contemporary face recognition\nmodels. This demonstrates the fact that these models have weaknesses that are\nnot measured by commonly used validation datasets. We hypothesize that this\ntype of adversarial examples are not isolated, but usually lie in connected\ncomponents in the latent space of the simulator. We present a method to find\nthese adversarial regions as opposed to the typical adversarial points found in\nthe adversarial example literature.",
          "link": "http://arxiv.org/abs/2106.04569",
          "publishedOn": "2021-06-09T02:01:50.208Z",
          "wordCount": null,
          "title": "Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aladago_M/0/1/0/all/0/1\">Maxwell Mbabilla Aladago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1\">Lorenzo Torresani</a>",
          "description": "In contrast to traditional weight optimization in a continuous space, we\ndemonstrate the existence of effective random networks whose weights are never\nupdated. By selecting a weight among a fixed set of random values for each\nindividual connection, our method uncovers combinations of random weights that\nmatch the performance of traditionally-trained networks of the same capacity.\nWe refer to our networks as \"slot machines\" where each reel (connection)\ncontains a fixed set of symbols (random values). Our backpropagation algorithm\n\"spins\" the reels to seek \"winning\" combinations, i.e., selections of random\nweight values that minimize the given loss. Quite surprisingly, we find that\nallocating just a few random values to each connection (e.g., 8 values per\nconnection) yields highly competitive combinations despite being dramatically\nmore constrained compared to traditionally learned weights. Moreover,\nfinetuning these combinations often improves performance over the trained\nbaselines. A randomly initialized VGG-19 with 8 values per connection contains\na combination that achieves 91% test accuracy on CIFAR-10. Our method also\nachieves an impressive performance of 98.2% on MNIST for neural networks\ncontaining only random weights.",
          "link": "http://arxiv.org/abs/2101.06475",
          "publishedOn": "2021-06-09T02:01:50.208Z",
          "wordCount": null,
          "title": "Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks. (arXiv:2101.06475v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08208",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Junhyung Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muandet_K/0/1/0/all/0/1\">Krikamol Muandet</a>",
          "description": "We propose to analyse the conditional distributional treatment effect\n(CoDiTE), which, in contrast to the more common conditional average treatment\neffect (CATE), is designed to encode a treatment's distributional aspects\nbeyond the mean. We first introduce a formal definition of the CoDiTE\nassociated with a distance function between probability measures. Then we\ndiscuss the CoDiTE associated with the maximum mean discrepancy via kernel\nconditional mean embeddings, which, coupled with a hypothesis test, tells us\nwhether there is any conditional distributional effect of the treatment.\nFinally, we investigate what kind of conditional distributional effect the\ntreatment has, both in an exploratory manner via the conditional witness\nfunction, and in a quantitative manner via U-statistic regression, generalising\nthe CATE to higher-order moments. Experiments on synthetic, semi-synthetic and\nreal datasets demonstrate the merits of our approach.",
          "link": "http://arxiv.org/abs/2102.08208",
          "publishedOn": "2021-06-09T02:01:50.207Z",
          "wordCount": null,
          "title": "Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression. (arXiv:2102.08208v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rass_S/0/1/0/all/0/1\">Stefan Rass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konig_S/0/1/0/all/0/1\">Sandra K&#xf6;nig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachter_J/0/1/0/all/0/1\">Jasmin Wachter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_M/0/1/0/all/0/1\">Manuel Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hobisch_M/0/1/0/all/0/1\">Manuel Hobisch</a>",
          "description": "We study the question of how well machine learning (ML) models trained on a\ncertain data set provide privacy for the training data, or equivalently,\nwhether it is possible to reverse-engineer the training data from a given ML\nmodel. While this is easy to answer negatively in the most general case, it is\ninteresting to note that the protection extends over non-recoverability towards\nplausible deniability: Given an ML model $f$, we show that one can take a set\nof purely random training data, and from this define a suitable ``learning\nrule'' that will produce a ML model that is exactly $f$. Thus, any speculation\nabout which data has been used to train $f$ is deniable upon the claim that any\nother data could have led to the same results. We corroborate our theoretical\nfinding with practical examples, and open source implementations of how to find\nthe learning rules for a chosen set of raining data.",
          "link": "http://arxiv.org/abs/2106.04267",
          "publishedOn": "2021-06-09T02:01:50.205Z",
          "wordCount": null,
          "title": "Supervised Machine Learning with Plausible Deniability. (arXiv:2106.04267v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Deep learning has achieved remarkable success in numerous domains with help\nfrom large amounts of big data. However, the quality of data labels is a\nconcern because of the lack of high-quality labels in many real-world\nscenarios. As noisy labels severely degrade the generalization performance of\ndeep neural networks, learning from noisy labels (robust training) is becoming\nan important task in modern deep learning applications. In this survey, we\nfirst describe the problem of learning with label noise from a supervised\nlearning perspective. Next, we provide a comprehensive review of 57\nstate-of-the-art robust training methods, all of which are categorized into\nfive groups according to their methodological difference, followed by a\nsystematic comparison of six properties used to evaluate their superiority.\nSubsequently, we perform an in-depth analysis of noise rate estimation and\nsummarize the typically used evaluation methodology, including public noisy\ndatasets and evaluation metrics. Finally, we present several promising research\ndirections that can serve as a guideline for future studies. All the contents\nwill be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.",
          "link": "http://arxiv.org/abs/2007.08199",
          "publishedOn": "2021-06-09T02:01:50.204Z",
          "wordCount": null,
          "title": "Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03891",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Bharti_K/0/1/0/all/0/1\">Kishor Bharti</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Haug_T/0/1/0/all/0/1\">Tobias Haug</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vedral_V/0/1/0/all/0/1\">Vlatko Vedral</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kwek_L/0/1/0/all/0/1\">Leong-Chuan Kwek</a>",
          "description": "Semidefinite Programming (SDP) is a class of convex optimization programs\nwith vast applications in control theory, quantum information, combinatorial\noptimization and operational research. Noisy intermediate-scale quantum (NISQ)\nalgorithms aim to make an efficient use of the current generation of quantum\nhardware. However, optimizing variational quantum algorithms is a challenge as\nit is an NP-hard problem that in general requires an exponential time to solve\nand can contain many far from optimal local minima. Here, we present a current\nterm NISQ algorithm for SDP. The classical optimization program of our NISQ\nsolver is another SDP over a smaller dimensional ansatz space. We harness the\nSDP based formulation of the Hamiltonian ground state problem to design a NISQ\neigensolver. Unlike variational quantum eigensolvers, the classical\noptimization program of our eigensolver is convex, can be solved in polynomial\ntime with the number of ansatz parameters and every local minimum is a global\nminimum. Further, we demonstrate the potential of our NISQ SDP solver by\nfinding the largest eigenvalue of up to $2^{1000}$ dimensional matrices and\nsolving graph problems related to quantum contextuality. We also discuss NISQ\nalgorithms for rank-constrained SDPs. Our work extends the application of NISQ\ncomputers onto one of the most successful algorithmic frameworks of the past\nfew decades.",
          "link": "http://arxiv.org/abs/2106.03891",
          "publishedOn": "2021-06-09T02:01:50.203Z",
          "wordCount": null,
          "title": "NISQ Algorithm for Semidefinite Programming. (arXiv:2106.03891v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2102.00760",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1\">Vivien Cabannes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1\">Alessandro Rudi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1\">Francis Bach</a>",
          "description": "Discrete supervised learning problems such as classification are often\ntackled by introducing a continuous surrogate problem akin to regression.\nBounding the original error, between estimate and solution, by the surrogate\nerror endows discrete problems with convergence rates already shown for\ncontinuous instances. Yet, current approaches do not leverage the fact that\ndiscrete problems are essentially predicting a discrete output when continuous\nproblems are predicting a continuous value. In this paper, we tackle this issue\nfor general structured prediction problems, opening the way to \"super fast\"\nrates, that is, convergence rates for the excess risk faster than $n^{-1}$,\nwhere $n$ is the number of observations, with even exponential rates with the\nstrongest assumptions. We first illustrate it for predictors based on nearest\nneighbors, generalizing rates known for binary classification to any discrete\nproblem within the framework of structured prediction. We then consider kernel\nridge regression where we improve known rates in $n^{-1/4}$ to arbitrarily fast\nrates, depending on a parameter characterizing the hardness of the problem,\nthus allowing, under smoothness assumptions, to bypass the curse of\ndimensionality.",
          "link": "http://arxiv.org/abs/2102.00760",
          "publishedOn": "2021-06-09T02:01:50.201Z",
          "wordCount": null,
          "title": "Fast rates in structured prediction. (arXiv:2102.00760v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angelopoulos_S/0/1/0/all/0/1\">Spyros Angelopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamali_S/0/1/0/all/0/1\">Shahin Kamali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadkami_K/0/1/0/all/0/1\">Kimia Shadkami</a>",
          "description": "Bin packing is a classic optimization problem with a wide range of\napplications from load balancing in networks to supply chain management. In\nthis work we study the online variant of the problem, in which a sequence of\nitems of various sizes must be placed into a minimum number of bins of uniform\ncapacity. The online algorithm is enhanced with a (potentially erroneous)\nprediction concerning the frequency of item sizes in the sequence. We design\nand analyze online algorithms with efficient tradeoffs between consistency\n(i.e., the competitive ratio assuming no prediction error) and robustness\n(i.e., the competitive ratio under adversarial error), and whose performance\ndegrades gently as a function of the prediction error. This is the first\ntheoretical study of online bin packing in the realistic setting of erroneous\npredictions, as well as the first experimental study in the setting in which\nthe input is generated according to both static and evolving distributions.\nPrevious work on this problem has only addressed the extreme cases with respect\nto the prediction error, has relied on overly powerful and error-free\nprediction oracles, and has focused on experimental evaluation based on static\ninput distributions.",
          "link": "http://arxiv.org/abs/2102.03311",
          "publishedOn": "2021-06-09T02:01:50.201Z",
          "wordCount": null,
          "title": "Online Bin Packing with Predictions. (arXiv:2102.03311v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1\">Zachary Nado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1\">Neil Band</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1\">Mark Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djolonga_J/0/1/0/all/0/1\">Josip Djolonga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusenberry_M/0/1/0/all/0/1\">Michael W. Dusenberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filos_A/0/1/0/all/0/1\">Angelos Filos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havasi_M/0/1/0/all/0/1\">Marton Havasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jerfel_G/0/1/0/all/0/1\">Ghassen Jerfel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jeremiah Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mariet_Z/0/1/0/all/0/1\">Zelda Mariet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nixon_J/0/1/0/all/0/1\">Jeremy Nixon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padhy_S/0/1/0/all/0/1\">Shreyas Padhy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudner_T/0/1/0/all/0/1\">Tim G. J. Rudner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yeming Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenzel_F/0/1/0/all/0/1\">Florian Wenzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kevin Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sculley_D/0/1/0/all/0/1\">D. Sculley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Balaji Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_J/0/1/0/all/0/1\">Jasper Snoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1\">Dustin Tran</a>",
          "description": "High-quality estimates of uncertainty and robustness are crucial for numerous\nreal-world applications, especially for deep learning which underlies many\ndeployed ML systems. The ability to compare techniques for improving these\nestimates is therefore very important for research and practice alike. Yet,\ncompetitive comparisons of methods are often lacking due to a range of reasons,\nincluding: compute availability for extensive tuning, incorporation of\nsufficiently many baselines, and concrete documentation for reproducibility. In\nthis paper we introduce Uncertainty Baselines: high-quality implementations of\nstandard and state-of-the-art deep learning methods on a variety of tasks. As\nof this writing, the collection spans 19 methods across 9 tasks, each with at\nleast 5 metrics. Each baseline is a self-contained experiment pipeline with\neasily reusable and extendable components. Our goal is to provide immediate\nstarting points for experimentation with new methods or applications.\nAdditionally we provide model checkpoints, experiment outputs as Python\nnotebooks, and leaderboards for comparing results. Code available at\nhttps://github.com/google/uncertainty-baselines.",
          "link": "http://arxiv.org/abs/2106.04015",
          "publishedOn": "2021-06-09T02:01:50.198Z",
          "wordCount": null,
          "title": "Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep Learning. (arXiv:2106.04015v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Dongxia Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zhiqian Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Recently, there has been considerable research interest in graph clustering\naimed at data partition using the graph information. However, one limitation of\nthe most of graph-based methods is that they assume the graph structure to\noperate is fixed and reliable. And there are inevitably some edges in the graph\nthat are not conducive to graph clustering, which we call spurious edges. This\npaper is the first attempt to employ graph pooling technique for node\nclustering and we propose a novel dual graph embedding network (DGEN), which is\ndesigned as a two-step graph encoder connected by a graph pooling layer to\nlearn the graph embedding. In our model, it is assumed that if a node and its\nnearest neighboring node are close to the same clustering center, this node is\nan informative node and this edge can be considered as a cluster-friendly edge.\nBased on this assumption, the neighbor cluster pooling (NCPool) is devised to\nselect the most informative subset of nodes and the corresponding edges based\non the distance of nodes and their nearest neighbors to the cluster centers.\nThis can effectively alleviate the impact of the spurious edges on the\nclustering. Finally, to obtain the clustering assignment of all nodes, a\nclassifier is trained using the clustering results of the selected nodes.\nExperiments on five benchmark graph datasets demonstrate the superiority of the\nproposed method over state-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2105.05320",
          "publishedOn": "2021-06-09T02:01:50.198Z",
          "wordCount": null,
          "title": "Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph Clustering. (arXiv:2105.05320v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahan_S/0/1/0/all/0/1\">Scott Mahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doster_T/0/1/0/all/0/1\">Tim Doster</a>",
          "description": "Building invariance to non-meaningful transformations is essential to\nbuilding efficient and generalizable machine learning models. In practice, the\nmost common way to learn invariance is through data augmentation. There has\nbeen recent interest in the development of methods that learn distributions on\naugmentation transformations from the training data itself. While such\napproaches are beneficial since they are responsive to the data, they ignore\nthe fact that in many situations the range of transformations to which a model\nneeds to be invariant changes depending on the particular class input belongs\nto. For example, if a model needs to be able to predict whether an image\ncontains a starfish or a dog, we may want to apply random rotations to starfish\nimages during training (since these do not have a preferred orientation), but\nwe would not want to do this to images of dogs. In this work we introduce a\nmethod by which we can learn class conditional distributions on augmentation\ntransformations. We give a number of examples where our methods learn different\nnon-meaningful transformations depending on class and further show how our\nmethod can be used as a tool to probe the symmetries intrinsic to a potentially\ncomplex dataset.",
          "link": "http://arxiv.org/abs/2106.04009",
          "publishedOn": "2021-06-09T02:01:50.197Z",
          "wordCount": null,
          "title": "Rotating spiders and reflecting dogs: a class conditional approach to learning data augmentation distributions. (arXiv:2106.04009v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yuan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baskiotis_N/0/1/0/all/0/1\">Nicolas Baskiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>",
          "description": "When modeling dynamical systems from real-world data samples, the\ndistribution of data often changes according to the environment in which they\nare captured, and the dynamics of the system itself vary from one environment\nto another. Generalizing across environments thus challenges the conventional\nframeworks. The classical settings suggest either considering data as i.i.d.\nand learning a single model to cover all situations or learning\nenvironment-specific models. Both are sub-optimal: the former disregards the\ndiscrepancies between environments leading to biased solutions, while the\nlatter does not exploit their potential commonalities and is prone to scarcity\nproblems. We propose LEADS, a novel framework that leverages the commonalities\nand discrepancies among known environments to improve model generalization.\nThis is achieved with a tailored training formulation aiming at capturing\ncommon dynamics within a shared model while additional terms capture\nenvironment-specific dynamics. We ground our approach in theory, exhibiting a\ndecrease in sample complexity with our approach and corroborate these results\nempirically, instantiating it for linear dynamics. Moreover, we concretize this\nframework for neural networks and evaluate it experimentally on representative\nfamilies of nonlinear dynamics. We show that this new setting can exploit\nknowledge extracted from environment-dependent data and improves generalization\nfor both known and novel environments.",
          "link": "http://arxiv.org/abs/2106.04546",
          "publishedOn": "2021-06-09T02:01:50.197Z",
          "wordCount": null,
          "title": "LEADS: Learning Dynamical Systems that Generalize Across Environments. (arXiv:2106.04546v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.12594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Angelina Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1\">Olga Russakovsky</a>",
          "description": "Mitigating bias in machine learning systems requires refining our\nunderstanding of bias propagation pathways: from societal structures to\nlarge-scale data to trained models to impact on society. In this work, we focus\non one aspect of the problem, namely bias amplification: the tendency of models\nto amplify the biases present in the data they are trained on. A metric for\nmeasuring bias amplification was introduced in the seminal work by Zhao et al.\n(2017); however, as we demonstrate, this metric suffers from a number of\nshortcomings including conflating different types of bias amplification and\nfailing to account for varying base rates of protected attributes. We introduce\nand analyze a new, decoupled metric for measuring bias amplification,\n$\\text{BiasAmp}_{\\rightarrow}$ (Directional Bias Amplification). We thoroughly\nanalyze and discuss both the technical assumptions and normative implications\nof this metric. We provide suggestions about its measurement by cautioning\nagainst predicting sensitive attributes, encouraging the use of confidence\nintervals due to fluctuations in the fairness of models across runs, and\ndiscussing the limitations of what this metric captures. Throughout this paper,\nwe work to provide an interrogative look at the technical measurement of bias\namplification, guided by our normative ideas of what we want it to encompass.\nCode is located at https://github.com/princetonvisualai/directional-bias-amp",
          "link": "http://arxiv.org/abs/2102.12594",
          "publishedOn": "2021-06-09T02:01:50.197Z",
          "wordCount": null,
          "title": "Directional Bias Amplification. (arXiv:2102.12594v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sokar_G/0/1/0/all/0/1\">Ghada Sokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mocanu_E/0/1/0/all/0/1\">Elena Mocanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1\">Decebal Constantin Mocanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>",
          "description": "Deep reinforcement learning has achieved significant success in many\ndecision-making tasks in various fields. However, it requires a large training\ntime of dense neural networks to obtain a good performance. This hinders its\napplicability on low-resource devices where memory and computation are strictly\nconstrained. In a step towards enabling deep reinforcement learning agents to\nbe applied to low-resource devices, in this work, we propose for the first time\nto dynamically train deep reinforcement learning agents with sparse neural\nnetworks from scratch. We adopt the evolution principles of dynamic sparse\ntraining in the reinforcement learning paradigm and introduce a training\nalgorithm that optimizes the sparse topology and the weight values jointly to\ndynamically fit the incoming data. Our approach is easy to be integrated into\nexisting deep reinforcement learning algorithms and has many favorable\nadvantages. First, it allows for significant compression of the network size\nwhich reduces the memory and computation costs substantially. This would\naccelerate not only the agent inference but also its training process. Second,\nit speeds up the agent learning process and allows for reducing the number of\nrequired training steps. Third, it can achieve higher performance than training\nthe dense counterpart network. We evaluate our approach on OpenAI gym\ncontinuous control tasks. The experimental results show the effectiveness of\nour approach in achieving higher performance than one of the state-of-art\nbaselines with a 50\\% reduction in the network size and floating-point\noperations (FLOPs). Moreover, our proposed approach can reach the same\nperformance achieved by the dense network with a 40-50\\% reduction in the\nnumber of training steps.",
          "link": "http://arxiv.org/abs/2106.04217",
          "publishedOn": "2021-06-09T02:01:50.196Z",
          "wordCount": null,
          "title": "Dynamic Sparse Training for Deep Reinforcement Learning. (arXiv:2106.04217v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minghao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "This paper studies unsupervised/self-supervised whole-graph representation\nlearning, which is critical in many tasks such as molecule properties\nprediction in drug and material discovery. Existing methods mainly focus on\npreserving the local similarity structure between different graph instances but\nfail to discover the global semantic structure of the entire data set. In this\npaper, we propose a unified framework called Local-instance and Global-semantic\nLearning (GraphLoG) for self-supervised whole-graph representation learning.\nSpecifically, besides preserving the local similarities, GraphLoG introduces\nthe hierarchical prototypes to capture the global semantic clusters. An\nefficient online expectation-maximization (EM) algorithm is further developed\nfor learning the model. We evaluate GraphLoG by pre-training it on massive\nunlabeled graphs followed by fine-tuning on downstream tasks. Extensive\nexperiments on both chemical and biological benchmark data sets demonstrate the\neffectiveness of the proposed approach.",
          "link": "http://arxiv.org/abs/2106.04113",
          "publishedOn": "2021-06-09T02:01:50.195Z",
          "wordCount": null,
          "title": "Self-supervised Graph-level Representation Learning with Local and Global Structure. (arXiv:2106.04113v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04219",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Omidshafiei_S/0/1/0/all/0/1\">Shayegan Omidshafiei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennes_D/0/1/0/all/0/1\">Daniel Hennes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garnelo_M/0/1/0/all/0/1\">Marta Garnelo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarassov_E/0/1/0/all/0/1\">Eugene Tarassov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Connor_J/0/1/0/all/0/1\">Jerome T. Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_P/0/1/0/all/0/1\">Paul Muller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graham_I/0/1/0/all/0/1\">Ian Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spearman_W/0/1/0/all/0/1\">William Spearman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1\">Karl Tuyls</a>",
          "description": "In multiagent environments, several decision-making individuals interact\nwhile adhering to the dynamics constraints imposed by the environment. These\ninteractions, combined with the potential stochasticity of the agents'\ndecision-making processes, make such systems complex and interesting to study\nfrom a dynamical perspective. Significant research has been conducted on\nlearning models for forward-direction estimation of agent behaviors, for\nexample, pedestrian predictions used for collision-avoidance in self-driving\ncars. However, in many settings, only sporadic observations of agents may be\navailable in a given trajectory sequence. For instance, in football, subsets of\nplayers may come in and out of view of broadcast video footage, while\nunobserved players continue to interact off-screen. In this paper, we study the\nproblem of multiagent time-series imputation, where available past and future\nobservations of subsets of agents are used to estimate missing observations for\nother agents. Our approach, called the Graph Imputer, uses forward- and\nbackward-information in combination with graph networks and variational\nautoencoders to enable learning of a distribution of imputed trajectories. We\nevaluate our approach on a dataset of football matches, using a projective\ncamera module to train and evaluate our model for the off-screen player state\nestimation setting. We illustrate that our method outperforms several\nstate-of-the-art approaches, including those hand-crafted for football.",
          "link": "http://arxiv.org/abs/2106.04219",
          "publishedOn": "2021-06-09T02:01:50.193Z",
          "wordCount": null,
          "title": "Time-series Imputation of Temporally-occluded Multiagent Trajectories. (arXiv:2106.04219v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.03085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Errica_F/0/1/0/all/0/1\">Federico Errica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1\">Davide Bacciu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micheli_A/0/1/0/all/0/1\">Alessio Micheli</a>",
          "description": "We introduce the Graph Mixture Density Networks, a new family of machine\nlearning models that can fit multimodal output distributions conditioned on\ngraphs of arbitrary topology. By combining ideas from mixture models and graph\nrepresentation learning, we address a broader class of challenging conditional\ndensity estimation problems that rely on structured data. In this respect, we\nevaluate our method on a new benchmark application that leverages random graphs\nfor stochastic epidemic simulations. We show a significant improvement in the\nlikelihood of epidemic outcomes when taking into account both multimodality and\nstructure. The empirical analysis is complemented by two real-world regression\ntasks showing the effectiveness of our approach in modeling the output\nprediction uncertainty. Graph Mixture Density Networks open appealing research\nopportunities in the study of structure-dependent phenomena that exhibit\nnon-trivial conditional output distributions.",
          "link": "http://arxiv.org/abs/2012.03085",
          "publishedOn": "2021-06-09T02:01:50.193Z",
          "wordCount": null,
          "title": "Graph Mixture Density Networks. (arXiv:2012.03085v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zakka_K/0/1/0/all/0/1\">Kevin Zakka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Andy Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1\">Pete Florence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1\">Jonathan Tompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1\">Debidatta Dwibedi</a>",
          "description": "We investigate the visual cross-embodiment imitation setting, in which agents\nlearn policies from videos of other agents (such as humans) demonstrating the\nsame task, but with stark differences in their embodiments -- shape, actions,\nend-effector dynamics, etc. In this work, we demonstrate that it is possible to\nautomatically discover and learn vision-based reward functions from\ncross-embodiment demonstration videos that are robust to these differences.\nSpecifically, we present a self-supervised method for Cross-embodiment Inverse\nReinforcement Learning (XIRL) that leverages temporal cycle-consistency\nconstraints to learn deep visual embeddings that capture task progression from\noffline videos of demonstrations across multiple expert agents, each performing\nthe same task differently due to embodiment differences. Prior to our work,\nproducing rewards from self-supervised embeddings has typically required\nalignment with a reference trajectory, which may be difficult to acquire. We\nshow empirically that if the embeddings are aware of task-progress, simply\ntaking the negative distance between the current state and goal state in the\nlearned embedding space is useful as a reward for training policies with\nreinforcement learning. We find our learned reward function not only works for\nembodiments seen during training, but also generalizes to entirely new\nembodiments. We also find that XIRL policies are more sample efficient than\nbaselines, and in some cases exceed the sample efficiency of the same agent\ntrained with ground truth sparse rewards.",
          "link": "http://arxiv.org/abs/2106.03911",
          "publishedOn": "2021-06-09T02:01:50.192Z",
          "wordCount": null,
          "title": "XIRL: Cross-embodiment Inverse Reinforcement Learning. (arXiv:2106.03911v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04229",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Sauceda_H/0/1/0/all/0/1\">Huziel E. Sauceda</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Galvez_Gonzalez_L/0/1/0/all/0/1\">Luis E. G&#xe1;lvez-Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Paz_Borbon_L/0/1/0/all/0/1\">Lauro Oliver Paz-Borb&#xf3;n</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tkatchenko_A/0/1/0/all/0/1\">Alexandre Tkatchenko</a>",
          "description": "Machine-learning force fields (MLFF) should be accurate, computationally and\ndata efficient, and applicable to molecules, materials, and interfaces thereof.\nCurrently, MLFFs often introduce tradeoffs that restrict their practical\napplicability to small subsets of chemical space or require exhaustive datasets\nfor training. Here, we introduce the Bravais-Inspired Gradient-Domain Machine\nLearning (BIGDML) approach and demonstrate its ability to construct reliable\nforce fields using a training set with just 10-200 geometries for materials\nincluding pristine and defect-containing 2D and 3D semiconductors and metals,\nas well as chemisorbed and physisorbed atomic and molecular adsorbates on\nsurfaces. The BIGDML model employs the full relevant symmetry group for a given\nmaterial, does not assume artificial atom types or localization of atomic\ninteractions and exhibits high data efficiency and state-of-the-art energy\naccuracies (errors substantially below 1 meV per atom) for an extended set of\nmaterials. Extensive path-integral molecular dynamics carried out with BIGDML\nmodels demonstrate the counterintuitive localization of benzene--graphene\ndynamics induced by nuclear quantum effects and allow to rationalize the\nArrhenius behavior of hydrogen diffusion coefficient in a Pd crystal for a wide\nrange of temperatures.",
          "link": "http://arxiv.org/abs/2106.04229",
          "publishedOn": "2021-06-09T02:01:50.192Z",
          "wordCount": null,
          "title": "BIGDML: Towards Exact Machine Learning Force Fields for Materials. (arXiv:2106.04229v1 [cond-mat.mtrl-sci])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meinke_A/0/1/0/all/0/1\">Alexander Meinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitterwolf_J/0/1/0/all/0/1\">Julian Bitterwolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "When applying machine learning in safety-critical systems, a reliable\nassessment of the uncertainy of a classifier is required. However, deep neural\nnetworks are known to produce highly overconfident predictions on\nout-of-distribution (OOD) data and even if trained to be non-confident on OOD\ndata one can still adversarially manipulate OOD data so that the classifer\nagain assigns high confidence to the manipulated samples. In this paper we\npropose a novel method where from first principles we combine a certifiable OOD\ndetector with a standard classifier into an OOD aware classifier. In this way\nwe achieve the best of two worlds: certifiably adversarially robust OOD\ndetection, even for OOD samples close to the in-distribution, without loss in\nprediction accuracy and close to state-of-the-art OOD detection performance for\nnon-manipulated OOD data. Moreover, due to the particular construction our\nclassifier provably avoids the asymptotic overconfidence problem of standard\nneural networks.",
          "link": "http://arxiv.org/abs/2106.04260",
          "publishedOn": "2021-06-09T02:01:50.192Z",
          "wordCount": null,
          "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free. (arXiv:2106.04260v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tas_O/0/1/0/all/0/1\">&#xd6;mer &#x15e;ahin Ta&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauser_F/0/1/0/all/0/1\">Felix Hauser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauer_M/0/1/0/all/0/1\">Martin Lauer</a>",
          "description": "Decision making under uncertainty can be framed as a partially observable\nMarkov decision process (POMDP). Finding exact solutions of POMDPs is generally\ncomputationally intractable, but the solution can be approximated by\nsampling-based approaches. These sampling-based POMDP solvers rely on\nmulti-armed bandit (MAB) heuristics, which assume the outcomes of different\nactions to be uncorrelated. In some applications, like motion planning in\ncontinuous spaces, similar actions yield similar outcomes. In this paper, we\nutilize variants of MAB heuristics that make Lipschitz continuity assumptions\non the outcomes of actions to improve the efficiency of sampling-based planning\napproaches. We demonstrate the effectiveness of this approach in the context of\nmotion planning for automated driving.",
          "link": "http://arxiv.org/abs/2106.04206",
          "publishedOn": "2021-06-09T02:01:50.191Z",
          "wordCount": null,
          "title": "Efficient Sampling in POMDPs with Lipschitz Bandits for Motion Planning in Continuous Spaces. (arXiv:2106.04206v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nazi_Z/0/1/0/all/0/1\">Zabir Al Nazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huda_S/0/1/0/all/0/1\">Sayed Mohammed Tasmimul Huda</a>",
          "description": "Speech synthesis is one of the challenging tasks to automate by deep\nlearning, also being a low-resource language there are very few attempts at\nBangla speech synthesis. Most of the existing works can't work with anything\nother than simple Bangla characters script, very short sentences, etc. This\nwork attempts to solve these problems by introducing Byakta, the first-ever\nopen-source deep learning-based bilingual (Bangla and English) text to a speech\nsynthesis system. A speech recognition model-based automated scoring metric was\nalso proposed to evaluate the performance of a TTS model. We also introduce a\ntest benchmark dataset for Bangla speech synthesis models for evaluating speech\nquality. The TTS is available at https://github.com/zabir-nabil/bangla-tts",
          "link": "http://arxiv.org/abs/2106.03937",
          "publishedOn": "2021-06-09T02:01:50.184Z",
          "wordCount": null,
          "title": "Byakto Speech: Real-time long speech synthesis with convolutional neural network: Transfer learning from English to Bangla. (arXiv:2106.03937v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Ying Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qingjiang Shi</a>",
          "description": "Deep neural networks have been shown as a class of useful tools for\naddressing signal recognition issues in recent years, especially for\nidentifying the nonlinear feature structures of signals. However, this power of\nmost deep learning techniques heavily relies on an abundant amount of training\ndata, so the performance of classic neural nets decreases sharply when the\nnumber of training data samples is small or unseen data are presented in the\ntesting phase. This calls for an advanced strategy, i.e., model-agnostic\nmeta-learning (MAML), which is able to capture the invariant representation of\nthe data samples or signals. In this paper, inspired by the special structure\nof the signal, i.e., real and imaginary parts consisted in practical\ntime-series signals, we propose a Complex-valued Attentional MEta Learner\n(CAMEL) for the problem of few-shot signal recognition by leveraging attention\nand meta-learning in the complex domain. To the best of our knowledge, this is\nalso the first complex-valued MAML that can find the first-order stationary\npoints of general nonconvex problems with theoretical convergence guarantees.\nExtensive experiments results showcase the superiority of the proposed CAMEL\ncompared with the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04392",
          "publishedOn": "2021-06-09T02:01:50.184Z",
          "wordCount": null,
          "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition. (arXiv:2106.04392v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brams_A/0/1/0/all/0/1\">Anders H. Brams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobsen_A/0/1/0/all/0/1\">Anders L. Jakobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jendal_T/0/1/0/all/0/1\">Theis E. Jendal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lissandrini_M/0/1/0/all/0/1\">Matteo Lissandrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolog_P/0/1/0/all/0/1\">Peter Dolog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hose_K/0/1/0/all/0/1\">Katja Hose</a>",
          "description": "Knowledge Graphs (KGs) have been integrated in several models of\nrecommendation to augment the informational value of an item by means of its\nrelated entities in the graph. Yet, existing datasets only provide explicit\nratings on items and no information is provided about user opinions of other\n(non-recommendable) entities. To overcome this limitation, we introduce a new\ndataset, called the MindReader, providing explicit user ratings both for items\nand for KG entities. In this first version, the MindReader dataset provides\nmore than 102 thousands explicit ratings collected from 1,174 real users on\nboth items and entities from a KG in the movie domain. This dataset has been\ncollected through an online interview application that we also release open\nsource. As a demonstration of the importance of this new dataset, we present a\ncomparative study of the effect of the inclusion of ratings on non-item KG\nentities in a variety of state-of-the-art recommendation models. In particular,\nwe show that most models, whether designed specifically for graph data or not,\nsee improvements in recommendation quality when trained on explicit non-item\nratings. Moreover, for some models, we show that non-item ratings can\neffectively replace item ratings without loss of recommendation quality. This\nfinding, thanks also to an observed greater familiarity of users towards common\nKG entities than towards long-tail items, motivates the use of KG entities for\nboth warm and cold-start recommendations.",
          "link": "http://arxiv.org/abs/2106.04209",
          "publishedOn": "2021-06-09T02:01:50.183Z",
          "wordCount": null,
          "title": "MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings. (arXiv:2106.04209v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1\">Sai Praneeth Karimireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_S/0/1/0/all/0/1\">Satyen Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1\">Mehryar Mohri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1\">Sashank J. Reddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>",
          "description": "Federated learning (FL) is a challenging setting for optimization due to the\nheterogeneity of the data across different clients which gives rise to the\nclient drift phenomenon. In fact, obtaining an algorithm for FL which is\nuniformly better than simple centralized training has been a major open problem\nthus far. In this work, we propose a general algorithmic framework, Mime, which\ni) mitigates client drift and ii) adapts arbitrary centralized optimization\nalgorithms such as momentum and Adam to the cross-device federated learning\nsetting. Mime uses a combination of control-variates and server-level\nstatistics (e.g. momentum) at every client-update step to ensure that each\nlocal update mimics that of the centralized method run on iid data. We prove a\nreduction result showing that Mime can translate the convergence of a generic\nalgorithm in the centralized setting into convergence in the federated setting.\nFurther, we show that when combined with momentum based variance reduction,\nMime is provably faster than any centralized method--the first such result. We\nalso perform a thorough experimental exploration of Mime's performance on real\nworld datasets.",
          "link": "http://arxiv.org/abs/2008.03606",
          "publishedOn": "2021-06-09T02:01:50.183Z",
          "wordCount": null,
          "title": "Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning. (arXiv:2008.03606v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balcilar_M/0/1/0/all/0/1\">Muhammet Balcilar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heroux_P/0/1/0/all/0/1\">Pierre H&#xe9;roux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauzere_B/0/1/0/all/0/1\">Benoit Ga&#xfc;z&#xe8;re</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasseur_P/0/1/0/all/0/1\">Pascal Vasseur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adam_S/0/1/0/all/0/1\">S&#xe9;bastien Adam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honeine_P/0/1/0/all/0/1\">Paul Honeine</a>",
          "description": "Since the Message Passing (Graph) Neural Networks (MPNNs) have a linear\ncomplexity with respect to the number of nodes when applied to sparse graphs,\nthey have been widely implemented and still raise a lot of interest even though\ntheir theoretical expressive power is limited to the first order\nWeisfeiler-Lehman test (1-WL). In this paper, we show that if the graph\nconvolution supports are designed in spectral-domain by a non-linear custom\nfunction of eigenvalues and masked with an arbitrary large receptive field, the\nMPNN is theoretically more powerful than the 1-WL test and experimentally as\npowerful as a 3-WL existing models, while remaining spatially localized.\nMoreover, by designing custom filter functions, outputs can have various\nfrequency components that allow the convolution process to learn different\nrelationships between a given input graph signal and its associated properties.\nSo far, the best 3-WL equivalent graph neural networks have a computational\ncomplexity in $\\mathcal{O}(n^3)$ with memory usage in $\\mathcal{O}(n^2)$,\nconsider non-local update mechanism and do not provide the spectral richness of\noutput profile. The proposed method overcomes all these aforementioned problems\nand reaches state-of-the-art results in many downstream tasks.",
          "link": "http://arxiv.org/abs/2106.04319",
          "publishedOn": "2021-06-09T02:01:50.182Z",
          "wordCount": null,
          "title": "Breaking the Limits of Message Passing Graph Neural Networks. (arXiv:2106.04319v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barut_O/0/1/0/all/0/1\">Onur Barut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weigang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peilong Li</a>",
          "description": "Classifying network traffic is the basis for important network applications.\nPrior research in this area has faced challenges on the availability of\nrepresentative datasets, and many of the results cannot be readily reproduced.\nSuch a problem is exacerbated by emerging data-driven machine learning based\napproaches. To address this issue, we present(N et)2databasewith three open\ndatasets containing nearly 1.3M labeled flows in total, with a comprehensive\nlist of flow features, for there search community1. We focus on broad aspects\nin network traffic analysis, including both malware detection and application\nclassification. As we continue to grow them, we expect the datasets to serve as\na common ground for AI driven, reproducible research on network flow analytics.\nWe release the datasets publicly and also introduce a Multi-Task Hierarchical\nLearning (MTHL)model to perform all tasks in a single model. Our results show\nthat MTHL is capable of accurately performing multiple tasks with hierarchical\nlabeling with a dramatic reduction in training time.",
          "link": "http://arxiv.org/abs/2106.03850",
          "publishedOn": "2021-06-09T02:01:50.181Z",
          "wordCount": null,
          "title": "Multi-Task Hierarchical Learning Based Network Traffic Analytics. (arXiv:2106.03850v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1\">Nathan Inkawhich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hai Li</a>",
          "description": "Enabling out-of-distribution (OOD) detection for DNNs is critical for their\nsafe and reliable operation in the \"open world\". Unfortunately, current works\nin both methodology and evaluation focus on rather contrived detection\nproblems, and only consider a coarse level of granularity w.r.t.: 1) the\nin-distribution (ID) classes, and 2) the OOD data's \"closeness\" to the ID data.\nWe posit that such settings may be poor approximations of many real-world tasks\nthat are naturally fine-grained (e.g., bird species classification), and thus\nthe reported detection abilities may be over-estimates. Differently, in this\nwork we make granularity a top priority and focus on fine-grained OOD\ndetection. We start by carefully constructing five novel fine-grained test\nenvironments in which existing methods are shown to have difficulties. We then\npropose a new DNN training algorithm, Mixup Outlier Exposure (MixupOE), which\nleverages an outlier distribution and principles from vicinal risk\nminimization. Finally, we perform extensive experiments and analyses in our\ncustom test environments and demonstrate that MixupOE can consistently improve\nfine-grained detection performance, establishing a strong baseline in these\nmore realistic and challenging OOD detection settings.",
          "link": "http://arxiv.org/abs/2106.03917",
          "publishedOn": "2021-06-09T02:01:50.181Z",
          "wordCount": null,
          "title": "Fine-grained Out-of-Distribution Detection with Mixup Outlier Exposure. (arXiv:2106.03917v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Filstroff_L/0/1/0/all/0/1\">Louis Filstroff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sundin_I/0/1/0/all/0/1\">Iiris Sundin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikkola_P/0/1/0/all/0/1\">Petrus Mikkola</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tiulpin_A/0/1/0/all/0/1\">Aleksei Tiulpin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kylmaoja_J/0/1/0/all/0/1\">Juuso Kylm&#xe4;oja</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Active learning is usually applied to acquire labels of informative data\npoints in supervised learning, to maximize accuracy in a sample-efficient way.\nHowever, maximizing the accuracy is not the end goal when the results are used\nfor decision-making, for example in personalized medicine or economics. We\nargue that when acquiring samples sequentially, separating learning and\ndecision-making is sub-optimal, and we introduce a novel active learning\nstrategy which takes the down-the-line decision problem into account.\nSpecifically, we introduce a novel active learning criterion which maximizes\nthe expected information gain on the posterior distribution of the optimal\ndecision. We compare our decision-making-aware active learning strategy to\nexisting alternatives on both simulated and real data, and show improved\nperformance in decision-making accuracy.",
          "link": "http://arxiv.org/abs/2106.04193",
          "publishedOn": "2021-06-09T02:01:50.180Z",
          "wordCount": null,
          "title": "Targeted Active Learning for Bayesian Decision-Making. (arXiv:2106.04193v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soori_S/0/1/0/all/0/1\">Saeed Soori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Can_B/0/1/0/all/0/1\">Bugra Can</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_B/0/1/0/all/0/1\">Baourun Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehnavi_M/0/1/0/all/0/1\">Maryam Mehri Dehnavi</a>",
          "description": "This work proposes a time-efficient Natural Gradient Descent method, called\nTENGraD, with linear convergence guarantees. Computing the inverse of the\nneural network's Fisher information matrix is expensive in NGD because the\nFisher matrix is large. Approximate NGD methods such as KFAC attempt to improve\nNGD's running time and practical application by reducing the Fisher matrix\ninversion cost with approximation. However, the approximations do not reduce\nthe overall time significantly and lead to less accurate parameter updates and\nloss of curvature information. TENGraD improves the time efficiency of NGD by\ncomputing Fisher block inverses with a computationally efficient covariance\nfactorization and reuse method. It computes the inverse of each block exactly\nusing the Woodbury matrix identity to preserve curvature information while\nadmitting (linear) fast convergence rates. Our experiments on image\nclassification tasks for state-of-the-art deep neural architecture on CIFAR-10,\nCIFAR-100, and Fashion-MNIST show that TENGraD significantly outperforms\nstate-of-the-art NGD methods and often stochastic gradient descent in\nwall-clock time.",
          "link": "http://arxiv.org/abs/2106.03947",
          "publishedOn": "2021-06-09T02:01:50.177Z",
          "wordCount": null,
          "title": "TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block Inversion. (arXiv:2106.03947v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chuanlong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "Generalization to out-of-distribution (OOD) data, or domain generalization,\nis one of the central problems in modern machine learning. Recently, there is a\nsurge of attempts to propose algorithms for OOD that mainly build upon the idea\nof extracting invariant features. Although intuitively reasonable, theoretical\nunderstanding of what kind of invariance can guarantee OOD generalization is\nstill limited, and generalization to arbitrary out-of-distribution is clearly\nimpossible. In this work, we take the first step towards rigorous and\nquantitative definitions of 1) what is OOD; and 2) what does it mean by saying\nan OOD problem is learnable. We also introduce a new concept of expansion\nfunction, which characterizes to what extent the variance is amplified in the\ntest domains over the training domains, and therefore give a quantitative\nmeaning of invariant features. Based on these, we prove OOD generalization\nerror bounds. It turns out that OOD generalization largely depends on the\nexpansion function. As recently pointed out by Gulrajani and Lopez-Paz (2020),\nany OOD learning algorithm without a model selection module is incomplete. Our\ntheory naturally induces a model selection criterion. Extensive experiments on\nbenchmark OOD datasets demonstrate that our model selection criterion has a\nsignificant advantage over baselines.",
          "link": "http://arxiv.org/abs/2106.04496",
          "publishedOn": "2021-06-09T02:01:50.176Z",
          "wordCount": null,
          "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization. (arXiv:2106.04496v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1\">Tung Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1\">Anup B. Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>",
          "description": "We give relative error coresets for training linear classifiers with a broad\nclass of loss functions, including the logistic loss and hinge loss. Our\nconstruction achieves $(1\\pm \\epsilon)$ relative error with $\\tilde O(d \\cdot\n\\mu_y(X)^2/\\epsilon^2)$ points, where $\\mu_y(X)$ is a natural complexity\nmeasure of the data matrix $X \\in \\mathbb{R}^{n \\times d}$ and label vector $y\n\\in \\{-1,1\\}^n$, introduced in by Munteanu et al. 2018. Our result is based on\nsubsampling data points with probabilities proportional to their $\\ell_1$\n$Lewis$ $weights$. It significantly improves on existing theoretical bounds and\nperforms well in practice, outperforming uniform subsampling along with other\nimportance sampling methods. Our sampling distribution does not depend on the\nlabels, so can be used for active learning. It also does not depend on the\nspecific loss function, so a single coreset can be used in multiple training\nscenarios.",
          "link": "http://arxiv.org/abs/2106.04254",
          "publishedOn": "2021-06-09T02:01:50.173Z",
          "wordCount": null,
          "title": "Coresets for Classification -- Simplified and Strengthened. (arXiv:2106.04254v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>",
          "description": "Vision transformers (ViTs) process input images as sequences of patches via\nself-attention; a radically different architecture than convolutional neural\nnetworks (CNNs). This makes it interesting to study the adversarial feature\nspace of ViT models and their transferability. In particular, we observe that\nadversarial patterns found via conventional adversarial attacks show very low\nblack-box transferability even for large ViT models. However, we show that this\nphenomenon is only due to the sub-optimal attack procedures that do not\nleverage the true representation potential of ViTs. A deep ViT is composed of\nmultiple blocks, with a consistent architecture comprising of self-attention\nand feed-forward layers, where each block is capable of independently producing\na class token. Formulating an attack using only the last class token\n(conventional approach) does not directly leverage the discriminative\ninformation stored in the earlier tokens, leading to poor adversarial\ntransferability of ViTs. Using the compositional nature of ViT models, we\nenhance the transferability of existing attacks by introducing two novel\nstrategies specific to the architecture of ViT models. (i) Self-Ensemble: We\npropose a method to find multiple discriminative pathways by dissecting a\nsingle ViT model into an ensemble of networks. This allows explicitly utilizing\nclass-specific information at each ViT block. (ii) Token Refinement: We then\npropose to refine the tokens to further enhance the discriminative capacity at\neach block of ViT. Our token refinement systematically combines the class\ntokens with structural information preserved within the patch tokens. An\nadversarial attack, when applied to such refined tokens within the ensemble of\nclassifiers found in a single vision transformer, has significantly higher\ntransferability.",
          "link": "http://arxiv.org/abs/2106.04169",
          "publishedOn": "2021-06-09T02:01:50.157Z",
          "wordCount": 706,
          "title": "On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Szep_G/0/1/0/all/0/1\">Gregory Szep</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalchau_N/0/1/0/all/0/1\">Neil Dalchau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Csikasz_Nagy_A/0/1/0/all/0/1\">Attila Csikasz-Nagy</a>",
          "description": "Estimation of parameters in differential equation models can be achieved by\napplying learning algorithms to quantitative time-series data. However,\nsometimes it is only possible to measure qualitative changes of a system in\nresponse to a controlled condition. In dynamical systems theory, such change\npoints are known as \\textit{bifurcations} and lie on a function of the\ncontrolled condition called the \\textit{bifurcation diagram}. In this work, we\npropose a gradient-based semi-supervised approach for inferring the parameters\nof differential equations that produce a user-specified bifurcation diagram.\nThe cost function contains a supervised error term that is minimal when the\nmodel bifurcations match the specified targets and an unsupervised bifurcation\nmeasure which has gradients that push optimisers towards bifurcating parameter\nregimes. The gradients can be computed without the need to differentiate\nthrough the operations of the solver that was used to compute the diagram. We\ndemonstrate parameter inference with minimal models which explore the space of\nsaddle-node and pitchfork diagrams and the genetic toggle switch from synthetic\nbiology. Furthermore, the cost landscape allows us to organise models in terms\nof topological and geometric equivalence.",
          "link": "http://arxiv.org/abs/2106.04243",
          "publishedOn": "2021-06-09T02:01:50.151Z",
          "wordCount": 612,
          "title": "Parameter Inference with Bifurcation Diagrams. (arXiv:2106.04243v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nabati_O/0/1/0/all/0/1\">Ofir Nabati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1\">Tom Zahavy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "We study neural-linear bandits for solving problems where {\\em both}\nexploration and representation learning play an important role. Neural-linear\nbandits harnesses the representation power of Deep Neural Networks (DNNs) and\ncombines it with efficient exploration mechanisms by leveraging uncertainty\nestimation of the model, designed for linear contextual bandits on top of the\nlast hidden layer. In order to mitigate the problem of representation change\nduring the process, new uncertainty estimations are computed using stored data\nfrom an unlimited buffer. Nevertheless, when the amount of stored data is\nlimited, a phenomenon called catastrophic forgetting emerges. To alleviate\nthis, we propose a likelihood matching algorithm that is resilient to\ncatastrophic forgetting and is completely online. We applied our algorithm,\nLimited Memory Neural-Linear with Likelihood Matching (NeuralLinear-LiM2) on a\nvariety of datasets and observed that our algorithm achieves comparable\nperformance to the unlimited memory approach while exhibits resilience to\ncatastrophic forgetting.",
          "link": "http://arxiv.org/abs/2102.03799",
          "publishedOn": "2021-06-09T02:01:50.144Z",
          "wordCount": 612,
          "title": "Online Limited Memory Neural-Linear Bandits with Likelihood Matching. (arXiv:2102.03799v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.00527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Geoffrey X. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yubo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golikov_P/0/1/0/all/0/1\">Pavel Golikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1\">Gennady Pekhimenko</a>",
          "description": "Deep learning researchers and practitioners usually leverage GPUs to help\ntrain their deep neural networks (DNNs) faster. However, choosing which GPU to\nuse is challenging both because (i) there are many options, and (ii) users\ngrapple with competing concerns: maximizing compute performance while\nminimizing costs. In this work, we present a new practical technique to help\nusers make informed and cost-efficient GPU selections: make performance\npredictions with the help of a GPU that the user already has. Our technique\nexploits the observation that, because DNN training consists of repetitive\ncompute steps, predicting the execution time of a single iteration is usually\nenough to characterize the performance of an entire training process. We make\npredictions by scaling the execution time of each operation in a training\niteration from one GPU to another using either (i) wave scaling, a technique\nbased on a GPU's execution model, or (ii) pre-trained multilayer perceptrons.\nWe implement our technique into a Python library called Habitat and find that\nit makes accurate iteration execution time predictions (with an average error\nof 11.8%) on ResNet-50, Inception v3, the Transformer, GNMT, and DCGAN across\nsix different GPU architectures. Habitat supports PyTorch, is easy to use, and\nis open source.",
          "link": "http://arxiv.org/abs/2102.00527",
          "publishedOn": "2021-06-09T02:01:50.128Z",
          "wordCount": 683,
          "title": "A Runtime-Based Computational Performance Predictor for Deep Neural Network Training. (arXiv:2102.00527v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaopeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haohang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenrui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">Junni Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hongkai Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>",
          "description": "Collecting annotated data for semantic segmentation is time-consuming and\nhard to scale up. In this paper, we for the first time propose a unified\nframework, termed as Multi-Dataset Pretraining, to take full advantage of the\nfragmented annotations of different datasets. The highlight is that the\nannotations from different domains can be efficiently reused and consistently\nboost performance for each specific domain. This is achieved by first\npretraining the network via the proposed pixel-to-prototype contrastive loss\nover multiple datasets regardless of their taxonomy labels, and followed by\nfine-tuning the pretrained model over specific dataset as usual. In order to\nbetter model the relationship among images and classes from different datasets,\nwe extend the pixel level embeddings via cross dataset mixing and propose a\npixel-to-class sparse coding strategy that explicitly models the pixel-class\nsimilarity over the manifold embedding space. In this way, we are able to\nincrease intra-class compactness and inter-class separability, as well as\nconsidering inter-class similarity across different datasets for better\ntransferability. Experiments conducted on several benchmarks demonstrate its\nsuperior performance. Notably, MDP consistently outperforms the pretrained\nmodels over ImageNet by a considerable margin, while only using less than 10%\nsamples for pretraining.",
          "link": "http://arxiv.org/abs/2106.04121",
          "publishedOn": "2021-06-09T02:01:50.112Z",
          "wordCount": 633,
          "title": "Multi-dataset Pretraining: A Unified Model for Semantic Segmentation. (arXiv:2106.04121v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1\">Semih Cayci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1\">R. Srikant</a>",
          "description": "Natural policy gradient (NPG) methods with function approximation achieve\nimpressive empirical success in reinforcement learning problems with large\nstate-action spaces. However, theoretical understanding of their convergence\nbehaviors remains limited in the function approximation setting. In this paper,\nwe perform a finite-time analysis of NPG with linear function approximation and\nsoftmax parameterization, and prove for the first time that widely used entropy\nregularization method, which encourages exploration, leads to linear\nconvergence rate. We adopt a Lyapunov drift analysis to prove the convergence\nresults and explain the effectiveness of entropy regularization in improving\nthe convergence rates.",
          "link": "http://arxiv.org/abs/2106.04096",
          "publishedOn": "2021-06-09T02:01:50.106Z",
          "wordCount": 534,
          "title": "Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation. (arXiv:2106.04096v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mokhtari_K/0/1/0/all/0/1\">Kasra Mokhtari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1\">Alan R. Wagner</a>",
          "description": "We propose a safe DRL approach for autonomous vehicle (AV) navigation through\ncrowds of pedestrians while making a left turn at an unsignalized intersection.\nOur method uses two long-short term memory (LSTM) models that are trained to\ngenerate the perceived state of the environment and the future trajectories of\npedestrians given noisy observations of their movement. A future collision\nprediction algorithm based on the future trajectories of the ego vehicle and\npedestrians is used to mask unsafe actions if the system predicts a collision.\nThe performance of our approach is evaluated in two experiments using the\nhigh-fidelity CARLA simulation environment. The first experiment tests the\nperformance of our method at intersections that are similar to the training\nintersection and the second experiment tests our method at intersections with a\ndifferent topology. For both experiments, our methods do not result in a\ncollision with a pedestrian while still navigating the intersection at a\nreasonable speed.",
          "link": "http://arxiv.org/abs/2106.04561",
          "publishedOn": "2021-06-09T02:01:50.096Z",
          "wordCount": 597,
          "title": "Safe Deep Q-Network for Autonomous Vehicles at Unsignalized Intersection. (arXiv:2106.04561v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1\">Daniel Ben David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Resheff_Y/0/1/0/all/0/1\">Yehezkel S. Resheff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tron_T/0/1/0/all/0/1\">Talia Tron</a>",
          "description": "We study whether receiving advice from either a human or algorithmic advisor,\naccompanied by five types of Local and Global explanation labelings, has an\neffect on the readiness to adopt, willingness to pay, and trust in a financial\nAI consultant. We compare the differences over time and in various key\nsituations using a unique experimental framework where participants play a\nweb-based game with real monetary consequences. We observed that accuracy-based\nexplanations of the model in initial phases leads to higher adoption rates.\nWhen the performance of the model is immaculate, there is less importance\nassociated with the kind of explanation for adoption. Using more elaborate\nfeature-based or accuracy-based explanations helps substantially in reducing\nthe adoption drop upon model failure. Furthermore, using an autopilot increases\nadoption significantly. Participants assigned to the AI-labeled advice with\nexplanations were willing to pay more for the advice than the AI-labeled advice\nwith a No-explanation alternative. These results add to the literature on the\nimportance of XAI for algorithmic adoption and trust.",
          "link": "http://arxiv.org/abs/2101.02555",
          "publishedOn": "2021-06-09T02:01:50.090Z",
          "wordCount": 639,
          "title": "Explainable AI and Adoption of Financial Algorithmic Advisors: an Experimental Study. (arXiv:2101.02555v2 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04492",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1\">Yohei Kawaguchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Imoto_K/0/1/0/all/0/1\">Keisuke Imoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harada_N/0/1/0/all/0/1\">Noboru Harada</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niizumi_D/0/1/0/all/0/1\">Daisuke Niizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dohi_K/0/1/0/all/0/1\">Kota Dohi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tanabe_R/0/1/0/all/0/1\">Ryo Tanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Purohit_H/0/1/0/all/0/1\">Harsh Purohit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Endo_T/0/1/0/all/0/1\">Takashi Endo</a>",
          "description": "We present the task description and discussion on the results of the DCASE\n2021 Challenge Task 2. Last year, we organized unsupervised anomalous sound\ndetection (ASD) task; identifying whether the given sound is normal or\nanomalous without anomalous training data. In this year, we organize an\nadvanced unsupervised ASD task under domain-shift conditions which focuses on\nthe inevitable problem for the practical use of ASD systems. The main challenge\nof this task is to detect unknown anomalous sounds where the acoustic\ncharacteristics of the training and testing samples are different, i.e.\ndomain-shifted. This problem is frequently occurs due to changes in seasons,\nmanufactured products, and/or environmental noise. After the challenge\nsubmission deadline, we will add challenge results and analysis of the\nsubmissions.",
          "link": "http://arxiv.org/abs/2106.04492",
          "publishedOn": "2021-06-09T02:01:50.076Z",
          "wordCount": 615,
          "title": "Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions. (arXiv:2106.04492v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindenbaum_O/0/1/0/all/0/1\">Ofir Lindenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salhov_M/0/1/0/all/0/1\">Moshe Salhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Averbuch_A/0/1/0/all/0/1\">Amir Averbuch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kluger_Y/0/1/0/all/0/1\">Yuval Kluger</a>",
          "description": "Canonical Correlation Analysis (CCA) models are powerful for studying the\nassociations between two sets of variables. The canonically correlated\nrepresentations, termed \\textit{canonical variates} are widely used in\nunsupervised learning to analyze unlabeled multi-modal registered datasets.\nDespite their success, CCA models may break (or overfit) if the number of\nvariables in either of the modalities exceeds the number of samples. Moreover,\noften a significant fraction of the variables measures modality-specific\ninformation, and thus removing them is beneficial for identifying the\n\\textit{canonically correlated variates}. Here, we propose $\\ell_0$-CCA, a\nmethod for learning correlated representations based on sparse subsets of\nvariables from two observed modalities. Sparsity is obtained by multiplying the\ninput variables by stochastic gates, whose parameters are learned together with\nthe CCA weights via an $\\ell_0$-regularized correlation loss. We further\npropose $\\ell_0$-Deep CCA for solving the problem of non-linear sparse CCA by\nmodeling the correlated representations using deep nets. We demonstrate the\nefficacy of the method using several synthetic and real examples. Most notably,\nby gating nuisance input variables, our approach improves the extracted\nrepresentations compared to other linear, non-linear and sparse CCA-based\nmodels.",
          "link": "http://arxiv.org/abs/2010.05620",
          "publishedOn": "2021-06-09T02:01:50.070Z",
          "wordCount": 634,
          "title": "$\\ell_0$-based Sparse Canonical Correlation Analysis. (arXiv:2010.05620v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1\">Jeff Z. HaoChen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1\">Adrien Gaidon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Recent works in self-supervised learning have advanced the state-of-the-art\nby relying on the contrastive learning paradigm, which learns representations\nby pushing positive pairs, or similar examples from the same class, closer\ntogether while keeping negative pairs far apart. Despite the empirical\nsuccesses, theoretical foundations are limited -- prior analyses assume\nconditional independence of the positive pairs given the same class label, but\nrecent empirical applications use heavily correlated positive pairs (i.e., data\naugmentations of the same image). Our work analyzes contrastive learning\nwithout assuming conditional independence of positive pairs using a novel\nconcept of the augmentation graph on data. Edges in this graph connect\naugmentations of the same data, and ground-truth classes naturally form\nconnected sub-graphs. We propose a loss that performs spectral decomposition on\nthe population augmentation graph and can be succinctly written as a\ncontrastive learning objective on neural net representations. Minimizing this\nobjective leads to features with provable accuracy guarantees under linear\nprobe evaluation. By standard generalization bounds, these accuracy guarantees\nalso hold when minimizing the training contrastive loss. Empirically, the\nfeatures learned by our objective can match or outperform several strong\nbaselines on benchmark vision datasets. In all, this work provides the first\nprovable analysis for contrastive learning where guarantees for linear probe\nevaluation can apply to realistic empirical settings.",
          "link": "http://arxiv.org/abs/2106.04156",
          "publishedOn": "2021-06-09T02:01:50.064Z",
          "wordCount": 649,
          "title": "Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss. (arXiv:2106.04156v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2005.07519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1\">Dongqi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Ying Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiahai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shuqiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xia Yin</a>",
          "description": "Machine learning (ML), especially deep learning (DL) techniques have been\nincreasingly used in anomaly-based network intrusion detection systems (NIDS).\nHowever, ML/DL has shown to be extremely vulnerable to adversarial attacks,\nespecially in such security-sensitive systems. Many adversarial attacks have\nbeen proposed to evaluate the robustness of ML-based NIDSs. Unfortunately,\nexisting attacks mostly focused on feature-space and/or white-box attacks,\nwhich make impractical assumptions in real-world scenarios, leaving the study\non practical gray/black-box attacks largely unexplored.\n\nTo bridge this gap, we conduct the first systematic study of the\ngray/black-box traffic-space adversarial attacks to evaluate the robustness of\nML-based NIDSs. Our work outperforms previous ones in the following aspects:\n(i) practical-the proposed attack can automatically mutate original traffic\nwith extremely limited knowledge and affordable overhead while preserving its\nfunctionality; (ii) generic-the proposed attack is effective for evaluating the\nrobustness of various NIDSs using diverse ML/DL models and non-payload-based\nfeatures; (iii) explainable-we propose an explanation method for the fragile\nrobustness of ML-based NIDSs. Based on this, we also propose a defense scheme\nagainst adversarial attacks to improve system robustness. We extensively\nevaluate the robustness of various NIDSs using diverse feature sets and ML/DL\nmodels. Experimental results show our attack is effective (e.g., >97% evasion\nrate in half cases for Kitsune, a state-of-the-art NIDS) with affordable\nexecution cost and the proposed defense method can effectively mitigate such\nattacks (evasion rate is reduced by >50% in most cases).",
          "link": "http://arxiv.org/abs/2005.07519",
          "publishedOn": "2021-06-09T02:01:50.058Z",
          "wordCount": 743,
          "title": "Evaluating and Improving Adversarial Robustness of Machine Learning-Based Network Intrusion Detectors. (arXiv:2005.07519v4 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04740",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert Gurbuzbalaban</a>, <a href=\"http://arxiv.org/find/math/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut Simsekli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>",
          "description": "In recent years, various notions of capacity and complexity have been\nproposed for characterizing the generalization properties of stochastic\ngradient descent (SGD) in deep learning. Some of the popular notions that\ncorrelate well with the performance on unseen data are (i) the `flatness' of\nthe local minimum found by SGD, which is related to the eigenvalues of the\nHessian, (ii) the ratio of the stepsize $\\eta$ to the batch-size $b$, which\nessentially controls the magnitude of the stochastic gradient noise, and (iii)\nthe `tail-index', which measures the heaviness of the tails of the network\nweights at convergence. In this paper, we argue that these three seemingly\nunrelated perspectives for generalization are deeply linked to each other. We\nclaim that depending on the structure of the Hessian of the loss at the\nminimum, and the choices of the algorithm parameters $\\eta$ and $b$, the SGD\niterates will converge to a \\emph{heavy-tailed} stationary distribution. We\nrigorously prove this claim in the setting of quadratic optimization: we show\nthat even in a simple linear regression problem with independent and\nidentically distributed data whose distribution has finite moments of all\norder, the iterates can be heavy-tailed with infinite variance. We further\ncharacterize the behavior of the tails with respect to algorithm parameters,\nthe dimension, and the curvature. We then translate our results into insights\nabout the behavior of SGD in deep learning. We support our theory with\nexperiments conducted on synthetic data, fully connected, and convolutional\nneural networks.",
          "link": "http://arxiv.org/abs/2006.04740",
          "publishedOn": "2021-06-09T02:01:50.053Z",
          "wordCount": 723,
          "title": "The Heavy-Tail Phenomenon in SGD. (arXiv:2006.04740v4 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiaheng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Label smoothing (LS) is an arising learning paradigm that uses the positively\nweighted average of both the hard training labels and uniformly distributed\nsoft labels. It was shown that LS serves as a regularizer for training data\nwith hard labels and therefore improves the generalization of the model. Later\nit was reported LS even helps with improving robustness when learning with\nnoisy labels. However, we observe that the advantage of LS vanishes when we\noperate in a high label noise regime. Puzzled by the observation, we proceeded\nto discover that several proposed learning-with-noisy-labels solutions in the\nliterature instead relate more closely to negative label smoothing (NLS), which\ndefines as using a negative weight to combine the hard and soft labels! We show\nthat NLS functions substantially differently from LS in their achieved model\nconfidence. To differentiate the two cases, we will call LS the positive label\nsmoothing (PLS), and this paper unifies PLS and NLS into generalized label\nsmoothing (GLS). We provide understandings for the properties of GLS when\nlearning with noisy labels. Among other established properties, we\ntheoretically show NLS is considered more beneficial when the label noise rates\nare high. We provide experimental results to support our findings too.",
          "link": "http://arxiv.org/abs/2106.04149",
          "publishedOn": "2021-06-09T02:01:50.047Z",
          "wordCount": 630,
          "title": "Understanding (Generalized) Label Smoothing whenLearning with Noisy Labels. (arXiv:2106.04149v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Manli Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_Q/0/1/0/all/0/1\">Qianhui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_H/0/1/0/all/0/1\">Howard Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>",
          "description": "Early prediction of cerebral palsy is essential as it leads to early\ntreatment and monitoring. Deep learning has shown promising results in\nbiomedical engineering thanks to its capacity of modelling complicated data\nwith its non-linear architecture. However, due to their complex structure, deep\nlearning models are generally not interpretable by humans, making it difficult\nfor clinicians to rely on the findings. In this paper, we propose a channel\nattention module for deep learning models to predict cerebral palsy from\ninfants' body movements, which highlights the key features (i.e. body joints)\nthe model identifies as important, thereby indicating why certain diagnostic\nresults are found. To highlight the capacity of the deep network in modelling\ninput features, we utilize raw joint positions instead of hand-crafted\nfeatures. We validate our system with a real-world infant movement dataset. Our\nproposed channel attention module enables the visualization of the vital joints\nto this disease that the network considers. Our system achieves 91.67%\naccuracy, suppressing other state-of-the-art deep learning methods.",
          "link": "http://arxiv.org/abs/2106.04471",
          "publishedOn": "2021-06-09T02:01:50.029Z",
          "wordCount": 617,
          "title": "Interpreting Deep Learning based Cerebral Palsy Prediction with Channel Attention. (arXiv:2106.04471v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1\">Tobias Sutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>",
          "description": "Training models that perform well under distribution shifts is a central\nchallenge in machine learning. In this paper, we introduce a modeling framework\nwhere, in addition to training data, we have partial structural knowledge of\nthe shifted test distribution. We employ the principle of minimum\ndiscriminating information to embed the available prior knowledge, and use\ndistributionally robust optimization to account for uncertainty due to the\nlimited samples. By leveraging large deviation results, we obtain explicit\ngeneralization bounds with respect to the unknown shifted distribution. Lastly,\nwe demonstrate the versatility of our framework by demonstrating it on two\nrather distinct applications: (1) training classifiers on systematically biased\ndata and (2) off-policy evaluation in Markov Decision Processes.",
          "link": "http://arxiv.org/abs/2106.04443",
          "publishedOn": "2021-06-09T02:01:50.024Z",
          "wordCount": 554,
          "title": "Robust Generalization despite Distribution Shift via Minimum Discriminating Information. (arXiv:2106.04443v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-09T02:01:50.019Z",
          "wordCount": 569,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1\">Avi Schwarzschild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgnia_E/0/1/0/all/0/1\">Eitan Borgnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arjun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishkin_U/0/1/0/all/0/1\">Uzi Vishkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>",
          "description": "Deep neural networks are powerful machines for visual pattern recognition,\nbut reasoning tasks that are easy for humans may still be difficult for neural\nmodels. Humans possess the ability to extrapolate reasoning strategies learned\non simple problems to solve harder examples, often by thinking for longer. For\nexample, a person who has learned to solve small mazes can easily extend the\nvery same search techniques to solve much larger mazes by spending more time.\nIn computers, this behavior is often achieved through the use of algorithms,\nwhich scale to arbitrarily hard problem instances at the cost of more\ncomputation. In contrast, the sequential computing budget of feed-forward\nneural networks is limited by their depth, and networks trained on simple\nproblems have no way of extending their reasoning to accommodate harder\nproblems. In this work, we show that recurrent networks trained to solve simple\nproblems with few recurrent steps can indeed solve much more complex problems\nsimply by performing additional recurrences during inference. We demonstrate\nthis algorithmic behavior of recurrent networks on prefix sum computation,\nmazes, and chess. In all three domains, networks trained on simple problem\ninstances are able to extend their reasoning abilities at test time simply by\n\"thinking for longer.\"",
          "link": "http://arxiv.org/abs/2106.04537",
          "publishedOn": "2021-06-09T02:01:50.013Z",
          "wordCount": 647,
          "title": "Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks. (arXiv:2106.04537v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deruyttere_T/0/1/0/all/0/1\">Thierry Deruyttere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milewski_V/0/1/0/all/0/1\">Victor Milewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>",
          "description": "Current technology for autonomous cars primarily focuses on getting the\npassenger from point A to B. Nevertheless, it has been shown that passengers\nare afraid of taking a ride in self-driving cars. One way to alleviate this\nproblem is by allowing the passenger to give natural language commands to the\ncar. However, the car can misunderstand the issued command or the visual\nsurroundings which could lead to uncertain situations. It is desirable that the\nself-driving car detects these situations and interacts with the passenger to\nsolve them. This paper proposes a model that detects uncertain situations when\na command is given and finds the visual objects causing it. Optionally, a\nquestion generated by the system describing the uncertain objects is included.\nWe argue that if the car could explain the objects in a human-like way,\npassengers could gain more confidence in the car's abilities. Thus, we\ninvestigate how to (1) detect uncertain situations and their underlying causes,\nand (2) how to generate clarifying questions for the passenger. When evaluating\non the Talk2Car dataset, we show that the proposed model, \\acrfull{pipeline},\nimproves \\gls{m:ambiguous-absolute-increase} in terms of $IoU_{.5}$ compared to\nnot using \\gls{pipeline}. Furthermore, we designed a referring expression\ngenerator (REG) \\acrfull{reg_model} tailored to a self-driving car setting\nwhich yields a relative improvement of \\gls{m:meteor-relative} METEOR and\n\\gls{m:rouge-relative} ROUGE-l compared with state-of-the-art REG models, and\nis three times faster.",
          "link": "http://arxiv.org/abs/2106.04232",
          "publishedOn": "2021-06-09T02:01:50.008Z",
          "wordCount": 672,
          "title": "Giving Commands to a Self-Driving Car: How to Deal with Uncertain Situations?. (arXiv:2106.04232v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poiitis_M/0/1/0/all/0/1\">Marinos Poiitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1\">Stefanie Jegelka</a>",
          "description": "This work explores the hypothesis that the complexity of the function a deep\nneural network (NN) is learning can be deduced by how fast its weights change\nduring training. Our analysis provides evidence for this supposition by\nrelating the network's distribution of Lipschitz constants (i.e., the norm of\nthe gradient at different regions of the input space) during different training\nintervals with the behavior of the stochastic training procedure. We first\nobserve that the average Lipschitz constant close to the training data affects\nvarious aspects of the parameter trajectory, with more complex networks having\na longer trajectory, bigger variance, and often veering further from their\ninitialization. We then show that NNs whose biases are trained more steadily\nhave bounded complexity even in regions of the input space that are far from\nany training point. Finally, we find that steady training with Dropout implies\na training- and data-dependent generalization bound that grows\npoly-logarithmically with the number of parameters. Overall, our results\nsupport the hypothesis that good training behavior can be a useful bias towards\ngood generalization.",
          "link": "http://arxiv.org/abs/2106.04186",
          "publishedOn": "2021-06-09T02:01:49.992Z",
          "wordCount": 605,
          "title": "What training reveals about neural network complexity. (arXiv:2106.04186v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_A/0/1/0/all/0/1\">Alireza Ranjbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1\">Joschka Boedecker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "While classic control theory offers state of the art solutions in many\nproblem scenarios, it is often desired to improve beyond the structure of such\nsolutions and surpass their limitations. To this end, \\emph{\\gls{rpl}} offers a\nformulation to improve existing controllers with reinforcement learning (RL) by\nlearning an additive \"residual\" to the output of a given controller. However,\nthe applicability of such an approach highly depends on the structure of the\ncontroller. Often, internal feedback signals of the controller limit an RL\nalgorithm to adequately change the policy and, hence, learn the task. We\npropose a new formulation that addresses these limitations by also modifying\nthe feedback signals to the controller with an RL policy and show superior\nperformance of our approach on a contact-rich peg-insertion task under position\nand orientation uncertainty. In addition, we use a recent impedance control\narchitecture as control framework and show the difficulties of standard RPL.\nFurthermore, we introduce an adaptive curriculum for the given task to\ngradually increase the task difficulty in terms of position and orientation\nuncertainty. A video showing the results can be found at\nhttps://youtu.be/SAZm_Krze7U .",
          "link": "http://arxiv.org/abs/2106.04306",
          "publishedOn": "2021-06-09T02:01:49.981Z",
          "wordCount": null,
          "title": "Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty. (arXiv:2106.04306v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1\">Da Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "Attention mechanisms have become a standard tool for sequence modeling tasks,\nin particular by stacking self-attention layers over the entire input sequence\nas in the Transformer architecture. In this work we introduce a novel attention\nprocedure called staircase attention that, unlike self-attention, operates\nacross the sequence (in time) recurrently processing the input by adding\nanother step of processing. A step in the staircase comprises of backward\ntokens (encoding the sequence so far seen) and forward tokens (ingesting a new\npart of the sequence), or an extreme Ladder version with a forward step of zero\nthat simply repeats the Transformer on each step of the ladder, sharing the\nweights. We thus describe a family of such models that can trade off\nperformance and compute, by either increasing the amount of recurrence through\ntime, the amount of sequential processing via recurrence in depth, or both.\nStaircase attention is shown to be able to solve tasks that involve tracking\nthat conventional Transformers cannot, due to this recurrence. Further, it is\nshown to provide improved modeling power for the same size model (number of\nparameters) compared to self-attentive Transformers on large language modeling\nand dialogue tasks, yielding significant perplexity gains.",
          "link": "http://arxiv.org/abs/2106.04279",
          "publishedOn": "2021-06-09T02:01:49.973Z",
          "wordCount": 623,
          "title": "Staircase Attention for Recurrent Processing of Sequences. (arXiv:2106.04279v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khandan_N/0/1/0/all/0/1\">Nouna Khandan</a>",
          "description": "Digitization, i.e., the process of converting information into a digital\nformat, may provide various opportunities (e.g., increase in productivity,\ndisaster recovery, and environmentally friendly solutions) and challenges for\nbusinesses. In this context, one of the main challenges would be to accurately\nclassify numerous scanned documents uploaded every day by customers as usual\nbusiness processes. For example, processes in banking (e.g., applying for\nloans) or the Government Registry of BDM (Births, Deaths, and Marriages)\napplications may involve uploading several documents such as a driver's license\nand passport. There are not many studies available to address the challenge as\nan application of image classification. Although some studies are available\nwhich used various methods, a more accurate model is still required. The\ncurrent study has proposed a robust fusion model to define the type of identity\ndocuments accurately. The proposed approach is based on two different methods\nin which images are classified based on their visual features and text\nfeatures. A novel model based on statistics and regression has been proposed to\ncalculate the confidence level for the feature-based classifier. A fuzzy-mean\nfusion model has been proposed to combine the classifier results based on their\nconfidence score. The proposed approach has been implemented using Python and\nexperimentally validated on synthetic and real-world datasets. The performance\nof the proposed model is evaluated using the Receiver Operating Characteristic\n(ROC) curve analysis.",
          "link": "http://arxiv.org/abs/2106.04345",
          "publishedOn": "2021-06-09T02:01:49.968Z",
          "wordCount": 661,
          "title": "An Intelligent Hybrid Model for Identity Document Classification. (arXiv:2106.04345v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thoma_N/0/1/0/all/0/1\">Nils Thoma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhongjie Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1\">Fabrizio Ventola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Time series forecasting is a relevant task that is performed in several\nreal-world scenarios such as product sales analysis and prediction of energy\ndemand. Given their accuracy performance, currently, Recurrent Neural Networks\n(RNNs) are the models of choice for this task. Despite their success in time\nseries forecasting, less attention has been paid to make the RNNs trustworthy.\nFor example, RNNs can not naturally provide an uncertainty measure to their\npredictions. This could be extremely useful in practice in several cases e.g.\nto detect when a prediction might be completely wrong due to an unusual pattern\nin the time series. Whittle Sum-Product Networks (WSPNs), prominent deep\ntractable probabilistic circuits (PCs) for time series, can assist an RNN with\nproviding meaningful probabilities as uncertainty measure. With this aim, we\npropose RECOWN, a novel architecture that employs RNNs and a discriminant\nvariant of WSPNs called Conditional WSPNs (CWSPNs). We also formulate a\nLog-Likelihood Ratio Score as better estimation of uncertainty that is tailored\nto time series and Whittle likelihoods. In our experiments, we show that\nRECOWNs are accurate and trustworthy time series predictors, able to \"know when\nthey do not know\".",
          "link": "http://arxiv.org/abs/2106.04148",
          "publishedOn": "2021-06-09T02:01:49.962Z",
          "wordCount": 617,
          "title": "RECOWNs: Probabilistic Circuits for Trustworthy Time Series Forecasting. (arXiv:2106.04148v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2005.12979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shijun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1\">Peng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "Static recommendation methods like collaborative filtering suffer from the\ninherent limitation of performing real-time personalization for cold-start\nusers. Online recommendation, e.g., multi-armed bandit approach, addresses this\nlimitation by interactively exploring user preference online and pursuing the\nexploration-exploitation (EE) trade-off. However, existing bandit-based methods\nmodel recommendation actions homogeneously. Specifically, they only consider\nthe items as the arms, being incapable of handling the item attributes, which\nnaturally provide interpretable information of user's current demands and can\neffectively filter out undesired items. In this work, we consider the\nconversational recommendation for cold-start users, where a system can both ask\nthe attributes from and recommend items to a user interactively. This important\nscenario was studied in a recent work. However, it employs a hand-crafted\nfunction to decide when to ask attributes or make recommendations. Such\nseparate modeling of attributes and items makes the effectiveness of the system\nhighly rely on the choice of the hand-crafted function, thus introducing\nfragility to the system. To address this limitation, we seamlessly unify\nattributes and items in the same arm space and achieve their EE trade-offs\nautomatically using the framework of Thompson Sampling. Our Conversational\nThompson Sampling (ConTS) model holistically solves all questions in\nconversational recommendation by choosing the arm with the maximal reward to\nplay. Extensive experiments on three benchmark datasets show that ConTS\noutperforms the state-of-the-art methods Conversational UCB (ConUCB) and\nEstimation-Action-Reflection model in both metrics of success rate and average\nnumber of conversation turns.",
          "link": "http://arxiv.org/abs/2005.12979",
          "publishedOn": "2021-06-09T02:01:49.921Z",
          "wordCount": 740,
          "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-Start Users. (arXiv:2005.12979v4 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galvez_R/0/1/0/all/0/1\">Rafa G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moonsamy_V/0/1/0/all/0/1\">Veelasha Moonsamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_C/0/1/0/all/0/1\">Claudia Diaz</a>",
          "description": "In this paper we present LiM (\"Less is More\"), a malware classification\nframework that leverages Federated Learning to detect and classify malicious\napps in a privacy-respecting manner. Information about newly installed apps is\nkept locally on users' devices, so that the provider cannot infer which apps\nwere installed by users. At the same time, input from all users is taken into\naccount in the federated learning process and they all benefit from better\nclassification performance. A key challenge of this setting is that users do\nnot have access to the ground truth (i.e. they cannot correctly identify\nwhether an app is malicious). To tackle this, LiM uses a safe semi-supervised\nensemble that maximizes classification accuracy with respect to a baseline\nclassifier trained by the service provider (i.e. the cloud). We implement LiM\nand show that the cloud server has F1 score of 95%, while clients have perfect\nrecall with only 1 false positive in >100 apps, using a dataset of 25K clean\napps and 25K malicious apps, 200 users and 50 rounds of federation.\nFurthermore, we conduct a security analysis and demonstrate that LiM is robust\nagainst both poisoning attacks by adversaries who control half of the clients,\nand inference attacks performed by an honest-but-curious cloud server. Further\nexperiments with MaMaDroid's dataset confirm resistance against poisoning\nattacks and a performance improvement due to the federation.",
          "link": "http://arxiv.org/abs/2007.08319",
          "publishedOn": "2021-06-09T02:01:49.913Z",
          "wordCount": 690,
          "title": "Less is More: A privacy-respecting Android malware classifier using Federated Learning. (arXiv:2007.08319v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.11741",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jorgensen_M/0/1/0/all/0/1\">Martin J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "We present a probabilistic model where the latent variable respects both the\ndistances and the topology of the modeled data. The model leverages the\nRiemannian geometry of the generated manifold to endow the latent space with a\nwell-defined stochastic distance measure, which is modeled locally as Nakagami\ndistributions. These stochastic distances are sought to be as similar as\npossible to observed distances along a neighborhood graph through a censoring\nprocess. The model is inferred by variational inference based on observations\nof pairwise distances. We demonstrate how the new model can encode invariances\nin the learned manifolds.",
          "link": "http://arxiv.org/abs/2006.11741",
          "publishedOn": "2021-06-09T02:01:49.907Z",
          "wordCount": 542,
          "title": "Isometric Gaussian Process Latent Variable Model for Dissimilarity Data. (arXiv:2006.11741v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Massaroli_S/0/1/0/all/0/1\">Stefano Massaroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1\">Michael Poli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1\">Taji Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jinkyoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_A/0/1/0/all/0/1\">Atsushi Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asama_H/0/1/0/all/0/1\">Hajime Asama</a>",
          "description": "We detail a novel class of implicit neural models. Leveraging time-parallel\nmethods for differential equations, Multiple Shooting Layers (MSLs) seek\nsolutions of initial value problems via parallelizable root-finding algorithms.\nMSLs broadly serve as drop-in replacements for neural ordinary differential\nequations (Neural ODEs) with improved efficiency in number of function\nevaluations (NFEs) and wall-clock inference time. We develop the algorithmic\nframework of MSLs, analyzing the different choices of solution methods from a\ntheoretical and computational perspective. MSLs are showcased in long horizon\noptimal control of ODEs and PDEs and as latent models for sequence generation.\nFinally, we investigate the speedups obtained through application of MSL\ninference in neural controlled differential equations (Neural CDEs) for time\nseries classification of medical data.",
          "link": "http://arxiv.org/abs/2106.03885",
          "publishedOn": "2021-06-09T02:01:49.902Z",
          "wordCount": 556,
          "title": "Differentiable Multiple Shooting Layers. (arXiv:2106.03885v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.07601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>",
          "description": "Mental health is a critical issue in modern society, and mental disorders\ncould sometimes turn to suicidal ideation without effective treatment. Early\ndetection of mental disorders and suicidal ideation from social content\nprovides a potential way for effective social intervention. However,\nclassifying suicidal ideation and other mental disorders is challenging as they\nshare similar patterns in language usage and sentimental polarity. This paper\nenhances text representation with lexicon-based sentiment scores and latent\ntopics and proposes using relation networks to detect suicidal ideation and\nmental disorders with related risk indicators. The relation module is further\nequipped with the attention mechanism to prioritize more critical relational\nfeatures. Through experiments on three real-world datasets, our model\noutperforms most of its counterparts.",
          "link": "http://arxiv.org/abs/2004.07601",
          "publishedOn": "2021-06-09T02:01:49.887Z",
          "wordCount": 595,
          "title": "Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks. (arXiv:2004.07601v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitfield_C/0/1/0/all/0/1\">Christopher Whitfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_M/0/1/0/all/0/1\">Mohad Anwar</a>",
          "description": "Coronavirus disease (COVID-19) pandemic has changed various aspects of\npeople's lives and behaviors. At this stage, there are no other ways to control\nthe natural progression of the disease than adopting mitigation strategies such\nas wearing masks, watching distance, and washing hands. Moreover, at this time\nof social distancing, social media plays a key role in connecting people and\nproviding a platform for expressing their feelings. In this study, we tap into\nsocial media to surveil the uptake of mitigation and detection strategies, and\ncapture issues and concerns about the pandemic. In particular, we explore the\nresearch question, \"how much can be learned regarding the public uptake of\nmitigation strategies and concerns about COVID-19 pandemic by using natural\nlanguage processing on Reddit posts?\" After extracting COVID-related posts from\nthe four largest subreddit communities of North Carolina over six months, we\nperformed NLP-based preprocessing to clean the noisy data. We employed a custom\nNamed-entity Recognition (NER) system and a Latent Dirichlet Allocation (LDA)\nmethod for topic modeling on a Reddit corpus. We observed that 'mask', 'flu',\nand 'testing' are the most prevalent named-entities for \"Personal Protective\nEquipment\", \"symptoms\", and \"testing\" categories, respectively. We also\nobserved that the most discussed topics are related to testing, masks, and\nemployment. The mitigation measures are the most prevalent theme of discussion\nacross all subreddits.",
          "link": "http://arxiv.org/abs/2106.04515",
          "publishedOn": "2021-06-09T02:01:49.882Z",
          "wordCount": 720,
          "title": "Surveillance of COVID-19 Pandemic using Social Media: A Reddit Study in North Carolina. (arXiv:2106.04515v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1\">Ayoosh Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jayati Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verucchi_M/0/1/0/all/0/1\">Micaela Verucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caccamo_M/0/1/0/all/0/1\">Marco Caccamo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1\">Lui Sha</a>",
          "description": "Commonly used metrics for evaluation of object detection systems (precision,\nrecall, mAP) do not give complete information about their suitability of use in\nsafety critical tasks, like obstacle detection for collision avoidance in\nAutonomous Vehicles (AV). This work introduces the Risk Ranked Recall ($R^3$)\nmetrics for object detection systems. The $R^3$ metrics categorize objects\nwithin three ranks. Ranks are assigned based on an objective cyber-physical\nmodel for the risk of collision. Recall is measured for each rank.",
          "link": "http://arxiv.org/abs/2106.04146",
          "publishedOn": "2021-06-09T02:01:49.876Z",
          "wordCount": 529,
          "title": "Risk Ranked Recall: Collision Safety Metric for Object Detection Systems in Autonomous Vehicles. (arXiv:2106.04146v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1\">Hadi Beik-Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1\">Georgios Arvanitidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1\">Leonel Rozo</a>",
          "description": "For robots to work alongside humans and perform in unstructured environments,\nthey must learn new motion skills and adapt them to unseen situations on the\nfly. This demands learning models that capture relevant motion patterns, while\noffering enough flexibility to adapt the encoded skills to new requirements,\nsuch as dynamic obstacle avoidance. We introduce a Riemannian manifold\nperspective on this problem, and propose to learn a Riemannian manifold from\nhuman demonstrations on which geodesics are natural motion skills. We realize\nthis with a variational autoencoder (VAE) over the space of position and\norientations of the robot end-effector. Geodesic motion skills let a robot plan\nmovements from and to arbitrary points on the data manifold. They also provide\na straightforward method to avoid obstacles by redefining the ambient metric in\nan online fashion. Moreover, geodesics naturally exploit the manifold resulting\nfrom multiple--mode tasks to design motions that were not explicitly\ndemonstrated previously. We test our learning framework using a 7-DoF robotic\nmanipulator, where the robot satisfactorily learns and reproduces realistic\nskills featuring elaborated motion patterns, avoids previously unseen\nobstacles, and generates novel movements in multiple-mode settings.",
          "link": "http://arxiv.org/abs/2106.04315",
          "publishedOn": "2021-06-09T02:01:49.870Z",
          "wordCount": 615,
          "title": "Learning Riemannian Manifolds for Geodesic Motion Skills. (arXiv:2106.04315v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lounici_K/0/1/0/all/0/1\">Karim Lounici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meziani_K/0/1/0/all/0/1\">Katia Meziani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riu_B/0/1/0/all/0/1\">Benjamin Riu</a>",
          "description": "Deep Learning (DL) is considered the state-of-the-art in computer vision,\nspeech recognition and natural language processing. Until recently, it was also\nwidely accepted that DL is irrelevant for learning tasks on tabular data,\nespecially in the small sample regime where ensemble methods are acknowledged\nas the gold standard. We present a new end-to-end differentiable method to\ntrain a standard FFNN. Our method, \\textbf{Muddling labels for Regularization}\n(\\texttt{MLR}), penalizes memorization through the generation of uninformative\nlabels and the application of a differentiable close-form regularization scheme\non the last hidden layer during training. \\texttt{MLR} outperforms classical NN\nand the gold standard (GBDT, RF) for regression and classification tasks on\nseveral datasets from the UCI database and Kaggle covering a large range of\nsample sizes and feature to sample ratios. Researchers and practitioners can\nuse \\texttt{MLR} on its own as an off-the-shelf \\DL{} solution or integrate it\ninto the most advanced ML pipelines.",
          "link": "http://arxiv.org/abs/2106.04462",
          "publishedOn": "2021-06-09T02:01:49.857Z",
          "wordCount": 585,
          "title": "Muddling Label Regularization: Deep Learning for Tabular Datasets. (arXiv:2106.04462v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-06-09T02:01:49.842Z",
          "wordCount": 570,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04540",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lei_J/0/1/0/all/0/1\">Jordan Lei</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Benjamin_A/0/1/0/all/0/1\">Ari S. Benjamin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kording_K/0/1/0/all/0/1\">Konrad P. Kording</a>",
          "description": "Object-based attention is a key component of the visual system, relevant for\nperception, learning, and memory. Neurons tuned to features of attended objects\ntend to be more active than those associated with non-attended objects. There\nis a rich set of models of this phenomenon in computational neuroscience.\nHowever, there is currently a divide between models that successfully match\nphysiological data but can only deal with extremely simple problems and models\nof attention used in computer vision. For example, attention in the brain is\nknown to depend on top-down processing, whereas self-attention in deep learning\ndoes not. Here, we propose an artificial neural network model of object-based\nattention that captures the way in which attention is both top-down and\nrecurrent. Our attention model works well both on simple test stimuli, such as\nthose using images of handwritten digits, and on more complex stimuli, such as\nnatural images drawn from the COCO dataset. We find that our model replicates a\nrange of findings from neuroscience, including attention-invariant tuning,\ninhibition of return, and attention-mediated scaling of activity. Understanding\nobject based attention is both computationally interesting and a key problem\nfor computational neuroscience.",
          "link": "http://arxiv.org/abs/2106.04540",
          "publishedOn": "2021-06-09T02:01:49.837Z",
          "wordCount": 632,
          "title": "Object Based Attention Through Internal Gating. (arXiv:2106.04540v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaocheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaodong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yintai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>",
          "description": "Recent works on ride-sharing order dispatching have highlighted the\nimportance of taking into account both the spatial and temporal dynamics in the\ndispatching process for improving the transportation system efficiency. At the\nsame time, deep reinforcement learning has advanced to the point where it\nachieves superhuman performance in a number of fields. In this work, we propose\na deep reinforcement learning based solution for order dispatching and we\nconduct large scale online A/B tests on DiDi's ride-dispatching platform to\nshow that the proposed method achieves significant improvement on both total\ndriver income and user experience related metrics. In particular, we model the\nride dispatching problem as a Semi Markov Decision Process to account for the\ntemporal aspect of the dispatching actions. To improve the stability of the\nvalue iteration with nonlinear function approximators like neural networks, we\npropose Cerebellar Value Networks (CVNet) with a novel distributed state\nrepresentation layer. We further derive a regularized policy evaluation scheme\nfor CVNet that penalizes large Lipschitz constant of the value network for\nadditional robustness against adversarial perturbation and noises. Finally, we\nadapt various transfer learning methods to CVNet for increased learning\nadaptability and efficiency across multiple cities. We conduct extensive\noffline simulations based on real dispatching data as well as online AB tests\nthrough the DiDi's platform. Results show that CVNet consistently outperforms\nother recently proposed dispatching methods. We finally show that the\nperformance can be further improved through the efficient use of transfer\nlearning.",
          "link": "http://arxiv.org/abs/2106.04493",
          "publishedOn": "2021-06-09T02:01:49.825Z",
          "wordCount": 683,
          "title": "A Deep Value-network Based Approach for Multi-Driver Order Dispatching. (arXiv:2106.04493v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1\">Cameron Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_N/0/1/0/all/0/1\">Neev Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottesman_O/0/1/0/all/0/1\">Omer Gottesman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konidaris_G/0/1/0/all/0/1\">George Konidaris</a>",
          "description": "The fundamental assumption of reinforcement learning in Markov decision\nprocesses (MDPs) is that the relevant decision process is, in fact, Markov.\nHowever, when MDPs have rich observations, agents typically learn by way of an\nabstract state representation, and such representations are not guaranteed to\npreserve the Markov property. We introduce a novel set of conditions and prove\nthat they are sufficient for learning a Markov abstract state representation.\nWe then describe a practical training procedure that combines inverse model\nestimation and temporal contrastive learning to learn an abstraction that\napproximately satisfies these conditions. Our novel training objective is\ncompatible with both online and offline training: it does not require a reward\nsignal, but agents can capitalize on reward information when available. We\nempirically evaluate our approach on a visual gridworld domain and a set of\ncontinuous control benchmarks. Our approach learns representations that capture\nthe underlying structure of the domain and lead to improved sample efficiency\nover state-of-the-art deep reinforcement learning with visual features -- often\nmatching or exceeding the performance achieved with hand-designed compact state\ninformation.",
          "link": "http://arxiv.org/abs/2106.04379",
          "publishedOn": "2021-06-09T02:01:49.808Z",
          "wordCount": 617,
          "title": "Learning Markov State Abstractions for Deep Reinforcement Learning. (arXiv:2106.04379v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1\">Philip Sellars</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1\">Angelica I. Aviles-Rivero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "Semi-supervised learning has received a lot of recent attention as it\nalleviates the need for large amounts of labelled data which can often be\nexpensive, requires expert knowledge and be time consuming to collect. Recent\ndevelopments in deep semi-supervised classification have reached unprecedented\nperformance and the gap between supervised and semi-supervised learning is\never-decreasing. This improvement in performance has been based on the\ninclusion of numerous technical tricks, strong augmentation techniques and\ncostly optimisation schemes with multi-term loss functions. We propose a new\nframework, LaplaceNet, for deep semi-supervised classification that has a\ngreatly reduced model complexity. We utilise a hybrid energy-neural network\nwhere graph based pseudo-labels, generated by minimising the graphical\nLaplacian, are used to iteratively improve a neural-network backbone. Our model\noutperforms state-of-the-art methods for deep semi-supervised classification,\nover several benchmark datasets. Furthermore, we consider the application of\nstrong-augmentations to neural networks theoretically and justify the use of a\nmulti-sampling approach for semi-supervised learning. We demonstrate, through\nrigorous experimentation, that a multi-sampling augmentation approach improves\ngeneralisation and reduces the sensitivity of the network to augmentation.",
          "link": "http://arxiv.org/abs/2106.04527",
          "publishedOn": "2021-06-09T02:01:49.796Z",
          "wordCount": 600,
          "title": "LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised Classification. (arXiv:2106.04527v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04416",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Leonelli_M/0/1/0/all/0/1\">Manuele Leonelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Varando_G/0/1/0/all/0/1\">Gherardo Varando</a>",
          "description": "Causal discovery algorithms aims at untangling complex causal relationships\nusing observational data only. Here, we introduce new causal discovery\nalgorithms based on staged tree models, which can represent complex and\nnon-symmetric causal effects. To demonstrate the efficacy of our algorithms, we\nintroduce a new distance, inspired by the widely used structural interventional\ndistance, to quantify the closeness between two staged trees in terms of their\ncorresponding causal inference statements. A simulation study highlights the\nefficacy of staged trees in uncovering complex, asymmetric causal relationship\nfrom data and a real-world data application illustrates their use in a\npractical causal analysis.",
          "link": "http://arxiv.org/abs/2106.04416",
          "publishedOn": "2021-06-09T02:01:49.790Z",
          "wordCount": 522,
          "title": "Context-Specific Causal Discovery for Categorical Data Using Staged Trees. (arXiv:2106.04416v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Van_H/0/1/0/all/0/1\">Hoang Van</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vikas Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>",
          "description": "We propose a simple and effective strategy for data augmentation for\nlow-resource machine reading comprehension (MRC). Our approach first pretrains\nthe answer extraction components of a MRC system on the augmented data that\ncontains approximate context of the correct answers, before training it on the\nexact answer spans. The approximate context helps the QA method components in\nnarrowing the location of the answers. We demonstrate that our simple strategy\nsubstantially improves both document retrieval and answer extraction\nperformance by providing larger context of the answers and additional training\ndata. In particular, our method significantly improves the performance of BERT\nbased retriever (15.12\\%), and answer extractor (4.33\\% F1) on TechQA, a\ncomplex, low-resource MRC task. Further, our data augmentation strategy yields\nsignificant improvements of up to 3.9\\% exact match (EM) and 2.7\\% F1 for\nanswer extraction on PolicyQA, another practical but moderate sized QA dataset\nthat also contains long answer spans.",
          "link": "http://arxiv.org/abs/2106.04134",
          "publishedOn": "2021-06-09T02:01:49.777Z",
          "wordCount": 603,
          "title": "Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading. (arXiv:2106.04134v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Jimin Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jake Zhao</a> (Junbo)",
          "description": "The randomized or cross-validated split of training and testing sets has been\nadopted as the gold standard of machine learning for decades. The establishment\nof these split protocols are based on two assumptions: (i)-fixing the dataset\nto be eternally static so we could evaluate different machine learning\nalgorithms or models; (ii)-there is a complete set of annotated data available\nto researchers or industrial practitioners. However, in this article, we intend\nto take a closer and critical look at the split protocol itself and point out\nits weakness and limitation, especially for industrial applications. In many\nreal-world problems, we must acknowledge that there are numerous situations\nwhere assumption (ii) does not hold. For instance, for interdisciplinary\napplications like drug discovery, it often requires real lab experiments to\nannotate data which poses huge costs in both time and financial considerations.\nIn other words, it can be very difficult or even impossible to satisfy\nassumption (ii). In this article, we intend to access this problem and\nreiterate the paradigm of active learning, and investigate its potential on\nsolving problems under unconventional train/test split protocols. We further\npropose a new adaptive active learning architecture (AAL) which involves an\nadaptation policy, in comparison with the traditional active learning that only\nunidirectionally adds data points to the training pool. We primarily justify\nour points by extensively investigating an interdisciplinary drug-protein\nbinding problem. We additionally evaluate AAL on more conventional machine\nlearning benchmarking datasets like CIFAR-10 to demonstrate the\ngeneralizability and efficacy of the new framework.",
          "link": "http://arxiv.org/abs/2106.04525",
          "publishedOn": "2021-06-09T02:01:49.771Z",
          "wordCount": 686,
          "title": "A critical look at the current train/test split in machine learning. (arXiv:2106.04525v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1\">Siddharth Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_M/0/1/0/all/0/1\">Mohit Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>",
          "description": "Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges and subgraphs in an online manner, for the purpose of detecting\nunusual behavior, using constant time and memory? For example, in intrusion\ndetection, existing work seeks to detect either anomalous edges or anomalous\nsubgraphs, but not both. In this paper, we first extend the count-min sketch\ndata structure to a higher-order sketch. This higher-order sketch has the\nuseful property of preserving the dense subgraph structure (dense subgraphs in\nthe input turn into dense submatrices in the data structure). We then propose\nfour online algorithms that utilize this enhanced data structure, which (a)\ndetect both edge and graph anomalies; (b) process each edge and graph in\nconstant memory and constant update time per newly arriving edge, and; (c)\noutperform state-of-the-art baselines on four real-world datasets. Our method\nis the first streaming approach that incorporates dense subgraph search to\ndetect graph anomalies in constant memory and time.",
          "link": "http://arxiv.org/abs/2106.04486",
          "publishedOn": "2021-06-09T02:01:49.765Z",
          "wordCount": 597,
          "title": "Sketch-Based Streaming Anomaly Detection in Dynamic Graphs. (arXiv:2106.04486v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raviv_N/0/1/0/all/0/1\">Netanel Raviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelley_A/0/1/0/all/0/1\">Aidan Kelley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Michael Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1\">Yevgeny Vorobeychik</a>",
          "description": "Despite the considerable success of neural networks in security settings such\nas malware detection, such models have proved vulnerable to evasion attacks, in\nwhich attackers make slight changes to inputs (e.g., malware) to bypass\ndetection. We propose a novel approach, \\emph{Fourier stabilization}, for\ndesigning evasion-robust neural networks with binary inputs. This approach,\nwhich is complementary to other forms of defense, replaces the weights of\nindividual neurons with robust analogs derived using Fourier analytic tools.\nThe choice of which neurons to stabilize in a neural network is then a\ncombinatorial optimization problem, and we propose several methods for\napproximately solving it. We provide a formal bound on the per-neuron drop in\naccuracy due to Fourier stabilization, and experimentally demonstrate the\neffectiveness of the proposed approach in boosting robustness of neural\nnetworks in several detection settings. Moreover, we show that our approach\neffectively composes with adversarial training.",
          "link": "http://arxiv.org/abs/2106.04435",
          "publishedOn": "2021-06-09T02:01:49.728Z",
          "wordCount": 582,
          "title": "Enhancing Robustness of Neural Networks through Fourier Stabilization. (arXiv:2106.04435v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04197",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xie_P/0/1/0/all/0/1\">Pengfei Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yin_Y/0/1/0/all/0/1\">YanShu Yin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hou_J/0/1/0/all/0/1\">JiaGen Hou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1\">Mei Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Lixin Wang</a>",
          "description": "Seismic inverse modeling is a common method in reservoir prediction and it\nplays a vital role in the exploration and development of oil and gas.\nConventional seismic inversion method is difficult to combine with complicated\nand abstract knowledge on geological mode and its uncertainty is difficult to\nbe assessed. The paper proposes an inversion modeling method based on GAN\nconsistent with geology, well logs, seismic data. GAN is a the most promising\ngeneration model algorithm that extracts spatial structure and abstract\nfeatures of training images. The trained GAN can reproduce the models with\nspecific mode. In our test, 1000 models were generated in 1 second. Based on\nthe trained GAN after assessment, the optimal result of models can be\ncalculated through Bayesian inversion frame. Results show that inversion models\nconform to observation data and have a low uncertainty under the premise of\nfast generation. This seismic inverse modeling method increases the efficiency\nand quality of inversion iteration. It is worthy of studying and applying in\nfusion of seismic data and geological knowledge.",
          "link": "http://arxiv.org/abs/2106.04197",
          "publishedOn": "2021-06-09T02:01:49.714Z",
          "wordCount": 616,
          "title": "Seismic Inverse Modeling Method based on Generative Adversarial Network. (arXiv:2106.04197v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04362",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Morehead_A/0/1/0/all/0/1\">Alex Morehead</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sedova_A/0/1/0/all/0/1\">Ada Sedova</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cheng_J/0/1/0/all/0/1\">Jianlin Cheng</a>",
          "description": "How and where proteins interface with one another can ultimately impact the\nproteins' functions along with a range of other biological processes. As such,\nprecise computational methods for protein interface prediction (PIP) come\nhighly sought after as they could yield significant advances in drug discovery\nand design as well as protein function analysis. However, the traditional\nbenchmark dataset for this task, Docking Benchmark 5 (DB5), contains only a\npaltry 230 complexes for training, validating, and testing different machine\nlearning algorithms. In this work, we expand on a dataset recently introduced\nfor this task, the Database of Interacting Protein Structures (DIPS), to\npresent DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for\ngeometric deep learning of protein interfaces. The previous version of DIPS\ncontains only the Cartesian coordinates and types of the atoms comprising a\ngiven protein complex, whereas DIPS-Plus now includes a plethora of new\nresidue-level features including protrusion indices, half-sphere amino acid\ncompositions, and new profile hidden Markov model (HMM)-based sequence features\nfor each amino acid, giving researchers a large, well-curated feature bank for\ntraining protein interface prediction methods.",
          "link": "http://arxiv.org/abs/2106.04362",
          "publishedOn": "2021-06-09T02:01:49.700Z",
          "wordCount": 631,
          "title": "DIPS-Plus: The Enhanced Database of Interacting Protein Structures for Interface Prediction. (arXiv:2106.04362v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhekai Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hongzu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Ke Lu</a>",
          "description": "Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned\nfrom a well-labeled source domain to an unlabeled target domain. Recently,\nadversarial domain adaptation with two distinct classifiers (bi-classifier) has\nbeen introduced into UDA which is effective to align distributions between\ndifferent domains. Previous bi-classifier adversarial learning methods only\nfocus on the similarity between the outputs of two distinct classifiers.\nHowever, the similarity of the outputs cannot guarantee the accuracy of target\nsamples, i.e., target samples may match to wrong categories even if the\ndiscrepancy between two classifiers is small. To challenge this issue, in this\npaper, we propose a cross-domain gradient discrepancy minimization (CGDM)\nmethod which explicitly minimizes the discrepancy of gradients generated by\nsource samples and target samples. Specifically, the gradient gives a cue for\nthe semantic information of target samples so it can be used as a good\nsupervision to improve the accuracy of target samples. In order to compute the\ngradient signal of target samples, we further obtain target pseudo labels\nthrough a clustering-based self-supervised learning. Extensive experiments on\nthree widely used UDA datasets show that our method surpasses many previous\nstate-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.",
          "link": "http://arxiv.org/abs/2106.04151",
          "publishedOn": "2021-06-09T02:01:49.686Z",
          "wordCount": 647,
          "title": "Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korablyov_M/0/1/0/all/0/1\">Maksym Korablyov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "This paper is about the problem of learning a stochastic policy for\ngenerating an object (like a molecular graph) from a sequence of actions, such\nthat the probability of generating an object is proportional to a given\npositive reward for that object. Whereas standard return maximization tends to\nconverge to a single return-maximizing sequence, there are cases where we would\nlike to sample a diverse set of high-return solutions. These arise, for\nexample, in black-box function optimization when few rounds are possible, each\nwith large batches of queries, where the batches should be diverse, e.g., in\nthe design of new molecules. One can also see this as a problem of\napproximately converting an energy function to a generative distribution. While\nMCMC methods can achieve that, they are expensive and generally only perform\nlocal exploration. Instead, training a generative policy amortizes the cost of\nsearch during training and yields to fast generation. Using insights from\nTemporal Difference learning, we propose GFlowNet, based on a view of the\ngenerative process as a flow network, making it possible to handle the tricky\ncase where different trajectories can yield the same final state, e.g., there\nare many ways to sequentially add atoms to generate some molecular graph. We\ncast the set of trajectories as a flow and convert the flow consistency\nequations into a learning objective, akin to the casting of the Bellman\nequations into Temporal Difference methods. We prove that any global minimum of\nthe proposed objectives yields a policy which samples from the desired\ndistribution, and demonstrate the improved performance and diversity of\nGFlowNet on a simple domain where there are many modes to the reward function,\nand on a molecule synthesis task.",
          "link": "http://arxiv.org/abs/2106.04399",
          "publishedOn": "2021-06-09T02:01:49.670Z",
          "wordCount": 715,
          "title": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation. (arXiv:2106.04399v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04381",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rundo_L/0/1/0/all/0/1\">Leonardo Rundo</a>",
          "description": "Nowadays, the amount of heterogeneous biomedical data is increasing more and\nmore thanks to novel sensing techniques and high-throughput technologies. In\nreference to biomedical image analysis, the advances in image acquisition\nmodalities and high-throughput imaging experiments are creating new challenges.\nThis huge information ensemble could overwhelm the analytic capabilities needed\nby physicians in their daily decision-making tasks as well as by biologists\ninvestigating complex biochemical systems. In particular, quantitative imaging\nmethods convey scientifically and clinically relevant information in\nprediction, prognosis or treatment response assessment, by also considering\nradiomics approaches. Therefore, the computational analysis of medical and\nbiological images plays a key role in radiology and laboratory applications. In\nthis regard, frameworks based on advanced Machine Learning and Computational\nIntelligence can significantly improve traditional Image Processing and Pattern\nRecognition approaches. However, conventional Artificial Intelligence\ntechniques must be tailored to address the unique challenges concerning\nbiomedical imaging data. This thesis aims at proposing novel and advanced\ncomputer-assisted methods for biomedical image analysis, also as an instrument\nin the development of Clinical Decision Support Systems, by always keeping in\nmind the clinical feasibility of the developed solutions. In conclusion, the\nultimate goal of these research studies is to gain clinically and biologically\nuseful insights that can guide differential diagnosis and therapies, leading\ntowards biomedical data integration for personalized medicine. As a matter of\nfact, the proposed computer-assisted bioimage analysis methods can be\nbeneficial for the definition of imaging biomarkers, as well as for\nquantitative medicine and biology.",
          "link": "http://arxiv.org/abs/2106.04381",
          "publishedOn": "2021-06-09T02:01:49.664Z",
          "wordCount": 685,
          "title": "Computer-Assisted Analysis of Biomedical Images. (arXiv:2106.04381v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04452",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Gopal_B/0/1/0/all/0/1\">Bryan Gopal</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Han_R/0/1/0/all/0/1\">Ryan W. Han</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Raghupathi_G/0/1/0/all/0/1\">Gautham Raghupathi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ng_A/0/1/0/all/0/1\">Andrew Y. Ng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tison_G/0/1/0/all/0/1\">Geoffrey H. Tison</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>",
          "description": "Self-supervised contrastive learning approaches leverage modality-specific\ncontext or invariances to pretrain models using unlabeled data. While\ncontrastive learning has demonstrated promising on results in the image domain,\nthere has been limited work on determining how to exploit modality-specific\ninvariances in biosignals such as the electrocardiogram. In this work, we\npropose 3KG, a method to generate positive pairs for contrastive learning using\nphysiologically-inspired 3D augmentations of the 12-lead electrocardiogram. We\nevaluate representation quality by fine-tuning a linear layer for the\ndownstream task of 24-class diagnosis on the PhysioNet 2020 challenge training\ndata, and find that models trained with physiologically-inspired augmentations\nboth outperform and complement standard time-series augmentations. Our best\nperforming strategy, which incorporates spatial rotation, spatial scaling, and\ntime masking, achieves a performance increase of 0.16, .086, and .046 in mean\nAUROC over a randomly initialized baseline at 1%, 10%, and 100% label fractions\nrespectively. Additionally, we show that the strength of spatial augmentations\ndoes not significantly affect the quality of the learned representations.\nFinally, we investigate the clinical relevance of how physiologically-inspired\naugmentations affect the performance of our classifier on different disease\nsubgroupings. As expert annotations are often expensive and scarce for medical\ncontexts, our approach highlights the potential of machine learning to tackle\nmedical problems with large quantities of unlabeled biosignal data by\nexploiting their unique biological properties.",
          "link": "http://arxiv.org/abs/2106.04452",
          "publishedOn": "2021-06-09T02:01:49.658Z",
          "wordCount": 660,
          "title": "3KG: Contrastive Learning of 12-Lead Electrocardiograms using Physiologically-Inspired Augmentations. (arXiv:2106.04452v1 [physics.med-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shiqi Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1\">Qi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Learning dynamics governed by differential equations is crucial for\npredicting and controlling the systems in science and engineering. Neural\nOrdinary Differential Equation (NODE), a deep learning model integrated with\ndifferential equations, learns the dynamics directly from the samples on the\ntrajectory and shows great promise in the scientific field. However, the\ntraining of NODE highly depends on the numerical solver, which can amplify\nnumerical noise and be unstable, especially for ill-conditioned dynamical\nsystems. In this paper, to reduce the reliance on the numerical solver, we\npropose to enhance the supervised signal in learning dynamics. Specifically,\nbeyond learning directly from the trajectory samples, we pre-train a neural\ndifferential operator (NDO) to output an estimation of the derivatives to serve\nas an additional supervised signal. The NDO is pre-trained on a class of\nsymbolic functions, and it learns the mapping between the trajectory samples of\nthese functions to their derivatives. We provide theoretical guarantee on that\nthe output of NDO can well approximate the ground truth derivatives by proper\ntuning the complexity of the library. To leverage both the trajectory signal\nand the estimated derivatives from NDO, we propose an algorithm called\nNDO-NODE, in which the loss function contains two terms: the fitness on the\ntrue trajectory samples and the fitness on the estimated derivatives that are\noutput by the pre-trained NDO. Experiments on various of dynamics show that our\nproposed NDO-NODE can consistently improve the forecasting accuracy.",
          "link": "http://arxiv.org/abs/2106.04166",
          "publishedOn": "2021-06-09T02:01:49.653Z",
          "wordCount": 677,
          "title": "Incorporating NODE with Pre-trained Neural Differential Operator for Learning Dynamics. (arXiv:2106.04166v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04510",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Messaoud_R/0/1/0/all/0/1\">Remy Ben Messaoud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chavez_M/0/1/0/all/0/1\">Mario Chavez</a>",
          "description": "Epileptic seizure prediction has gained considerable interest in the\ncomputational Epilepsy research community. This paper presents a Machine\nLearning based method for epileptic seizure prediction which outperforms\nstate-of-the art methods. We compute a probability for a given epoch, of being\npre-ictal against interictal using the Random Forest classifier and introduce\nnew concepts to enhance the robustness of the algorithm to false alarms. We\nassessed our method on 20 patients of the benchmark scalp EEG CHB-MIT dataset\nfor a seizure prediction horizon (SPH) of 5 minutes and a seizure occurrence\nperiod (SOP) of 30 minutes. Our approach achieves a sensitivity of 82.07 % and\na low false positive rate (FPR) of 0.0799 /h. We also tested our approach on\nintracranial EEG recordings.",
          "link": "http://arxiv.org/abs/2106.04510",
          "publishedOn": "2021-06-09T02:01:49.640Z",
          "wordCount": 570,
          "title": "Random Forest classifier for EEG-based seizure prediction. (arXiv:2106.04510v1 [physics.med-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arriojas_A/0/1/0/all/0/1\">Argenis Arriojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiomkin_S/0/1/0/all/0/1\">Stas Tiomkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1\">Rahul V. Kulkarni</a>",
          "description": "We introduce a mapping between Maximum Entropy Reinforcement Learning (MaxEnt\nRL) and Markovian processes conditioned on rare events. In the long time limit,\nthis mapping allows us to derive analytical expressions for the optimal policy,\ndynamics and initial state distributions for the general case of stochastic\ndynamics in MaxEnt RL. We find that soft-$\\mathcal{Q}$ functions in MaxEnt RL\ncan be obtained from the Perron-Frobenius eigenvalue and the corresponding left\neigenvector of a regular, non-negative matrix derived from the underlying\nMarkov Decision Process (MDP). The results derived lead to novel algorithms for\nmodel-based and model-free MaxEnt RL, which we validate by numerical\nsimulations. The mapping established in this work opens further avenues for the\napplication of novel analytical and computational approaches to problems in\nMaxEnt RL. We make our code available at:\nhttps://github.com/argearriojas/maxent-rl-mdp-scripts",
          "link": "http://arxiv.org/abs/2106.03931",
          "publishedOn": "2021-06-09T02:01:49.590Z",
          "wordCount": 570,
          "title": "Closed-Form Analytical Results for Maximum Entropy Reinforcement Learning. (arXiv:2106.03931v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04464",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chenthamarakshan_V/0/1/0/all/0/1\">Vijil Chenthamarakshan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hoffman_S/0/1/0/all/0/1\">Samuel Hoffman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ramamurthy_K/0/1/0/all/0/1\">Karthikeyan Natesan Ramamurthy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>",
          "description": "Deep generative models have emerged as a powerful tool for learning\ninformative molecular representations and designing novel molecules with\ndesired properties, with applications in drug discovery and material design.\nDeep generative auto-encoders defined over molecular SMILES strings have been a\npopular choice for that purpose. However, capturing salient molecular\nproperties like quantum-chemical energies remains challenging and requires\nsophisticated neural net models of molecular graphs or geometry-based\ninformation. As a simpler and more efficient alternative, we present a SMILES\nVariational Auto-Encoder (VAE) augmented with topological data analysis (TDA)\nrepresentations of molecules, known as persistence images. Our experiments show\nthat this TDA augmentation enables a SMILES VAE to capture the complex relation\nbetween 3D geometry and electronic properties, and allows generation of novel,\ndiverse, and valid molecules with geometric features consistent with the\ntraining data, which exhibit a varying range of global electronic structural\nproperties, such as a small HOMO-LUMO gap - a critical property for designing\norganic solar cells. We demonstrate that our TDA augmentation yields better\nsuccess in downstream tasks compared to models trained without these\nrepresentations and can assist in targeted molecule discovery.",
          "link": "http://arxiv.org/abs/2106.04464",
          "publishedOn": "2021-06-09T02:01:49.584Z",
          "wordCount": 624,
          "title": "Augmenting Molecular Deep Generative Models with Topological Data Analysis Representations. (arXiv:2106.04464v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1\">Siddharth Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1\">Tuomas Sandholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitercik_E/0/1/0/all/0/1\">Ellen Vitercik</a>",
          "description": "Cutting-plane methods have enabled remarkable successes in integer\nprogramming over the last few decades. State-of-the-art solvers integrate a\nmyriad of cutting-plane techniques to speed up the underlying tree-search\nalgorithm used to find optimal solutions. In this paper we prove the first\nguarantees for learning high-performing cut-selection policies tailored to the\ninstance distribution at hand using samples. We first bound the sample\ncomplexity of learning cutting planes from the canonical family of\nChv\\'atal-Gomory cuts. Our bounds handle any number of waves of any number of\ncuts and are fine tuned to the magnitudes of the constraint coefficients. Next,\nwe prove sample complexity bounds for more sophisticated cut selection policies\nthat use a combination of scoring rules to choose from a family of cuts.\nFinally, beyond the realm of cutting planes for integer programming, we develop\na general abstraction of tree search that captures key components such as node\nselection and variable selection. For this abstraction, we bound the sample\ncomplexity of learning a good policy for building the search tree.",
          "link": "http://arxiv.org/abs/2106.04033",
          "publishedOn": "2021-06-09T02:01:49.568Z",
          "wordCount": 601,
          "title": "Sample Complexity of Tree Search Configuration: Cutting Planes and Beyond. (arXiv:2106.04033v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Briesch_M/0/1/0/all/0/1\">Martin Briesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sobania_D/0/1/0/all/0/1\">Dominik Sobania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rothlauf_F/0/1/0/all/0/1\">Franz Rothlauf</a>",
          "description": "Over-parameterized models can perfectly learn various types of data\ndistributions, however, generalization error is usually lower for real data in\ncomparison to artificial data. This suggests that the properties of data\ndistributions have an impact on generalization capability. This work focuses on\nthe search space defined by the input data and assumes that the correlation\nbetween labels of neighboring input values influences generalization. If\ncorrelation is low, the randomness of the input data space is high leading to\nhigh generalization error. We suggest to measure the randomness of an input\ndata space using Maurer's universal. Results for synthetic classification tasks\nand common image classification benchmarks (MNIST, CIFAR10, and Microsoft's\ncats vs. dogs data set) find a high correlation between the randomness of input\ndata spaces and the generalization error of deep neural networks for binary\nclassification problems.",
          "link": "http://arxiv.org/abs/2106.04181",
          "publishedOn": "2021-06-09T02:01:49.558Z",
          "wordCount": 574,
          "title": "The Randomness of Input Data Spaces is an A Priori Predictor for Generalization. (arXiv:2106.04181v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_B/0/1/0/all/0/1\">Bing-Jing Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_P/0/1/0/all/0/1\">Ping-Chun Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xi Liu</a>",
          "description": "Bayesian optimization (BO) conventionally relies on handcrafted acquisition\nfunctions (AFs) to sequentially determine the sample points. However, it has\nbeen widely observed in practice that the best-performing AF in terms of regret\ncan vary significantly under different types of black-box functions. It has\nremained a challenge to design one AF that can attain the best performance over\na wide variety of black-box functions. This paper aims to attack this challenge\nthrough the perspective of reinforced few-shot AF learning (FSAF).\nSpecifically, we first connect the notion of AFs with Q-functions and view a\ndeep Q-network (DQN) as a surrogate differentiable AF. While it serves as a\nnatural idea to combine DQN and an existing few-shot learning method, we\nidentify that such a direct combination does not perform well due to severe\noverfitting, which is particularly critical in BO due to the need of a\nversatile sampling policy. To address this, we present a Bayesian variant of\nDQN with the following three features: (i) It learns a distribution of\nQ-networks as AFs based on the Kullback-Leibler regularization framework. This\ninherently provides the uncertainty required in sampling for BO and mitigates\noverfitting. (ii) For the prior of the Bayesian DQN, we propose to use a demo\npolicy induced by an off-the-shelf AF for better training stability. (iii) On\nthe meta-level, we leverage the meta-loss of Bayesian model-agnostic\nmeta-learning, which serves as a natural companion to the proposed FSAF.\nMoreover, with the proper design of the Q-networks, FSAF is general-purpose in\nthat it is agnostic to the dimension and the cardinality of the input domain.\nThrough extensive experiments, we demonstrate that the FSAF achieves comparable\nor better regrets than the state-of-the-art benchmarks on a wide variety of\nsynthetic and real-world test functions.",
          "link": "http://arxiv.org/abs/2106.04335",
          "publishedOn": "2021-06-09T02:01:49.552Z",
          "wordCount": 724,
          "title": "Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization. (arXiv:2106.04335v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryan_J/0/1/0/all/0/1\">John Paul Ryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1\">Sebastian Ament</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damle_A/0/1/0/all/0/1\">Anil Damle</a>",
          "description": "Kernel methods are a highly effective and widely used collection of modern\nmachine learning algorithms. A fundamental limitation of virtually all such\nmethods are computations involving the kernel matrix that naively scale\nquadratically (e.g., constructing the kernel matrix and matrix-vector\nmultiplication) or cubically (solving linear systems) with the size of the data\nset $N.$ We propose the Fast Kernel Transform (FKT), a general algorithm to\ncompute matrix-vector multiplications (MVMs) for datasets in moderate\ndimensions with quasilinear complexity. Typically, analytically grounded fast\nmultiplication methods require specialized development for specific kernels. In\ncontrast, our scheme is based on auto-differentiation and automated symbolic\ncomputations that leverage the analytical structure of the underlying kernel.\nThis allows the FKT to be easily applied to a broad class of kernels, including\nGaussian, Matern, and Rational Quadratic covariance functions and physically\nmotivated Green's functions, including those of the Laplace and Helmholtz\nequations. Furthermore, the FKT maintains a high, quantifiable, and\ncontrollable level of accuracy -- properties that many acceleration methods\nlack. We illustrate the efficacy and versatility of the FKT by providing timing\nand accuracy benchmarks and by applying it to scale the stochastic neighborhood\nembedding (t-SNE) and Gaussian processes to large real-world data sets.",
          "link": "http://arxiv.org/abs/2106.04487",
          "publishedOn": "2021-06-09T02:01:49.541Z",
          "wordCount": 621,
          "title": "The Fast Kernel Transform. (arXiv:2106.04487v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perifanis_V/0/1/0/all/0/1\">Vasileios Perifanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efraimidis_P/0/1/0/all/0/1\">Pavlos S. Efraimidis</a>",
          "description": "In this work, we present a federated version of the state-of-the-art Neural\nCollaborative Filtering (NCF) approach for item recommendations. The system,\nnamed FedNCF, allows learning without requiring users to expose or transmit\ntheir raw data. Experimental validation shows that FedNCF achieves comparable\nrecommendation quality to the original NCF system. Although federated learning\n(FL) enables learning without raw data transmission, recent attacks showed that\nFL alone does not eliminate privacy concerns. To overcome this challenge, we\nintegrate a privacy-preserving enhancement with a secure aggregation scheme\nthat satisfies the security requirements against an honest-but-curious (HBC)\nentity, without affecting the quality of the original model. Finally, we\ndiscuss the peculiarities observed in the application of FL in a collaborative\nfiltering (CF) task as well as we evaluate the privacy-preserving mechanism in\nterms of computational cost.",
          "link": "http://arxiv.org/abs/2106.04405",
          "publishedOn": "2021-06-09T02:01:49.524Z",
          "wordCount": 554,
          "title": "Federated Neural Collaborative Filtering. (arXiv:2106.04405v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04145",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chapel_L/0/1/0/all/0/1\">Laetitia Chapel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wu_H/0/1/0/all/0/1\">Haoran Wu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fevotte_C/0/1/0/all/0/1\">C&#xe9;dric F&#xe9;votte</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasso_G/0/1/0/all/0/1\">Gilles Gasso</a>",
          "description": "This paper addresses the problem of Unbalanced Optimal Transport (UOT) in\nwhich the marginal conditions are relaxed (using weighted penalties in lieu of\nequality) and no additional regularization is enforced on the OT plan. In this\ncontext, we show that the corresponding optimization problem can be\nreformulated as a non-negative penalized linear regression problem. This\nreformulation allows us to propose novel algorithms inspired from inverse\nproblems and nonnegative matrix factorization. In particular, we consider\nmajorization-minimization which leads in our setting to efficient\nmultiplicative updates for a variety of penalties. Furthermore, we derive for\nthe first time an efficient algorithm to compute the regularization path of UOT\nwith quadratic penalties. The proposed algorithm provides a continuity of\npiece-wise linear OT plans converging to the solution of balanced OT\n(corresponding to infinite penalty weights). We perform several numerical\nexperiments on simulated and real data illustrating the new algorithms, and\nprovide a detailed discussion about more sophisticated optimization tools that\ncan further be used to solve OT problems thanks to our reformulation.",
          "link": "http://arxiv.org/abs/2106.04145",
          "publishedOn": "2021-06-09T02:01:49.519Z",
          "wordCount": 615,
          "title": "Unbalanced Optimal Transport through Non-negative Penalized Linear Regression. (arXiv:2106.04145v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Cuiling Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1\">Mingxiao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhibo Chen</a>",
          "description": "Learning good feature representations is important for deep reinforcement\nlearning (RL). However, with limited experience, RL often suffers from data\ninefficiency for training. For un-experienced or less-experienced trajectories\n(i.e., state-action sequences), the lack of data limits the use of them for\nbetter feature learning. In this work, we propose a novel method, dubbed\nPlayVirtual, which augments cycle-consistent virtual trajectories to enhance\nthe data efficiency for RL feature representation learning. Specifically,\nPlayVirtual predicts future states based on the current state and action by a\ndynamics model and then predicts the previous states by a backward dynamics\nmodel, which forms a trajectory cycle. Based on this, we augment the actions to\ngenerate a large amount of virtual state-action trajectories. Being free of\ngroudtruth state supervision, we enforce a trajectory to meet the cycle\nconsistency constraint, which can significantly enhance the data efficiency. We\nvalidate the effectiveness of our designs on the Atari and DeepMind Control\nSuite benchmarks. Our method outperforms the current state-of-the-art methods\nby a large margin on both benchmarks.",
          "link": "http://arxiv.org/abs/2106.04152",
          "publishedOn": "2021-06-09T02:01:49.513Z",
          "wordCount": 595,
          "title": "PlayVirtual: Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning. (arXiv:2106.04152v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Varun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1\">Christopher Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neel_S/0/1/0/all/0/1\">Seth Neel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Aaron Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharifi_Malvajerdi_S/0/1/0/all/0/1\">Saeed Sharifi-Malvajerdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waites_C/0/1/0/all/0/1\">Chris Waites</a>",
          "description": "Data deletion algorithms aim to remove the influence of deleted data points\nfrom trained models at a cheaper computational cost than fully retraining those\nmodels. However, for sequences of deletions, most prior work in the non-convex\nsetting gives valid guarantees only for sequences that are chosen independently\nof the models that are published. If people choose to delete their data as a\nfunction of the published models (because they don't like what the models\nreveal about them, for example), then the update sequence is adaptive. In this\npaper, we give a general reduction from deletion guarantees against adaptive\nsequences to deletion guarantees against non-adaptive sequences, using\ndifferential privacy and its connection to max information. Combined with ideas\nfrom prior work which give guarantees for non-adaptive deletion sequences, this\nleads to extremely flexible algorithms able to handle arbitrary model classes\nand training methodologies, giving strong provable deletion guarantees for\nadaptive deletion sequences. We show in theory how prior work for non-convex\nmodels fails against adaptive deletion sequences, and use this intuition to\ndesign a practical attack against the SISA algorithm of Bourtoule et al. [2021]\non CIFAR-10, MNIST, Fashion-MNIST.",
          "link": "http://arxiv.org/abs/2106.04378",
          "publishedOn": "2021-06-09T02:01:49.462Z",
          "wordCount": 611,
          "title": "Adaptive Machine Unlearning. (arXiv:2106.04378v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanagawa_H/0/1/0/all/0/1\">Heishiro Kanagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "Proxy causal learning (PCL) is a method for estimating the causal effect of\ntreatments on outcomes in the presence of unobserved confounding, using proxies\n(structured side information) for the confounder. This is achieved via\ntwo-stage regression: in the first stage, we model relations among the\ntreatment and proxies; in the second stage, we use this model to learn the\neffect of treatment on the outcome, given the context provided by the proxies.\nPCL guarantees recovery of the true causal effect, subject to identifiability\nconditions. We propose a novel method for PCL, the deep feature proxy variable\nmethod (DFPV), to address the case where the proxies, treatments, and outcomes\nare high-dimensional and have nonlinear complex relationships, as represented\nby deep neural network features. We show that DFPV outperforms recent\nstate-of-the-art PCL methods on challenging synthetic benchmarks, including\nsettings involving high dimensional image data. Furthermore, we show that PCL\ncan be applied to off-policy evaluation for the confounded bandit problem, in\nwhich DFPV also exhibits competitive performance.",
          "link": "http://arxiv.org/abs/2106.03907",
          "publishedOn": "2021-06-09T02:01:49.277Z",
          "wordCount": null,
          "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03898",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Shmakov_A/0/1/0/all/0/1\">Alexander Shmakov</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Fenton_M/0/1/0/all/0/1\">Michael James Fenton</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Ho_T/0/1/0/all/0/1\">Ta-Wei Ho</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Hsu_S/0/1/0/all/0/1\">Shih-Chieh Hsu</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Whiteson_D/0/1/0/all/0/1\">Daniel Whiteson</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>",
          "description": "The creation of unstable heavy particles at the Large Hadron Collider is the\nmost direct way to address some of the deepest open questions in physics.\nCollisions typically produce variable-size sets of observed particles which\nhave inherent ambiguities complicating the assignment of observed particles to\nthe decay products of the heavy particles. Current strategies for tackling\nthese challenges in the physics community ignore the physical symmetries of the\ndecay products and consider all possible assignment permutations and do not\nscale to complex configurations. Attention based deep learning methods for\nsequence modelling have achieved state-of-the-art performance in natural\nlanguage processing, but they lack built-in mechanisms to deal with the unique\nsymmetries found in physical set-assignment problems. We introduce a novel\nmethod for constructing symmetry-preserving attention networks which reflect\nthe problem's natural invariances to efficiently find assignments without\nevaluating all permutations. This general approach is applicable to arbitrarily\ncomplex configurations and significantly outperforms current methods, improving\nreconstruction efficiency between 19\\% - 35\\% on typical benchmark problems\nwhile decreasing inference time by two to five orders of magnitude on the most\ncomplex events, making many important and previously intractable cases\ntractable.\n\nA full code repository containing a general library, the specific\nconfiguration used, and a complete dataset release, are avaiable at\nhttps://github.com/Alexanders101/SPANet",
          "link": "http://arxiv.org/abs/2106.03898",
          "publishedOn": "2021-06-09T02:01:49.246Z",
          "wordCount": null,
          "title": "SPANet: Generalized Permutationless Set Assignment for Particle Physics using Symmetry Preserving Attention. (arXiv:2106.03898v1 [hep-ex])"
        },
        {
          "id": "http://arxiv.org/abs/1708.00568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1\">Richard Nock</a>",
          "description": "We consider the space of $w$-mixtures which is defined as the set of finite\nstatistical mixtures sharing the same prescribed component distributions closed\nunder convex combinations. The information geometry induced by the Bregman\ngenerator set to the Shannon negentropy on this space yields a dually flat\nspace called the mixture family manifold. We show how the Kullback-Leibler (KL)\ndivergence can be recovered from the corresponding Bregman divergence for the\nnegentropy generator: That is, the KL divergence between two $w$-mixtures\namounts to a Bregman Divergence (BD) induced by the Shannon negentropy\ngenerator. Thus the KL divergence between two Gaussian Mixture Models (GMMs)\nsharing the same Gaussian components is equivalent to a Bregman divergence.\nThis KL-BD equivalence on a mixture family manifold implies that we can perform\noptimal KL-averaging aggregation of $w$-mixtures without information loss. More\ngenerally, we prove that the statistical skew Jensen-Shannon divergence between\n$w$-mixtures is equivalent to a skew Jensen divergence between their\ncorresponding parameters. Finally, we state several properties, divergence\nidentities, and inequalities relating to $w$-mixtures.",
          "link": "http://arxiv.org/abs/1708.00568",
          "publishedOn": "2021-06-09T02:01:49.225Z",
          "wordCount": 635,
          "title": "On $w$-mixtures: Finite convex combinations of prescribed component distributions. (arXiv:1708.00568v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedersen_B/0/1/0/all/0/1\">Bj&#xf8;rn-Richard Pedersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holsbo_E/0/1/0/all/0/1\">Einar Holsb&#xf8;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersen_T/0/1/0/all/0/1\">Trygve Andersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shvetsov_N/0/1/0/all/0/1\">Nikita Shvetsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravn_J/0/1/0/all/0/1\">Johan Ravn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sommerseth_H/0/1/0/all/0/1\">Hilde Leikny Sommerseth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bongo_L/0/1/0/all/0/1\">Lars Ailo Bongo</a>",
          "description": "Machine learning approaches achieve high accuracy for text recognition and\nare therefore increasingly used for the transcription of handwritten historical\nsources. However, using machine learning in production requires a streamlined\nend-to-end machine learning pipeline that scales to the dataset size, and a\nmodel that achieves high accuracy with few manual transcriptions. In addition,\nthe correctness of the model results must be verified. This paper describes our\nlessons learned developing, tuning, and using the Occode end-to-end machine\nlearning pipeline for transcribing 7,3 million rows with handwritten occupation\ncodes in the Norwegian 1950 population census. We achieve an accuracy of 97%\nfor the automatically transcribed codes, and we send 3% of the codes for manual\nverification. We verify that the occupation code distribution found in our\nresult matches the distribution found in our training data which should be\nrepresentative for the census as a whole. We believe our approach and lessons\nlearned are useful for other transcription projects that plan to use machine\nlearning in production. The source code is available at:\nhttps://github.com/uit-hdl/rhd-codes",
          "link": "http://arxiv.org/abs/2106.03996",
          "publishedOn": "2021-06-09T02:01:49.197Z",
          "wordCount": null,
          "title": "Occode: an end-to-end machine learning pipeline for transcription of historical population censuses. (arXiv:2106.03996v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04492",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1\">Binxin Ru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lyle_C/0/1/0/all/0/1\">Clare Lyle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schut_L/0/1/0/all/0/1\">Lisa Schut</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fil_M/0/1/0/all/0/1\">Miroslav Fil</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "Reliable yet efficient evaluation of generalisation performance of a proposed\narchitecture is crucial to the success of neural architecture search (NAS).\nTraditional approaches face a variety of limitations: training each\narchitecture to completion is prohibitively expensive, early stopped validation\naccuracy may correlate poorly with fully trained performance, and model-based\nestimators require large training sets. We instead propose to estimate the\nfinal test performance based on a simple measure of training speed. Our\nestimator is theoretically motivated by the connection between generalisation\nand training speed, and is also inspired by the reformulation of a PAC-Bayes\nbound under the Bayesian setting. Our model-free estimator is simple,\nefficient, and cheap to implement, and does not require hyperparameter-tuning\nor surrogate training before deployment. We demonstrate on various NAS search\nspaces that our estimator consistently outperforms other alternatives in\nachieving better correlation with the true test performance rankings. We\nfurther show that our estimator can be easily incorporated into both\nquery-based and one-shot NAS methods to improve the speed or quality of the\nsearch.",
          "link": "http://arxiv.org/abs/2006.04492",
          "publishedOn": "2021-06-09T02:01:49.141Z",
          "wordCount": null,
          "title": "Speedy Performance Estimation for Neural Architecture Search. (arXiv:2006.04492v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinchong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buettner_F/0/1/0/all/0/1\">Florian Buettner</a>",
          "description": "Recommender systems are often designed based on a collaborative filtering\napproach, where user preferences are predicted by modelling interactions\nbetween users and items. Many common approaches to solve the collaborative\nfiltering task are based on learning representations of users and items,\nincluding simple matrix factorization, Gaussian process latent variable models,\nand neural-network based embeddings. While matrix factorization approaches fail\nto model nonlinear relations, neural networks can potentially capture such\ncomplex relations with unprecedented predictive power and are highly scalable.\nHowever, neither of them is able to model predictive uncertainties. In\ncontrast, Gaussian Process based models can generate a predictive distribution,\nbut cannot scale to large amounts of data. In this manuscript, we propose a\nnovel approach combining the representation learning paradigm of collaborative\nfiltering with multi-output Gaussian processes in a joint framework to generate\nuncertainty-aware recommendations. We introduce an efficient strategy for model\ntraining and inference, resulting in a model that scales to very large and\nsparse datasets and achieves competitive performance in terms of classical\nmetrics quantifying the reconstruction error. In addition to accurately\npredicting user preferences, our model also provides meaningful uncertainty\nestimates about that prediction.",
          "link": "http://arxiv.org/abs/2106.04221",
          "publishedOn": "2021-06-09T02:01:49.089Z",
          "wordCount": null,
          "title": "Multi-output Gaussian Processes for Uncertainty-aware Recommender Systems. (arXiv:2106.04221v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guijarro_Ordonez_J/0/1/0/all/0/1\">Jorge Guijarro-Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelger_M/0/1/0/all/0/1\">Markus Pelger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanotti_G/0/1/0/all/0/1\">Greg Zanotti</a>",
          "description": "Statistical arbitrage identifies and exploits temporal price differences\nbetween similar assets. We propose a unifying conceptual framework for\nstatistical arbitrage and develop a novel deep learning solution, which finds\ncommonality and time-series patterns from large panels in a data-driven and\nflexible way. First, we construct arbitrage portfolios of similar assets as\nresidual portfolios from conditional latent asset pricing factors. Second, we\nextract the time series signals of these residual portfolios with one of the\nmost powerful machine learning time-series solutions, a convolutional\ntransformer. Last, we use these signals to form an optimal trading policy, that\nmaximizes risk-adjusted returns under constraints. We conduct a comprehensive\nempirical comparison study with daily large cap U.S. stocks. Our optimal\ntrading strategy obtains a consistently high out-of-sample Sharpe ratio and\nsubstantially outperforms all benchmark approaches. It is orthogonal to common\nrisk factors, and exploits asymmetric local trend and reversion patterns. Our\nstrategies remain profitable after taking into account trading frictions and\ncosts. Our findings suggest a high compensation for arbitrageurs to enforce the\nlaw of one price.",
          "link": "http://arxiv.org/abs/2106.04028",
          "publishedOn": "2021-06-09T02:01:49.045Z",
          "wordCount": 591,
          "title": "Deep Learning Statistical Arbitrage. (arXiv:2106.04028v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddi_V/0/1/0/all/0/1\">Vijay Janapa Reddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plancher_B/0/1/0/all/0/1\">Brian Plancher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_S/0/1/0/all/0/1\">Susan Kennedy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moroney_L/0/1/0/all/0/1\">Laurence Moroney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warden_P/0/1/0/all/0/1\">Pete Warden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anant Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banbury_C/0/1/0/all/0/1\">Colby Banbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banzi_M/0/1/0/all/0/1\">Massimo Banzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1\">Matthew Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_B/0/1/0/all/0/1\">Benjamin Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitlangia_S/0/1/0/all/0/1\">Sharad Chitlangia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_R/0/1/0/all/0/1\">Radhika Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grafman_S/0/1/0/all/0/1\">Sarah Grafman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaeger_R/0/1/0/all/0/1\">Rupert Jaeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_S/0/1/0/all/0/1\">Srivatsan Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1\">Maximilian Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leiker_D/0/1/0/all/0/1\">Daniel Leiker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mann_C/0/1/0/all/0/1\">Cara Mann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_M/0/1/0/all/0/1\">Mark Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajak_D/0/1/0/all/0/1\">Dominic Pajak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramaprasad_D/0/1/0/all/0/1\">Dhilan Ramaprasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">J. Evan Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_M/0/1/0/all/0/1\">Matthew Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tingley_D/0/1/0/all/0/1\">Dustin Tingley</a>",
          "description": "Broadening access to both computational and educational resources is critical\nto diffusing machine-learning (ML) innovation. However, today, most ML\nresources and experts are siloed in a few countries and organizations. In this\npaper, we describe our pedagogical approach to increasing access to applied ML\nthrough a massive open online course (MOOC) on Tiny Machine Learning (TinyML).\nWe suggest that TinyML, ML on resource-constrained embedded devices, is an\nattractive means to widen access because TinyML both leverages low-cost and\nglobally accessible hardware, and encourages the development of complete,\nself-contained applications, from data collection to deployment. To this end, a\ncollaboration between academia (Harvard University) and industry (Google)\nproduced a four-part MOOC that provides application-oriented instruction on how\nto develop solutions using TinyML. The series is openly available on the edX\nMOOC platform, has no prerequisites beyond basic programming, and is designed\nfor learners from a global variety of backgrounds. It introduces pupils to\nreal-world applications, ML algorithms, data-set engineering, and the ethical\nconsiderations of these technologies via hands-on programming and deployment of\nTinyML applications in both the cloud and their own microcontrollers. To\nfacilitate continued learning, community building, and collaboration beyond the\ncourses, we launched a standalone website, a forum, a chat, and an optional\ncourse-project competition. We also released the course materials publicly,\nhoping they will inspire the next generation of ML practitioners and educators\nand further broaden access to cutting-edge ML technologies.",
          "link": "http://arxiv.org/abs/2106.04008",
          "publishedOn": "2021-06-09T02:01:49.039Z",
          "wordCount": 713,
          "title": "Widening Access to Applied Machine Learning with TinyML. (arXiv:2106.04008v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naveh_G/0/1/0/all/0/1\">Gadi Naveh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "Deep neural networks (DNNs) in the infinite width/channel limit have received\nmuch attention recently, as they provide a clear analytical window to deep\nlearning via mappings to Gaussian Processes (GPs). Despite its theoretical\nappeal, this viewpoint lacks a crucial ingredient of deep learning in finite\nDNNs, laying at the heart of their success -- feature learning. Here we\nconsider DNNs trained with noisy gradient descent on a large training set and\nderive a self consistent Gaussian Process theory accounting for strong\nfinite-DNN and feature learning effects. Applying this to a toy model of a\ntwo-layer linear convolutional neural network (CNN) shows good agreement with\nexperiments. We further identify, both analytical and numerically, a sharp\ntransition between a feature learning regime and a lazy learning regime in this\nmodel. Strong finite-DNN effects are also derived for a non-linear two-layer\nfully connected network. Our self consistent theory provides a rich and\nversatile analytical framework for studying feature learning and other non-lazy\neffects in finite DNNs.",
          "link": "http://arxiv.org/abs/2106.04110",
          "publishedOn": "2021-06-09T02:01:49.028Z",
          "wordCount": 618,
          "title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs. (arXiv:2106.04110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1\">Stefano Teso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontempelli_A/0/1/0/all/0/1\">Andrea Bontempelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1\">Fausto Giunchiglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>",
          "description": "We tackle sequential learning under label noise in applications where a human\nsupervisor can be queried to relabel suspicious examples. Existing approaches\nare flawed, in that they only relabel incoming examples that look\n``suspicious'' to the model. As a consequence, those mislabeled examples that\nelude (or don't undergo) this cleaning step end up tainting the training data\nand the model with no further chance of being cleaned. We propose Cincer, a\nnovel approach that cleans both new and past data by identifying pairs of\nmutually incompatible examples. Whenever it detects a suspicious example,\nCincer identifies a counter-example in the training set that -- according to\nthe model -- is maximally incompatible with the suspicious example, and asks\nthe annotator to relabel either or both examples, resolving this possible\ninconsistency. The counter-examples are chosen to be maximally incompatible, so\nto serve as explanations of the model' suspicion, and highly influential, so to\nconvey as much information as possible if relabeled. Cincer achieves this by\nleveraging an efficient and robust approximation of influence functions based\non the Fisher information matrix (FIM). Our extensive empirical evaluation\nshows that clarifying the reasons behind the model's suspicions by cleaning the\ncounter-examples helps acquiring substantially better data and models,\nespecially when paired with our FIM approximation.",
          "link": "http://arxiv.org/abs/2106.03922",
          "publishedOn": "2021-06-09T02:01:49.017Z",
          "wordCount": 635,
          "title": "Interactive Label Cleaning with Example-based Explanations. (arXiv:2106.03922v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stretcu_O/0/1/0/all/0/1\">Otilia Stretcu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Platanios_E/0/1/0/all/0/1\">Emmanouil Antonios Platanios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom M. Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1\">Barnab&#xe1;s P&#xf3;czos</a>",
          "description": "When faced with learning challenging new tasks, humans often follow sequences\nof steps that allow them to incrementally build up the necessary skills for\nperforming these new tasks. However, in machine learning, models are most often\ntrained to solve the target tasks directly.Inspired by human learning, we\npropose a novel curriculum learning approach which decomposes challenging tasks\ninto sequences of easier intermediate goals that are used to pre-train a model\nbefore tackling the target task. We focus on classification tasks, and design\nthe intermediate tasks using an automatically constructed label hierarchy. We\ntrain the model at each level of the hierarchy, from coarse labels to fine\nlabels, transferring acquired knowledge across these levels. For instance, the\nmodel will first learn to distinguish animals from objects, and then use this\nacquired knowledge when learning to classify among more fine-grained classes\nsuch as cat, dog, car, and truck. Most existing curriculum learning algorithms\nfor supervised learning consist of scheduling the order in which the training\nexamples are presented to the model. In contrast, our approach focuses on the\noutput space of the model. We evaluate our method on several established\ndatasets and show significant performance gains especially on classification\nproblems with many labels. We also evaluate on a new synthetic dataset which\nallows us to study multiple aspects of our method.",
          "link": "http://arxiv.org/abs/2106.04072",
          "publishedOn": "2021-06-09T02:01:49.010Z",
          "wordCount": 640,
          "title": "Coarse-to-Fine Curriculum Learning. (arXiv:2106.04072v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Sahil Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hines_K/0/1/0/all/0/1\">Keegan Hines</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John P. Dickerson</a>",
          "description": "Explainable machine learning (ML) has gained traction in recent years due to\nthe increasing adoption of ML-based systems in many sectors. Counterfactual\nexplanations (CFEs) provide ``what if'' feedback of the form ``if an input\ndatapoint were $x'$ instead of $x$, then an ML-based system's output would be\n$y'$ instead of $y$.'' CFEs are attractive due to their actionable feedback,\namenability to existing legal frameworks, and fidelity to the underlying ML\nmodel. Yet, current CFE approaches are single shot -- that is, they assume $x$\ncan change to $x'$ in a single time period. We propose a novel\nstochastic-control-based approach that generates sequential CFEs, that is, CFEs\nthat allow $x$ to move stochastically and sequentially across intermediate\nstates to a final state $x'$. Our approach is model agnostic and black box.\nFurthermore, calculation of CFEs is amortized such that once trained, it\napplies to multiple datapoints without the need for re-optimization. In\naddition to these primary characteristics, our approach admits optional\ndesiderata such as adherence to the data manifold, respect for causal\nrelations, and sparsity -- identified by past research as desirable properties\nof CFEs. We evaluate our approach using three real-world datasets and show\nsuccessful generation of sequential CFEs that respect other counterfactual\ndesiderata.",
          "link": "http://arxiv.org/abs/2106.03962",
          "publishedOn": "2021-06-09T02:01:48.994Z",
          "wordCount": 639,
          "title": "Amortized Generation of Sequential Counterfactual Explanations for Black-box Models. (arXiv:2106.03962v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luzi_L/0/1/0/all/0/1\">Lorenzo Luzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dar_Y/0/1/0/all/0/1\">Yehuda Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard Baraniuk</a>",
          "description": "We study overparameterization in generative adversarial networks (GANs) that\ncan interpolate the training data. We show that overparameterization can\nimprove generalization performance and accelerate the training process. We\nstudy the generalization error as a function of latent space dimension and\nidentify two main behaviors, depending on the learning setting. First, we show\nthat overparameterized generative models that learn distributions by minimizing\na metric or $f$-divergence do not exhibit double descent in generalization\nerrors; specifically, all the interpolating solutions achieve the same\ngeneralization error. Second, we develop a new pseudo-supervised learning\napproach for GANs where the training utilizes pairs of fabricated (noise)\ninputs in conjunction with real output samples. Our pseudo-supervised setting\nexhibits double descent (and in some cases, triple descent) of generalization\nerrors. We combine pseudo-supervision with overparameterization (i.e., overly\nlarge latent space dimension) to accelerate training while performing better,\nor close to, the generalization performance without pseudo-supervision. While\nour analysis focuses mostly on linear GANs, we also apply important insights\nfor improving generalization of nonlinear, multilayer GANs.",
          "link": "http://arxiv.org/abs/2106.04003",
          "publishedOn": "2021-06-09T02:01:48.989Z",
          "wordCount": 590,
          "title": "Double Descent and Other Interpolation Phenomena in GANs. (arXiv:2106.04003v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1\">Ignacio Tampe Palma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1\">Marcelo Mendoza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1\">Evangelos Milios</a>",
          "description": "Summarization has usually relied on gold standard summaries to train\nextractive or abstractive models. Social media brings a hurdle to summarization\ntechniques since it requires addressing a multi-document multi-author approach.\nWe address this challenging task by introducing a novel method that generates\nabstractive summaries of online news discussions. Our method extends a\nBERT-based architecture, including an attention encoding that fed comments'\nlikes during the training stage. To train our model, we define a task which\nconsists of reconstructing high impact comments based on popularity (likes).\nAccordingly, our model learns to summarize online discussions based on their\nmost relevant comments. Our novel approach provides a summary that represents\nthe most relevant aspects of a news item that users comment on, incorporating\nthe social context as a source of information to summarize texts in online\nsocial networks. Our model is evaluated using ROUGE scores between the\ngenerated summary and each comment on the thread. Our model, including the\nsocial attention encoding, significantly outperforms both extractive and\nabstractive summarization methods based on such evaluation.",
          "link": "http://arxiv.org/abs/2106.03953",
          "publishedOn": "2021-06-09T02:01:48.982Z",
          "wordCount": 600,
          "title": "Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zixuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shengfeng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunfeng Liu</a>",
          "description": "Emotion recognition from speech is a challenging task. Re-cent advances in\ndeep learning have led bi-directional recur-rent neural network (Bi-RNN) and\nattention mechanism as astandard method for speech emotion recognition,\nextractingand attending multi-modal features - audio and text, and thenfusing\nthem for downstream emotion classification tasks. Inthis paper, we propose a\nsimple yet efficient neural networkarchitecture to exploit both acoustic and\nlexical informationfrom speech. The proposed framework using multi-scale\ncon-volutional layers (MSCNN) to obtain both audio and text hid-den\nrepresentations. Then, a statistical pooling unit (SPU)is used to further\nextract the features in each modality. Be-sides, an attention module can be\nbuilt on top of the MSCNN-SPU (audio) and MSCNN (text) to further improve the\nperfor-mance. Extensive experiments show that the proposed modeloutperforms\nprevious state-of-the-art methods on IEMOCAPdataset with four emotion\ncategories (i.e., angry, happy, sadand neutral) in both weighted accuracy (WA)\nand unweightedaccuracy (UA), with an improvement of 5.0% and 5.2% respectively\nunder the ASR setting.",
          "link": "http://arxiv.org/abs/2106.04133",
          "publishedOn": "2021-06-09T02:01:48.970Z",
          "wordCount": 607,
          "title": "Efficient Speech Emotion Recognition Using Multi-Scale CNN and Attention. (arXiv:2106.04133v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03905",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Aleem_A/0/1/0/all/0/1\">Abdullah Aleem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nallabothula_M/0/1/0/all/0/1\">Manoj Prabhakar Nallabothula</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Setabutr_P/0/1/0/all/0/1\">Pete Setabutr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hallak_J/0/1/0/all/0/1\">Joelle A. Hallak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_D/0/1/0/all/0/1\">Darvin Yi</a>",
          "description": "Blepharoptosis, or ptosis as it is more commonly referred to, is a condition\nof the eyelid where the upper eyelid droops. The current diagnosis for ptosis\ninvolves cumbersome manual measurements that are time-consuming and prone to\nhuman error. In this paper, we present AutoPtosis, an artificial intelligence\nbased system with interpretable results for rapid diagnosis of ptosis. We\nutilize a diverse dataset collected at the University of Illinois Hospital and\nHealth to successfully develop a robust deep learning model for prediction and\nalso develop a clinically inspired model that calculates the marginal reflex\ndistance and iris ratio. AutoPtosis achieved 95.5% accuracy on physician\nverified data that had an equal class balance. The proposed algorithm can help\nin the rapid and timely diagnosis of ptosis, significantly reduce the burden on\nthe healthcare system, and save the patients and clinics valuable resources.",
          "link": "http://arxiv.org/abs/2106.03905",
          "publishedOn": "2021-06-09T02:01:48.945Z",
          "wordCount": 572,
          "title": "AutoPtosis. (arXiv:2106.03905v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Flow-based generative models have shown excellent ability to explicitly learn\nthe probability density function of data via a sequence of invertible\ntransformations. Yet, modeling long-range dependencies over normalizing flows\nremains understudied. To fill the gap, in this paper, we introduce two types of\ninvertible attention mechanisms for generative flow models. To be precise, we\npropose map-based and scaled dot-product attention for unconditional and\nconditional generative flow models. The key idea is to exploit split-based\nattention mechanisms to learn the attention weights and input representations\non every two splits of flow feature maps. Our method provides invertible\nattention modules with tractable Jacobian determinants, enabling seamless\nintegration of it at any positions of the flow-based models. The proposed\nattention mechanism can model the global data dependencies, leading to more\ncomprehensive flow models. Evaluation on multiple generation tasks demonstrates\nthat the introduced attention flow idea results in efficient flow models and\ncompares favorably against the state-of-the-art unconditional and conditional\ngenerative flow methods.",
          "link": "http://arxiv.org/abs/2106.03959",
          "publishedOn": "2021-06-09T02:01:48.939Z",
          "wordCount": 588,
          "title": "Generative Flows with Invertible Attentions. (arXiv:2106.03959v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04013",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mufan Bill Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nica_M/0/1/0/all/0/1\">Mihai Nica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>",
          "description": "Theoretical results show that neural networks can be approximated by Gaussian\nprocesses in the infinite-width limit. However, for fully connected networks,\nit has been previously shown that for any fixed network width, $n$, the\nGaussian approximation gets worse as the network depth, $d$, increases. Given\nthat modern networks are deep, this raises the question of how well modern\narchitectures, like ResNets, are captured by the infinite-width limit. To\nprovide a better approximation, we study ReLU ResNets in the\ninfinite-depth-and-width limit, where both depth and width tend to infinity as\ntheir ratio, $d/n$, remains constant. In contrast to the Gaussian\ninfinite-width limit, we show theoretically that the network exhibits\nlog-Gaussian behaviour at initialization in the infinite-depth-and-width limit,\nwith parameters depending on the ratio $d/n$. Using Monte Carlo simulations, we\ndemonstrate that even basic properties of standard ResNet architectures are\npoorly captured by the Gaussian limit, but remarkably well captured by our\nlog-Gaussian limit. Moreover, our analysis reveals that ReLU ResNets at\ninitialization are hypoactivated: fewer than half of the ReLUs are activated.\nAdditionally, we calculate the interlayer correlations, which have the effect\nof exponentially increasing the variance of the network output. Based on our\nanalysis, we introduce Balanced ResNets, a simple architecture modification,\nwhich eliminates hypoactivation and interlayer correlations and is more\namenable to theoretical analysis.",
          "link": "http://arxiv.org/abs/2106.04013",
          "publishedOn": "2021-06-09T02:01:48.932Z",
          "wordCount": 650,
          "title": "The Future is Log-Gaussian: ResNets and Their Infinite-Depth-and-Width Limit at Initialization. (arXiv:2106.04013v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1\">Debadeepta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shital Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1\">Sebastien Bubeck</a>",
          "description": "The fundamental problem in Neural Architecture Search (NAS) is to efficiently\nfind high-performing architectures from a given search space. We propose a\nsimple but powerful method which we call FEAR, for ranking architectures in any\nsearch space. FEAR leverages the viewpoint that neural networks are powerful\nnon-linear feature extractors. First, we train different architectures in the\nsearch space to the same training or validation error. Then, we compare the\nusefulness of the features extracted by each architecture. We do so with a\nquick training keeping most of the architecture frozen. This gives fast\nestimates of the relative performance. We validate FEAR on Natsbench topology\nsearch space on three different datasets against competing baselines and show\nstrong ranking correlation especially compared to recently proposed zero-cost\nmethods. FEAR particularly excels at ranking high-performance architectures in\nthe search space. When used in the inner loop of discrete search algorithms\nlike random search, FEAR can cut down the search time by approximately 2.4X\nwithout losing accuracy. We additionally empirically study very recently\nproposed zero-cost measures for ranking and find that they breakdown in ranking\nperformance as training proceeds and also that data-agnostic ranking scores\nwhich ignore the dataset do not generalize across dissimilar datasets.",
          "link": "http://arxiv.org/abs/2106.04010",
          "publishedOn": "2021-06-09T02:01:48.923Z",
          "wordCount": 633,
          "title": "FEAR: A Simple Lightweight Method to Rank Architectures. (arXiv:2106.04010v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1\">Ekin Aky&#xfc;rek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Sequence-to-sequence transduction is the core problem in language processing\napplications as diverse as semantic parsing, machine translation, and\ninstruction following. The neural network models that provide the dominant\nsolution to these problems are brittle, especially in low-resource settings:\nthey fail to generalize correctly or systematically from small datasets. Past\nwork has shown that many failures of systematic generalization arise from\nneural models' inability to disentangle lexical phenomena from syntactic ones.\nTo address this, we augment neural decoders with a lexical translation\nmechanism that generalizes existing copy mechanisms to incorporate learned,\ndecontextualized, token-level translation rules. We describe how to initialize\nthis mechanism using a variety of lexicon learning algorithms, and show that it\nimproves systematic generalization on a diverse set of sequence modeling tasks\ndrawn from cognitive science, formal semantics, and machine translation.",
          "link": "http://arxiv.org/abs/2106.03993",
          "publishedOn": "2021-06-09T02:01:48.917Z",
          "wordCount": 559,
          "title": "Lexicon Learning for Few-Shot Neural Sequence Modeling. (arXiv:2106.03993v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04018",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Block_A/0/1/0/all/0/1\">Adam Block</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jia_Z/0/1/0/all/0/1\">Zeyu Jia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Polyanskiy_Y/0/1/0/all/0/1\">Yury Polyanskiy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rakhlin_A/0/1/0/all/0/1\">Alexander Rakhlin</a>",
          "description": "It has long been thought that high-dimensional data encountered in many\npractical machine learning tasks have low-dimensional structure, i.e., the\nmanifold hypothesis holds. A natural question, thus, is to estimate the\nintrinsic dimension of a given population distribution from a finite sample. We\nintroduce a new estimator of the intrinsic dimension and provide finite sample,\nnon-asymptotic guarantees. We then apply our techniques to get new sample\ncomplexity bounds for Generative Adversarial Networks (GANs) depending only on\nthe intrinsic dimension of the data.",
          "link": "http://arxiv.org/abs/2106.04018",
          "publishedOn": "2021-06-09T02:01:48.900Z",
          "wordCount": 500,
          "title": "Intrinsic Dimension Estimation. (arXiv:2106.04018v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1\">Stephen McAleer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanier_J/0/1/0/all/0/1\">John Lanier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1\">Roy Fox</a>",
          "description": "Machine learning algorithms often make decisions on behalf of agents with\nvaried and sometimes conflicting interests. In domains where agents can choose\nto take their own action or delegate their action to a central mediator, an\nopen question is how mediators should take actions on behalf of delegating\nagents. The main existing approach uses delegating agents to punish\nnon-delegating agents in an attempt to get all agents to delegate, which tends\nto be costly for all. We introduce a Pareto Mediator which aims to improve\noutcomes for delegating agents without making any of them worse off. Our\nexperiments in random normal form games, a restaurant recommendation game, and\na reinforcement learning sequential social dilemma show that the Pareto\nMediator greatly increases social welfare. Also, even when the Pareto Mediator\nis based on an incorrect model of agent utility, performance gracefully\ndegrades to the pre-intervention level, due to the individual autonomy\npreserved by the voluntary mediator.",
          "link": "http://arxiv.org/abs/2106.03927",
          "publishedOn": "2021-06-09T02:01:48.874Z",
          "wordCount": 602,
          "title": "Improving Social Welfare While Preserving Autonomy via a Pareto Mediator. (arXiv:2106.03927v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_P/0/1/0/all/0/1\">P. H. O. Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerqueira_A/0/1/0/all/0/1\">A. S. Cerqueira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepomuceno_E/0/1/0/all/0/1\">E. G. Nepomuceno</a>",
          "description": "This work presents a novel technique that integrates the methodologies of\nmachine learning and system identification to solve multiclass problems. Such\nan approach allows to extract and select sets of representative features with\nreduced dimensionality, as well as predicts categorical outputs. The efficiency\nof the method was tested by running case studies investigated in machine\nlearning, obtaining better absolute results when compared with classical\nclassification algorithms.",
          "link": "http://arxiv.org/abs/2106.04021",
          "publishedOn": "2021-06-09T02:01:48.868Z",
          "wordCount": 528,
          "title": "Hybrid Method Based on NARX models and Machine Learning for Pattern Recognition. (arXiv:2106.04021v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>",
          "description": "Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.",
          "link": "http://arxiv.org/abs/2105.11601",
          "publishedOn": "2021-06-09T00:28:49.163Z",
          "wordCount": 641,
          "title": "Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1\">Wei Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1\">Zhenglun Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weiwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jiexiong Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Caiwen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1\">Bin Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>",
          "description": "Transformer-based deep learning models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. In this paper, we\npropose a compression-compilation co-design framework that can guarantee the\nidentified model to meet both resource and real-time specifications of mobile\ndevices. Our framework applies a compiler-aware neural architecture\noptimization method (CANAO), which can generate the optimal compressed model\nthat balances both accuracy and latency. We are able to achieve up to 7.8x\nspeedup compared with TensorFlow-Lite with only minor accuracy loss. We present\ntwo types of BERT applications on mobile devices: Question Answering (QA) and\nText Generation. Both can be executed in real-time with latency as low as 45ms.\nVideos for demonstrating the framework can be found on\nhttps://www.youtube.com/watch?v=_WIRvK_2PZI",
          "link": "http://arxiv.org/abs/2106.00526",
          "publishedOn": "2021-06-08T22:44:25.107Z",
          "wordCount": 587,
          "title": "A Compression-Compilation Framework for On-mobile Real-time BERT Applications. (arXiv:2106.00526v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jialu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cong Yu</a>",
          "description": "Effectively modeling text-rich fresh content such as news articles at\ndocument-level is a challenging problem. To ensure a content-based model\ngeneralize well to a broad range of applications, it is critical to have a\ntraining dataset that is large beyond the scale of human labels while achieving\ndesired quality. In this work, we address those two challenges by proposing a\nnovel approach to mine semantically-relevant fresh documents, and their topic\nlabels, with little human supervision. Meanwhile, we design a multitask model\ncalled NewsEmbed that alternatively trains a contrastive learning with a\nmulti-label classification to derive a universal document encoder. We show that\nthe proposed approach can provide billions of high quality organic training\nexamples and can be naturally extended to multilingual setting where texts in\ndifferent languages are encoded in the same semantic space. We experimentally\ndemonstrate NewsEmbed's competitive performance across multiple natural\nlanguage understanding tasks, both supervised and unsupervised.",
          "link": "http://arxiv.org/abs/2106.00590",
          "publishedOn": "2021-06-08T22:44:25.008Z",
          "wordCount": 603,
          "title": "NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00444",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1\">Tor Lattimore</a>",
          "description": "We analyse adversarial bandit convex optimisation with an adversary that is\nrestricted to playing functions of the form $f_t(x) = g_t(\\langle x,\n\\theta\\rangle)$ for convex $g_t : \\mathbb R \\to \\mathbb R$ and unknown $\\theta\n\\in \\mathbb R^d$ that is homogeneous over time. We provide a short\ninformation-theoretic proof that the minimax regret is at most $O(d \\sqrt{n}\n\\log(n \\operatorname{diam}(\\mathcal K)))$ where $n$ is the number of\ninteractions, $d$ the dimension and $\\operatorname{diam}(\\mathcal K)$ is the\ndiameter of the constraint set.",
          "link": "http://arxiv.org/abs/2106.00444",
          "publishedOn": "2021-06-08T22:44:24.996Z",
          "wordCount": 535,
          "title": "Minimax Regret for Bandit Convex Optimisation of Ridge Functions. (arXiv:2106.00444v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuanwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huaijun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingchao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jinyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wentao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1\">Bin Cui</a>",
          "description": "Black-box optimization (BBO) has a broad range of applications, including\nautomatic machine learning, engineering, physics, and experimental design.\nHowever, it remains a challenge for users to apply BBO methods to their\nproblems at hand with existing software packages, in terms of applicability,\nperformance, and efficiency. In this paper, we build OpenBox, an open-source\nand general-purpose BBO service with improved usability. The modular design\nbehind OpenBox also facilitates flexible abstraction and optimization of basic\nBBO components that are common in other existing systems. OpenBox is\ndistributed, fault-tolerant, and scalable. To improve efficiency, OpenBox\nfurther utilizes \"algorithm agnostic\" parallelization and transfer learning.\nOur experimental results demonstrate the effectiveness and efficiency of\nOpenBox compared to existing systems.",
          "link": "http://arxiv.org/abs/2106.00421",
          "publishedOn": "2021-06-08T22:44:24.840Z",
          "wordCount": 589,
          "title": "OpenBox: A Generalized Black-box Optimization Service. (arXiv:2106.00421v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00106",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gonzalez_E/0/1/0/all/0/1\">Efrain Gonzalez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Abudia_M/0/1/0/all/0/1\">Moad Abudia</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jury_M/0/1/0/all/0/1\">Michael Jury</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rosenfeld_J/0/1/0/all/0/1\">Joel A. Rosenfeld</a>",
          "description": "This article addresses several longstanding misconceptions concerning Koopman\noperators, including the existence of lattices of eigenfunctions, common\neigenfunctions between Koopman operators, and boundedness and compactness of\nKoopman operators, among others. Counterexamples are provided for each\nmisconception. This manuscript also proves that the Gaussian RBF's native space\nonly supports bounded Koopman operator corresponding to affine dynamics, which\nshows that the assumption of boundedness is very limiting. A framework for DMD\nis presented that requires only densely defined Koopman operators over\nreproducing kernel Hilbert spaces, and the effectiveness of this approach is\ndemonstrated through reconstruction examples.",
          "link": "http://arxiv.org/abs/2106.00106",
          "publishedOn": "2021-06-08T22:44:24.822Z",
          "wordCount": 535,
          "title": "Anti-Koopmanism. (arXiv:2106.00106v2 [math.FA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Stochastic gradient descent (SGD) with stochastic momentum is popular in\nnonconvex stochastic optimization and particularly for the training of deep\nneural networks. In standard SGD, parameters are updated by improving along the\npath of the gradient at the current iterate on a batch of examples, where the\naddition of a ``momentum'' term biases the update in the direction of the\nprevious change in parameters. In non-stochastic convex optimization one can\nshow that a momentum adjustment provably reduces convergence time in many\nsettings, yet such results have been elusive in the stochastic and non-convex\nsettings. At the same time, a widely-observed empirical phenomenon is that in\ntraining deep networks stochastic momentum appears to significantly improve\nconvergence time, variants of it have flourished in the development of other\npopular update methods, e.g. ADAM [KB15], AMSGrad [RKK18], etc. Yet theoretical\njustification for the use of stochastic momentum has remained a significant\nopen question. In this paper we propose an answer: stochastic momentum improves\ndeep network training because it modifies SGD to escape saddle points faster\nand, consequently, to more quickly find a second order stationary point. Our\ntheoretical results also shed light on the related question of how to choose\nthe ideal momentum parameter--our analysis suggests that $\\beta \\in [0,1)$\nshould be large (close to 1), which comports with empirical findings. We also\nprovide experimental findings that further validate these conclusions.",
          "link": "http://arxiv.org/abs/2106.02985",
          "publishedOn": "2021-06-08T02:20:28.095Z",
          "wordCount": 653,
          "title": "Escaping Saddle Points Faster with Stochastic Momentum. (arXiv:2106.02985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1\">Wamiq Reyaz Para</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1\">Tom Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "Computer-aided design (CAD) is the most widely used modeling approach for\ntechnical design. The typical starting point in these designs is 2D sketches\nwhich can later be extruded and combined to obtain complex three-dimensional\nassemblies. Such sketches are typically composed of parametric primitives, such\nas points, lines, and circular arcs, augmented with geometric constraints\nlinking the primitives, such as coincidence, parallelism, or orthogonality.\nSketches can be represented as graphs, with the primitives as nodes and the\nconstraints as edges. Training a model to automatically generate CAD sketches\ncan enable several novel workflows, but is challenging due to the complexity of\nthe graphs and the heterogeneity of the primitives and constraints. In\nparticular, each type of primitive and constraint may require a record of\ndifferent size and parameter types. We propose SketchGen as a generative model\nbased on a transformer architecture to address the heterogeneity problem by\ncarefully designing a sequential language for the primitives and constraints\nthat allows distinguishing between different primitive or constraint types and\ntheir parameters, while encouraging our model to re-use information across\nrelated parameters, encoding shared structure. A particular highlight of our\nwork is the ability to produce primitives linked via constraints that enables\nthe final output to be further regularized via a constraint solver. We evaluate\nour model by demonstrating constraint prediction for given sets of primitives\nand full sketch generation from scratch, showing that our approach\nsignificantly out performs the state-of-the-art in CAD sketch generation.",
          "link": "http://arxiv.org/abs/2106.02711",
          "publishedOn": "2021-06-08T02:20:28.076Z",
          "wordCount": 688,
          "title": "SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "Meta-learning enables algorithms to quickly learn a newly encountered task\nwith just a few labeled examples by transferring previously learned knowledge.\nHowever, the bottleneck of current meta-learning algorithms is the requirement\nof a large number of meta-training tasks, which may not be accessible in\nreal-world scenarios. To address the challenge that available tasks may not\ndensely sample the space of tasks, we propose to augment the task set through\ninterpolation. By meta-learning with task interpolation (MLTI), our approach\neffectively generates additional tasks by randomly sampling a pair of tasks and\ninterpolating the corresponding features and labels. Under both gradient-based\nand metric-based meta-learning settings, our theoretical analysis shows MLTI\ncorresponds to a data-adaptive meta-regularization and further improves the\ngeneralization. Empirically, in our experiments on eight datasets from diverse\ndomains including image recognition, pose prediction, molecule property\nprediction, and medical image classification, we find that the proposed general\nMLTI framework is compatible with representative meta-learning algorithms and\nconsistently outperforms other state-of-the-art strategies.",
          "link": "http://arxiv.org/abs/2106.02695",
          "publishedOn": "2021-06-08T02:20:28.057Z",
          "wordCount": 580,
          "title": "Meta-Learning with Fewer Tasks through Task Interpolation. (arXiv:2106.02695v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02964",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1\">Rajdeep Kumar Nath</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1\">Himanshu Thapliyal</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1\">Travis S. Humble</a>",
          "description": "Optimizing the training of a machine learning pipeline helps in reducing\ntraining costs and improving model performance. One such optimizing strategy is\nquantum annealing, which is an emerging computing paradigm that has shown\npotential in optimizing the training of a machine learning model. The\nimplementation of a physical quantum annealer has been realized by D-Wave\nsystems and is available to the research community for experiments. Recent\nexperimental results on a variety of machine learning applications using\nquantum annealing have shown interesting results where the performance of\nclassical machine learning techniques is limited by limited training data and\nhigh dimensional features. This article explores the application of D-Wave's\nquantum annealer for optimizing machine learning pipelines for real-world\nclassification problems. We review the application domains on which a physical\nquantum annealer has been used to train machine learning classifiers. We\ndiscuss and analyze the experiments performed on the D-Wave quantum annealer\nfor applications such as image recognition, remote sensing imagery,\ncomputational biology, and particle physics. We discuss the possible advantages\nand the problems for which quantum annealing is likely to be advantageous over\nclassical computation.",
          "link": "http://arxiv.org/abs/2106.02964",
          "publishedOn": "2021-06-08T02:20:28.031Z",
          "wordCount": 628,
          "title": "A Review of Machine Learning Classification Using Quantum Annealing for Real-world Applications. (arXiv:2106.02964v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1\">Mai ElSherief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Existing work on automated hate speech classification assumes that the\ndataset is fixed and the classes are pre-defined. However, the amount of data\nin social media increases every day, and the hot topics changes rapidly,\nrequiring the classifiers to be able to continuously adapt to new data without\nforgetting the previously learned knowledge. This ability, referred to as\nlifelong learning, is crucial for the real-word application of hate speech\nclassifiers in social media. In this work, we propose lifelong learning of hate\nspeech classification on social media. To alleviate catastrophic forgetting, we\npropose to use Variational Representation Learning (VRL) along with a memory\nmodule based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural\nNetwork). Experimentally, we show that combining variational representation\nlearning and the LB-SOINN memory module achieves better performance than the\ncommonly-used lifelong learning techniques.",
          "link": "http://arxiv.org/abs/2106.02821",
          "publishedOn": "2021-06-08T02:20:27.999Z",
          "wordCount": 568,
          "title": "Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yao-Hung Hubert Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Martin Q. Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "Self-supervised learning is a form of unsupervised learning that leverages\nrich information in data to learn representations. However, data sometimes\ncontains certain information that may be undesirable for downstream tasks. For\ninstance, gender information may lead to biased decisions on many\ngender-irrelevant tasks. In this paper, we develop conditional contrastive\nlearning to remove undesirable information in self-supervised representations.\nTo remove the effect of the undesirable variable, our proposed approach\nconditions on the undesirable variable (i.e., by fixing the variations of it)\nduring the contrastive learning process. In particular, inspired by the\ncontrastive objective InfoNCE, we introduce Conditional InfoNCE (C-InfoNCE),\nand its computationally efficient variant, Weak-Conditional InfoNCE\n(WeaC-InfoNCE), for conditional contrastive learning. We demonstrate\nempirically that our methods can successfully learn self-supervised\nrepresentations for downstream tasks while removing a great level of\ninformation related to the undesirable variables. We study three scenarios,\neach with a different type of undesirable variables: task-irrelevant\nmeta-information for self-supervised speech representation learning, sensitive\nattributes for fair representation learning, and domain specification for\nmulti-domain visual representation learning.",
          "link": "http://arxiv.org/abs/2106.02866",
          "publishedOn": "2021-06-08T02:20:27.986Z",
          "wordCount": 602,
          "title": "Conditional Contrastive Learning: Removing Undesirable Information in Self-Supervised Representations. (arXiv:2106.02866v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Huaisheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Ruiqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuhui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>",
          "description": "Imbalanced classification on graphs is ubiquitous yet challenging in many\nreal-world applications, such as fraudulent node detection. Recently, graph\nneural networks (GNNs) have shown promising performance on many network\nanalysis tasks. However, most existing GNNs have almost exclusively focused on\nthe balanced networks, and would get unappealing performance on the imbalanced\nnetworks. To bridge this gap, in this paper, we present a generative\nadversarial graph network model, called ImGAGN to address the imbalanced\nclassification problem on graphs. It introduces a novel generator for graph\nstructure data, named GraphGenerator, which can simulate both the minority\nclass nodes' attribute distribution and network topological structure\ndistribution by generating a set of synthetic minority nodes such that the\nnumber of nodes in different classes can be balanced. Then a graph\nconvolutional network (GCN) discriminator is trained to discriminate between\nreal nodes and fake (i.e., generated) nodes, and also between minority nodes\nand majority nodes on the synthetic balanced network. To validate the\neffectiveness of the proposed method, extensive experiments are conducted on\nfour real-world imbalanced network datasets. Experimental results demonstrate\nthat the proposed method ImGAGN outperforms state-of-the-art algorithms for\nsemi-supervised imbalanced node classification task.",
          "link": "http://arxiv.org/abs/2106.02817",
          "publishedOn": "2021-06-08T02:20:27.959Z",
          "wordCount": 626,
          "title": "ImGAGN:Imbalanced Network Embedding via Generative Adversarial Graph Networks. (arXiv:2106.02817v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_A/0/1/0/all/0/1\">Akihisa Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuramata_M/0/1/0/all/0/1\">Michiya Kuramata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majima_K/0/1/0/all/0/1\">Kaito Majima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1\">Haruka Kiyohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondo_K/0/1/0/all/0/1\">Kensho Kondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1\">Kazuhide Nakata</a>",
          "description": "In recent years, machine learning and AI have been introduced in many\nindustrial fields. In fields such as finance, medicine, and autonomous driving,\nwhere the inference results of a model may have serious consequences, high\ninterpretability as well as prediction accuracy is required. In this study, we\npropose CGA2M+, which is based on the Generalized Additive 2 Model (GA2M) and\ndiffers from it in two major ways. The first is the introduction of\nmonotonicity. Imposing monotonicity on some functions based on an analyst's\nknowledge is expected to improve not only interpretability but also\ngeneralization performance. The second is the introduction of a higher-order\nterm: given that GA2M considers only second-order interactions, we aim to\nbalance interpretability and prediction accuracy by introducing a higher-order\nterm that can capture higher-order interactions. In this way, we can improve\nprediction performance without compromising interpretability by applying\nlearning innovation. Numerical experiments showed that the proposed model has\nhigh predictive performance and interpretability. Furthermore, we confirmed\nthat generalization performance is improved by introducing monotonicity.",
          "link": "http://arxiv.org/abs/2106.02836",
          "publishedOn": "2021-06-08T02:20:27.896Z",
          "wordCount": 598,
          "title": "Constrained Generalized Additive 2 Model with Consideration of High-Order Interactions. (arXiv:2106.02836v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Liang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weijun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qianlan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Learning sparse coordination graphs adaptive to the coordination dynamics\namong agents is a long-standing problem in cooperative multi-agent learning.\nThis paper studies this problem by proposing several value-based and\nobservation-based schemes for learning dynamic topologies and evaluating them\non a new Multi-Agent COordination (MACO) benchmark. The benchmark collects\nclassic coordination problems in the literature, increases their difficulty,\nand classifies them into different types. By analyzing the individual\nadvantages of each learning scheme on each type of problem and their overall\nperformance, we propose a novel method using the variance of utility difference\nfunctions to learn context-aware sparse coordination topologies. Moreover, our\nmethod learns action representations that effectively reduce the influence of\nutility functions' estimation errors on graph construction. Experiments show\nthat our method significantly outperforms dense and static topologies across\nthe MACO and StarCraft II micromanagement benchmark.",
          "link": "http://arxiv.org/abs/2106.02886",
          "publishedOn": "2021-06-08T02:20:27.884Z",
          "wordCount": 559,
          "title": "Context-Aware Sparse Deep Coordination Graphs. (arXiv:2106.02886v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rafid Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Marc T. Law</a>",
          "description": "Given restrictions on the availability of data, active learning is the\nprocess of training a model with limited labeled data by selecting a core\nsubset of an unlabeled data pool to label. Although selecting the most useful\npoints for training is an optimization problem, the scale of deep learning data\nsets forces most selection strategies to employ efficient heuristics. Instead,\nwe propose a new integer optimization problem for selecting a core set that\nminimizes the discrete Wasserstein distance from the unlabeled pool. We\ndemonstrate that this problem can be tractably solved with a Generalized\nBenders Decomposition algorithm. Our strategy requires high-quality latent\nfeatures which we obtain by unsupervised learning on the unlabeled pool.\nNumerical results on several data sets show that our optimization approach is\ncompetitive with baselines and particularly outperforms them in the low budget\nregime where less than one percent of the data set is labeled.",
          "link": "http://arxiv.org/abs/2106.02968",
          "publishedOn": "2021-06-08T02:20:27.867Z",
          "wordCount": 582,
          "title": "Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Classical recommender system methods typically face the filter bubble problem\nwhen users only receive recommendations of their familiar items, making them\nbored and dissatisfied. To address the filter bubble problem, unexpected\nrecommendations have been proposed to recommend items significantly deviating\nfrom user's prior expectations and thus surprising them by presenting \"fresh\"\nand previously unexplored items to the users. In this paper, we describe a\nnovel Personalized Unexpected Recommender System (PURS) model that incorporates\nunexpectedness into the recommendation process by providing multi-cluster\nmodeling of user interests in the latent space and personalized unexpectedness\nvia the self-attention mechanism and via selection of an appropriate unexpected\nactivation function. Extensive offline experiments on three real-world datasets\nillustrate that the proposed PURS model significantly outperforms the\nstate-of-the-art baseline approaches in terms of both accuracy and\nunexpectedness measures. In addition, we conduct an online A/B test at a major\nvideo platform Alibaba-Youku, where our model achieves over 3\\% increase in the\naverage video view per user metric. The proposed model is in the process of\nbeing deployed by the company.",
          "link": "http://arxiv.org/abs/2106.02771",
          "publishedOn": "2021-06-08T02:20:27.861Z",
          "wordCount": 609,
          "title": "PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:27.854Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.06471",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1\">Antoine Dedieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hazimeh_H/0/1/0/all/0/1\">Hussein Hazimeh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>",
          "description": "We consider a discrete optimization formulation for learning sparse\nclassifiers, where the outcome depends upon a linear combination of a small\nsubset of features. Recent work has shown that mixed integer programming (MIP)\ncan be used to solve (to optimality) $\\ell_0$-regularized regression problems\nat scales much larger than what was conventionally considered possible. Despite\ntheir usefulness, MIP-based global optimization approaches are significantly\nslower compared to the relatively mature algorithms for $\\ell_1$-regularization\nand heuristics for nonconvex regularized problems. We aim to bridge this gap in\ncomputation times by developing new MIP-based algorithms for\n$\\ell_0$-regularized classification. We propose two classes of scalable\nalgorithms: an exact algorithm that can handle $p\\approx 50,000$ features in a\nfew minutes, and approximate algorithms that can address instances with\n$p\\approx 10^6$ in times comparable to the fast $\\ell_1$-based algorithms. Our\nexact algorithm is based on the novel idea of \\textsl{integrality generation},\nwhich solves the original problem (with $p$ binary variables) via a sequence of\nmixed integer programs that involve a small number of binary variables. Our\napproximate algorithms are based on coordinate descent and local combinatorial\nsearch. In addition, we present new estimation error bounds for a class of\n$\\ell_0$-regularized estimators. Experiments on real and synthetic data\ndemonstrate that our approach leads to models with considerably improved\nstatistical performance (especially, variable selection) when compared to\ncompeting methods.",
          "link": "http://arxiv.org/abs/2001.06471",
          "publishedOn": "2021-06-08T02:20:27.845Z",
          "wordCount": 679,
          "title": "Learning Sparse Classifiers: Continuous and Mixed Integer Optimization Perspectives. (arXiv:2001.06471v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajan_S/0/1/0/all/0/1\">Subramaniam Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khaled_B/0/1/0/all/0/1\">Bilal Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shyamsunder_L/0/1/0/all/0/1\">Loukham Shyamsunder</a>",
          "description": "Numerous theories of failure have been postulated and implemented in various\ncommercial programs for composite materials. Even the best theories have had\nlimited success in predicting damage and failure in validation exercises. In\nview of this background, many researchers have started exploring the use of\nmultiscale modeling to improve the fidelity of the modeling and simulation of\nvarious structural and materials systems. In this paper, a multi-scale modeling\nscheme is used to illustrate how a combination of virtual and laboratory\ntesting programs can be used to generate a point cloud of failure surface data\nthat can then be queried during finite element analysis at the continuum scale\nto ascertain if the onset of failure has occurred. The k-nearest neighbor\n(k-NN) classification concept is used to obtain the answer to the query. A\nlinear, elastic, static finite element example using a unidirectional composite\nshows that the framework can be generated and used effectively and efficiently\nwith the possibility to extend the approach for all types of composite\narchitectures and behaviors.",
          "link": "http://arxiv.org/abs/2106.02714",
          "publishedOn": "2021-06-08T02:20:27.824Z",
          "wordCount": 598,
          "title": "Point Cloud Failure Criterion for Composites using k-Nearest Neighbor Classification. (arXiv:2106.02714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weiran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1\">Xin Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "Graph Convolutional Network (GCN) is an emerging technique for information\nretrieval (IR) applications. While GCN assumes the homophily property of a\ngraph, real-world graphs are never perfect: the local structure of a node may\ncontain discrepancy, e.g., the labels of a node's neighbors could vary. This\npushes us to consider the discrepancy of local structure in GCN modeling.\nExisting work approaches this issue by introducing an additional module such as\ngraph attention, which is expected to learn the contribution of each neighbor.\nHowever, such module may not work reliably as expected, especially when there\nlacks supervision signal, e.g., when the labeled data is small. Moreover,\nexisting methods focus on modeling the nodes in the training data, and never\nconsider the local structure discrepancy of testing nodes.\n\nThis work focuses on the local structure discrepancy issue for testing nodes,\nwhich has received little scrutiny. From a novel perspective of causality, we\ninvestigate whether a GCN should trust the local structure of a testing node\nwhen predicting its label. To this end, we analyze the working mechanism of GCN\nwith causal graph, estimating the causal effect of a node's local structure for\nthe prediction. The idea is simple yet effective: given a trained GCN model, we\nfirst intervene the prediction by blocking the graph structure; we then compare\nthe original prediction with the intervened prediction to assess the causal\neffect of the local structure on the prediction. Through this way, we can\neliminate the impact of local structure discrepancy and make more accurate\nprediction. Extensive experiments on seven node classification datasets show\nthat our method effectively enhances the inference stage of GCN.",
          "link": "http://arxiv.org/abs/2010.11797",
          "publishedOn": "2021-06-08T02:20:26.099Z",
          "wordCount": 743,
          "title": "Should Graph Convolution Trust Neighbors? A Simple Causal Inference Method. (arXiv:2010.11797v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Mandy Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Anqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyk_K/0/1/0/all/0/1\">Karl Van Wyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellaert_F/0/1/0/all/0/1\">Frank Dellaert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1\">Byron Boots</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_N/0/1/0/all/0/1\">Nathan Ratliff</a>",
          "description": "Imitation learning (IL) is a frequently used approach for data-efficient\npolicy learning. Many IL methods, such as Dataset Aggregation (DAgger), combat\nchallenges like distributional shift by interacting with oracular experts.\nUnfortunately, assuming access to oracular experts is often unrealistic in\npractice; data used in IL frequently comes from offline processes such as\nlead-through or teleoperation. In this paper, we present a novel imitation\nlearning technique called Collocation for Demonstration Encoding (CoDE) that\noperates on only a fixed set of trajectory demonstrations. We circumvent\nchallenges with methods like back-propagation-through-time by introducing an\nauxiliary trajectory network, which takes inspiration from collocation\ntechniques in optimal control. Our method generalizes well and more accurately\nreproduces the demonstrated behavior with fewer guiding trajectories when\ncompared to standard behavioral cloning methods. We present simulation results\non a 7-degree-of-freedom (DoF) robotic manipulator that learns to exhibit\nlifting, target-reaching, and obstacle avoidance behaviors.",
          "link": "http://arxiv.org/abs/2105.03019",
          "publishedOn": "2021-06-08T02:20:26.066Z",
          "wordCount": 612,
          "title": "Imitation Learning via Simultaneous Optimization of Policies and Auxiliary Trajectories. (arXiv:2105.03019v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gohari_P/0/1/0/all/0/1\">Parham Gohari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_M/0/1/0/all/0/1\">Matthew Hale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "Kickstarting deep reinforcement learning algorithms facilitate a\nteacher-student relationship among the agents and allow for a well-performing\nteacher to share demonstrations with a student to expedite the student's\ntraining. However, despite the known benefits, the demonstrations may contain\nsensitive information about the teacher's training data and existing\nkickstarting methods do not take any measures to protect it. Therefore, we use\nthe framework of differential privacy to develop a mechanism that securely\nshares the teacher's demonstrations with the student. The mechanism allows for\nthe teacher to decide upon the accuracy of its demonstrations with respect to\nthe privacy budget that it consumes, thereby granting the teacher full control\nover its data privacy. We then develop a kickstarted deep reinforcement\nlearning algorithm for the student that is privacy-aware because we calibrate\nits objective with the parameters of the teacher's privacy mechanism. The\nprivacy-aware design of the algorithm makes it possible to kickstart the\nstudent's learning despite the perturbations induced by the privacy mechanism.\nFrom numerical experiments, we highlight three empirical results: (i) the\nalgorithm succeeds in expediting the student's learning, (ii) the student\nconverges to a performance level that was not possible without the\ndemonstrations, and (iii) the student maintains its enhanced performance even\nafter the teacher stops sharing useful demonstrations due to its privacy budget\nconstraints.",
          "link": "http://arxiv.org/abs/2102.09599",
          "publishedOn": "2021-06-08T02:20:26.023Z",
          "wordCount": 684,
          "title": "Privacy-Preserving Kickstarting Deep Reinforcement Learning with Privacy-Aware Learners. (arXiv:2102.09599v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Su Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Le Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "Meta-learning can extract an inductive bias from previous learning experience\nand assist the training processes of new tasks. It is often realized through\noptimizing a meta-model with the evaluation loss of a series of task-specific\nsolvers. Most existing algorithms sample non-overlapping $\\mathit{support}$\nsets and $\\mathit{query}$ sets to train and evaluate the solvers respectively\ndue to simplicity ($\\mathcal{S}/\\mathcal{Q}$ protocol). However, another\nevaluation method that assesses the discrepancy between the solver and a target\nmodel is short of research ($\\mathcal{S}/\\mathcal{T}$ protocol).\n$\\mathcal{S}/\\mathcal{T}$ protocol has unique advantages such as offering more\ninformative supervision, but it is computationally expensive. This paper looks\ninto this special evaluation method and takes a step towards putting it into\npractice. We find that with a small ratio of tasks armed with target models,\nclassic meta-learning algorithms can be improved a lot without consuming many\nresources. Furthermore, we empirically verify the effectiveness of\n$\\mathcal{S}/\\mathcal{T}$ protocol in a typical application of meta-learning,\n$\\mathit{i.e.}$, few-shot learning. In detail, after constructing target models\nby fine-tuning the pre-trained network on those hard tasks, we match the\ntask-specific solvers to target models via knowledge distillation. Experiments\ndemonstrate the superiority of our proposal.",
          "link": "http://arxiv.org/abs/2104.03736",
          "publishedOn": "2021-06-08T02:20:25.998Z",
          "wordCount": 645,
          "title": "Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhenghai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1\">Jing-Cheng Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shengyi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Feng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>",
          "description": "In reinforcement learning, experience replay stores past samples for further\nreuse. Prioritized sampling is a promising technique to better utilize these\nsamples. Previous criteria of prioritization include TD error, recentness and\ncorrective feedback, which are mostly heuristically designed. In this work, we\nstart from the regret minimization objective, and obtain an optimal\nprioritization strategy for Bellman update that can directly maximize the\nreturn of the policy. The theory suggests that data with higher hindsight TD\nerror, better on-policiness and more accurate Q value should be assigned with\nhigher weights during sampling. Thus most previous criteria only consider this\nstrategy partially. We not only provide theoretical justifications for previous\ncriteria, but also propose two new methods to compute the prioritization\nweight, namely ReMERN and ReMERT. ReMERN learns an error network, while ReMERT\nexploits the temporal ordering of states. Both methods outperform previous\nprioritized sampling algorithms in challenging RL benchmarks, including MuJoCo,\nAtari and Meta-World.",
          "link": "http://arxiv.org/abs/2105.07253",
          "publishedOn": "2021-06-08T02:20:25.992Z",
          "wordCount": 604,
          "title": "Regret Minimization Experience Replay. (arXiv:2105.07253v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bechavod_Y/0/1/0/all/0/1\">Yahav Bechavod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1\">Chara Podimata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziani_J/0/1/0/all/0/1\">Juba Ziani</a>",
          "description": "We study the effects of information discrepancy across sub-populations on\ntheir ability to simultaneously improve their features in strategic learning\nsettings. Specifically, we consider a game where a principal deploys a decision\nrule in an attempt to optimize the whole population's welfare, and agents\nstrategically adapt to it to receive better scores. Inspired by real-life\nsettings, such as loan approvals and college admissions, we remove the typical\nassumption made in the strategic learning literature that the decision rule is\nfully known to the agents, and focus on settings where it is inaccessible. In\ntheir lack of knowledge, individuals try to infer this rule by learning from\ntheir peers (e.g., friends and acquaintances who previously applied for a\nloan), naturally forming groups in the population, each with possibly different\ntype and level of information about the decision rule. In our equilibrium\nanalysis, we show that the principal's decision rule optimizing the welfare\nacross subgroups may cause a surprising negative externality; the true quality\nof some of the subgroups can actually deteriorate. On the positive side, we\nshow that in many natural cases, optimal improvement is guaranteed\nsimultaneously for all subgroups in equilibrium. We also characterize the\ndisparity in improvements across subgroups via a measure of their informational\noverlap. Finally, we complement our theoretical analysis with experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2103.01028",
          "publishedOn": "2021-06-08T02:20:25.986Z",
          "wordCount": 692,
          "title": "Information Discrepancy in Strategic Learning. (arXiv:2103.01028v3 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13523",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chi Chen</a>",
          "description": "Directional data consist of observations distributed on a (hyper)sphere, and\nappear in many applied fields, such as astronomy, ecology, and environmental\nscience. This paper studies both statistical and computational problems of\nkernel smoothing for directional data. We generalize the classical mean shift\nalgorithm to directional data, which allows us to identify local modes of the\ndirectional kernel density estimator (KDE). The statistical convergence rates\nof the directional KDE and its derivatives are derived, and the problem of mode\nestimation is examined. We also prove the ascending property of the directional\nmean shift algorithm and investigate a general problem of gradient ascent on\nthe unit hypersphere. To demonstrate the applicability of the algorithm, we\nevaluate it as a mode clustering method on both simulated and real-world data\nsets.",
          "link": "http://arxiv.org/abs/2010.13523",
          "publishedOn": "2021-06-08T02:20:25.979Z",
          "wordCount": 589,
          "title": "Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data. (arXiv:2010.13523v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rolf_E/0/1/0/all/0/1\">Esther Rolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worledge_T/0/1/0/all/0/1\">Theodora Worledge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1\">Benjamin Recht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "Collecting more diverse and representative training data is often touted as a\nremedy for the disparate performance of machine learning predictors across\nsubpopulations. However, a precise framework for understanding how dataset\nproperties like diversity affect learning outcomes is largely lacking. By\ncasting data collection as part of the learning process, we demonstrate that\ndiverse representation in training data is key not only to increasing subgroup\nperformances, but also to achieving population level objectives. Our analysis\nand experiments describe how dataset compositions influence performance and\nprovide constructive results for using trends in existing data, alongside\ndomain knowledge, to help guide intentional, objective-aware dataset design.",
          "link": "http://arxiv.org/abs/2103.03399",
          "publishedOn": "2021-06-08T02:20:25.973Z",
          "wordCount": 576,
          "title": "Representation Matters: Assessing the Importance of Subgroup Allocations in Training Data. (arXiv:2103.03399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1\">T. Mitchell Roddenberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaze_N/0/1/0/all/0/1\">Nicholas Glaze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "We consider the construction of neural network architectures for data on\nsimplicial complexes. In studying maps on the chain complex of a simplicial\ncomplex, we define three desirable properties of a simplicial neural network\narchitecture: namely, permutation equivariance, orientation equivariance, and\nsimplicial awareness. The first two properties respectively account for the\nfact that the node indexing and the simplex orientations in a simplicial\ncomplex are arbitrary. The last property encodes the desirable feature that the\noutput of the neural network depends on the entire simplicial complex and not\non a subset of its dimensions. Based on these properties, we propose a simple\nconvolutional architecture, rooted in tools from algebraic topology, for the\nproblem of trajectory prediction, and show that it obeys all three of these\nproperties when an odd, nonlinear activation function is used. We then\ndemonstrate the effectiveness of this architecture in extrapolating\ntrajectories on synthetic and real datasets, with particular emphasis on the\ngains in generalizability to unseen trajectories.",
          "link": "http://arxiv.org/abs/2102.10058",
          "publishedOn": "2021-06-08T02:20:25.965Z",
          "wordCount": 630,
          "title": "Principled Simplicial Neural Networks for Trajectory Prediction. (arXiv:2102.10058v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Sen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weishen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "Bipartite ranking, which aims to learn a scoring function that ranks positive\nindividuals higher than negative ones from labeled data, is widely adopted in\nvarious applications where sample prioritization is needed. Recently, there\nhave been rising concerns on whether the learned scoring function can cause\nsystematic disparity across different protected groups defined by sensitive\nattributes. While there could be trade-off between fairness and performance, in\nthis paper we propose a model agnostic post-processing framework for balancing\nthem in the bipartite ranking scenario. Specifically, we maximize a weighted\nsum of the utility and fairness by directly adjusting the relative ordering of\nsamples across groups. By formulating this problem as the identification of an\noptimal warping path across different protected groups, we propose a\nnon-parametric method to search for such an optimal path through a dynamic\nprogramming process. Our method is compatible with various classification\nmodels and applicable to a variety of ranking fairness metrics. Comprehensive\nexperiments on a suite of benchmark data sets and two real-world patient\nelectronic health record repositories show that our method can achieve a great\nbalance between the algorithm utility and ranking fairness. Furthermore, we\nexperimentally verify the robustness of our method when faced with the fewer\ntraining samples and the difference between training and testing ranking score\ndistributions.",
          "link": "http://arxiv.org/abs/2006.08267",
          "publishedOn": "2021-06-08T02:20:25.948Z",
          "wordCount": 697,
          "title": "Towards Model-Agnostic Post-Hoc Adjustment for Balancing Ranking Fairness and Algorithm Utility. (arXiv:2006.08267v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04792",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vygon_R/0/1/0/all/0/1\">Roman Vygon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mikhaylovskiy_N/0/1/0/all/0/1\">Nikolay Mikhaylovskiy</a>",
          "description": "In the past few years, triplet loss-based metric embeddings have become a\nde-facto standard for several important computer vision problems, most\nno-tably, person reidentification. On the other hand, in the area of speech\nrecognition the metric embeddings generated by the triplet loss are rarely used\neven for classification problems. We fill this gap showing that a combination\nof two representation learning techniques: a triplet loss-based embedding and a\nvariant of kNN for classification instead of cross-entropy loss significantly\n(by 26% to 38%) improves the classification accuracy for convolutional networks\non a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel\nphonetic similarity based triplet mining approach. We also improve the current\nbest published SOTA for Google Speech Commands dataset V1 10+2 -class\nclassification by about 34%, achieving 98.55% accuracy, V2 10+2-class\nclassification by about 20%, achieving 98.37% accuracy, and V2 35-class\nclassification by over 50%, achieving 97.0% accuracy.",
          "link": "http://arxiv.org/abs/2101.04792",
          "publishedOn": "2021-06-08T02:20:25.935Z",
          "wordCount": 626,
          "title": "Learning Efficient Representations for Keyword Spotting with Triplet Loss. (arXiv:2101.04792v4 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1\">Karan Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidahmed_H/0/1/0/all/0/1\">Hakim Sidahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shanshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1\">Keith Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1\">Sushant Prakash</a>",
          "description": "Personalization methods in federated learning aim to balance the benefits of\nfederated and local training for data availability, communication cost, and\nrobustness to client heterogeneity. Approaches that require clients to\ncommunicate all model parameters can be undesirable due to privacy and\ncommunication constraints. Other approaches require always-available or\nstateful clients, impractical in large-scale cross-device settings. We\nintroduce Federated Reconstruction, the first model-agnostic framework for\npartially local federated learning suitable for training and inference at\nscale. We motivate the framework via a connection to model-agnostic meta\nlearning, empirically demonstrate its performance over existing approaches for\ncollaborative filtering and next word prediction, and release an open-source\nlibrary for evaluating approaches in this setting. We also describe the\nsuccessful deployment of this approach at scale for federated collaborative\nfiltering in a mobile keyboard application.",
          "link": "http://arxiv.org/abs/2102.03448",
          "publishedOn": "2021-06-08T02:20:25.930Z",
          "wordCount": 607,
          "title": "Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seidl_P/0/1/0/all/0/1\">Philipp Seidl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1\">Philipp Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyubankova_N/0/1/0/all/0/1\">Natalia Dyubankova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neves_P/0/1/0/all/0/1\">Paulo Neves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1\">Jonas Verhoeven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1\">J&#xf6;rg K. Wegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1\">G&#xfc;nter Klambauer</a>",
          "description": "Finding synthesis routes for molecules of interest is an essential step in\nthe discovery of new drugs and materials. To find such routes,\ncomputer-assisted synthesis planning (CASP) methods are employed which rely on\na model of chemical reactivity. In this study, we model single-step\nretrosynthesis in a template-based approach using modern Hopfield networks\n(MHNs). We adapt MHNs to associate different modalities, reaction templates and\nmolecules, which allows the model to leverage structural information about\nreaction templates. This approach significantly improves the performance of\ntemplate relevance prediction, especially for templates with few or zero\ntraining examples. With inference speed several times faster than that of\nbaseline methods, we improve predictive performance for top-k exact match\naccuracy for $\\mathrm{k}\\geq5$ in the retrosynthesis benchmark USPTO-50k.",
          "link": "http://arxiv.org/abs/2104.03279",
          "publishedOn": "2021-06-08T02:20:25.923Z",
          "wordCount": 611,
          "title": "Modern Hopfield Networks for Few- and Zero-Shot Reaction Template Prediction. (arXiv:2104.03279v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.17182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zeke Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "It is well-known that stochastic gradient noise (SGN) acts as implicit\nregularization for deep learning and is essentially important for both\noptimization and generalization of deep networks. Some works attempted to\nartificially simulate SGN by injecting random noise to improve deep learning.\nHowever, it turned out that the injected simple random noise cannot work as\nwell as SGN, which is anisotropic and parameter-dependent. For simulating SGN\nat low computational costs and without changing the learning rate or batch\nsize, we propose the Positive-Negative Momentum (PNM) approach that is a\npowerful alternative to conventional Momentum in classic optimizers. The\nintroduced PNM method maintains two approximate independent momentum terms.\nThen, we can control the magnitude of SGN explicitly by adjusting the momentum\ndifference. We theoretically prove the convergence guarantee and the\ngeneralization advantage of PNM over Stochastic Gradient Descent (SGD). By\nincorporating PNM into the two conventional optimizers, SGD with Momentum and\nAdam, our extensive experiments empirically verified the significant advantage\nof the PNM-based variants over the corresponding conventional Momentum-based\noptimizers.",
          "link": "http://arxiv.org/abs/2103.17182",
          "publishedOn": "2021-06-08T02:20:25.906Z",
          "wordCount": 650,
          "title": "Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization. (arXiv:2103.17182v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paria_D/0/1/0/all/0/1\">Debjit Paria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>",
          "description": "We consider a set-valued online prediction problem in the context of network\ncaching. Assume that users are connected to a number of caches via a bipartite\nnetwork. At any time slot, each user requests some file chosen from a large\ncatalog. A user's request is met if the requested file is cached in at least\none of the caches connected to the user. The objective is to predict and\noptimally store the files on the caches to maximize the total number of cache\nhits. We propose $\\texttt{LeadCache}$ - an online caching policy based on the\nFollow-the-Perturbed-Leader paradigm. We show that the policy is regret-optimal\nup to a factor of $\\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We\nimplement the policy by designing a new linear-time Pipage rounding algorithm.\nWith an additional Strong-Law-type assumption, we show that the total number of\nfile fetches under $\\texttt{LeadCache}$ remains almost surely finite.\nAdditionally, we derive a tight regret lower bound using results from graph\ncoloring. Our conclusion is that the proposed learning-based caching policy\ndecisively outperforms the classical policies both theoretically and\nempirically.",
          "link": "http://arxiv.org/abs/2009.08228",
          "publishedOn": "2021-06-08T02:20:25.900Z",
          "wordCount": 635,
          "title": "LeadCache: Regret-Optimal Caching in Networks. (arXiv:2009.08228v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03955",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Craven_J/0/1/0/all/0/1\">Jessica Craven</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Jejjala_V/0/1/0/all/0/1\">Vishnu Jejjala</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Kar_A/0/1/0/all/0/1\">Arjun Kar</a>",
          "description": "We present a simple phenomenological formula which approximates the\nhyperbolic volume of a knot using only a single evaluation of its Jones\npolynomial at a root of unity. The average error is just $2.86$% on the first\n$1.7$ million knots, which represents a large improvement over previous\nformulas of this kind. To find the approximation formula, we use layer-wise\nrelevance propagation to reverse engineer a black box neural network which\nachieves a similar average error for the same approximation task when trained\non $10$% of the total dataset. The particular roots of unity which appear in\nour analysis cannot be written as $e^{2\\pi i / (k+2)}$ with integer $k$;\ntherefore, the relevant Jones polynomial evaluations are not given by\nunknot-normalized expectation values of Wilson loop operators in conventional\n$SU(2)$ Chern$\\unicode{x2013}$Simons theory with level $k$. Instead, they\ncorrespond to an analytic continuation of such expectation values to fractional\nlevel. We briefly review the continuation procedure and comment on the presence\nof certain Lefschetz thimbles, to which our approximation formula is sensitive,\nin the analytically continued Chern$\\unicode{x2013}$Simons integration cycle.",
          "link": "http://arxiv.org/abs/2012.03955",
          "publishedOn": "2021-06-08T02:20:25.894Z",
          "wordCount": 645,
          "title": "Disentangling a Deep Learned Volume Formula. (arXiv:2012.03955v2 [hep-th] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_J/0/1/0/all/0/1\">Jayneel Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "To tackle interpretability in deep learning, we present a novel framework to\njointly learn a predictive model and its associated interpretation model. The\ninterpreter provides both local and global interpretability about the\npredictive model in terms of human-understandable high level attribute\nfunctions, with minimal loss of accuracy. This is achieved by a dedicated\narchitecture and well chosen regularization penalties. We seek for a small-size\ndictionary of high level attribute functions that take as inputs the outputs of\nselected hidden layers and whose outputs feed a linear classifier. We impose\nstrong conciseness on the activation of attributes with an entropy-based\ncriterion while enforcing fidelity to both inputs and outputs of the predictive\nmodel. A detailed pipeline to visualize the learnt features is also developed.\nMoreover, besides generating interpretable models by design, our approach can\nbe specialized to provide post-hoc interpretations for a pre-trained neural\nnetwork. We validate our approach against several state-of-the-art methods on\nmultiple datasets and show its efficacy on both kinds of tasks.",
          "link": "http://arxiv.org/abs/2010.09345",
          "publishedOn": "2021-06-08T02:20:25.882Z",
          "wordCount": 623,
          "title": "A Framework to Learn with Interpretation. (arXiv:2010.09345v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Honglin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1\">Sashank Reddi</a>",
          "description": "Federated Learning (FL) is a distributed learning paradigm that scales\non-device learning collaboratively and privately. Standard FL algorithms such\nas FedAvg are primarily geared towards smooth unconstrained settings. In this\npaper, we study the Federated Composite Optimization (FCO) problem, in which\nthe loss function contains a non-smooth regularizer. Such problems arise\nnaturally in FL applications that involve sparsity, low-rank, monotonicity, or\nmore general constraints. We first show that straightforward extensions of\nprimal algorithms such as FedAvg are not well-suited for FCO since they suffer\nfrom the \"curse of primal averaging,\" resulting in poor convergence. As a\nsolution, we propose a new primal-dual algorithm, Federated Dual Averaging\n(FedDualAvg), which by employing a novel server dual averaging procedure\ncircumvents the curse of primal averaging. Our theoretical analysis and\nempirical experiments demonstrate that FedDualAvg outperforms the other\nbaselines.",
          "link": "http://arxiv.org/abs/2011.08474",
          "publishedOn": "2021-06-08T02:20:25.875Z",
          "wordCount": 613,
          "title": "Federated Composite Optimization. (arXiv:2011.08474v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Rohitash Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1\">Shaurya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rishabh Gupta</a>",
          "description": "Time series prediction with neural networks has been the focus of much\nresearch in the past few decades. Given the recent deep learning revolution,\nthere has been much attention in using deep learning models for time series\nprediction, and hence it is important to evaluate their strengths and\nweaknesses. In this paper, we present an evaluation study that compares the\nperformance of deep learning models for multi-step ahead time series\nprediction. The deep learning methods comprise simple recurrent neural\nnetworks, long short-term memory (LSTM) networks, bidirectional LSTM networks,\nencoder-decoder LSTM networks, and convolutional neural networks. We provide a\nfurther comparison with simple neural networks that use stochastic gradient\ndescent and adaptive moment estimation (Adam) for training. We focus on\nunivariate time series for multi-step-ahead prediction from benchmark\ntime-series datasets and provide a further comparison of the results with\nrelated methods from the literature. The results show that the bidirectional\nand encoder-decoder LSTM network provides the best performance in accuracy for\nthe given time series problems.",
          "link": "http://arxiv.org/abs/2103.14250",
          "publishedOn": "2021-06-08T02:20:25.858Z",
          "wordCount": 630,
          "title": "Evaluation of deep learning models for multi-step ahead time series prediction. (arXiv:2103.14250v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuefeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "In label-noise learning, the transition matrix plays a key role in building\nstatistically consistent classifiers. Existing consistent estimators for the\ntransition matrix have been developed by exploiting anchor points. However, the\nanchor-point assumption is not always satisfied in real scenarios. In this\npaper, we propose an end-to-end framework for solving label-noise learning\nwithout anchor points, in which we simultaneously optimize two objectives: the\ncross entropy loss between the prediction by the neural network and the given\nnoisy label, and the volume of the simplex formed by the columns of the\ntransition matrix. Our proposed framework can identify the transition matrix if\nthe clean class-posterior probabilities are sufficiently scattered. This is by\nfar the mildest assumption under which the transition matrix is provably\nidentifiable and the learned classifier is statistically consistent.\nExperimental results on benchmark datasets demonstrate the effectiveness and\nrobustness of the proposed method.",
          "link": "http://arxiv.org/abs/2102.02400",
          "publishedOn": "2021-06-08T02:20:25.852Z",
          "wordCount": 598,
          "title": "Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Snoswell_A/0/1/0/all/0/1\">Aaron J. Snoswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Surya P. N. Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1\">Nan Ye</a>",
          "description": "We provide new perspectives and inference algorithms for Maximum Entropy\n(MaxEnt) Inverse Reinforcement Learning (IRL), which provides a principled\nmethod to find a most non-committal reward function consistent with given\nexpert demonstrations, among many consistent reward functions.\n\nWe first present a generalized MaxEnt formulation based on minimizing a\nKL-divergence instead of maximizing an entropy. This improves the previous\nheuristic derivation of the MaxEnt IRL model (for stochastic MDPs), allows a\nunified view of MaxEnt IRL and Relative Entropy IRL, and leads to a model-free\nlearning algorithm for the MaxEnt IRL model. Second, a careful review of\nexisting inference algorithms and implementations showed that they\napproximately compute the marginals required for learning the model. We provide\nexamples to illustrate this, and present an efficient and exact inference\nalgorithm. Our algorithm can handle variable length demonstrations; in\naddition, while a basic version takes time quadratic in the maximum\ndemonstration length L, an improved version of this algorithm reduces this to\nlinear using a padding trick.\n\nExperiments show that our exact algorithm improves reward learning as\ncompared to the approximate ones. Furthermore, our algorithm scales up to a\nlarge, real-world dataset involving driver behaviour forecasting. We provide an\noptimized implementation compatible with the OpenAI Gym interface. Our new\ninsight and algorithms could possibly lead to further interest and exploration\nof the original MaxEnt IRL model.",
          "link": "http://arxiv.org/abs/2012.00889",
          "publishedOn": "2021-06-08T02:20:25.838Z",
          "wordCount": 700,
          "title": "Revisiting Maximum Entropy Inverse Reinforcement Learning: New Perspectives and Algorithms. (arXiv:2012.00889v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05313",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1\">Carl Remlinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1\">Joseph Mikael</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>",
          "description": "We introduce three new generative models for time series. Based on Euler\ndiscretization and Wasserstein metrics, they are able to capture time marginal\ndistributions and temporal dynamics. Two of these methods rely on the\nadaptation of generative adversarial networks (GANs) to time series. Both of\nthem outperform state-of-the-art benchmarks by capturing the underlying\ntemporal structure on synthetic time series. The third algorithm, called\nConditional Euler Generator (CEGEN), minimizes a dedicated distance between the\ntransition probability distributions over all time steps. In the context of Ito\nprocesses, we provide theoretical guarantees that minimizing this criterion\nimplies accurate estimations of the drift and volatility parameters. We\ndemonstrate empirically that CEGEN outperforms state-of-the-art and GAN\ngenerators on both marginal and temporal dynamics metrics. Besides, it\nidentifies accurate correlation structures in high dimension. When few data\npoints are available, we verify the effectiveness of CEGEN, when combined with\ntransfer learning methods on Monte Carlo simulations. Finally, we illustrate\nthe robustness of our method on various real-world datasets.",
          "link": "http://arxiv.org/abs/2102.05313",
          "publishedOn": "2021-06-08T02:20:25.820Z",
          "wordCount": 614,
          "title": "Conditional Versus Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaojun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haomin Zhou</a>",
          "description": "We propose a new formulation and learning strategy for computing the\nWasserstein geodesic between two probability distributions in high dimensions.\nBy applying the method of Lagrange multipliers to the dynamic formulation of\nthe optimal transport (OT) problem, we derive a minimax problem whose saddle\npoint is the Wasserstein geodesic. We then parametrize the functions by deep\nneural networks and design a sample based bidirectional learning algorithm for\ntraining. The trained networks enable sampling from the Wasserstein geodesic.\nAs by-products, the algorithm also computes the Wasserstein distance and OT map\nbetween the marginal distributions. We demonstrate the performance of our\nalgorithms through a series of experiments with both synthetic and realistic\ndata.",
          "link": "http://arxiv.org/abs/2102.02992",
          "publishedOn": "2021-06-08T02:20:25.814Z",
          "wordCount": 587,
          "title": "Learning High Dimensional Wasserstein Geodesics. (arXiv:2102.02992v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1\">Osman Aka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1\">Ken Burke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1\">Alex B&#xe4;uerle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1\">Christina Greer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Margaret Mitchell</a>",
          "description": "The measurement of bias in machine learning often focuses on model\nperformance across identity subgroups (such as man and woman) with respect to\ngroundtruth labels. However, these methods do not directly measure the\nassociations that a model may have learned, for example between labels and\nidentity subgroups. Further, measuring a model's bias requires a fully\nannotated evaluation dataset which may not be easily available in practice. We\npresent an elegant mathematical solution that tackles both issues\nsimultaneously, using image classification as a working example. By treating a\nclassification model's predictions for a given image as a set of labels\nanalogous to a bag of words, we rank the biases that a model has learned with\nrespect to different identity labels. We use (man, woman) as a concrete example\nof an identity label set (although this set need not be binary), and present\nrankings for the labels that are most biased towards one identity or the other.\nWe demonstrate how the statistical properties of different association metrics\ncan lead to different rankings of the most \"gender biased\" labels, and conclude\nthat normalized pointwise mutual information (nPMI) is most useful in practice.\nFinally, we announce an open-sourced nPMI visualization tool using TensorBoard.",
          "link": "http://arxiv.org/abs/2103.03417",
          "publishedOn": "2021-06-08T02:20:25.808Z",
          "wordCount": 675,
          "title": "Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bromberg_M/0/1/0/all/0/1\">Michael Bromberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyogi_R/0/1/0/all/0/1\">Ritwik Niyogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1\">Jezabel Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>",
          "description": "Meta-learning models transfer the knowledge acquired from previous tasks to\nquickly learn new ones. They are trained on benchmarks with a fixed number of\ndata points per task. This number is usually arbitrary and it is unknown how it\naffects performance at testing. Since labelling of data is expensive, finding\nthe optimal allocation of labels across training tasks may reduce costs. Given\na fixed budget of labels, should we use a small number of highly labelled\ntasks, or many tasks with few labels each? Should we allocate more labels to\nsome tasks and less to others? We show that: 1) If tasks are homogeneous, there\nis a uniform optimal allocation, whereby all tasks get the same amount of data;\n2) At fixed budget, there is a trade-off between number of tasks and number of\ndata points per task, with a unique and constant optimum; 3) When trained\nseparately, harder task should get more data, at the cost of a smaller number\nof tasks; 4) When training on a mixture of easy and hard tasks, more data\nshould be allocated to easy tasks. Interestingly, Neuroscience experiments have\nshown that human visual skills also transfer better from easy tasks. We prove\nthese results mathematically on mixed linear regression, and we show\nempirically that the same results hold for few-shot image classification on\nCIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels\nacross tasks when collecting data for meta-learning.",
          "link": "http://arxiv.org/abs/2103.08463",
          "publishedOn": "2021-06-08T02:20:25.801Z",
          "wordCount": 696,
          "title": "How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.07524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiaheng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiahao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiutong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">James Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "In this paper, we introduce PeerGAN, a generative adversarial network (GAN)\nsolution to improve the stability of the generated samples and to mitigate mode\ncollapse. Built upon the Vanilla GAN's two-player game between the\ndiscriminator $D_1$ and the generator $G$, we introduce a peer discriminator\n$D_2$ to the min-max game. Similar to previous work using two discriminators,\nthe first role of both $D_1$, $D_2$ is to distinguish between generated samples\nand real ones, while the generator tries to generate high-quality samples which\nare able to fool both discriminators. Different from existing methods, we\nintroduce another game between $D_1$ and $D_2$ to discourage their agreement\nand therefore increase the level of diversity of the generated samples. This\nproperty alleviates the issue of early mode collapse by preventing $D_1$ and\n$D_2$ from converging too fast. We provide theoretical analysis for the\nequilibrium of the min-max game formed among $G, D_1, D_2$. We offer\nconvergence behavior of PeerGAN as well as stability of the min-max game. It's\nworth mentioning that PeerGAN operates in the unsupervised setting, and the\nadditional game between $D_1$ and $D_2$ does not need any label supervision.\nExperiments results on a synthetic dataset and on real-world image datasets\n(MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG) demonstrate that PeerGAN\noutperforms competitive baseline work in generating diverse and high-quality\nsamples, while only introduces negligible computation cost.",
          "link": "http://arxiv.org/abs/2101.07524",
          "publishedOn": "2021-06-08T02:20:25.794Z",
          "wordCount": 684,
          "title": "PeerGAN: Generative Adversarial Networks with a Competing Peer Discriminator. (arXiv:2101.07524v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1\">Manan Tomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1\">Roberto Calandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "Accuracy and generalization of dynamics models is key to the success of\nmodel-based reinforcement learning (MBRL). As the complexity of tasks\nincreases, so does the sample inefficiency of learning accurate dynamics\nmodels. However, many complex tasks also exhibit sparsity in the dynamics,\ni.e., actions have only a local effect on the system dynamics. In this paper,\nwe exploit this property with a causal invariance perspective in the\nsingle-task setting, introducing a new type of state abstraction called\n\\textit{model-invariance}. Unlike previous forms of state abstractions, a\nmodel-invariance state abstraction leverages causal sparsity over state\nvariables. This allows for compositional generalization to unseen states,\nsomething that non-factored forms of state abstractions cannot do. We prove\nthat an optimal policy can be learned over this model-invariance state\nabstraction and show improved generalization in a simple toy domain. Next, we\npropose a practical method to approximately learn a model-invariant\nrepresentation for complex domains and validate our approach by showing\nimproved modelling performance over standard maximum likelihood approaches on\nchallenging tasks, such as the MuJoCo-based Humanoid. Finally, within the MBRL\nsetting we show strong performance gains with respect to sample efficiency\nacross a host of other continuous control tasks.",
          "link": "http://arxiv.org/abs/2102.09850",
          "publishedOn": "2021-06-08T02:20:25.788Z",
          "wordCount": 658,
          "title": "Model-Invariant State Abstractions for Model-Based Reinforcement Learning. (arXiv:2102.09850v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1\">Brijen Thananjeyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1\">Kirthevasan Kandasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>",
          "description": "We study exploration in stochastic multi-armed bandits when we have access to\na divisible resource that can be allocated in varying amounts to arm pulls. We\nfocus in particular on the allocation of distributed computing resources, where\nwe may obtain results faster by allocating more resources per pull, but might\nhave reduced throughput due to nonlinear scaling. For example, in\nsimulation-based scientific studies, an expensive simulation can be sped up by\nrunning it on multiple cores. This speed-up however, is partly offset by the\ncommunication among cores, which results in lower throughput than if fewer\ncores were allocated per trial to run more trials in parallel. In this paper,\nwe explore these trade-offs in two settings. First, in a fixed confidence\nsetting, we need to find the best arm with a given target success probability\nas quickly as possible. We propose an algorithm which trades off between\ninformation accumulation and throughput and show that the time taken can be\nupper bounded by the solution of a dynamic program whose inputs are the gaps\nbetween the sub-optimal and optimal arms. We also prove a matching hardness\nresult. Second, we present an algorithm for a fixed deadline setting, where we\nare given a time deadline and need to maximize the probability of finding the\nbest arm. We corroborate our theoretical insights with simulation experiments\nthat show that the algorithms consistently match or outperform baseline\nalgorithms on a variety of problem instances.",
          "link": "http://arxiv.org/abs/2011.00330",
          "publishedOn": "2021-06-08T02:20:25.770Z",
          "wordCount": 730,
          "title": "Resource Allocation in Multi-armed Bandit Exploration: Overcoming Sublinear Scaling with Adaptive Parallelism. (arXiv:2011.00330v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kubler_J/0/1/0/all/0/1\">Jonas M. K&#xfc;bler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1\">Wittawat Jitkrittum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1\">Krikamol Muandet</a>",
          "description": "The Maximum Mean Discrepancy (MMD) has been the state-of-the-art\nnonparametric test for tackling the two-sample problem. Its statistic is given\nby the difference in expectations of the witness function, a real-valued\nfunction defined as a weighted sum of kernel evaluations on a set of basis\npoints. Typically the kernel is optimized on a training set, and hypothesis\ntesting is performed on a separate test set to avoid overfitting (i.e., control\ntype-I error). That is, the test set is used to simultaneously estimate the\nexpectations and define the basis points, while the training set only serves to\nselect the kernel and is discarded. In this work, we argue that this data\nsplitting scheme is overly conservative, and propose to use the training data\nto also define the weights and the basis points for better data efficiency. We\nshow that 1) the new test is consistent and has a well-controlled type-I error;\n2) the optimal witness function is given by a precision-weighted mean in the\nreproducing kernel Hilbert space associated with the kernel, and is closely\nrelated to kernel Fisher discriminant analysis; and 3) the test power of the\nproposed test is comparable or exceeds that of the MMD and other modern tests,\nas verified empirically on challenging synthetic and real problems (e.g., Higgs\ndata).",
          "link": "http://arxiv.org/abs/2102.05573",
          "publishedOn": "2021-06-08T02:20:25.764Z",
          "wordCount": 674,
          "title": "A Witness Two-Sample Test. (arXiv:2102.05573v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1\">Freddy C. Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel P. Duffy</a>",
          "description": "We address the challenge of extracting structured information from business\ndocuments without detailed annotations. We propose Deep Conditional\nProbabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional\ncomplex documents and use Recursive Neural Networks to create an end-to-end\nsystem for finding the most probable parse that represents the structured\ninformation to be extracted. This system is trained end-to-end with scanned\ndocuments as input and only relational-records as labels. The\nrelational-records are extracted from existing databases avoiding the cost of\nannotating documents by hand. We apply this approach to extract information\nfrom scanned invoices achieving state-of-the-art results despite using no\nhand-annotations.",
          "link": "http://arxiv.org/abs/2103.05908",
          "publishedOn": "2021-06-08T02:20:25.757Z",
          "wordCount": 561,
          "title": "DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manupriya_P/0/1/0/all/0/1\">Piyushi Manupriya</a> (IIT Hyderabad, INDIA), <a href=\"http://arxiv.org/find/cs/1/au:+Nath_J/0/1/0/all/0/1\">J. Saketha Nath</a> (IIT Hyderabad, INDIA), <a href=\"http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1\">Pratik Jawanpuria</a> (Microsoft IDC, INDIA)",
          "description": "Regularization in Optimal Transport (OT) problems has been shown to\ncritically affect the associated computational and sample complexities. It also\nhas been observed that regularization effectively helps in handling noisy\nmarginals as well as marginals with unequal masses. However, existing works on\nOT restrict themselves to $\\phi$-divergences based regularization. In this\nwork, we propose and analyze Integral Probability Metric (IPM) based\nregularization in OT problems. While it is expected that the well-established\nadvantages of IPMs are inherited by the IPM-regularized OT variants, we\ninterestingly observe that some useful aspects of $\\phi$-regularization are\npreserved. For example, we show that the OT formulation, where the marginal\nconstraints are relaxed using IPM-regularization, also lifts the ground metric\nto that over (perhaps un-normalized) measures. Infact, the lifted metric turns\nout to be another IPM whose generating set is the intersection of that of the\nIPM employed for regularization and the set of 1-Lipschitz functions under the\nground metric. Also, in the special case where the regularization is squared\nmaximum mean discrepancy based, the proposed OT variant, as well as the\ncorresponding Barycenter formulation, turn out to be those of minimizing a\nconvex quadratic subject to non-negativity/simplex constraints and hence can be\nsolved efficiently. Simulations confirm that the optimal transport plans/maps\nobtained with IPM-regularization are intrinsically different from those\nobtained with $\\phi$-regularization. Empirical results illustrate the efficacy\nof the proposed IPM-regularized OT formulation.\n\nThis draft contains the main paper and the Appendices.",
          "link": "http://arxiv.org/abs/2011.05001",
          "publishedOn": "2021-06-08T02:20:25.750Z",
          "wordCount": 703,
          "title": "Integral Probability Metric based Regularization for Optimal Transport. (arXiv:2011.05001v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11994",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ariu_K/0/1/0/all/0/1\">Kaito Ariu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abe_K/0/1/0/all/0/1\">Kenshi Abe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Prouti&#xe8;re</a>",
          "description": "In this paper, we revisit the regret minimization problem in sparse\nstochastic contextual linear bandits, where feature vectors may be of large\ndimension $d$, but where the reward function depends on a few, say $s_0\\ll d$,\nof these features only. We present Thresholded Lasso bandit, an algorithm that\n(i) estimates the vector defining the reward function as well as its sparse\nsupport, i.e., significant feature elements, using the Lasso framework with\nthresholding, and (ii) selects an arm greedily according to this estimate\nprojected on its support. The algorithm does not require prior knowledge of the\nsparsity index $s_0$. For this simple algorithm, we establish non-asymptotic\nregret upper bounds scaling as $\\mathcal{O}( \\log d + \\sqrt{T} )$ in general,\nand as $\\mathcal{O}( \\log d + \\log T)$ under the so-called margin condition (a\nsetting where arms are well separated). The regret of previous algorithms\nscales as $\\mathcal{O}( \\log d + \\sqrt{T \\log (d T)})$ and $\\mathcal{O}( \\log T\n\\log d)$ in the two settings, respectively. Through numerical experiments, we\nconfirm that our algorithm outperforms existing methods.",
          "link": "http://arxiv.org/abs/2010.11994",
          "publishedOn": "2021-06-08T02:20:25.725Z",
          "wordCount": 608,
          "title": "Thresholded Lasso Bandit. (arXiv:2010.11994v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.13086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldsteen_A/0/1/0/all/0/1\">Abigail Goldsteen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ezov_G/0/1/0/all/0/1\">Gilad Ezov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmelkin_R/0/1/0/all/0/1\">Ron Shmelkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moffie_M/0/1/0/all/0/1\">Micha Moffie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farkash_A/0/1/0/all/0/1\">Ariel Farkash</a>",
          "description": "There is a known tension between the need to analyze personal data to drive\nbusiness and privacy concerns. Many data protection regulations, including the\nEU General Data Protection Regulation (GDPR) and the California Consumer\nProtection Act (CCPA), set out strict restrictions and obligations on companies\nthat collect or process personal data. Moreover, machine learning models\nthemselves can be used to derive personal information, as demonstrated by\nrecent membership and attribute inference attacks. Anonymized data, however, is\nexempt from data protection principles and obligations. Thus, models built on\nanonymized data are also exempt from any privacy obligations, in addition to\nproviding better protection against such attacks on the training data. Learning\non anonymized data typically results in a significant degradation in accuracy.\nWe address this challenge by guiding our anonymization using the knowledge\nencoded within the model, and targeting it to minimize the impact on the\nmodel's accuracy, a process we call accuracy-guided anonymization. We\ndemonstrate that by focusing on the model's accuracy rather than information\nloss, our method outperforms state of the art k-anonymity methods in terms of\nthe achieved utility, in particular with high values of k and large numbers of\nquasi-identifiers. We also demonstrate that our approach achieves similar\nresults in its ability to prevent membership inference attacks as alternative\napproaches based on differential privacy. This shows that model-guided\nanonymization can, in some cases, be a legitimate substitute for such methods,\nwhile averting some of their inherent drawbacks such as complexity, performance\noverhead and being fitted to specific model types. As opposed to methods that\nrely on adding noise during training, our approach does not rely on making any\nmodifications to the training algorithm itself.",
          "link": "http://arxiv.org/abs/2007.13086",
          "publishedOn": "2021-06-08T02:20:25.718Z",
          "wordCount": 731,
          "title": "Anonymizing Machine Learning Models. (arXiv:2007.13086v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Huiru Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Caigao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">James Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Junwu Xiong</a>",
          "description": "Learning the representation of data with hierarchical structures in the\nhyperbolic space attracts increasing attention in recent years. Due to the\nconstant negative curvature, the hyperbolic space resembles tree metrics and\ncaptures the tree-like properties naturally, which enables the hyperbolic\nembeddings to improve over traditional Euclidean models. However, many\nreal-world hierarchically structured data such as taxonomies and multitree\nnetworks have varying local structures and they are not trees, thus they do not\nubiquitously match the constant curvature property of the hyperbolic space. To\naddress this limitation of hyperbolic embeddings, we explore the complex\nhyperbolic space, which has the variable negative curvature, for representation\nlearning. Specifically, we propose to learn the embeddings of hierarchically\nstructured data in the unit ball model of the complex hyperbolic space. The\nunit ball model based embeddings have a more powerful representation capacity\nto capture a variety of hierarchical structures. Through experiments on\nsynthetic and real-world data, we show that our approach improves over the\nhyperbolic embedding models significantly.",
          "link": "http://arxiv.org/abs/2105.03966",
          "publishedOn": "2021-06-08T02:20:25.711Z",
          "wordCount": 625,
          "title": "Unit Ball Model for Embedding Hierarchical Structures in the Complex Hyperbolic Space. (arXiv:2105.03966v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wang-Cheng Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Derek Zhiyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tiansheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinyang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "Embedding learning of categorical features (e.g. user/item IDs) is at the\ncore of various recommendation models including matrix factorization and neural\ncollaborative filtering. The standard approach creates an embedding table where\neach row represents a dedicated embedding vector for every unique feature\nvalue. However, this method fails to efficiently handle high-cardinality\nfeatures and unseen feature values (e.g. new video ID) that are prevalent in\nreal-world recommendation systems. In this paper, we propose an alternative\nembedding framework Deep Hash Embedding (DHE), replacing embedding tables by a\ndeep embedding network to compute embeddings on the fly. DHE first encodes the\nfeature value to a unique identifier vector with multiple hashing functions and\ntransformations, and then applies a DNN to convert the identifier vector to an\nembedding. The encoding module is deterministic, non-learnable, and free of\nstorage, while the embedding network is updated during the training time to\nlearn embedding generation. Empirical results show that DHE achieves comparable\nAUC against the standard one-hot full embedding, with smaller model sizes. Our\nwork sheds light on the design of DNN-based alternative embedding schemes for\ncategorical features without using embedding table lookup.",
          "link": "http://arxiv.org/abs/2010.10784",
          "publishedOn": "2021-06-08T02:20:25.704Z",
          "wordCount": 663,
          "title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.11622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Han Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Ligeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "On-device learning enables edge devices to continually adapt the AI models to\nnew data, which requires a small memory footprint to fit the tight memory\nconstraint of edge devices. Existing work solves this problem by reducing the\nnumber of trainable parameters. However, this doesn't directly translate to\nmemory saving since the major bottleneck is the activations, not parameters. In\nthis work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient\non-device learning. TinyTL freezes the weights while only learns the bias\nmodules, thus no need to store the intermediate activations. To maintain the\nadaptation capacity, we introduce a new memory-efficient bias module, the lite\nresidual module, to refine the feature extractor by learning small residual\nfeature maps adding only 3.8% memory overhead. Extensive experiments show that\nTinyTL significantly saves the memory (up to 6.5x) with little accuracy loss\ncompared to fine-tuning the full network. Compared to fine-tuning the last\nlayer, TinyTL provides significant accuracy improvements (up to 34.1%) with\nlittle memory overhead. Furthermore, combined with feature extractor\nadaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing\naccuracy compared to fine-tuning the full Inception-V3.",
          "link": "http://arxiv.org/abs/2007.11622",
          "publishedOn": "2021-06-08T02:20:25.698Z",
          "wordCount": 675,
          "title": "TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.",
          "link": "http://arxiv.org/abs/2010.14439",
          "publishedOn": "2021-06-08T02:20:25.690Z",
          "wordCount": 631,
          "title": "Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1\">Leopoldo Bertossi</a>",
          "description": "We propose answer-set programs that specify and compute counterfactual\ninterventions on entities that are input on a classification model. In relation\nto the outcome of the model, the resulting counterfactual entities serve as a\nbasis for the definition and computation of causality-based explanation scores\nfor the feature values in the entity under classification, namely\n\"responsibility scores\". The approach and the programs can be applied with\nblack-box models, and also with models that can be specified as logic programs,\nsuch as rule-based classifiers. The main focus of this work is on the\nspecification and computation of \"best\" counterfactual entities, i.e. those\nthat lead to maximum responsibility scores. From them one can read off the\nexplanations as maximum responsibility feature values in the original entity.\nWe also extend the programs to bring into the picture semantic or domain\nknowledge. We show how the approach could be extended by means of probabilistic\nmethods, and how the underlying probability distributions could be modified\nthrough the use of constraints.",
          "link": "http://arxiv.org/abs/2011.07423",
          "publishedOn": "2021-06-08T02:20:25.684Z",
          "wordCount": 638,
          "title": "Declarative Approaches to Counterfactual Explanations for Classification. (arXiv:2011.07423v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10488",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bonner_S/0/1/0/all/0/1\">Stephen Bonner</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barrett_I/0/1/0/all/0/1\">Ian P Barrett</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ye_C/0/1/0/all/0/1\">Cheng Ye</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Swiers_R/0/1/0/all/0/1\">Rowan Swiers</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Engkvist_O/0/1/0/all/0/1\">Ola Engkvist</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hoyt_C/0/1/0/all/0/1\">Charles Tapley Hoyt</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hamilton_W/0/1/0/all/0/1\">William L Hamilton</a>",
          "description": "Knowledge Graphs (KG) and associated Knowledge Graph Embedding (KGE) models\nhave recently begun to be explored in the context of drug discovery and have\nthe potential to assist in key challenges such as target identification. In the\ndrug discovery domain, KGs can be employed as part of a process which can\nresult in lab-based experiments being performed, or impact on other decisions,\nincurring significant time and financial costs and most importantly, ultimately\ninfluencing patient healthcare. For KGE models to have impact in this domain, a\nbetter understanding of not only of performance, but also the various factors\nwhich determine it, is required.\n\nIn this study we investigate, over the course of many thousands of\nexperiments, the predictive performance of five KGE models on two public drug\ndiscovery-oriented KGs. Our goal is not to focus on the best overall model or\nconfiguration, instead we take a deeper look at how performance can be affected\nby changes in the training setup, choice of hyperparameters, model parameter\ninitialisation seed and different splits of the datasets. Our results highlight\nthat these factors have significant impact on performance and can even affect\nthe ranking of models. Indeed these factors should be reported along with model\narchitectures to ensure complete reproducibility and fair comparisons of future\nwork, and we argue this is critical for the acceptance of use, and impact of\nKGEs in a biomedical setting. To aid reproducibility of our own work, we\nrelease all experimentation code.",
          "link": "http://arxiv.org/abs/2105.10488",
          "publishedOn": "2021-06-08T02:20:25.677Z",
          "wordCount": 702,
          "title": "Understanding the Performance of Knowledge Graph Embeddings in Drug Discovery. (arXiv:2105.10488v2 [q-bio.BM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.06997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1\">S&#xe9;bastien Ragot</a>",
          "description": "Originality criteria are frequently used to compare assets and, in\nparticular, to assess the validity of intellectual property (IP) rights such as\ncopyright and design rights. In this work, the originality of an asset is\nformulated as a function of the distances between this asset and its\ncomparands, using concepts of maximum entropy and surprisal analysis. Namely,\nthe originality function is defined according to the surprisal associated with\na given asset. Creative assets can be justifiably compared to particles that\nrepel each other via an electrostatic-like pair potential. This allows a very\nsimple, suitably bounded formula to be obtained, in which the originality of an\nasset writes as the ratio of a reference energy to an interaction energy\nimparted to that asset. In particular, the originality of an asset can be\nexpressed as a ratio of two average distances, i.e., the harmonic mean of the\ndistances from this asset to its comparands divided by the harmonic mean of the\ndistances between the sole comparands. Accordingly, the originality of objects\nsuch as IP assets can be simply estimated based on distances computed thanks to\nunsupervised machine learning techniques or other distance computation\nalgorithms. Application is made to various types of assets, including emojis,\ntypeface designs, paintings, and novel titles.",
          "link": "http://arxiv.org/abs/2010.06997",
          "publishedOn": "2021-06-08T02:20:25.623Z",
          "wordCount": 676,
          "title": "Measuring the originality of intellectual property assets based on machine learning outputs. (arXiv:2010.06997v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhuoran Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_A/0/1/0/all/0/1\">Anders S. Christensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welborn_M/0/1/0/all/0/1\">Matthew Welborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manby_F/0/1/0/all/0/1\">Frederick R. Manby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1\">Thomas F. Miller III</a>",
          "description": "Equivariant neural networks have been successful in incorporating various\ntypes of symmetries, but are mostly limited to vector representations of\ngeometric objects. Despite the prevalence of higher-order tensors in various\napplication domains, e.g. in quantum chemistry, equivariant neural networks for\ngeneral tensors remain unexplored. Previous strategies for learning equivariant\nfunctions on tensors mostly rely on expensive tensor factorization which is not\nscalable when the dimensionality of the problem becomes large. In this work, we\npropose unitary $N$-body tensor equivariant neural network (UNiTE), an\narchitecture for a general class of symmetric tensors called $N$-body tensors.\nThe proposed neural network is equivariant with respect to the actions of a\nunitary group, such as the group of 3D rotations. Furthermore, it has a linear\ntime complexity with respect to the number of non-zero elements in the tensor.\nWe also introduce a normalization method, viz., Equivariant Normalization, to\nimprove generalization of the neural network while preserving symmetry. When\napplied to quantum chemistry, UNiTE outperforms all state-of-the-art machine\nlearning methods of that domain with over 110% average improvements on multiple\nbenchmarks. Finally, we show that UNiTE achieves a robust zero-shot\ngeneralization performance on diverse down stream chemistry tasks, while being\nthree orders of magnitude faster than conventional numerical methods with\ncompetitive accuracy.",
          "link": "http://arxiv.org/abs/2105.14655",
          "publishedOn": "2021-06-08T02:20:25.610Z",
          "wordCount": 667,
          "title": "UNiTE: Unitary N-body Tensor Equivariant Network with Applications to Quantum Chemistry. (arXiv:2105.14655v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1\">Antoine de Mathelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1\">Francois Deheeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1\">Mathilde Mougeot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The goal of the paper is to design active learning strategies which lead to\ndomain adaptation under an assumption of covariate shift in the case of\nLipschitz labeling function. Building on previous work by Mansour et al. (2009)\nwe adapt the concept of discrepancy distance between source and target\ndistributions to restrict the maximization over the hypothesis class to a\nlocalized class of functions which are performing accurate labeling on the\nsource domain. We derive generalization error bounds for such active learning\nstrategies in terms of Rademacher average and localized discrepancy for general\nloss functions which satisfy a regularity condition. A practical K-medoids\nalgorithm that can address the case of large data set is inferred from the\ntheoretical bounds. Our numerical experiments show that the proposed algorithm\nis competitive against other state-of-the-art active learning techniques in the\ncontext of domain adaptation, in particular on large data sets of around one\nhundred thousand images.",
          "link": "http://arxiv.org/abs/2103.03757",
          "publishedOn": "2021-06-08T02:20:25.600Z",
          "wordCount": 606,
          "title": "Discrepancy-Based Active Learning for Domain Adaptation. (arXiv:2103.03757v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ansari_A/0/1/0/all/0/1\">Abdul Fatir Ansari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Ming Liang Ang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1\">Harold Soh</a>",
          "description": "Deep generative modeling has seen impressive advances in recent years, to the\npoint where it is now commonplace to see simulated samples (e.g., images) that\nclosely resemble real-world data. However, generation quality is generally\ninconsistent for any given model and can vary dramatically between samples. We\nintroduce Discriminator Gradient flow (DGflow), a new technique that improves\ngenerated samples via the gradient flow of entropy-regularized f-divergences\nbetween the real and the generated data distributions. The gradient flow takes\nthe form of a non-linear Fokker-Plank equation, which can be easily simulated\nby sampling from the equivalent McKean-Vlasov process. By refining inferior\nsamples, our technique avoids wasteful sample rejection used by previous\nmethods (DRS & MH-GAN). Compared to existing works that focus on specific GAN\nvariants, we show our refinement approach can be applied to GANs with\nvector-valued critics and even other deep generative models such as VAEs and\nNormalizing Flows. Empirical results on multiple synthetic, image, and text\ndatasets demonstrate that DGflow leads to significant improvement in the\nquality of generated samples for a variety of generative models, outperforming\nthe state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator\nDriven Latent Sampling (DDLS) methods.",
          "link": "http://arxiv.org/abs/2012.00780",
          "publishedOn": "2021-06-08T02:20:25.585Z",
          "wordCount": 684,
          "title": "Refining Deep Generative Models via Discriminator Gradient Flow. (arXiv:2012.00780v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1\">Michael F. Zimmer</a>",
          "description": "The purpose of this paper is to improve upon existing variants of gradient\ndescent by solving two problems: (1) removing (or reducing) the plateau that\noccurs while minimizing the cost function,(2) continually adjusting the\nlearning rate to an \"ideal\" value. The approach taken is to approximately solve\nfor the learning rate as a function of a trust metric. When this technique is\nhybridized with momentum, it creates an especially effective gradient descent\nvariant, called NeogradM. It is shown to outperform Adam on several test\nproblems, and can easily reach cost function values that are smaller by a\nfactor of $10^8$.",
          "link": "http://arxiv.org/abs/2010.07873",
          "publishedOn": "2021-06-08T02:20:25.572Z",
          "wordCount": 559,
          "title": "Neograd: Near-Ideal Gradient Descent. (arXiv:2010.07873v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06828",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathbun_S/0/1/0/all/0/1\">Stephen L. Rathbun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "The dramatically growing availability of observational data is being\nwitnessed in various domains of science and technology, which facilitates the\nstudy of causal inference. However, estimating treatment effects from\nobservational data is faced with two major challenges, missing counterfactual\noutcomes and treatment selection bias. Matching methods are among the most\nwidely used and fundamental approaches to estimating treatment effects, but\nexisting matching methods have poor performance when facing data with high\ndimensional and complicated variables. We propose a feature selection\nrepresentation matching (FSRM) method based on deep representation learning and\nmatching, which maps the original covariate space into a selective, nonlinear,\nand balanced representation space, and then conducts matching in the learned\nrepresentation space. FSRM adopts deep feature selection to minimize the\ninfluence of irrelevant variables for estimating treatment effects and\nincorporates a regularizer based on the Wasserstein distance to learn balanced\nrepresentations. We evaluate the performance of our FSRM method on three\ndatasets, and the results demonstrate superiority over the state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2009.06828",
          "publishedOn": "2021-06-08T02:20:25.555Z",
          "wordCount": 638,
          "title": "Matching in Selective and Balanced Representation Space for Treatment Effects Estimation. (arXiv:2009.06828v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nozawa_K/0/1/0/all/0/1\">Kento Nozawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>",
          "description": "Instance discriminative self-supervised representation learning has been\nattracted attention thanks to its unsupervised nature and informative feature\nrepresentation for downstream tasks. In practice, it commonly uses a larger\nnumber of negative samples than the number of supervised classes. However,\nthere is an inconsistency in the existing analysis; theoretically, a large\nnumber of negative samples degrade classification performance on a downstream\nsupervised task, while empirically, they improve the performance. We provide a\nnovel framework to analyze this empirical result regarding negative samples\nusing the coupon collector's problem. Our bound can implicitly incorporate the\nsupervised loss of the downstream task in the self-supervised loss by\nincreasing the number of negative samples. We confirm that our proposed\nanalysis holds on real-world benchmark datasets.",
          "link": "http://arxiv.org/abs/2102.06866",
          "publishedOn": "2021-06-08T02:20:25.537Z",
          "wordCount": 582,
          "title": "Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning. (arXiv:2102.06866v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04324",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1\">Vivien Cabannes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1\">Loucas Pillaud-Vivien</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1\">Francis Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1\">Alessandro Rudi</a>",
          "description": "As annotations of data can be scarce in large-scale practical problems,\nleveraging unlabelled examples is one of the most important aspects of machine\nlearning. This is the aim of semi-supervised learning. To benefit from the\naccess to unlabelled data, it is natural to diffuse smoothly knowledge of\nlabelled data to unlabelled one. This induces to the use of Laplacian\nregularization. Yet, current implementations of Laplacian regularization suffer\nfrom several drawbacks, notably the well-known curse of dimensionality. In this\npaper, we provide a statistical analysis to overcome those issues, and unveil a\nlarge body of spectral filtering methods that exhibit desirable behaviors. They\nare implemented through (reproducing) kernel methods, for which we provide\nrealistic computational guidelines in order to make our method usable with\nlarge amounts of data.",
          "link": "http://arxiv.org/abs/2009.04324",
          "publishedOn": "2021-06-08T02:20:25.531Z",
          "wordCount": 592,
          "title": "Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning. (arXiv:2009.04324v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_S/0/1/0/all/0/1\">Siu Lun Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouabid_S/0/1/0/all/0/1\">Shahine Bouabid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>",
          "description": "Refining low-resolution (LR) spatial fields with high-resolution (HR)\ninformation is challenging as the diversity of spatial datasets often prevents\ndirect matching of observations. Yet, when LR samples are modeled as aggregate\nconditional means of HR samples with respect to a mediating variable that is\nglobally observed, the recovery of the underlying fine-grained field can be\nframed as taking an \"inverse\" of the conditional expectation, namely a\ndeconditioning problem. In this work, we introduce conditional mean processes\n(CMP), a new class of Gaussian Processes describing conditional means. By\ntreating CMPs as inter-domain features of the underlying field, a posterior for\nthe latent field can be established as a solution to the deconditioning\nproblem. Furthermore, we show that this solution can be viewed as a two-staged\nvector-valued kernel ridge regressor and show that it has a minimax optimal\nconvergence rate under mild assumptions. Lastly, we demonstrate its proficiency\nin a synthetic and a real-world atmospheric field downscaling problem, showing\nsubstantial improvements over existing methods.",
          "link": "http://arxiv.org/abs/2105.12909",
          "publishedOn": "2021-06-08T02:20:25.525Z",
          "wordCount": 609,
          "title": "Deconditional Downscaling with Gaussian Processes. (arXiv:2105.12909v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Real-world data inevitably contains noisy labels, which induce the poor\ngeneralization of deep neural networks. It is known that the network typically\nbegins to rapidly memorize false-labeled samples after a certain point of\ntraining. Thus, to counter the label noise challenge, we propose a novel\nself-transitional learning method called MORPH, which automatically switches\nits learning phase at the transition point from seeding to evolution. In the\nseeding phase, the network is updated using all the samples to collect a seed\nof clean samples. Then, in the evolution phase, the network is updated using\nonly the set of arguably clean samples, which precisely keeps expanding by the\nupdated network. Thus, MORPH effectively avoids the overfitting to\nfalse-labeled samples throughout the entire training period. Extensive\nexperiments using five real-world or synthetic benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods in terms of robustness\nand efficiency.",
          "link": "http://arxiv.org/abs/2012.04337",
          "publishedOn": "2021-06-08T02:20:25.519Z",
          "wordCount": 614,
          "title": "Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-06-08T02:20:25.512Z",
          "wordCount": 744,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mostafa_F/0/1/0/all/0/1\">Fahad B. Mostafa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hasan_M/0/1/0/all/0/1\">Md Easin Hasan</a>",
          "description": "For a medical diagnosis, health professionals use different kinds of\npathological ways to make a decision for medical reports in terms of patients\nmedical condition. In the modern era, because of the advantage of computers and\ntechnologies, one can collect data and visualize many hidden outcomes from\nthem. Statistical machine learning algorithms based on specific problems can\nassist one to make decisions. Machine learning data driven algorithms can be\nused to validate existing methods and help researchers to suggest potential new\ndecisions. In this paper, multiple imputation by chained equations was applied\nto deal with missing data, and Principal Component Analysis to reduce the\ndimensionality. To reveal significant findings, data visualizations were\nimplemented. We presented and compared many binary classifier machine learning\nalgorithms (Artificial Neural Network, Random Forest, Support Vector Machine)\nwhich were used to classify blood donors and non-blood donors with hepatitis,\nfibrosis and cirrhosis diseases. From the data published in UCI-MLR [1], all\nmentioned techniques were applied to find one better method to classify blood\ndonors and non-blood donors (hepatitis, fibrosis, and cirrhosis) that can help\nhealth professionals in a laboratory to make better decisions. Our proposed\nML-method showed better accuracy score (e.g. 98.23% for SVM). Thus, it improved\nthe quality of classification.",
          "link": "http://arxiv.org/abs/2104.12055",
          "publishedOn": "2021-06-08T02:20:25.495Z",
          "wordCount": 660,
          "title": "Machine Learning Approaches for Binary Classification to Discover Liver Diseases using Clinical Data. (arXiv:2104.12055v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toenshoff_J/0/1/0/all/0/1\">Jan Toenshoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritzert_M/0/1/0/all/0/1\">Martin Ritzert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_H/0/1/0/all/0/1\">Hinrikus Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>",
          "description": "We propose CRaWl (CNNs for Random Walks), a novel neural network architecture\nfor graph learning. It is based on processing sequences of small subgraphs\ninduced by random walks with standard 1D CNNs. Thus, CRaWl is fundamentally\ndifferent from typical message passing graph neural network architectures. It\nis inspired by techniques counting small subgraphs, such as the graphlet kernel\nand motif counting, and combines them with random walk based techniques in a\nhighly efficient and scalable neural architecture. We demonstrate empirically\nthat CRaWl matches or outperforms state-of-the-art GNN architectures across a\nmultitude of benchmark datasets for classification and regression on graphs.",
          "link": "http://arxiv.org/abs/2102.08786",
          "publishedOn": "2021-06-08T02:20:25.488Z",
          "wordCount": 556,
          "title": "Graph Learning with 1D Convolutions on Random Walks. (arXiv:2102.08786v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matni_N/0/1/0/all/0/1\">Nikolai Matni</a>",
          "description": "We study the following question in the context of imitation learning for\ncontinuous control: how are the underlying stability properties of an expert\npolicy reflected in the sample-complexity of an imitation learning task? We\nprovide the first results showing that a surprisingly granular connection can\nbe made between the underlying expert system's incremental gain stability, a\nnovel measure of robust convergence between pairs of system trajectories, and\nthe dependency on the task horizon $T$ of the resulting generalization bounds.\nIn particular, we propose and analyze incremental gain stability constrained\nversions of behavior cloning and a DAgger-like algorithm, and show that the\nresulting sample-complexity bounds naturally reflect the underlying stability\nproperties of the expert system. As a special case, we delineate a class of\nsystems for which the number of trajectories needed to achieve\n$\\varepsilon$-suboptimality is sublinear in the task horizon $T$, and do so\nwithout requiring (strong) convexity of the loss function in the policy\nparameters. Finally, we conduct numerical experiments demonstrating the\nvalidity of our insights on both a simple nonlinear system for which the\nunderlying stability properties can be easily tuned, and on a high-dimensional\nquadrupedal robotic simulation.",
          "link": "http://arxiv.org/abs/2102.09161",
          "publishedOn": "2021-06-08T02:20:25.476Z",
          "wordCount": 651,
          "title": "On the Sample Complexity of Stability Constrained Imitation Learning. (arXiv:2102.09161v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Takashi Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "The noise in stochastic gradient descent (SGD), caused by minibatch sampling,\nis poorly understood despite its practical importance in deep learning. In this\nwork, we study the nature of SGD noise and fluctuation. We show that some\ndegree of mismatch between model and data complexity is needed for SGD to\n``stir\" a noise; such mismatch may be due to a label or input noise,\nregularization, or underparametrization. Compared with previous works, the\npresent work focuses on deriving exactly solvable analytical results. Our work\nalso motivates a more accurate general formulation to describe minibatch noise,\nand we show that the SGD noise takes different shapes and strengths in\ndifferent kinds of minima.",
          "link": "http://arxiv.org/abs/2102.05375",
          "publishedOn": "2021-06-08T02:20:25.460Z",
          "wordCount": 570,
          "title": "Strength of Minibatch Noise in SGD. (arXiv:2102.05375v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05126",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "In this paper we suggest two statistical hypothesis tests for the regression\nfunction of binary classification based on conditional kernel mean embeddings.\nThe regression function is a fundamental object in classification as it\ndetermines both the Bayes optimal classifier and the misclassification\nprobabilities. A resampling based framework is presented and combined with\nconsistent point estimators of the conditional kernel mean map, in order to\nconstruct distribution-free hypothesis tests. These tests are introduced in a\nflexible manner allowing us to control the exact probability of type I error\nfor any sample size. We also prove that both proposed techniques are consistent\nunder weak statistical assumptions, i.e., the type II error probabilities\npointwise converge to zero.",
          "link": "http://arxiv.org/abs/2103.05126",
          "publishedOn": "2021-06-08T02:20:25.366Z",
          "wordCount": null,
          "title": "Exact Distribution-Free Hypothesis Tests for the Regression Function of Binary Classification via Conditional Kernel Mean Embeddings. (arXiv:2103.05126v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Campos_V/0/1/0/all/0/1\">V&#xed;ctor Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1\">Pablo Sprechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_S/0/1/0/all/0/1\">Steven Hansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1\">Andre Barreto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapturowski_S/0/1/0/all/0/1\">Steven Kapturowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitvitskyi_A/0/1/0/all/0/1\">Alex Vitvitskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badia_A/0/1/0/all/0/1\">Adri&#xe0; Puigdom&#xe8;nech Badia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1\">Charles Blundell</a>",
          "description": "Designing agents that acquire knowledge autonomously and use it to solve new\ntasks efficiently is an important challenge in reinforcement learning.\nKnowledge acquired during an unsupervised pre-training phase is often\ntransferred by fine-tuning neural network weights once rewards are exposed, as\nis common practice in supervised domains. Given the nature of the reinforcement\nlearning problem, we argue that standard fine-tuning strategies alone are not\nenough for efficient transfer in challenging domains. We introduce Behavior\nTransfer (BT), a technique that leverages pre-trained policies for exploration\nand that is complementary to transferring neural network weights. Our\nexperiments show that, when combined with large-scale pre-training in the\nabsence of rewards, existing intrinsic motivation objectives can lead to the\nemergence of complex behaviors. These pre-trained policies can then be\nleveraged by BT to discover better solutions than without pre-training, and\ncombining BT with standard fine-tuning strategies results in additional\nbenefits. The largest gains are generally observed in domains requiring\nstructured exploration, including settings where the behavior of the\npre-trained policies is misaligned with the downstream task.",
          "link": "http://arxiv.org/abs/2102.13515",
          "publishedOn": "2021-06-08T02:20:25.365Z",
          "wordCount": null,
          "title": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning. (arXiv:2102.13515v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Etter_P/0/1/0/all/0/1\">Philip A. Etter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1\">Kai Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hsiang-Fu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1\">Lexing Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit Dhillon</a>",
          "description": "Tree-based models underpin many modern semantic search engines and\nrecommender systems due to their sub-linear inference times. In industrial\napplications, these models operate at extreme scales, where every bit of\nperformance is critical. Memory constraints at extreme scales also require that\nmodels be sparse, hence tree-based models are often back-ended by sparse matrix\nalgebra routines. However, there are currently no sparse matrix techniques\nspecifically designed for the sparsity structure one encounters in tree-based\nmodels for extreme multi-label ranking/classification (XMR/XMC) problems. To\naddress this issue, we present the masked sparse chunk multiplication (MSCM)\ntechnique, a sparse matrix technique specifically tailored to XMR trees. MSCM\nis easy to implement, embarrassingly parallelizable, and offers a significant\nperformance boost to any existing tree inference pipeline at no cost. We\nperform a comprehensive study of MSCM applied to several different sparse\ninference schemes and benchmark our methods on a general purpose extreme\nmulti-label ranking framework. We observe that MSCM gives consistently dramatic\nspeedups across both the online and batch inference settings, single- and\nmulti-threaded settings, and on many different tree models and datasets. To\ndemonstrate its utility in industrial applications, we apply MSCM to an\nenterprise-scale semantic product search problem with 100 million products and\nachieve sub-millisecond latency of 0.88 ms per query on a single thread -- an\n8x reduction in latency over vanilla inference techniques. The MSCM technique\nrequires absolutely no sacrifices to model accuracy as it gives exactly the\nsame results as standard sparse matrix techniques. Therefore, we believe that\nMSCM will enable users of XMR trees to save a substantial amount of compute\nresources in their inference pipelines at very little cost.",
          "link": "http://arxiv.org/abs/2106.02697",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "Accelerating Inference for Sparse Extreme Multi-Label Ranking Trees. (arXiv:2106.02697v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.13954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongrui Wu</a>",
          "description": "Over-parameterized deep neural networks (DNNs) with sufficient capacity to\nmemorize random noise can achieve excellent generalization performance,\nchallenging the bias-variance trade-off in classical learning theory. Recent\nstudies claimed that DNNs first learn simple patterns and then memorize noise;\nsome other works showed a phenomenon that DNNs have a spectral bias to learn\ntarget functions from low to high frequencies during training. However, we show\nthat the monotonicity of the learning bias does not always hold: under the\nexperimental setup of deep double descent, the high-frequency components of\nDNNs diminish in the late stage of training, leading to the second descent of\nthe test error. Besides, we find that the spectrum of DNNs can be applied to\nindicating the second descent of the test error, even though it is calculated\nfrom the training set only.",
          "link": "http://arxiv.org/abs/2004.13954",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "Rethink the Connections among Generalization, Memorization and the Spectral Bias of DNNs. (arXiv:2004.13954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1\">Jay Whang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Anish Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyeji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1\">Alexandros G. Dimakis</a>",
          "description": "Distributed source coding is the task of encoding an input in the absence of\ncorrelated side information that is only available to the decoder. Remarkably,\nSlepian and Wolf showed in 1973 that an encoder that has no access to the\ncorrelated side information can asymptotically achieve the same compression\nrate as when the side information is available at both the encoder and the\ndecoder. While there is significant prior work on this topic in information\ntheory, practical distributed source coding has been limited to synthetic\ndatasets and specific correlation structures. Here we present a general\nframework for lossy distributed source coding that is agnostic to the\ncorrelation structure and can scale to high dimensions. Rather than relying on\nhand-crafted source-modeling, our method utilizes a powerful conditional deep\ngenerative model to learn the distributed encoder and decoder. We evaluate our\nmethod on realistic high-dimensional datasets and show substantial improvements\nin distributed compression performance.",
          "link": "http://arxiv.org/abs/2106.02797",
          "publishedOn": "2021-06-08T02:20:25.294Z",
          "wordCount": null,
          "title": "Neural Distributed Source Coding. (arXiv:2106.02797v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2005.13273",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1\">Chihiro Watanabe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Model selection in latent block models has been a challenging but important\ntask in the field of statistics. Specifically, a major challenge is encountered\nwhen constructing a test on a block structure obtained by applying a specific\nclustering algorithm to a finite size matrix. In this case, it becomes crucial\nto consider the selective bias in the block structure, that is, the block\nstructure is selected from all the possible cluster memberships based on some\ncriterion by the clustering algorithm. To cope with this problem, this study\nprovides a selective inference method for latent block models. Specifically, we\nconstruct a statistical test on a set of row and column cluster memberships of\na latent block model, which is given by a squared residue minimization\nalgorithm. The proposed test, by its nature, includes and thus can also be used\nas the test on the set of row and column cluster numbers. We also propose an\napproximated version of the test based on simulated annealing to avoid\ncombinatorial explosion in searching the optimal block structure. The results\nshow that the proposed exact and approximated tests work effectively, compared\nto the naive test that did not take the selective bias into account.",
          "link": "http://arxiv.org/abs/2005.13273",
          "publishedOn": "2021-06-08T02:20:25.294Z",
          "wordCount": null,
          "title": "Selective Inference for Latent Block Models. (arXiv:2005.13273v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1\">Glenn Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1\">Robi Polikar</a>",
          "description": "Most studies on learning from noisy labels rely on unrealistic models of\ni.i.d. label noise, such as class-conditional transition matrices. More recent\nwork on instance-dependent noise models are more realistic, but assume a single\ngenerative process for label noise across the entire dataset. We propose a more\nprincipled model of label noise that generalizes instance-dependent noise to\nmultiple labelers, based on the observation that modern datasets are typically\nannotated using distributed crowdsourcing methods. Under our labeler-dependent\nmodel, label noise manifests itself under two modalities: natural error of\ngood-faith labelers, and adversarial labels provided by malicious actors. We\npresent two adversarial attack vectors that more accurately reflect the label\nnoise that may be encountered in real-world settings, and demonstrate that\nunder our multimodal noisy labels model, state-of-the-art approaches for\nlearning from noisy labels are defeated by adversarial label attacks. Finally,\nwe propose a multi-stage, labeler-aware, model-agnostic framework that reliably\nfilters noisy labels by leveraging knowledge about which data partitions were\nlabeled by which labeler, and show that our proposed framework remains robust\neven in the presence of extreme adversarial label noise.",
          "link": "http://arxiv.org/abs/2105.14083",
          "publishedOn": "2021-06-08T02:20:25.285Z",
          "wordCount": null,
          "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial Awareness. (arXiv:2105.14083v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1\">Robert Turko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what they\nhave learned, and how they can improve. We present Dodrio, an open-source\ninteractive visualization tool to help NLP researchers and practitioners\nanalyze attention mechanisms in transformer-based models with linguistic\nknowledge. Dodrio tightly integrates an overview that summarizes the roles of\ndifferent attention heads, and detailed views that help users compare attention\nweights with the syntactic structure and semantic information in the input\ntext. To facilitate the visual comparison of attention weights and linguistic\nknowledge, Dodrio applies different graph visualization techniques to represent\nattention weights scalable to longer input text. Case studies highlight how\nDodrio provides insights into understanding the attention mechanism in\ntransformer-based models. Dodrio is available at\nhttps://poloclub.github.io/dodrio/.",
          "link": "http://arxiv.org/abs/2103.14625",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangtao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qinbao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>",
          "description": "Recommending appropriate algorithms to a classification problem is one of the\nmost challenging issues in the field of data mining. The existing algorithm\nrecommendation models are generally constructed on only one kind of\nmeta-features by single learners. Considering that i) ensemble learners usually\nshow better performance and ii) different kinds of meta-features characterize\nthe classification problems in different viewpoints independently, and further\nthe models constructed with different sets of meta-features will be\ncomplementary with each other and applicable for ensemble. This paper proposes\nan ensemble learning-based algorithm recommendation method. To evaluate the\nproposed recommendation method, extensive experiments with 13 well-known\ncandidate classification algorithms and five different kinds of meta-features\nare conducted on 1090 benchmark classification problems. The results show the\neffectiveness of the proposed ensemble learning based recommendation method.",
          "link": "http://arxiv.org/abs/2101.05993",
          "publishedOn": "2021-06-08T02:20:25.282Z",
          "wordCount": null,
          "title": "Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1\">Glenn Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1\">Robi Polikar</a>",
          "description": "As larger and more comprehensive datasets become standard in contemporary\nmachine learning, it becomes increasingly more difficult to obtain reliable,\ntrustworthy label information with which to train sophisticated models. To\naddress this problem, crowdsourcing has emerged as a popular, inexpensive, and\nefficient data mining solution for performing distributed label collection.\nHowever, crowdsourced annotations are inherently untrustworthy, as the labels\nare provided by anonymous volunteers who may have varying, unreliable\nexpertise. Worse yet, some participants on commonly used platforms such as\nAmazon Mechanical Turk may be adversarial, and provide intentionally incorrect\nlabel information without the end user's knowledge. We discuss three\nconventional models of the label generation process, describing their\nparameterizations and the model-based approaches used to solve them. We then\npropose OpinionRank, a model-free, interpretable, graph-based spectral\nalgorithm for integrating crowdsourced annotations into reliable labels for\nperforming supervised or semi-supervised learning. Our experiments show that\nOpinionRank performs favorably when compared against more highly parameterized\nalgorithms. We also show that OpinionRank is scalable to very large datasets\nand numbers of label sources, and requires considerably fewer computational\nresources than previous approaches.",
          "link": "http://arxiv.org/abs/2102.05884",
          "publishedOn": "2021-06-08T02:20:25.282Z",
          "wordCount": null,
          "title": "OpinionRank: Extracting Ground Truth Labels from Unreliable Expert Opinions with Graph-Based Spectral Ranking. (arXiv:2102.05884v2 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>",
          "description": "Many works in signal processing and learning theory operate under the\nassumption that the underlying model is simple, e.g. that a signal is\napproximately $k$-Fourier-sparse or that a distribution can be approximated by\na mixture model that has at most $k$ components. However the problem of fitting\nthe parameters of such a model becomes more challenging when the\nfrequencies/components are too close together.\n\nIn this work we introduce new methods for sparsifying sums of exponentials\nand give various algorithmic applications. First we study Fourier-sparse\ninterpolation without a frequency gap, where Chen et al. gave an algorithm for\nfinding an $\\epsilon$-approximate solution which uses $k' = \\mbox{poly}(k, \\log\n1/\\epsilon)$ frequencies. Second, we study learning Gaussian mixture models in\none dimension without a separation condition. Kernel density estimators give an\n$\\epsilon$-approximation that uses $k' = O(k/\\epsilon^2)$ components. These\nmethods both output models that are much more complex than what we started out\nwith. We show how to post-process to reduce the number of\nfrequencies/components down to $k' = \\widetilde{O}(k)$, which is optimal up to\nlogarithmic factors. Moreover we give applications to model selection. In\nparticular, we give the first algorithms for approximately (and robustly)\ndetermining the number of components in a Gaussian mixture model that work\nwithout a separation condition.",
          "link": "http://arxiv.org/abs/2106.02774",
          "publishedOn": "2021-06-08T02:20:25.281Z",
          "wordCount": null,
          "title": "Sparsification for Sums of Exponentials and its Algorithmic Applications. (arXiv:2106.02774v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilgard_S/0/1/0/all/0/1\">Sophie Hilgard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Counterfactual explanations are emerging as an attractive option for\nproviding recourse to individuals adversely impacted by algorithmic decisions.\nAs they are deployed in critical applications (e.g. law enforcement, financial\nlending), it becomes important to ensure that we clearly understand the\nvulnerabilities of these methods and find ways to address them. However, there\nis little understanding of the vulnerabilities and shortcomings of\ncounterfactual explanations. In this work, we introduce the first framework\nthat describes the vulnerabilities of counterfactual explanations and shows how\nthey can be manipulated. More specifically, we show counterfactual explanations\nmay converge to drastically different counterfactuals under a small\nperturbation indicating they are not robust. Leveraging this insight, we\nintroduce a novel objective to train seemingly fair models where counterfactual\nexplanations find much lower cost recourse under a slight perturbation. We\ndescribe how these models can unfairly provide low-cost recourse for specific\nsubgroups in the data while appearing fair to auditors. We perform experiments\non loan and violent crime prediction data sets where certain subgroups achieve\nup to 20x lower cost recourse under the perturbation. These results raise\nconcerns regarding the dependability of current counterfactual explanation\ntechniques, which we hope will inspire investigations in robust counterfactual\nexplanations.",
          "link": "http://arxiv.org/abs/2106.02666",
          "publishedOn": "2021-06-08T02:20:25.275Z",
          "wordCount": null,
          "title": "Counterfactual Explanations Can Be Manipulated. (arXiv:2106.02666v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "Recently, hypergraphs have attracted a lot of attention due to their ability\nto capture complex relations among entities. The insurgence of hypergraphs has\nresulted in data of increasing size and complexity that exhibit interesting\nsmall-scale and local structure, e.g., small-scale communities and localized\nnode-ranking around a given set of seed nodes. Popular and principled ways to\ncapture the local structure are the local hypergraph clustering problem and\nrelated seed set expansion problem. In this work, we propose the first local\ndiffusion method that achieves edge-size-independent Cheeger-type guarantee for\nthe problem of local hypergraph clustering while applying to a rich class of\nhigher-order relations that covers many previously studied special cases. Our\nmethod is based on a primal-dual optimization formulation where the primal\nproblem has a natural network flow interpretation, and the dual problem has a\ncut-based interpretation using the $\\ell_2$-norm penalty on associated\ncut-costs. We demonstrate the new technique is significantly better than\nstate-of-the-art methods on both synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2102.07945",
          "publishedOn": "2021-06-08T02:20:25.270Z",
          "wordCount": null,
          "title": "Local Hyper-Flow Diffusion. (arXiv:2102.07945v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1\">Agustinus Kristiadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "Laplace approximations are classic, computationally lightweight means for\nconstructing Bayesian neural networks (BNNs). As in other approximate BNNs, one\ncannot necessarily expect the induced predictive uncertainty to be calibrated.\nHere we develop a formalism to explicitly \"train\" the uncertainty in a\ndecoupled way to the prediction itself. To this end, we introduce uncertainty\nunits for Laplace-approximated networks: Hidden units associated with a\nparticular weight structure that can be added to any pre-trained,\npoint-estimated network. Due to their weights, these units are inactive -- they\ndo not affect the predictions. But their presence changes the geometry (in\nparticular the Hessian) of the loss landscape, thereby affecting the network's\nuncertainty estimates under a Laplace approximation. We show that such units\ncan be trained via an uncertainty-aware objective, improving standard Laplace\napproximations' performance in various uncertainty quantification tasks.",
          "link": "http://arxiv.org/abs/2010.02720",
          "publishedOn": "2021-06-08T02:20:25.225Z",
          "wordCount": null,
          "title": "Learnable Uncertainty under Laplace Approximations. (arXiv:2010.02720v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1\">He Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1\">Daniel M. Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1\">Pravesh K. Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1\">Santosh S. Vempala</a>",
          "description": "We give a polynomial-time algorithm for the problem of robustly estimating a\nmixture of $k$ arbitrary Gaussians in $\\mathbb{R}^d$, for any fixed $k$, in the\npresence of a constant fraction of arbitrary corruptions. This resolves the\nmain open problem in several previous works on algorithmic robust statistics,\nwhich addressed the special cases of robustly estimating (a) a single Gaussian,\n(b) a mixture of TV-distance separated Gaussians, and (c) a uniform mixture of\ntwo Gaussians. Our main tools are an efficient \\emph{partial clustering}\nalgorithm that relies on the sum-of-squares method, and a novel \\emph{tensor\ndecomposition} algorithm that allows errors in both Frobenius norm and low-rank\nterms.",
          "link": "http://arxiv.org/abs/2012.02119",
          "publishedOn": "2021-06-08T02:20:25.176Z",
          "wordCount": null,
          "title": "Robustly Learning Mixtures of $k$ Arbitrary Gaussians. (arXiv:2012.02119v3 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chun-Hao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Sarah Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Ben Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1\">Anna Goldenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1\">Rich Caruana</a>",
          "description": "Generalized additive models (GAMs) have become a leading modelclass for\ninterpretable machine learning. However, there are many algorithms for training\nGAMs, and these can learn different or even contradictory models, while being\nequally accurate. Which GAM should we trust? In this paper, we quantitatively\nand qualitatively investigate a variety of GAM algorithms on real and simulated\ndatasets. We find that GAMs with high feature sparsity (only using afew\nvariables to make predictions) can miss patterns in the data and be unfair to\nrare subpopulations. Our results suggest that inductive bias plays a crucial\nrole in what interpretable models learn and that tree-based GAMs represent the\nbest balance of sparsity, fidelity and accuracy and thus appear to be the most\ntrustworthy GAM.",
          "link": "http://arxiv.org/abs/2006.06466",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "How Interpretable and Trustworthy are GAMs?. (arXiv:2006.06466v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>",
          "description": "We study generalization under labeled shift for categorical and general\nnormed label spaces. We propose a series of methods to estimate the importance\nweights from labeled source to unlabeled target domain and provide confidence\nbounds for these estimators. We deploy these estimators and provide\ngeneralization bounds in the unlabeled target domain.",
          "link": "http://arxiv.org/abs/2011.14251",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Importance Weight Estimation and Generalization in Domain Adaptation under Label Shift. (arXiv:2011.14251v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1\">Chandan Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1\">Sethupathy Parameswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ashish Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Suresh Sundaram</a>",
          "description": "Zero-shot learning is a new paradigm to classify objects from classes that\nare not available at training time. Zero-shot learning (ZSL) methods have\nattracted considerable attention in recent years because of their ability to\nclassify unseen/novel class examples. Most of the existing approaches on ZSL\nworks when all the samples from seen classes are available to train the model,\nwhich does not suit real life. In this paper, we tackle this hindrance by\ndeveloping a generative replay-based continual ZSL (GRCZSL). The proposed\nmethod endows traditional ZSL to learn from streaming data and acquire new\nknowledge without forgetting the previous tasks' gained experience. We handle\ncatastrophic forgetting in GRCZSL by replaying the synthetic samples of seen\nclasses, which have appeared in the earlier tasks. These synthetic samples are\nsynthesized using the trained conditional variational autoencoder (VAE) over\nthe immediate past task. Moreover, we only require the current and immediate\nprevious VAE at any time for training and testing. The proposed GRZSL method is\ndeveloped for a single-head setting of continual learning, simulating a\nreal-world problem setting. In this setting, task identity is given during\ntraining but unavailable during testing. GRCZSL performance is evaluated on\nfive benchmark datasets for the generalized setup of ZSL with fixed and dynamic\n(incremental class) settings of continual learning. The existing class setting\npresented recently in the literature is not suitable for a class-incremental\nsetting. Therefore, this paper proposes a new setting to address this issue.\nExperimental results show that the proposed method significantly outperforms\nthe baseline and the state-of-the-art method and makes it more suitable for\nreal-world applications.",
          "link": "http://arxiv.org/abs/2101.08894",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_G/0/1/0/all/0/1\">Guruprasad Raghavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomson_M/0/1/0/all/0/1\">Matt Thomson</a>",
          "description": "Machine learning problems have an intrinsic geometric structure as central\nobjects including a neural network's weight space and the loss function\nassociated with a particular task can be viewed as encoding the intrinsic\ngeometry of a given machine learning problem. Therefore, geometric concepts can\nbe applied to analyze and understand theoretical properties of machine learning\nstrategies as well as to develop new algorithms. In this paper, we address\nthree seemingly unrelated open questions in machine learning by viewing them\nthrough a unified framework grounded in differential geometry. Specifically, we\nview the weight space of a neural network as a manifold endowed with a\nRiemannian metric that encodes performance on specific tasks. By defining a\nmetric, we can construct geodesic, minimum length, paths in weight space that\nrepresent sets of networks of equivalent or near equivalent functional\nperformance on a specific task. We, then, traverse geodesic paths while\nidentifying networks that satisfy a second objective. Inspired by the geometric\ninsight, we apply our geodesic framework to 3 major applications: (i) Network\nsparsification (ii) Mitigating catastrophic forgetting by constructing networks\nwith high performance on a series of objectives and (iii) Finding high-accuracy\npaths connecting distinct local optima of deep networks in the non-convex loss\nlandscape. Our results are obtained on a wide range of network architectures\n(MLP, VGG11/16) trained on MNIST, CIFAR-10/100. Broadly, we introduce a\ngeometric framework that unifies a range of machine learning objectives and\nthat can be applied to multiple classes of neural network architectures.",
          "link": "http://arxiv.org/abs/2106.02793",
          "publishedOn": "2021-06-08T02:20:25.173Z",
          "wordCount": null,
          "title": "Solving hybrid machine learning tasks by traversing weight space geodesics. (arXiv:2106.02793v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.00815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qinghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1\">Sobhan Miryoosefi</a>",
          "description": "Finding the minimal structural assumptions that empower sample-efficient\nlearning is one of the most important research directions in Reinforcement\nLearning (RL). This paper advances our understanding of this fundamental\nquestion by introducing a new complexity measure -- Bellman Eluder (BE)\ndimension. We show that the family of RL problems of low BE dimension is\nremarkably rich, which subsumes a vast majority of existing tractable RL\nproblems including but not limited to tabular MDPs, linear MDPs, reactive\nPOMDPs, low Bellman rank problems as well as low Eluder dimension problems.\nThis paper further designs a new optimization-based algorithm -- GOLF, and\nreanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang\net al., 2017). We prove that both algorithms learn the near-optimal policies of\nlow BE dimension problems in a number of samples that is polynomial in all\nrelevant parameters, but independent of the size of state-action space. Our\nregret and sample complexity results match or improve the best existing results\nfor several well-known subclasses of low BE dimension problems.",
          "link": "http://arxiv.org/abs/2102.00815",
          "publishedOn": "2021-06-08T02:20:25.173Z",
          "wordCount": null,
          "title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Honglin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "We propose Federated Accelerated Stochastic Gradient Descent (FedAc), a\nprincipled acceleration of Federated Averaging (FedAvg, also known as Local\nSGD) for distributed optimization. FedAc is the first provable acceleration of\nFedAvg that improves convergence speed and communication efficiency on various\ntypes of convex functions. For example, for strongly convex and smooth\nfunctions, when using $M$ workers, the previous state-of-the-art FedAvg\nanalysis can achieve a linear speedup in $M$ if given $M$ rounds of\nsynchronization, whereas FedAc only requires $M^{\\frac{1}{3}}$ rounds.\nMoreover, we prove stronger guarantees for FedAc when the objectives are\nthird-order smooth. Our technique is based on a potential-based perturbed\niterate analysis, a novel stability analysis of generalized accelerated SGD,\nand a strategic tradeoff between acceleration and stability.",
          "link": "http://arxiv.org/abs/2006.08950",
          "publishedOn": "2021-06-08T02:20:25.166Z",
          "wordCount": 626,
          "title": "Federated Accelerated Stochastic Gradient Descent. (arXiv:2006.08950v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1902.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sakata_A/0/1/0/all/0/1\">Ayaka Sakata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Obuchi_T/0/1/0/all/0/1\">Tomoyuki Obuchi</a>",
          "description": "We consider compressed sensing formulated as a minimization problem of\nnonconvex sparse penalties, Smoothly Clipped Absolute deviation (SCAD) and\nMinimax Concave Penalty (MCP). The nonconvexity of these penalties is\ncontrolled by nonconvexity parameters, and L1 penalty is contained as a limit\nwith respect to these parameters. The analytically derived reconstruction limit\novercomes that of L1 and the algorithmic limit in the Bayes-optimal setting,\nwhen the nonconvexity parameters have suitable values. However, for small\nnonconvexity parameters, where the reconstruction of the relatively dense\nsignals is theoretically guaranteed, the corresponding approximate message\npassing (AMP) cannot achieve perfect reconstruction. We identify that the\nshrinks in the basin of attraction to the perfect reconstruction causes the\ndiscrepancy between the AMP and corresponding theory using state evolution. A\npart of the discrepancy is resolved by introducing the control of the\nnonconvexity parameters to guide the AMP trajectory to the basin of the\nattraction.",
          "link": "http://arxiv.org/abs/1902.07436",
          "publishedOn": "2021-06-08T02:20:25.147Z",
          "wordCount": 613,
          "title": "Perfect reconstruction of sparse signals with piecewise continuous nonconvex penalties and nonconvexity control. (arXiv:1902.07436v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.07162",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yue_M/0/1/0/all/0/1\">Man-Chung Yue</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wiesemann_W/0/1/0/all/0/1\">Wolfram Wiesemann</a>",
          "description": "Wasserstein balls, which contain all probability measures within a\npre-specified Wasserstein distance to a reference measure, have recently\nenjoyed wide popularity in the distributionally robust optimization and machine\nlearning communities to formulate and solve data-driven optimization problems\nwith rigorous statistical guarantees. In this technical note we prove that the\nWasserstein ball is weakly compact under mild conditions, and we offer\nnecessary and sufficient conditions for the existence of optimal solutions. We\nalso characterize the sparsity of solutions if the Wasserstein ball is centred\nat a discrete reference measure. In comparison with the existing literature,\nwhich has proved similar results under different conditions, our proofs are\nself-contained and shorter, yet mathematically rigorous, and our necessary and\nsufficient conditions for the existence of optimal solutions are easily\nverifiable in practice.",
          "link": "http://arxiv.org/abs/2004.07162",
          "publishedOn": "2021-06-08T02:20:25.138Z",
          "wordCount": null,
          "title": "On Linear Optimization over Wasserstein Balls. (arXiv:2004.07162v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Kaleel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rigel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>",
          "description": "Recent advances in attention-based networks have shown that Vision\nTransformers can achieve state-of-the-art or near state-of-the-art results on\nmany image classification tasks. This puts transformers in the unique position\nof being a promising alternative to traditional convolutional neural networks\n(CNNs). While CNNs have been carefully studied with respect to adversarial\nattacks, the same cannot be said of Vision Transformers. In this paper, we\nstudy the robustness of Vision Transformers to adversarial examples. Our\nanalyses of transformer security is divided into three parts. First, we test\nthe transformer under standard white-box and black-box attacks. Second, we\nstudy the transferability of adversarial examples between CNNs and\ntransformers. We show that adversarial examples do not readily transfer between\nCNNs and transformers. Based on this finding, we analyze the security of a\nsimple ensemble defense of CNNs and transformers. By creating a new attack, the\nself-attention blended gradient attack, we show that such an ensemble is not\nsecure under a white-box adversary. However, under a black-box adversary, we\nshow that an ensemble can achieve unprecedented robustness without sacrificing\nclean accuracy. Our analysis for this work is done using six types of white-box\nattacks and two types of black-box attacks. Our study encompasses multiple\nVision Transformers, Big Transfer Models and CNN architectures trained on\nCIFAR-10, CIFAR-100 and ImageNet.",
          "link": "http://arxiv.org/abs/2104.02610",
          "publishedOn": "2021-06-08T02:20:25.137Z",
          "wordCount": null,
          "title": "On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Larios_Cardenas_L/0/1/0/all/0/1\">Luis &#xc1;ngel Larios-C&#xe1;rdenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibou_F/0/1/0/all/0/1\">Frederic Gibou</a>",
          "description": "We present a novel hybrid strategy based on machine learning to improve\ncurvature estimation in the level-set method. The proposed inference system\ncouples enhanced neural networks with standard numerical schemes to compute\ncurvature more accurately. The core of our hybrid framework is a switching\nmechanism that relies on well established numerical techniques to gauge\ncurvature. If the curvature magnitude is larger than a resolution-dependent\nthreshold, it uses a neural network to yield a better approximation. Our\nnetworks are multilayer perceptrons fitted to synthetic data sets composed of\nsinusoidal- and circular-interface samples at various configurations. To reduce\ndata set size and training complexity, we leverage the problem's characteristic\nsymmetry and build our models on just half of the curvature spectrum. These\nsavings lead to a powerful inference system able to outperform any of its\nnumerical or neural component alone. Experiments with static, smooth interfaces\nshow that our hybrid solver is notably superior to conventional numerical\nmethods in coarse grids and along steep interface regions. Compared to prior\nresearch, we have observed outstanding gains in precision after training the\nregression model with data pairs from more than a single interface type and\ntransforming data with specialized input preprocessing. In particular, our\nfindings confirm that machine learning is a promising venue for reducing or\nremoving mass loss in the level-set method.",
          "link": "http://arxiv.org/abs/2104.02951",
          "publishedOn": "2021-06-08T02:20:25.136Z",
          "wordCount": null,
          "title": "A Hybrid Inference System for Improved Curvature Estimation in the Level-Set Method Using Machine Learning. (arXiv:2104.02951v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.05123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1\">Roi Pony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1\">Itay Naeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.",
          "link": "http://arxiv.org/abs/2002.05123",
          "publishedOn": "2021-06-08T02:20:25.135Z",
          "wordCount": null,
          "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Pengqian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_A/0/1/0/all/0/1\">Achintya Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wynter_L/0/1/0/all/0/1\">Laura Wynter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Shiau Hong Lim</a>",
          "description": "We present a class of methods for robust, personalized federated learning,\ncalled Fed+, that unifies many federated learning algorithms. The principal\nadvantage of this class of methods is to better accommodate the real-world\ncharacteristics found in federated training, such as the lack of IID data\nacross parties, the need for robustness to outliers or stragglers, and the\nrequirement to perform well on party-specific datasets. We achieve this through\na problem formulation that allows the central server to employ robust ways of\naggregating the local models while keeping the structure of local computation\nintact. Without making any statistical assumption on the degree of\nheterogeneity of local data across parties, we provide convergence guarantees\nfor Fed+ for convex and non-convex loss functions and robust aggregation. The\nFed+ theory is also equipped to handle heterogeneous computing environments\nincluding stragglers without additional assumptions; specifically, the\nconvergence results cover the general setting where the number of local update\nsteps across parties can vary. We demonstrate the benefits of Fed+ through\nextensive experiments across standard benchmark datasets as well as on a\nchallenging real-world problem in financial portfolio management where the\nheterogeneity of party-level data can lead to training failure in standard\nfederated learning approaches.",
          "link": "http://arxiv.org/abs/2009.06303",
          "publishedOn": "2021-06-08T02:20:25.134Z",
          "wordCount": null,
          "title": "Fed+: A Unified Approach to Robust Personalized Federated Learning. (arXiv:2009.06303v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.02437",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Luo_Y/0/1/0/all/0/1\">Yuetian Luo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Raskutti_G/0/1/0/all/0/1\">Garvesh Raskutti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yuan_M/0/1/0/all/0/1\">Ming Yuan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "In this paper, we develop novel perturbation bounds for the high-order\northogonal iteration (HOOI) [DLDMV00b]. Under mild regularity conditions, we\nestablish blockwise tensor perturbation bounds for HOOI with guarantees for\nboth tensor reconstruction in Hilbert-Schmidt norm $\\|\\widehat{\\bcT} - \\bcT\n\\|_{\\tHS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\\|\n\\sin \\Theta (\\widehat{\\U}_k, \\U_k) \\|_q$ for any $q \\geq 1$. We show the upper\nbounds of mode-$k$ singular subspace estimation are unilateral and converge\nlinearly to a quantity characterized by blockwise errors of the perturbation\nand signal strength. For the tensor reconstruction error bound, we express the\nbound through a simple quantity $\\xi$, which depends only on perturbation and\nthe multilinear rank of the underlying signal. Rate matching deterministic\nlower bound for tensor reconstruction, which demonstrates the optimality of\nHOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI\nwith only a single iteration) is also optimal in terms of tensor reconstruction\nand can be used to lower the computational cost. The perturbation results are\nalso extended to the case that only partial modes of $\\bcT$ have low-rank\nstructure. We support our theoretical results by extensive numerical studies.\nFinally, we apply the novel perturbation bounds of HOOI on two applications,\ntensor denoising and tensor co-clustering, from machine learning and\nstatistics, which demonstrates the superiority of the new perturbation results.",
          "link": "http://arxiv.org/abs/2008.02437",
          "publishedOn": "2021-06-08T02:20:25.133Z",
          "wordCount": null,
          "title": "A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration. (arXiv:2008.02437v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1\">Will Grathwohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1\">Kevin Swersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Milad Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1\">Chris J. Maddison</a>",
          "description": "We propose a general and scalable approximate sampling strategy for\nprobabilistic models with discrete variables. Our approach uses gradients of\nthe likelihood function with respect to its discrete inputs to propose updates\nin a Metropolis-Hastings sampler. We show empirically that this approach\noutperforms generic samplers in a number of difficult settings including Ising\nmodels, Potts models, restricted Boltzmann machines, and factorial hidden\nMarkov models. We also demonstrate the use of our improved sampler for training\ndeep energy-based models on high dimensional discrete data. This approach\noutperforms variational auto-encoders and existing energy-based models.\nFinally, we give bounds showing that our approach is near-optimal in the class\nof samplers which propose local updates.",
          "link": "http://arxiv.org/abs/2102.04509",
          "publishedOn": "2021-06-08T02:20:25.131Z",
          "wordCount": null,
          "title": "Oops I Took A Gradient: Scalable Sampling for Discrete Distributions. (arXiv:2102.04509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1\">Idan Achituve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1\">Aviv Navon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yemini_Y/0/1/0/all/0/1\">Yochai Yemini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1\">Ethan Fetaya</a>",
          "description": "Gaussian processes (GPs) are non-parametric, flexible, models that work well\nin many tasks. Combining GPs with deep learning methods via deep kernel\nlearning (DKL) is especially compelling due to the strong representational\npower induced by the network. However, inference in GPs, whether with or\nwithout DKL, can be computationally challenging on large datasets. Here, we\npropose GP-Tree, a novel method for multi-class classification with Gaussian\nprocesses and DKL. We develop a tree-based hierarchical model in which each\ninternal node of the tree fits a GP to the data using the P\\'olya-Gamma\naugmentation scheme. As a result, our method scales well with both the number\nof classes and data size. We demonstrate the effectiveness of our method\nagainst other Gaussian process training baselines, and we show how our general\nGP approach achieves improved accuracy on standard incremental few-shot\nlearning benchmarks.",
          "link": "http://arxiv.org/abs/2102.07868",
          "publishedOn": "2021-06-08T02:20:25.130Z",
          "wordCount": null,
          "title": "GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. (arXiv:2102.07868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>",
          "description": "We give a simple proof for the global convergence of gradient descent in\ntraining deep ReLU networks with the standard square loss, and show some of its\nimprovements over the state-of-the-art. In particular, while prior works\nrequire all the hidden layers to be wide with width at least $\\Omega(N^8)$ ($N$\nbeing the number of training samples), we require a single wide layer of\nlinear, quadratic or cubic width depending on the type of initialization.\nUnlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof\nneed not track the evolution of the entire NTK matrix, or more generally, any\nquantities related to the changes of activation patterns during training.\nInstead, we only need to track the evolution of the output at the last hidden\nlayer, which can be done much more easily thanks to the Lipschitz property of\nReLU. Some highlights of our setting: (i) all the layers are trained with\nstandard gradient descent, (ii) the network has standard parameterization as\nopposed to the NTK one, and (iii) the network has a single wide layer as\nopposed to having all wide hidden layers as in most of NTK-related results.",
          "link": "http://arxiv.org/abs/2101.09612",
          "publishedOn": "2021-06-08T02:20:25.129Z",
          "wordCount": null,
          "title": "On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Markov Chain Monte Carlo (MCMC) algorithms ubiquitously employ complex\ndeterministic transformations to generate proposal points that are then\nfiltered by the Metropolis-Hastings-Green (MHG) test. However, the condition of\nthe target measure invariance puts restrictions on the design of these\ntransformations. In this paper, we first derive the acceptance test for the\nstochastic Markov kernel considering arbitrary deterministic maps as proposal\ngenerators. When applied to the transformations with orbits of period two\n(involutions), the test reduces to the MHG test. Based on the derived test we\npropose two practical algorithms: one operates by constructing periodic orbits\nfrom any diffeomorphism, another on contractions of the state space (such as\noptimization trajectories). Finally, we perform an empirical study\ndemonstrating the practical advantages of both kernels.",
          "link": "http://arxiv.org/abs/2010.08047",
          "publishedOn": "2021-06-08T02:20:25.125Z",
          "wordCount": null,
          "title": "Orbital MCMC. (arXiv:2010.08047v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Siyang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1\">Seth Austin Harding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shih-wei Liao</a>",
          "description": "Multi-Agent Reinforcement Learning (MARL) has seen revolutionary\nbreakthroughs with its successful application to multi-agent cooperative tasks\nsuch as computer games and robot swarms. QMIX, a widely popular MARL algorithm,\nhas been used to solve cooperative tasks, e.g. Starcraft Multi-Agent Challenge\n(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX\ntarget relaxing the monotonicity constraint of QMIX, allowing for performance\nimprovement in SMAC. However, in this paper, we investigate the code-level\noptimizations of these variants and the monotonicity constraint. We find that\n(1) such improvements of the variants are significantly affected by various\ncode-level optimizations; (2) QMIX with normalized optimizations outperforms\nother previous works in SMAC; (3) the monotonicity constraint may improve\nsample efficiency in SMAC and DEPP. Last, a discussion with theoretical\nanalysis is demonstrated about why QMIX works well in SMAC. We open-source the\ncode at \\url{https://github.com/hijkzzz/pymarl2}.",
          "link": "http://arxiv.org/abs/2102.03479",
          "publishedOn": "2021-06-08T02:20:25.124Z",
          "wordCount": null,
          "title": "Rethinking the Implementation Matters in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v11 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1\">Daniela Mihai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>",
          "description": "Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.",
          "link": "http://arxiv.org/abs/2106.02067",
          "publishedOn": "2021-06-08T02:20:25.103Z",
          "wordCount": 600,
          "title": "Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study a theory of reinforcement learning (RL) in which the learner\nreceives binary feedback only once at the end of an episode. While this is an\nextreme test case for theory, it is also arguably more representative of\nreal-world applications than the traditional requirement in RL practice that\nthe learner receive feedback at every time step. Indeed, in many real-world\napplications of reinforcement learning, such as self-driving cars and robotics,\nit is easier to evaluate whether a learner's complete trajectory was either\n\"good\" or \"bad,\" but harder to provide a reward signal at each step. To show\nthat learning is possible in this more challenging setting, we study the case\nwhere trajectory labels are generated by an unknown parametric model, and\nprovide a statistically and computationally efficient algorithm that achieves\nsub-linear regret.",
          "link": "http://arxiv.org/abs/2105.14363",
          "publishedOn": "2021-06-08T02:20:25.097Z",
          "wordCount": 588,
          "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback. (arXiv:2105.14363v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.09890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Simin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianrui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_A/0/1/0/all/0/1\">Ali Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yulin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We consider sketching algorithms which first quickly compress data by\nmultiplication with a random sketch matrix, and then apply the sketch to\nquickly solve an optimization problem, e.g., low rank approximation. In the\nlearning-based sketching paradigm proposed by Indyk et al. [2019], the sketch\nmatrix is found by choosing a random sparse matrix, e.g., the CountSketch, and\nthen updating the values of the non-zero entries by running gradient descent on\na training data set. Despite the growing body of work on this paradigm, a\nnoticeable omission is that the locations of the non-zero entries of previous\nalgorithms were fixed, and only their values were learned. In this work we\npropose the first learning algorithm that also optimizes the locations of the\nnon-zero entries. We show this algorithm gives better accuracy for low rank\napproximation than previous work, and apply it to other problems such as\n$k$-means clustering for the first time. We show that our algorithm is provably\nbetter in the spiked covariance model and for Zipfian matrices. We also show\nthe importance of the sketch monotonicity property for combining learned\nsketches. Our empirical results show the importance of optimizing not only the\nvalues of the non-zero entries but also their positions.",
          "link": "http://arxiv.org/abs/2007.09890",
          "publishedOn": "2021-06-08T02:20:25.089Z",
          "wordCount": 678,
          "title": "Learning the Positions in CountSketch. (arXiv:2007.09890v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1\">Erik Englesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>",
          "description": "Prior works have found it beneficial to combine provably noise-robust loss\nfunctions e.g., mean absolute error (MAE) with standard categorical loss\nfunction e.g. cross entropy (CE) to improve their learnability. Here, we\npropose to use Jensen-Shannon divergence as a noise-robust loss function and\nshow that it interestingly interpolate between CE and MAE with a controllable\nmixing parameter. Furthermore, we make a crucial observation that CE exhibit\nlower consistency around noisy data points. Based on this observation, we adopt\na generalized version of the Jensen-Shannon divergence for multiple\ndistributions to encourage consistency around data points. Using this loss\nfunction, we show state-of-the-art results on both synthetic (CIFAR), and\nreal-world (WebVision) noise with varying noise rates.",
          "link": "http://arxiv.org/abs/2105.04522",
          "publishedOn": "2021-06-08T02:20:25.078Z",
          "wordCount": 584,
          "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thomas_D/0/1/0/all/0/1\">Deepak-George Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olshanskyi_D/0/1/0/all/0/1\">Daniil Olshanskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krueger_K/0/1/0/all/0/1\">Karter Krueger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wongpiromsarn_T/0/1/0/all/0/1\">Tichakorn Wongpiromsarn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "The significant components of any successful autonomous flight system are\ntask completion and collision avoidance. Most deep learning algorithms\nsuccessfully execute these aspects under the environment and conditions they\nare trained. However, they fail when subjected to novel environments. This\npaper presents an autonomous multi-rotor flight algorithm, using Deep\nReinforcement Learning augmented with Self-Attention Models, that can\neffectively reason when subjected to varying inputs. In addition to their\nreasoning ability, they are also interpretable, enabling it to be used under\nreal-world conditions. We have tested our algorithm under different weather\nconditions and environments and found it robust compared to conventional Deep\nReinforcement Learning algorithms.",
          "link": "http://arxiv.org/abs/2105.12254",
          "publishedOn": "2021-06-08T02:20:25.039Z",
          "wordCount": 558,
          "title": "Interpretable UAV Collision Avoidance using Deep Reinforcement Learning. (arXiv:2105.12254v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "We present SegFormer, a simple, efficient yet powerful semantic segmentation\nframework which unifies Transformers with lightweight multilayer perception\n(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a\nnovel hierarchically structured Transformer encoder which outputs multiscale\nfeatures. It does not need positional encoding, thereby avoiding the\ninterpolation of positional codes which leads to decreased performance when the\ntesting resolution differs from training. 2) SegFormer avoids complex decoders.\nThe proposed MLP decoder aggregates information from different layers, and thus\ncombining both local attention and global attention to render powerful\nrepresentations. We show that this simple and lightweight design is the key to\nefficient segmentation on Transformers. We scale our approach up to obtain a\nseries of models from SegFormer-B0 to SegFormer-B5, reaching significantly\nbetter performance and efficiency than previous counterparts. For example,\nSegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x\nsmaller and 2.2% better than the previous best method. Our best model,\nSegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows\nexcellent zero-shot robustness on Cityscapes-C. Code will be released at:\ngithub.com/NVlabs/SegFormer.",
          "link": "http://arxiv.org/abs/2105.15203",
          "publishedOn": "2021-06-08T02:20:25.030Z",
          "wordCount": 641,
          "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02847",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marjani_A/0/1/0/all/0/1\">Aymen Al Marjani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garivier_A/0/1/0/all/0/1\">Aur&#xe9;lien Garivier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>",
          "description": "We investigate the classical active pure exploration problem in Markov\nDecision Processes, where the agent sequentially selects actions and, from the\nresulting system trajectory, aims at identifying the best policy as fast as\npossible. We propose an information-theoretic lower bound on the average number\nof steps required before a correct answer can be given with probability at\nleast $1-\\delta$. This lower bound involves a non-convex optimization problem,\nfor which we propose a convex relaxation. We further provide an algorithm whose\nsample complexity matches the relaxed lower bound up to a factor $2$. This\nalgorithm addresses general communicating MDPs; we propose a variant with\nreduced exploration rate (and hence faster convergence) under an additional\nergodicity assumption. This work extends previous results relative to the\n\\emph{generative setting}~\\cite{marjani2020adaptive}, where the agent could at\neach step observe the random outcome of any (state, action) pair. In contrast,\nwe show here how to deal with the \\emph{navigation constraints}. Our analysis\nrelies on an ergodic theorem for non-homogeneous Markov chains which we\nconsider of wide interest in the analysis of Markov Decision Processes.",
          "link": "http://arxiv.org/abs/2106.02847",
          "publishedOn": "2021-06-08T02:20:25.022Z",
          "wordCount": 607,
          "title": "Navigating to the Best Policy in Markov Decision Processes. (arXiv:2106.02847v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Shiyi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1\">Christopher Choy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Subhashree Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1\">Larry S. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce DiscoBox, a novel framework that jointly learns instance\nsegmentation and semantic correspondence using bounding box supervision.\nSpecifically, we propose a self-ensembling framework where instance\nsegmentation and semantic correspondence are jointly guided by a structured\nteacher in addition to the bounding box supervision. The teacher is a\nstructured energy model incorporating a pairwise potential and a cross-image\npotential to model the pairwise pixel relationships both within and across the\nboxes. Minimizing the teacher energy simultaneously yields refined object masks\nand dense correspondences between intra-class objects, which are taken as\npseudo-labels to supervise the task network and provide positive/negative\ncorrespondence pairs for dense constrastive learning. We show a symbiotic\nrelationship where the two tasks mutually benefit from each other. Our best\nmodel achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly\nsupervised methods and is competitive to supervised methods. We also obtain\nstate of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with\nreal-time inference.",
          "link": "http://arxiv.org/abs/2105.06464",
          "publishedOn": "2021-06-08T02:20:25.014Z",
          "wordCount": 642,
          "title": "DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.00558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1\">Mark Sellke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1\">Aleksandrs Slivkins</a>",
          "description": "We consider incentivized exploration: a version of multi-armed bandits where\nthe choice of arms is controlled by self-interested agents, and the algorithm\ncan only issue recommendations. The algorithm controls the flow of information,\nand the information asymmetry can incentivize the agents to explore. Prior work\nachieves optimal regret rates up to multiplicative factors that become\narbitrarily large depending on the Bayesian priors, and scale exponentially in\nthe number of arms. A more basic problem of sampling each arm once runs into\nsimilar factors.\n\nWe focus on the price of incentives: the loss in performance, broadly\nconstrued, incurred for the sake of incentive-compatibility. We prove that\nThompson Sampling, a standard bandit algorithm, is incentive-compatible if\ninitialized with sufficiently many data points. The performance loss due to\nincentives is therefore limited to the initial rounds when these data points\nare collected. The problem is largely reduced to that of sample complexity: how\nmany rounds are needed? We address this question, providing matching upper and\nlower bounds and instantiating them in various corollaries. Typically, the\noptimal sample complexity is polynomial in the number of arms and exponential\nin the \"strength of beliefs\".",
          "link": "http://arxiv.org/abs/2002.00558",
          "publishedOn": "2021-06-08T02:20:25.006Z",
          "wordCount": 681,
          "title": "The Price of Incentivizing Exploration: A Characterization via Thompson Sampling and Sample Complexity. (arXiv:2002.00558v4 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Stochastic simulations such as large-scale, spatiotemporal, age-structured\nepidemic models are computationally expensive at fine-grained resolution. We\npropose Interactive Neural Process (INP), an interactive framework to\ncontinuously learn a deep learning surrogate model and accelerate simulation.\nOur framework is based on the novel integration of Bayesian active learning,\nstochastic simulation and deep sequence modeling. In particular, we develop a\nnovel spatiotemporal neural process model to mimic the underlying process\ndynamics. Our model automatically infers the latent process which describes the\nintrinsic uncertainty of the simulator. This also gives rise to a new\nacquisition function that can quantify the uncertainty of deep learning\npredictions. We design Bayesian active learning algorithms to iteratively query\nthe simulator, gather more data, and continuously improve the model. We perform\ntheoretical analysis and demonstrate that our approach reduces sample\ncomplexity compared with random sampling in high dimension. Empirically, we\ndemonstrate our framework can faithfully imitate the behavior of a complex\ninfectious disease simulator with a small number of examples, enabling rapid\nsimulation and scenario exploration.",
          "link": "http://arxiv.org/abs/2106.02770",
          "publishedOn": "2021-06-08T02:20:24.988Z",
          "wordCount": 597,
          "title": "Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiant&#xe9; Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1\">Miroslav Dudik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1\">Thodoris Lykouris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1\">Sobhan Miryoosefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1\">Aleksandrs Slivkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "We propose an algorithm for tabular episodic reinforcement learning with\nconstraints. We provide a modular analysis with strong theoretical guarantees\nfor settings with concave rewards and convex constraints, and for settings with\nhard constraints (knapsacks). Most of the previous work in constrained\nreinforcement learning is limited to linear constraints, and the remaining work\nfocuses on either the feasibility question or settings with a single episode.\nOur experiments demonstrate that the proposed algorithm significantly\noutperforms these approaches in existing constrained episodic environments.",
          "link": "http://arxiv.org/abs/2006.05051",
          "publishedOn": "2021-06-08T02:20:24.977Z",
          "wordCount": 622,
          "title": "Constrained episodic reinforcement learning in concave-convex and knapsack settings. (arXiv:2006.05051v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.11646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chenggang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yaoqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bolun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Cross-view geo-localization is to spot images of the same geographic target\nfrom different platforms, e.g., drone-view cameras and satellites. It is\nchallenging in the large visual appearance changes caused by extreme viewpoint\nvariations. Existing methods usually concentrate on mining the fine-grained\nfeature of the geographic target in the image center, but underestimate the\ncontextual information in neighbor areas. In this work, we argue that neighbor\nareas can be leveraged as auxiliary information, enriching discriminative clues\nfor geolocalization. Specifically, we introduce a simple and effective deep\nneural network, called Local Pattern Network (LPN), to take advantage of\ncontextual information in an end-to-end manner. Without using extra part\nestimators, LPN adopts a square-ring feature partition strategy, which provides\nthe attention according to the distance to the image center. It eases the part\nmatching and enables the part-wise representation learning. Owing to the\nsquare-ring partition design, the proposed LPN has good scalability to rotation\nvariations and achieves competitive results on three prevailing benchmarks,\ni.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN\ncan be easily embedded into other frameworks to further boost performance.",
          "link": "http://arxiv.org/abs/2008.11646",
          "publishedOn": "2021-06-08T02:20:24.967Z",
          "wordCount": 666,
          "title": "Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1\">Antoine de Mathelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Guillaume Richard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1\">Francois Deheeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1\">Mathilde Mougeot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "We present a novel instance-based approach to handle regression tasks in the\ncontext of supervised domain adaptation. The approach developed in this paper\nrelies on the assumption that the task on the target domain can be efficiently\nlearned by adequately reweighting the source instances during training phase.\nWe introduce a novel formulation of the optimization objective for domain\nadaptation which relies on a discrepancy distance characterizing the difference\nbetween domains according to a specific task and a class of hypotheses. To\nsolve this problem, we develop an adversarial network algorithm which learns\nboth the source weighting scheme and the task in one feed-forward gradient\ndescent. We provide numerical evidence of the relevance of the method on public\ndatasets for domain adaptation through reproducible experiments accessible via\nan online demo interface at: https://antoinedemathelin.github.io/demo/",
          "link": "http://arxiv.org/abs/2006.08251",
          "publishedOn": "2021-06-08T02:20:24.958Z",
          "wordCount": 609,
          "title": "Weighting Adversarial Neural Network for Domain Adaptation in Regression. (arXiv:2006.08251v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Quan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shorten_R/0/1/0/all/0/1\">Robert N. Shorten</a>",
          "description": "It is well known that two-sided markets are unfair in a number of ways. For\ninstance, female workers at Uber earn less than their male colleagues per mile\ndriven. Similar observations have been made for other minority subgroups in\nother two-sided markets. Here, we suggest a novel market-clearing mechanism for\ntwo-sided markets, which promotes equalisation of the pay per hour worked\nacross multiple subgroups, as well as within each subgroup. In the process, we\nintroduce a novel notion of subgroup fairness (which we call Inter-fairness),\nwhich can be combined with other notions of fairness within each subgroup\n(called Intra-fairness), and the utility for the customers (Customer-Care) in\nthe objective of the market-clearing problem. While the novel non-linear terms\nin the objective complicate market clearing by making the problem non-convex,\nwe show that a certain non-convex augmented Lagrangian relaxation can be\napproximated to any precision in time polynomial in the number of market\nparticipants using semi-definite programming. This makes it possible to\nimplement the market-clearing mechanism efficiently. On the example of\ndriver-ride assignment in an Uber-like system, we demonstrate the efficacy and\nscalability of the approach, and trade-offs between Inter- and Intra-fairness.",
          "link": "http://arxiv.org/abs/2106.02702",
          "publishedOn": "2021-06-08T02:20:24.947Z",
          "wordCount": 626,
          "title": "Subgroup Fairness in Two-Sided Markets. (arXiv:2106.02702v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05558",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1\">Amir Ali Ahmadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>",
          "description": "We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.",
          "link": "http://arxiv.org/abs/2008.05558",
          "publishedOn": "2021-06-08T02:20:24.927Z",
          "wordCount": 584,
          "title": "On the complexity of finding a local minimizer of a quadratic function over a polytope. (arXiv:2008.05558v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "We consider the contextual bandit problem, where a player sequentially makes\ndecisions based on past observations to maximize the cumulative reward.\nAlthough many algorithms have been proposed for contextual bandit, most of them\nrely on finding the maximum likelihood estimator at each iteration, which\nrequires $O(t)$ time at the $t$-th iteration and are memory inefficient. A\nnatural way to resolve this problem is to apply online stochastic gradient\ndescent (SGD) so that the per-step time and memory complexity can be reduced to\nconstant with respect to $t$, but a contextual bandit policy based on online\nSGD updates that balances exploration and exploitation has remained elusive. In\nthis work, we show that online SGD can be applied to the generalized linear\nbandit problem. The proposed SGD-TS algorithm, which uses a single-step SGD\nupdate to exploit past information and uses Thompson Sampling for exploration,\nachieves $\\tilde{O}(\\sqrt{T})$ regret with the total time complexity that\nscales linearly in $T$ and $d$, where $T$ is the total number of rounds and $d$\nis the number of features. Experimental results show that SGD-TS consistently\noutperforms existing algorithms on both synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2006.04012",
          "publishedOn": "2021-06-08T02:20:24.912Z",
          "wordCount": null,
          "title": "An Efficient Algorithm For Generalized Linear Bandit: Online Stochastic Gradient Descent and Thompson Sampling. (arXiv:2006.04012v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1\">Andjela Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1\">Avishek Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1\">Hugo Berard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>",
          "description": "Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.",
          "link": "http://arxiv.org/abs/2103.02014",
          "publishedOn": "2021-06-08T02:20:24.905Z",
          "wordCount": null,
          "title": "Online Adversarial Attacks. (arXiv:2103.02014v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenshuo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Serena Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Peng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "While many areas of machine learning have benefited from the increasing\navailability of large and varied datasets, the benefit to causal inference has\nbeen limited given the strong assumptions needed to ensure identifiability of\ncausal effects; these are often not satisfied in real-world datasets. For\nexample, many large observational datasets (e.g., case-control studies in\nepidemiology, click-through data in recommender systems) suffer from selection\nbias on the outcome, which makes the average treatment effect (ATE)\nunidentifiable. We propose a general algorithm to estimate causal effects from\n\\emph{multiple} data sources, where the ATE may be identifiable only in some\ndatasets but not others. The key idea is to construct control variates using\nthe datasets in which the ATE is not identifiable. We show theoretically that\nthis reduces the variance of the ATE estimate. We apply this framework to\ninference from observational data under outcome selection bias, assuming access\nto an auxiliary small dataset from which we can obtain a consistent estimate of\nthe ATE. We construct a control variate by taking the difference of the odds\nratio estimates from the two datasets. Across simulations and two case studies\nwith real data, we show that this control variate can significantly reduce the\nvariance of the ATE estimate.",
          "link": "http://arxiv.org/abs/2103.16689",
          "publishedOn": "2021-06-08T02:20:24.903Z",
          "wordCount": null,
          "title": "Multi-Source Causal Inference Using Control Variates. (arXiv:2103.16689v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.09814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1\">Manan Tomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shani_L/0/1/0/all/0/1\">Lior Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1\">Yonathan Efroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "Mirror descent (MD), a well-known first-order method in constrained convex\noptimization, has recently been shown as an important tool to analyze\ntrust-region algorithms in reinforcement learning (RL). However, there remains\na considerable gap between such theoretically analyzed algorithms and the ones\nused in practice. Inspired by this, we propose an efficient RL algorithm,\ncalled {\\em mirror descent policy optimization} (MDPO). MDPO iteratively\nupdates the policy by {\\em approximately} solving a trust-region problem, whose\nobjective function consists of two terms: a linearization of the standard RL\nobjective and a proximity term that restricts two consecutive policies to be\nclose to each other. Each update performs this approximation by taking multiple\ngradient steps on this objective function. We derive {\\em on-policy} and {\\em\noff-policy} variants of MDPO, while emphasizing important design choices\nmotivated by the existing theory of MD in RL. We highlight the connections\nbetween on-policy MDPO and two popular trust-region RL algorithms: TRPO and\nPPO, and show that explicitly enforcing the trust-region constraint is in fact\n{\\em not} a necessity for high performance gains in TRPO. We then show how the\npopular soft actor-critic (SAC) algorithm can be derived by slight\nmodifications of off-policy MDPO. Overall, MDPO is derived from the MD\nprinciples, offers a unified approach to viewing a number of popular RL\nalgorithms, and performs better than or on-par with TRPO, PPO, and SAC in a\nnumber of continuous control tasks. Code is available at\n\\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.",
          "link": "http://arxiv.org/abs/2005.09814",
          "publishedOn": "2021-06-08T02:20:24.895Z",
          "wordCount": 722,
          "title": "Mirror Descent Policy Optimization. (arXiv:2005.09814v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.10224",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Nelsen_N/0/1/0/all/0/1\">Nicholas H. Nelsen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>",
          "description": "Well known to the machine learning community, the random feature model is a\nparametric approximation to kernel interpolation or regression methods. It is\ntypically used to approximate functions mapping a finite-dimensional input\nspace to the real line. In this paper, we instead propose a methodology for use\nof the random feature model as a data-driven surrogate for operators that map\nan input Banach space to an output Banach space. Although the methodology is\nquite general, we consider operators defined by partial differential equations\n(PDEs); here, the inputs and outputs are themselves functions, with the input\nparameters being functions required to specify the problem, such as initial\ndata or coefficients, and the outputs being solutions of the problem. Upon\ndiscretization, the model inherits several desirable attributes from this\ninfinite-dimensional viewpoint, including mesh-invariant approximation error\nwith respect to the true PDE solution map and the capability to be trained at\none mesh resolution and then deployed at different mesh resolutions. We view\nthe random feature model as a non-intrusive data-driven emulator, provide a\nmathematical framework for its interpretation, and demonstrate its ability to\nefficiently and accurately approximate the nonlinear parameter-to-solution maps\nof two prototypical PDEs arising in physical science and engineering\napplications: viscous Burgers' equation and a variable coefficient elliptic\nequation.",
          "link": "http://arxiv.org/abs/2005.10224",
          "publishedOn": "2021-06-08T02:20:24.886Z",
          "wordCount": 687,
          "title": "The Random Feature Model for Input-Output Maps between Banach Spaces. (arXiv:2005.10224v2 [math.NA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xingyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiuhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zenan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guangcan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Implicit equilibrium models, i.e., deep neural networks (DNNs) defined by\nimplicit equations, have been becoming more and more attractive recently. In\nthis paper, we investigate an emerging question: can an implicit equilibrium\nmodel's equilibrium point be regarded as the solution of an optimization\nproblem? To this end, we first decompose DNNs into a new class of unit layer\nthat is the proximal operator of an implicit convex function while keeping its\noutput unchanged. Then, the equilibrium model of the unit layer can be derived,\nnamed Optimization Induced Equilibrium Networks (OptEq), which can be easily\nextended to deep layers. The equilibrium point of OptEq can be theoretically\nconnected to the solution of its corresponding convex optimization problem with\nexplicit objectives. Based on this, we can flexibly introduce prior properties\nto the equilibrium points: 1) modifying the underlying convex problems\nexplicitly so as to change the architectures of OptEq; and 2) merging the\ninformation into the fixed point iteration, which guarantees to choose the\ndesired equilibrium point when the fixed point set is non-singleton. We show\nthat deep OptEq outperforms previous implicit models even with fewer\nparameters. This work establishes the first step towards the\noptimization-guided design of deep models.",
          "link": "http://arxiv.org/abs/2105.13228",
          "publishedOn": "2021-06-08T02:20:24.875Z",
          "wordCount": 667,
          "title": "Optimization Induced Equilibrium Networks. (arXiv:2105.13228v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lukina_A/0/1/0/all/0/1\">Anna Lukina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1\">Christian Schilling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1\">Thomas A. Henzinger</a>",
          "description": "Neural-network classifiers achieve high accuracy when predicting the class of\nan input that they were trained to identify. Maintaining this accuracy in\ndynamic environments, where inputs frequently fall outside the fixed set of\ninitially known classes, remains a challenge. The typical approach is to detect\ninputs from novel classes and retrain the classifier on an augmented dataset.\nHowever, not only the classifier but also the detection mechanism needs to\nadapt in order to distinguish between newly learned and yet unknown input\nclasses. To address this challenge, we introduce an algorithmic framework for\nactive monitoring of a neural network. A monitor wrapped in our framework\noperates in parallel with the neural network and interacts with a human user\nvia a series of interpretable labeling queries for incremental adaptation. In\naddition, we propose an adaptive quantitative monitor to improve precision. An\nexperimental evaluation on a diverse set of benchmarks with varying numbers of\nclasses confirms the benefits of our active monitoring framework in dynamic\nscenarios.",
          "link": "http://arxiv.org/abs/2009.06429",
          "publishedOn": "2021-06-08T02:20:24.869Z",
          "wordCount": 625,
          "title": "Into the Unknown: Active Monitoring of Neural Networks. (arXiv:2009.06429v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Recognition accuracy and response time are both critically essential ahead of\nbuilding practical electroencephalography (EEG) based brain-computer interface\n(BCI). Recent approaches, however, have either compromised in the\nclassification accuracy or responding time. This paper presents a novel deep\nlearning approach designed towards remarkably accurate and responsive motor\nimagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term\nMemory (BiLSTM) with the Attention mechanism manages to derive relevant\nfeatures from raw EEG signals. The connected graph convolutional neural network\n(GCN) promotes the decoding performance by cooperating with the topological\nstructure of features, which are estimated from the overall data. The\n0.4-second detection framework has shown effective and efficient prediction\nbased on individual and group-wise training, with 98.81% and 94.64% accuracy,\nrespectively, which outperformed all the state-of-the-art studies. The\nintroduced deep feature mining approach can precisely recognize human motion\nintents from raw EEG signals, which paves the road to translate the EEG based\nMI recognition to practical BCI systems.",
          "link": "http://arxiv.org/abs/2005.00777",
          "publishedOn": "2021-06-08T02:20:24.848Z",
          "wordCount": 624,
          "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.10085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>",
          "description": "Spiking neural networks (SNNs) are well suited for spatio-temporal learning\nand implementations on energy-efficient event-driven neuromorphic processors.\nHowever, existing SNN error backpropagation (BP) methods lack proper handling\nof spiking discontinuities and suffer from low performance compared with the BP\nmethods for traditional artificial neural networks. In addition, a large number\nof time steps are typically required to achieve decent performance, leading to\nhigh latency and rendering spike-based computation unscalable to deep\narchitectures. We present a novel Temporal Spike Sequence Learning\nBackpropagation (TSSL-BP) method for training deep SNNs, which breaks down\nerror backpropagation across two types of inter-neuron and intra-neuron\ndependencies and leads to improved temporal learning precision. It captures\ninter-neuron dependencies through presynaptic firing times by considering the\nall-or-none characteristics of firing activities and captures intra-neuron\ndependencies by handling the internal evolution of each neuronal state in time.\nTSSL-BP efficiently trains deep SNNs within a much shortened temporal window of\na few steps while improving the accuracy for various image classification\ndatasets including CIFAR10.",
          "link": "http://arxiv.org/abs/2002.10085",
          "publishedOn": "2021-06-08T02:20:24.819Z",
          "wordCount": 658,
          "title": "Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks. (arXiv:2002.10085v4 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yao-Hung Hubert Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianqin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>",
          "description": "This paper presents to integrate the auxiliary information (e.g., additional\nattributes for data such as the hashtags for Instagram images) in the\nself-supervised learning process. We first observe that the auxiliary\ninformation may bring us useful information about data structures: for\ninstance, the Instagram images with the same hashtags can be semantically\nsimilar. Hence, to leverage the structural information from the auxiliary\ninformation, we present to construct data clusters according to the auxiliary\ninformation. Then, we introduce the Clustering InfoNCE (Cl-InfoNCE) objective\nthat learns similar representations for augmented variants of data from the\nsame cluster and dissimilar representations for data from different clusters.\nOur approach contributes as follows: 1) Comparing to conventional\nself-supervised representations, the auxiliary-information-infused\nself-supervised representations bring the performance closer to the supervised\nrepresentations; 2) The presented Cl-InfoNCE can also work with unsupervised\nconstructed clusters (e.g., k-means clusters) and outperform strong\nclustering-based self-supervised learning approaches, such as the Prototypical\nContrastive Learning (PCL) method; 3) We show that Cl-InfoNCE may be a better\napproach to leverage the data clustering information, by comparing it to the\nbaseline approach - learning to predict the clustering assignments with\ncross-entropy loss. For analysis, we connect the goodness of the learned\nrepresentations with the statistical relationships: i) the mutual information\nbetween the labels and the clusters and ii) the conditional entropy of the\nclusters given the labels.",
          "link": "http://arxiv.org/abs/2106.02869",
          "publishedOn": "2021-06-08T02:20:24.807Z",
          "wordCount": 648,
          "title": "Integrating Auxiliary Information in Self-supervised Learning. (arXiv:2106.02869v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05973",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Agrawal_R/0/1/0/all/0/1\">Rohit Agrawal</a>, <a href=\"http://arxiv.org/find/math/1/au:+Horel_T/0/1/0/all/0/1\">Thibaut Horel</a>",
          "description": "The families of $f$-divergences (e.g. the Kullback-Leibler divergence) and\nIntegral Probability Metrics (e.g. total variation distance or maximum mean\ndiscrepancies) are widely used to quantify the similarity between probability\ndistributions. In this work, we systematically study the relationship between\nthese two families from the perspective of convex duality. Starting from a\ntight variational representation of the $f$-divergence, we derive a\ngeneralization of the moment-generating function, which we show exactly\ncharacterizes the best lower bound of the $f$-divergence as a function of a\ngiven IPM. Using this characterization, we obtain new bounds while also\nrecovering in a unified manner well-known results, such as Hoeffding's lemma,\nPinsker's inequality and its extension to subgaussian functions, and the\nHammersley-Chapman-Robbins bound. This characterization also allows us to prove\nnew results on topological properties of the divergence which may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2006.05973",
          "publishedOn": "2021-06-08T02:20:24.801Z",
          "wordCount": 615,
          "title": "Optimal Bounds between $f$-Divergences and Integral Probability Metrics. (arXiv:2006.05973v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02713",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The generalization performance of a machine learning algorithm such as a\nneural network depends in a non-trivial way on the structure of the data\ndistribution. Models of generalization in machine learning theory often ignore\nthe low-dimensional structure of natural signals, either by considering\ndata-agnostic bounds or by studying the performance of the algorithm when\ntrained on uncorrelated features. To analyze the influence of data structure on\ntest loss dynamics, we study an exactly solveable model of stochastic gradient\ndescent (SGD) which predicts test loss when training on features with arbitrary\ncovariance structure. We solve the theory exactly for both Gaussian features\nand arbitrary features and we show that the simpler Gaussian model accurately\npredicts test loss of nonlinear random-feature models and deep neural networks\ntrained with SGD on real datasets such as MNIST and CIFAR-10. We show that\nmodeling the geometry of the data in the induced feature space is indeed\ncrucial to accurately predict the test error throughout learning.",
          "link": "http://arxiv.org/abs/2106.02713",
          "publishedOn": "2021-06-08T02:20:24.795Z",
          "wordCount": 581,
          "title": "Learning Curves for SGD on Structured Features. (arXiv:2106.02713v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2004.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1\">Liam Paull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Le Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.",
          "link": "http://arxiv.org/abs/2004.04690",
          "publishedOn": "2021-06-08T02:20:24.778Z",
          "wordCount": 685,
          "title": "Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizian_W/0/1/0/all/0/1\">Wa&#xef;ss Azizian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "Various classes of Graph Neural Networks (GNN) have been proposed and shown\nto be successful in a wide range of applications with graph structured data. In\nthis paper, we propose a theoretical framework able to compare the expressive\npower of these GNN architectures. The current universality theorems only apply\nto intractable classes of GNNs. Here, we prove the first approximation\nguarantees for practical GNNs, paving the way for a better understanding of\ntheir generalization. Our theoretical results are proved for invariant GNNs\ncomputing a graph embedding (permutation of the nodes of the input graph does\nnot affect the output) and equivariant GNNs computing an embedding of the nodes\n(permutation of the input permutes the output). We show that Folklore Graph\nNeural Networks (FGNN), which are tensor based GNNs augmented with matrix\nmultiplication are the most expressive architectures proposed so far for a\ngiven tensor order. We illustrate our results on the Quadratic Assignment\nProblem (a NP-Hard combinatorial problem) by showing that FGNNs are able to\nlearn how to solve the problem, leading to much better average performances\nthan existing algorithms (based on spectral, SDP or other GNNs architectures).\nOn a practical side, we also implement masked tensors to handle batches of\ngraphs of varying sizes.",
          "link": "http://arxiv.org/abs/2006.15646",
          "publishedOn": "2021-06-08T02:20:24.771Z",
          "wordCount": 692,
          "title": "Expressive Power of Invariant and Equivariant Graph Neural Networks. (arXiv:2006.15646v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jared Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "Bilevel optimization (BLO) is a popular approach with many applications\nincluding hyperparameter optimization, neural architecture search, adversarial\nrobustness and model-agnostic meta-learning. However, the approach suffers from\ntime and memory complexity proportional to the length $r$ of its inner\noptimization loop, which has led to several modifications being proposed. One\nsuch modification is \\textit{first-order} BLO (FO-BLO) which approximates\nouter-level gradients by zeroing out second derivative terms, yielding\nsignificant speed gains and requiring only constant memory as $r$ varies.\nDespite FO-BLO's popularity, there is a lack of theoretical understanding of\nits convergence properties. We make progress by demonstrating a rich family of\nexamples where FO-BLO-based stochastic optimization does not converge to a\nstationary point of the BLO objective. We address this concern by proposing a\nnew FO-BLO-based unbiased estimate of outer-level gradients, enabling us to\ntheoretically guarantee this convergence, with no harm to memory and expected\ntime complexity. Our findings are supported by experimental results on Omniglot\nand Mini-ImageNet, popular few-shot meta-learning benchmarks.",
          "link": "http://arxiv.org/abs/2006.03631",
          "publishedOn": "2021-06-08T02:20:24.763Z",
          "wordCount": 622,
          "title": "UFO-BLO: Unbiased First-Order Bilevel Optimization. (arXiv:2006.03631v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1\">Harikrishna Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1\">Dara Bahri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1\">Andrew Cotter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1\">Afshin Rostamizadeh</a>",
          "description": "In real-world systems, models are frequently updated as more data becomes\navailable, and in addition to achieving high accuracy, the goal is to also\nmaintain a low difference in predictions compared to the base model (i.e.\npredictive ``churn''). If model retraining results in vastly different\nbehavior, then it could cause negative effects in downstream systems,\nespecially if this churn can be avoided with limited impact on model accuracy.\nIn this paper, we show an equivalence between training with distillation using\nthe base model as the teacher and training with an explicit constraint on the\npredictive churn. We then show that distillation performs strongly for low\nchurn training against a number of recent baselines on a wide range of datasets\nand model architectures, including fully-connected networks, convolutional\nnetworks, and transformers.",
          "link": "http://arxiv.org/abs/2106.02654",
          "publishedOn": "2021-06-08T02:20:24.754Z",
          "wordCount": null,
          "title": "Churn Reduction via Distillation. (arXiv:2106.02654v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.12315",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Amiridi_M/0/1/0/all/0/1\">Magda Amiridi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kargas_N/0/1/0/all/0/1\">Nikos Kargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sidiropoulos_N/0/1/0/all/0/1\">Nicholas D. Sidiropoulos</a>",
          "description": "Effective non-parametric density estimation is a key challenge in\nhigh-dimensional multivariate data analysis. In this paper,we propose a novel\napproach that builds upon tensor factorization tools. Any multivariate density\ncan be represented by its characteristic function, via the Fourier transform.\nIf the sought density is compactly supported, then its characteristic function\ncan be approximated, within controllable error, by a finite tensor of leading\nFourier coefficients, whose size de-pends on the smoothness of the underlying\ndensity. This tensor can be naturally estimated from observed realizations of\nthe random vector of interest, via sample averaging. In order to circumvent the\ncurse of dimensionality, we introduce a low-rank model of this characteristic\ntensor, which significantly improves the density estimate especially for\nhigh-dimensional data and/or in the sample-starved regime. By virtue of\nuniqueness of low-rank tensor decomposition, under certain conditions, our\nmethod enables learning the true data-generating distribution. We demonstrate\nthe very promising performance of the proposed method using several measured\ndatasets.",
          "link": "http://arxiv.org/abs/2008.12315",
          "publishedOn": "2021-06-08T02:20:24.737Z",
          "wordCount": null,
          "title": "Low-rank Characteristic Tensor Density Estimation Part I: Foundations. (arXiv:2008.12315v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1\">Fan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>",
          "description": "The learning and evaluation of energy-based latent variable models (EBLVMs)\nwithout any structural assumptions are highly challenging, because the true\nposteriors and the partition functions in such models are generally\nintractable. This paper presents variational estimates of the score function\nand its gradient with respect to the model parameters in a general EBLVM,\nreferred to as VaES and VaGES respectively. The variational posterior is\ntrained to minimize a certain divergence to the true model posterior and the\nbias in both estimates can be bounded by the divergence theoretically. With a\nminimal model assumption, VaES and VaGES can be applied to the kernelized Stein\ndiscrepancy (KSD) and score matching (SM)-based methods to learn EBLVMs.\nBesides, VaES can also be used to estimate the exact Fisher divergence between\nthe data and general EBLVMs.",
          "link": "http://arxiv.org/abs/2010.08258",
          "publishedOn": "2021-06-08T02:20:24.735Z",
          "wordCount": 611,
          "title": "Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models. (arXiv:2010.08258v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zaixi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenya Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chengqiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuanren Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>",
          "description": "As machine learning becomes more widely used for critical applications, the\nneed to study its implications in privacy turns to be urgent. Given access to\nthe target model and auxiliary information, the model inversion attack aims to\ninfer sensitive features of the training dataset, which leads to great privacy\nconcerns. Despite its success in grid-like domains, directly applying model\ninversion techniques on non-grid domains such as graph achieves poor attack\nperformance due to the difficulty to fully exploit the intrinsic properties of\ngraphs and attributes of nodes used in Graph Neural Networks (GNN). To bridge\nthis gap, we present \\textbf{Graph} \\textbf{M}odel \\textbf{I}nversion attack\n(GraphMI), which aims to extract private graph data of the training graph by\ninverting GNN, one of the state-of-the-art graph analysis tools. Specifically,\nwe firstly propose a projected gradient module to tackle the discreteness of\ngraph edges while preserving the sparsity and smoothness of graph features.\nThen we design a graph auto-encoder module to efficiently exploit graph\ntopology, node attributes, and target model parameters for edge inference. With\nthe proposed methods, we study the connection between model inversion risk and\nedge influence and show that edges with greater influence are more likely to be\nrecovered. Extensive experiments over several public datasets demonstrate the\neffectiveness of our method. We also show that differential privacy in its\ncanonical form can hardly defend our attack while preserving decent utility.",
          "link": "http://arxiv.org/abs/2106.02820",
          "publishedOn": "2021-06-08T02:20:24.729Z",
          "wordCount": 673,
          "title": "GraphMI: Extracting Private Graph Data from Graph Neural Networks. (arXiv:2106.02820v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Incorporating a so-called \"momentum\" dynamic in gradient descent methods is\nwidely used in neural net training as it has been broadly observed that, at\nleast empirically, it often leads to significantly faster convergence. At the\nsame time, there are very few theoretical guarantees in the literature to\nexplain this apparent acceleration effect. Even for the classical strongly\nconvex quadratic problems, several existing results only show Polyak's momentum\nhas an accelerated linear rate asymptotically. In this paper, we first revisit\nthe quadratic problems and show a non-asymptotic accelerated linear rate of\nPolyak's momentum. Then, we provably show that Polyak's momentum achieves\nacceleration for training a one-layer wide ReLU network and a deep linear\nnetwork, which are perhaps the two most popular canonical models for studying\noptimization and deep learning in the literature. Prior work Du at al. 2019 and\nWu et al. 2019 showed that using vanilla gradient descent, and with an use of\nover-parameterization, the error decays as $(1- \\Theta(\\frac{1}{ \\kappa'}))^t$\nafter $t$ iterations, where $\\kappa'$ is the condition number of a Gram Matrix.\nOur result shows that with the appropriate choice of parameters Polyak's\nmomentum has a rate of $(1-\\Theta(\\frac{1}{\\sqrt{\\kappa'}}))^t$. For the deep\nlinear network, prior work Hu et al. 2020 showed that vanilla gradient descent\nhas a rate of $(1-\\Theta(\\frac{1}{\\kappa}))^t$, where $\\kappa$ is the condition\nnumber of a data matrix. Our result shows an acceleration rate $(1-\n\\Theta(\\frac{1}{\\sqrt{\\kappa}}))^t$ is achievable by Polyak's momentum. All the\nresults in this work are obtained from a modular analysis, which can be of\nindependent interest. This work establishes that momentum does indeed speed up\nneural net training.",
          "link": "http://arxiv.org/abs/2010.01618",
          "publishedOn": "2021-06-08T02:20:24.710Z",
          "wordCount": null,
          "title": "A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nair_H/0/1/0/all/0/1\">Harideep Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vellaisamy_P/0/1/0/all/0/1\">Prabhu Vellaisamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhasuthkar_S/0/1/0/all/0/1\">Santha Bhasuthkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">John Paul Shen</a>",
          "description": "A set of highly-optimized custom macro extensions is developed for a 7nm CMOS\ncell library for implementing Temporal Neural Networks (TNNs) that can mimic\nbrain-like sensory processing with extreme energy efficiency. A TNN prototype\n(13,750 neurons and 315,000 synapses) for MNIST requires only 1.56mm2 die area\nand consumes only 1.69mW.",
          "link": "http://arxiv.org/abs/2012.05419",
          "publishedOn": "2021-06-08T02:20:24.710Z",
          "wordCount": null,
          "title": "A Custom 7nm CMOS Standard Cell Library for Implementing TNN-based Neuromorphic Processors. (arXiv:2012.05419v2 [cs.AR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08548",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chenthamarakshan_V/0/1/0/all/0/1\">Vijil Chenthamarakshan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ramamurthy_K/0/1/0/all/0/1\">Karthikeyan Natesan Ramamurthy</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>",
          "description": "Deep generative models are increasingly becoming integral parts of the in\nsilico molecule design pipeline and have dual goals of learning the chemical\nand structural features that render candidate molecules viable while also being\nflexible enough to generate novel designs. Specifically, Variational Auto\nEncoders (VAEs) are generative models in which encoder-decoder network pairs\nare trained to reconstruct training data distributions in such a way that the\nlatent space of the encoder network is smooth. Therefore, novel candidates can\nbe found by sampling from this latent space. However, the scope of\narchitectures and hyperparameters is vast and choosing the best combination for\nin silico discovery has important implications for downstream success.\nTherefore, it is important to develop a principled methodology for\ndistinguishing how well a given generative model is able to learn salient\nmolecular features. In this work, we propose a method for measuring how well\nthe latent space of deep generative models is able to encode structural and\nchemical features of molecular datasets by correlating latent space metrics\nwith metrics from the field of topological data analysis (TDA). We apply our\nevaluation methodology to a VAE trained on SMILES strings and show that 3D\ntopology information is consistently encoded throughout the latent space of the\nmodel.",
          "link": "http://arxiv.org/abs/2010.08548",
          "publishedOn": "2021-06-08T02:20:24.709Z",
          "wordCount": null,
          "title": "Characterizing the Latent Space of Molecular Deep Generative Models with Persistent Homology Metrics. (arXiv:2010.08548v2 [q-bio.BM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>",
          "description": "In this work we study the orbit recovery problem, which is a natural\nabstraction for the problem of recovering a planted signal from noisy\nmeasurements under unknown group actions. Many important inverse problems in\nstatistics, engineering and the sciences fit into this framework. Prior work\nhas studied cases when the group is discrete and/or abelian. However\nfundamentally new techniques are needed in order to handle more complex group\nactions.\n\nOur main result is a quasi-polynomial time algorithm to solve orbit recovery\nover $SO(3)$ - i.e. the cryo-electron tomography problem which asks to recover\nthe three-dimensional structure of a molecule from noisy measurements of\nrandomly rotated copies of it. We analyze a variant of the frequency marching\nheuristic in the framework of smoothed analysis. Our approach exploits the\nlayered structure of the invariant polynomials, and simultaneously yields a new\nclass of tensor decomposition algorithms that work in settings when the tensor\nis not low-rank but rather where the factors are algebraically related to each\nother by a group action.",
          "link": "http://arxiv.org/abs/2106.02680",
          "publishedOn": "2021-06-08T02:20:24.708Z",
          "wordCount": 602,
          "title": "How to Decompose a Tensor with Group Structure. (arXiv:2106.02680v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/1802.04064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Agarwal_A/0/1/0/all/0/1\">Alekh Agarwal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>",
          "description": "Contextual bandit algorithms are essential for solving many real-world\ninteractive machine learning problems. Despite multiple recent successes on\nstatistically and computationally efficient methods, the practical behavior of\nthese algorithms is still poorly understood. We leverage the availability of\nlarge numbers of supervised learning datasets to empirically evaluate\ncontextual bandit algorithms, focusing on practical methods that learn by\nrelying on optimization oracles from supervised learning. We find that a recent\nmethod (Foster et al., 2018) using optimism under uncertainty works the best\noverall. A surprisingly close second is a simple greedy baseline that only\nexplores implicitly through the diversity of contexts, followed by a variant of\nOnline Cover (Agarwal et al., 2014) which tends to be more conservative but\nrobust to problem specification by design. Along the way, we also evaluate\nvarious components of contextual bandit algorithm design such as loss\nestimators. Overall, this is a thorough study and review of contextual bandit\nmethodology.",
          "link": "http://arxiv.org/abs/1802.04064",
          "publishedOn": "2021-06-08T02:20:24.699Z",
          "wordCount": 617,
          "title": "A Contextual Bandit Bake-off. (arXiv:1802.04064v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1\">Joel Lamy-Poirier</a>",
          "description": "The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n\nIn addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.",
          "link": "http://arxiv.org/abs/2106.02679",
          "publishedOn": "2021-06-08T02:20:24.693Z",
          "wordCount": 646,
          "title": "Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06522",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wiqvist_S/0/1/0/all/0/1\">Samuel Wiqvist</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Picchini_U/0/1/0/all/0/1\">Umberto Picchini</a>",
          "description": "We introduce the sequential neural posterior and likelihood approximation\n(SNPLA) algorithm. SNPLA is a normalizing flows-based algorithm for inference\nin implicit models, and therefore is a simulation-based inference method that\nonly requires simulations from a generative model. SNPLA avoids Markov chain\nMonte Carlo sampling and correction-steps of the parameter proposal function\nthat are introduced in similar methods, but that can be numerically unstable or\nrestrictive. By utilizing the reverse KL divergence, SNPLA manages to learn\nboth the likelihood and the posterior in a sequential manner. Over four\nexperiments, we show that SNPLA performs competitively when utilizing the same\nnumber of model simulations as used in other methods, even though the inference\nproblem for SNPLA is more complex due to the joint learning of posterior and\nlikelihood function. Due to utilizing normalizing flows SNPLA generates\nposterior draws much faster (4 orders of magnitude) than MCMC-based methods.",
          "link": "http://arxiv.org/abs/2102.06522",
          "publishedOn": "2021-06-08T02:20:24.668Z",
          "wordCount": null,
          "title": "Sequential Neural Posterior and Likelihood Approximation. (arXiv:2102.06522v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1\">Nguyen Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Diep N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1\">Eryk Dutkiewicz</a>",
          "description": "In intelligent transportation systems (ITS), vehicles are expected to feature\nwith advanced applications and services which demand ultra-high data rates and\nlow-latency communications. For that, the millimeter wave (mmWave)\ncommunication has been emerging as a very promising solution. However,\nincorporating the mmWave into ITS is particularly challenging due to the high\nmobility of vehicles and the inherent sensitivity of mmWave beams to dynamic\nblockages. This article addresses these problems by developing an optimal beam\nassociation framework for mmWave vehicular networks under high mobility.\nSpecifically, we use the semi-Markov decision process to capture the dynamics\nand uncertainty of the environment. The Q-learning algorithm is then often used\nto find the optimal policy. However, Q-learning is notorious for its\nslow-convergence. Instead of adopting deep reinforcement learning structures\n(like most works in the literature), we leverage the fact that there are\nusually multiple vehicles on the road to speed up the learning process. To that\nend, we develop a lightweight yet very effective parallel Q-learning algorithm\nto quickly obtain the optimal policy by simultaneously learning from various\nvehicles. Extensive simulations demonstrate that our proposed solution can\nincrease the data rate by 47% and reduce the disconnection probability by 29%\ncompared to other solutions.",
          "link": "http://arxiv.org/abs/2005.00694",
          "publishedOn": "2021-06-08T02:20:24.658Z",
          "wordCount": null,
          "title": "Optimal Beam Association for High Mobility mmWave Vehicular Networks: Lightweight Parallel Reinforcement Learning Approach. (arXiv:2005.00694v2 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07550",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Soh_Y/0/1/0/all/0/1\">Yong Sheng Soh</a>",
          "description": "The dictionary learning problem concerns the task of representing data as\nsparse linear sums drawn from a smaller collection of basic building blocks. In\napplication domains where such techniques are deployed, we frequently encounter\ndatasets where some form of symmetry or invariance is present. Motivated by\nthis observation, we develop a framework for learning dictionaries for data\nunder the constraint that the collection of basic building blocks remains\ninvariant under such symmetries. Our procedure for learning such dictionaries\nrelies on representing the symmetry as the action of a matrix group acting on\nthe data, and subsequently introducing a convex penalty function so as to\ninduce sparsity with respect to the collection of matrix group elements. Our\nframework specializes to the convolutional dictionary learning problem when we\nconsider integer shifts. Using properties of positive semidefinite Hermitian\nToeplitz matrices, we develop an extension that learns dictionaries that are\ninvariant under continuous shifts. Our numerical experiments on synthetic data\nand ECG data show that the incorporation of such symmetries as priors are most\nvaluable when the dataset has few data-points, or when the full range of\nsymmetries is inadequately expressed in the dataset.",
          "link": "http://arxiv.org/abs/2007.07550",
          "publishedOn": "2021-06-08T02:20:24.657Z",
          "wordCount": 643,
          "title": "Group Invariant Dictionary Learning. (arXiv:2007.07550v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.00742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+El_Mhamdi_E/0/1/0/all/0/1\">El-Mahdi El-Mhamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1\">Sadegh Farhadkhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guirguis_A/0/1/0/all/0/1\">Arsany Guirguis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1\">L&#xea; Nguy&#xea;n Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1\">S&#xe9;bastien Rouault</a>",
          "description": "We study Byzantine collaborative learning, where $n$ nodes seek to\ncollectively learn from each others' local data. The data distribution may vary\nfrom one node to another. No node is trusted, and $f < n$ nodes can behave\narbitrarily. We prove that collaborative learning is equivalent to a new form\nof agreement, which we call averaging agreement. In this problem, nodes start\neach with an initial vector and seek to approximately agree on a common vector,\nwhich is close to the average of honest nodes' initial vectors. We present two\nasynchronous solutions to averaging agreement, each we prove optimal according\nto some dimension. The first, based on the minimum-diameter averaging, requires\n$ n \\geq 6f+1$, but achieves asymptotically the best-possible averaging\nconstant up to a multiplicative constant. The second, based on reliable\nbroadcast and coordinate-wise trimmed mean, achieves optimal Byzantine\nresilience, i.e., $n \\geq 3f+1$. Each of these algorithms induces an optimal\nByzantine collaborative learning protocol. In particular, our equivalence\nyields new impossibility theorems on what any collaborative learning algorithm\ncan achieve in adversarial and heterogeneous environments.",
          "link": "http://arxiv.org/abs/2008.00742",
          "publishedOn": "2021-06-08T02:20:24.643Z",
          "wordCount": null,
          "title": "Collaborative Learning in the Jungle. (arXiv:2008.00742v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1\">Marina Sapir</a>",
          "description": "ML is approached from logic point of view as a problem of maximizing\nconsistency of a hypothesis in a context of a given training set. Nonjudgmental\nlogic (NjL) with modalities ``It appears that'', ``Assume that'' is introduced\nto formalize and quantify the concepts of inconsistency. Two conjectures are\nformulated. First, there are only 5 types of steps for all learners. Second,\nany learner minimizes a criterion, which can be represented as a measure of\ninconsistency in a semantic of NjL. Many popular ML algorithms (from\nhierarchical clustering to k-NN and SVM) are shown to corroborate both\nconjectures. In addition, it is demonstrated that NjL allows to formalize and\nsolve several general learning problems which are not considered as ML usually.",
          "link": "http://arxiv.org/abs/2006.09500",
          "publishedOn": "2021-06-08T02:20:24.635Z",
          "wordCount": null,
          "title": "Logic of Machine Learning. (arXiv:2006.09500v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02639",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rosenfeld_J/0/1/0/all/0/1\">Joel A. Rosenfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "This manuscript is aimed at addressing several long standing limitations of\ndynamic mode decompositions in the application of Koopman analysis. Principle\namong these limitations are the convergence of associated Dynamic Mode\nDecomposition algorithms and the existence of Koopman modes. To address these\nlimitations, two major modifications are made, where Koopman operators are\nremoved from the analysis in light of Liouville operators (known as Koopman\ngenerators in special cases), and these operators are shown to be compact for\ncertain pairs of Hilbert spaces selected separately as the domain and range of\nthe operator. While eigenfunctions are discarded in this analysis, a viable\nreconstruction algorithm is still demonstrated, and the sacrifice of\neigenfunctions realizes the theoretical goals of DMD analysis that have yet to\nbe achieved in other contexts. The manuscript concludes with the description of\na Dynamic Mode Decomposition algorithm that converges when a dense collection\nof occupation kernels, arising from the data, are leveraged in the analysis.",
          "link": "http://arxiv.org/abs/2106.02639",
          "publishedOn": "2021-06-08T02:20:24.615Z",
          "wordCount": 611,
          "title": "Singular Dynamic Mode Decompositions. (arXiv:2106.02639v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1\">Cenk Baykal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1\">Lucas Liebenwein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1\">Dan Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "We develop an online learning algorithm for identifying unlabeled data points\nthat are most informative for training (i.e., active learning). By formulating\nthe active learning problem as the prediction with sleeping experts problem, we\nprovide a framework for identifying informative data with respect to any given\ndefinition of informativeness. At the core of our work is an efficient\nalgorithm for sleeping experts that is tailored to achieve low regret on\npredictable (easy) instances while remaining resilient to adversarial ones.\nThis stands in contrast to state-of-the-art active learning methods that are\noverwhelmingly based on greedy selection, and hence cannot ensure good\nperformance across varying problem instances. We present empirical results\ndemonstrating that our method (i) instantiated with an informativeness measure\nconsistently outperforms its greedy counterpart and (ii) reliably outperforms\nuniform sampling on real-world data sets and models.",
          "link": "http://arxiv.org/abs/2104.02822",
          "publishedOn": "2021-06-08T02:20:24.601Z",
          "wordCount": null,
          "title": "Low-Regret Active learning. (arXiv:2104.02822v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Tom Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshkovitz_M/0/1/0/all/0/1\">Michal Moshkovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabato_S/0/1/0/all/0/1\">Sivan Sabato</a>",
          "description": "We study k-median clustering under the sequential no-substitution setting. In\nthis setting, a data stream is sequentially observed, and some of the points\nare selected by the algorithm as cluster centers. However, a point can be\nselected as a center only immediately after it is observed, before observing\nthe next point. In addition, a selected center cannot be substituted later. We\ngive the first algorithm for this setting that obtains a constant approximation\nfactor on the optimal risk under a random arrival order, an exponential\nimprovement over previous work. This is also the first constant approximation\nguarantee that holds without any structural assumptions on the input data.\nMoreover, the number of selected centers is only quasi-linear in k. Our\nalgorithm and analysis are based on a careful risk estimation that avoids\noutliers, a new concept of a linear bin division, and a multiscale approach to\ncenter selection.",
          "link": "http://arxiv.org/abs/2102.04050",
          "publishedOn": "2021-06-08T02:20:24.598Z",
          "wordCount": null,
          "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering. (arXiv:2102.04050v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02780",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Farias_V/0/1/0/all/0/1\">Vivek F. Farias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_A/0/1/0/all/0/1\">Andrew A. Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peng_T/0/1/0/all/0/1\">Tianyi Peng</a>",
          "description": "The problem of causal inference with panel data is a central econometric\nquestion. The following is a fundamental version of this problem: Let $M^*$ be\na low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix\n$Z$ with entries in $\\{0,1\\}$ we observe the matrix $O$ with entries $O_{ij} :=\nM^*_{ij} + E_{ij} + \\mathcal{T}_{ij} Z_{ij}$ where $\\mathcal{T}_{ij} $ are\nunknown, heterogenous treatment effects. The problem requires we estimate the\naverage treatment effect $\\tau^* := \\sum_{ij} \\mathcal{T}_{ij} Z_{ij} /\n\\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to\nestimating $\\tau^*$ when $Z$ places support on a single row. This paper extends\nthat framework to allow rate-optimal recovery of $\\tau^*$ for general $Z$, thus\nbroadly expanding its applicability. Our guarantees are the first of their type\nin this general setting. Computational experiments on synthetic and real-world\ndata show a substantial advantage over competing estimators.",
          "link": "http://arxiv.org/abs/2106.02780",
          "publishedOn": "2021-06-08T02:20:24.597Z",
          "wordCount": 582,
          "title": "Learning Treatment Effects in Panels with General Intervention Patterns. (arXiv:2106.02780v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2007.05975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_T/0/1/0/all/0/1\">Tobias Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zuhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sanming Zhou</a>",
          "description": "Blowfish privacy is a recent generalisation of differential privacy that\nenables improved utility while maintaining privacy policies with semantic\nguarantees, a factor that has driven the popularity of differential privacy in\ncomputer science. This paper relates Blowfish privacy to an important measure\nof privacy loss of information channels from the communications theory\ncommunity: min-entropy leakage. Symmetry in an input data neighbouring relation\nis central to known connections between differential privacy and min-entropy\nleakage. But while differential privacy exhibits strong symmetry, Blowfish\nneighbouring relations correspond to arbitrary simple graphs owing to the\nframework's flexible privacy policies. To bound the min-entropy leakage of\nBlowfish-private mechanisms we organise our analysis over symmetrical\npartitions corresponding to orbits of graph automorphism groups. A construction\nmeeting our bound with asymptotic equality demonstrates tightness.",
          "link": "http://arxiv.org/abs/2007.05975",
          "publishedOn": "2021-06-08T02:20:24.589Z",
          "wordCount": null,
          "title": "A Graph Symmetrisation Bound on Channel Information Leakage under Blowfish Privacy. (arXiv:2007.05975v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_T/0/1/0/all/0/1\">Tong Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1\">Aria Masoomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1\">Stratis Ioannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1\">Jennifer Dy</a>",
          "description": "We investigate the HSIC (Hilbert-Schmidt independence criterion) bottleneck\nas a regularizer for learning an adversarially robust deep neural network\nclassifier. We show that the HSIC bottleneck enhances robustness to adversarial\nattacks both theoretically and experimentally. Our experiments on multiple\nbenchmark datasets and architectures demonstrate that incorporating an HSIC\nbottleneck regularizer attains competitive natural accuracy and improves\nadversarial robustness, both with and without adversarial examples during\ntraining.",
          "link": "http://arxiv.org/abs/2106.02734",
          "publishedOn": "2021-06-08T02:20:24.576Z",
          "wordCount": 490,
          "title": "Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness. (arXiv:2106.02734v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_M/0/1/0/all/0/1\">Mikael Johansson</a>",
          "description": "Many popular learning-rate schedules for deep neural networks combine a\ndecaying trend with local perturbations that attempt to escape saddle points\nand bad local minima. We derive convergence guarantees for bandwidth-based\nstep-sizes, a general class of learning-rates that are allowed to vary in a\nbanded region. This framework includes cyclic and non-monotonic step-sizes for\nwhich no theoretical guarantees were previously known. We provide worst-case\nguarantees for SGD on smooth non-convex problems under several bandwidth-based\nstep sizes, including stagewise $1/\\sqrt{t}$ and the popular step-decay\n(constant and then drop by a constant), which is also shown to be optimal.\nMoreover, we show that its momentum variant (SGDM) converges as fast as SGD\nwith the bandwidth-based step-decay step-size. Finally, we propose some novel\nstep-size schemes in the bandwidth-based family and verify their efficiency on\nseveral deep neural network training tasks.",
          "link": "http://arxiv.org/abs/2106.02888",
          "publishedOn": "2021-06-08T02:20:24.569Z",
          "wordCount": 559,
          "title": "Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization. (arXiv:2106.02888v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1905.11824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_S/0/1/0/all/0/1\">Soham Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rade_R/0/1/0/all/0/1\">Rahul Rade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazi_D/0/1/0/all/0/1\">Dr. Faruk Kazi</a>",
          "description": "Cyber threat intelligence is one of the emerging areas of focus in\ninformation security. Much of the recent work has focused on rule-based methods\nand detection of network attacks using Intrusion Detection algorithms. In this\npaper we propose a framework for inspecting and modelling the behavioural\naspect of an attacker to obtain better insight predictive power on his future\nactions. For modelling we propose a novel semi-supervised algorithm called\nFusion Hidden Markov Model (FHMM) which is more robust to noise, requires\ncomparatively less training time, and utilizes the benefits of ensemble\nlearning to better model temporal relationships in data. This paper evaluates\nthe performances of FHMM and compares it with both traditional algorithms like\nMarkov Chain, Hidden Markov Model (HMM) and recently developed Deep Recurrent\nNeural Network (Deep RNN) architectures. We conduct the experiments on dataset\nconsisting of real data attacks on a Cowrie honeypot system. FHMM provides\naccuracy comparable to deep RNN architectures at significant lower training\ntime. Given these experimental results, we recommend using FHMM for modelling\ndiscrete temporal data for significantly faster training and better performance\nthan existing methods.",
          "link": "http://arxiv.org/abs/1905.11824",
          "publishedOn": "2021-06-08T02:20:24.551Z",
          "wordCount": 650,
          "title": "Attacker Behaviour Profiling using Stochastic Ensemble of Hidden Markov Models. (arXiv:1905.11824v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safaryan_M/0/1/0/all/0/1\">Mher Safaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islamov_R/0/1/0/all/0/1\">Rustem Islamov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1\">Xun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "Inspired by recent work of Islamov et al (2021), we propose a family of\nFederated Newton Learn (FedNL) methods, which we believe is a marked step in\nthe direction of making second-order methods applicable to FL. In contrast to\nthe aforementioned work, FedNL employs a different Hessian learning technique\nwhich i) enhances privacy as it does not rely on the training data to be\nrevealed to the coordinating server, ii) makes it applicable beyond generalized\nlinear models, and iii) provably works with general contractive compression\noperators for compressing the local Hessians, such as Top-$K$ or Rank-$R$,\nwhich are vastly superior in practice. Notably, we do not need to rely on error\nfeedback for our methods to work with contractive compressors. Moreover, we\ndevelop FedNL-PP, FedNL-CR and FedNL-LS, which are variants of FedNL that\nsupport partial participation, and globalization via cubic regularization and\nline search, respectively, and FedNL-BC, which is a variant that can further\nbenefit from bidirectional compression of gradients and models, i.e., smart\nuplink gradient and smart downlink model compression. We prove local\nconvergence rates that are independent of the condition number, the number of\ntraining data points, and compression variance. Our communication efficient\nHessian learning technique provably learns the Hessian at the optimum. Finally,\nwe perform a variety of numerical experiments that show that our FedNL methods\nhave state-of-the-art communication complexity when compared to key baselines.",
          "link": "http://arxiv.org/abs/2106.02969",
          "publishedOn": "2021-06-08T02:20:24.536Z",
          "wordCount": 672,
          "title": "FedNL: Making Newton-Type Methods Applicable to Federated Learning. (arXiv:2106.02969v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.03513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaojun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haomin Zhou</a>",
          "description": "Learning nonlinear dynamics from aggregate data is a challenging problem\nbecause the full trajectory of each individual is not available, namely, the\nindividual observed at one time may not be observed at the next time point, or\nthe identity of individual is unavailable. This is in sharp contrast to\nlearning dynamics with full trajectory data, on which the majority of existing\nmethods are based. We propose a novel method using the weak form of Fokker\nPlanck Equation (FPE) -- a partial differential equation -- to describe the\ndensity evolution of data in a sampled form, which is then combined with\nWasserstein generative adversarial network (WGAN) in the training process. In\nsuch a sample-based framework we are able to learn the nonlinear dynamics from\naggregate data without explicitly solving the partial differential equation\n(PDE) FPE. We demonstrate our approach in the context of a series of synthetic\nand real-world data sets.",
          "link": "http://arxiv.org/abs/2002.03513",
          "publishedOn": "2021-06-08T02:20:24.529Z",
          "wordCount": null,
          "title": "Learning Stochastic Behaviour from Aggregate Data. (arXiv:2002.03513v7 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perekrestenko_D/0/1/0/all/0/1\">Dmytro Perekrestenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1\">Stephan M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1\">Helmut B&#xf6;lcskei</a>",
          "description": "We present an explicit deep neural network construction that transforms\nuniformly distributed one-dimensional noise into an arbitrarily close\napproximation of any two-dimensional Lipschitz-continuous target distribution.\nThe key ingredient of our design is a generalization of the \"space-filling\"\nproperty of sawtooth functions discovered in (Bailey & Telgarsky, 2018). We\nelicit the importance of depth - in our neural network construction - in\ndriving the Wasserstein distance between the target distribution and the\napproximation realized by the network to zero. An extension to output\ndistributions of arbitrary dimension is outlined. Finally, we show that the\nproposed construction does not incur a cost - in terms of error measured in\nWasserstein-distance - relative to generating $d$-dimensional target\ndistributions from $d$ independent random variables.",
          "link": "http://arxiv.org/abs/2006.16664",
          "publishedOn": "2021-06-08T02:20:24.525Z",
          "wordCount": 577,
          "title": "Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks. (arXiv:2006.16664v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.12725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "A fundamental problem in computational chemistry is to find a set of\nreactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.\nExisting state-of-the-art methods rely on matching the target molecule with a\nlarge set of reaction templates, which are very computationally expensive and\nalso suffer from the problem of coverage. In this paper, we propose a novel\ntemplate-free approach called G2Gs by transforming a target molecular graph\ninto a set of reactant molecular graphs. G2Gs first splits the target molecular\ngraph into a set of synthons by identifying the reaction centers, and then\ntranslates the synthons to the final reactant graphs via a variational graph\ntranslation framework. Experimental results show that G2Gs significantly\noutperforms existing template-free approaches by up to 63% in terms of the\ntop-1 accuracy and achieves a performance close to that of state-of-the-art\ntemplate based approaches, but does not require domain knowledge and is much\nmore scalable.",
          "link": "http://arxiv.org/abs/2003.12725",
          "publishedOn": "2021-06-08T02:20:24.516Z",
          "wordCount": null,
          "title": "A Graph to Graphs Framework for Retrosynthesis Prediction. (arXiv:2003.12725v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Anming Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1\">Edward Chien</a>",
          "description": "Mixup is a popular regularization technique for training deep neural networks\nthat can improve generalization and increase adversarial robustness. It\nperturbs input training data in the direction of other randomly-chosen\ninstances in the training set. To better leverage the structure of the data, we\nextend mixup to \\emph{$k$-mixup} by perturbing $k$-batches of training points\nin the direction of other $k$-batches using displacement interpolation,\ninterpolation under the Wasserstein metric. We demonstrate theoretically and in\nsimulations that $k$-mixup preserves cluster and manifold structures, and we\nextend theory studying efficacy of standard mixup. Our empirical results show\nthat training with $k$-mixup further improves generalization and robustness on\nbenchmark datasets.",
          "link": "http://arxiv.org/abs/2106.02933",
          "publishedOn": "2021-06-08T02:20:24.485Z",
          "wordCount": 531,
          "title": "k-Mixup Regularization for Deep Learning via Optimal Transport. (arXiv:2106.02933v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1\">Patrick Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wen Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.",
          "link": "http://arxiv.org/abs/2106.02658",
          "publishedOn": "2021-06-08T02:20:24.469Z",
          "wordCount": 516,
          "title": "W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daw_A/0/1/0/all/0/1\">Arka Daw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maruf_M/0/1/0/all/0/1\">M. Maruf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpatne_A/0/1/0/all/0/1\">Anuj Karpatne</a>",
          "description": "As applications of deep learning (DL) continue to seep into critical\nscientific use-cases, the importance of performing uncertainty quantification\n(UQ) with DL has become more pressing than ever before. In scientific\napplications, it is also important to inform the learning of DL models with\nknowledge of physics of the problem to produce physically consistent and\ngeneralized solutions. This is referred to as the emerging field of\nphysics-informed deep learning (PIDL). We consider the problem of developing\nPIDL formulations that can also perform UQ. To this end, we propose a novel\nphysics-informed GAN architecture, termed PID-GAN, where the knowledge of\nphysics is used to inform the learning of both the generator and discriminator\nmodels, making ample use of unlabeled data instances. We show that our proposed\nPID-GAN framework does not suffer from imbalance of generator gradients from\nmultiple loss terms as compared to state-of-the-art. We also empirically\ndemonstrate the efficacy of our proposed framework on a variety of case studies\ninvolving benchmark physics-based PDEs as well as imperfect physics. All the\ncode and datasets used in this study have been made available on this link :\nhttps://github.com/arkadaw9/PID-GAN.",
          "link": "http://arxiv.org/abs/2106.02993",
          "publishedOn": "2021-06-08T02:20:24.456Z",
          "wordCount": 640,
          "title": "PID-GAN: A GAN Framework based on a Physics-informed Discriminator for Uncertainty Quantification with Physics. (arXiv:2106.02993v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathbun_S/0/1/0/all/0/1\">Stephen L. Rathbun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "Treatment effect estimation from observational data is a critical research\ntopic across many domains. The foremost challenge in treatment effect\nestimation is how to capture hidden confounders. Recently, the growing\navailability of networked observational data offers a new opportunity to deal\nwith the issue of hidden confounders. Unlike networked data in traditional\ngraph learning tasks, such as node classification and link detection, the\nnetworked data under the causal inference problem has its particularity, i.e.,\nimbalanced network structure. In this paper, we propose a Graph Infomax\nAdversarial Learning (GIAL) model for treatment effect estimation, which makes\nfull use of the network structure to capture more information by recognizing\nthe imbalance in network structure. We evaluate the performance of our GIAL\nmodel on two benchmark datasets, and the results demonstrate superiority over\nthe state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.02881",
          "publishedOn": "2021-06-08T02:20:24.434Z",
          "wordCount": 596,
          "title": "Graph Infomax Adversarial Learning for Treatment Effect Estimation with Networked Observational Data. (arXiv:2106.02881v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02810",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Lin Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Su_B/0/1/0/all/0/1\">Bo-Hao Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hong_Y/0/1/0/all/0/1\">Y.-W. Peter Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_C/0/1/0/all/0/1\">Chi-Chun Lee</a>",
          "description": "Advancement in speech technology has brought convenience to our life.\nHowever, the concern is on the rise as speech signal contains multiple personal\nattributes, which would lead to either sensitive information leakage or bias\ntoward decision. In this work, we propose an attribute-aligned learning\nstrategy to derive speech representation that can flexibly address these issues\nby attribute-selection mechanism. Specifically, we propose a\nlayered-representation variational autoencoder (LR-VAE), which factorizes\nspeech representation into attribute-sensitive nodes, to derive an\nidentity-free representation for speech emotion recognition (SER), and an\nemotionless representation for speaker verification (SV). Our proposed method\nachieves competitive performances on identity-free SER and a better performance\non emotionless SV, comparing to the current state-of-the-art method of using\nadversarial learning applied on a large emotion corpora, the MSP-Podcast. Also,\nour proposed learning strategy reduces the model and training process needed to\nachieve multiple privacy-preserving tasks.",
          "link": "http://arxiv.org/abs/2106.02810",
          "publishedOn": "2021-06-08T02:20:24.391Z",
          "wordCount": 581,
          "title": "An Attribute-Aligned Strategy for Learning Speech Representation. (arXiv:2106.02810v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2101.10318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Satya Narayan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marlin_B/0/1/0/all/0/1\">Benjamin M. Marlin</a>",
          "description": "Irregular sampling occurs in many time series modeling applications where it\npresents a significant challenge to standard deep learning models. This work is\nmotivated by the analysis of physiological time series data in electronic\nhealth records, which are sparse, irregularly sampled, and multivariate. In\nthis paper, we propose a new deep learning framework for this setting that we\ncall Multi-Time Attention Networks. Multi-Time Attention Networks learn an\nembedding of continuous-time values and use an attention mechanism to produce a\nfixed-length representation of a time series containing a variable number of\nobservations. We investigate the performance of this framework on interpolation\nand classification tasks using multiple datasets. Our results show that the\nproposed approach performs as well or better than a range of baseline and\nrecently proposed models while offering significantly faster training times\nthan current state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2101.10318",
          "publishedOn": "2021-06-08T02:20:24.112Z",
          "wordCount": 603,
          "title": "Multi-Time Attention Networks for Irregularly Sampled Time Series. (arXiv:2101.10318v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.04238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yun Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bo Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "In spite of the success of existing meta reinforcement learning methods, they\nstill have difficulty in learning a meta policy effectively for RL problems\nwith sparse reward. In this respect, we develop a novel meta reinforcement\nlearning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.\nIt is consisted with three modules including the cross-environment meta state\nembedding module which constructs a common meta state space to adapt to\ndifferent environments; the meta state based environment-specific meta reward\nshaping which effectively extends the original sparse reward trajectory by\ncross-environmental knowledge complementarity and as a consequence the meta\npolicy achieves better generalization and efficiency with the shaped meta\nreward. Experiments with sparse-reward environments show the superiority of\nHMRL on both transferability and policy learning efficiency.",
          "link": "http://arxiv.org/abs/2002.04238",
          "publishedOn": "2021-06-08T02:20:24.070Z",
          "wordCount": 615,
          "title": "HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning Problem. (arXiv:2002.04238v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atashin_A/0/1/0/all/0/1\">Amir Ahooye Atashin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razeghi_B/0/1/0/all/0/1\">Behrooz Razeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz G&#xfc;nd&#xfc;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1\">Slava Voloshynovskiy</a>",
          "description": "We study the role of information complexity in privacy leakage about an\nattribute of an adversary's interest, which is not known a priori to the system\ndesigner. Considering the supervised representation learning setup and using\nneural networks to parameterize the variational bounds of information\nquantities, we study the impact of the following factors on the amount of\ninformation leakage: information complexity regularizer weight, latent space\ndimension, the cardinalities of the known utility and unknown sensitive\nattribute sets, the correlation between utility and sensitive attributes, and a\npotential bias in a sensitive attribute of adversary's interest. We conduct\nextensive experiments on Colored-MNIST and CelebA datasets to evaluate the\neffect of information complexity on the amount of intrinsic leakage.",
          "link": "http://arxiv.org/abs/2106.02818",
          "publishedOn": "2021-06-08T02:20:24.063Z",
          "wordCount": 555,
          "title": "Variational Leakage: The Role of Information Complexity in Privacy Leakage. (arXiv:2106.02818v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02988",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1\">Yangyi Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meisami_A/0/1/0/all/0/1\">Amirhossein Meisami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "In causal bandit problems, the action set consists of interventions on\nvariables of a causal graph. Several researchers have recently studied such\nbandit problems and pointed out their practical applications. However, all\nexisting works rely on a restrictive and impractical assumption that the\nlearner is given full knowledge of the causal graph structure upfront. In this\npaper, we develop novel causal bandit algorithms without knowing the causal\ngraph. Our algorithms work well for causal trees, causal forests and a general\nclass of causal graphs. The regret guarantees of our algorithms greatly improve\nupon those of standard multi-armed bandit (MAB) algorithms under mild\nconditions. Lastly, we prove our mild conditions are necessary: without them\none cannot do better than standard MAB bandit algorithms.",
          "link": "http://arxiv.org/abs/2106.02988",
          "publishedOn": "2021-06-08T02:20:24.056Z",
          "wordCount": 544,
          "title": "Causal Bandits with Unknown Graph Structure. (arXiv:2106.02988v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1\">Lukas Wutschitz</a>",
          "description": "We give a fast algorithm to optimally compose privacy guarantees of\ndifferentially private (DP) algorithms to arbitrary accuracy. Our method is\nbased on the notion of privacy loss random variables to quantify the privacy\nloss of DP algorithms. The running time and memory needed for our algorithm to\napproximate the privacy curve of a DP algorithm composed with itself $k$ times\nis $\\tilde{O}(\\sqrt{k})$. This improves over the best prior method by Koskela\net al. (2020) which requires $\\tilde{\\Omega}(k^{1.5})$ running time. We\ndemonstrate the utility of our algorithm by accurately computing the privacy\nloss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm\nspeeds up the privacy computations by a few orders of magnitude compared to\nprior work, while maintaining similar accuracy.",
          "link": "http://arxiv.org/abs/2106.02848",
          "publishedOn": "2021-06-08T02:20:24.051Z",
          "wordCount": 555,
          "title": "Numerical Composition of Differential Privacy. (arXiv:2106.02848v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Attentional mechanisms are order-invariant. Positional encoding is a crucial\ncomponent to allow attention-based deep model architectures such as Transformer\nto address sequences or images where the position of information matters. In\nthis paper, we propose a novel positional encoding method based on learnable\nFourier features. Instead of hard-coding each position as a token or a vector,\nwe represent each position, which can be multi-dimensional, as a trainable\nencoding based on learnable Fourier feature mapping, modulated with a\nmulti-layer perceptron. The representation is particularly advantageous for a\nspatial multi-dimensional position, e.g., pixel positions on an image, where\n$L_2$ distances or more complex positional relationships need to be captured.\nOur experiments based on several public benchmark tasks show that our learnable\nFourier feature representation for multi-dimensional positional encoding\noutperforms existing methods by both improving the accuracy and allowing faster\nconvergence.",
          "link": "http://arxiv.org/abs/2106.02795",
          "publishedOn": "2021-06-08T02:20:24.044Z",
          "wordCount": 573,
          "title": "Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01529",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1\">Joseph E. Gaudio</a>, <a href=\"http://arxiv.org/find/math/1/au:+Annaswamy_A/0/1/0/all/0/1\">Anuradha M. Annaswamy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Moreu_J/0/1/0/all/0/1\">Jos&#xe9; M. Moreu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bolender_M/0/1/0/all/0/1\">Michael A. Bolender</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gibson_T/0/1/0/all/0/1\">Travis E. Gibson</a>",
          "description": "High order momentum-based parameter update algorithms have seen widespread\napplications in training machine learning models. Recently, connections with\nvariational approaches have led to the derivation of new learning algorithms\nwith accelerated learning guarantees. Such methods however, have only\nconsidered the case of static regressors. There is a significant need for\nparameter update algorithms which can be proven stable in the presence of\nadversarial time-varying regressors, as is commonplace in control theory. In\nthis paper, we propose a new discrete time algorithm which 1) provides\nstability and asymptotic convergence guarantees in the presence of adversarial\nregressors by leveraging insights from adaptive control theory and 2) provides\nnon-asymptotic accelerated learning guarantees leveraging insights from convex\noptimization. In particular, our algorithm reaches an $\\epsilon$ sub-optimal\npoint in at most $\\tilde{\\mathcal{O}}(1/\\sqrt{\\epsilon})$ iterations when\nregressors are constant - matching lower bounds due to Nesterov of\n$\\Omega(1/\\sqrt{\\epsilon})$, up to a $\\log(1/\\epsilon)$ factor and provides\nguaranteed bounds for stability when regressors are time-varying. We provide\nnumerical experiments for a variant of Nesterov's provably hard convex\noptimization problem with time-varying regressors, as well as the problem of\nrecovering an image with a time-varying blur and noise using streaming data.",
          "link": "http://arxiv.org/abs/2005.01529",
          "publishedOn": "2021-06-08T02:20:24.038Z",
          "wordCount": 664,
          "title": "Accelerated Learning with Robustness to Adversarial Regressors. (arXiv:2005.01529v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kessler_S/0/1/0/all/0/1\">Samuel Kessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1\">Philip Ball</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zohren_S/0/1/0/all/0/1\">Stefan Zohren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen J. Roberts</a>",
          "description": "Continual Learning (CL) considers the problem of training an agent\nsequentially on a set of tasks while seeking to retain performance on all\nprevious tasks. A key challenge in CL is catastrophic forgetting, which arises\nwhen performance on a previously mastered task is reduced when learning a new\ntask. While a variety of methods exist to combat forgetting, in some cases\ntasks are fundamentally incompatible with each other and thus cannot be learnt\nby a single policy. This can occur, in reinforcement learning (RL) when an\nagent may be rewarded for achieving different goals from the same observation.\nIn this paper we formalize this ``interference'' as distinct from the problem\nof forgetting. We show that existing CL methods based on single neural network\npredictors with shared replay buffers fail in the presence of interference.\nInstead, we propose a simple method, OWL, to address this challenge. OWL learns\na factorized policy, using shared feature extraction layers, but separate\nheads, each specializing on a new task. The separate heads in OWL are used to\nprevent interference. At test time, we formulate policy selection as a\nmulti-armed bandit problem, and show it is possible to select the best policy\nfor an unknown task using feedback from the environment. The use of bandit\nalgorithms allows the OWL agent to constructively re-use different continually\nlearnt policies at different times during an episode. We show in multiple RL\nenvironments that existing replay based CL methods fail, while OWL is able to\nachieve close to optimal performance when training sequentially.",
          "link": "http://arxiv.org/abs/2106.02940",
          "publishedOn": "2021-06-08T02:20:24.032Z",
          "wordCount": 690,
          "title": "Same State, Different Task: Continual Reinforcement Learning without Interference. (arXiv:2106.02940v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02978",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "Stochastic linear contextual bandit algorithms have substantial applications\nin practice, such as recommender systems, online advertising, clinical trials,\netc. Recent works show that optimal bandit algorithms are vulnerable to\nadversarial attacks and can fail completely in the presence of attacks.\nExisting robust bandit algorithms only work for the non-contextual setting\nunder the attack of rewards and cannot improve the robustness in the general\nand popular contextual bandit environment. In addition, none of the existing\nmethods can defend against attacked context. In this work, we provide the first\nrobust bandit algorithm for stochastic linear contextual bandit setting under a\nfully adaptive and omniscient attack. Our algorithm not only works under the\nattack of rewards, but also under attacked context. Moreover, it does not need\nany information about the attack budget or the particular form of the attack.\nWe provide theoretical guarantees for our proposed algorithm and show by\nextensive experiments that our proposed algorithm significantly improves the\nrobustness against various kinds of popular attacks.",
          "link": "http://arxiv.org/abs/2106.02978",
          "publishedOn": "2021-06-08T02:20:24.025Z",
          "wordCount": 590,
          "title": "Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks. (arXiv:2106.02978v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1\">Jacob Goldberger</a>",
          "description": "We introduce a new approach for smoothing and improving the quality of word\nembeddings. We consider a method of fusing word embeddings that were trained on\nthe same corpus but with different initializations. We project all the models\nto a shared vector space using an efficient implementation of the Generalized\nProcrustes Analysis (GPA) procedure, previously used in multilingual word\ntranslation. Our word representation demonstrates consistent improvements over\nthe raw models as well as their simplistic average, on a range of tasks. As the\nnew representations are more stable and reliable, there is a noticeable\nimprovement in rare word evaluations.",
          "link": "http://arxiv.org/abs/2106.02954",
          "publishedOn": "2021-06-08T02:20:24.001Z",
          "wordCount": 533,
          "title": "Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02948",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Takagi_Y/0/1/0/all/0/1\">Yu Takagi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hunt_L/0/1/0/all/0/1\">Laurence T. Hunt</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ohata_R/0/1/0/all/0/1\">Ryu Ohata</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Imamizu_H/0/1/0/all/0/1\">Hiroshi Imamizu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hirayama_J/0/1/0/all/0/1\">Jun-ichiro Hirayama</a>",
          "description": "Multi-regional interaction among neuronal populations underlies the brain's\nprocessing of rich sensory information in our daily lives. Recent neuroscience\nand neuroimaging studies have increasingly used naturalistic stimuli and\nexperimental design to identify such realistic sensory computation in the\nbrain. However, existing methods for cross-areal interaction analysis with\ndimensionality reduction, such as reduced-rank regression and canonical\ncorrelation analysis, have limited applicability and interpretability in\nnaturalistic settings because they usually do not appropriately 'demix' neural\ninteractions into those associated with different types of task parameters or\nstimulus features (e.g., visual or audio). In this paper, we develop a new\nmethod for cross-areal interaction analysis that uses the rich task or stimulus\nparameters to reveal how and what types of information are shared by different\nneural populations. The proposed neural demixed shared component analysis\ncombines existing dimensionality reduction methods with a practical neural\nnetwork implementation of functional analysis of variance with latent\nvariables, thereby efficiently demixing nonlinear effects of continuous and\nmultimodal stimuli. We also propose a simplifying alternative under the\nassumptions of linear effects and unimodal stimuli. To demonstrate our methods,\nwe analyzed two human neuroimaging datasets of participants watching\nnaturalistic videos of movies and dance movements. The results demonstrate that\nour methods provide new insights into multi-regional interaction in the brain\nduring naturalistic sensory inputs, which cannot be captured by conventional\ntechniques.",
          "link": "http://arxiv.org/abs/2106.02948",
          "publishedOn": "2021-06-08T02:20:23.981Z",
          "wordCount": 664,
          "title": "Neural dSCA: demixing multimodal interaction among brain areas during naturalistic experiments. (arXiv:2106.02948v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hengbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "An effective understanding of the contextual environment and accurate motion\nforecasting of surrounding agents is crucial for the development of autonomous\nvehicles and social mobile robots. This task is challenging since the behavior\nof an autonomous agent is not only affected by its own intention, but also by\nthe static environment and surrounding dynamically interacting agents. Previous\nworks focused on utilizing the spatial and temporal information in time domain\nwhile not sufficiently taking advantage of the cues in frequency domain. To\nthis end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which\ncan capture inter-agent correlations and temporal dependency simultaneously in\nfrequency domain in addition to time domain. SpecTGNN operates on both an agent\ngraph with dynamic state information and an environment graph with the features\nextracted from context images in two streams. The model integrates graph\nFourier transform, spectral graph convolution and temporal gated convolution to\nencode history information and forecast future trajectories. Moreover, we\nincorporate a multi-head spatio-temporal attention mechanism to mitigate the\neffect of error propagation in a long time horizon. We demonstrate the\nperformance of SpecTGNN on two public trajectory prediction benchmark datasets,\nwhich achieves state-of-the-art performance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.02930",
          "publishedOn": "2021-06-08T02:20:23.942Z",
          "wordCount": 641,
          "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:23.924Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00520",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Paltun_B/0/1/0/all/0/1\">Bet&#xfc;l G&#xfc;ven&#xe7; Paltun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mamitsuka_H/0/1/0/all/0/1\">Hiroshi Mamitsuka</a>",
          "description": "Detecting predictive biomarkers from multi-omics data is important for\nprecision medicine, to improve diagnostics of complex diseases and for better\ntreatments. This needs substantial experimental efforts that are made difficult\nby the heterogeneity of cell lines and huge cost. An effective solution is to\nbuild a computational model over the diverse omics data, including genomic,\nmolecular, and environmental information. However, choosing informative and\nreliable data sources from among the different types of data is a challenging\nproblem. We propose DIVERSE, a framework of Bayesian importance-weighted tri-\nand bi-matrix factorization(DIVERSE3 or DIVERSE2) to predict drug responses\nfrom data of cell lines, drugs, and gene interactions. DIVERSE integrates the\ndata sources systematically, in a step-wise manner, examining the importance of\neach added data set in turn. More specifically, we sequentially integrate five\ndifferent data sets, which have not all been combined in earlier bioinformatic\nmethods for predicting drug responses. Empirical experiments show that DIVERSE\nclearly outperformed five other methods including three state-of-the-art\napproaches, under cross-validation, particularly in out-of-matrix prediction,\nwhich is closer to the setting of real use cases and more challenging than\nsimpler in-matrix prediction. Additionally, case studies for discovering new\ndrugs further confirmed the performance advantage of DIVERSE.",
          "link": "http://arxiv.org/abs/2104.00520",
          "publishedOn": "2021-06-08T02:20:23.913Z",
          "wordCount": 681,
          "title": "DIVERSE: Bayesian Data IntegratiVE learning for precise drug ResponSE prediction. (arXiv:2104.00520v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02979",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yi-Wei Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "The stochastic contextual bandit problem, which models the trade-off between\nexploration and exploitation, has many real applications, including recommender\nsystems, online advertising and clinical trials. As many other machine learning\nalgorithms, contextual bandit algorithms often have one or more\nhyper-parameters. As an example, in most optimal stochastic contextual bandit\nalgorithms, there is an unknown exploration parameter which controls the\ntrade-off between exploration and exploitation. A proper choice of the\nhyper-parameters is essential for contextual bandit algorithms to perform well.\nHowever, it is infeasible to use offline tuning methods to select\nhyper-parameters in contextual bandit environment since there is no\npre-collected dataset and the decisions have to be made in real time. To tackle\nthis problem, we first propose a two-layer bandit structure for auto tuning the\nexploration parameter and further generalize it to the Syndicated Bandits\nframework which can learn multiple hyper-parameters dynamically in contextual\nbandit environment. We show our Syndicated Bandits framework can achieve the\noptimal regret upper bounds and is general enough to handle the tuning tasks in\nmany popular contextual bandit algorithms, such as LinUCB, LinTS, UCB-GLM, etc.\nExperiments on both synthetic and real datasets validate the effectiveness of\nour proposed framework.",
          "link": "http://arxiv.org/abs/2106.02979",
          "publishedOn": "2021-06-08T02:20:23.906Z",
          "wordCount": 632,
          "title": "Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms. (arXiv:2106.02979v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01379",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lecuyer_M/0/1/0/all/0/1\">Mathias L&#xe9;cuyer</a>",
          "description": "Differential Privacy (DP) is the leading approach to privacy preserving deep\nlearning. As such, there are multiple efforts to provide drop-in integration of\nDP into popular frameworks. These efforts, which add noise to each gradient\ncomputation to make it DP, rely on composition theorems to bound the total\nprivacy loss incurred over this sequence of DP computations.\n\nHowever, existing composition theorems present a tension between efficiency\nand flexibility. Most theorems require all computations in the sequence to have\na predefined DP parameter, called the privacy budget. This prevents the design\nof training algorithms that adapt the privacy budget on the fly, or that\nterminate early to reduce the total privacy loss. Alternatively, the few\nexisting composition results for adaptive privacy budgets provide complex\nbounds on the privacy loss, with constants too large to be practical.\n\nIn this paper, we study DP composition under adaptive privacy budgets through\nthe lens of R\\'enyi Differential Privacy, proving a simpler composition theorem\nwith smaller constants, making it practical enough to use in algorithm design.\nWe demonstrate two applications of this theorem for DP deep learning: adapting\nthe noise or batch size online to improve a model's accuracy within a fixed\ntotal privacy loss, and stopping early when fine-tuning a model to reduce total\nprivacy loss.",
          "link": "http://arxiv.org/abs/2103.01379",
          "publishedOn": "2021-06-08T02:20:23.899Z",
          "wordCount": 665,
          "title": "Practical Privacy Filters and Odometers with R\\'enyi Differential Privacy and Applications to Differentially Private Deep Learning. (arXiv:2103.01379v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Cong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1\">Won-Yong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spitz_A/0/1/0/all/0/1\">Andreas Spitz</a>",
          "description": "In real-world applications of influence maximization (IM), the network\nstructure is often unknown. In this case, we may identify the most influential\nseed nodes by exploring only a part of the underlying network given a small\nbudget for node queries. Motivated by the fact that collecting node metadata is\nmore cost-effective than investigating the relationship between nodes via\nqueried nodes, we develop IM-META, an end-to-end solution to IM in networks\nwith unknown topology by retrieving information from both queries and node\nmetadata. However, using such metadata to aid the IM process is not without\nrisk due to the noisy nature of metadata and uncertainties in connectivity\ninference. To tackle these challenges, we formulate an IM problem that aims to\nfind two sets, i.e., seed nodes and queried nodes. We propose an effective\nmethod that iteratively performs three steps: 1) we learn the relationship\nbetween collected metadata and edges via a Siamese neural network model, 2) we\nselect a number of inferred influential edges to construct a reinforced graph\nused for discovering an optimal seed set, and 3) we identify the next node to\nquery by maximizing the inferred influence spread using a topology-aware\nranking strategy. By querying only 5% of nodes, IM-META reaches 93% of the\nupper bound performance.",
          "link": "http://arxiv.org/abs/2106.02926",
          "publishedOn": "2021-06-08T02:20:23.893Z",
          "wordCount": 667,
          "title": "IM-META: Influence Maximization Using Node Metadata in Networks With Unknown Topology. (arXiv:2106.02926v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mastouri_A/0/1/0/all/0/1\">Afsaneh Mastouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korba_A/0/1/0/all/0/1\">Anna Korba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ricardo Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1\">Krikamol Muandet</a>",
          "description": "We address the problem of causal effect estimation in the presence of\nunobserved confounding, but where proxies for the latent confounder(s) are\nobserved. We propose two kernel-based methods for nonlinear causal effect\nestimation in this setting: (a) a two-stage regression approach, and (b) a\nmaximum moment restriction approach. We focus on the proximal causal learning\nsetting, but our methods can be used to solve a wider class of inverse problems\ncharacterised by a Fredholm integral equation. In particular, we provide a\nunifying view of two-stage and moment restriction approaches for solving this\nproblem in a nonlinear setting. We provide consistency guarantees for each\nalgorithm, and we demonstrate these approaches achieve competitive results on\nsynthetic data and data simulating a real-world task. In particular, our\napproach outperforms earlier methods that are not suited to leveraging proxy\nvariables.",
          "link": "http://arxiv.org/abs/2105.04544",
          "publishedOn": "2021-06-08T02:20:23.873Z",
          "wordCount": 613,
          "title": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment Restriction. (arXiv:2105.04544v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02855",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Santosh_S/0/1/0/all/0/1\">S. V. Sai Santosh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Darak_S/0/1/0/all/0/1\">Sumit J. Darak</a>",
          "description": "Multi-armed Bandit (MAB) algorithms identify the best arm among multiple arms\nvia exploration-exploitation trade-off without prior knowledge of arm\nstatistics. Their usefulness in wireless radio, IoT, and robotics demand\ndeployment on edge devices, and hence, a mapping on system-on-chip (SoC) is\ndesired. Theoretically, the Bayesian approach-based Thompson Sampling (TS)\nalgorithm offers better performance than the frequentist approach-based Upper\nConfidence Bound (UCB) algorithm. However, TS is not synthesizable due to Beta\nfunction. We address this problem by approximating it via a pseudo-random\nnumber generator-based approach and efficiently realize the TS algorithm on\nZynq SoC. In practice, the type of arms distribution (e.g., Bernoulli,\nGaussian, etc.) is unknown and hence, a single algorithm may not be optimal. We\npropose a reconfigurable and intelligent MAB (RI-MAB) framework. Here,\nintelligence enables the identification of appropriate MAB algorithms for a\ngiven environment, and reconfigurability allows on-the-fly switching between\nalgorithms on the SoC. This eliminates the need for parallel implementation of\nalgorithms resulting in huge savings in resources and power consumption. We\nanalyze the functional correctness, area, power, and execution time of the\nproposed and existing architectures for various arm distributions, word-length,\nand hardware-software co-design approaches. We demonstrate the superiority of\nthe RI-MAB over TS and UCB only architectures.",
          "link": "http://arxiv.org/abs/2106.02855",
          "publishedOn": "2021-06-08T02:20:23.867Z",
          "wordCount": 644,
          "title": "Multi-armed Bandit Algorithms on System-on-Chip: Go Frequentist or Bayesian?. (arXiv:2106.02855v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1\">Sagar Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Mhafuzul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Mashrur Chowdhury</a>",
          "description": "In this study, a sensor fusion based GNSS spoofing attack detection framework\nis presented that consists of three concurrent strategies for an autonomous\nvehicle (AV): (i) prediction of location shift, (ii) detection of turns (left\nor right), and (iii) recognition of motion state (including standstill state).\nData from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering\nangle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural\nnetwork model, which is a long short-term memory (LSTM) network for predicting\nthe location shift, i.e., the distance that an AV travels between two\nconsecutive timestamps. We have then combined k-Nearest Neighbors (k-NN) and\nDynamic Time Warping (DTW) algorithms to detect turns using data from the\nsteering angle sensor. In addition, data from an AV's speed sensor is used to\nrecognize the AV's motion state including the standstill state. To prove the\nefficacy of the sensor fusion-based attack detection framework, attack datasets\nare created for three unique and sophisticated spoofing attacks turn by turn,\novershoot, and stop using the publicly available real-world Honda Research\nInstitute Driving Dataset (HDD). Our analysis reveals that the sensor\nfusion-based detection framework successfully detects all three types of\nspoofing attacks within the required computational latency threshold.",
          "link": "http://arxiv.org/abs/2106.02982",
          "publishedOn": "2021-06-08T02:20:23.860Z",
          "wordCount": 635,
          "title": "Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles. (arXiv:2106.02982v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.02468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1\">Leonardo Petrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1\">Alessandro Favero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1\">Mario Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Understanding why deep nets can classify data in large dimensions remains a\nchallenge. It has been proposed that they do so by becoming stable to\ndiffeomorphisms, yet existing empirical measurements support that it is often\nnot the case. We revisit this question by defining a maximum-entropy\ndistribution on diffeomorphisms, that allows to study typical diffeomorphisms\nof a given norm. We confirm that stability toward diffeomorphisms does not\nstrongly correlate to performance on benchmark data sets of images. By\ncontrast, we find that the stability toward diffeomorphisms relative to that of\ngeneric transformations $R_f$ correlates remarkably with the test error\n$\\epsilon_t$. It is of order unity at initialization but decreases by several\ndecades during training for state-of-the-art architectures. For CIFAR10 and 15\nknown architectures, we find $\\epsilon_t\\approx 0.2\\sqrt{R_f}$, suggesting that\nobtaining a small $R_f$ is important to achieve good performance. We study how\n$R_f$ depends on the size of the training set and compare it to a simple model\nof invariant learning.",
          "link": "http://arxiv.org/abs/2105.02468",
          "publishedOn": "2021-06-08T02:20:23.854Z",
          "wordCount": 621,
          "title": "Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1\">Kartik Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "While recent work has shown that scores from models trained by the ubiquitous\nmasked language modeling (MLM) objective effectively discriminate probable and\nimprobable sequences, it is still an open question if these MLMs specify a\nprincipled probability distribution over the space of possible sequences. In\nthis paper, we interpret MLMs as energy-based sequence models and propose two\nenergy parametrizations derivable from the trained MLMs. In order to draw\nsamples correctly from these models, we develop a tractable \\emph{sampling}\nscheme based on the Metropolis--Hastings Monte Carlo algorithm. In our\napproach, samples are proposed from the same masked conditionals used for\ntraining the masked language models, and they are accepted or rejected based on\ntheir energy values according to the target distribution. We validate the\neffectiveness of the proposed parametrizations by exploring the quality of\nsamples drawn from these energy-based models on the conditional generation task\nof machine translation. We theoretically and empirically justify our sampling\nalgorithm by showing that the masked conditionals on their own do not yield a\nMarkov chain whose stationary distribution is that of our target distribution,\nand our approach generates higher quality samples than other recently proposed\nundirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,\n2019).",
          "link": "http://arxiv.org/abs/2106.02736",
          "publishedOn": "2021-06-08T02:20:23.846Z",
          "wordCount": 634,
          "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiaosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1\">Geewon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1\">Changho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>",
          "description": "In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),\nan algorithm that performs matrix completion in the presence of social and item\nsimilarity graphs. MC2G runs in quasilinear time and is parameter free. It is\nbased on spectral clustering and local refinement steps. The expected number of\nsampled entries required for MC2G to succeed (i.e., recover the clusters in the\ngraphs and complete the matrix) matches an information-theoretic lower bound up\nto a constant factor for a wide range of parameters. We show via extensive\nexperiments on both synthetic and real datasets that MC2G outperforms other\nstate-of-the-art matrix completion algorithms that leverage graph side\ninformation.",
          "link": "http://arxiv.org/abs/2006.04373",
          "publishedOn": "2021-06-08T02:20:23.828Z",
          "wordCount": 594,
          "title": "MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1\">Soumyya Kanti Datta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammad Abuzar Shaikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1\">Sargur N. Srihari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1\">Mingchen Gao</a>",
          "description": "In clinical applications, neural networks must focus on and highlight the\nmost important parts of an input image. Soft-Attention mechanism enables a\nneural network toachieve this goal. This paper investigates the effectiveness\nof Soft-Attention in deep neural architectures. The central aim of\nSoft-Attention is to boost the value of important features and suppress the\nnoise-inducing features. We compare the performance of VGG, ResNet,\nInceptionResNetv2 and DenseNet architectures with and without the\nSoft-Attention mechanism, while classifying skin lesions. The original network\nwhen coupled with Soft-Attention outperforms the baseline[16] by 4.7% while\nachieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,\nSoft-Attention coupling improves the sensitivity score by 3.8% compared to\nbaseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly\navailable at github.",
          "link": "http://arxiv.org/abs/2105.03358",
          "publishedOn": "2021-06-08T02:20:23.821Z",
          "wordCount": 600,
          "title": "Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_H/0/1/0/all/0/1\">Hossein Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyunsin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sungrack Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louizos_C/0/1/0/all/0/1\">Christos Louizos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soriaga_J/0/1/0/all/0/1\">Joseph Soriaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "We consider the problem of training User Verification (UV) models in\nfederated setting, where each user has access to the data of only one class and\nuser embeddings cannot be shared with the server or other users. To address\nthis problem, we propose Federated User Verification (FedUV), a framework in\nwhich users jointly learn a set of vectors and maximize the correlation of\ntheir instance embeddings with a secret linear combination of those vectors. We\nshow that choosing the linear combinations from the codewords of an\nerror-correcting code allows users to collaboratively train the model without\nrevealing their embedding vectors. We present the experimental results for user\nverification with voice, face, and handwriting data and show that FedUV is on\npar with existing approaches, while not sharing the embeddings with other users\nor the server.",
          "link": "http://arxiv.org/abs/2104.08776",
          "publishedOn": "2021-06-08T02:20:23.815Z",
          "wordCount": 598,
          "title": "Federated Learning of User Verification Models Without Sharing Embeddings. (arXiv:2104.08776v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1\">Armin Hadzic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Neil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Phil Burlina</a>",
          "description": "We propose a novel method for enforcing AI fairness with respect to protected\nor sensitive factors. This method uses a dual strategy performing training and\nrepresentation alteration (TARA) for the mitigation of prominent causes of AI\nbias by including: a) the use of representation learning alteration via\nadversarial independence to suppress the bias-inducing dependence of the data\nrepresentation from protected factors; and b) training set alteration via\nintelligent augmentation to address bias-causing data imbalance, by using\ngenerative models that allow the fine control of sensitive factors related to\nunderrepresented populations via domain adaptation and latent space\nmanipulation. When testing our methods on image analytics, experiments\ndemonstrate that TARA significantly or fully debiases baseline models while\noutperforming competing debiasing methods that have the same amount of\ninformation, e.g., with (% overall accuracy, % accuracy gap) = (78.8, 0.5) vs.\nthe baseline method's score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.\n(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in\ncurrent metrics used for assessing debiasing performance, we propose novel\nconjunctive debiasing metrics. Our experiments also demonstrate the ability of\nthese novel metrics in assessing the Pareto efficiency of the proposed methods.",
          "link": "http://arxiv.org/abs/2012.06387",
          "publishedOn": "2021-06-08T02:20:23.807Z",
          "wordCount": 675,
          "title": "TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havens_A/0/1/0/all/0/1\">Aaron Havens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1\">Girish Chowdhary</a>",
          "description": "As deep learning becomes more prevalent for prediction and control of real\nphysical systems, it is important that these overparameterized models are\nconsistent with physically plausible dynamics. This elicits a problem with how\nmuch inductive bias to impose on the model through known physical parameters\nand principles to reduce complexity of the learning problem to give us more\nreliable predictions. Recent work employs discrete variational integrators\nparameterized as a neural network architecture to learn conservative Lagrangian\nsystems. The learned model captures and enforces global energy preserving\nproperties of the system from very few trajectories. However, most real systems\nare inherently non-conservative and, in practice, we would also like to apply\nactuation. In this paper we extend this paradigm to account for general forcing\n(e.g. control input and damping) via discrete d'Alembert's principle which may\nultimately be used for control applications. We show that this forced\nvariational integrator networks (FVIN) architecture allows us to accurately\naccount for energy dissipation and external forcing while still capturing the\ntrue underlying energy-based passive dynamics. We show that in application this\ncan result in highly-data efficient model-based control and can predict on real\nnon-conservative systems.",
          "link": "http://arxiv.org/abs/2106.02973",
          "publishedOn": "2021-06-08T02:20:23.782Z",
          "wordCount": 622,
          "title": "Forced Variational Integrator Networks for Prediction and Control of Mechanical Systems. (arXiv:2106.02973v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1\">Fartash Faghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1\">Sven Gowal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1\">Cristina Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1\">Fabian Pedregosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>",
          "description": "We demonstrate that the choice of optimizer, neural network architecture, and\nregularizer significantly affect the adversarial robustness of linear neural\nnetworks, providing guarantees without the need for adversarial training. To\nthis end, we revisit a known result linking maximally robust classifiers and\nminimum norm solutions, and combine it with recent results on the implicit bias\nof optimizers. First, we show that, under certain conditions, it is possible to\nachieve both perfect standard accuracy and a certain degree of robustness,\nsimply by training an overparametrized model using the implicit bias of the\noptimization. In that regime, there is a direct relationship between the type\nof the optimizer and the attack to which the model is robust. To the best of\nour knowledge, this work is the first to study the impact of optimization\nmethods such as sign gradient descent and proximal methods on adversarial\nrobustness. Second, we characterize the robustness of linear convolutional\nmodels, showing that they resist attacks subject to a constraint on the\nFourier-$\\ell_\\infty$ norm. To illustrate these findings we design a novel\nFourier-$\\ell_\\infty$ attack that finds adversarial examples with controllable\nfrequencies. We evaluate Fourier-$\\ell_\\infty$ robustness of\nadversarially-trained deep CIFAR-10 models from the standard RobustBench\nbenchmark and visualize adversarial perturbations.",
          "link": "http://arxiv.org/abs/2102.08868",
          "publishedOn": "2021-06-08T02:20:23.761Z",
          "wordCount": 685,
          "title": "Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_K/0/1/0/all/0/1\">Kyra Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1\">Su Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Andrew Li</a>",
          "description": "In the problem of active sequential hypotheses testing (ASHT), a learner\nseeks to identify the true hypothesis from among a known set of hypotheses. The\nlearner is given a set of actions and knows the random distribution of the\noutcome of any action under any true hypothesis. Given a target error\n$\\delta>0$, the goal is to sequentially select the fewest number of actions so\nas to identify the true hypothesis with probability at least $1 - \\delta$.\nMotivated by applications in which the number of hypotheses or actions is\nmassive (e.g. genomics-based cancer detection), we propose efficient (greedy,\nin fact) algorithms and provide the first approximation guarantees for ASHT,\nunder two types of adaptivity. Both of our guarantees are independent of the\nnumber of actions and logarithmic in the number of hypotheses. We numerically\nevaluate the performance of our algorithms using both synthetic and real DNA\nmutation data, demonstrating that our algorithms outperform previous heuristic\npolicies by large margins.",
          "link": "http://arxiv.org/abs/2103.04250",
          "publishedOn": "2021-06-08T02:20:23.753Z",
          "wordCount": 612,
          "title": "Greedy Approximation Algorithms for Active Sequential Hypothesis Testing. (arXiv:2103.04250v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pathan_S/0/1/0/all/0/1\">Sharmin Pathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_V/0/1/0/all/0/1\">Vyom Shrivastava</a>",
          "description": "We present an end-to-end framework for the Assignment Problem with multiple\ntasks mapped to a group of workers, using reinforcement learning while\npreserving many constraints. Tasks and workers have time constraints and there\nis a cost associated with assigning a worker to a task. Each worker can perform\nmultiple tasks until it exhausts its allowed time units (capacity). We train a\nreinforcement learning agent to find near optimal solutions to the problem by\nminimizing total cost associated with the assignments while maintaining hard\nconstraints. We use proximal policy optimization to optimize model parameters.\nThe model generates a sequence of actions in real-time which correspond to task\nassignment to workers, without having to retrain for changes in the dynamic\nstate of the environment. In our problem setting reward is computed as negative\nof the assignment cost. We also demonstrate our results on bin packing and\ncapacitated vehicle routing problem, using the same framework. Our results\noutperform Google OR-Tools using MIP and CP-SAT solvers with large problem\ninstances, in terms of solution quality and computation time.",
          "link": "http://arxiv.org/abs/2106.02856",
          "publishedOn": "2021-06-08T02:20:23.721Z",
          "wordCount": 598,
          "title": "Reinforcement Learning for Assignment Problem with Time Constraints. (arXiv:2106.02856v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02800",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1\">Konstantina Sampani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mengjia Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yixiang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">He Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer K. Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time\nretinal images with high resolution down to 2 $\\mu m$. This technique enables\ndetection of the morphologies of individual microaneurysms (MAs), which are one\nof the earliest signs of diabetic retinopathy (DR), a frequent complication of\ndiabetes that can lead to visual impairment and blindness. In contrast to\nprevious automatic models developed for MA detection on standard fundus\nphotographs, currently there is no high throughput image protocol available for\nautomatic analysis of AOSLO photographs. To address this urgency, we introduce\nAOSLO-net, a deep neural network framework with customized training policy,\nincluding preprocessing, data augmentation and transfer learning, to\nautomatically segment MAs from AOSLO images. We evaluate the performance of\nAOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and\nsegmentation, leading to correct MA morphological classification, while\noutperforming the state-of-the-art both in accuracy and cost.",
          "link": "http://arxiv.org/abs/2106.02800",
          "publishedOn": "2021-06-08T02:20:23.696Z",
          "wordCount": 617,
          "title": "AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schutt_K/0/1/0/all/0/1\">Kristof T. Sch&#xfc;tt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unke_O/0/1/0/all/0/1\">Oliver T. Unke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gastegger_M/0/1/0/all/0/1\">Michael Gastegger</a>",
          "description": "Message passing neural networks have become a method of choice for learning\non graphs, in particular the prediction of chemical properties and the\nacceleration of molecular dynamics studies. While they readily scale to large\ntraining data sets, previous approaches have proven to be less data efficient\nthan kernel methods. We identify limitations of invariant representations as a\nmajor reason and extend the message passing formulation to rotationally\nequivariant representations. On this basis, we propose the polarizable atom\ninteraction neural network (PaiNN) and improve on common molecule benchmarks\nover previous networks, while reducing model size and inference time. We\nleverage the equivariant atomwise representations obtained by PaiNN for the\nprediction of tensorial properties. Finally, we apply this to the simulation of\nmolecular spectra, achieving speedups of 4-5 orders of magnitude compared to\nthe electronic structure reference.",
          "link": "http://arxiv.org/abs/2102.03150",
          "publishedOn": "2021-06-08T02:20:23.689Z",
          "wordCount": 623,
          "title": "Equivariant message passing for the prediction of tensorial properties and molecular spectra. (arXiv:2102.03150v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.01302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Richards_J/0/1/0/all/0/1\">John A. Richards</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bagchi_S/0/1/0/all/0/1\">Saurabh Bagchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1\">Shreyas Sundaram</a>",
          "description": "We consider the problem of distributed inference where agents in a network\nobserve a stream of private signals generated by an unknown state, and aim to\nuniquely identify this state from a finite set of hypotheses. We focus on\nscenarios where communication between agents is costly, and takes place over\nchannels with finite bandwidth. To reduce the frequency of communication, we\ndevelop a novel event-triggered distributed learning rule that is based on the\nprinciple of diffusing low beliefs on each false hypothesis. Building on this\nprinciple, we design a trigger condition under which an agent broadcasts only\nthose components of its belief vector that have adequate innovation, to only\nthose neighbors that require such information. We prove that our rule\nguarantees convergence to the true state exponentially fast almost surely\ndespite sparse communication, and that it has the potential to significantly\nreduce information flow from uninformative agents to informative agents. Next,\nto deal with finite-precision communication channels, we propose a distributed\nlearning rule that leverages the idea of adaptive quantization. We show that by\nsequentially refining the range of the quantizers, every agent can learn the\ntruth exponentially fast almost surely, while using just $1$ bit to encode its\nbelief on each hypothesis. For both our proposed algorithms, we rigorously\ncharacterize the trade-offs between communication-efficiency and the learning\nrate.",
          "link": "http://arxiv.org/abs/2004.01302",
          "publishedOn": "2021-06-08T02:20:23.670Z",
          "wordCount": 717,
          "title": "Distributed Inference with Sparse and Quantized Communication. (arXiv:2004.01302v4 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.",
          "link": "http://arxiv.org/abs/2103.09593",
          "publishedOn": "2021-06-08T02:20:23.663Z",
          "wordCount": 652,
          "title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02693",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Rosanne Turner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ly_A/0/1/0/all/0/1\">Alexander Ly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grunwald_P/0/1/0/all/0/1\">Peter Gr&#xfc;nwald</a>",
          "description": "We develop E variables for testing whether two data streams come from the\nsame source or not, and more generally, whether the difference between the\nsources is larger than some minimal effect size. These E variables lead to\ntests that remain safe, i.e. keep their Type-I error guarantees, under flexible\nsampling scenarios such as optional stopping and continuation. We also develop\nthe corresponding always-valid confidence intervals. In special cases our E\nvariables also have an optimal `growth' property under the alternative. We\nillustrate the generic construction through the special case of 2x2 contingency\ntables, where we also allow for the incorporation of different restrictions on\na composite alternative. Comparison to p-value analysis in simulations and a\nreal-world example show that E variables, through their flexibility, often\nallow for early stopping of data collection, thereby retaining similar power as\nclassical methods.",
          "link": "http://arxiv.org/abs/2106.02693",
          "publishedOn": "2021-06-08T02:20:23.657Z",
          "wordCount": 575,
          "title": "Safe Tests and Always-Valid Confidence Intervals for contingency tables and beyond. (arXiv:2106.02693v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shabat_E/0/1/0/all/0/1\">Eliran Shabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1\">Lee Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>",
          "description": "There is a growing interest in societal concerns in machine learning systems,\nespecially in fairness. Multicalibration gives a comprehensive methodology to\naddress group fairness. In this work, we address the multicalibration error and\ndecouple it from the prediction error. The importance of decoupling the\nfairness metric (multicalibration) and the accuracy (prediction error) is due\nto the inherent trade-off between the two, and the societal decision regarding\nthe \"right tradeoff\" (as imposed many times by regulators). Our work gives\nsample complexity bounds for uniform convergence guarantees of multicalibration\nerror, which implies that regardless of the accuracy, we can guarantee that the\nempirical and (true) multicalibration errors are close. We emphasize that our\nresults: (1) are more general than previous bounds, as they apply to both\nagnostic and realizable settings, and do not rely on a specific type of\nalgorithm (such as deferentially private), (2) improve over previous\nmulticalibration sample complexity bounds and (3) implies uniform convergence\nguarantees for the classical calibration error.",
          "link": "http://arxiv.org/abs/2005.01757",
          "publishedOn": "2021-06-08T02:20:23.634Z",
          "wordCount": 629,
          "title": "Sample Complexity of Uniform Convergence for Multicalibration. (arXiv:2005.01757v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05640",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scott_C/0/1/0/all/0/1\">Clayton D. Scott</a>",
          "description": "Recent empirical evidence suggests that the Weston-Watkins support vector\nmachine is among the best performing multiclass extensions of the binary SVM.\nCurrent state-of-the-art solvers repeatedly solve a particular subproblem\napproximately using an iterative strategy. In this work, we propose an\nalgorithm that solves the subproblem exactly using a novel reparametrization of\nthe Weston-Watkins dual problem. For linear WW-SVMs, our solver shows\nsignificant speed-up over the state-of-the-art solver when the number of\nclasses is large. Our exact subproblem solver also allows us to prove linear\nconvergence of the overall solver.",
          "link": "http://arxiv.org/abs/2102.05640",
          "publishedOn": "2021-06-08T02:20:23.627Z",
          "wordCount": 533,
          "title": "An Exact Solver for the Weston-Watkins SVM Subproblem. (arXiv:2102.05640v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Jay Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1\">Haim Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1\">Uri Stemmer</a>",
          "description": "We give an $(\\varepsilon,\\delta)$-differentially private algorithm for the\nmulti-armed bandit (MAB) problem in the shuffle model with a\ndistribution-dependent regret of $O\\left(\\left(\\sum_{a\\in\n[k]:\\Delta_a>0}\\frac{\\log\nT}{\\Delta_a}\\right)+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log\nT}{\\varepsilon}\\right)$, and a distribution-independent regret of\n$O\\left(\\sqrt{kT\\log T}+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log\nT}{\\varepsilon}\\right)$, where $T$ is the number of rounds, $\\Delta_a$ is the\nsuboptimality gap of the arm $a$, and $k$ is the total number of arms. Our\nupper bound almost matches the regret of the best known algorithms for the\ncentralized model, and significantly outperforms the best known algorithm in\nthe local model.",
          "link": "http://arxiv.org/abs/2106.02900",
          "publishedOn": "2021-06-08T02:20:23.618Z",
          "wordCount": 514,
          "title": "Differentially Private Multi-Armed Bandits in the Shuffle Model. (arXiv:2106.02900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-08T02:20:23.611Z",
          "wordCount": 624,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1907.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yantao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shujian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giraldo_L/0/1/0/all/0/1\">Luis Sanchez Giraldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1\">Jose C. Principe</a>",
          "description": "This paper proposes a novel architecture, termed multiscale principle of\nrelevant information (MPRI), to learn discriminative spectral-spatial features\nfor hyperspectral image (HSI) classification. MPRI inherits the merits of the\nprinciple of relevant information (PRI) to effectively extract multiscale\ninformation embedded in the given data, and also takes advantage of the\nmultilayer structure to learn representations in a coarse-to-fine manner.\nSpecifically, MPRI performs spectral-spatial pixel characterization (using PRI)\nand feature dimensionality reduction (using regularized linear discriminant\nanalysis) iteratively and successively. Extensive experiments on three\nbenchmark data sets demonstrate that MPRI outperforms existing state-of-the-art\nmethods (including deep learning based ones) qualitatively and quantitatively,\nespecially in the scenario of limited training samples. Code of MPRI is\navailable at \\url{this http URL}.",
          "link": "http://arxiv.org/abs/1907.06022",
          "publishedOn": "2021-06-08T02:20:23.549Z",
          "wordCount": 612,
          "title": "Multiscale Principle of Relevant Information for Hyperspectral Image Classification. (arXiv:1907.06022v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Atticus Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanson Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1\">Thomas Icard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "Structural analysis methods (e.g., probing and feature attribution) are\nincreasingly important tools for neural network analysis. We propose a new\nstructural analysis method grounded in a formal theory of \\textit{causal\nabstraction} that provides rich characterizations of model-internal\nrepresentations and their roles in input/output behavior. In this method,\nneural representations are aligned with variables in interpretable causal\nmodels, and then \\textit{interchange interventions} are used to experimentally\nverify that the neural representations have the causal properties of their\naligned variables. We apply this method in a case study to analyze neural\nmodels trained on Multiply Quantified Natural Language Inference (MQNLI)\ncorpus, a highly complex NLI dataset that was constructed with a\ntree-structured natural logic causal model. We discover that a BERT-based model\nwith state-of-the-art performance successfully realizes the approximate causal\nstructure of the natural logic causal model, whereas a simpler baseline model\nfails to show any such structure, demonstrating that neural representations\nencode the compositional structure of MQNLI examples.",
          "link": "http://arxiv.org/abs/2106.02997",
          "publishedOn": "2021-06-08T02:20:23.542Z",
          "wordCount": 578,
          "title": "Causal Abstractions of Neural Networks. (arXiv:2106.02997v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hyfte_Z/0/1/0/all/0/1\">Zach Van Hyfte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1\">Avideh Zakhor</a>",
          "description": "Smartphone apps for exposure notification and contact tracing have been shown\nto be effective in controlling the COVID-19 pandemic. However, Bluetooth Low\nEnergy tokens similar to those broadcast by existing apps can still be picked\nup far away from the transmitting device. In this paper, we present a new class\nof methods for detecting whether or not two Wi-Fi-enabled devices are in\nimmediate physical proximity, i.e. 2 or fewer meters apart, as established by\nthe U.S. Centers for Disease Control and Prevention (CDC). Our goal is to\nenhance the accuracy of smartphone-based exposure notification and contact\ntracing systems. We present a set of binary machine learning classifiers that\ntake as input pairs of Wi-Fi RSSI fingerprints. We empirically verify that a\nsingle classifier cannot generalize well to a range of different environments\nwith vastly different numbers of detectable Wi-Fi Access Points (APs). However,\nspecialized classifiers, tailored to situations where the number of detectable\nAPs falls within a certain range, are able to detect immediate physical\nproximity significantly more accurately. As such, we design three classifiers\nfor situations with low, medium, and high numbers of detectable APs. These\nclassifiers distinguish between pairs of RSSI fingerprints recorded 2 or fewer\nmeters apart and pairs recorded further apart but still in Bluetooth range. We\ncharacterize their balanced accuracy for this task to be between 66.8% and\n77.8%.",
          "link": "http://arxiv.org/abs/2106.02777",
          "publishedOn": "2021-06-08T02:20:23.534Z",
          "wordCount": 704,
          "title": "Immediate Proximity Detection Using Wi-Fi-Enabled Smartphones. (arXiv:2106.02777v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koti_N/0/1/0/all/0/1\">Nishat Koti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patra_A/0/1/0/all/0/1\">Arpita Patra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rachuri_R/0/1/0/all/0/1\">Rahul Rachuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ajith Suresh</a>",
          "description": "In this work, we design an efficient mixed-protocol framework, Tetrad, with\napplications to privacy-preserving machine learning. It is designed for the\nfour-party setting with at most one active corruption and supports rings.\n\nOur fair multiplication protocol requires communicating only 5 ring elements\nimproving over the state-of-the-art protocol of Trident (Chaudhari et al.\nNDSS'20). The technical highlights of Tetrad include efficient (a) truncation\nwithout any overhead, (b) multi-input multiplication protocols for arithmetic\nand boolean worlds, (c) garbled-world, tailor-made for the mixed-protocol\nframework, and (d) conversion mechanisms to switch between the computation\nstyles. The fair framework is also extended to provide robustness without\ninflating the costs.\n\nThe competence of Tetrad is tested with benchmarks for deep neural networks\nsuch as LeNet and VGG16 and support vector machines. One variant of our\nframework aims at minimizing the execution time, while the other focuses on the\nmonetary cost. We observe improvements up to 6x over Trident across these\nparameters.",
          "link": "http://arxiv.org/abs/2106.02850",
          "publishedOn": "2021-06-08T02:20:23.469Z",
          "wordCount": 586,
          "title": "Tetrad: Actively Secure 4PC for Secure Training and Inference. (arXiv:2106.02850v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cimolino_G/0/1/0/all/0/1\">Gabriele Cimolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivest_F/0/1/0/all/0/1\">Francois Rivest</a>",
          "description": "Animals can quickly learn the timing of events with fixed intervals and their\nrate of acquisition does not depend on the length of the interval. In contrast,\nrecurrent neural networks that use gradient based learning have difficulty\npredicting the timing of events that depend on stimulus that occurred long ago.\nWe present the latent time-adaptive drift-diffusion model (LTDDM), an extension\nto the time-adaptive drift-diffusion model (TDDM), a model for animal learning\nof timing that exhibits behavioural properties consistent with experimental\ndata from animals. The performance of LTDDM is compared to that of a state of\nthe art long short-term memory (LSTM) recurrent neural network across three\ntiming tasks. Differences in the relative performance of these two models is\ndiscussed and it is shown how LTDDM can learn these events time series orders\nof magnitude faster than recurrent neural networks.",
          "link": "http://arxiv.org/abs/2106.02742",
          "publishedOn": "2021-06-08T02:20:23.458Z",
          "wordCount": 553,
          "title": "Latent Time-Adaptive Drift-Diffusion Model. (arXiv:2106.02742v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmidgall_S/0/1/0/all/0/1\">Samuel Schmidgall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashkanazy_J/0/1/0/all/0/1\">Julia Ashkanazy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawson_W/0/1/0/all/0/1\">Wallace Lawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1\">Joe Hays</a>",
          "description": "The adaptive changes in synaptic efficacy that occur between spiking neurons\nhave been demonstrated to play a critical role in learning for biological\nneural networks. Despite this source of inspiration, many learning focused\napplications using Spiking Neural Networks (SNNs) retain static synaptic\nconnections, preventing additional learning after the initial training period.\nHere, we introduce a framework for simultaneously learning the underlying\nfixed-weights and the rules governing the dynamics of synaptic plasticity and\nneuromodulated synaptic plasticity in SNNs through gradient descent. We further\ndemonstrate the capabilities of this framework on a series of challenging\nbenchmarks, learning the parameters of several plasticity rules including BCM,\nOja's, and their respective set of neuromodulatory variants. The experimental\nresults display that SNNs augmented with differentiable plasticity are\nsufficient for solving a set of challenging temporal learning tasks that a\ntraditional SNN fails to solve, even in the presence of significant noise.\nThese networks are also shown to be capable of producing locomotion on a\nhigh-dimensional robotic learning task, where near-minimal degradation in\nperformance is observed in the presence of novel conditions not seen during the\ninitial training period.",
          "link": "http://arxiv.org/abs/2106.02681",
          "publishedOn": "2021-06-08T02:20:23.220Z",
          "wordCount": 615,
          "title": "SpikePropamine: Differentiable Plasticity in Spiking Neural Networks. (arXiv:2106.02681v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2104.09435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyoungjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1\">Myeongsu Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Bumju Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soohyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Ki Hean Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Sunghoe Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Volumetric imaging by fluorescence microscopy is often limited by anisotropic\nspatial resolution from inferior axial resolution compared to the lateral\nresolution. To address this problem, here we present a deep-learning-enabled\nunsupervised super-resolution technique that enhances anisotropic images in\nvolumetric fluorescence microscopy. In contrast to the existing deep learning\napproaches that require matched high-resolution target volume images, our\nmethod greatly reduces the effort to put into practice as the training of a\nnetwork requires as little as a single 3D image stack, without a priori\nknowledge of the image formation process, registration of training data, or\nseparate acquisition of target data. This is achieved based on the optimal\ntransport driven cycle-consistent generative adversarial network that learns\nfrom an unpaired matching between high-resolution 2D images in lateral image\nplane and low-resolution 2D images in the other planes. Using fluorescence\nconfocal microscopy and light-sheet microscopy, we demonstrate that the trained\nnetwork not only enhances axial resolution, but also restores suppressed visual\ndetails between the imaging planes and removes imaging artifacts.",
          "link": "http://arxiv.org/abs/2104.09435",
          "publishedOn": "2021-06-08T02:20:23.214Z",
          "wordCount": 651,
          "title": "Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1\">Srikanth Ronanki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Neural Language Models (NLM), when trained and evaluated with context\nspanning multiple utterances, have been shown to consistently outperform both\nconventional n-gram language models and NLMs that use limited context. In this\npaper, we investigate various techniques to incorporate turn based context\nhistory into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent\nbased NLMs, we explore context carry over mechanism and feature based\naugmentation, where we incorporate other forms of contextual information such\nas bot response and system dialogue acts as classified by a Natural Language\nUnderstanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem\nwith contextual NLM, we propose the use of attention layer over lexical\nmetadata to improve feature based augmentation. Additionally, we adapt our\ncontextual NLM towards user provided on-the-fly speech patterns by leveraging\nencodings from a large pre-trained masked language model and performing fusion\nwith a Transformer-XL based NLM. We test our proposed models using N-best\nrescoring of ASR hypotheses of task-oriented dialogues and also evaluate on\ndownstream NLU tasks such as intent classification and slot labeling. The best\nperforming model shows a relative WER between 1.6% and 9.1% and a slot labeling\nF1 score improvement of 4% over non-contextual baselines.",
          "link": "http://arxiv.org/abs/2104.11070",
          "publishedOn": "2021-06-08T02:20:23.207Z",
          "wordCount": 676,
          "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toreini_E/0/1/0/all/0/1\">Ehsan Toreini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1\">Mhairi Aitken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coopamootoo_K/0/1/0/all/0/1\">Kovila P. L. Coopamootoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_K/0/1/0/all/0/1\">Karen Elliott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelaya_V/0/1/0/all/0/1\">Vladimiro Gonzalez Zelaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Missier_P/0/1/0/all/0/1\">Paolo Missier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1\">Magdalene Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moorsel_A/0/1/0/all/0/1\">Aad van Moorsel</a>",
          "description": "Concerns about the societal impact of AI-based services and systems has\nencouraged governments and other organisations around the world to propose AI\npolicy frameworks to address fairness, accountability, transparency and related\ntopics. To achieve the objectives of these frameworks, the data and software\nengineers who build machine-learning systems require knowledge about a variety\nof relevant supporting tools and techniques. In this paper we provide an\noverview of technologies that support building trustworthy machine learning\nsystems, i.e., systems whose properties justify that people place trust in\nthem. We argue that four categories of system properties are instrumental in\nachieving the policy objectives, namely fairness, explainability, auditability\nand safety & security (FEAS). We discuss how these properties need to be\nconsidered across all stages of the machine learning life cycle, from data\ncollection through run-time model inference. As a consequence, we survey in\nthis paper the main technologies with respect to all four of the FEAS\nproperties, for data-centric as well as model-centric stages of the machine\nlearning system life cycle. We conclude with an identification of open research\nproblems, with a particular focus on the connection between trustworthy machine\nlearning technologies and their implications for individuals and society.",
          "link": "http://arxiv.org/abs/2007.08911",
          "publishedOn": "2021-06-08T02:20:23.184Z",
          "wordCount": 702,
          "title": "Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Context. (arXiv:2007.08911v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Heng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiayuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "How cooperation emerges is a long-standing and interdisciplinary problem.\nGame-theoretical studies on social dilemmas reveal that altruistic incentives\nare critical to the emergence of cooperation but their analyses are limited to\nstateless games. For more realistic scenarios, multi-agent reinforcement\nlearning has been used to study sequential social dilemmas (SSDs). Recent works\nshow that learning to incentivize other agents can promote cooperation in SSDs.\nHowever, we find that, with these incentivizing mechanisms, the team\ncooperation level does not converge and regularly oscillates between\ncooperation and defection during learning. We show that a second-order social\ndilemma resulting from the incentive mechanisms is the main reason for such\nfragile cooperation. We formally analyze the dynamics of second-order social\ndilemmas and find that a typical tendency of humans, called homophily, provides\na promising solution. We propose a novel learning framework to encourage\nhomophilic incentives and show that it achieves stable cooperation in both SSDs\nof public goods and tragedy of the commons.",
          "link": "http://arxiv.org/abs/2104.11455",
          "publishedOn": "2021-06-08T02:20:23.178Z",
          "wordCount": 634,
          "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence via Multi-Agent RL. (arXiv:2104.11455v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.07255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1\">Amit Boyarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1\">Sanketh Vedula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>",
          "description": "Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.",
          "link": "http://arxiv.org/abs/1911.07255",
          "publishedOn": "2021-06-08T02:20:23.171Z",
          "wordCount": 615,
          "title": "Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1\">Andrey Kolobov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1\">Adith Swaminathan</a>",
          "description": "We provide a framework for accelerating reinforcement learning (RL)\nalgorithms by heuristics constructed from domain knowledge or offline data.\nTabula rasa RL algorithms require environment interactions or computation that\nscales with the horizon of the sequential decision-making task. Using our\nframework, we show how heuristic-guided RL induces a much shorter-horizon\nsubproblem that provably solves the original task. Our framework can be viewed\nas a horizon-based regularization for controlling bias and variance in RL under\na finite interaction budget. On the theoretical side, we characterize\nproperties of a good heuristic and its impact on RL acceleration. In\nparticular, we introduce the novel concept of an \"improvable heuristic\" -- a\nheuristic that allows an RL agent to extrapolate beyond its prior knowledge. On\nthe empirical side, we instantiate our framework to accelerate several\nstate-of-the-art algorithms in simulated robotic control tasks and procedurally\ngenerated games. Our framework complements the rich literature on warm-starting\nRL with expert demonstrations or exploratory datasets, and introduces a\nprincipled method for injecting prior knowledge into RL.",
          "link": "http://arxiv.org/abs/2106.02757",
          "publishedOn": "2021-06-08T02:20:23.164Z",
          "wordCount": 584,
          "title": "Heuristic-Guided Reinforcement Learning. (arXiv:2106.02757v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09050",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Strypsteen_T/0/1/0/all/0/1\">Thomas Strypsteen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bertrand_A/0/1/0/all/0/1\">Alexander Bertrand</a>",
          "description": "Many electroencephalography (EEG) applications rely on channel selection\nmethods to remove the least informative channels, e.g., to reduce the amount of\nelectrodes to be mounted, to decrease the computational load, or to reduce\noverfitting effects and improve performance. Wrapper-based channel selection\nmethods aim to match the channel selection step to the target model, yet they\nrequire to re-train the model multiple times on different candidate channel\nsubsets, which often leads to an unacceptably high computational cost,\nespecially when said model is a (deep) neural network. To alleviate this, we\npropose a framework to embed the EEG channel selection in the neural network\nitself to jointly learn the network weights and optimal channels in an\nend-to-end manner by traditional backpropagation algorithms. We deal with the\ndiscrete nature of this new optimization problem by employing continuous\nrelaxations of the discrete channel selection parameters based on the\nGumbel-softmax trick. We also propose a regularization method that discourages\nselecting channels more than once. This generic approach is evaluated on two\ndifferent EEG tasks: motor imagery brain-computer interfaces and auditory\nattention decoding. The results demonstrate that our framework is generally\napplicable, while being competitive with state-of-the art EEG channel selection\nmethods, tailored to these tasks.",
          "link": "http://arxiv.org/abs/2102.09050",
          "publishedOn": "2021-06-08T02:20:23.158Z",
          "wordCount": 664,
          "title": "End-to-end learnable EEG channel selection for deep neural networks with Gumbel-softmax. (arXiv:2102.09050v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Subhrajit Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blum_R/0/1/0/all/0/1\">Rick S. Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadler_B/0/1/0/all/0/1\">Brian M. Sadler</a>",
          "description": "Graph neural networks (GNNs) are processing architectures that exploit graph\nstructural information to model representations from network data. Despite\ntheir success, GNNs suffer from sub-optimal generalization performance given\nlimited training data, referred to as over-fitting. This paper proposes\nTopology Adaptive Edge Dropping (TADropEdge) method as an adaptive data\naugmentation technique to improve generalization performance and learn robust\nGNN models. We start by explicitly analyzing how random edge dropping increases\nthe data diversity during training, while indicating i.i.d. edge dropping does\nnot account for graph structural information and could result in noisy\naugmented data degrading performance. To overcome this issue, we consider graph\nconnectivity as the key property that captures graph topology. TADropEdge\nincorporates this factor into random edge dropping such that the edge-dropped\nsubgraphs maintain similar topology as the underlying graph, yielding more\nsatisfactory data augmentation. In particular, TADropEdge first leverages the\ngraph spectrum to assign proper weights to graph edges, which represent their\ncriticality for establishing the graph connectivity. It then normalizes the\nedge weights and drops graph edges adaptively based on their normalized\nweights. Besides improving generalization performance, TADropEdge reduces\nvariance for efficient training and can be applied as a generic method modular\nto different GNN models. Intensive experiments on real-life and synthetic\ndatasets corroborate theory and verify the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.02892",
          "publishedOn": "2021-06-08T02:20:23.139Z",
          "wordCount": 655,
          "title": "Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping. (arXiv:2106.02892v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03584",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Scheinker_A/0/1/0/all/0/1\">Alexander Scheinker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cropp_F/0/1/0/all/0/1\">Frederick Cropp</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paiagua_S/0/1/0/all/0/1\">Sergio Paiagua</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Filippetto_D/0/1/0/all/0/1\">Daniele Filippetto</a>",
          "description": "Powerful deep learning tools, such as convolutional neural networks (CNN),\nare able to learn the input-output relationships of large complicated systems\ndirectly from data. Encoder-decoder deep CNNs are able to extract features\ndirectly from images, mix them with scalar inputs within a general\nlow-dimensional latent space, and then generate new complex 2D outputs which\nrepresent complex physical phenomenon. One important challenge faced by deep\nlearning methods is large non-stationary systems whose characteristics change\nquickly with time for which re-training is not feasible. In this paper we\npresent a method for adaptive tuning of the low-dimensional latent space of\ndeep encoder-decoder style CNNs based on real-time feedback to quickly\ncompensate for unknown and fast distribution shifts. We demonstrate our\napproach for predicting the properties of a time-varying charged particle beam\nin a particle accelerator whose components (accelerating electric fields and\nfocusing magnetic fields) are also quickly changing with time.",
          "link": "http://arxiv.org/abs/2105.03584",
          "publishedOn": "2021-06-08T02:20:23.132Z",
          "wordCount": 616,
          "title": "Adaptive Latent Space Tuning for Non-Stationary Distributions. (arXiv:2105.03584v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Cross domain recommender system constitutes a powerful method to tackle the\ncold-start and sparsity problem by aggregating and transferring user\npreferences across multiple category domains. Therefore, it has great potential\nto improve click-through-rate prediction performance in online commerce\nplatforms having many domains of products. While several cross domain\nsequential recommendation models have been proposed to leverage information\nfrom a source domain to improve CTR predictions in a target domain, they did\nnot take into account bidirectional latent relations of user preferences across\nsource-target domain pairs. As such, they cannot provide enhanced cross-domain\nCTR predictions for both domains simultaneously. In this paper, we propose a\nnovel approach to cross-domain sequential recommendations based on the dual\nlearning mechanism that simultaneously transfers information between two\nrelated domains in an iterative manner until the learning process stabilizes.\nIn particular, the proposed Dual Attentive Sequential Learning (DASL) model\nconsists of two novel components Dual Embedding and Dual Attention, which\njointly establish the two-stage learning process: we first construct dual\nlatent embeddings that extract user preferences in both domains simultaneously,\nand subsequently provide cross-domain recommendations by matching the extracted\nlatent embeddings with candidate items through dual-attention learning\nmechanism. We conduct extensive offline experiments on three real-world\ndatasets to demonstrate the superiority of our proposed model, which\nsignificantly and consistently outperforms several state-of-the-art baselines\nacross all experimental settings. We also conduct an online A/B test at a major\nvideo streaming platform Alibaba-Youku, where our proposed model significantly\nimproves business performance over the latest production system in the company.",
          "link": "http://arxiv.org/abs/2106.02768",
          "publishedOn": "2021-06-08T02:20:23.125Z",
          "wordCount": 686,
          "title": "Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1\">Travers Rhodes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "There have been many recent advances in representation learning; however,\nunsupervised representation learning can still struggle with model\nidentification issues. Variational Auto-Encoders (VAEs) and their extensions\nsuch as $\\beta$-VAEs have been shown to locally align latent variables with PCA\ndirections, which can help to improve model disentanglement under some\nconditions. Borrowing inspiration from Independent Component Analysis (ICA) and\nsparse coding, we propose applying an $L_1$ loss to the VAE's generative\nJacobian during training to encourage local latent variable alignment with\nindependent factors of variation in the data. We demonstrate our results on a\nvariety of datasets, giving qualitative and quantitative results using\ninformation theoretic and modularity measures that show our added $L_1$ cost\nencourages local axis alignment of the latent representation with individual\nfactors of variation.",
          "link": "http://arxiv.org/abs/2106.02923",
          "publishedOn": "2021-06-08T02:20:23.112Z",
          "wordCount": 560,
          "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02901",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1\">Jingjing Si</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_Y/0/1/0/all/0/1\">Yinbo Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Enemali_G/0/1/0/all/0/1\">Godwin Enemali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>",
          "description": "As an in situ combustion diagnostic tool, Tunable Diode Laser Absorption\nSpectroscopy (TDLAS) tomography has been widely used for imaging of\ntwo-dimensional temperature distributions in reactive flows. Compared with the\ncomputational tomographic algorithms, Convolutional Neural Networks (CNNs) have\nbeen proofed to be more robust and accurate for image reconstruction,\nparticularly in case of limited access of laser beams in the Region of Interest\n(RoI). In practice, flame in the RoI that requires to be reconstructed with\ngood spatial resolution is commonly surrounded by low-temperature background.\nAlthough the background is not of high interest, spectroscopic absorption still\nexists due to heat dissipation and gas convection. Therefore, we propose a\nPseudo-Inversed CNN (PI-CNN) for hierarchical temperature imaging that (a) uses\nefficiently the training and learning resources for temperature imaging in the\nRoI with good spatial resolution, and (b) reconstructs the less spatially\nresolved background temperature by adequately addressing the integrity of the\nspectroscopic absorption model. In comparison with the traditional CNN, the\nnewly introduced pseudo inversion of the RoI sensitivity matrix is more\npenetrating for revealing the inherent correlation between the projection data\nand the RoI to be reconstructed, thus prioritising the temperature imaging in\nthe RoI with high accuracy and high computational efficiency. In this paper,\nthe proposed algorithm was validated by both numerical simulation and lab-scale\nexperiment, indicating good agreement between the phantoms and the\nhigh-fidelity reconstructions.",
          "link": "http://arxiv.org/abs/2106.02901",
          "publishedOn": "2021-06-08T02:20:23.105Z",
          "wordCount": 686,
          "title": "Hierarchical Temperature Imaging Using Pseudo-Inversed Convolutional Neural Network Aided TDLAS Tomography. (arXiv:2106.02901v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02676",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Berlyand_L/0/1/0/all/0/1\">Leonid Berlyand</a>, <a href=\"http://arxiv.org/find/math/1/au:+Creese_R/0/1/0/all/0/1\">Robert Creese</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jabin_P/0/1/0/all/0/1\">Pierre-Emmanuel Jabin</a>",
          "description": "We introduce two-scale loss functions for use in various gradient descent\nalgorithms applied to classification problems via deep neural networks. This\nnew method is generic in the sense that it can be applied to a wide range of\nmachine learning architectures, from deep neural networks to support vector\nmachines for example. These two-scale loss functions allow to focus the\ntraining onto objects in the training set which are not well classified. This\nleads to an increase in several measures of performance for\nappropriately-defined two-scale loss functions with respect to the more\nclassical cross-entropy when tested on traditional deep neural networks on the\nMNIST, CIFAR10, and CIFAR100 data-sets.",
          "link": "http://arxiv.org/abs/2106.02676",
          "publishedOn": "2021-06-08T02:20:23.083Z",
          "wordCount": 549,
          "title": "A novel multi-scale loss function for classification problems in machine learning. (arXiv:2106.02676v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Altschuler_J/0/1/0/all/0/1\">Jason M. Altschuler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parrilo_P/0/1/0/all/0/1\">Pablo A. Parrilo</a>",
          "description": "Low-rank approximation of kernels is a fundamental mathematical problem with\nwidespread algorithmic applications. Often the kernel is restricted to an\nalgebraic variety, e.g., in problems involving sparse or low-rank data. We show\nthat significantly better approximations are obtainable in this setting: the\nrank required to achieve a given error depends on the variety's dimension\nrather than the ambient dimension, which is typically much larger. This is true\nin both high-precision and high-dimensional regimes. Our results are presented\nfor smooth isotropic kernels, the predominant class of kernels used in\napplications. Our main technical insight is to approximate smooth kernels by\npolynomial kernels, and leverage two key properties of polynomial kernels that\nhold when they are restricted to a variety. First, their ranks decrease\nexponentially in the variety's co-dimension. Second, their maximum values are\ngoverned by their values over a small set of points. Together, our results\nprovide a general approach for exploiting (approximate) \"algebraic structure\"\nin datasets in order to efficiently solve large-scale data science problems.",
          "link": "http://arxiv.org/abs/2106.02755",
          "publishedOn": "2021-06-08T02:20:23.077Z",
          "wordCount": 592,
          "title": "Kernel approximation on algebraic varieties. (arXiv:2106.02755v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.10115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1\">Florian Stelzer</a> (1, 2 and 4), <a href=\"http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1\">Andr&#xe9; R&#xf6;hm</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1\">Raul Vicente</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1\">Ingo Fischer</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1\">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Instituto de F&#xed;sica Interdisciplinar y Sistemas Complejos, IFISC (UIB-CSIC), Spain, (4) Institute of Computer Science, University of Tartu, Estonia)",
          "description": "Deep neural networks are among the most widely applied machine learning tools\nshowing outstanding performance in a broad range of tasks. We present a method\nfor folding a deep neural network of arbitrary size into a single neuron with\nmultiple time-delayed feedback loops. This single-neuron deep neural network\ncomprises only a single nonlinearity and appropriately adjusted modulations of\nthe feedback signals. The network states emerge in time as a temporal unfolding\nof the neuron's dynamics. By adjusting the feedback-modulation within the\nloops, we adapt the network's connection weights. These connection weights are\ndetermined via a back-propagation algorithm, where both the delay-induced and\nlocal network connections must be taken into account. Our approach can fully\nrepresent standard Deep Neural Networks (DNN), encompasses sparse DNNs, and\nextends the DNN concept toward dynamical systems implementations. The new\nmethod, which we call Folded-in-time DNN (Fit-DNN), exhibits promising\nperformance in a set of benchmark tasks.",
          "link": "http://arxiv.org/abs/2011.10115",
          "publishedOn": "2021-06-08T02:20:23.071Z",
          "wordCount": 666,
          "title": "Deep Neural Networks using a Single Neuron: Folded-in-Time Architecture using Feedback-Modulated Delay Loops. (arXiv:2011.10115v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dinghuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yilun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Can models with particular structure avoid being biased towards spurious\ncorrelation in out-of-distribution (OOD) generalization? Peters et al. (2016)\nprovides a positive answer for linear cases. In this paper, we use a functional\nmodular probing method to analyze deep model structures under OOD setting. We\ndemonstrate that even in biased models (which focus on spurious correlation)\nthere still exist unbiased functional subnetworks. Furthermore, we articulate\nand demonstrate the functional lottery ticket hypothesis: full network contains\na subnetwork that can achieve better OOD performance. We then propose Modular\nRisk Minimization to solve the subnetwork selection problem. Our algorithm\nlearns the subnetwork structure from a given dataset, and can be combined with\nany other OOD regularization methods. Experiments on various OOD generalization\ntasks corroborate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2106.02890",
          "publishedOn": "2021-06-08T02:20:23.061Z",
          "wordCount": 567,
          "title": "Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?. (arXiv:2106.02890v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aimin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "In this paper, we propose a framework of filter-based ensemble of deep\nneuralnetworks (DNNs) to defend against adversarial attacks. The framework\nbuilds an ensemble of sub-models -- DNNs with differentiated preprocessing\nfilters. From the theoretical perspective of DNN robustness, we argue that\nunder the assumption of high quality of the filters, the weaker the\ncorrelations of the sensitivity of the filters are, the more robust the\nensemble model tends to be, and this is corroborated by the experiments of\ntransfer-based attacks. Correspondingly, we propose a principle that chooses\nthe specific filters with smaller Pearson correlation coefficients, which\nensures the diversity of the inputs received by DNNs, as well as the\neffectiveness of the entire framework against attacks. Our ensemble models are\nmore robust than those constructed by previous defense methods like adversarial\ntraining, and even competitive with the classical ensemble of adversarial\ntrained DNNs under adversarial attacks when the attacking radius is large.",
          "link": "http://arxiv.org/abs/2106.02867",
          "publishedOn": "2021-06-08T02:20:23.056Z",
          "wordCount": 588,
          "title": "Ensemble Defense with Data Diversity: Weak Correlation Implies Strong Robustness. (arXiv:2106.02867v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1\">Muhammed O. Sayin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1\">David S. Leslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1\">Tamer Basar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "We study multi-agent reinforcement learning (MARL) in infinite-horizon\ndiscounted zero-sum Markov games. We focus on the practical but challenging\nsetting of decentralized MARL, where agents make decisions without coordination\nby a centralized controller, but only based on their own payoffs and local\nactions executed. The agents need not observe the opponent's actions or\npayoffs, possibly being even oblivious to the presence of the opponent, nor be\naware of the zero-sum structure of the underlying game, a setting also referred\nto as radically uncoupled in the literature of learning in games. In this\npaper, we develop for the first time a radically uncoupled Q-learning dynamics\nthat is both rational and convergent: the learning dynamics converges to the\nbest response to the opponent's strategy when the opponent follows an\nasymptotically stationary strategy; the value function estimates converge to\nthe payoffs at a Nash equilibrium when both agents adopt the dynamics. The key\nchallenge in this decentralized setting is the non-stationarity of the learning\nenvironment from an agent's perspective, since both her own payoffs and the\nsystem evolution depend on the actions of other agents, and each agent adapts\ntheir policies simultaneously and independently. To address this issue, we\ndevelop a two-timescale learning dynamics where each agent updates her local\nQ-function and value function estimates concurrently, with the latter happening\nat a slower timescale.",
          "link": "http://arxiv.org/abs/2106.02748",
          "publishedOn": "2021-06-08T02:20:23.040Z",
          "wordCount": 665,
          "title": "Decentralized Q-Learning in Zero-sum Markov Games. (arXiv:2106.02748v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yongduo Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuxi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "With graphs rapidly growing in size and deeper graph neural networks (GNNs)\nemerging, the training and inference of GNNs become increasingly expensive.\nExisting network weight pruning algorithms cannot address the main space and\ncomputational bottleneck in GNNs, caused by the size and connectivity of the\ngraph. To this end, this paper first presents a unified GNN sparsification\n(UGS) framework that simultaneously prunes the graph adjacency matrix and the\nmodel weights, for effectively accelerating GNN inference on large-scale\ngraphs. Leveraging this new tool, we further generalize the recently popular\nlottery ticket hypothesis to GNNs for the first time, by defining a graph\nlottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,\nwhich can be jointly identified from the original GNN and the full dense graph\nby iteratively applying UGS. Like its counterpart in convolutional neural\nnetworks, GLT can be trained in isolation to match the performance of training\nwith the full model and graph, and can be drawn from both randomly initialized\nand self-supervised pre-trained GNNs. Our proposal has been experimentally\nverified across various GNN architectures and diverse tasks, on both\nsmall-scale graph datasets (Cora, Citeseer and PubMed), and large-scale\ndatasets from the challenging Open Graph Benchmark (OGB). Specifically, for\nnode classification, our found GLTs achieve the same accuracies with 20%~98%\nMACs saving on small graphs and 25%~85% MACs saving on large ones. For link\nprediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph\ndatasets, respectively, without compromising predictive performance. Codes\navailable at https://github.com/VITA-Group/Unified-LTH-GNN.",
          "link": "http://arxiv.org/abs/2102.06790",
          "publishedOn": "2021-06-08T02:20:23.033Z",
          "wordCount": 718,
          "title": "A Unified Lottery Ticket Hypothesis for Graph Neural Networks. (arXiv:2102.06790v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1\">Sourbh Bhadane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1\">Aaron B. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1\">Jayadev Acharya</a>",
          "description": "We consider a linear autoencoder in which the latent variables are quantized,\nor corrupted by noise, and the constraint is Schur-concave in the set of latent\nvariances. Although finding the optimal encoder/decoder pair for this setup is\na nonconvex optimization problem, we show that decomposing the source into its\nprincipal components is optimal. If the constraint is strictly Schur-concave\nand the empirical covariance matrix has only simple eigenvalues, then any\noptimal encoder/decoder must decompose the source in this way. As one\napplication, we consider a strictly Schur-concave constraint that estimates the\nnumber of bits needed to represent the latent variables under fixed-rate\nencoding, a setup that we call \\emph{Principal Bit Analysis (PBA)}. This yields\na practical, general-purpose, fixed-rate compressor that outperforms existing\nalgorithms. As a second application, we show that a prototypical\nautoencoder-based variable-rate compressor is guaranteed to decompose the\nsource into its principal components.",
          "link": "http://arxiv.org/abs/2106.02796",
          "publishedOn": "2021-06-08T02:20:23.025Z",
          "wordCount": 581,
          "title": "Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Chaoyang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceyani_E/0/1/0/all/0/1\">Emir Ceyani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Keshav Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Annavaram_M/0/1/0/all/0/1\">Murali Annavaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Graph Neural Networks (GNNs) are the first choice methods for graph machine\nlearning problems thanks to their ability to learn state-of-the-art level\nrepresentations from graph-structured data. However, centralizing a massive\namount of real-world graph data for GNN training is prohibitive due to\nuser-side privacy concerns, regulation restrictions, and commercial\ncompetition. Federated Learning is the de-facto standard for collaborative\ntraining of machine learning models over many distributed edge devices without\nthe need for centralization. Nevertheless, training graph neural networks in a\nfederated setting is vaguely defined and brings statistical and systems\nchallenges. This work proposes SpreadGNN, a novel multi-task federated training\nframework capable of operating in the presence of partial labels and absence of\na central server for the first time in the literature. SpreadGNN extends\nfederated multi-task learning to realistic serverless settings for GNNs, and\nutilizes a novel optimization algorithm with a convergence guarantee,\nDecentralized Periodic Averaging SGD (DPA-SGD), to solve decentralized\nmulti-task learning problems. We empirically demonstrate the efficacy of our\nframework on a variety of non-I.I.D. distributed graph-level molecular property\nprediction datasets with partial labels. Our results show that SpreadGNN\noutperforms GNN models trained over a central server-dependent federated\nlearning system, even in constrained topologies. The source code is publicly\navailable at https://github.com/FedML-AI/SpreadGNN",
          "link": "http://arxiv.org/abs/2106.02743",
          "publishedOn": "2021-06-08T02:20:23.019Z",
          "wordCount": 643,
          "title": "SpreadGNN: Serverless Multi-task Federated Learning for Graph Neural Networks. (arXiv:2106.02743v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1\">Will Grathwohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jacob Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Milad Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1\">Kevin Swersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>",
          "description": "Energy-Based Models (EBMs) present a flexible and appealing way to represent\nuncertainty. Despite recent advances, training EBMs on high-dimensional data\nremains a challenging problem as the state-of-the-art approaches are costly,\nunstable, and require considerable tuning and domain expertise to apply\nsuccessfully. In this work, we present a simple method for training EBMs at\nscale which uses an entropy-regularized generator to amortize the MCMC sampling\ntypically used in EBM training. We improve upon prior MCMC-based entropy\nregularization methods with a fast variational approximation. We demonstrate\nthe effectiveness of our approach by using it to train tractable likelihood\nmodels. Next, we apply our estimator to the recently proposed Joint Energy\nModel (JEM), where we match the original performance with faster and stable\ntraining. This allows us to extend JEM models to semi-supervised classification\non tabular data from a variety of continuous domains.",
          "link": "http://arxiv.org/abs/2010.04230",
          "publishedOn": "2021-06-08T02:20:23.012Z",
          "wordCount": 623,
          "title": "No MCMC for me: Amortized sampling for fast and stable training of energy-based models. (arXiv:2010.04230v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02803",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_T/0/1/0/all/0/1\">Tianxi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_C/0/1/0/all/0/1\">Can M. Le</a>",
          "description": "Networks analysis has been commonly used to study the interactions between\nunits of complex systems. One problem of particular interest is learning the\nnetwork's underlying connection pattern given a single and noisy instantiation.\nWhile many methods have been proposed to address this problem in recent years,\nthey usually assume that the true model belongs to a known class, which is not\nverifiable in most real-world applications. Consequently, network modeling\nbased on these methods either suffers from model misspecification or relies on\nadditional model selection procedures that are not well understood in theory\nand can potentially be unstable in practice. To address this difficulty, we\npropose a mixing strategy that leverages available arbitrary models to improve\ntheir individual performances. The proposed method is computationally efficient\nand almost tuning-free; thus, it can be used as an off-the-shelf method for\nnetwork modeling. We show that the proposed method performs equally well as the\noracle estimate when the true model is included as individual candidates. More\nimportantly, the method remains robust and outperforms all current estimates\neven when the models are misspecified. Extensive simulation examples are used\nto verify the advantage of the proposed mixing method. Evaluation of link\nprediction performance on 385 real-world networks from six domains also\ndemonstrates the universal competitiveness of the mixing method across multiple\ndomains.",
          "link": "http://arxiv.org/abs/2106.02803",
          "publishedOn": "2021-06-08T02:20:22.994Z",
          "wordCount": 648,
          "title": "Network Estimation by Mixing: Adaptivity and More. (arXiv:2106.02803v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nichani_E/0/1/0/all/0/1\">Eshaan Nichani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1\">Adityanarayanan Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhler_C/0/1/0/all/0/1\">Caroline Uhler</a>",
          "description": "Recent works have demonstrated that increasing model capacity through width\nin over-parameterized neural networks leads to a decrease in test risk. For\nneural networks, however, model capacity can also be increased through depth,\nyet understanding the impact of increasing depth on test risk remains an open\nquestion. In this work, we demonstrate that the test risk of over-parameterized\nconvolutional networks is a U-shaped curve (i.e. monotonically decreasing, then\nincreasing) with increasing depth. We first provide empirical evidence for this\nphenomenon via image classification experiments using both ResNets and the\nconvolutional neural tangent kernel (CNTK). We then present a novel linear\nregression framework for characterizing the impact of depth on test risk, and\nshow that increasing depth leads to a U-shaped test risk for the linear CNTK.\nIn particular, we prove that the linear CNTK corresponds to a depth-dependent\nlinear transformation on the original space and characterize properties of this\ntransformation. We then analyze over-parameterized linear regression under\narbitrary linear transformations and, in simplified settings, provably identify\nthe depths which minimize each of the bias and variance terms of the test risk.",
          "link": "http://arxiv.org/abs/2010.09610",
          "publishedOn": "2021-06-08T02:20:22.987Z",
          "wordCount": 646,
          "title": "Increasing Depth Leads to U-Shaped Test Risk in Over-parameterized Convolutional Networks. (arXiv:2010.09610v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yehui Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "This paper studies the efficiency problem for visual transformers by\nexcavating redundant calculation in given networks. The recent transformer\narchitecture has demonstrated its effectiveness for achieving excellent\nperformance on a series of computer vision tasks. However, similar to that of\nconvolutional neural networks, the huge computational cost of vision\ntransformers is still a severe issue. Considering that the attention mechanism\naggregates different patches layer-by-layer, we present a novel patch slimming\napproach that discards useless patches in a top-down paradigm. We first\nidentify the effective patches in the last layer and then use them to guide the\npatch selection process of previous layers. For each layer, the impact of a\npatch on the final output feature is approximated and patches with less impact\nwill be removed. Experimental results on benchmark datasets demonstrate that\nthe proposed method can significantly reduce the computational costs of vision\ntransformers without affecting their performances. For example, over 45% FLOPs\nof the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the\nImageNet dataset.",
          "link": "http://arxiv.org/abs/2106.02852",
          "publishedOn": "2021-06-08T02:20:22.975Z",
          "wordCount": 606,
          "title": "Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chin-Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1\">Jae Hyun Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Discrete-time diffusion-based generative models and score matching methods\nhave shown promising results in modeling high-dimensional image data. Recently,\nSong et al. (2021) show that diffusion processes that transform data into noise\ncan be reversed via learning the score function, i.e. the gradient of the\nlog-density of the perturbed data. They propose to plug the learned score\nfunction into an inverse formula to define a generative diffusion process.\nDespite the empirical success, a theoretical underpinning of this procedure is\nstill lacking. In this work, we approach the (continuous-time) generative\ndiffusion directly and derive a variational framework for likelihood\nestimation, which includes continuous-time normalizing flows as a special case,\nand can be seen as an infinitely deep variational autoencoder. Under this\nframework, we show that minimizing the score-matching loss is equivalent to\nmaximizing a lower bound of the likelihood of the plug-in reverse SDE proposed\nby Song et al. (2021), bridging the theoretical gap.",
          "link": "http://arxiv.org/abs/2106.02808",
          "publishedOn": "2021-06-08T02:20:22.968Z",
          "wordCount": 579,
          "title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching. (arXiv:2106.02808v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woodworth_B/0/1/0/all/0/1\">Blake Woodworth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1\">Nathan Srebro</a>",
          "description": "We present and analyze an algorithm for optimizing smooth and convex or\nstrongly convex objectives using minibatch stochastic gradient estimates. The\nalgorithm is optimal with respect to its dependence on both the minibatch size\nand minimum expected loss simultaneously. This improves over the optimal method\nof Lan (2012), which is insensitive to the minimum expected loss; over the\noptimistic acceleration of Cotter et al. (2011), which has suboptimal\ndependence on the minibatch size; and over the algorithm of Liu and Belkin\n(2018), which is limited to least squares problems and is also similarly\nsuboptimal with respect to the minibatch size. Applied to interpolation\nlearning, the improvement over Cotter et al. and Liu and Belkin translates to a\nlinear, rather than square-root, parallelization speedup.",
          "link": "http://arxiv.org/abs/2106.02720",
          "publishedOn": "2021-06-08T02:20:22.953Z",
          "wordCount": 559,
          "title": "An Even More Optimal Stochastic Optimization Algorithm: Minibatching and Interpolation Learning. (arXiv:2106.02720v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:22.946Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08115",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1\">P. Nagabhushan</a>",
          "description": "The infection of respiratory coronavirus disease 2019 (COVID-19) starts with\nthe upper respiratory tract and as the virus grows, the infection can progress\nto lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is\nreverse transcription polymerase chain reaction (RT-PCR), which is less\nsensitive during early stages; especially if the patient is asymptomatic, which\nmay further cause more severe pneumonia. In this context, several deep learning\nmodels have been proposed to identify pulmonary infections using publicly\navailable chest X-ray (CXR) image datasets for early diagnosis, better\ntreatment and quick cure. In these datasets, presence of less number of\nCOVID-19 positive samples compared to other classes (normal, pneumonia and\nTuberculosis) raises the challenge for unbiased learning of deep learning\nmodels. All deep learning models opted class balancing techniques to solve this\nissue; which however should be avoided in any medical diagnosis process.\nMoreover, the deep learning models are also data hungry and need massive\ncomputation resources. Therefore for quicker diagnosis, this research proposes\na novel pinball loss function based one-class support vector machine\n(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples\nwith objectives to maximize the learning efficiency and to minimize the false\npredictions. The performance of the proposed model is compared with\nconventional OCSVM and existing deep learning models, and the experimental\nresults prove that the proposed model outperformed over state-of-the-art\nmethods. To validate the robustness of the proposed model, experiments are also\nperformed with noisy CXR images and UCI benchmark datasets.",
          "link": "http://arxiv.org/abs/2010.08115",
          "publishedOn": "2021-06-08T02:20:22.935Z",
          "wordCount": 759,
          "title": "Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanlin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_G/0/1/0/all/0/1\">George Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiyao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dapeng Wu</a>",
          "description": "Current federated learning algorithms take tens of communication rounds\ntransmitting unwieldy model weights under ideal circumstances and hundreds when\ndata is poorly distributed. Inspired by recent work on dataset distillation and\ndistributed one-shot learning, we propose Distilled One-Shot Federated Learning\n(DOSFL) to significantly reduce the communication cost while achieving\ncomparable performance. In just one round, each client distills their private\ndataset, sends the synthetic data (e.g. images or sentences) to the server, and\ncollectively trains a global model. The distilled data look like noise and are\nonly useful to the specific model weights, i.e., become useless after the model\nupdates. With this weight-less and gradient-less design, the total\ncommunication cost of DOSFL is up to three orders of magnitude less than FedAvg\nwhile preserving between 93% to 99% performance of a centralized counterpart.\nAfterwards, clients could switch to traditional methods such as FedAvg to\nfinetune the last few percent to fit personalized local models with local\ndatasets. Through comprehensive experiments, we show the accuracy and\ncommunication performance of DOSFL on both vision and language tasks with\ndifferent models including CNN, LSTM, Transformer, etc. We demonstrate that an\neavesdropping attacker cannot properly train a good model using the leaked\ndistilled data, without knowing the initial model weights. DOSFL serves as an\ninexpensive method to quickly converge on a performant pre-trained model with\nless than 0.1% communication cost of traditional methods.",
          "link": "http://arxiv.org/abs/2009.07999",
          "publishedOn": "2021-06-08T02:20:22.918Z",
          "wordCount": 693,
          "title": "Distilled One-Shot Federated Learning. (arXiv:2009.07999v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1\">Donald Goldfarb</a>",
          "description": "Despite the predominant use of first-order methods for training deep learning\nmodels, second-order methods, and in particular, natural gradient methods,\nremain of interest because of their potential for accelerating training through\nthe use of curvature information. Several methods with non-diagonal\npreconditioning matrices, including KFAC and Shampoo, have been proposed and\nshown to be effective. Based on the so-called tensor normal (TN) distribution,\nwe propose and analyze a brand new approximate natural gradient method, Tensor\nNormal Training (TNT), which like Shampoo, only requires knowledge on the shape\nof the training parameters. By approximating the probabilistically based Fisher\nmatrix, as opposed to the empirical Fisher matrix, our method uses the\nlayer-wise covariance of the sampling based gradient as the pre-conditioning\nmatrix. Moreover, the assumption that the sampling-based (tensor) gradient\nfollows a TN distribution, ensures that its covariance has a Kronecker\nseparable structure, which leads to a tractable approximation to the Fisher\nmatrix. Consequently, TNT's memory requirements and per-iteration computational\ncosts are only slightly higher than those for first-order methods. In our\nexperiments, TNT exhibited superior optimization performance to KFAC and\nShampoo, and to state-of-the-art first-order methods. Moreover, TNT\ndemonstrated its ability to generalize as well as these first-order methods,\nusing fewer epochs.",
          "link": "http://arxiv.org/abs/2106.02925",
          "publishedOn": "2021-06-08T02:20:22.909Z",
          "wordCount": 618,
          "title": "Tensor Normal Training for Deep Learning Models. (arXiv:2106.02925v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bronzino_F/0/1/0/all/0/1\">Francesco Bronzino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_P/0/1/0/all/0/1\">Paul Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayoubi_S/0/1/0/all/0/1\">Sara Ayoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyojoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teixeira_R/0/1/0/all/0/1\">Renata Teixeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1\">Nick Feamster</a>",
          "description": "Network management often relies on machine learning to make predictions about\nperformance and security from network traffic. Often, the representation of the\ntraffic is as important as the choice of the model. The features that the model\nrelies on, and the representation of those features, ultimately determine model\naccuracy, as well as where and whether the model can be deployed in practice.\nThus, the design and evaluation of these models ultimately requires\nunderstanding not only model accuracy but also the systems costs associated\nwith deploying the model in an operational network. Towards this goal, this\npaper develops a new framework and system that enables a joint evaluation of\nboth the conventional notions of machine learning performance (e.g., model\naccuracy) and the systems-level costs of different representations of network\ntraffic. We highlight these two dimensions for two practical network management\ntasks, video streaming quality inference and malware detection, to demonstrate\nthe importance of exploring different representations to find the appropriate\noperating point. We demonstrate the benefit of exploring a range of\nrepresentations of network traffic and present Traffic Refinery, a\nproof-of-concept implementation that both monitors network traffic at 10 Gbps\nand transforms traffic in real time to produce a variety of feature\nrepresentations for machine learning. Traffic Refinery both highlights this\ndesign space and makes it possible to explore different representations for\nlearning, balancing systems costs related to feature extraction and model\ntraining against model accuracy.",
          "link": "http://arxiv.org/abs/2010.14605",
          "publishedOn": "2021-06-08T02:20:22.898Z",
          "wordCount": 716,
          "title": "Traffic Refinery: Cost-Aware Data Representation for Machine Learning on Network Traffic. (arXiv:2010.14605v3 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08924",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Towards developing effective and efficient brain-computer interface (BCI)\nsystems, precise decoding of brain activity measured by electroencephalogram\n(EEG), is highly demanded. Traditional works classify EEG signals without\nconsidering the topological relationship among electrodes. However,\nneuroscience research has increasingly emphasized network patterns of brain\ndynamics. Thus, the Euclidean structure of electrodes might not adequately\nreflect the interaction between signals. To fill the gap, a novel deep learning\nframework based on the graph convolutional neural networks (GCNs) was presented\nto enhance the decoding performance of raw EEG signals during different types\nof motor imagery (MI) tasks while cooperating with the functional topological\nrelationship of electrodes. Based on the absolute Pearson's matrix of overall\nsignals, the graph Laplacian of EEG electrodes was built up. The GCNs-Net\nconstructed by graph convolutional layers learns the generalized features. The\nfollowed pooling layers reduce dimensionality, and the fully-connected softmax\nlayer derives the final prediction. The introduced approach has been shown to\nconverge for both personalized and group-wise predictions. It has achieved the\nhighest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and\n80.89% (High Gamma Dataset), at the subject and group level, respectively,\ncompared with existing studies, which suggests adaptability and robustness to\nindividual variability. Moreover, the performance was stably reproducible among\nrepetitive experiments for cross-validation. To conclude, the GCNs-Net filters\nEEG signals based on the functional topological relationship, which manages to\ndecode relevant features for brain motor imagery.",
          "link": "http://arxiv.org/abs/2006.08924",
          "publishedOn": "2021-06-08T02:20:22.781Z",
          "wordCount": 700,
          "title": "GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals. (arXiv:2006.08924v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.14268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Lei Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1\">Morten Goodwin</a>",
          "description": "The Tsetlin Machine (TM) is a recent machine learning algorithm with several\ndistinct properties, such as interpretability, simplicity, and\nhardware-friendliness. Although numerous empirical evaluations report on its\nperformance, the mathematical analysis of its convergence is still open. In\nthis article, we analyze the convergence of the TM with only one clause\ninvolved for classification. More specifically, we examine two basic logical\noperators, namely, the \"IDENTITY\"- and \"NOT\" operators. Our analysis reveals\nthat the TM, with just one clause, can converge correctly to the intended\nlogical operator, learning from training data over an infinite time horizon.\nBesides, it can capture arbitrarily rare patterns and select the most accurate\none when two candidate patterns are incompatible, by configuring a granularity\nparameter. The analysis of the convergence of the two basic operators lays the\nfoundation for analyzing other logical operators. These analyses altogether,\nfrom a mathematical perspective, provide new insights on why TMs have obtained\nstate-of-the-art performance on several pattern recognition problems.",
          "link": "http://arxiv.org/abs/2007.14268",
          "publishedOn": "2021-06-08T02:20:22.770Z",
          "wordCount": 632,
          "title": "On the Convergence of Tsetlin Machines for the IDENTITY- and NOT Operators. (arXiv:2007.14268v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1\">Safa Cicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We present a method for inferring dense depth maps from images and sparse\ndepth measurements by leveraging synthetic data to learn the association of\nsparse point clouds with dense natural shapes, and using the image as evidence\nto validate the predicted depth map. Our learned prior for natural shapes uses\nonly sparse depth as input, not images, so the method is not affected by the\ncovariate shift when attempting to transfer learned models from synthetic data\nto real ones. This allows us to use abundant synthetic data with ground truth\nto learn the most difficult component of the reconstruction process, which is\ntopology estimation, and use the image to refine the prediction based on\nphotometric evidence. Our approach uses fewer parameters than previous methods,\nyet, achieves the state of the art on both indoor and outdoor benchmark\ndatasets. Code available at:\nhttps://github.com/alexklwong/learning-topology-synthetic-data.",
          "link": "http://arxiv.org/abs/2106.02994",
          "publishedOn": "2021-06-08T02:20:22.729Z",
          "wordCount": 580,
          "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yuan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Luchan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yang Xiang</a>",
          "description": "Pruning is a model compression method that removes redundant parameters in\ndeep neural networks (DNNs) while maintaining accuracy. Most available filter\npruning methods require complex treatments such as iterative pruning, features\nstatistics/ranking, or additional optimization designs in the training process.\nIn this paper, we propose a simple and effective regularization strategy from a\nnew perspective of evolution of features, which we call feature flow\nregularization (FFR), for improving structured sparsity and filter pruning in\nDNNs. Specifically, FFR imposes controls on the gradient and curvature of\nfeature flow along the neural network, which implicitly increases the sparsity\nof the parameters. The principle behind FFR is that coherent and smooth\nevolution of features will lead to an efficient network that avoids redundant\nparameters. The high structured sparsity obtained from FFR enables us to prune\nfilters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and\nTiny ImageNet datasets demonstrate that FFR can significantly improve both\nunstructured and structured sparsity. Our pruning results in terms of reduction\nof parameters and FLOPs are comparable to or even better than those of\nstate-of-the-art pruning methods.",
          "link": "http://arxiv.org/abs/2106.02914",
          "publishedOn": "2021-06-08T02:20:22.703Z",
          "wordCount": 616,
          "title": "Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cetin_E/0/1/0/all/0/1\">Edoardo Cetin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celiktutan_O/0/1/0/all/0/1\">Oya Celiktutan</a>",
          "description": "The performance of reinforcement learning depends upon designing an\nappropriate action space, where the effect of each action is measurable, yet,\ngranular enough to permit flexible behavior. So far, this process involved\nnon-trivial user choices in terms of the available actions and their execution\nfrequency. We propose a novel framework for reinforcement learning that\neffectively lifts such constraints. Within our framework, agents learn\neffective behavior over a routine space: a new, higher-level action space,\nwhere each routine represents a set of 'equivalent' sequences of granular\nactions with arbitrary length. Our routine space is learned end-to-end to\nfacilitate the accomplishment of underlying off-policy reinforcement learning\nobjectives. We apply our framework to two state-of-the-art off-policy\nalgorithms and show that the resulting agents obtain relevant performance\nimprovements while requiring fewer interactions with the environment per\nepisode, improving computational efficiency.",
          "link": "http://arxiv.org/abs/2106.02943",
          "publishedOn": "2021-06-08T02:20:22.697Z",
          "wordCount": 557,
          "title": "Learning Routines for Effective Off-Policy Reinforcement Learning. (arXiv:2106.02943v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lacroce_C/0/1/0/all/0/1\">Clara Lacroce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1\">Prakash Panangaden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1\">Guillaume Rabusseau</a>",
          "description": "In this paper we study the approximate minimization problem for language\nmodelling. We assume we are given some language model as a black box. The\nobjective is to obtain a weighted finite automaton (WFA) that fits within a\ngiven size constraint and which mimics the behaviour of the original model\nwhile minimizing some notion of distance between the black box and the\nextracted WFA. We provide an algorithm for the approximate minimization of\nblack boxes trained for language modelling of sequential data over a one-letter\nalphabet. By reformulating the problem in terms of Hankel matrices, we leverage\nclassical results on the approximation of Hankel operators, namely the\ncelebrated Adamyan-Arov-Krein (AAK) theory. This allows us to use the spectral\nnorm to measure the distance between the black box and the WFA. We provide\ntheoretical guarantees to study the potentially infinite-rank Hankel matrix of\nthe black box, without accessing the training data, and we prove that our\nmethod returns an asymptotically-optimal approximation.",
          "link": "http://arxiv.org/abs/2106.02965",
          "publishedOn": "2021-06-08T02:20:22.691Z",
          "wordCount": 602,
          "title": "Extracting Weighted Automata for Approximate Minimization in Language Modelling. (arXiv:2106.02965v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prost_F/0/1/0/all/0/1\">Flavien Prost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "As multi-task models gain popularity in a wider range of machine learning\napplications, it is becoming increasingly important for practitioners to\nunderstand the fairness implications associated with those models. Most\nexisting fairness literature focuses on learning a single task more fairly,\nwhile how ML fairness interacts with multiple tasks in the joint learning\nsetting is largely under-explored. In this paper, we are concerned with how\ngroup fairness (e.g., equal opportunity, equalized odds) as an ML fairness\nconcept plays out in the multi-task scenario. In multi-task learning, several\ntasks are learned jointly to exploit task correlations for a more efficient\ninductive transfer. This presents a multi-dimensional Pareto frontier on (1)\nthe trade-off between group fairness and accuracy with respect to each task, as\nwell as (2) the trade-offs across multiple tasks. We aim to provide a deeper\nunderstanding on how group fairness interacts with accuracy in multi-task\nlearning, and we show that traditional approaches that mainly focus on\noptimizing the Pareto frontier of multi-task accuracy might not perform well on\nfairness goals. We propose a new set of metrics to better capture the\nmulti-dimensional Pareto frontier of fairness-accuracy trade-offs uniquely\npresented in a multi-task learning setting. We further propose a\nMulti-Task-Aware Fairness (MTA-F) approach to improve fairness in multi-task\nlearning. Experiments on several real-world datasets demonstrate the\neffectiveness of our proposed approach.",
          "link": "http://arxiv.org/abs/2106.02705",
          "publishedOn": "2021-06-08T02:20:22.670Z",
          "wordCount": 651,
          "title": "Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning. (arXiv:2106.02705v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siemenn_A/0/1/0/all/0/1\">Alexander E. Siemenn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaulsky_E/0/1/0/all/0/1\">Evyatar Shaulsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beveridge_M/0/1/0/all/0/1\">Matthew Beveridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buonassisi_T/0/1/0/all/0/1\">Tonio Buonassisi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashmi_S/0/1/0/all/0/1\">Sara M. Hashmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1\">Iddo Drori</a>",
          "description": "Autonomous optimization is a process by which hardware conditions are\ndiscovered that generate an optimized experimental product without the guidance\nof a domain expert. We design an autonomous optimization framework to discover\nthe experimental conditions within fluid systems that generate discrete and\nuniform droplet patterns. Generating discrete and uniform droplets requires\nhigh-precision control over the experimental conditions of a fluid system.\nFluid stream instabilities, such as Rayleigh-Plateau instability and capillary\ninstability, drive the separation of a flow into individual droplets. However,\nbecause this phenomenon leverages an instability, by nature the hardware must\nbe precisely tuned to achieve uniform, repeatable droplets. Typically this\nrequires a domain expert in the loop and constant re-tuning depending on the\nhardware configuration and liquid precursor selection. Herein, we propose a\ncomputer vision-driven Bayesian optimization framework to discover the precise\nhardware conditions that generate uniform, reproducible droplets with the\ndesired features, leveraging flow instability without a domain expert in the\nloop. This framework is validated on two fluid systems, at the micrometer and\nmillimeter length scales, using microfluidic and inkjet systems, respectively,\nindicating the application breadth of this approach.",
          "link": "http://arxiv.org/abs/2105.13553",
          "publishedOn": "2021-06-08T02:20:22.664Z",
          "wordCount": 654,
          "title": "Autonomous Optimization of Fluid Systems at Varying Length Scales. (arXiv:2105.13553v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1\">Ilia Shumailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1\">Dmitry Kazhdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1\">Ross Anderson</a>",
          "description": "Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.",
          "link": "http://arxiv.org/abs/2104.09667",
          "publishedOn": "2021-06-08T02:20:22.657Z",
          "wordCount": 642,
          "title": "Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1\">Zhaozhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1\">William R. Zame</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleuren_L/0/1/0/all/0/1\">Lucas M. Fleuren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1\">Paul Elbers</a>",
          "description": "Modeling a system's temporal behaviour in reaction to external stimuli is a\nfundamental problem in many areas. Pure Machine Learning (ML) approaches often\nfail in the small sample regime and cannot provide actionable insights beyond\npredictions. A promising modification has been to incorporate expert domain\nknowledge into ML models. The application we consider is predicting the\nprogression of disease under medications, where a plethora of domain knowledge\nis available from pharmacology. Pharmacological models describe the dynamics of\ncarefully-chosen medically meaningful variables in terms of systems of Ordinary\nDifferential Equations (ODEs). However, these models only describe a limited\ncollection of variables, and these variables are often not observable in\nclinical environments. To close this gap, we propose the latent hybridisation\nmodel (LHM) that integrates a system of expert-designed ODEs with\nmachine-learned Neural ODEs to fully describe the dynamics of the system and to\nlink the expert and latent variables to observable quantities. We evaluated LHM\non synthetic data as well as real-world intensive care data of COVID-19\npatients. LHM consistently outperforms previous works, especially when few\ntraining samples are available such as at the beginning of the pandemic.",
          "link": "http://arxiv.org/abs/2106.02875",
          "publishedOn": "2021-06-08T02:20:22.623Z",
          "wordCount": 670,
          "title": "Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression. (arXiv:2106.02875v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhagoji_A/0/1/0/all/0/1\">Arjun Nitin Bhagoji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cullina_D/0/1/0/all/0/1\">Daniel Cullina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "Understanding the fundamental limits of robust supervised learning has\nemerged as a problem of immense interest, from both practical and theoretical\nstandpoints. In particular, it is critical to determine classifier-agnostic\nbounds on the training loss to establish when learning is possible. In this\npaper, we determine optimal lower bounds on the cross-entropy loss in the\npresence of test-time adversaries, along with the corresponding optimal\nclassification outputs. Our formulation of the bound as a solution to an\noptimization problem is general enough to encompass any loss function depending\non soft classifier outputs. We also propose and provide a proof of correctness\nfor a bespoke algorithm to compute this lower bound efficiently, allowing us to\ndetermine lower bounds for multiple practical datasets of interest. We use our\nlower bounds as a diagnostic tool to determine the effectiveness of current\nrobust training methods and find a gap from optimality at larger budgets.\nFinally, we investigate the possibility of using of optimal classification\noutputs as soft labels to empirically improve robust training.",
          "link": "http://arxiv.org/abs/2104.08382",
          "publishedOn": "2021-06-08T02:20:22.603Z",
          "wordCount": 648,
          "title": "Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries. (arXiv:2104.08382v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1\">Ruichu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1\">Jie Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhifeng Hao</a>",
          "description": "Causal discovery from observational data is an important but challenging task\nin many scientific fields. Recently, NOTEARS [Zheng et al., 2018] formulates\nthe causal structure learning problem as a continuous optimization problem\nusing least-square loss with an acyclicity constraint. Though the least-square\nloss function is well justified under the standard Gaussian noise assumption,\nit is limited if the assumption does not hold. In this work, we theoretically\nshow that the violation of the Gaussian noise assumption will hinder the causal\ndirection identification, making the causal orientation fully determined by the\ncausal strength as well as the variances of noises in the linear case and the\nnoises of strong non-Gaussianity in the nonlinear case. Consequently, we\npropose a more general entropy-based loss that is theoretically consistent with\nthe likelihood score under any noise distribution. We run extensive empirical\nevaluations on both synthetic data and real-world data to validate the\neffectiveness of the proposed method and show that our method achieves the best\nin Structure Hamming Distance, False Discovery Rate, and True Positive Rate\nmatrices.",
          "link": "http://arxiv.org/abs/2106.02835",
          "publishedOn": "2021-06-08T02:20:22.589Z",
          "wordCount": 610,
          "title": "On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Okawa_M/0/1/0/all/0/1\">Maya Okawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_Y/0/1/0/all/0/1\">Yusuke Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_H/0/1/0/all/0/1\">Hiroyuki Toda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurashima_T/0/1/0/all/0/1\">Takeshi Kurashima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Sequences of events including infectious disease outbreaks, social network\nactivities, and crimes are ubiquitous and the data on such events carry\nessential information about the underlying diffusion processes between\ncommunities (e.g., regions, online user groups). Modeling diffusion processes\nand predicting future events are crucial in many applications including\nepidemic control, viral marketing, and predictive policing. Hawkes processes\noffer a central tool for modeling the diffusion processes, in which the\ninfluence from the past events is described by the triggering kernel. However,\nthe triggering kernel parameters, which govern how each community is influenced\nby the past events, are assumed to be static over time. In the real world, the\ndiffusion processes depend not only on the influences from the past, but also\nthe current (time-evolving) states of the communities, e.g., people's awareness\nof the disease and people's current interests. In this paper, we propose a\nnovel Hawkes process model that is able to capture the underlying dynamics of\ncommunity states behind the diffusion processes and predict the occurrences of\nevents based on the dynamics. Specifically, we model the latent dynamic\nfunction that encodes these hidden dynamics by a mixture of neural networks.\nThen we design the triggering kernel using the latent dynamic function and its\nintegral. The proposed method, termed DHP (Dynamic Hawkes Processes), offers a\nflexible way to learn complex representations of the time-evolving communities'\nstates, while at the same time it allows to computing the exact likelihood,\nwhich makes parameter learning tractable. Extensive experiments on four\nreal-world event datasets show that DHP outperforms five widely adopted methods\nfor event prediction.",
          "link": "http://arxiv.org/abs/2105.11152",
          "publishedOn": "2021-06-08T02:20:22.582Z",
          "wordCount": 758,
          "title": "Dynamic Hawkes Processes for Discovering Time-evolving Communities' States behind Diffusion Processes. (arXiv:2105.11152v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.06643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wanyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1\">Hao Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baochun Li</a>",
          "description": "This paper presents Gem, a model-agnostic approach for providing\ninterpretable explanations for any GNNs on various graph learning tasks.\nSpecifically, we formulate the problem of providing explanations for the\ndecisions of GNNs as a causal learning task. Then we train a causal explanation\nmodel equipped with a loss function based on Granger causality. Different from\nexisting explainers for GNNs, Gem explains GNNs on graph-structured data from a\ncausal perspective. It has better generalization ability as it has no\nrequirements on the internal structure of the GNNs or prior knowledge on the\ngraph learning tasks. In addition, Gem, once trained, can be used to explain\nthe target GNN very quickly. Our theoretical analysis shows that several recent\nexplainers fall into a unified framework of additive feature attribution\nmethods. Experimental results on synthetic and real-world datasets show that\nGem achieves a relative increase of the explanation accuracy by up to $30\\%$\nand speeds up the explanation process by up to $110\\times$ as compared to its\nstate-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2104.06643",
          "publishedOn": "2021-06-08T02:20:22.575Z",
          "wordCount": 628,
          "title": "Generative Causal Explanations for Graph Neural Networks. (arXiv:2104.06643v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adams_S/0/1/0/all/0/1\">Samuel Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_C/0/1/0/all/0/1\">Chaitali Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cock_M/0/1/0/all/0/1\">Martine De Cock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1\">Rafael Dowsley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melanson_D/0/1/0/all/0/1\">David Melanson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1\">Anderson C. A. Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Railsback_D/0/1/0/all/0/1\">Davis Railsback</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianwei Shen</a>",
          "description": "Most existing Secure Multi-Party Computation (MPC) protocols for\nprivacy-preserving training of decision trees over distributed data assume that\nthe features are categorical. In real-life applications, features are often\nnumerical. The standard ``in the clear'' algorithm to grow decision trees on\ndata with continuous values requires sorting of training examples for each\nfeature in the quest for an optimal cut-point in the range of feature values in\neach node. Sorting is an expensive operation in MPC, hence finding secure\nprotocols that avoid such an expensive step is a relevant problem in\nprivacy-preserving machine learning. In this paper we propose three more\nefficient alternatives for secure training of decision tree based models on\ndata with continuous features, namely: (1) secure discretization of the data,\nfollowed by secure training of a decision tree over the discretized data; (2)\nsecure discretization of the data, followed by secure training of a random\nforest over the discretized data; and (3) secure training of extremely\nrandomized trees (``extra-trees'') on the original data. Approaches (2) and (3)\nboth involve randomizing feature choices. In addition, in approach (3)\ncut-points are chosen randomly as well, thereby alleviating the need to sort or\nto discretize the data up front. We implemented all proposed solutions in the\nsemi-honest setting with additive secret sharing based MPC. In addition to\nmathematically proving that all proposed approaches are correct and secure, we\nexperimentally evaluated and compared them in terms of classification accuracy\nand runtime. We privately train tree ensembles over data sets with 1000s of\ninstances or features in a few minutes, with accuracies that are at par with\nthose obtained in the clear. This makes our solution orders of magnitude more\nefficient than the existing approaches, which are based on oblivious sorting.",
          "link": "http://arxiv.org/abs/2106.02769",
          "publishedOn": "2021-06-08T02:20:22.556Z",
          "wordCount": 729,
          "title": "Privacy-Preserving Training of Tree Ensembles over Continuous Data. (arXiv:2106.02769v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1\">Tong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bang Liu</a>",
          "description": "Keyword spotting aims to identify specific keyword audio utterances. In\nrecent years, deep convolutional neural networks have been widely utilized in\nkeyword spotting systems. However, their model architectures are mainly based\non off-the shelfbackbones such as VGG-Net or ResNet, instead of specially\ndesigned for the task. In this paper, we utilize neural architecture search to\ndesign convolutional neural network models that can boost the performance of\nkeyword spotting while maintaining an acceptable memory footprint.\nSpecifically, we search the model operators and their connections in a specific\nsearch space with Encoder-Decoder neural architecture optimization. Extensive\nevaluations on Google's Speech Commands Dataset show that the model\narchitecture searched by our approach achieves a state-of-the-art accuracy of\nover 97%.",
          "link": "http://arxiv.org/abs/2106.02738",
          "publishedOn": "2021-06-08T02:20:22.549Z",
          "wordCount": 540,
          "title": "Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yu Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tingyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>",
          "description": "Valuation problems, such as attribution-based feature interpretation, data\nvaluation and model valuation for ensembles, become increasingly more important\nin many machine learning applications. Such problems are commonly solved by\nwell-known game-theoretic criteria, such as Shapley value or Banzhaf index. In\nthis work, we present a novel energy-based treatment for cooperative games,\nwith a theoretical justification by the maximum entropy framework.\nSurprisingly, by conducting variational inference of the energy-based model, we\nrecover various game-theoretic valuation criteria, such as Shapley value and\nBanzhaf index, through conducting one-step gradient ascent for maximizing the\nmean-field ELBO objective. This observation also verifies the rationality of\nexisting criteria, as they are all trying to decouple the correlations among\nthe players through the mean-field approach. By running gradient ascent for\nmultiple steps, we achieve a trajectory of the valuations, among which we\ndefine the valuation with the best conceivable decoupling error as the\nVariational Index. We experimentally demonstrate that the proposed Variational\nIndex enjoys intriguing properties on certain synthetic and real-world\nvaluation problems.",
          "link": "http://arxiv.org/abs/2106.02938",
          "publishedOn": "2021-06-08T02:20:22.543Z",
          "wordCount": 598,
          "title": "Energy-Based Learning for Cooperative Games, with Applications to Feature/Data/Model Valuations. (arXiv:2106.02938v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02700",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Campos_C/0/1/0/all/0/1\">C&#xe9;dric M. Campos</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mahillo_A/0/1/0/all/0/1\">Alejandro Mahillo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Diego_D/0/1/0/all/0/1\">David Mart&#xed;n de Diego</a>",
          "description": "Many of the new developments in machine learning are connected with\ngradient-based optimization methods. Recently, these methods have been studied\nusing a variational perspective. This has opened up the possibility of\nintroducing variational and symplectic integration methods using geometric\nintegrators. In particular, in this paper, we introduce variational integrators\nwhich allow us to derive different methods for optimization. Using both,\nHamilton's principle and Lagrange-d'Alembert's, we derive two families of\noptimization methods in one-to-one correspondence that generalize Polyak's\nheavy ball and the well known Nesterov accelerated gradient method, mimicking\nthe behavior of the latter which reduces the oscillations of typical momentum\nmethods. However, since the systems considered are explicitly time-dependent,\nthe preservation of symplecticity of autonomous systems occurs here solely on\nthe fibers. Several experiments exemplify the result.",
          "link": "http://arxiv.org/abs/2106.02700",
          "publishedOn": "2021-06-08T02:20:22.537Z",
          "wordCount": 574,
          "title": "A Discrete Variational Derivation of Accelerated Methods in Optimization. (arXiv:2106.02700v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "ImageNet-1K serves as the primary dataset for pretraining deep learning\nmodels for computer vision tasks. ImageNet-21K dataset, which is bigger and\nmore diverse, is used less frequently for pretraining, mainly due to its\ncomplexity, low accessibility, and underestimation of its added value. This\npaper aims to close this gap, and make high-quality efficient pretraining on\nImageNet-21K available for everyone. Via a dedicated preprocessing stage,\nutilization of WordNet hierarchical structure, and a novel training scheme\ncalled semantic softmax, we show that various models significantly benefit from\nImageNet-21K pretraining on numerous datasets and tasks, including small\nmobile-oriented models. We also show that we outperform previous ImageNet-21K\npretraining schemes for prominent new models like ViT and Mixer. Our proposed\npretraining pipeline is efficient, accessible, and leads to SoTA reproducible\nresults, from a publicly available dataset. The training code and pretrained\nmodels are available at: https://github.com/Alibaba-MIIL/ImageNet21K",
          "link": "http://arxiv.org/abs/2104.10972",
          "publishedOn": "2021-06-08T02:20:22.512Z",
          "wordCount": 609,
          "title": "ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Cuong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_M/0/1/0/all/0/1\">My H. Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>",
          "description": "Differential Privacy (DP) is an important privacy-enhancing technology for\nprivate machine learning systems. It allows to measure and bound the risk\nassociated with an individual participation in a computation. However, it was\nrecently observed that DP learning systems may exacerbate bias and unfairness\nfor different groups of individuals. This paper builds on these important\nobservations and sheds light on the causes of the disparate impacts arising in\nthe problem of differentially private empirical risk minimization. It focuses\non the accuracy disparity arising among groups of individuals in two\nwell-studied DP learning methods: output perturbation and differentially\nprivate stochastic gradient descent. The paper analyzes which data and model\nproperties are responsible for the disproportionate impacts, why these aspects\nare affecting different groups disproportionately and proposes guidelines to\nmitigate these effects. The proposed approach is evaluated on several datasets\nand settings.",
          "link": "http://arxiv.org/abs/2106.02674",
          "publishedOn": "2021-06-08T02:20:22.505Z",
          "wordCount": 571,
          "title": "Differentially Private Deep Learning under the Fairness Lens. (arXiv:2106.02674v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Prasoon Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.",
          "link": "http://arxiv.org/abs/2106.02972",
          "publishedOn": "2021-06-08T02:20:22.499Z",
          "wordCount": 625,
          "title": "Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02735",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ren_Y/0/1/0/all/0/1\">Yunxiang Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1\">Sui Tang</a>",
          "description": "Interacting particle or agent systems that display a rich variety of\ncollection motions are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand collective behaviors. In this paper, we study the data-driven discovery of\ndistance-based interaction laws in second-order interacting particle systems.\nWe propose a learning approach that models the latent interaction kernel\nfunctions as Gaussian processes, which can simultaneously fulfill two inference\ngoals: one is the nonparametric inference of interaction kernel function with\nthe pointwise uncertainty quantification, and the other one is the inference of\nunknown parameters in the non-collective forces of the system. We formulate\nlearning interaction kernel functions as a statistical inverse problem and\nprovide a detailed analysis of recoverability conditions, establishing that a\ncoercivity condition is sufficient for recoverability. We provide a\nfinite-sample analysis, showing that our posterior mean estimator converges at\nan optimal rate equal to the one in the classical 1-dimensional Kernel Ridge\nregression. Numerical results on systems that exhibit different collective\nbehaviors demonstrate efficient learning of our approach from scarce noisy\ntrajectory data.",
          "link": "http://arxiv.org/abs/2106.02735",
          "publishedOn": "2021-06-08T02:20:22.491Z",
          "wordCount": 625,
          "title": "Data-driven discovery of interacting particle systems using Gaussian processes. (arXiv:2106.02735v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2104.06249",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Ntumba_M/0/1/0/all/0/1\">Manuel Ntumba</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Gore_S/0/1/0/all/0/1\">Saurabh Gore</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Awanyo_J/0/1/0/all/0/1\">Jean-Baptiste Awanyo</a>",
          "description": "In recent years, understanding asteroids has shifted from light worlds to\ngeological worlds by exploring modern spacecraft and advanced radar and\ntelescopic surveys. However, flyby in 2029 will be an opportunity to conduct an\ninternal geophysical study and test the current hypothesis on the effects of\ntidal forces on asteroids. The Earth-Apophis mission is driven by additional\nfactors and scientific goals beyond the unique opportunity for natural\nexperimentation. However, the internal geophysical structures remain largely\nunknown. Understanding the strength and internal integrity of asteroids is not\njust a matter of scientific curiosity. It is a practical imperative to advance\nknowledge for planetary defense against the possibility of an asteroid impact.\nThis paper presents a conceptual robotics system required for efficiency at\nevery stage from entry to post-landing and for asteroid monitoring. In short,\nasteroid surveillance missions are futuristic frontiers, with the potential for\ntechnological growth that could revolutionize space exploration. Advanced space\ntechnologies and robotic systems are needed to minimize risk and prepare these\ntechnologies for future missions. A neural network model is implemented to\ntrack and predict asteroids' orbits. Advanced algorithms are also needed to\nnumerically predict orbital events to minimize error",
          "link": "http://arxiv.org/abs/2104.06249",
          "publishedOn": "2021-06-08T02:20:22.483Z",
          "wordCount": 679,
          "title": "Prediction of Apophis Asteroid Flyby Optimal Trajectories and Data Fusion of Earth-Apophis Mission Launch Windows using Deep Neural Networks. (arXiv:2104.06249v2 [astro-ph.IM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fanjie Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>",
          "description": "An increasing number of applications in the computer vision domain,\nspecially, in medical imaging and remote sensing, are challenging when the goal\nis to classify very large images with tiny objects. More specifically, these\ntype of classification tasks face two key challenges: $i$) the size of the\ninput image in the target dataset is usually in the order of megapixels,\nhowever, existing deep architectures do not easily operate on such big images\ndue to memory constraints, consequently, we seek a memory-efficient method to\nprocess these images; and $ii$) only a small fraction of the input images are\ninformative of the label of interest, resulting in low region of interest (ROI)\nto image ratio. However, most of the current convolutional neural networks\n(CNNs) are designed for image classification datasets that have relatively\nlarge ROIs and small image size (sub-megapixel). Existing approaches have\naddressed these two challenges in isolation. We present an end-to-end CNN model\ntermed Zoom-In network that leverages hierarchical attention sampling for\nclassification of large images with tiny objects using a single GPU. We\nevaluate our method on two large-image datasets and one gigapixel dataset.\nExperimental results show that our model achieves higher accuracy than existing\nmethods while requiring less computing resources.",
          "link": "http://arxiv.org/abs/2106.02694",
          "publishedOn": "2021-06-08T02:20:22.464Z",
          "wordCount": 634,
          "title": "Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shitong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "We study a fundamental problem in computational chemistry known as molecular\nconformation generation, trying to predict stable 3D structures from 2D\nmolecular graphs. Existing machine learning approaches usually first predict\ndistances between atoms and then generate a 3D structure satisfying the\ndistances, where noise in predicted distances may induce extra errors during 3D\ncoordinate generation. Inspired by the traditional force field methods for\nmolecular dynamics simulation, in this paper, we propose a novel approach\ncalled ConfGF by directly estimating the gradient fields of the log density of\natomic coordinates. The estimated gradient fields allow directly generating\nstable conformations via Langevin dynamics. However, the problem is very\nchallenging as the gradient fields are roto-translation equivariant. We notice\nthat estimating the gradient fields of atomic coordinates can be translated to\nestimating the gradient fields of interatomic distances, and hence develop a\nnovel algorithm based on recent score-based generative models to effectively\nestimate these gradients. Experimental results across multiple tasks show that\nConfGF outperforms previous state-of-the-art baselines by a significant margin.",
          "link": "http://arxiv.org/abs/2105.03902",
          "publishedOn": "2021-06-08T02:20:22.457Z",
          "wordCount": 631,
          "title": "Learning Gradient Fields for Molecular Conformation Generation. (arXiv:2105.03902v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1\">Aur&#xe9;lien Bellet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kermarrec_A/0/1/0/all/0/1\">Anne-Marie Kermarrec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavoie_E/0/1/0/all/0/1\">Erick Lavoie</a>",
          "description": "The convergence speed of machine learning models trained with Federated\nLearning is significantly affected by non-independent and identically\ndistributed (non-IID) data partitions, even more so in a fully decentralized\nsetting without a central server. In this paper, we show that the impact of\nlocal class bias, an important type of data non-IIDness, can be significantly\nreduced by carefully designing the underlying communication topology. We\npresent D-Cliques, a novel topology that reduces gradient bias by grouping\nnodes in interconnected cliques such that the local joint distribution in a\nclique is representative of the global class distribution. We also show how to\nadapt the updates of decentralized SGD to obtain unbiased gradients and\nimplement an effective momentum with D-Cliques. Our empirical evaluation on\nMNIST and CIFAR10 demonstrates that our approach provides similar convergence\nspeed as a fully-connected topology with a significant reduction in the number\nof edges and messages. In a 1000-node topology, D-Cliques requires 98% less\nedges and 96% less total messages, with further possible gains using a\nsmall-world topology across cliques.",
          "link": "http://arxiv.org/abs/2104.07365",
          "publishedOn": "2021-06-08T02:20:22.450Z",
          "wordCount": 634,
          "title": "D-Cliques: Compensating NonIIDness in Decentralized Federated Learning with Topology. (arXiv:2104.07365v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ruida Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalathil_D/0/1/0/all/0/1\">Dileep Kalathil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">P. R. Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chao Tian</a>",
          "description": "We address the issue of safety in reinforcement learning. We pose the problem\nin an episodic framework of a constrained Markov decision process. Existing\nresults have shown that it is possible to achieve a reward regret of\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$ while allowing an\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$ constraint violation in $K$ episodes. A\ncritical question that arises is whether it is possible to keep the constraint\nviolation even smaller. We show that when a strictly safe policy is known, then\none can confine the system to zero constraint violation with arbitrarily high\nprobability while keeping the reward regret of order\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$. The algorithm which does so employs the\nprinciple of optimistic pessimism in the face of uncertainty to achieve safe\nexploration. When no strictly safe policy is known, though one is known to\nexist, then it is possible to restrict the system to bounded constraint\nviolation with arbitrarily high probability. This is shown to be realized by a\nprimal-dual algorithm with an optimistic primal estimate and a pessimistic dual\nupdate.",
          "link": "http://arxiv.org/abs/2106.02684",
          "publishedOn": "2021-06-08T02:20:22.407Z",
          "wordCount": 598,
          "title": "Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs. (arXiv:2106.02684v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shucheng Yu</a>",
          "description": "Decision-based attacks (DBA), wherein attackers perturb inputs to spoof\nlearning algorithms by observing solely the output labels, are a type of severe\nadversarial attacks against Deep Neural Networks (DNNs) requiring minimal\nknowledge of attackers. State-of-the-art DBA attacks relying on zeroth-order\ngradient estimation require an excessive number of queries. Recently, Bayesian\noptimization (BO) has shown promising in reducing the number of queries in\nscore-based attacks (SBA), in which attackers need to observe real-valued\nprobability scores as outputs. However, extending BO to the setting of DBA is\nnontrivial because in DBA only output labels instead of real-valued scores, as\nneeded by BO, are available to attackers. In this paper, we close this gap by\nproposing an efficient DBA attack, namely BO-DBA. Different from existing\napproaches, BO-DBA generates adversarial examples by searching so-called\n\\emph{directions of perturbations}. It then formulates the problem as a BO\nproblem that minimizes the real-valued distortion of perturbations. With the\noptimized perturbation generation process, BO-DBA converges much faster than\nthe state-of-the-art DBA techniques. Experimental results on pre-trained\nImageNet classifiers show that BO-DBA converges within 200 queries while the\nstate-of-the-art DBA techniques need over 15,000 queries to achieve the same\nlevel of perturbation distortion. BO-DBA also shows similar attack success\nrates even as compared to BO-based SBA attacks but with less distortion.",
          "link": "http://arxiv.org/abs/2106.02732",
          "publishedOn": "2021-06-08T02:20:22.400Z",
          "wordCount": 644,
          "title": "BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian Optimization. (arXiv:2106.02732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02669",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1\">Jafar Pourbemany</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1\">Almabrok Essa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Ye Zhu</a>",
          "description": "In recent years, research about monitoring vital signs by smartphones grows\nsignificantly. There are some special sensors like Electrocardiogram (ECG) and\nPhotoplethysmographic (PPG) to detect heart rate (HR) and respiration rate\n(RR). Smartphone cameras also can measure HR by detecting and processing\nimaging Photoplethysmographic (iPPG) signals from the video of a user's face.\nIndeed, the variation in the intensity of the green channel can be measured by\nthe iPPG signals of the video. This study aimed to provide a method to extract\nheart rate and respiration rate using the video of individuals' faces. The\nproposed method is based on measuring fluctuations in the Hue, and can\ntherefore extract both HR and RR from the video of a user's face. The proposed\nmethod is evaluated by performing on 25 healthy individuals. For each subject,\n20 seconds video of his/her face is recorded. Results show that the proposed\napproach of measuring iPPG using Hue gives more accurate rates than the Green\nchannel.",
          "link": "http://arxiv.org/abs/2106.02669",
          "publishedOn": "2021-06-08T02:20:22.368Z",
          "wordCount": 606,
          "title": "Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Suhas S Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1\">Dheeraj Nagaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1\">Praneeth Netrapalli</a>",
          "description": "We consider the setting of vector valued non-linear dynamical systems\n$X_{t+1} = \\phi(A^* X_t) + \\eta_t$, where $\\eta_t$ is unbiased noise and $\\phi\n: \\mathbb{R} \\to \\mathbb{R}$ is a known link function that satisfies certain\n{\\em expansivity property}. The goal is to learn $A^*$ from a single trajectory\n$X_1,\\cdots,X_T$ of {\\em dependent or correlated} samples. While the problem is\nwell-studied in the linear case, where $\\phi$ is identity, with optimal error\nrates even for non-mixing systems, existing results in the non-linear case hold\nonly for mixing systems. In this work, we improve existing results for learning\nnonlinear systems in a number of ways: a) we provide the first offline\nalgorithm that can learn non-linear dynamical systems without the mixing\nassumption, b) we significantly improve upon the sample complexity of existing\nresults for mixing systems, c) in the much harder one-pass, streaming setting\nwe study a SGD with Reverse Experience Replay ($\\mathsf{SGD-RER}$) method, and\ndemonstrate that for mixing systems, it achieves the same sample complexity as\nour offline algorithm, d) we justify the expansivity assumption by showing that\nfor the popular ReLU link function -- a non-expansive but easy to learn link\nfunction with i.i.d. samples -- any method would require exponentially many\nsamples (with respect to dimension of $X_t$) from the dynamical system. We\nvalidate our results via. simulations and demonstrate that a naive application\nof SGD can be highly sub-optimal. Indeed, our work demonstrates that for\ncorrelated data, specialized methods designed for the dependency structure in\ndata can significantly outperform standard SGD based methods.",
          "link": "http://arxiv.org/abs/2105.11558",
          "publishedOn": "2021-06-07T22:33:05.470Z",
          "wordCount": 726,
          "title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems. (arXiv:2105.11558v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1\">Aur&#xe9;lien Decelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furtlehner_C/0/1/0/all/0/1\">Cyril Furtlehner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seoane_B/0/1/0/all/0/1\">Beatriz Seoane</a>",
          "description": "Training Restricted Boltzmann Machines (RBMs) has been challenging for a long\ntime due to the difficulty of computing precisely the log-likelihood gradient.\nOver the past decades, many works have proposed more or less successful\ntraining recipes but without studying the crucial quantity of the problem: the\nmixing time i.e. the number of Monte Carlo iterations needed to sample new\nconfigurations from a model. In this work, we show that this mixing time plays\na crucial role in the dynamics and stability of the trained model, and that\nRBMs operate in two well-defined regimes, namely equilibrium and\nout-of-equilibrium, depending on the interplay between this mixing time of the\nmodel and the number of steps, $k$, used to approximate the gradient. We\nfurther show empirically that this mixing time increases with the learning,\nwhich often implies a transition from one regime to another as soon as $k$\nbecomes smaller than this time. In particular, we show that using the popular\n$k$ (persistent) contrastive divergence approaches, with $k$ small, the\ndynamics of the learned model are extremely slow and often dominated by strong\nout-of-equilibrium effects. On the contrary, RBMs trained in equilibrium\ndisplay faster dynamics, and a smooth convergence to dataset-like\nconfigurations during the sampling. Finally we discuss how to exploit in\npractice both regimes depending on the task one aims to fulfill: (i) short $k$s\ncan be used to generate convincing samples in short times, (ii) large $k$ (or\nincreasingly large) must be used to learn the correct equilibrium distribution\nof the RBM.",
          "link": "http://arxiv.org/abs/2105.13889",
          "publishedOn": "2021-06-07T22:33:05.420Z",
          "wordCount": 730,
          "title": "Equilibrium and non-Equilibrium regimes in the learning of Restricted Boltzmann Machines. (arXiv:2105.13889v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roux_C/0/1/0/all/0/1\">Christophe Roux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirth_E/0/1/0/all/0/1\">Elias Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1\">Sebastian Pokutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerdreux_T/0/1/0/all/0/1\">Thomas Kerdreux</a>",
          "description": "Several learning problems involve solving min-max problems, e.g., empirical\ndistributional robust learning or learning with non-standard aggregated losses.\nMore specifically, these problems are convex-linear problems where the\nminimization is carried out over the model parameters $w\\in\\mathcal{W}$ and the\nmaximization over the empirical distribution $p\\in\\mathcal{K}$ of the training\nset indexes, where $\\mathcal{K}$ is the simplex or a subset of it. To design\nefficient methods, we let an online learning algorithm play against a\n(combinatorial) bandit algorithm. We argue that the efficiency of such\napproaches critically depends on the structure of $\\mathcal{K}$ and propose two\nproperties of $\\mathcal{K}$ that facilitate designing efficient algorithms. We\nfocus on a specific family of sets $\\mathcal{S}_{n,k}$ encompassing various\nlearning applications and provide high-probability convergence guarantees to\nthe minimax values.",
          "link": "http://arxiv.org/abs/2105.13939",
          "publishedOn": "2021-06-07T22:33:05.409Z",
          "wordCount": 583,
          "title": "Efficient Online-Bandit Strategies for Minimax Learning Problems. (arXiv:2105.13939v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dewanto_V/0/1/0/all/0/1\">Vektor Dewanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1\">Marcus Gallagher</a>",
          "description": "For continuing environments, reinforcement learning methods commonly maximize\na discounted reward criterion with discount factor close to 1 in order to\napproximate the steady-state reward (the gain). However, such a criterion only\nconsiders the long-run performance, ignoring the transient behaviour. In this\nwork, we develop a policy gradient method that optimizes the gain, then the\nbias (which indicates the transient performance and is important to capably\nselect from policies with equal gain). We derive expressions that enable\nsampling for the gradient of the bias, and its preconditioning Fisher matrix.\nWe further propose an algorithm that solves the corresponding bi-level\noptimization using a logarithmic barrier. Experimental results provide insights\ninto the fundamental mechanisms of our proposal.",
          "link": "http://arxiv.org/abs/2105.13609",
          "publishedOn": "2021-06-07T22:33:05.399Z",
          "wordCount": 576,
          "title": "A nearly Blackwell-optimal policy gradient method. (arXiv:2105.13609v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Baoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Shuo Shao</a>",
          "description": "This paper studies \\emph{differential privacy (DP)} and \\emph{local\ndifferential privacy (LDP)} in cascading bandits. Under DP, we propose an\nalgorithm which guarantees $\\epsilon$-indistinguishability and a regret of\n$\\mathcal{O}((\\frac{\\log T}{\\epsilon})^{1+\\xi})$ for an arbitrarily small\n$\\xi$. This is a significant improvement from the previous work of\n$\\mathcal{O}(\\frac{\\log^3 T}{\\epsilon})$ regret. Under\n($\\epsilon$,$\\delta$)-LDP, we relax the $K^2$ dependence through the tradeoff\nbetween privacy budget $\\epsilon$ and error probability $\\delta$, and obtain a\nregret of $\\mathcal{O}(\\frac{K\\log (1/\\delta) \\log T}{\\epsilon^2})$, where $K$\nis the size of the arm subset. This result holds for both Gaussian mechanism\nand Laplace mechanism by analyses on the composition. Our results extend to\ncombinatorial semi-bandit. We show respective lower bounds for DP and LDP\ncascading bandits. Extensive experiments corroborate our theoretic findings.",
          "link": "http://arxiv.org/abs/2105.11126",
          "publishedOn": "2021-06-07T22:33:05.386Z",
          "wordCount": 570,
          "title": "Cascading Bandit under Differential Privacy. (arXiv:2105.11126v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we relate a feedback channel with any finite-order\nautoregressive moving-average (ARMA) Gaussian noises to a variant of the Kalman\nfilter. In light of this, we obtain relatively explicit lower bounds on the\nfeedback capacity for such colored Gaussian noises, and the bounds are seen to\nbe consistent with various existing results in the literature. Meanwhile, this\nvariant of the Kalman filter also leads to explicit recursive coding schemes\nwith clear structures to achieve the lower bounds. In general, our results\nprovide an alternative perspective while pointing to potentially tighter bounds\nfor the feedback capacity problem.",
          "link": "http://arxiv.org/abs/2001.03108",
          "publishedOn": "2021-06-07T22:33:05.322Z",
          "wordCount": 649,
          "title": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian Noises: Explicit Bounds and Feedback Coding Design. (arXiv:2001.03108v6 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaocheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yansheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dingyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bingchen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongxin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>",
          "description": "Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of\nthousands of vehicles in a city to millions of ride demands throughout the day,\nproviding great promises for improving transportation efficiency through the\ntasks of order dispatching and vehicle repositioning. Existing studies,\nhowever, usually consider the two tasks in simplified settings that hardly\naddress the complex interactions between the two, the real-time fluctuations\nbetween supply and demand, and the necessary coordinations due to the\nlarge-scale nature of the problem. In this paper we propose a unified\nvalue-based dynamic learning framework (V1D3) for tackling both tasks. At the\ncenter of the framework is a globally shared value function that is updated\ncontinuously using online experiences generated from real-time platform\ntransactions. To improve the sample-efficiency and the robustness, we further\npropose a novel periodic ensemble method combining the fast online learning\nwith a large-scale offline training scheme that leverages the abundant\nhistorical driver trajectory data. This allows the proposed framework to adapt\nquickly to the highly dynamic environment, to generalize robustly to recurrent\npatterns and to drive implicit coordinations among the population of managed\nvehicles. Extensive experiments based on real-world datasets show considerably\nimprovements over other recently proposed methods on both tasks. Particularly,\nV1D3 outperforms the first prize winners of both dispatching and repositioning\ntracks in the KDD Cup 2020 RL competition, achieving state-of-the-art results\non improving both total driver income and user experience related metrics.",
          "link": "http://arxiv.org/abs/2105.08791",
          "publishedOn": "2021-06-07T22:33:05.308Z",
          "wordCount": 736,
          "title": "Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2021-06-07T03:06:17.007Z",
          "wordCount": 566,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunhao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxiang Yang</a>",
          "description": "We introduce ES-ENAS, a simple yet general evolutionary joint optimization\nprocedure by combining continuous optimization via Evolutionary Strategies (ES)\nand combinatorial optimization via Efficient NAS (ENAS) in a highly scalable\nand intuitive way. Our main insight is noticing that ES is already a highly\ndistributed algorithm involving hundreds of forward passes which can not only\nbe used for training neural network weights, but also for jointly training a\nNAS controller, both in a blackbox fashion. By doing so, we also bridge the gap\nfrom NAS research in supervised learning settings to the reinforcement learning\nscenario through this relatively simple marriage between two different yet\ncommon lines of research. We demonstrate the utility and effectiveness of our\nmethod over a large search space by training highly combinatorial neural\nnetwork architectures for RL problems in continuous control, via edge pruning\nand quantization. We also incorporate a wide variety of popular techniques from\nmodern NAS literature including multiobjective optimization along with various\ncontroller methods, to showcase their promise in the RL field and discuss\npossible extensions.",
          "link": "http://arxiv.org/abs/2101.07415",
          "publishedOn": "2021-06-07T03:06:17.000Z",
          "wordCount": 674,
          "title": "ES-ENAS: Controller-Based Architecture Search for Evolutionary Reinforcement Learning. (arXiv:2101.07415v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Luo_Y/0/1/0/all/0/1\">Yubo Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nirjon_S/0/1/0/all/0/1\">Shahriar Nirjon</a>",
          "description": "We propose SmartON, a batteryless system that learns to wake up proactively\nat the right moment in order to detect events of interest. It does so by\nadapting the duty cycle to match the distribution of event arrival times under\nthe constraints of harvested energy. While existing energy harvesting systems\neither wake up periodically at a fixed rate to sense and process the data, or\nwake up only in accordance with the availability of the energy source, SmartON\nemploys a three-phase learning framework to learn the energy harvesting pattern\nas well as the pattern of events at run-time, and uses that knowledge to wake\nitself up when events are most likely to occur. The three-phase learning\nframework enables rapid adaptation to environmental changes in both short and\nlong terms. Being able to remain asleep more often than a CTID\n(charging-then-immediate-discharging) wake-up system and adapt to the event\npattern, SmartON is able to reduce energy waste, increase energy efficiency,\nand capture more events. To realize SmartON we have developed a dedicated\nhardware platform whose power management module activates capacitors on-the-fly\nto dynamically increase its storage capacitance. We conduct both\nsimulation-driven and real-system experiments to demonstrate that SmartON\ncaptures 1X--7X more events and is 8X--17X more energy-efficient than a CTID\nsystem.",
          "link": "http://arxiv.org/abs/2103.00749",
          "publishedOn": "2021-06-07T03:06:16.993Z",
          "wordCount": 677,
          "title": "SmartON: Just-in-Time Active Event Detection on Energy Harvesting Systems. (arXiv:2103.00749v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.12376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keswani_V/0/1/0/all/0/1\">Vijay Keswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1\">Oren Mangoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1\">Sushant Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "Motivated by the recent work of Mangoubi and Vishnoi (STOC 2021), we propose\na variant of the min-max optimization framework where the max-player is\nconstrained to update the maximization variable in a greedy manner until it\nreaches a *first-order* stationary point. We present an algorithm that provably\nconverges to an approximate local equilibrium for our framework from any\ninitialization and for nonconvex-nonconcave loss functions. Compared to the\nsecond-order algorithm of Mangoubi and Vishnoi, whose iteration bound is\npolynomial in the dimension, our algorithm is first-order and its iteration\nbound is independent of dimension. We empirically evaluate our algorithm on\nchallenging nonconvex-nonconcave test-functions and loss functions that arise\nin GAN training. Our algorithm converges on these test functions and, when used\nto train GANs on synthetic and real-world datasets, trains stably and avoids\nmode collapse.",
          "link": "http://arxiv.org/abs/2006.12376",
          "publishedOn": "2021-06-07T03:06:16.987Z",
          "wordCount": 634,
          "title": "A Convergent and Dimension-Independent First-Order Algorithm for Min-Max Optimization. (arXiv:2006.12376v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forde_J/0/1/0/all/0/1\">Jessica Zosa Forde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Recent empirical work shows that inconsistent results, based on choice of\nhyperparameter optimization (HPO) configuration, are a widespread problem in ML\nresearch. When comparing two algorithms J and K, searching one subspace can\nyield the conclusion that J outperforms K, whereas searching another can entail\nthe opposite. In short, the way we choose hyperparameters can deceive us. We\nprovide a theoretical complement to this prior work, arguing that, to avoid\nsuch deception, the process of drawing conclusions from HPO should be made more\nrigorous. We call this process epistemic hyperparameter optimization (EHPO),\nand put forth a logical framework to capture its semantics and how it can lead\nto inconsistent conclusions about performance. Our framework enables us to\nprove EHPO methods that are guaranteed to be defended against deception. We\ndemonstrate its utility by proving and empirically validating a defended\nvariant of random search.",
          "link": "http://arxiv.org/abs/2102.03034",
          "publishedOn": "2021-06-07T03:06:16.981Z",
          "wordCount": 617,
          "title": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It. (arXiv:2102.03034v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jackie Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farias_V/0/1/0/all/0/1\">Vivek F. Farias</a>",
          "description": "Motivated by the consideration of fairly sharing the cost of exploration\nbetween multiple groups in learning problems, we develop the Nash bargaining\nsolution in the context of multi-armed bandits. Specifically, the 'grouped'\nbandit associated with any multi-armed bandit problem associates, with each\ntime step, a single group from some finite set of groups. The utility gained by\na given group under some learning policy is naturally viewed as the reduction\nin that group's regret relative to the regret that group would have incurred\n'on its own'. We derive policies that yield the Nash bargaining solution\nrelative to the set of incremental utilities possible under any policy. We show\nthat on the one hand, the 'price of fairness' under such policies is limited,\nwhile on the other hand, regret optimal policies are arbitrarily unfair under\ngeneric conditions. Our theoretical development is complemented by a case study\non contextual bandits for warfarin dosing where we are concerned with the cost\nof exploration across multiple races and age groups.",
          "link": "http://arxiv.org/abs/2106.02553",
          "publishedOn": "2021-06-07T03:06:16.974Z",
          "wordCount": 587,
          "title": "Fair Exploration via Axiomatic Bargaining. (arXiv:2106.02553v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shushan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaojing Ye</a>",
          "description": "We propose a novel learning framework using neural mean-field (NMF) dynamics\nfor inference and estimation problems on heterogeneous diffusion networks. Our\nnew framework leverages the Mori-Zwanzig formalism to obtain an exact evolution\nequation of the individual node infection probabilities, which renders a delay\ndifferential equation with memory integral approximated by learnable time\nconvolution operators. Directly using information diffusion cascade data, our\nframework can simultaneously learn the structure of the diffusion network and\nthe evolution of node infection probabilities. Connections between parameter\nlearning and optimal control are also established, leading to a rigorous and\nimplementable algorithm for training NMF. Moreover, we show that the projected\ngradient descent method can be employed to solve the challenging influence\nmaximization problem, where the gradient is computed extremely fast by\nintegrating NMF forward in time just once in each iteration. Extensive\nempirical studies show that our approach is versatile and robust to variations\nof the underlying diffusion network models, and significantly outperform\nexisting approaches in accuracy and efficiency on both synthetic and real-world\ndata.",
          "link": "http://arxiv.org/abs/2106.02608",
          "publishedOn": "2021-06-07T03:06:16.956Z",
          "wordCount": 631,
          "title": "Influence Estimation and Maximization via Neural Mean-Field Dynamics. (arXiv:2106.02608v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.07038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Somnath_V/0/1/0/all/0/1\">Vignesh Ram Somnath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1\">Charlotte Bunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coley_C/0/1/0/all/0/1\">Connor W. Coley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "Retrosynthesis prediction is a fundamental problem in organic synthesis,\nwhere the task is to identify precursor molecules that can be used to\nsynthesize a target molecule. A key consideration in building neural models for\nthis task is aligning model design with strategies adopted by chemists.\nBuilding on this viewpoint, this paper introduces a graph-based approach that\ncapitalizes on the idea that the graph topology of precursor molecules is\nlargely unaltered during a chemical reaction. The model first predicts the set\nof graph edits transforming the target into incomplete molecules called\nsynthons. Next, the model learns to expand synthons into complete molecules by\nattaching relevant leaving groups. This decomposition simplifies the\narchitecture, making its predictions more interpretable, and also amenable to\nmanual correction. Our model achieves a top-1 accuracy of $53.7\\%$,\noutperforming previous template-free and semi-template-based methods.",
          "link": "http://arxiv.org/abs/2006.07038",
          "publishedOn": "2021-06-07T03:06:16.949Z",
          "wordCount": 596,
          "title": "Learning Graph Models for Retrosynthesis Prediction. (arXiv:2006.07038v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Timm Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1\">Martin Mundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1\">Iuliia Pliushch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1\">Visvanathan Ramesh</a>",
          "description": "Several families of continual learning techniques have been proposed to\nalleviate catastrophic interference in deep neural network training on\nnon-stationary data. However, a comprehensive comparison and analysis of\nlimitations remains largely open due to the inaccessibility to suitable\ndatasets. Empirical examination not only varies immensely between individual\nworks, it further currently relies on contrived composition of benchmarks\nthrough subdivision and concatenation of various prevalent static vision\ndatasets. In this work, our goal is to bridge this gap by introducing a\ncomputer graphics simulation framework that repeatedly renders only upcoming\nurban scene fragments in an endless real-time procedural world generation\nprocess. At its core lies a modular parametric generative model with adaptable\ngenerative factors. The latter can be used to flexibly compose data streams,\nwhich significantly facilitates a detailed analysis and allows for effortless\ninvestigation of various continual learning schemes.",
          "link": "http://arxiv.org/abs/2106.02585",
          "publishedOn": "2021-06-07T03:06:16.942Z",
          "wordCount": 576,
          "title": "A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makar_M/0/1/0/all/0/1\">Maggie Makar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Packer_B/0/1/0/all/0/1\">Ben Packer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moldovan_D/0/1/0/all/0/1\">Dan Moldovan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blalock_D/0/1/0/all/0/1\">Davis Blalock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halpern_Y/0/1/0/all/0/1\">Yoni Halpern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>",
          "description": "Robustness to certain forms of distribution shift is a key concern in many ML\napplications. Often, robustness can be formulated as enforcing invariances to\nparticular interventions on the data generating process. Here, we study a\nflexible, causally-motivated approach to enforcing such invariances, paying\nspecial attention to shortcut learning, where a robust predictor can achieve\noptimal i.i.d generalization in principle, but instead it relies on spurious\ncorrelations or shortcuts in practice. Our approach uses auxiliary labels,\ntypically available at training time, to enforce conditional independences\nbetween the latent factors that determine these labels. We show both\ntheoretically and empirically that causally-motivated regularization schemes\n(a) lead to more robust estimators that generalize well under distribution\nshift, and (b) have better finite sample efficiency compared to usual\nregularization schemes, even in the absence of distribution shifts. Our\nanalysis highlights important theoretical properties of training techniques\ncommonly used in causal inference, fairness, and disentanglement literature.",
          "link": "http://arxiv.org/abs/2105.06422",
          "publishedOn": "2021-06-07T03:06:16.936Z",
          "wordCount": 604,
          "title": "Causally-motivated Shortcut Removal Using Auxiliary Labels. (arXiv:2105.06422v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Shyam Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grbic_D/0/1/0/all/0/1\">Djordje Grbic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katona_A/0/1/0/all/0/1\">Adam Katona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najarro_E/0/1/0/all/0/1\">Elias Najarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1\">Claire Glanois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1\">Sebastian Risi</a>",
          "description": "Neural Cellular Automata (NCAs) have been proven effective in simulating\nmorphogenetic processes, the continuous construction of complex structures from\nvery few starting cells. Recent developments in NCAs lie in the 2D domain,\nnamely reconstructing target images from a single pixel or infinitely growing\n2D textures. In this work, we propose an extension of NCAs to 3D, utilizing 3D\nconvolutions in the proposed neural network architecture. Minecraft is selected\nas the environment for our automaton since it allows the generation of both\nstatic structures and moving machines. We show that despite their simplicity,\nNCAs are capable of growing complex entities such as castles, apartment blocks,\nand trees, some of which are composed of over 3,000 blocks. Additionally, when\ntrained for regeneration, the system is able to regrow parts of simple\nfunctional machines, significantly expanding the capabilities of simulated\nmorphogenetic systems. The code for the experiment in this paper can be found\nat: https://github.com/real-itu/3d-artefacts-nca.",
          "link": "http://arxiv.org/abs/2103.08737",
          "publishedOn": "2021-06-07T03:06:16.920Z",
          "wordCount": 628,
          "title": "Growing 3D Artefacts and Functional Machines with Neural Cellular Automata. (arXiv:2103.08737v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_P/0/1/0/all/0/1\">Puja Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1\">Danai Koutra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>",
          "description": "Catastrophic forgetting undermines the effectiveness of deep neural networks\n(DNNs) in scenarios such as continual learning and lifelong learning. While\nseveral methods have been proposed to tackle this problem, there is limited\nwork explaining why these methods work well. This paper has the goal of better\nexplaining a popularly used technique for avoiding catastrophic forgetting:\nquadratic regularization. We show that quadratic regularizers prevent\nforgetting of past tasks by interpolating current and previous values of model\nparameters at every training iteration. Over multiple training iterations, this\ninterpolation operation reduces the learning rates of more important model\nparameters, thereby minimizing their movement. Our analysis also reveals two\ndrawbacks of quadratic regularization: (a) dependence of parameter\ninterpolation on training hyperparameters, which often leads to training\ninstability and (b) assignment of lower importance to deeper layers, which are\ngenerally the place forgetting occurs in DNNs. Via a simple modification to the\norder of operations, we show these drawbacks can be easily avoided, resulting\nin 6.2% higher average accuracy at 4.5% lower average forgetting. Code\navailable at \\url{https://github.com/EkdeepSLubana/QRforgetting}",
          "link": "http://arxiv.org/abs/2102.02805",
          "publishedOn": "2021-06-07T03:06:16.914Z",
          "wordCount": 643,
          "title": "How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation. (arXiv:2102.02805v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.09997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1\">Sharan Vaswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishkin_A/0/1/0/all/0/1\">Aaron Mishkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1\">Mark Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>",
          "description": "Recent works have shown that stochastic gradient descent (SGD) achieves the\nfast convergence rates of full-batch gradient descent for over-parameterized\nmodels satisfying certain interpolation conditions. However, the step-size used\nin these works depends on unknown quantities and SGD's practical performance\nheavily relies on the choice of this step-size. We propose to use line-search\ntechniques to automatically set the step-size when training models that can\ninterpolate the data. In the interpolation setting, we prove that SGD with a\nstochastic variant of the classic Armijo line-search attains the deterministic\nconvergence rates for both convex and strongly-convex functions. Under\nadditional assumptions, SGD with Armijo line-search is shown to achieve fast\nconvergence for non-convex functions. Furthermore, we show that stochastic\nextra-gradient with a Lipschitz line-search attains linear convergence for an\nimportant class of non-convex functions and saddle-point problems satisfying\ninterpolation. To improve the proposed methods' practical performance, we give\nheuristics to use larger step-sizes and acceleration. We compare the proposed\nalgorithms against numerous optimization methods on standard classification\ntasks using both kernel methods and deep networks. The proposed methods result\nin competitive performance across all models and datasets, while being robust\nto the precise choices of hyper-parameters. For multi-class classification\nusing deep networks, SGD with Armijo line-search results in both faster\nconvergence and better generalization.",
          "link": "http://arxiv.org/abs/1905.09997",
          "publishedOn": "2021-06-07T03:06:16.908Z",
          "wordCount": 734,
          "title": "Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates. (arXiv:1905.09997v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1\">Partha Maji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1\">Matthew Mattina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>",
          "description": "Bayesian neural networks (BNNs) are making significant progress in many\nresearch areas where decision-making needs to be accompanied by uncertainty\nestimation. Being able to quantify uncertainty while making decisions is\nessential for understanding when the model is over-/under-confident, and hence\nBNNs are attracting interest in safety-critical applications, such as\nautonomous driving, healthcare, and robotics. Nevertheless, BNNs have not been\nas widely used in industrial practice, mainly because of their increased memory\nand compute costs. In this work, we investigate quantisation of BNNs by\ncompressing 32-bit floating-point weights and activations to their integer\ncounterparts, that has already been successful in reducing the compute demand\nin standard pointwise neural networks. We study three types of quantised BNNs,\nwe evaluate them under a wide range of different settings, and we empirically\ndemonstrate that a uniform quantisation scheme applied to BNNs does not\nsubstantially decrease their quality of uncertainty estimation.",
          "link": "http://arxiv.org/abs/2102.11062",
          "publishedOn": "2021-06-07T03:06:16.902Z",
          "wordCount": 620,
          "title": "On the Effects of Quantisation on Model Uncertainty in Bayesian Neural Networks. (arXiv:2102.11062v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diotalevi_T/0/1/0/all/0/1\">Tommaso Diotalevi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falabella_A/0/1/0/all/0/1\">Antonio Falabella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martelli_B/0/1/0/all/0/1\">Barbara Martelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michelotto_D/0/1/0/all/0/1\">Diego Michelotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morganti_L/0/1/0/all/0/1\">Lucia Morganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonacorsi_D/0/1/0/all/0/1\">Daniele Bonacorsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giommi_L/0/1/0/all/0/1\">Luca Giommi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tisbeni_S/0/1/0/all/0/1\">Simone Rossi Tisbeni</a>",
          "description": "The distributed Grid infrastructure for High Energy Physics experiments at\nthe Large Hadron Collider (LHC) in Geneva comprises a set of computing centres,\nspread all over the world, as part of the Worldwide LHC Computing Grid (WLCG).\nIn Italy, the Tier-1 functionalities are served by the INFN-CNAF data center,\nwhich provides also computing and storage resources to more than twenty non-LHC\nexperiments. For this reason, a high amount of logs are collected each day from\nvarious sources, which are highly heterogeneous and difficult to harmonize. In\nthis contribution, a working implementation of a system that collects, parses\nand displays the log information from CNAF data sources and the investigation\nof a Machine Learning based predictive maintenance system, is presented.",
          "link": "http://arxiv.org/abs/2106.02612",
          "publishedOn": "2021-06-07T03:06:16.895Z",
          "wordCount": 608,
          "title": "Collection and harmonization of system logs and prototypal Analytics services with the Elastic (ELK) suite at the INFN-CNAF computing centre. (arXiv:2106.02612v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2005.04310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1\">Sara Abdali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1\">Evangelos E. Papalexakis</a>",
          "description": "Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.",
          "link": "http://arxiv.org/abs/2005.04310",
          "publishedOn": "2021-06-07T03:06:16.886Z",
          "wordCount": 665,
          "title": "Semi-Supervised Multi-aspect Detection of Misinformation using Hierarchical Joint Decomposition. (arXiv:2005.04310v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02630",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dohmatob_E/0/1/0/all/0/1\">Elvis Dohmatob</a>",
          "description": "This work studies the (non)robustness of two-layer neural networks in various\nhigh-dimensional linearized regimes. We establish fundamental trade-offs\nbetween memorization and robustness, as measured by the Sobolev-seminorm of the\nmodel w.r.t the data distribution, i.e the square root of the average squared\n$L_2$-norm of the gradients of the model w.r.t the its input. More precisely,\nif $n$ is the number of training examples, $d$ is the input dimension, and $k$\nis the number of hidden neurons in a two-layer neural network, we prove for a\nlarge class of activation functions that, if the model memorizes even a\nfraction of the training, then its Sobolev-seminorm is lower-bounded by (i)\n$\\sqrt{n}$ in case of infinite-width random features (RF) or neural tangent\nkernel (NTK) with $d \\gtrsim n$; (ii) $\\sqrt{n}$ in case of finite-width RF\nwith proportionate scaling of $d$ and $k$; and (iii) $\\sqrt{n/k}$ in case of\nfinite-width NTK with proportionate scaling of $d$ and $k$. Moreover, all of\nthese lower-bounds are tight: they are attained by the min-norm / least-squares\ninterpolator (when $n$, $d$, and $k$ are in the appropriate interpolating\nregime). All our results hold as soon as data is log-concave isotropic, and\nthere is label-noise, i.e the target variable is not a deterministic function\nof the data / features. We empirically validate our theoretical results with\nexperiments. Accidentally, these experiments also reveal for the first time,\n(iv) a multiple-descent phenomenon in the robustness of the min-norm\ninterpolator.",
          "link": "http://arxiv.org/abs/2106.02630",
          "publishedOn": "2021-06-07T03:06:16.878Z",
          "wordCount": 670,
          "title": "Fundamental tradeoffs between memorization and robustness in random features and neural tangent regimes. (arXiv:2106.02630v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bach_P/0/1/0/all/0/1\">Philipp Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1\">Victor Chernozhukov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kurz_M/0/1/0/all/0/1\">Malte S. Kurz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Spindler_M/0/1/0/all/0/1\">Martin Spindler</a>",
          "description": "The R package DoubleML implements the double/debiased machine learning\nframework of Chernozhukov et al. (2018). It provides functionalities to\nestimate parameters in causal models based on machine learning methods. The\ndouble machine learning framework consist of three key ingredients: Neyman\northogonality, high-quality machine learning estimation and sample splitting.\nEstimation of nuisance components can be performed by various state-of-the-art\nmachine learning methods that are available in the mlr3 ecosystem. DoubleML\nmakes it possible to perform inference in a variety of causal models, including\npartially linear and interactive regression models and their extensions to\ninstrumental variable estimation. The object-oriented implementation of\nDoubleML enables a high flexibility for the model specification and makes it\neasily extendable. This paper serves as an introduction to the double machine\nlearning framework and the R package DoubleML. In reproducible code examples\nwith simulated and real data sets, we demonstrate how DoubleML users can\nperform valid inference based on machine learning methods.",
          "link": "http://arxiv.org/abs/2103.09603",
          "publishedOn": "2021-06-07T03:06:16.871Z",
          "wordCount": 618,
          "title": "DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R. (arXiv:2103.09603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1\">Johan Bjorck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>",
          "description": "Low-precision training has become a popular approach to reduce compute\nrequirements, memory footprint, and energy consumption in supervised learning.\nIn contrast, this promising approach has not yet enjoyed similarly widespread\nadoption within the reinforcement learning (RL) community, partly because RL\nagents can be notoriously hard to train even in full precision. In this paper\nwe consider continuous control with the state-of-the-art SAC agent and\ndemonstrate that a na\\\"ive adaptation of low-precision methods from supervised\nlearning fails. We propose a set of six modifications, all straightforward to\nimplement, that leaves the underlying agent and its hyperparameters unchanged\nbut improves the numerical stability dramatically. The resulting modified SAC\nagent has lower memory and compute requirements while matching full-precision\nrewards, demonstrating that low-precision training can substantially accelerate\nstate-of-the-art RL without parameter tuning.",
          "link": "http://arxiv.org/abs/2102.13565",
          "publishedOn": "2021-06-07T03:06:16.840Z",
          "wordCount": 593,
          "title": "Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half Precision. (arXiv:2102.13565v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.07107",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kutalev_A/0/1/0/all/0/1\">Alexey Kutalev</a>",
          "description": "Not so long ago, a method was discovered that successfully overcomes the\ncatastrophic forgetting in neural networks. Although we know about the cases of\nusing this method to preserve skills when adapting pre-trained networks to\nparticular tasks, it has not obtained widespread distribution yet. In this\npaper, we would like to propose an alternative method of overcoming\ncatastrophic forgetting based on the total absolute signal passing through each\nconnection in the network. This method has a simple implementation and seems to\nus essentially close to the processes occurring in the brain of animals to\npreserve previously learned skills during subsequent learning. We hope that the\nease of implementation of this method will serve its wide application.",
          "link": "http://arxiv.org/abs/2005.07107",
          "publishedOn": "2021-06-07T03:06:16.822Z",
          "wordCount": 574,
          "title": "Natural Way to Overcome the Catastrophic Forgetting in Neural Networks. (arXiv:2005.07107v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.01384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agnew_W/0/1/0/all/0/1\">William Agnew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domingos_P/0/1/0/all/0/1\">Pedro Domingos</a>",
          "description": "Current deep reinforcement learning (RL) approaches incorporate minimal prior\nknowledge about the environment, limiting computational and sample efficiency.\n\\textit{Objects} provide a succinct and causal description of the world, and\nmany recent works have proposed unsupervised object representation learning\nusing priors and losses over static object properties like visual consistency.\nHowever, object dynamics and interactions are also critical cues for\nobjectness. In this paper we propose a framework for reasoning about object\ndynamics and behavior to rapidly determine minimal and task-specific object\nrepresentations. To demonstrate the need to reason over object behavior and\ndynamics, we introduce a suite of RGBD MuJoCo object collection and avoidance\ntasks that, while intuitive and visually simple, confound state-of-the-art\nunsupervised object representation learning algorithms. We also highlight the\npotential of this framework on several Atari games, using our object\nrepresentation and standard RL and planning algorithms to learn dramatically\nfaster than existing deep RL algorithms.",
          "link": "http://arxiv.org/abs/2003.01384",
          "publishedOn": "2021-06-07T03:06:16.801Z",
          "wordCount": 613,
          "title": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning. (arXiv:2003.01384v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12174",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we examine the fundamental performance limitations in the\ncontrol of stochastic dynamical systems; more specifically, we derive generic\n$\\mathcal{L}_p$ bounds that hold for any causal (stabilizing) controllers and\nany stochastic disturbances, by an information-theoretic analysis. We first\nconsider the scenario where the plant (i.e., the dynamical system to be\ncontrolled) is linear time-invariant, and it is seen in general that the lower\nbounds are characterized by the unstable poles (or nonminimum-phase zeros) of\nthe plant as well as the conditional entropy of the disturbance. We then\nanalyze the setting where the plant is assumed to be (strictly) causal, for\nwhich case the lower bounds are determined by the conditional entropy of the\ndisturbance. We also discuss the special cases of $p = 2$ and $p = \\infty$,\nwhich correspond to minimum-variance control and controlling the maximum\ndeviations, respectively. In addition, we investigate the power-spectral\ncharacterization of the lower bounds as well as its relation to the\nKolmogorov-Szeg\\\"o formula.",
          "link": "http://arxiv.org/abs/2012.12174",
          "publishedOn": "2021-06-07T03:06:16.779Z",
          "wordCount": 700,
          "title": "Fundamental Limits of Controlled Stochastic Dynamical Systems: An Information-Theoretic Approach. (arXiv:2012.12174v6 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">DiJia Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulvey_J/0/1/0/all/0/1\">John M. Mulvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "In many contemporary applications such as healthcare, finance, robotics, and\nrecommendation systems, continuous deployment of new policies for data\ncollection and online learning is either cost ineffective or impractical. We\nconsider a setting that lies between pure offline reinforcement learning (RL)\nand pure online RL called deployment constrained RL in which the number of\npolicy deployments for data sampling is limited. To solve this challenging\ntask, we propose a new algorithmic learning framework called Model-based\nUncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our\nframework discovers novel and high quality samples for each deployment to\nenable efficient data collection. During each offline training session, we\nbootstrap the policy update by quantifying the amount of uncertainty within our\ncollected data. In the high support region (low uncertainty), we encourage our\npolicy by taking an aggressive update. In the low support region (high\nuncertainty) when the policy bootstraps into the out-of-distribution region, we\ndownweight it by our estimated uncertainty quantification. Experimental results\nshow that MUSBO achieves state-of-the-art performance in the deployment\nconstrained RL setting.",
          "link": "http://arxiv.org/abs/2102.11448",
          "publishedOn": "2021-06-07T03:06:16.770Z",
          "wordCount": 644,
          "title": "MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch Optimization for Deployment Constrained Reinforcement Learning. (arXiv:2102.11448v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1\">Samuel Horvath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1\">Stefanos Laskaridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_M/0/1/0/all/0/1\">Mario Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1\">Ilias Leontiadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "Federated Learning (FL) has been gaining significant traction across\ndifferent ML tasks, ranging from vision to keyboard predictions. In large-scale\ndeployments, client heterogeneity is a fact, and constitutes a primary problem\nfor fairness, training performance and accuracy. Although significant efforts\nhave been made into tackling statistical data heterogeneity, the diversity in\nthe processing capabilities and network bandwidth of clients, termed as system\nheterogeneity, has remained largely unexplored. Current solutions either\ndisregard a large portion of available devices or set a uniform limit on the\nmodel's capacity, restricted by the least capable participants. In this work,\nwe introduce Ordered Dropout, a mechanism that achieves an ordered, nested\nrepresentation of knowledge in Neural Networks and enables the extraction of\nlower footprint submodels without the need of retraining. We further show that\nfor linear maps our Ordered Dropout is equivalent to SVD. We employ this\ntechnique, along with a self-distillation methodology, in the realm of FL in a\nframework called FjORD. FjORD alleviates the problem of client system\nheterogeneity by tailoring the model width to the client's capabilities.\nExtensive evaluation on both CNNs and RNNs across diverse modalities shows that\nFjORD consistently leads to significant performance gains over state-of-the-art\nbaselines, while maintaining its nested structure.",
          "link": "http://arxiv.org/abs/2102.13451",
          "publishedOn": "2021-06-07T03:06:16.751Z",
          "wordCount": 703,
          "title": "FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout. (arXiv:2102.13451v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.13631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengding Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.",
          "link": "http://arxiv.org/abs/2004.13631",
          "publishedOn": "2021-06-07T03:06:16.744Z",
          "wordCount": 647,
          "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.07945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1\">Ahmed Touati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ollivier_Y/0/1/0/all/0/1\">Yann Ollivier</a>",
          "description": "We introduce the forward-backward (FB) representation of the dynamics of a\nreward-free Markov decision process. It provides explicit near-optimal policies\nfor any reward specified a posteriori. During an unsupervised phase, we use\nreward-free interactions with the environment to learn two representations via\noff-the-shelf deep learning methods and temporal difference (TD) learning. In\nthe test phase, a reward representation is estimated either from observations\nor an explicit reward description (e.g., a target state). The optimal policy\nfor that reward is directly obtained from these representations, with no\nplanning. We assume access to an exploration scheme or replay buffer for the\nfirst phase.\n\nThe unsupervised FB loss is well-principled: if training is perfect, the\npolicies obtained are provably optimal for any reward function. With imperfect\ntraining, the sub-optimality is proportional to the unsupervised approximation\nerror. The FB representation learns long-range relationships between states and\nactions, via a predictive occupancy map, without having to synthesize states as\nin model-based approaches.\n\nThis is a step towards learning controllable agents in arbitrary black-box\nstochastic environments. This approach compares well to goal-oriented RL\nalgorithms on discrete and continuous mazes, pixel-based MsPacman, and the\nFetchReach virtual robot arm. We also illustrate how the agent can immediately\nadapt to new tasks beyond goal-oriented RL.",
          "link": "http://arxiv.org/abs/2103.07945",
          "publishedOn": "2021-06-07T03:06:16.728Z",
          "wordCount": 661,
          "title": "Learning One Representation to Optimize All Rewards. (arXiv:2103.07945v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.",
          "link": "http://arxiv.org/abs/2005.12964",
          "publishedOn": "2021-06-07T03:06:16.706Z",
          "wordCount": 759,
          "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.10460",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_V/0/1/0/all/0/1\">Violet Xinying Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kilinc_Karzan_F/0/1/0/all/0/1\">Fatma K&#x131;l&#x131;n&#xe7;-Karzan</a>",
          "description": "We study the problem of online learning (OL) from revealed preferences: a\nlearner wishes to learn a non-strategic agent's private utility function\nthrough observing the agent's utility-maximizing actions in a changing\nenvironment. We adopt an online inverse optimization setup, where the learner\nobserves a stream of agent's actions in an online fashion and the learning\nperformance is measured by regret associated with a loss function. We first\ncharacterize a special but broad class of agent's utility functions, then\nutilize this structure in designing a new convex loss function. We establish\nthat the regret with respect to our new loss function also bounds the regret\nwith respect to all other usual loss functions in the literature. This allows\nus to design a flexible OL framework that enables a unified treatment of loss\nfunctions and supports a variety of online convex optimization algorithms. We\ndemonstrate with theoretical and empirical evidence that our framework based on\nthe new loss function (in particular online Mirror Descent) has significant\nadvantages in terms of regret performance and solution time over other OL\nalgorithms from the literature and bypasses the previous technical assumptions\nas well.",
          "link": "http://arxiv.org/abs/2008.10460",
          "publishedOn": "2021-06-07T03:06:16.665Z",
          "wordCount": 651,
          "title": "Online Convex Optimization Perspective for Learning from Dynamically Revealed Preferences. (arXiv:2008.10460v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1\">Afshin Rostamizadeh</a>",
          "description": "We analyze the problem of active covering, where the learner is given an\nunlabeled dataset and can sequentially label query examples. The objective is\nto label query all of the positive examples in the fewest number of total label\nqueries. We show under standard non-parametric assumptions that a classical\nsupport estimator can be repurposed as an offline algorithm attaining an excess\nquery cost of $\\widetilde{\\Theta}(n^{D/(D+1)})$ compared to the optimal\nlearner, where $n$ is the number of datapoints and $D$ is the dimension. We\nthen provide a simple active learning method that attains an improved excess\nquery cost of $\\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed\nalgorithms only require access to the positive labeled examples, which in\ncertain settings provides additional computational and privacy benefits.\nFinally, we show that the active learning method consistently outperforms\noffline methods as well as a variety of baselines on a wide range of benchmark\nimage-based datasets.",
          "link": "http://arxiv.org/abs/2106.02552",
          "publishedOn": "2021-06-07T03:06:16.658Z",
          "wordCount": 567,
          "title": "Active Covering. (arXiv:2106.02552v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.06799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1\">Th&#xe9;o Barollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "In this work we target the problem of provably computing the equivalence\nbetween two programs represented as dataflow graphs. To this end, we formalize\nthe problem of equivalence between two programs as finding a set of\nsemantics-preserving rewrite rules from one into the other, such that after the\nrewrite the two programs are structurally identical, and therefore trivially\nequivalent. We then develop the first graph-to-sequence neural network system\nfor program equivalence, trained to produce such rewrite sequences from a\ncarefully crafted automatic example generation algorithm. We extensively\nevaluate our system on a rich multi-type linear algebra expression language,\nusing arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our\nsystem outputs via inference a correct rewrite sequence for 96% of the 10,000\nprogram pairs isolated for testing, using 30-term programs. And in all cases,\nthe validity of the sequence produced and therefore the provable assertion of\nprogram equivalence is computable, in negligible time.",
          "link": "http://arxiv.org/abs/2002.06799",
          "publishedOn": "2021-06-07T03:06:16.651Z",
          "wordCount": 634,
          "title": "Equivalence of Dataflow Graphs via Rewrite Rules Using a Graph-to-Sequence Neural Model. (arXiv:2002.06799v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:16.634Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.01350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1\">Zejian Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>",
          "description": "We study the problem of estimating the derivatives of the regression\nfunction, which has a wide range of applications as a key nonparametric\nfunctional of unknown functions. Standard analysis may be tailored to specific\nderivative orders, and parameter tuning remains a daunting challenge\nparticularly for high-order derivatives. In this article, we propose a simple\nplug-in kernel ridge regression (KRR) estimator in nonparametric regression\nwith random design that is broadly applicable for multi-dimensional support and\narbitrary mixed-partial derivatives. We provide a non-asymptotic analysis to\nstudy the behavior of the proposed estimator, leading to two error bounds for a\ngeneral class of kernels under the strong $L_\\infty$ norm. In a concrete\nexample specialized to kernels with polynomially decaying eigenvalues, the\nproposed estimator recovers the minimax optimal rate up to a logarithmic factor\nfor estimating derivatives of functions in H\\\"older class. Interestingly, the\nproposed estimator achieves the optimal rate of convergence with the same\nchoice of tuning parameter for any order of derivatives. Hence, the proposed\nestimator enjoys a remarkable \\textit{plug-in property} for derivatives in that\nit automatically adapts to the order of derivatives to be estimated, enabling\neasy tuning in practice. Our simulation studies show favorable finite sample\nperformance of the proposed method relative to several existing methods.",
          "link": "http://arxiv.org/abs/2006.01350",
          "publishedOn": "2021-06-07T03:06:16.624Z",
          "wordCount": 655,
          "title": "On the Estimation of Derivatives Using Plug-in KRR Estimators. (arXiv:2006.01350v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pellegrini_G/0/1/0/all/0/1\">Giovanni Pellegrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasconi_P/0/1/0/all/0/1\">Paolo Frasconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaeger_M/0/1/0/all/0/1\">Manfred Jaeger</a>",
          "description": "Learning on sets is increasingly gaining attention in the machine learning\ncommunity, due to its widespread applicability. Typically, representations over\nsets are computed by using fixed aggregation functions such as sum or maximum.\nHowever, recent results showed that universal function representation by sum-\n(or max-) decomposition requires either highly discontinuous (and thus poorly\nlearnable) mappings, or a latent dimension equal to the maximum number of\nelements in the set. To mitigate this problem, we introduce a learnable\naggregation function (LAF) for sets of arbitrary cardinality. LAF can\napproximate several extensively used aggregators (such as average, sum,\nmaximum) as well as more complex functions (e.g., variance and skewness). We\nreport experiments on semi-synthetic and real data showing that LAF outperforms\nstate-of-the-art sum- (max-) decomposition architectures such as DeepSets and\nlibrary-based architectures like Principal Neighborhood Aggregation, and can be\neffectively combined with attention-based architectures.",
          "link": "http://arxiv.org/abs/2012.08482",
          "publishedOn": "2021-06-07T03:06:16.611Z",
          "wordCount": 604,
          "title": "Learning Aggregation Functions. (arXiv:2012.08482v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Steven Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiuming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhoutong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1\">Bryan Russell</a>",
          "description": "A neural radiance field (NeRF) is a scene model supporting high-quality view\nsynthesis, optimized per scene. In this paper, we explore enabling user editing\nof a category-level NeRF - also known as a conditional radiance field - trained\non a shape category. Specifically, we introduce a method for propagating coarse\n2D user scribbles to the 3D space, to modify the color or shape of a local\nregion. First, we propose a conditional radiance field that incorporates new\nmodular network components, including a shape branch that is shared across\nobject instances. Observing multiple instances of the same category, our model\nlearns underlying part semantics without any supervision, thereby allowing the\npropagation of coarse 2D user scribbles to the entire 3D region (e.g., chair\nseat). Next, we propose a hybrid network update strategy that targets specific\nnetwork components, which balances efficiency and accuracy. During user\ninteraction, we formulate an optimization problem that both satisfies the\nuser's constraints and preserves the original object structure. We demonstrate\nour approach on various editing tasks over three shape datasets and show that\nit outperforms prior neural editing approaches. Finally, we edit the appearance\nand shape of a real photograph and show that the edit propagates to\nextrapolated novel views.",
          "link": "http://arxiv.org/abs/2105.06466",
          "publishedOn": "2021-06-07T03:06:16.515Z",
          "wordCount": 682,
          "title": "Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1\">Alexandre Galashov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1\">Jakub Sygnowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desjardins_G/0/1/0/all/0/1\">Guillaume Desjardins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Humplik_J/0/1/0/all/0/1\">Jan Humplik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasenclever_L/0/1/0/all/0/1\">Leonard Hasenclever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_R/0/1/0/all/0/1\">Rae Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>",
          "description": "The ability to exploit prior experience to solve novel problems rapidly is a\nhallmark of biological learning systems and of great practical importance for\nartificial ones. In the meta reinforcement learning literature much recent work\nhas focused on the problem of optimizing the learning process itself. In this\npaper we study a complementary approach which is conceptually simple, general,\nmodular and built on top of recent improvements in off-policy learning. The\nframework is inspired by ideas from the probabilistic inference literature and\ncombines robust off-policy learning with a behavior prior, or default behavior\nthat constrains the space of solutions and serves as a bias for exploration; as\nwell as a representation for the value function, both of which are easily\nlearned from a number of training tasks in a multi-task scenario. Our approach\nachieves competitive adaptation performance on hold-out tasks compared to meta\nreinforcement learning baselines and can scale to complex sparse-reward\nscenarios.",
          "link": "http://arxiv.org/abs/2009.04875",
          "publishedOn": "2021-06-07T03:06:16.506Z",
          "wordCount": 622,
          "title": "Importance Weighted Policy Learning and Adaptation. (arXiv:2009.04875v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01484",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "We use explicit representation formulas to show that solutions to certain\npartial differential equations lie in Barron spaces or multilayer spaces if the\nPDE data lie in such function spaces. Consequently, these solutions can be\nrepresented efficiently using artificial neural networks, even in high\ndimension. Conversely, we present examples in which the solution fails to lie\nin the function space associated to a neural network under consideration.",
          "link": "http://arxiv.org/abs/2012.01484",
          "publishedOn": "2021-06-07T03:06:16.243Z",
          "wordCount": null,
          "title": "Some observations on high-dimensional partial differential equations with Barron data. (arXiv:2012.01484v3 [math.AP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.",
          "link": "http://arxiv.org/abs/2105.14849",
          "publishedOn": "2021-06-07T03:06:16.242Z",
          "wordCount": null,
          "title": "Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Igor L. Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jacqueline Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1\">Adam Vagner</a>",
          "description": "Text classifiers are at the core of many NLP applications and use a variety\nof algorithmic approaches and software. This paper introduces infrastructure\nand methodologies for text classifiers based on large-scale regular\nexpressions. In particular, we describe how Facebook determines if a given\npiece of text - anything from a hashtag to a post - belongs to a narrow topic\nsuch as COVID-19. To fully define a topic and evaluate classifier performance\nwe employ human-guided iterations of keyword discovery, but do not require\nlabeled data. For COVID-19, we build two sets of regular expressions: (1) for\n66 languages, with 99% precision and recall >50%, (2) for the 11 most common\nlanguages, with precision >90% and recall >90%. Regular expressions enable\nlow-latency queries from multiple platforms. Response to challenges like\nCOVID-19 is fast and so are revisions. Comparisons to a DNN classifier show\nexplainable results, higher precision and recall, and less overfitting. Our\nlearnings can be applied to other narrow-topic classifiers.",
          "link": "http://arxiv.org/abs/2102.09507",
          "publishedOn": "2021-06-07T03:06:16.231Z",
          "wordCount": null,
          "title": "Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samoilescu_R/0/1/0/all/0/1\">Robert-Florian Samoilescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Looveren_A/0/1/0/all/0/1\">Arnaud Van Looveren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klaise_J/0/1/0/all/0/1\">Janis Klaise</a>",
          "description": "Counterfactual instances are a powerful tool to obtain valuable insights into\nautomated decision processes, describing the necessary minimal changes in the\ninput space to alter the prediction towards a desired target. Most previous\napproaches require a separate, computationally expensive optimization procedure\nper instance, making them impractical for both large amounts of data and\nhigh-dimensional data. Moreover, these methods are often restricted to certain\nsubclasses of machine learning models (e.g. differentiable or tree-based\nmodels). In this work, we propose a deep reinforcement learning approach that\ntransforms the optimization procedure into an end-to-end learnable process,\nallowing us to generate batches of counterfactual instances in a single forward\npass. Our experiments on real-world data show that our method i) is\nmodel-agnostic (does not assume differentiability), relying only on feedback\nfrom model predictions; ii) allows for generating target-conditional\ncounterfactual instances; iii) allows for flexible feature range constraints\nfor numerical and categorical attributes, including the immutability of\nprotected features (e.g. gender, race); iv) is easily extended to other data\nmodalities such as images.",
          "link": "http://arxiv.org/abs/2106.02597",
          "publishedOn": "2021-06-07T03:06:16.230Z",
          "wordCount": 599,
          "title": "Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning. (arXiv:2106.02597v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.03939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Busch_J/0/1/0/all/0/1\">Julian Busch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocheturov_A/0/1/0/all/0/1\">Anton Kocheturov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidl_T/0/1/0/all/0/1\">Thomas Seidl</a>",
          "description": "Malicious software (malware) poses an increasing threat to the security of\ncommunication systems as the number of interconnected mobile devices increases\nexponentially. While some existing malware detection and classification\napproaches successfully leverage network traffic data, they treat network flows\nbetween pairs of endpoints independently and thus fail to leverage rich\ncommunication patterns present in the complete network. Our approach first\nextracts flow graphs and subsequently classifies them using a novel edge\nfeature-based graph neural network model. We present three variants of our base\nmodel, which support malware detection and classification in supervised and\nunsupervised settings. We evaluate our approach on flow graphs that we extract\nfrom a recently published dataset for mobile malware detection that addresses\nseveral issues with previously available datasets. Experiments on four\ndifferent prediction tasks consistently demonstrate the advantages of our\napproach and show that our graph neural network model can boost detection\nperformance by a significant margin.",
          "link": "http://arxiv.org/abs/2103.03939",
          "publishedOn": "2021-06-07T03:06:16.224Z",
          "wordCount": 639,
          "title": "NF-GNN: Network Flow Graph Neural Networks for Malware Detection and Classification. (arXiv:2103.03939v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09258",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Durkan_C/0/1/0/all/0/1\">Conor Durkan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1\">Iain Murray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Score-based diffusion models synthesize samples by reversing a stochastic\nprocess that diffuses data to noise, and are trained by minimizing a weighted\ncombination of score matching losses. The log-likelihood of score-based models\ncan be tractably computed through a connection to continuous normalizing flows,\nbut log-likelihood is not directly optimized by the weighted combination of\nscore matching losses. We show that for a specific weighting scheme, the\nobjective upper bounds the negative log-likelihood, thus enabling approximate\nmaximum likelihood training of score-based models. We empirically observe that\nmaximum likelihood training consistently improves the likelihood of score-based\nmodels across multiple datasets, stochastic processes, and model architectures.\nOur best models achieve negative log-likelihoods of 2.74 and 3.76 bits/dim on\nCIFAR-10 and down-sampled ImageNet, outperforming all existing likelihood-based\nmodels.",
          "link": "http://arxiv.org/abs/2101.09258",
          "publishedOn": "2021-06-07T03:06:16.211Z",
          "wordCount": 567,
          "title": "Maximum Likelihood Training of Score-Based Diffusion Models. (arXiv:2101.09258v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.03309",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Carrasco_Davis_R/0/1/0/all/0/1\">Rodrigo Carrasco-Davis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Reyes_E/0/1/0/all/0/1\">Esteban Reyes</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Valenzuela_C/0/1/0/all/0/1\">Camilo Valenzuela</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Forster_F/0/1/0/all/0/1\">Francisco F&#xf6;rster</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Estevez_P/0/1/0/all/0/1\">Pablo A. Est&#xe9;vez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pignata_G/0/1/0/all/0/1\">Giuliano Pignata</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bauer_F/0/1/0/all/0/1\">Franz E. Bauer</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Reyes_I/0/1/0/all/0/1\">Ignacio Reyes</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sanchez_Saez_P/0/1/0/all/0/1\">Paula S&#xe1;nchez-S&#xe1;ez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Cabrera_Vives_G/0/1/0/all/0/1\">Guillermo Cabrera-Vives</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Eyheramendy_S/0/1/0/all/0/1\">Susana Eyheramendy</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Catelan_M/0/1/0/all/0/1\">M&#xe1;rcio Catelan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Arredondo_J/0/1/0/all/0/1\">Javier Arredondo</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Castillo_Navarrete_E/0/1/0/all/0/1\">Ernesto Castillo-Navarrete</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rodriguez_Mancini_D/0/1/0/all/0/1\">Diego Rodr&#xed;guez-Mancini</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ruz_Mieres_D/0/1/0/all/0/1\">Daniela Ruz-Mieres</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moya_A/0/1/0/all/0/1\">Alberto Moya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sabatini_Gacitua_L/0/1/0/all/0/1\">Luis Sabatini-Gacit&#xfa;a</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sepulveda_Cobo_C/0/1/0/all/0/1\">Crist&#xf3;bal Sep&#xfa;lveda-Cobo</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Mahabal_A/0/1/0/all/0/1\">Ashish A. Mahabal</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Silva_Farfan_J/0/1/0/all/0/1\">Javier Silva-Farf&#xe1;n</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Camacho_Iniquez_E/0/1/0/all/0/1\">Ernesto Camacho-I&#xf1;iquez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Galbany_L/0/1/0/all/0/1\">Llu&#xed;s Galbany</a>",
          "description": "We present a real-time stamp classifier of astronomical events for the ALeRCE\n(Automatic Learning for the Rapid Classification of Events) broker. The\nclassifier is based on a convolutional neural network, trained on alerts\ningested from the Zwicky Transient Facility (ZTF). Using only the\n\\textit{science, reference} and \\textit{difference} images of the first\ndetection as inputs, along with the metadata of the alert as features, the\nclassifier is able to correctly classify alerts from active galactic nuclei,\nsupernovae (SNe), variable stars, asteroids and bogus classes, with high\naccuracy ($\\sim$94\\%) in a balanced test set. In order to find and analyze SN\ncandidates selected by our classifier from the ZTF alert stream, we designed\nand deployed a visualization tool called SN Hunter, where relevant information\nabout each possible SN is displayed for the experts to choose among candidates\nto report to the Transient Name Server database. From June 26th 2019 to\nFebruary 28th 2021, we have reported 6846 SN candidates to date (11.8\ncandidates per day on average), of which 971 have been confirmed\nspectroscopically. Our ability to report objects using only a single detection\nmeans that 70\\% of the reported SNe occurred within one day after the first\ndetection. ALeRCE has only reported candidates not otherwise detected or\nselected by other groups, therefore adding new early transients to the bulk of\nobjects available for early follow-up. Our work represents an important\nmilestone toward rapid alert classifications with the next generation of large\netendue telescopes, such as the Vera C. Rubin Observatory.",
          "link": "http://arxiv.org/abs/2008.03309",
          "publishedOn": "2021-06-07T03:06:16.204Z",
          "wordCount": 764,
          "title": "Alert Classification for the ALeRCE Broker System: The Real-time Stamp Classifier. (arXiv:2008.03309v2 [astro-ph.IM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Anusua Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1\">Alyssa Suhm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1\">Prathamesh Mahankal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1\">Subhiksha Mukuntharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1\">Meghana D. Parab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1\">Malvika Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Meredith Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1\">Arathi Sethumadhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1\">Ashish Jaiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1\">Rahul Dodhia</a>",
          "description": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.",
          "link": "http://arxiv.org/abs/2106.02607",
          "publishedOn": "2021-06-07T03:06:16.183Z",
          "wordCount": 600,
          "title": "Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/1912.11603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1\">Tetsuya Shioda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1\">Shoichiro Takeda</a>",
          "description": "The rotation prediction (Rotation) is a simple pretext-task for\nself-supervised learning (SSL), where models learn useful representations for\ntarget vision tasks by solving pretext-tasks. Although Rotation captures\ninformation of object shapes, it hardly captures information of textures. To\ntackle this problem, we introduce a novel pretext-task called image enhanced\nrotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and\nanother pretext-task based on image enhancement (e.g., sharpening and\nsolarizing) while maintaining simplicity. Through the simultaneous prediction\nof rotation and image enhancement, models learn representations to capture the\ninformation of not only object shapes but also textures. Our experimental\nresults show that IE-Rot models outperform Rotation on various standard\nbenchmarks including ImageNet classification, PASCAL-VOC detection, and COCO\ndetection/segmentation.",
          "link": "http://arxiv.org/abs/1912.11603",
          "publishedOn": "2021-06-07T03:06:16.176Z",
          "wordCount": 589,
          "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1\">Shachar Lovett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_G/0/1/0/all/0/1\">Gaurav Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruosong Wang</a>",
          "description": "This work introduces Bilinear Classes, a new structural framework, which\npermit generalization in reinforcement learning in a wide variety of settings\nthrough the use of function approximation. The framework incorporates nearly\nall existing models in which a polynomial sample complexity is achievable, and,\nnotably, also includes new models, such as the Linear $Q^*/V^*$ model in which\nboth the optimal $Q$-function and the optimal $V$-function are linear in some\nknown feature space. Our main result provides an RL algorithm which has\npolynomial sample complexity for Bilinear Classes; notably, this sample\ncomplexity is stated in terms of a reduction to the generalization error of an\nunderlying supervised learning sub-problem. These bounds nearly match the best\nknown sample complexity bounds for existing models. Furthermore, this framework\nalso extends to the infinite dimensional (RKHS) setting: for the the Linear\n$Q^*/V^*$ model, linear MDPs, and linear mixture MDPs, we provide sample\ncomplexities that have no explicit dependence on the explicit feature dimension\n(which could be infinite), but instead depends only on information theoretic\nquantities.",
          "link": "http://arxiv.org/abs/2103.10897",
          "publishedOn": "2021-06-07T03:06:16.169Z",
          "wordCount": 674,
          "title": "Bilinear Classes: A Structural Framework for Provable Generalization in RL. (arXiv:2103.10897v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we examine the fundamental performance limits of prediction,\nwith or without side information. More specifically, we derive generic lower\nbounds on the $\\mathcal{L}_p$ norms of the prediction errors that are valid for\nany prediction algorithms and for any data distributions. Meanwhile, we combine\nthe entropic analysis from information theory and the innovations approach from\nprediction/estimation theory to characterize the conditions (in terms of, e.g.,\ndirected information or mutual information) to achieve the bounds. We also\ninvestigate the implications of the results in analyzing the fundamental limits\nof generalization in fitting (learning) problems from the perspective of\nprediction with side information, as well as the fundamental limits of\nrecursive algorithms by viewing them as generalized prediction problems.",
          "link": "http://arxiv.org/abs/2001.03813",
          "publishedOn": "2021-06-07T03:06:16.162Z",
          "wordCount": 628,
          "title": "Fundamental Limits of Prediction, Generalization, and Recursion: An Entropic-Innovations Perspective. (arXiv:2001.03813v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-06-07T03:06:16.150Z",
          "wordCount": 695,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09541",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Geffner_T/0/1/0/all/0/1\">Tomas Geffner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Domke_J/0/1/0/all/0/1\">Justin Domke</a>",
          "description": "Several approximate inference algorithms have been proposed to minimize an\nalpha-divergence between an approximating distribution and a target\ndistribution. Many of these algorithms introduce bias, the magnitude of which\nbecomes problematic in high dimensions. Other algorithms are unbiased. These\noften seem to suffer from high variance, but little is rigorously known. In\nthis work we study unbiased methods for alpha-divergence minimization through\nthe Signal-to-Noise Ratio (SNR) of the gradient estimator. We study several\nrepresentative scenarios where strong analytical results are possible, such as\nfully-factorized or Gaussian distributions. We find that when alpha is not\nzero, the SNR worsens exponentially in the dimensionality of the problem. This\ncasts doubt on the practicality of these methods. We empirically confirm these\ntheoretical results.",
          "link": "http://arxiv.org/abs/2010.09541",
          "publishedOn": "2021-06-07T03:06:16.132Z",
          "wordCount": 576,
          "title": "On the Difficulty of Unbiased Alpha Divergence Minimization. (arXiv:2010.09541v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1\">Michael C. Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassoun_S/0/1/0/all/0/1\">Soha Hassoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Li-Ping Liu</a>",
          "description": "Recent works leveraging Graph Neural Networks to approach graph matching\ntasks have shown promising results. Recent progress in learning discrete\ndistributions poses new opportunities for learning graph matching models. In\nthis work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),\nto address the graph matching problem. Our model defines a distribution of\nmatchings for a graph pair so the model can explore a wide range of possible\nmatchings. We further introduce a novel multi-step matching procedure, which\nlearns how to refine a graph pair's matching results incrementally. The model\nalso includes dummy nodes so that the model does not have to find matchings for\nnodes without correspondence. We fit this model to data via scalable stochastic\noptimization. We conduct extensive experiments across synthetic graph datasets\nas well as biochemistry and computer vision applications. Across all tasks, our\nresults show that SIGMA can produce significantly improved graph matching\nresults compared to state-of-the-art models. Ablation studies verify that each\nof our components (stochastic training, iterative matching, and dummy nodes)\noffers noticeable improvement.",
          "link": "http://arxiv.org/abs/2106.02206",
          "publishedOn": "2021-06-07T03:06:16.126Z",
          "wordCount": 603,
          "title": "Stochastic Iterative Graph Matching. (arXiv:2106.02206v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frank_T/0/1/0/all/0/1\">Thorben Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>",
          "description": "Attention mechanisms are developing into a viable alternative to\nconvolutional layers as elementary building block of NNs. Their main advantage\nis that they are not restricted to capture local dependencies in the input, but\ncan draw arbitrary connections. This unprecedented capability coincides with\nthe long-standing problem of modeling global atomic interactions in molecular\nforce fields and other many-body problems. In its original formulation,\nhowever, attention is not applicable to the continuous domains in which the\natoms live. For this purpose we propose a variant to describe geometric\nrelations for arbitrary atomic configurations in Euclidean space that also\nrespects all relevant physical symmetries. We furthermore demonstrate, how the\nsuccessive application of our learned attention matrices effectively translates\nthe molecular geometry into a set of individual atomic contributions\non-the-fly.",
          "link": "http://arxiv.org/abs/2106.02549",
          "publishedOn": "2021-06-07T03:06:16.120Z",
          "wordCount": 561,
          "title": "Detect the Interactions that Matter in Matter: Geometric Attention for Many-Body Systems. (arXiv:2106.02549v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02356",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1\">Marco Mondelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Venkataramanan_R/0/1/0/all/0/1\">Ramji Venkataramanan</a>",
          "description": "We study the problem of estimating a rank-$1$ signal in the presence of\nrotationally invariant noise-a class of perturbations more general than\nGaussian noise. Principal Component Analysis (PCA) provides a natural\nestimator, and sharp results on its performance have been obtained in the\nhigh-dimensional regime. Recently, an Approximate Message Passing (AMP)\nalgorithm has been proposed as an alternative estimator with the potential to\nimprove the accuracy of PCA. However, the existing analysis of AMP requires an\ninitialization that is both correlated with the signal and independent of the\nnoise, which is often unrealistic in practice. In this work, we combine the two\nmethods, and propose to initialize AMP with PCA. Our main result is a rigorous\nasymptotic characterization of the performance of this estimator. Both the AMP\nalgorithm and its analysis differ from those previously derived in the Gaussian\nsetting: at every iteration, our AMP algorithm requires a specific term to\naccount for PCA initialization, while in the Gaussian case, PCA initialization\naffects only the first iteration of AMP. The proof is based on a two-phase\nartificial AMP that first approximates the PCA estimator and then mimics the\ntrue AMP. Our numerical simulations show an excellent agreement between AMP\nresults and theoretical predictions, and suggest an interesting open direction\non achieving Bayes-optimal performance.",
          "link": "http://arxiv.org/abs/2106.02356",
          "publishedOn": "2021-06-07T03:06:16.112Z",
          "wordCount": 658,
          "title": "PCA Initialization for Approximate Message Passing in Rotationally Invariant Models. (arXiv:2106.02356v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Suhas S Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1\">Dheeraj Nagaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1\">Praneeth Netrapalli</a>",
          "description": "We consider the problem of estimating a linear time-invariant (LTI) dynamical\nsystem from a single trajectory via streaming algorithms, which is encountered\nin several applications including reinforcement learning (RL) and time-series\nanalysis. While the LTI system estimation problem is well-studied in the {\\em\noffline} setting, the practically important streaming/online setting has\nreceived little attention. Standard streaming methods like stochastic gradient\ndescent (SGD) are unlikely to work since streaming points can be highly\ncorrelated. In this work, we propose a novel streaming algorithm, SGD with\nReverse Experience Replay ($\\mathsf{SGD}-\\mathsf{RER}$), that is inspired by\nthe experience replay (ER) technique popular in the RL literature.\n$\\mathsf{SGD}-\\mathsf{RER}$ divides data into small buffers and runs SGD\nbackwards on the data stored in the individual buffers. We show that this\nalgorithm exactly deconstructs the dependency structure and obtains information\ntheoretically optimal guarantees for both parameter error and prediction error.\nThus, we provide the first -- to the best of our knowledge -- optimal SGD-style\nalgorithm for the classical problem of linear system identification with a\nfirst order oracle. Furthermore, $\\mathsf{SGD}-\\mathsf{RER}$ can be applied to\nmore general settings like sparse LTI identification with known sparsity\npattern, and non-linear dynamical systems. Our work demonstrates that the\nknowledge of data dependency structure can aid us in designing statistically\nand computationally efficient algorithms which can \"decorrelate\" streaming\nsamples.",
          "link": "http://arxiv.org/abs/2103.05896",
          "publishedOn": "2021-06-07T03:06:16.106Z",
          "wordCount": 685,
          "title": "Streaming Linear System Identification with Reverse Experience Replay. (arXiv:2103.05896v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilson_B/0/1/0/all/0/1\">Benjamin Wilson</a>",
          "description": "We propose a novel method for the inference of phylogenetic trees that\nutilises point configurations on hyperbolic space as its optimisation\nlandscape. Each taxon corresponds to a point of the point configuration, while\nthe evolutionary distance between taxa is represented by the geodesic distance\nbetween their corresponding points. The point configuration is iteratively\nmodified to increase an objective function that additively combines pairwise\nlog-likelihood terms. After convergence, the final tree is derived from the\ninter-point distances using a standard distance-based method. The objective\nfunction, which is shown to mimic the log-likelihood on tree space, is a\ndifferentiable function on a Riemannian manifold. Thus gradient-based\noptimisation techniques can be applied, avoiding the need for combinatorial\nrearrangements of tree topology.",
          "link": "http://arxiv.org/abs/2104.11430",
          "publishedOn": "2021-06-07T03:06:16.086Z",
          "wordCount": 576,
          "title": "Learning phylogenetic trees as hyperbolic point configurations. (arXiv:2104.11430v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07446",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Talwai_P/0/1/0/all/0/1\">Prem Talwai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shameli_A/0/1/0/all/0/1\">Ali Shameli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simchi_Levi_D/0/1/0/all/0/1\">David Simchi-Levi</a>",
          "description": "We develop novel learning rates for conditional mean embeddings by applying\nthe theory of interpolation for reproducing kernel Hilbert spaces (RKHS). We\nderive explicit, adaptive convergence rates for the sample estimator under the\nmisspecifed setting, where the target operator is not Hilbert-Schmidt or\nbounded with respect to the input/output RKHSs. We demonstrate that in certain\nparameter regimes, we can achieve uniform convergence rates in the output RKHS.\nWe hope our analyses will allow the much broader application of conditional\nmean embeddings to more complex ML/RL settings involving infinite dimensional\nRKHSs and continuous state spaces.",
          "link": "http://arxiv.org/abs/2105.07446",
          "publishedOn": "2021-06-07T03:06:16.080Z",
          "wordCount": 537,
          "title": "Sobolev Norm Learning Rates for Conditional Mean Embeddings. (arXiv:2105.07446v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05982",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "We study the natural function space for infinitely wide two-layer neural\nnetworks with ReLU activation (Barron space) and establish different\nrepresentation formulae. In two cases, we describe the space explicitly up to\nisomorphism.\n\nUsing a convenient representation, we study the pointwise properties of\ntwo-layer networks and show that functions whose singular set is fractal or\ncurved (for example distance functions from smooth submanifolds) cannot be\nrepresented by infinitely wide two-layer networks with finite path-norm. We use\nthis structure theorem to show that the only $C^1$-diffeomorphisms which Barron\nspace are affine.\n\nFurthermore, we show that every Barron function can be decomposed as the sum\nof a bounded and a positively one-homogeneous function and that there exist\nBarron functions which decay rapidly at infinity and are globally\nLebesgue-integrable. This result suggests that two-layer neural networks may be\nable to approximate a greater variety of functions than commonly believed.",
          "link": "http://arxiv.org/abs/2006.05982",
          "publishedOn": "2021-06-07T03:06:16.074Z",
          "wordCount": 604,
          "title": "Representation formulas and pointwise properties for Barron functions. (arXiv:2006.05982v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alamdari_P/0/1/0/all/0/1\">Parand Alizadeh Alamdari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klassen_T/0/1/0/all/0/1\">Toryn Q. Klassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icarte_R/0/1/0/all/0/1\">Rodrigo Toro Icarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1\">Sheila A. McIlraith</a>",
          "description": "Recent work in AI safety has highlighted that in sequential decision making,\nobjectives are often underspecified or incomplete. This gives discretion to the\nacting agent to realize the stated objective in ways that may result in\nundesirable outcomes. We contend that to learn to act safely, a reinforcement\nlearning (RL) agent should include contemplation of the impact of its actions\non the wellbeing and agency of others in the environment, including other\nacting agents and reactive processes. We endow RL agents with the ability to\ncontemplate such impact by augmenting their reward based on expectation of\nfuture return by others in the environment, providing different criteria for\ncharacterizing impact. We further endow these agents with the ability to\ndifferentially factor this impact into their decision making, manifesting\nbehavior that ranges from self-centred to self-less, as demonstrated by\nexperiments in gridworld environments.",
          "link": "http://arxiv.org/abs/2106.02617",
          "publishedOn": "2021-06-07T03:06:16.068Z",
          "wordCount": 578,
          "title": "Be Considerate: Objectives, Side Effects, and Deciding How to Act. (arXiv:2106.02617v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Ze-Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Z.Y. Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhong-Yi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "This paper presents a novel pre-trained language models (PLM) compression\napproach based on the matrix product operator (short as MPO) from quantum\nmany-body physics. It can decompose an original matrix into central tensors\n(containing the core information) and auxiliary tensors (with only a small\nproportion of parameters). With the decomposed MPO structure, we propose a\nnovel fine-tuning strategy by only updating the parameters from the auxiliary\ntensors, and design an optimization algorithm for MPO-based approximation over\nstacked network architectures. Our approach can be applied to the original or\nthe compressed PLMs in a general way, which derives a lighter network and\nsignificantly reduces the parameters to be fine-tuned. Extensive experiments\nhave demonstrated the effectiveness of the proposed approach in model\ncompression, especially the reduction in finetuning parameters (91% reduction\non average).",
          "link": "http://arxiv.org/abs/2106.02205",
          "publishedOn": "2021-06-07T03:06:16.062Z",
          "wordCount": 586,
          "title": "Enabling Lightweight Fine-tuning for Pre-trained Language Model Compression based on Matrix Product Operators. (arXiv:2106.02205v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1\">Tristan Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Suiyi Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1\">Thomas Fr&#xe9;our</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1\">Harold Mouch&#xe8;re</a>",
          "description": "The prevalence of employing attention mechanisms has brought along concerns\non the interpretability of attention distributions. Although it provides\ninsights about how a model is operating, utilizing attention as the explanation\nof model predictions is still highly dubious. The community is still seeking\nmore interpretable strategies for better identifying local active regions that\ncontribute the most to the final decision. To improve the interpretability of\nexisting attention models, we propose a novel Bilinear Representative\nNon-Parametric Attention (BR-NPA) strategy that captures the task-relevant\nhuman-interpretable information. The target model is first distilled to have\nhigher-resolution intermediate feature maps. From which, representative\nfeatures are then grouped based on local pairwise feature similarity, to\nproduce finer-grained, more precise attention maps highlighting task-relevant\nparts of the input. The obtained attention maps are ranked according to the\n`active level' of the compound feature, which provides information regarding\nthe important level of the highlighted regions. The proposed model can be\neasily adapted in a wide variety of modern deep models, where classification is\ninvolved. It is also more accurate, faster, and with a smaller memory footprint\nthan usual neural attention modules. Extensive experiments showcase more\ncomprehensive visual explanations compared to the state-of-the-art\nvisualization model across multiple tasks including few-shot classification,\nperson re-identification, fine-grained image classification. The proposed\nvisualization model sheds imperative light on how neural networks `pay their\nattention' differently in different tasks.",
          "link": "http://arxiv.org/abs/2106.02566",
          "publishedOn": "2021-06-07T03:06:16.056Z",
          "wordCount": 669,
          "title": "Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Ratnajit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1\">Haris Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1\">Shabbir Marzban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1\">Ahmed Badar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1\">Terence Brouns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1\">Shruthi Gowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.",
          "link": "http://arxiv.org/abs/2106.02567",
          "publishedOn": "2021-06-07T03:06:16.030Z",
          "wordCount": 575,
          "title": "AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chevalier_S/0/1/0/all/0/1\">Samuel Chevalier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiasny_J/0/1/0/all/0/1\">Jochen Stiasny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1\">Spyros Chatzivasileiadis</a>",
          "description": "Recent advances in deep learning have set the focus on neural networks (NNs)\nthat can successfully replace traditional numerical solvers in many\napplications, achieving impressive computing gains. One such application is\ntime domain simulation, which is indispensable for the design, analysis and\noperation of many engineering systems. Simulating dynamical systems with\nimplicit Newton-based solvers is a computationally heavy task, as it requires\nthe solution of a parameterized system of differential and algebraic equations\nat each time step. A variety of NN-based methodologies have been shown to\nsuccessfully approximate the dynamical trajectories computed by numerical time\ndomain solvers at a fraction of the time. However, so far no previous NN-based\nmodel has explicitly captured the fact that any predicted point on the time\ndomain trajectory also represents the fixed point of the numerical solver\nitself. As we show, explicitly capturing this property can lead to\nsignificantly increased NN accuracy and much smaller NN sizes. In this paper,\nwe model the Newton solver at the heart of an implicit Runge-Kutta integrator\nas a contracting map iteratively seeking this fixed point. Our primary\ncontribution is to develop a recurrent NN simulation tool, termed the\nContracting Neural-Newton Solver (CoNNS), which explicitly captures the\ncontracting nature of these Newton iterations. To build CoNNS, we train a\nfeedforward NN and mimic this contraction behavior by embedding a series of\ntraining constraints which guarantee the mapping provided by the NN satisfies\nthe Banach fixed-point theorem; thus, we are able to prove that successive\npasses through the NN are guaranteed to converge to a unique, fixed point.",
          "link": "http://arxiv.org/abs/2106.02543",
          "publishedOn": "2021-06-07T03:06:16.024Z",
          "wordCount": 678,
          "title": "Contracting Neural-Newton Solver. (arXiv:2106.02543v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weiwei Jiang</a>",
          "description": "Communication networks are important infrastructures in contemporary society.\nThere are still many challenges that are not fully solved and new solutions are\nproposed continuously in this active research area. In recent years, to model\nthe network topology, graph-based deep learning has achieved state-of-the-art\nperformance in a series of problems in communication networks. In this survey,\nwe review the rapidly growing body of research using different graph-based deep\nlearning models, e.g. graph convolutional and graph attention networks, in\nvarious problems from different communication networks, e.g. wireless networks,\nwired networks, and software-defined networks. We also present a well-organized\nlist of the problem and solution for each study and identify future research\ndirections. To the best of our knowledge, this paper is the first survey that\nfocuses on the application of graph-based deep learning methods in\ncommunication networks. To track the follow-up research, a public GitHub\nrepository is created, where the relevant papers will be updated continuously.",
          "link": "http://arxiv.org/abs/2106.02533",
          "publishedOn": "2021-06-07T03:06:16.018Z",
          "wordCount": 586,
          "title": "Graph-based Deep Learning for Communication Networks: A Survey. (arXiv:2106.02533v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02734",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Spadea_M/0/1/0/all/0/1\">Maria Francesca Spadea</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maspero_M/0/1/0/all/0/1\">Matteo Maspero</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zaffino_P/0/1/0/all/0/1\">Paolo Zaffino</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Seco_J/0/1/0/all/0/1\">Joao Seco</a>",
          "description": "Recently, deep learning (DL)-based methods for the generation of synthetic\ncomputed tomography (sCT) have received significant research attention as an\nalternative to classical ones. We present here a systematic review of these\nmethods by grouping them into three categories, according to their clinical\napplications: I) To replace CT in magnetic resonance (MR)-based treatment\nplanning. II) Facilitate cone-beam computed tomography (CBCT)-based\nimage-guided adaptive radiotherapy. III) Derive attenuation maps for the\ncorrection of positron emission tomography (PET). Appropriate database\nsearching was performed on journal articles published between January 2014 and\nDecember 2020. The DL methods' key characteristics were extracted from each\neligible study, and a comprehensive comparison among network architectures and\nmetrics was reported. A detailed review of each category was given,\nhighlighting essential contributions, identifying specific challenges, and\nsummarising the achievements. Lastly, the statistics of all the cited works\nfrom various aspects were analysed, revealing the popularity and future trends,\nand the potential of DL-based sCT generation. The current status of DL-based\nsCT generation was evaluated, assessing the clinical readiness of the presented\nmethods.",
          "link": "http://arxiv.org/abs/2102.02734",
          "publishedOn": "2021-06-07T03:06:16.011Z",
          "wordCount": 653,
          "title": "Deep learning-based synthetic-CT generation in radiotherapy and PET: a review. (arXiv:2102.02734v2 [physics.med-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yangkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jiarui Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>",
          "description": "Over the past few years, graph neural networks (GNN) and label\npropagation-based methods have made significant progress in addressing node\nclassification tasks on graphs. However, in addition to their reliance on\nelaborate architectures and algorithms, there are several key technical details\nthat are frequently overlooked, and yet nonetheless can play a vital role in\nachieving satisfactory performance. In this paper, we first summarize a series\nof existing tricks-of-the-trade, and then propose several new ones related to\nlabel usage, loss function formulation, and model design that can significantly\nimprove various GNN architectures. We empirically evaluate their impact on\nfinal node classification accuracy by conducting ablation studies and\ndemonstrate consistently-improved performance, often to an extent that\noutweighs the gains from more dramatic changes in the underlying GNN\narchitecture. Notably, many of the top-ranked models on the Open Graph\nBenchmark (OGB) leaderboard benefit from our techniques.",
          "link": "http://arxiv.org/abs/2103.13355",
          "publishedOn": "2021-06-07T03:06:16.001Z",
          "wordCount": 603,
          "title": "Bag of Tricks for Node Classification with Graph Neural Networks. (arXiv:2103.13355v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xiaoying Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>",
          "description": "Feature selection is a prevalent data preprocessing paradigm for various\nlearning tasks. Due to the expensive cost of acquiring supervision information,\nunsupervised feature selection sparks great interests recently. However,\nexisting unsupervised feature selection algorithms do not have fairness\nconsiderations and suffer from a high risk of amplifying discrimination by\nselecting features that are over associated with protected attributes such as\ngender, race, and ethnicity. In this paper, we make an initial investigation of\nthe fairness-aware unsupervised feature selection problem and develop a\nprincipled framework, which leverages kernel alignment to find a subset of\nhigh-quality features that can best preserve the information in the original\nfeature space while being minimally correlated with protected attributes.\nSpecifically, different from the mainstream in-processing debiasing methods,\nour proposed framework can be regarded as a model-agnostic debiasing strategy\nthat eliminates biases and discrimination before downstream learning algorithms\nare involved. Experimental results on multiple real-world datasets demonstrate\nthat our framework achieves a good trade-off between utility maximization and\nfairness promotion.",
          "link": "http://arxiv.org/abs/2106.02216",
          "publishedOn": "2021-06-07T03:06:15.981Z",
          "wordCount": 583,
          "title": "Fairness-Aware Unsupervised Feature Selection. (arXiv:2106.02216v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00628",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1\">Zixuan Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tang_S/0/1/0/all/0/1\">Shanjian Tang</a>",
          "description": "This paper is concerned with convergence of stochastic gradient algorithms\nwith momentum terms in the nonconvex setting. A class of stochastic momentum\nmethods, including stochastic gradient descent, heavy ball, and Nesterov's\naccelerated gradient, is analyzed in a general framework under mild\nassumptions. Based on the convergence result of expected gradients, we prove\nthe almost sure convergence by a detailed discussion of the effects of momentum\nand the number of upcrossings. It is worth noting that there are not additional\nrestrictions imposed on the objective function and stepsize. Another\nimprovement over previous results is that the existing Lipschitz condition of\nthe gradient is relaxed into the condition of Holder continuity. As a\nbyproduct, we apply a localization procedure to extend our results to\nstochastic stepsizes.",
          "link": "http://arxiv.org/abs/2012.00628",
          "publishedOn": "2021-06-07T03:06:15.975Z",
          "wordCount": 572,
          "title": "Convergence of Gradient Algorithms for Nonconvex C^{1+alpha} Cost Functions. (arXiv:2012.00628v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Song Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josef_C/0/1/0/all/0/1\">Christopher S. Josef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamaleswaran_R/0/1/0/all/0/1\">Rishikesan Kamaleswaran</a>",
          "description": "Continuous, automated surveillance systems that incorporate machine learning\nmodels are becoming increasingly more common in healthcare environments. These\nmodels can capture temporally dependent changes across multiple patient\nvariables and can enhance a clinician's situational awareness by providing an\nearly warning alarm of an impending adverse event such as sepsis. However, most\ncommonly used methods, e.g., XGBoost, fail to provide an interpretable\nmechanism for understanding why a model produced a sepsis alarm at a given\ntime. The black-box nature of many models is a severe limitation as it prevents\nclinicians from independently corroborating those physiologic features that\nhave contributed to the sepsis alarm. To overcome this limitation, we propose a\ngeneralized linear model (GLM) approach to fit a Granger causal graph based on\nthe physiology of several major sepsis-associated derangements (SADs). We adopt\na recently developed stochastic monotone variational inequality-based estimator\ncoupled with forwarding feature selection to learn the graph structure from\nboth continuous and discrete-valued as well as regularly and irregularly\nsampled time series. Most importantly, we develop a non-asymptotic upper bound\non the estimation error for any monotone link function in the GLM. We conduct\nreal-data experiments and demonstrate that our proposed method can achieve\ncomparable performance to popular and powerful prediction methods such as\nXGBoost while simultaneously maintaining a high level of interpretability.",
          "link": "http://arxiv.org/abs/2106.02600",
          "publishedOn": "2021-06-07T03:06:15.968Z",
          "wordCount": 660,
          "title": "Inferring Granger Causality from Irregularly Sampled Time Series. (arXiv:2106.02600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:15.958Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?",
          "link": "http://arxiv.org/abs/2106.02559",
          "publishedOn": "2021-06-07T03:06:15.952Z",
          "wordCount": 649,
          "title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dangel_F/0/1/0/all/0/1\">Felix Dangel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatzel_L/0/1/0/all/0/1\">Lukas Tatzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "Curvature in form of the Hessian or its generalized Gauss-Newton (GGN)\napproximation is valuable for algorithms that rely on a local model for the\nloss to train, compress, or explain deep networks. Existing methods based on\nimplicit multiplication via automatic differentiation or Kronecker-factored\nblock diagonal approximations do not consider noise in the mini-batch. We\npresent ViViT, a curvature model that leverages the GGN's low-rank structure\nwithout further approximations. It allows for efficient computation of\neigenvalues, eigenvectors, as well as per-sample first- and second-order\ndirectional derivatives. The representation is computed in parallel with\ngradients in one backward pass and offers a fine-grained cost-accuracy\ntrade-off, which allows it to scale. As examples for ViViT's usefulness, we\ninvestigate the directional gradients and curvatures during training, and how\nnoise information can be used to improve the stability of second-order methods.",
          "link": "http://arxiv.org/abs/2106.02624",
          "publishedOn": "2021-06-07T03:06:15.929Z",
          "wordCount": 578,
          "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank structure. (arXiv:2106.02624v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vadori_N/0/1/0/all/0/1\">Nelson Vadori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1\">Rahul Savani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spooner_T/0/1/0/all/0/1\">Thomas Spooner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_S/0/1/0/all/0/1\">Sumitra Ganesh</a>",
          "description": "Recently, Optimistic Multiplicative Weights Update (OMWU) was proven to be\nthe first constant step-size algorithm in the online no-regret framework to\nenjoy last-iterate convergence to Nash Equilibria in the constrained zero-sum\nbimatrix case, where weights represent the probabilities of playing pure\nstrategies. We introduce the second such algorithm, \\textit{Consensus MWU}, for\nwhich we prove local convergence and show empirically that it enjoys faster and\nmore robust convergence than OMWU. Our algorithm shows the importance of a new\nobject, the \\textit{simplex Hessian}, as well as of the interaction of the game\nwith the (eigen)space of vectors summing to zero, which we believe future\nresearch can build on. As for OMWU, CMWU has convergence guarantees in the\nzero-sum case only, but Cheung and Piliouras (2020) recently showed that OMWU\nand MWU display opposite convergence properties depending on whether the game\nis zero-sum or cooperative. Inspired by this work and the recent literature on\nlearning to optimize for single functions, we extend CMWU to non zero-sum games\nby introducing a new framework for online learning in games, where the update\nrule's gradient and Hessian coefficients along a trajectory are learnt by a\nreinforcement learning policy that is conditioned on the nature of the game:\n\\textit{the game signature}. We construct the latter using a new canonical\ndecomposition of two-player games into eight components corresponding to\ncommutative projection operators, generalizing and unifying recent game\nconcepts studied in the literature. We show empirically that our new learning\npolicy is able to exploit the game signature across a wide range of game types.",
          "link": "http://arxiv.org/abs/2106.02615",
          "publishedOn": "2021-06-07T03:06:15.922Z",
          "wordCount": 696,
          "title": "Consensus Multiplicative Weights Update: Learning to Learn using Projector-based Game Signatures. (arXiv:2106.02615v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2004.03238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1\">Kazutoshi Shinoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>",
          "description": "Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.",
          "link": "http://arxiv.org/abs/2004.03238",
          "publishedOn": "2021-06-07T03:06:15.914Z",
          "wordCount": 646,
          "title": "Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cannella_C/0/1/0/all/0/1\">Chris Cannella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "We introduce and demonstrate a semi-empirical procedure for determining\napproximate objective functions suitable for optimizing arbitrarily\nparameterized proposal distributions in MCMC methods. Our proposed Ab Initio\nobjective functions consist of the weighted combination of functions following\nconstraints on their global optima and of coordinate invariance that we argue\nshould be upheld by general measures of MCMC efficiency for use in proposal\noptimization. The coefficients of Ab Initio objective functions are determined\nso as to recover the optimal MCMC behavior prescribed by established\ntheoretical analysis for chosen reference problems. Our experimental results\ndemonstrate that Ab Initio objective functions maintain favorable performance\nand preferable optimization behavior compared to existing objective functions\nfor MCMC optimization when optimizing highly expressive proposal distributions.\nWe argue that Ab Initio objective functions are sufficiently robust to enable\nthe confident optimization of MCMC proposal distributions parameterized by deep\ngenerative networks that extend beyond the traditional limitations of\nindividual MCMC schemes.",
          "link": "http://arxiv.org/abs/2106.02104",
          "publishedOn": "2021-06-07T03:06:15.898Z",
          "wordCount": 577,
          "title": "Semi-Empirical Objective Functions for MCMC Proposal Optimization. (arXiv:2106.02104v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiayi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xilian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.",
          "link": "http://arxiv.org/abs/2106.02257",
          "publishedOn": "2021-06-07T03:06:15.889Z",
          "wordCount": 596,
          "title": "Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02602",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romanenkova_E/0/1/0/all/0/1\">Evgenia Romanenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zainulin_R/0/1/0/all/0/1\">Ramil Zainulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_M/0/1/0/all/0/1\">Matvey Morozov</a>",
          "description": "Change points are abrupt alterations in the distribution of sequential data.\nA change-point detection (CPD) model aims at quick detection of such changes.\nClassic approaches perform poorly for semi-structured sequential data because\nof the absence of adequate data representation learning. To deal with it, we\nintroduce a principled differentiable loss function that considers the\nspecificity of the CPD task. The theoretical results suggest that this function\napproximates well classic rigorous solutions. For such loss function, we\npropose an end-to-end method for the training of deep representation learning\nCPD models. Our experiments provide evidence that the proposed approach\nimproves baseline results of change point detection for various data types,\nincluding real-world videos and image sequences, and improve representations\nfor them.",
          "link": "http://arxiv.org/abs/2106.02602",
          "publishedOn": "2021-06-07T03:06:15.872Z",
          "wordCount": 541,
          "title": "Principled change point detection via representation learning. (arXiv:2106.02602v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.01023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wijeratne_P/0/1/0/all/0/1\">Peter A. Wijeratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>",
          "description": "Progressive diseases worsen over time and are characterised by monotonic\nchange in features that track disease progression. Here we connect ideas from\ntwo formerly separate methodologies -- event-based and hidden Markov modelling\n-- to derive a new generative model of disease progression. Our model can\nuniquely infer the most likely group-level sequence and timing of events\n(natural history) from limited datasets. Moreover, it can infer and predict\nindividual-level trajectories (prognosis) even when data are missing, giving it\nhigh clinical utility. Here we derive the model and provide an inference scheme\nbased on the expectation maximisation algorithm. We use clinical, imaging and\nbiofluid data from the Alzheimer's Disease Neuroimaging Initiative to\ndemonstrate the validity and utility of our model. First, we train our model to\nuncover a new group-level sequence of feature changes in Alzheimer's disease\nover a period of ${\\sim}17.3$ years. Next, we demonstrate that our model\nprovides improved utility over a continuous time hidden Markov model by area\nunder the receiver operator characteristic curve ${\\sim}0.23$. Finally, we\ndemonstrate that our model maintains predictive accuracy with up to $50\\%$\nmissing data. These results support the clinical validity of our model and its\nbroader utility in resource-limited medical applications.",
          "link": "http://arxiv.org/abs/2011.01023",
          "publishedOn": "2021-06-07T03:06:15.865Z",
          "wordCount": 671,
          "title": "Learning transition times in event sequences: the Event-Based Hidden Markov Model of disease progression. (arXiv:2011.01023v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1\">Max Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouwer_E/0/1/0/all/0/1\">Edward De Brouwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1\">Michael Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_Y/0/1/0/all/0/1\">Yves Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1\">Karsten Borgwardt</a>",
          "description": "Graph neural networks (GNNs) are a powerful architecture for tackling graph\nlearning tasks, yet have been shown to be oblivious to eminent substructures,\nsuch as cycles. We present TOGL, a novel layer that incorporates global\ntopological information of a graph using persistent homology. TOGL can be\neasily integrated into any type of GNN and is strictly more expressive in terms\nof the Weisfeiler--Lehman test of isomorphism. Augmenting GNNs with our layer\nleads to beneficial predictive performance for graph and node classification\ntasks, both on synthetic data sets, which can be classified by humans using\ntheir topology but not by ordinary GNNs, and on real-world data.",
          "link": "http://arxiv.org/abs/2102.07835",
          "publishedOn": "2021-06-07T03:06:15.851Z",
          "wordCount": null,
          "title": "Topological Graph Neural Networks. (arXiv:2102.07835v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melodia_L/0/1/0/all/0/1\">Luciano Melodia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenz_R/0/1/0/all/0/1\">Richard Lenz</a>",
          "description": "In this paper, we use topological data analysis techniques to construct a\nsuitable neural network classifier for the task of learning sensor signals of\nentire power plants according to their reference designation system. We use\nrepresentations of persistence diagrams to derive necessary preprocessing steps\nand visualize the large amounts of data. We derive architectures with deep\none-dimensional convolutional layers combined with stacked long short-term\nmemories as residual networks suitable for processing the persistence features.\nWe combine three separate sub-networks, obtaining as input the time series\nitself and a representation of the persistent homology for the zeroth and first\ndimension. We give a mathematical derivation for most of the used\nhyper-parameters. For validation, numerical experiments were performed with\nsensor data from four power plants of the same construction type.",
          "link": "http://arxiv.org/abs/2106.02493",
          "publishedOn": "2021-06-07T03:06:15.840Z",
          "wordCount": 557,
          "title": "Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alaya_M/0/1/0/all/0/1\">Mokhtar Z. Alaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasso_G/0/1/0/all/0/1\">Gilles Gasso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berar_M/0/1/0/all/0/1\">Maxime Berar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1\">Alain Rakotomamonjy</a>",
          "description": "Gromov-Wasserstein (GW) distance is a key tool for manifold learning and\ncross-domain learning, allowing the comparison of distributions that do not\nlive in the same metric space. Because of its high computational complexity,\nseveral approximate GW distances have been proposed based on entropy\nregularization or on slicing, and one-dimensional GW computation. In this\npaper, we propose a novel approach for comparing two incomparable\ndistributions, that hinges on the idea of distributional slicing, embeddings,\nand on computing the closed-form Wasserstein distance between the sliced\ndistributions. We provide a theoretical analysis of this new divergence, called\ndistributional sliced embedding (DSE) discrepancy, and we show that it\npreserves several interesting properties of GW distance including\nrotation-invariance. We show that the embeddings involved in DSE can be\nefficiently learned. Finally, we provide a large set of experiments\nillustrating the behavior of DSE as a divergence in the context of generative\nmodeling and in query framework.",
          "link": "http://arxiv.org/abs/2106.02542",
          "publishedOn": "2021-06-07T03:06:15.828Z",
          "wordCount": 580,
          "title": "Distributional Sliced Embedding Discrepancy for Incomparable Distributions. (arXiv:2106.02542v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11327",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Muthirayan_D/0/1/0/all/0/1\">Deepan Muthirayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khargonekar_P/0/1/0/all/0/1\">Pramod P. Khargonekar</a>",
          "description": "In this paper we provide provable regret guarantees for an online\nmeta-learning receding horizon control algorithm in an iterative control\nsetting. We consider the setting where, in each iteration the system to be\ncontrolled is a linear deterministic system that is different and unknown, the\ncost for the controller in an iteration is a general additive cost function and\nthere are affine control input constraints. By analysing conditions under which\nsub-linear regret is achievable, we prove that the online receding horizon\ncontroller achieves a regret for the controller cost and constraint violation\nthat are $\\tilde{O}(T^{3/4})$ with respect to the best policy that satisfies\nthe control input control constraints, when the preview of the cost functions\nis limited to an interval and the interval size is doubled from one to the\nnext. We then show that the average of the regret for the controller cost and\nconstraint violation with respect to the same policy vary as\n$\\tilde{O}((1+1/\\sqrt{N})T^{3/4})$ with the number of iterations $N$, under the\nsame setting.",
          "link": "http://arxiv.org/abs/2010.11327",
          "publishedOn": "2021-06-07T03:06:15.820Z",
          "wordCount": 715,
          "title": "Meta-Learning Guarantees for Online Receding Horizon Learning Control. (arXiv:2010.11327v12 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Ella Y. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1\">Anirudh Som</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1\">Ankita Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hongjun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>",
          "description": "Deep neural networks have increasingly been used as an auxiliary tool in\nhealthcare applications, due to their ability to improve performance of several\ndiagnosis tasks. However, these methods are not widely adopted in clinical\nsettings due to the practical limitations in the reliability, generalizability,\nand interpretability of deep learning based systems. As a result, methods have\nbeen developed that impose additional constraints during network training to\ngain more control as well as improve interpretabilty, facilitating their\nacceptance in healthcare community. In this work, we investigate the benefit of\nusing Orthogonal Spheres (OS) constraint for classification of COVID-19 cases\nfrom chest X-ray images. The OS constraint can be written as a simple\northonormality term which is used in conjunction with the standard\ncross-entropy loss during classification network training. Previous studies\nhave demonstrated significant benefits in applying such constraints to deep\nlearning models. Our findings corroborate these observations, indicating that\nthe orthonormality loss function effectively produces improved semantic\nlocalization via GradCAM visualizations, enhanced classification performance,\nand reduced model calibration error. Our approach achieves an improvement in\naccuracy of 1.6% and 4.8% for two- and three-class classification,\nrespectively; similar results are found for models with data augmentation\napplied. In addition to these findings, our work also presents a new\napplication of the OS regularizer in healthcare, increasing the post-hoc\ninterpretability and performance of deep learning models for COVID-19\nclassification to facilitate adoption of these methods in clinical settings. We\nalso identify the limitations of our strategy that can be explored for further\nresearch in future.",
          "link": "http://arxiv.org/abs/2102.08360",
          "publishedOn": "2021-06-07T03:06:15.801Z",
          "wordCount": null,
          "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaofan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kangcheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1\">Cynthia Rudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaposhnik_Y/0/1/0/all/0/1\">Yaron Shaposhnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sijia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>",
          "description": "Lending decisions are usually made with proprietary models that provide\nminimally acceptable explanations to users. In a future world without such\nsecrecy, what decision support tools would one want to use for justified\nlending decisions? This question is timely, since the economy has dramatically\nshifted due to a pandemic, and a massive number of new loans will be necessary\nin the short term. We propose a framework for such decisions, including a\nglobally interpretable machine learning model, an interactive visualization of\nit, and several types of summaries and explanations for any given decision. The\nmachine learning model is a two-layer additive risk model, which resembles a\ntwo-layer neural network, but is decomposable into subscales. In this model,\neach node in the first (hidden) layer represents a meaningful subscale model,\nand all of the nonlinearities are transparent. Our online visualization tool\nallows exploration of this model, showing precisely how it came to its\nconclusion. We provide three types of explanations that are simpler than, but\nconsistent with, the global model: case-based reasoning explanations that use\nneighboring past cases, a set of features that were the most important for the\nmodel's prediction, and summary-explanations that provide a customized sparse\nexplanation for any particular lending decision made by the model. Our\nframework earned the FICO recognition award for the Explainable Machine\nLearning Challenge, which was the first public challenge in the domain of\nexplainable machine learning.",
          "link": "http://arxiv.org/abs/2106.02605",
          "publishedOn": "2021-06-07T03:06:15.797Z",
          "wordCount": 669,
          "title": "A Holistic Approach to Interpretability in Financial Lending: Models, Visualizations, and Summary-Explanations. (arXiv:2106.02605v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Agniva Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drineas_P/0/1/0/all/0/1\">Petros Drineas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Samson Zhou</a>",
          "description": "Principal component analysis (PCA) is a widely used dimension reduction\ntechnique in machine learning and multivariate statistics. To improve the\ninterpretability of PCA, various approaches to obtain sparse principal\ndirection loadings have been proposed, which are termed Sparse Principal\nComponent Analysis (SPCA). In this paper, we present thresholding as a provably\naccurate, polynomial time, approximation algorithm for the SPCA problem,\nwithout imposing any restrictive assumptions on the input covariance matrix.\nOur first thresholding algorithm using the Singular Value Decomposition is\nconceptually simple; is faster than current state-of-the-art; and performs well\nin practice. On the negative side, our (novel) theoretical bounds do not\naccurately predict the strong practical performance of this approach. The\nsecond algorithm solves a well-known semidefinite programming relaxation and\nthen uses a novel, two step, deterministic thresholding scheme to compute a\nsparse principal vector. It works very well in practice and, remarkably, this\nsolid practical performance is accurately predicted by our theoretical bounds,\nwhich bridge the theory-practice gap better than current state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.12748",
          "publishedOn": "2021-06-07T03:06:15.789Z",
          "wordCount": 624,
          "title": "Approximation Algorithms for Sparse Principal Component Analysis. (arXiv:2006.12748v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geada_R/0/1/0/all/0/1\">Rob Geada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prangle_D/0/1/0/all/0/1\">Dennis Prangle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGough_A/0/1/0/all/0/1\">Andrew Stephen McGough</a>",
          "description": "One-shot Neural Architecture Search (NAS) aims to minimize the computational\nexpense of discovering state-of-the-art models. However, in the past year\nattention has been drawn to the comparable performance of naive random search\nacross the same search spaces used by leading NAS algorithms. To address this,\nwe explore the effects of drastically relaxing the NAS search space, and we\npresent Bonsai-Net, an efficient one-shot NAS method to explore our relaxed\nsearch space. Bonsai-Net is built around a modified differential pruner and can\nconsistently discover state-of-the-art architectures that are significantly\nbetter than random search with fewer parameters than other state-of-the-art\nmethods. Additionally, Bonsai-Net performs simultaneous model search and\ntraining, dramatically reducing the total time it takes to generate\nfully-trained models from scratch.",
          "link": "http://arxiv.org/abs/2006.09264",
          "publishedOn": "2021-06-07T03:06:15.769Z",
          "wordCount": 593,
          "title": "Bonsai-Net: One-Shot Neural Architecture Search via Differentiable Pruners. (arXiv:2006.09264v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02331",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tanaka_K/0/1/0/all/0/1\">Keitaro Tanaka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sawata_R/0/1/0/all/0/1\">Ryosuke Sawata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takahashi_S/0/1/0/all/0/1\">Shusuke Takahashi</a>",
          "description": "This paper presents a new deep clustering (DC) method called manifold-aware\nDC (M-DC) that can enhance hyperspace utilization more effectively than the\noriginal DC. The original DC has a limitation in that a pair of two speakers\nhas to be embedded having an orthogonal relationship due to its use of the\none-hot vector-based loss function, while our method derives a unique loss\nfunction aimed at maximizing the target angle in the hyperspace based on the\nnature of a regular simplex. Our proposed loss imposes a higher penalty than\nthe original DC when the speaker is assigned incorrectly. The change from DC to\nM-DC can be easily achieved by rewriting just one term in the loss function of\nDC, without any other modifications to the network architecture or model\nparameters. As such, our method has high practicability because it does not\naffect the original inference part. The experimental results show that the\nproposed method improves the performances of the original DC and its expansion\nmethod.",
          "link": "http://arxiv.org/abs/2106.02331",
          "publishedOn": "2021-06-07T03:06:15.758Z",
          "wordCount": 611,
          "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding Vectors Based on Regular Simplex. (arXiv:2106.02331v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1\">Pierre Laforgue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1\">Massimiliano Pontil</a>",
          "description": "We introduce and analyze MT-OMD, a multitask generalization of Online Mirror\nDescent (OMD) which operates by sharing updates between tasks. We prove that\nthe regret of MT-OMD is of order $\\sqrt{1 + \\sigma^2(N-1)}\\sqrt{T}$, where\n$\\sigma^2$ is the task variance according to the geometry induced by the\nregularizer, $N$ is the number of tasks, and $T$ is the time horizon. Whenever\ntasks are similar, that is, $\\sigma^2 \\le 1$, this improves upon the\n$\\sqrt{NT}$ bound obtained by running independent OMDs on each task. Our\nmultitask extensions of Online Gradient Descent and Exponentiated Gradient, two\nimportant instances of OMD, are shown to enjoy closed-form updates, making them\neasy to use in practice. Finally, we provide numerical experiments on four\nreal-world datasets which support our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.02393",
          "publishedOn": "2021-06-07T03:06:15.741Z",
          "wordCount": 540,
          "title": "Multitask Online Mirror Descent. (arXiv:2106.02393v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maeda_T/0/1/0/all/0/1\">Takashi Nicholas Maeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1\">Shohei Shimizu</a>",
          "description": "Causal discovery from data affected by unobserved variables is an important\nbut difficult problem to solve. The effects that unobserved variables have on\nthe relationships between observed variables are more complex in nonlinear\ncases than in linear cases. In this study, we focus on causal additive models\nin the presence of unobserved variables. Causal additive models exhibit\nstructural equations that are additive in the variables and error terms. We\ntake into account the presence of not only unobserved common causes but also\nunobserved intermediate variables. Our theoretical results show that, when the\ncausal relationships are nonlinear and there are unobserved variables, it is\nnot possible to identify all the causal relationships between observed\nvariables through regression and independence tests. However, our theoretical\nresults also show that it is possible to avoid incorrect inferences. We propose\na method to identify all the causal relationships that are theoretically\npossible to identify without being biased by unobserved variables. The\nempirical results using artificial data and simulated functional magnetic\nresonance imaging (fMRI) data show that our method effectively infers causal\nstructures in the presence of unobserved variables.",
          "link": "http://arxiv.org/abs/2106.02234",
          "publishedOn": "2021-06-07T03:06:15.702Z",
          "wordCount": 628,
          "title": "Discovery of Causal Additive Models in the Presence of Unobserved Variables. (arXiv:2106.02234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinxing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qiang Cheng</a>",
          "description": "Feature selection identifies subsets of informative features and reduces\ndimensions in the original feature space, helping provide insights into data\ngeneration or a variety of domain problems. Existing methods mainly depend on\nfeature scoring functions or sparse regularizations; nonetheless, they have\nlimited ability to reconcile the representativeness and inter-correlations of\nfeatures. In this paper, we introduce a novel, simple yet effective\nregularization approach, named top-$k$ regularization, to supervised feature\nselection in regression and classification tasks. Structurally, the top-$k$\nregularization induces a sub-architecture on the architecture of a learning\nmodel to boost its ability to select the most informative features and model\ncomplex nonlinear relationships simultaneously. Theoretically, we derive and\nmathematically prove a uniform approximation error bound for using this\napproach to approximate high-dimensional sparse functions. Extensive\nexperiments on a wide variety of benchmarking datasets show that the top-$k$\nregularization is effective and stable for supervised feature selection.",
          "link": "http://arxiv.org/abs/2106.02197",
          "publishedOn": "2021-06-07T03:06:15.657Z",
          "wordCount": 571,
          "title": "Top-$k$ Regularization for Supervised Feature Selection. (arXiv:2106.02197v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02346",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Elesedy_B/0/1/0/all/0/1\">Bryn Elesedy</a>",
          "description": "It is a commonly held belief that enforcing invariance improves\ngeneralisation. Although this approach enjoys widespread popularity, it is only\nvery recently that a rigorous theoretical demonstration of this benefit has\nbeen established. In this work we build on the function space perspective of\nElesedy and Zaidi arXiv:2102.10333 to derive a strictly non-zero generalisation\nbenefit of incorporating invariance in kernel ridge regression when the target\nis invariant to the action of a compact group. We study invariance enforced by\nfeature averaging and find that generalisation is governed by a notion of\neffective dimension that arises from the interplay between the kernel and the\ngroup. In building towards this result, we find that the action of the group\ninduces an orthogonal decomposition of both the reproducing kernel Hilbert\nspace and its kernel, which may be of interest in its own right.",
          "link": "http://arxiv.org/abs/2106.02346",
          "publishedOn": "2021-06-07T03:06:15.572Z",
          "wordCount": 564,
          "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods. (arXiv:2106.02346v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Youming Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "In this paper we study the problem of stochastic multi-armed bandits (MAB) in\nthe (local) differential privacy (DP/LDP) model. Unlike the previous results\nwhich need to assume bounded reward distributions, here we mainly focus on the\ncase the reward distribution of each arm only has $(1+v)$-th moment with some\n$v\\in (0, 1]$. In the first part, we study the problem in the central\n$\\epsilon$-DP model. We first provide a near-optimal result by developing a\nprivate and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the\nresult via a private and robust version of the Successive Elimination (SE)\nalgorithm. Finally, we show that the instance-dependent regret bound of our\nimproved algorithm is optimal by showing its lower bound. In the second part of\nthe paper, we study the problem in the $\\epsilon$-LDP model. We propose an\nalgorithm which could be seen as locally private and robust version of the SE\nalgorithm, and show it could achieve (near) optimal rates for both\ninstance-dependent and instance-independent regrets. All of the above results\ncan also reveal the differences between the problem of private MAB with bounded\nrewards and heavy-tailed rewards. To achieve these (near) optimal rates, we\ndevelop several new hard instances and private robust estimators as byproducts,\nwhich might could be used to other related problems. Finally, experimental\nresults also support our theoretical analysis and show the effectiveness of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.02575",
          "publishedOn": "2021-06-07T03:06:15.207Z",
          "wordCount": 655,
          "title": "Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits. (arXiv:2106.02575v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junguang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yifei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yufeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Domain adaptation (DA) aims at transferring knowledge from a labeled source\ndomain to an unlabeled target domain. Though many DA theories and algorithms\nhave been proposed, most of them are tailored into classification settings and\nmay fail in regression tasks, especially in the practical keypoint detection\ntask. To tackle this difficult but significant task, we present a method of\nregressive domain adaptation (RegDA) for unsupervised keypoint detection.\nInspired by the latest theoretical work, we first utilize an adversarial\nregressor to maximize the disparity on the target domain and train a feature\ngenerator to minimize this disparity. However, due to the high dimension of the\noutput space, this regressor fails to detect samples that deviate from the\nsupport of the source. To overcome this problem, we propose two important\nideas. First, based on our observation that the probability density of the\noutput space is sparse, we introduce a spatial probability distribution to\ndescribe this sparsity and then use it to guide the learning of the adversarial\nregressor. Second, to alleviate the optimization difficulty in the\nhigh-dimensional space, we innovatively convert the minimax game in the\nadversarial training to the minimization of two opposite goals. Extensive\nexperiments show that our method brings large improvement by 8% to 11% in terms\nof PCK on different datasets.",
          "link": "http://arxiv.org/abs/2103.06175",
          "publishedOn": "2021-06-07T03:06:15.201Z",
          "wordCount": 680,
          "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huanyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mironov_I/0/1/0/all/0/1\">Ilya Mironov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hejazinia_M/0/1/0/all/0/1\">Meisam Hejazinia</a>",
          "description": "Despite intense interest and considerable effort, the current generation of\nneural networks suffers a significant loss of accuracy under most practically\nrelevant privacy training regimes. One particularly challenging class of neural\nnetworks are the wide ones, such as those deployed for NLP typeahead prediction\nor recommender systems. Observing that these models share something in\ncommon--an embedding layer that reduces the dimensionality of the input--we\nfocus on developing a general approach towards training these models that takes\nadvantage of the sparsity of the gradients. More abstractly, we address the\nproblem of differentially private empirical risk minimization (ERM) for models\nthat admit sparse gradients. We demonstrate that for non-convex ERM problems,\nthe loss is logarithmically dependent on the number of parameters, in contrast\nwith polynomial dependence for the general case. Following the same intuition,\nwe propose a novel algorithm for privately training neural networks. Finally,\nwe provide an empirical study of a DP wide neural network on a real-world\ndataset, which has been rarely explored in the previous work.",
          "link": "http://arxiv.org/abs/2103.01294",
          "publishedOn": "2021-06-07T03:06:15.194Z",
          "wordCount": 628,
          "title": "Wide Network Learning with Differential Privacy. (arXiv:2103.01294v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallah_R/0/1/0/all/0/1\">Ranwa Al Mallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badu_Marfo_G/0/1/0/all/0/1\">Godwin Badu-Marfo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farooq_B/0/1/0/all/0/1\">Bilal Farooq</a>",
          "description": "Federated learning (FL) is a machine learning technique that aims at training\nan algorithm across decentralized entities holding their local data private.\nWireless mobile networks allow users to communicate with other fixed or mobile\nusers. The road traffic network represents an infrastructure-based\nconfiguration of a wireless mobile network where the Connected and Automated\nVehicles (CAV) represent the communicating entities. Applying FL in a wireless\nmobile network setting gives rise to a new threat in the mobile environment\nthat is very different from the traditional fixed networks. The threat is due\nto the intrinsic characteristics of the wireless medium and is caused by the\ncharacteristics of the vehicular networks such as high node-mobility and\nrapidly changing topology. Most cyber defense techniques depend on highly\nreliable and connected networks. This paper explores falsified information\nattacks, which target the FL process that is ongoing at the RSU. We identified\na number of attack strategies conducted by the malicious CAVs to disrupt the\ntraining of the global model in vehicular networks. We show that the attacks\nwere able to increase the convergence time and decrease the accuracy the model.\nWe demonstrate that our attacks bypass FL defense strategies in their primary\nform and highlight the need for novel poisoning resilience defense mechanisms\nin the wireless mobile setting of the future road networks.",
          "link": "http://arxiv.org/abs/2102.13256",
          "publishedOn": "2021-06-07T03:06:15.186Z",
          "wordCount": 692,
          "title": "Cybersecurity Threats in Connected and Automated Vehicles based Federated Learning Systems. (arXiv:2102.13256v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shyn_S/0/1/0/all/0/1\">Sung Kuk Shyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Donghee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwangsu Kim</a>",
          "description": "Client contribution evaluation, also known as data valuation, is a crucial\napproach in federated learning(FL) for client selection and incentive\nallocation. However, due to restrictions of accessibility of raw data, only\nlimited information such as local weights and local data size of each client is\nopen for quantifying the client contribution. Using data size from available\ninformation, we introduce an empirical evaluation method called Federated\nClient Contribution Evaluation through Accuracy Approximation(FedCCEA). This\nmethod builds the Accuracy Approximation Model(AAM), which estimates a\nsimulated test accuracy using inputs of sampled data size and extracts the\nclients' data quality and data size to measure client contribution. FedCCEA\nstrengthens some advantages: (1) enablement of data size selection to the\nclients, (2) feasible evaluation time regardless of the number of clients, and\n(3) precise estimation in non-IID settings. We demonstrate the superiority of\nFedCCEA compared to previous methods through several experiments: client\ncontribution distribution, client removal, and robustness test to partial\nparticipation.",
          "link": "http://arxiv.org/abs/2106.02310",
          "publishedOn": "2021-06-07T03:06:15.169Z",
          "wordCount": 607,
          "title": "FedCCEA : A Practical Approach of Client Contribution Evaluation for Federated Learning. (arXiv:2106.02310v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02528",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wal_M/0/1/0/all/0/1\">Michael D. Vander Wal</a> (1), <a href=\"http://arxiv.org/find/physics/1/au:+McClarren_R/0/1/0/all/0/1\">Ryan G. McClarren</a> (1), <a href=\"http://arxiv.org/find/physics/1/au:+Humbird_K/0/1/0/all/0/1\">Kelli D. Humbird</a> (2) ((1) University of Notre Dame, (2) Lawrence Livermore National Laboratory)",
          "description": "Simulations of high energy density physics are expensive in terms of\ncomputational resources. In particular, the computation of opacities of\nplasmas, which are needed to accurately compute radiation transport in the\nnon-local thermal equilibrium (NLTE) regime, are expensive to the point of\neasily requiring multiple times the sum-total compute time of all other\ncomponents of the simulation. As such, there is great interest in finding ways\nto accelerate NLTE computations. Previous work has demonstrated that a\ncombination of fully-connected autoencoders and a deep jointly-informed neural\nnetwork (DJINN) can successfully replace the standard NLTE calculations for the\nopacity of krypton. This work expands this idea to multiple elements in\ndemonstrating that individual surrogate models can be also be generated for\nother elements with the focus being on creating autoencoders that can\naccurately encode and decode the absorptivity and emissivity spectra.\nFurthermore, this work shows that multiple elements across a large range of\natomic numbers can be combined into a single autoencoder when using a\nconvolutional autoencoder while maintaining accuracy that is comparable to\nindividual fully-connected autoencoders. Lastly, it is demonstrated that DJINN\ncan effectively learn the latent space of a convolutional autoencoder that can\nencode multiple elements allowing the combination to effectively function as a\nsurrogate model.",
          "link": "http://arxiv.org/abs/2106.02528",
          "publishedOn": "2021-06-07T03:06:15.163Z",
          "wordCount": 703,
          "title": "Neural Network Surrogate Models for Absorptivity and Emissivity Spectra of Multiple Elements. (arXiv:2106.02528v1 [physics.plasm-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1\">Alex D&#xed;az</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1\">Damian Steele</a>",
          "description": "We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.",
          "link": "http://arxiv.org/abs/2106.02213",
          "publishedOn": "2021-06-07T03:06:15.157Z",
          "wordCount": 524,
          "title": "Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1\">Amir Hossein Akhavan Rahnama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butepage_J/0/1/0/all/0/1\">Judith Butepage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geurts_P/0/1/0/all/0/1\">Pierre Geurts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bostrom_H/0/1/0/all/0/1\">Henrik Bostrom</a>",
          "description": "Explanation techniques are commonly evaluated using human-grounded methods,\nlimiting the possibilities for large-scale evaluations and rapid progress in\nthe development of new techniques. We propose a functionally-grounded\nevaluation procedure for local model-agnostic explanation techniques. In our\napproach, we generate ground truth for explanations when the black-box model is\nLogistic Regression and Gaussian Naive Bayes and compare how similar each\nexplanation is to the extracted ground truth. In our empirical study,\nexplanations of Local Interpretable Model-agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Local Permutation Importance (LPI) are\ncompared in terms of how similar they are to the extracted ground truth. In the\ncase of Logistic Regression, we find that the performance of the explanation\ntechniques is highly dependent on the normalization of the data. In contrast,\nLocal Permutation Importance outperforms the other techniques on Naive Bayes,\nirrespective of normalization. We hope that this work lays the foundation for\nfurther research into functionally-grounded evaluation methods for explanation\ntechniques.",
          "link": "http://arxiv.org/abs/2106.02488",
          "publishedOn": "2021-06-07T03:06:15.152Z",
          "wordCount": 599,
          "title": "Evaluation of Local Model-Agnostic Explanations Using Ground Truth. (arXiv:2106.02488v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:15.145Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saito_M/0/1/0/all/0/1\">Masahiko Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kishimoto_T/0/1/0/all/0/1\">Tomoe Kishimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaneta_Y/0/1/0/all/0/1\">Yuya Kaneta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Itoh_T/0/1/0/all/0/1\">Taichi Itoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umeda_Y/0/1/0/all/0/1\">Yoshiaki Umeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_J/0/1/0/all/0/1\">Junichi Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iiyama_Y/0/1/0/all/0/1\">Yutaro Iiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawada_R/0/1/0/all/0/1\">Ryu Sawada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terashi_K/0/1/0/all/0/1\">Koji Terashi</a>",
          "description": "The usefulness and value of Multi-step Machine Learning (ML), where a task is\norganized into connected sub-tasks with known intermediate inference goals, as\nopposed to a single large model learned end-to-end without intermediate\nsub-tasks, is presented. Pre-optimized ML models are connected and better\nperformance is obtained by re-optimizing the connected one. The selection of an\nML model from several small ML model candidates for each sub-task has been\nperformed by using the idea based on Neural Architecture Search (NAS). In this\npaper, Differentiable Architecture Search (DARTS) and Single Path One-Shot NAS\n(SPOS-NAS) are tested, where the construction of loss functions is improved to\nkeep all ML models smoothly learning. Using DARTS and SPOS-NAS as an\noptimization and selection as well as the connections for multi-step machine\nlearning systems, we find that (1) such a system can quickly and successfully\nselect highly performant model combinations, and (2) the selected models are\nconsistent with baseline algorithms, such as grid search, and their outputs are\nwell controlled.",
          "link": "http://arxiv.org/abs/2106.02301",
          "publishedOn": "2021-06-07T03:06:15.138Z",
          "wordCount": 594,
          "title": "Event Classification with Multi-step Machine Learning. (arXiv:2106.02301v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1\">Elizabeth Excell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>",
          "description": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.",
          "link": "http://arxiv.org/abs/2106.02183",
          "publishedOn": "2021-06-07T03:06:15.120Z",
          "wordCount": 624,
          "title": "Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">X.Y. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papyan_V/0/1/0/all/0/1\">Vardan Papyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donoho_D/0/1/0/all/0/1\">David L. Donoho</a>",
          "description": "Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called\nNeural Collapse (NC) that occurs pervasively in today's deep net training\nparadigm of driving cross-entropy loss towards zero. In this phenomenon, the\nlast-layer features collapse to their class-means, both the classifiers and\nclass-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the\nbehavior of the last-layer classifier converges to that of the\nnearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.\n[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by\nreplacing the hard-to-study cross-entropy by the more tractable mean squared\nerror (MSE) loss. But, these works stopped short of demonstrating the empirical\nreality of MSE-NC on benchmark datasets and canonical networks-as had been done\nin Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we\nestablish the empirical reality of MSE-NC by reporting experimental\nobservations for three prototypical networks and five canonical datasets with\ncode for reproducing NC. Following this, we develop three main contributions\ninspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE\nloss into (A) a term assuming the last-layer classifier is exactly the\nleast-squares or Webb and Lowe [1990] classifier and (B) a term capturing the\ndeviation from this least-squares classifier. Secondly, we exhibit experiments\non canonical datasets and networks demonstrating that, during training,\nterm-(B) is negligible. This motivates a new theoretical construct: the central\npath, where the linear classifier stays MSE-optimal-for the given feature\nactivations-throughout the dynamics. Finally, through our study of continually\nrenormalized gradient flow along the central path, we produce closed-form\ndynamics that predict full Neural Collapse in an unconstrained features model.",
          "link": "http://arxiv.org/abs/2106.02073",
          "publishedOn": "2021-06-07T03:06:15.112Z",
          "wordCount": 747,
          "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path. (arXiv:2106.02073v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Lewis Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1\">Joost van Amersfoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haiwen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "ResNets constrained to be bi-Lipschitz, that is, approximately distance\npreserving, have been a crucial component of recently proposed techniques for\ndeterministic uncertainty quantification in neural models. We show that\ntheoretical justifications for recent regularisation schemes trying to enforce\nsuch a constraint suffer from a crucial flaw -- the theoretical link between\nthe regularisation scheme used and bi-Lipschitzness is only valid under\nconditions which do not hold in practice, rendering existing theory of limited\nuse, despite the strong empirical performance of these models. We provide a\ntheoretical explanation for the effectiveness of these regularisation schemes\nusing a frequency analysis perspective, showing that under mild conditions\nthese schemes will enforce a lower Lipschitz bound on the low-frequency\nprojection of images. We then provide empirical evidence supporting our\ntheoretical claims, and perform further experiments which demonstrate that our\nbroader conclusions appear to hold when some of the mathematical assumptions of\nour proof are relaxed, corresponding to the setup used in prior work. In\naddition, we present a simple constructive algorithm to search for counter\nexamples to the distance preservation condition, and discuss possible\nimplications of our theory for future model design.",
          "link": "http://arxiv.org/abs/2106.02469",
          "publishedOn": "2021-06-07T03:06:15.106Z",
          "wordCount": 642,
          "title": "Can convolutional ResNets approximately preserve input distances? A frequency analysis perspective. (arXiv:2106.02469v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02315",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hamadeh_N/0/1/0/all/0/1\">Nizar Hamadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karouni_A/0/1/0/all/0/1\">Ali Karouni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farhat_Z/0/1/0/all/0/1\">Zeinab Farhat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghor_H/0/1/0/all/0/1\">Hussein El Ghor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghor_M/0/1/0/all/0/1\">Mohamad El Ghor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Katea_I/0/1/0/all/0/1\">Israa Katea</a>",
          "description": "Intelligent transport systems have efficiently and effectively proved\nthemselves in settling up the problem of traffic congestion around the world.\nThe multi-agent based transportation system is one of the most important\nintelligent transport systems, which represents an interaction among the\nneighbouring vehicles, drivers, roads, infrastructure and vehicles. In this\npaper, two traffic management models have been created to mitigate congestion\nand to ensure that emergency vehicles arrive as quickly as possible. A\ntool-chain SUMO-JADE is employed to create a microscopic simulation symbolizing\nthe interactions of traffic. The simulation model has showed a significant\nreduction of at least 50% in the average time delay and thus a real improvement\nin the entire journey time.",
          "link": "http://arxiv.org/abs/2106.02315",
          "publishedOn": "2021-06-07T03:06:15.100Z",
          "wordCount": 554,
          "title": "Intelligent Transportation Systems to Mitigate Road Traffic Congestion. (arXiv:2106.02315v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/1905.02515",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1\">Kai Puolam&#xe4;ki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1\">Emilia Oikarinen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1\">Andreas Henelius</a>",
          "description": "Efficient explorative data analysis systems must take into account both what\na user knows and wants to know. This paper proposes a principled framework for\ninteractive visual exploration of relations in data, through views most\ninformative given the user's current knowledge and objectives. The user can\ninput pre-existing knowledge of relations in the data and also formulate\nspecific exploration interests, which are then taken into account in the\nexploration. The idea is to steer the exploration process towards the interests\nof the user, instead of showing uninteresting or already known relations. The\nuser's knowledge is modelled by a distribution over data sets parametrised by\nsubsets of rows and columns of data, called tile constraints. We provide a\ncomputationally efficient implementation of this concept based on constrained\nrandomisation. Furthermore, we describe a novel dimensionality reduction method\nfor finding the views most informative to the user, which at the limit of no\nbackground knowledge and with generic objectives reduces to PCA. We show that\nthe method is suitable for interactive use and is robust to noise, outperforms\nstandard projection pursuit visualisation methods, and gives understandable and\nuseful results in analysis of real-world data. We provide an open-source\nimplementation of the framework.",
          "link": "http://arxiv.org/abs/1905.02515",
          "publishedOn": "2021-06-07T03:06:15.084Z",
          "wordCount": 663,
          "title": "Guided Visual Exploration of Relations in Data Sets. (arXiv:1905.02515v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anji Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>",
          "description": "Probabilistic Circuits (PCs) are a promising avenue for probabilistic\nmodeling. They combine advantages of probabilistic graphical models (PGMs) with\nthose of neural networks (NNs). Crucially, however, they are tractable\nprobabilistic models, supporting efficient and exact computation of many\nprobabilistic inference queries, such as marginals and MAP. Further, since PCs\nare structured computation graphs, they can take advantage of\ndeep-learning-style parameter updates, which greatly improves their\nscalability. However, this innovation also makes PCs prone to overfitting,\nwhich has been observed in many standard benchmarks. Despite the existence of\nabundant regularization techniques for both PGMs and NNs, they are not\neffective enough when applied to PCs. Instead, we re-think regularization for\nPCs and propose two intuitive techniques, data softening and entropy\nregularization, that both take advantage of PCs' tractability and still have an\nefficient implementation as a computation graph. Specifically, data softening\nprovides a principled way to add uncertainty in datasets in closed form, which\nimplicitly regularizes PC parameters. To learn parameters from a softened\ndataset, PCs only need linear time by virtue of their tractability. In entropy\nregularization, the exact entropy of the distribution encoded by a PC can be\nregularized directly, which is again infeasible for most other density\nestimation models. We show that both methods consistently improve the\ngeneralization performance of a wide variety of PCs. Moreover, when paired with\na simple PC structure, we achieved state-of-the-art results on 10 out of 20\nstandard discrete density estimation benchmarks.",
          "link": "http://arxiv.org/abs/2106.02264",
          "publishedOn": "2021-06-07T03:06:15.078Z",
          "wordCount": 654,
          "title": "Tractable Regularization of Probabilistic Circuits. (arXiv:2106.02264v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1\">Larissa T. Triess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1\">Mariella Dreissig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1\">Christoph B. Rist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.",
          "link": "http://arxiv.org/abs/2106.02377",
          "publishedOn": "2021-06-07T03:06:15.072Z",
          "wordCount": 642,
          "title": "A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuran Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yitong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng Wu</a>",
          "description": "Data augmentation is widely known as a simple yet surprisingly effective\ntechnique for regularizing deep networks. Conventional data augmentation\nschemes, e.g., flipping, translation or rotation, are low-level,\ndata-independent and class-agnostic operations, leading to limited diversity\nfor augmented samples. To this end, we propose a novel semantic data\naugmentation algorithm to complement traditional approaches. The proposed\nmethod is inspired by the intriguing property that deep networks are effective\nin learning linearized features, i.e., certain directions in the deep feature\nspace correspond to meaningful semantic transformations, e.g., changing the\nbackground or view angle of an object. Based on this observation, translating\ntraining samples along many such directions in the feature space can\neffectively augment the dataset for more diversity. To implement this idea, we\nfirst introduce a sampling based method to obtain semantically meaningful\ndirections efficiently. Then, an upper bound of the expected cross-entropy (CE)\nloss on the augmented training set is derived by assuming the number of\naugmented samples goes to infinity, yielding a highly efficient algorithm. In\nfact, we show that the proposed implicit semantic data augmentation (ISDA)\nalgorithm amounts to minimizing a novel robust CE loss, which adds minimal\nextra computational cost to a normal training procedure. In addition to\nsupervised learning, ISDA can be applied to semi-supervised learning tasks\nunder the consistency regularization framework, where ISDA amounts to\nminimizing the upper bound of the expected KL-divergence between the augmented\nfeatures and the original features. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (e.g., ResNets\nand DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,\nImageNet, and Cityscapes.",
          "link": "http://arxiv.org/abs/2007.10538",
          "publishedOn": "2021-06-07T03:06:15.065Z",
          "wordCount": 781,
          "title": "Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1\">Ishaq Aden-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashtiani_H/0/1/0/all/0/1\">Hassan Ashtiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liaw_C/0/1/0/all/0/1\">Christopher Liaw</a>",
          "description": "We consider the problem of learning mixtures of Gaussians under the\nconstraint of approximate differential privacy. We prove that\n$\\widetilde{O}(k^2 d \\log^{3/2}(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are\nsufficient to learn a mixture of $k$ axis-aligned Gaussians in $\\mathbb{R}^d$\nto within total variation distance $\\alpha$ while satisfying $(\\varepsilon,\n\\delta)$-differential privacy. This is the first result for privately learning\nmixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If\nthe covariance matrices of each of the Gaussians is the identity matrix, we\nshow that $\\widetilde{O}(kd/\\alpha^2 + kd \\log(1/\\delta) / \\alpha \\varepsilon)$\nsamples are sufficient.\n\nRecently, the \"local covering\" technique of Bun, Kamath, Steinke, and Wu has\nbeen successfully used for privately learning high-dimensional Gaussians with a\nknown covariance matrix and extended to privately learning general\nhigh-dimensional Gaussians by Aden-Ali, Ashtiani, and Kamath. Given these\npositive results, this approach has been proposed as a promising direction for\nprivately learning mixtures of Gaussians. Unfortunately, we show that this is\nnot possible.\n\nWe design a new technique for privately learning mixture distributions. A\nclass of distributions $\\mathcal{F}$ is said to be list-decodable if there is\nan algorithm that, given \"heavily corrupted\" samples from $f\\in \\mathcal{F}$,\noutputs a list of distributions, $\\widehat{\\mathcal{F}}$, such that one of the\ndistributions in $\\widehat{\\mathcal{F}}$ approximates $f$. We show that if\n$\\mathcal{F}$ is privately list-decodable, then we can privately learn mixtures\nof distributions in $\\mathcal{F}$. Finally, we show axis-aligned Gaussian\ndistributions are privately list-decodable, thereby proving mixtures of such\ndistributions are privately learnable.",
          "link": "http://arxiv.org/abs/2106.02162",
          "publishedOn": "2021-06-07T03:06:15.059Z",
          "wordCount": 663,
          "title": "Privately Learning Mixtures of Axis-Aligned Gaussians. (arXiv:2106.02162v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1\">Shufeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guevarra_D/0/1/0/all/0/1\">Dan Guevarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregoire_J/0/1/0/all/0/1\">John M. Gregoire</a>",
          "description": "The adoption of machine learning in materials science has rapidly transformed\nmaterials property prediction. Hurdles limiting full capitalization of recent\nadvancements in machine learning include the limited development of methods to\nlearn the underlying interactions of multiple elements, as well as the\nrelationships among multiple properties, to facilitate property prediction in\nnew composition spaces. To address these issues, we introduce the Hierarchical\nCorrelation Learning for Multi-property Prediction (H-CLMP) framework that\nseamlessly integrates (i) prediction using only a material's composition, (ii)\nlearning and exploitation of correlations among target properties in\nmulti-target regression, and (iii) leveraging training data from tangential\ndomains via generative transfer learning. The model is demonstrated for\nprediction of spectral optical absorption of complex metal oxides spanning 69\n3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear\ncomposition-property relationships in composition spaces for which no training\ndata is available, which broadens the purview of machine learning to the\ndiscovery of materials with exceptional properties. This achievement results\nfrom the principled integration of latent embedding learning, property\ncorrelation learning, generative transfer learning, and attention models. The\nbest performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))\nwherein a generative adversarial network is trained on computational density of\nstates data and deployed in the target domain to augment prediction of optical\nabsorption from composition. H-CLMP(T) aggregates multiple knowledge sources\nwith a framework that is well-suited for multi-target regression across the\nphysical sciences.",
          "link": "http://arxiv.org/abs/2106.02225",
          "publishedOn": "2021-06-07T03:06:15.053Z",
          "wordCount": 674,
          "title": "Materials Representation and Transfer Learning for Multi-Property Prediction. (arXiv:2106.02225v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1\">Thangapavithraa Balaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1\">Patrick Blies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1\">Georg G&#xf6;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1\">Raphael Mitsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1\">Marcel Wasserer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Torsten Sch&#xf6;n</a>",
          "description": "This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.",
          "link": "http://arxiv.org/abs/2106.02328",
          "publishedOn": "2021-06-07T03:06:15.045Z",
          "wordCount": 574,
          "title": "Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qinghua Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>",
          "description": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.",
          "link": "http://arxiv.org/abs/2106.02401",
          "publishedOn": "2021-06-07T03:06:15.039Z",
          "wordCount": 605,
          "title": "Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Learning to predict missing links is important for many graph-based\napplications. Existing methods were designed to learn the observed association\nbetween two sets of variables: (1) the observed graph structure and (2) the\nexistence of link between a pair of nodes. However, the causal relationship\nbetween these variables was ignored and we visit the possibility of learning it\nby simply asking a counterfactual question: \"would the link exist or not if the\nobserved graph structure became different?\" To answer this question by causal\ninference, we consider the information of the node pair as context, global\ngraph structural properties as treatment, and link existence as outcome. In\nthis work, we propose a novel link prediction method that enhances graph\nlearning by the counterfactual inference. It creates counterfactual links from\nthe observed ones, and our method learns representations from both of them.\nExperiments on a number of benchmark datasets show that our proposed method\nachieves the state-of-the-art performance on link prediction.",
          "link": "http://arxiv.org/abs/2106.02172",
          "publishedOn": "2021-06-07T03:06:15.009Z",
          "wordCount": 580,
          "title": "Counterfactual Graph Learning for Link Prediction. (arXiv:2106.02172v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1\">Th&#xe9;o Barollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "We target the problem of provably computing the equivalence between two\ncomplex expression trees. To this end, we formalize the problem of equivalence\nbetween two such programs as finding a set of semantics-preserving rewrite\nrules from one into the other, such that after the rewrite the two programs are\nstructurally identical, and therefore trivially equivalent.We then develop a\ngraph-to-sequence neural network system for program equivalence, trained to\nproduce such rewrite sequences from a carefully crafted automatic example\ngeneration algorithm. We extensively evaluate our system on a rich multi-type\nlinear algebra expression language, using arbitrary combinations of 100+\ngraph-rewriting axioms of equivalence. Our machine learning system guarantees\ncorrectness for all true negatives, and ensures 0 false positive by design. It\noutputs via inference a valid proof of equivalence for 93% of the 10,000\nequivalent expression pairs isolated for testing, using up to 50-term\nexpressions. In all cases, the validity of the sequence produced and therefore\nthe provable assertion of program equivalence is always computable, in\nnegligible time.",
          "link": "http://arxiv.org/abs/2106.02452",
          "publishedOn": "2021-06-07T03:06:14.983Z",
          "wordCount": 614,
          "title": "Proving Equivalence Between Complex Expressions Using Graph-to-Sequence Neural Models. (arXiv:2106.02452v1 [cs.PL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "The representation of functions by artificial neural networks depends on a\nlarge number of parameters in a non-linear fashion. Suitable parameters of\nthese are found by minimizing a 'loss functional', typically by stochastic\ngradient descent (SGD) or an advanced SGD-based algorithm.\n\nIn a continuous time model for SGD with noise that follows the 'machine\nlearning scaling', we show that in a certain noise regime, the optimization\nalgorithm prefers 'flat' minima of the objective function in a sense which is\ndifferent from the flat minimum selection of continuous time SGD with\nhomogeneous noise.",
          "link": "http://arxiv.org/abs/2106.02588",
          "publishedOn": "2021-06-07T03:06:14.972Z",
          "wordCount": 541,
          "title": "Stochastic gradient descent with noise of machine learning type. Part II: Continuous time analysis. (arXiv:2106.02588v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldroubi_A/0/1/0/all/0/1\">Akram Aldroubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Rocio Diaz Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medri_I/0/1/0/all/0/1\">Ivan Medri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_G/0/1/0/all/0/1\">Gustavo K. Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thareja_S/0/1/0/all/0/1\">Sumati Thareja</a>",
          "description": "This paper presents a new mathematical signal transform that is especially\nsuitable for decoding information related to non-rigid signal displacements. We\nprovide a measure theoretic framework to extend the existing Cumulative\nDistribution Transform [ACHA 45 (2018), no. 3, 616-641] to arbitrary (signed)\nsignals on $\\overline{\\mathbb{R}}$. We present both forward (analysis) and\ninverse (synthesis) formulas for the transform, and describe several of its\nproperties including translation, scaling, convexity, linear separability and\nothers. Finally, we describe a metric in transform space, and demonstrate the\napplication of the transform in classifying (detecting) signals under random\ndisplacements.",
          "link": "http://arxiv.org/abs/2106.02146",
          "publishedOn": "2021-06-07T03:06:14.964Z",
          "wordCount": 543,
          "title": "The Signed Cumulative Distribution Transform for 1-D Signal Analysis and Classification. (arXiv:2106.02146v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1\">Wasim Huleihel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>",
          "description": "The fuzzy or soft $k$-means objective is a popular generalization of the\nwell-known $k$-means problem, extending the clustering capability of the\n$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.\nIn this paper, we propose a semi-supervised active clustering framework, where\nthe learner is allowed to interact with an oracle (domain expert), asking for\nthe similarity between a certain set of chosen items. We study the query and\ncomputational complexities of clustering in this framework. We prove that\nhaving a few of such similarity queries enables one to get a polynomial-time\napproximation algorithm to an otherwise conjecturally NP-hard problem. In\nparticular, we provide probabilistic algorithms for fuzzy clustering in this\nsetting that asks $O(\\mathsf{poly}(k)\\log n)$ similarity queries and run with\npolynomial-time-complexity, where $n$ is the number of items. The fuzzy\n$k$-means objective is nonconvex, with $k$-means as a special case, and is\nequivalent to some other generic nonconvex problem such as non-negative matrix\nfactorization. The ubiquitous Lloyd-type algorithms (or,\nexpectation-maximization algorithm) can get stuck at a local minima. Our\nresults show that by making few similarity queries, the problem becomes easier\nto solve. Finally, we test our algorithms over real-world datasets, showing\ntheir effectiveness in real-world applications.",
          "link": "http://arxiv.org/abs/2106.02212",
          "publishedOn": "2021-06-07T03:06:14.945Z",
          "wordCount": 632,
          "title": "Fuzzy Clustering with Similarity Queries. (arXiv:2106.02212v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1\">Emna Baccour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1\">Fatima Haouari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1\">Aiman Erbad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Amr Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1\">Kashif Bilal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1\">Mohsen Guizani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1\">Mounir Hamdi</a>",
          "description": "Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.",
          "link": "http://arxiv.org/abs/2106.02420",
          "publishedOn": "2021-06-07T03:06:14.933Z",
          "wordCount": 667,
          "title": "An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1\">Alexandre Pich&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1\">Joseph Marino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1\">Gian Maria Marconi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Target networks are at the core of recent success in Reinforcement Learning.\nThey stabilize the training by using old parameters to estimate the $Q$-values,\nbut this also limits the propagation of newly-encountered rewards which could\nultimately slow down the training. In this work, we propose an alternative\ntraining method based on functional regularization which does not have this\ndeficiency. Unlike target networks, our method uses up-to-date parameters to\nestimate the target $Q$-values, thereby speeding up training while maintaining\nstability. Surprisingly, in some cases, we can show that target networks are a\nspecial, restricted type of functional regularizers. Using this approach, we\nshow empirical improvements in sample efficiency and performance across a range\nof Atari and simulated robotics environments.",
          "link": "http://arxiv.org/abs/2106.02613",
          "publishedOn": "2021-06-07T03:06:14.915Z",
          "wordCount": 551,
          "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization. (arXiv:2106.02613v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1\">Nicholas Choma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1\">Mikaela Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1\">&#xc9;rica T. Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1\">Ver&#xf3;nica G. Melesse Vergara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1\">Thomas S. Brettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1\">Martha S. Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1\">Peter Nugent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1\">Daniel A. Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>",
          "description": "We developed Distilled Graph Attention Policy Networks (DGAPNs), a\ncuriosity-driven reinforcement learning model to generate novel\ngraph-structured chemical representations that optimize user-defined objectives\nby efficiently navigating a physically constrained domain. The framework is\nexamined on the task of generating molecules that are designed to bind,\nnoncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial\nGraph Attention Network (sGAT) that leverages self-attention over both node and\nedge attributes as well as encoding spatial structure -- this capability is of\nconsiderable interest in areas such as molecular and synthetic biology and drug\ndiscovery. An attentional policy network is then introduced to learn decision\nrules for a dynamic, fragment-based chemical environment, and state-of-the-art\npolicy gradient techniques are employed to train the network with enhanced\nstability. Exploration is efficiently encouraged by incorporating innovation\nreward bonuses learned and proposed by random network distillation. In\nexperiments, our framework achieved outstanding results compared to\nstate-of-the-art algorithms, while increasing the diversity of proposed\nmolecules and reducing the complexity of paths to chemical synthesis.",
          "link": "http://arxiv.org/abs/2106.02190",
          "publishedOn": "2021-06-07T03:06:14.892Z",
          "wordCount": 682,
          "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pravilov_M/0/1/0/all/0/1\">Mikhail Pravilov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogomolov_E/0/1/0/all/0/1\">Egor Bogomolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golubev_Y/0/1/0/all/0/1\">Yaroslav Golubev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bryksin_T/0/1/0/all/0/1\">Timofey Bryksin</a>",
          "description": "A lot of problems in the field of software engineering - bug fixing, commit\nmessage generation, etc. - require analyzing not only the code itself but\nspecifically code changes. Applying machine learning models to these tasks\nrequires us to create numerical representations of the changes, i.e.\nembeddings. Recent studies demonstrate that the best way to obtain these\nembeddings is to pre-train a deep neural network in an unsupervised manner on a\nlarge volume of unlabeled data and then further fine-tune it for a specific\ntask.\n\nIn this work, we propose an approach for obtaining such embeddings of code\nchanges during pre-training and evaluate them on two different downstream tasks\n- applying changes to code and commit message generation. The pre-training\nconsists of the model learning to apply the given change (an edit sequence) to\nthe code in a correct way, and therefore requires only the code change itself.\nTo increase the quality of the obtained embeddings, we only consider the\nchanged tokens in the edit sequence. In the task of applying code changes, our\nmodel outperforms the model that uses full edit sequences by 5.9 percentage\npoints in accuracy. As for the commit message generation, our model\ndemonstrated the same results as supervised models trained for this specific\ntask, which indicates that it can encode code changes well and can be improved\nin the future by pre-training on a larger dataset of easily gathered code\nchanges.",
          "link": "http://arxiv.org/abs/2106.02087",
          "publishedOn": "2021-06-07T03:06:14.886Z",
          "wordCount": 669,
          "title": "Unsupervised Learning of General-Purpose Embeddings for Code Changes. (arXiv:2106.02087v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1\">Osman Semih Kayhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1\">Bart Vredebregt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.",
          "link": "http://arxiv.org/abs/2106.02523",
          "publishedOn": "2021-06-07T03:06:14.880Z",
          "wordCount": 570,
          "title": "Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yikun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_M/0/1/0/all/0/1\">Manan Gandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovakimyan_N/0/1/0/all/0/1\">Naira Hovakimyan</a>",
          "description": "A reinforcement learning (RL) policy trained in a nominal environment could\nfail in a new/perturbed environment due to the existence of dynamic variations.\nExisting robust methods try to obtain a fixed policy for all envisioned dynamic\nvariation scenarios through robust or adversarial training. These methods could\nlead to conservative performance due to emphasis on the worst case, and often\ninvolve tedious modifications to the training environment. We propose an\napproach to robustifying a pre-trained non-robust RL policy with\n$\\mathcal{L}_1$ adaptive control. Leveraging the capability of an\n$\\mathcal{L}_1$ control law in the fast estimation of and active compensation\nfor dynamic variations, our approach can significantly improve the robustness\nof an RL policy trained in a standard (i.e., non-robust) way, either in a\nsimulator or in the real world. Numerical experiments are provided to validate\nthe efficacy of the proposed approach.",
          "link": "http://arxiv.org/abs/2106.02249",
          "publishedOn": "2021-06-07T03:06:14.874Z",
          "wordCount": 574,
          "title": "Robustifying Reinforcement Learning Policies with $\\mathcal{L}_1$ Adaptive Control. (arXiv:2106.02249v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1\">Geeticka Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1\">Brian Tse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>",
          "description": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via moral philosophy's definition of social good, propose a\nframework to evaluate NLP tasks' direct and indirect real-world impact, and\nadopt the methodology of global priorities research to identify priority causes\nfor NLP research. Finally, we use our theoretical framework to provide some\npractical guidelines for future NLP research for social good. Our data and\ncodes are available at this http URL",
          "link": "http://arxiv.org/abs/2106.02359",
          "publishedOn": "2021-06-07T03:06:14.867Z",
          "wordCount": 603,
          "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubost_F/0/1/0/all/0/1\">Florian Dubost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_K/0/1/0/all/0/1\">Khaled Kamal Saab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_E/0/1/0/all/0/1\">Erin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daniel Yang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pike_M/0/1/0/all/0/1\">Max Pike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Siddharth Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhaskhar_N/0/1/0/all/0/1\">Nandita Bhaskhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Messer_C/0/1/0/all/0/1\">Christopher Lee-Messer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Optimization plays a key role in the training of deep neural networks.\nDeciding when to stop training can have a substantial impact on the performance\nof the network during inference. Under certain conditions, the generalization\nerror can display a double descent pattern during training: the learning curve\nis non-monotonic and seemingly diverges before converging again after\nadditional epochs. This optimization pattern can lead to early stopping\nprocedures to stop training before the second convergence and consequently\nselect a suboptimal set of parameters for the network, with worse performance\nduring inference. In this work, in addition to confirming that double descent\noccurs with small datasets and noisy labels as evidenced by others, we show\nthat noisy labels must be present both in the training and generalization sets\nto observe a double descent pattern. We also show that the learning rate has an\ninfluence on double descent, and study how different optimizers and optimizer\nparameters influence the apparition of double descent. Finally, we show that\nincreasing the learning rate can create an aliasing effect that masks the\ndouble descent pattern without suppressing it. We study this phenomenon through\nextensive experiments on variants of CIFAR-10 and show that they translate to a\nreal world application: the forecast of seizure events in epileptic patients\nfrom continuous electroencephalographic recordings.",
          "link": "http://arxiv.org/abs/2106.02100",
          "publishedOn": "2021-06-07T03:06:14.849Z",
          "wordCount": 656,
          "title": "Double Descent Optimization Pattern and Aliasing: Caveats of Noisy Labels. (arXiv:2106.02100v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalvit_A/0/1/0/all/0/1\">Anand Kalvit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1\">Assaf Zeevi</a>",
          "description": "One of the key drivers of complexity in the classical (stochastic)\nmulti-armed bandit (MAB) problem is the difference between mean rewards in the\ntop two arms, also known as the instance gap. The celebrated Upper Confidence\nBound (UCB) policy is among the simplest optimism-based MAB algorithms that\nnaturally adapts to this gap: for a horizon of play n, it achieves optimal\nO(log n) regret in instances with \"large\" gaps, and a near-optimal O(\\sqrt{n\nlog n}) minimax regret when the gap can be arbitrarily \"small.\" This paper\nprovides new results on the arm-sampling behavior of UCB, leading to several\nimportant insights. Among these, it is shown that arm-sampling rates under UCB\nare asymptotically deterministic, regardless of the problem complexity. This\ndiscovery facilitates new sharp asymptotics and a novel alternative proof for\nthe O(\\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also\nprovides the first complete process-level characterization of the MAB problem\nunder UCB in the conventional diffusion scaling. Among other things, the\n\"small\" gap worst-case lens adopted in this paper also reveals profound\ndistinctions between the behavior of UCB and Thompson Sampling, such as an\n\"incomplete learning\" phenomenon characteristic of the latter.",
          "link": "http://arxiv.org/abs/2106.02126",
          "publishedOn": "2021-06-07T03:06:14.842Z",
          "wordCount": 625,
          "title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms. (arXiv:2106.02126v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahtalebi_S/0/1/0/all/0/1\">Soroosh Shahtalebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagnon_Audet_J/0/1/0/all/0/1\">Jean-Christophe Gagnon-Audet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laleh_T/0/1/0/all/0/1\">Touraj Laleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faramarzi_M/0/1/0/all/0/1\">Mojtaba Faramarzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "A major bottleneck in the real-world applications of machine learning models\nis their failure in generalizing to unseen domains whose data distribution is\nnot i.i.d to the training domains. This failure often stems from learning\nnon-generalizable features in the training domains that are spuriously\ncorrelated with the label of data. To address this shortcoming, there has been\na growing surge of interest in learning good explanations that are hard to\nvary, which is studied under the notion of Out-of-Distribution (OOD)\nGeneralization. The search for good explanations that are \\textit{invariant}\nacross different domains can be seen as finding local (global) minimas in the\nloss landscape that hold true across all of the training domains. In this\npaper, we propose a masking strategy, which determines a continuous weight\nbased on the agreement of gradients that flow in each edge of network, in order\nto control the amount of update received by the edge in each step of\noptimization. Particularly, our proposed technique referred to as \"Smoothed-AND\n(SAND)-masking\", not only validates the agreement in the direction of gradients\nbut also promotes the agreement among their magnitudes to further ensure the\ndiscovery of invariances across training domains. SAND-mask is validated over\nthe Domainbed benchmark for domain generalization and significantly improves\nthe state-of-the-art accuracy on the Colored MNIST dataset while providing\ncompetitive results on other domain generalization datasets.",
          "link": "http://arxiv.org/abs/2106.02266",
          "publishedOn": "2021-06-07T03:06:14.835Z",
          "wordCount": 666,
          "title": "SAND-mask: An Enhanced Gradient Masking Strategy for the Discovery of Invariances in Domain Generalization. (arXiv:2106.02266v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Plumb_G/0/1/0/all/0/1\">Gregory Plumb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Marco Tulio Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>",
          "description": "Machine learning models often use spurious patterns such as \"relying on the\npresence of a person to detect a tennis racket,\" which do not generalize. In\nthis work, we present an end-to-end pipeline for identifying and mitigating\nspurious patterns for image classifiers. We start by finding patterns such as\n\"the model's prediction for tennis racket changes 63% of the time if we hide\nthe people.\" Then, if a pattern is spurious, we mitigate it via a novel form of\ndata augmentation. We demonstrate that this approach identifies a diverse set\nof spurious patterns and that it mitigates them by producing a model that is\nboth more accurate on a distribution where the spurious pattern is not helpful\nand more robust to distribution shift.",
          "link": "http://arxiv.org/abs/2106.02112",
          "publishedOn": "2021-06-07T03:06:14.827Z",
          "wordCount": 543,
          "title": "Finding and Fixing Spurious Patterns with Explanations. (arXiv:2106.02112v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.02518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Many of the recent triumphs in machine learning are dependent on well-tuned\nhyperparameters. This is particularly prominent in reinforcement learning (RL)\nwhere a small change in the configuration can lead to failure. Despite the\nimportance of tuning hyperparameters, it remains expensive and is often done in\na naive and laborious way. A recent solution to this problem is Population\nBased Training (PBT) which updates both weights and hyperparameters in a single\ntraining run of a population of agents. PBT has been shown to be particularly\neffective in RL, leading to widespread use in the field. However, PBT lacks\ntheoretical guarantees since it relies on random heuristics to explore the\nhyperparameter space. This inefficiency means it typically requires vast\ncomputational resources, which is prohibitive for many small and medium sized\nlabs. In this work, we introduce the first provably efficient PBT-style\nalgorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to\nguide the search in an efficient way, making it possible to discover high\nperforming hyperparameter configurations with far fewer agents than typically\nrequired by PBT. We show in a series of RL experiments that PB2 is able to\nachieve high performance with a modest computational budget.",
          "link": "http://arxiv.org/abs/2002.02518",
          "publishedOn": "2021-06-07T03:06:14.822Z",
          "wordCount": 674,
          "title": "Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits. (arXiv:2002.02518v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1\">Fakhri Karray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>",
          "description": "This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.",
          "link": "http://arxiv.org/abs/2106.02154",
          "publishedOn": "2021-06-07T03:06:14.802Z",
          "wordCount": 598,
          "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shabka_Z/0/1/0/all/0/1\">Zacharaya Shabka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zervas_G/0/1/0/all/0/1\">Georgios Zervas</a>",
          "description": "Data centres (DCs) underline many prominent future technological trends such\nas distributed training of large scale machine learning models and\ninternet-of-things based platforms. DCs will soon account for over 3\\% of\nglobal energy demand, so efficient use of DC resources is essential. Robust DC\nnetworks (DCNs) are essential to form the large scale systems needed to handle\nthis demand, but can bottleneck how efficiently DC-server resources can be used\nwhen servers with insufficient connectivity between them cannot be jointly\nallocated to a job. However, allocating servers' resources whilst accounting\nfor their inter-connectivity maps to an NP-hard combinatorial optimisation\nproblem, and so is often ignored in DC resource management schemes. We present\nNara, a framework based on reinforcement learning (RL) and graph neural\nnetworks (GNN) to learn network-aware allocation policies that increase the\nnumber of requests allocated over time compared to previous methods. Unique to\nour solution is the use of a GNN to generate representations of server-nodes in\nthe DCN, which are then interpreted as actions by a RL policy-network which\nchooses from which servers resources will be allocated to incoming requests.\nNara is agnostic to the topology size and shape and is trained end-to-end. The\nmethod can accept up to 33\\% more requests than the best baseline when deployed\non DCNs with up to the order of $10\\times$ more compute nodes than the DCN seen\nduring training and is able to maintain its policy's performance on DCNs with\nthe order of $100\\times$ more servers than seen during training. It also\ngeneralises to unseen DCN topologies with varied network structure and unseen\nrequest distributions without re-training.",
          "link": "http://arxiv.org/abs/2106.02412",
          "publishedOn": "2021-06-07T03:06:14.795Z",
          "wordCount": 701,
          "title": "Nara: Learning Network-Aware Resource Allocation Algorithms for Cloud Data Centres. (arXiv:2106.02412v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02081",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thodoroff_P/0/1/0/all/0/1\">Pierre Thodoroff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lamacraft_A/0/1/0/all/0/1\">Austen Lamacraft</a>",
          "description": "The Schr\\\"odinger bridge problem (SBP) finds the most likely stochastic\nevolution between two probability distributions given a prior stochastic\nevolution. As well as applications in the natural sciences, problems of this\nkind have important applications in machine learning such as dataset alignment\nand hypothesis testing. Whilst the theory behind this problem is relatively\nmature, scalable numerical recipes to estimate the Schr\\\"odinger bridge remain\nan active area of research. We prove an equivalence between the SBP and maximum\nlikelihood estimation enabling direct application of successful machine\nlearning techniques. We propose a numerical procedure to estimate SBPs using\nGaussian process and demonstrate the practical usage of our approach in\nnumerical simulations and experiments.",
          "link": "http://arxiv.org/abs/2106.02081",
          "publishedOn": "2021-06-07T03:06:14.788Z",
          "wordCount": 544,
          "title": "Solving Schr\\\"odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02392",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Miladinovic_A/0/1/0/all/0/1\">Aleksandar Miladinovi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ajcevic_M/0/1/0/all/0/1\">Milo&#x161; Aj&#x10d;evi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siveri_G/0/1/0/all/0/1\">Giulia Siveri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liguori_L/0/1/0/all/0/1\">Laura Liguori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pascazio_L/0/1/0/all/0/1\">Lorenzo Pascazio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Accardo_A/0/1/0/all/0/1\">Agostino Accardo</a>",
          "description": "The accurate measurement of blood pressure (BP) is an important prerequisite\nfor the reliable diagnosis and efficient management of hypertension and other\nmedical conditions. Office Blood Pressure Measurement (OBP) is a technique\nperformed in-office with the sphygmomanometer, while Ambulatory Blood Pressure\nMonitoring (ABPM) is a technique that measures blood pressure during 24h. The\nBP fluctuations also depend on other factors such as physical activity,\ntemperature, mood, age, sex, any pathologies, a hormonal activity that may\nintrinsically influence the differences between OBP and ABPM. The aim of this\nstudy is to examine the possible influence of sex on the discrepancies between\nOBP and ABPM in 872 subjects with known or suspected hypertension. A\nsignificant correlation was observed between OBP and ABPM mean values\ncalculated during the day, night and 24h (ABPMday, ABPMnight, ABPM24h) in both\ngroups (p<0.0001). The main finding of this study is that no difference between\nsexes was observed in the relation between OBP and mean ABMP values except\nbetween systolic OBP and systolic ABPM during the night. In addition, this\nstudy showed a moderate correlation between BPs obtained with the two\napproaches with a great dispersion around the regression line which suggests\nthat the two approaches cannot be used interchangeably.",
          "link": "http://arxiv.org/abs/2106.02392",
          "publishedOn": "2021-06-07T03:06:14.782Z",
          "wordCount": 647,
          "title": "Ambulatory blood pressure monitoring versus office blood pressure measurement: Are there sex differences?. (arXiv:2106.02392v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02443",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1\">Kevin Kilgour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1\">Hassan Rom</a>",
          "description": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.",
          "link": "http://arxiv.org/abs/2106.02443",
          "publishedOn": "2021-06-07T03:06:14.775Z",
          "wordCount": 642,
          "title": "Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Canatar_A/0/1/0/all/0/1\">Abdulkadir Canatar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "In real word applications, data generating process for training a machine\nlearning model often differs from what the model encounters in the test stage.\nUnderstanding how and whether machine learning models generalize under such\ndistributional shifts have been a theoretical challenge. Here, we study\ngeneralization in kernel regression when the training and test distributions\nare different using methods from statistical physics. Using the replica method,\nwe derive an analytical formula for the out-of-distribution generalization\nerror applicable to any kernel and real datasets. We identify an overlap matrix\nthat quantifies the mismatch between distributions for a given kernel as a key\ndeterminant of generalization performance under distribution shift. Using our\nanalytical expressions we elucidate various generalization phenomena including\npossible improvement in generalization when there is a mismatch. We develop\nprocedures for optimizing training and test distributions for a given data\nbudget to find best and worst case generalizations under the shift. We present\napplications of our theory to real and synthetic datasets and for many kernels.\nWe compare results of our theory applied to Neural Tangent Kernel with\nsimulations of wide networks and show agreement. We analyze linear regression\nin further depth.",
          "link": "http://arxiv.org/abs/2106.02261",
          "publishedOn": "2021-06-07T03:06:14.755Z",
          "wordCount": 618,
          "title": "Out-of-Distribution Generalization in Kernel Regression. (arXiv:2106.02261v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1\">Dyah Adila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1\">Zach Zaiman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1\">Genevieve B. Melton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1\">Nicholas Ingraham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1\">Eric Murray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1\">Daniel Boley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1\">Sean Switzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John L. Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1\">Tadashi Allen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1\">Scott D. Steenburg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1\">Judy Wawira Gichoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1\">Erich Kummerfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1\">Christopher Tignanelli</a>",
          "description": "Importance: An artificial intelligence (AI)-based model to predict COVID-19\nlikelihood from chest x-ray (CXR) findings can serve as an important adjunct to\naccelerate immediate clinical decision making and improve clinical decision\nmaking. Despite significant efforts, many limitations and biases exist in\npreviously developed AI diagnostic models for COVID-19. Utilizing a large set\nof local and international CXR images, we developed an AI model with high\nperformance on temporal and external validation.\n\nConclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,\nbut not replacement, for clinical decision support of COVID-19 diagnosis, which\nlargely hinges on exposure history, signs, and symptoms. While AI-based tools\nhave not yet reached full diagnostic potential in COVID-19, they may still\noffer valuable information to clinicians taken into consideration along with\nclinical signs and symptoms.",
          "link": "http://arxiv.org/abs/2106.02118",
          "publishedOn": "2021-06-07T03:06:14.749Z",
          "wordCount": 670,
          "title": "A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yingtao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1\">Chikahiko Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses\non the object and style like other artwork researches. Such study has benefited\nfrom the renewed interest by the machine learning community in culturally\nimportant topics, leading to interdisciplinary works including collections of\nimages, quantitative approaches, and machine learning-based creativities. They,\nhowever, have several drawbacks, and it remains challenging to integrate these\nworks into a comprehensive view. To bridge this gap, we propose a holistic\napproach We first present a large-scale Ukiyo-e dataset with coherent semantic\nlabels and geometric annotations, then show its value in a quantitative study\nof Ukiyo-e paintings' object using these labels and annotations. We further\ndemonstrate the machine learning methods could help style study through soft\ncolor decomposition of Ukiyo-e, and finally provides joint insights into object\nand style by composing sketches and colors using colorization. Dataset\navailable at https://github.com/rois-codh/arc-ukiyoe-faces",
          "link": "http://arxiv.org/abs/2106.02267",
          "publishedOn": "2021-06-07T03:06:14.742Z",
          "wordCount": 584,
          "title": "Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Viswanath_V/0/1/0/all/0/1\">Vainavi Viswanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grannen_J/0/1/0/all/0/1\">Jennifer Grannen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1\">Priya Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1\">Brijen Thananjeyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1\">Ashwin Balakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novoseller_E/0/1/0/all/0/1\">Ellen Novoseller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichnowski_J/0/1/0/all/0/1\">Jeffrey Ichnowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskey_M/0/1/0/all/0/1\">Michael Laskey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>",
          "description": "Disentangling two or more cables requires many steps to remove crossings\nbetween and within cables. We formalize the problem of disentangling multiple\ncables and present an algorithm, Iterative Reduction Of Non-planar Multiple\ncAble kNots (IRON-MAN), that outputs robot actions to remove crossings from\nmulti-cable knotted structures. We instantiate this algorithm with a learned\nperception system, inspired by prior work in single-cable untying that given an\nimage input, can disentangle two-cable twists, three-cable braids, and knots of\ntwo or three cables, such as overhand, square, carrick bend, sheet bend, crown,\nand fisherman's knots. IRON-MAN keeps track of task-relevant keypoints\ncorresponding to target cable endpoints and crossings and iteratively\ndisentangles the cables by identifying and undoing crossings that are critical\nto knot structure. Using a da Vinci surgical robot, we experimentally evaluate\nthe effectiveness of IRON-MAN on untangling multi-cable knots of types that\nappear in the training data, as well as generalizing to novel classes of\nmulti-cable knots. Results suggest that IRON-MAN is effective in disentangling\nknots involving up to three cables with 80.5% success and generalizing to knot\ntypes that are not present during training, with cables of both distinct or\nidentical colors.",
          "link": "http://arxiv.org/abs/2106.02252",
          "publishedOn": "2021-06-07T03:06:14.737Z",
          "wordCount": 633,
          "title": "Disentangling Dense Multi-Cable Knots. (arXiv:2106.02252v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiuqin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>",
          "description": "We propose a deep switching state space model (DS$^3$M) for efficient\ninference and forecasting of nonlinear time series with irregularly switching\namong various regimes. The switching among regimes is captured by both discrete\nand continuous latent variables with recurrent neural networks. The model is\nestimated with variational inference using a reparameterization trick. We test\nthe approach on a variety of simulated and real datasets. In all cases, DS$^3$M\nachieves competitive performance compared to several state-of-the-art methods\n(e.g. GRU, SRNN, DSARF, SNLDS), with superior forecasting accuracy, convincing\ninterpretability of the discrete latent variables, and powerful representation\nof the continuous latent variables for different kinds of time series.\nSpecifically, the MAPE values increase by 0.09\\% to 15.71\\% against the\nsecond-best performing alternative models.",
          "link": "http://arxiv.org/abs/2106.02329",
          "publishedOn": "2021-06-07T03:06:14.730Z",
          "wordCount": 557,
          "title": "Deep Switching State Space Model (DS$^3$M) for Nonlinear Time Series Forecasting with Regime Switching. (arXiv:2106.02329v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1\">Tal Lancewicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segal_S/0/1/0/all/0/1\">Shahar Segal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1\">Tomer Koren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>",
          "description": "We study the stochastic Multi-Armed Bandit (MAB) problem with random delays\nin the feedback received by the algorithm. We consider two settings: the\nreward-dependent delay setting, where realized delays may depend on the\nstochastic rewards, and the reward-independent delay setting. Our main\ncontribution is algorithms that achieve near-optimal regret in each of the\nsettings, with an additional additive dependence on the quantiles of the delay\ndistribution. Our results do not make any assumptions on the delay\ndistributions: in particular, we do not assume they come from any parametric\nfamily of distributions and allow for unbounded support and expectation; we\nfurther allow for infinite delays where the algorithm might occasionally not\nobserve any feedback.",
          "link": "http://arxiv.org/abs/2106.02436",
          "publishedOn": "2021-06-07T03:06:14.724Z",
          "wordCount": 542,
          "title": "Stochastic Multi-Armed Bandits with Unrestricted Delay Distributions. (arXiv:2106.02436v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiahui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>",
          "description": "Convolutional neural networks (CNNs) have made great breakthroughs in 2D\ncomputer vision. However, the irregular structure of meshes makes it hard to\nexploit the power of CNNs directly. A subdivision surface provides a\nhierarchical multi-resolution structure, and each face in a closed 2-manifold\ntriangle mesh is exactly adjacent to three faces. Motivated by these two\nproperties, this paper introduces a novel and flexible CNN framework, named\nSubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.\nMaking an analogy between mesh faces and pixels in a 2D image allows us to\npresent a mesh convolution operator to aggregate local features from adjacent\nfaces. By exploiting face neighborhoods, this convolution can support standard\n2D convolutional network concepts, e.g. variable kernel size, stride, and\ndilation. Based on the multi-resolution hierarchy, we propose a spatial uniform\npooling layer which merges four faces into one and an upsampling method which\nsplits one face into four. As a result, many popular 2D CNN architectures can\nbe readily adapted to processing 3D meshes. Meshes with arbitrary connectivity\ncan be remeshed to hold Loop subdivision sequence connectivity via\nself-parameterization, making SubdivNet a general approach. Experiments on mesh\nclassification, segmentation, correspondence, and retrieval from the real-world\ndemonstrate the effectiveness and efficiency of SubdivNet.",
          "link": "http://arxiv.org/abs/2106.02285",
          "publishedOn": "2021-06-07T03:06:14.684Z",
          "wordCount": 651,
          "title": "Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1\">Yingjie Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1\">Summer Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>",
          "description": "We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.",
          "link": "http://arxiv.org/abs/2106.02229",
          "publishedOn": "2021-06-07T03:06:14.659Z",
          "wordCount": 585,
          "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02396",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Badoual_M/0/1/0/all/0/1\">Mathilde D. Badoual</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moura_S/0/1/0/all/0/1\">Scott J. Moura</a>",
          "description": "Load serving entities with storage units reach sizes and performances that\ncan significantly impact clearing prices in electricity markets. Nevertheless,\nprice endogeneity is rarely considered in storage bidding strategies and\nmodeling the electricity market is a challenging task. Meanwhile, model-free\nreinforcement learning such as the Actor-Critic are becoming increasingly\npopular for designing energy system controllers. Yet implementation frequently\nrequires lengthy, data-intense, and unsafe trial-and-error training. To fill\nthese gaps, we implement an online Supervised Actor-Critic (SAC) algorithm,\nsupervised with a model-based controller -- Model Predictive Control (MPC). The\nenergy storage agent is trained with this algorithm to optimally bid while\nlearning and adjusting to its impact on the market clearing prices. We compare\nthe supervised Actor-Critic algorithm with the MPC algorithm as a supervisor,\nfinding that the former reaps higher profits via learning. Our contribution,\nthus, is an online and safe SAC algorithm that outperforms the current\nmodel-based state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.02396",
          "publishedOn": "2021-06-07T03:06:14.610Z",
          "wordCount": 600,
          "title": "A Learning-based Optimal Market Bidding Strategy for Price-Maker Energy Storage. (arXiv:2106.02396v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bielak_P/0/1/0/all/0/1\">Piotr Bielak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajdanowicz_T/0/1/0/all/0/1\">Tomasz Kajdanowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1\">Nitesh V. Chawla</a>",
          "description": "The self-supervised learning (SSL) paradigm is an essential exploration area,\nwhich tries to eliminate the need for expensive data labeling. Despite the\ngreat success of SSL methods in computer vision and natural language\nprocessing, most of them employ contrastive learning objectives that require\nnegative samples, which are hard to define. This becomes even more challenging\nin the case of graphs and is a bottleneck for achieving robust representations.\nTo overcome such limitations, we propose a framework for self-supervised graph\nrepresentation learning -- Graph Barlow Twins, which utilizes a\ncross-correlation-based loss function instead of negative samples. Moreover, it\ndoes not rely on non-symmetric neural network architectures -- in contrast to\nstate-of-the-art self-supervised graph representation learning method BGRL. We\nshow that our method achieves as competitive results as BGRL, best\nself-supervised methods, and fully supervised ones while requiring\nsubstantially fewer hyperparameters and converging in an order of magnitude\ntraining steps earlier.",
          "link": "http://arxiv.org/abs/2106.02466",
          "publishedOn": "2021-06-07T03:06:14.601Z",
          "wordCount": 576,
          "title": "Graph Barlow Twins: A self-supervised representation learning framework for graphs. (arXiv:2106.02466v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kossen_J/0/1/0/all/0/1\">Jannik Kossen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1\">Neil Band</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1\">Clare Lyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1\">Aidan N. Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "We challenge a common assumption underlying most supervised deep learning:\nthat a model makes a prediction depending only on its parameters and the\nfeatures of a single input. To this end, we introduce a general-purpose deep\nlearning architecture that takes as input the entire dataset instead of\nprocessing one datapoint at a time. Our approach uses self-attention to reason\nabout relationships between datapoints explicitly, which can be seen as\nrealizing non-parametric models using parametric attention mechanisms. However,\nunlike conventional non-parametric models, we let the model learn end-to-end\nfrom the data how to make use of other datapoints for prediction. Empirically,\nour models solve cross-datapoint lookup and complex reasoning tasks unsolvable\nby traditional deep learning models. We show highly competitive results on\ntabular data, early results on CIFAR-10, and give insight into how the model\nmakes use of the interactions between points.",
          "link": "http://arxiv.org/abs/2106.02584",
          "publishedOn": "2021-06-07T03:06:14.434Z",
          "wordCount": 587,
          "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning. (arXiv:2106.02584v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.13268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiameng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenchao Li</a>",
          "description": "Deep reinforcement learning (DRL) agents are often sensitive to visual\nchanges that were unseen in their training environments. To address this\nproblem, we leverage the sequential nature of RL to learn robust\nrepresentations that encode only task-relevant information from observations\nbased on the unsupervised multi-view setting. Specifically, we introduce an\nauxiliary objective based on the multi-view in-formation bottleneck (MIB)\nprinciple which quantifies the amount of task-irrelevant information and\nencourages learning representations that are both predictive of the future and\nless sensitive to task-irrelevant distractions. This enables us to train\nhigh-performance policies that are robust to visual distractions and can\ngeneralize to unseen environments. We demonstrate that our approach can achieve\nSOTA performance on diverse visual control tasks on the DeepMind Control Suite,\neven when the background is replaced with natural videos. In addition, we show\nthat our approach outperforms well-established baselines for generalization to\nunseen environments on the Procgen benchmark. Our code is open-sourced and\navailable at https://github.com/JmfanBU/DRIBO.",
          "link": "http://arxiv.org/abs/2102.13268",
          "publishedOn": "2021-06-07T03:06:14.355Z",
          "wordCount": 615,
          "title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck. (arXiv:2102.13268v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1\">Zeyuan Allen-Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.",
          "link": "http://arxiv.org/abs/2106.02619",
          "publishedOn": "2021-06-07T03:06:14.330Z",
          "wordCount": 609,
          "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michelle M. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>",
          "description": "Spatial context is central to understanding health and disease. Yet reference\nprotein interaction networks lack such contextualization, thereby limiting the\nstudy of where protein interactions likely occur in the human body.\nContextualized protein interactions could better characterize genes with\ndisease-specific interactions and elucidate diseases' manifestation in specific\ncell types. Here, we introduce AWARE, a graph neural message passing approach\nto inject cellular and tissue context into protein embeddings. AWARE optimizes\nfor a multi-scale embedding space, whose structure reflects the topology of\ncell type specific networks. We construct a multi-scale network of the Human\nCell Atlas and apply AWARE to learn protein, cell type, and tissue embeddings\nthat uphold cell type and tissue hierarchies. We demonstrate AWARE on the novel\ntask of predicting whether a gene is associated with a disease and where it\nmost likely manifests in the human body. AWARE embeddings outperform global\nembeddings by at least 12.5%, highlighting the importance of contextual\nlearners for protein networks.",
          "link": "http://arxiv.org/abs/2106.02246",
          "publishedOn": "2021-06-07T03:06:14.321Z",
          "wordCount": 588,
          "title": "Deep Contextual Learners for Protein Networks. (arXiv:2106.02246v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1\">Marcello Carioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1\">Christian Etmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1\">Soroosh Afyouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1\">Zoe Kourtzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola Bibiane Sch&#xf6;nlieb</a>",
          "description": "We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.",
          "link": "http://arxiv.org/abs/2106.02531",
          "publishedOn": "2021-06-07T03:06:14.264Z",
          "wordCount": 546,
          "title": "CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1\">Erik Nijkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tian Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent variable models for text, when trained successfully, accurately model\nthe data distribution and capture global semantic and syntactic features of\nsentences. The prominent approach to train such models is variational\nautoencoders (VAE). It is nevertheless challenging to train and often results\nin a trivial local optimum where the latent variable is ignored and its\nposterior collapses into the prior, an issue known as posterior collapse.\nVarious techniques have been proposed to mitigate this issue. Most of them\nfocus on improving the inference model to yield latent codes of higher quality.\nThe present work proposes a short run dynamics for inference. It is initialized\nfrom the prior distribution of the latent variable and then runs a small number\n(e.g., 20) of Langevin dynamics steps guided by its posterior distribution. The\nmajor advantage of our method is that it does not require a separate inference\nmodel or assume simple geometry of the posterior distribution, thus rendering\nan automatic, natural and flexible inference engine. We show that the models\ntrained with short run dynamics more accurately model the data, compared to\nstrong language model and VAE baselines, and exhibit no sign of posterior\ncollapse. Analyses of the latent space show that interpolation in the latent\nspace is able to generate coherent sentences with smooth transition and\ndemonstrate improved classification over strong baselines with latent features\nfrom unsupervised pretraining. These results together expose a well-structured\nlatent space of our generative model.",
          "link": "http://arxiv.org/abs/2106.02513",
          "publishedOn": "2021-06-07T03:06:14.221Z",
          "wordCount": 664,
          "title": "Generative Text Modeling through Short Run Inference. (arXiv:2106.02513v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02110",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Neira_E/0/1/0/all/0/1\">Elva Luz Crespo Neira</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ebadi_A/0/1/0/all/0/1\">Ashkan Ebadi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beaudry_C/0/1/0/all/0/1\">Catherine Beaudry</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schiffauerova_A/0/1/0/all/0/1\">Andrea Schiffauerova</a>",
          "description": "Incorporating existing knowledge is vital for innovating, discovering, and\ngenerating new ideas. Knowledge production through research and invention is\nthe key to scientific and technological development. As an emerging technology,\nnanotechnology has already proved its great potential for the global economy,\nattracting considerable federal investments. Canada is reported as one of the\nmajor players in producing nanotechnology research. In this paper, we focused\non the main drivers of knowledge production and diffusion by analyzing Canadian\nnanotechnology researchers. We hypothesized that knowledge production in\nCanadian nanotechnology is influenced by three key proximity factors, namely\ncognitive, geographical, and collaborative. Using statistical analysis, social\nnetwork analysis, and machine learning techniques we comprehensively assessed\nthe influence of the proximity factors on academic knowledge production. Our\nresults not only prove a significant impact of the three key proximity factors\nbut also their predictive potential.",
          "link": "http://arxiv.org/abs/2106.02110",
          "publishedOn": "2021-06-07T03:06:14.212Z",
          "wordCount": 588,
          "title": "Influence of cognitive, geographical, and collaborative proximity on knowledge production of Canadian nanotechnology. (arXiv:2106.02110v1 [physics.soc-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2001.11628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Okumura_R/0/1/0/all/0/1\">Ryo Okumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okada_M/0/1/0/all/0/1\">Masashi Okada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1\">Tadahiro Taniguchi</a>",
          "description": "State representation learning (SRL) in partially observable Markov decision\nprocesses has been studied to learn abstract features of data useful for robot\ncontrol tasks. For SRL, acquiring domain-agnostic states is essential for\nachieving efficient imitation learning. Without these states, imitation\nlearning is hampered by domain-dependent information useless for control.\nHowever, existing methods fail to remove such disturbances from the states when\nthe data from experts and agents show large domain shifts. To overcome this\nissue, we propose a domain-adversarial and conditional state space model\n(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and\ndynamics-aware states. DAC-SSM jointly optimizes the state inference,\nobservation reconstruction, forward dynamics, and reward models. To remove\ndomain-dependent information from the states, the model is trained with domain\ndiscriminators in an adversarial manner, and the reconstruction is conditioned\non domain labels. We experimentally evaluated the model predictive control\nperformance via imitation learning for continuous control of sparse reward\ntasks in simulators and compared it with the performance of the existing SRL\nmethod. The agents from DAC-SSM achieved performance comparable to experts and\nmore than twice the baselines. We conclude domain-agnostic states are essential\nfor imitation learning that has large domain shifts and can be obtained using\nDAC-SSM.",
          "link": "http://arxiv.org/abs/2001.11628",
          "publishedOn": "2021-06-07T03:06:14.203Z",
          "wordCount": 670,
          "title": "Domain-Adversarial and Conditional State Space Model for Imitation Learning. (arXiv:2001.11628v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ven_L/0/1/0/all/0/1\">Leni Ven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1\">Johannes Lederer</a>",
          "description": "Deep learning requires several design choices, such as the nodes' activation\nfunctions and the widths, types, and arrangements of the layers. One\nconsideration when making these choices is the vanishing-gradient problem,\nwhich is the phenomenon of algorithms getting stuck at suboptimal points due to\nsmall gradients. In this paper, we revisit the vanishing-gradient problem in\nthe context of sigmoid-type activation. We use mathematical arguments to\nhighlight two different sources of the phenomenon, namely large individual\nparameters and effects across layers, and to illustrate two simple remedies,\nnamely regularization and rescaling. We then demonstrate the effectiveness of\nthe two remedies in practice. In view of the vanishing-gradient problem being a\nmain reason why tanh and other sigmoid-type activation has become much less\npopular than relu-type activation, our results bring sigmoid-type activation\nback to the table.",
          "link": "http://arxiv.org/abs/2106.02260",
          "publishedOn": "2021-06-07T03:06:14.197Z",
          "wordCount": 565,
          "title": "Regularization and Reparameterization Avoid Vanishing Gradients in Sigmoid-Type Networks. (arXiv:2106.02260v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02522",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1\">Junran Wu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1\">Xueyuan Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1\">Shangzhe Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1\">Jichang Zhao</a>",
          "description": "Stock prediction, with the purpose of forecasting the future price trends of\nstocks, is crucial for maximizing profits from stock investments. While great\nresearch efforts have been devoted to exploiting deep neural networks for\nimproved stock prediction, the existing studies still suffer from two major\nissues. First, the long-range dependencies in time series are not sufficiently\ncaptured. Second, the chaotic property of financial time series fundamentally\nlowers prediction performance. In this study, we propose a novel framework to\naddress both issues regarding stock prediction. Specifically, in terms of\ntransforming time series into complex networks, we convert market price series\ninto graphs. Then, structural information, referring to associations among\ntemporal points and the node weights, is extracted from the mapped graphs to\nresolve the problems regarding long-range dependencies and the chaotic\nproperty. We take graph embeddings to represent the associations among temporal\npoints as the prediction model inputs. Node weights are used as a priori\nknowledge to enhance the learning of temporal attention. The effectiveness of\nour proposed framework is validated using real-world stock data, and our\napproach obtains the best performance among several state-of-the-art\nbenchmarks. Moreover, in the conducted trading simulations, our framework\nfurther obtains the highest cumulative profits. Our results supplement the\nexisting applications of complex network methods in the financial realm and\nprovide insightful implications for investment applications regarding decision\nsupport in financial markets.",
          "link": "http://arxiv.org/abs/2106.02522",
          "publishedOn": "2021-06-07T03:06:14.186Z",
          "wordCount": 672,
          "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Attrapadung_N/0/1/0/all/0/1\">Nuttapong Attrapadung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamada_K/0/1/0/all/0/1\">Koki Hamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikarashi_D/0/1/0/all/0/1\">Dai Ikarashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kikuchi_R/0/1/0/all/0/1\">Ryo Kikuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_T/0/1/0/all/0/1\">Takahiro Matsuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishina_I/0/1/0/all/0/1\">Ibuki Mishina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morita_H/0/1/0/all/0/1\">Hiraku Morita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuldt_J/0/1/0/all/0/1\">Jacob C. N. Schuldt</a>",
          "description": "Privacy-preserving machine learning (PPML) aims at enabling machine learning\n(ML) algorithms to be used on sensitive data. We contribute to this line of\nresearch by proposing a framework that allows efficient and secure evaluation\nof full-fledged state-of-the-art ML algorithms via secure multi-party\ncomputation (MPC). This is in contrast to most prior works, which substitute ML\nalgorithms with approximated \"MPC-friendly\" variants. A drawback of the latter\napproach is that fine-tuning of the combined ML and MPC algorithms is required,\nwhich might lead to less efficient algorithms or inferior quality ML. This is\nan issue for secure deep neural networks (DNN) training in particular, as this\ninvolves arithmetic algorithms thought to be \"MPC-unfriendly\", namely, integer\ndivision, exponentiation, inversion, and square root. In this work, we propose\nsecure and efficient protocols for the above seemingly MPC-unfriendly\ncomputations. Our protocols are three-party protocols in the honest-majority\nsetting, and we propose both passively secure and actively secure with abort\nvariants. A notable feature of our protocols is that they simultaneously\nprovide high accuracy and efficiency. This framework enables us to efficiently\nand securely compute modern ML algorithms such as Adam and the softmax function\n\"as is\", without resorting to approximations. As a result, we obtain secure DNN\ntraining that outperforms state-of-the-art three-party systems; our full\ntraining is up to 6.7 times faster than just the online phase of the recently\nproposed FALCON@PETS'21 on a standard benchmark network. We further perform\nmeasurements on real-world DNNs, AlexNet and VGG16. The performance of our\nframework is up to a factor of about 12-14 faster for AlexNet and 46-48 faster\nfor VGG16 to achieve an accuracy of 70% and 75%, respectively, when compared to\nFALCON.",
          "link": "http://arxiv.org/abs/2106.02203",
          "publishedOn": "2021-06-07T03:06:14.163Z",
          "wordCount": 734,
          "title": "Adam in Private: Secure and Fast Training of Deep Neural Networks with Adaptive Moment Estimation. (arXiv:2106.02203v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1\">Zhong Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Liang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1\">Guoli Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>",
          "description": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets",
          "link": "http://arxiv.org/abs/2106.02302",
          "publishedOn": "2021-06-07T03:06:14.152Z",
          "wordCount": 675,
          "title": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "A recent numerical study observed that neural network classifiers enjoy a\nlarge degree of symmetry in the penultimate layer. Namely, if $h(x) = Af(x) +b$\nwhere $A$ is a linear map and $f$ is the output of the penultimate layer of the\nnetwork (after activation), then all data points $x_{i, 1}, \\dots, x_{i, N_i}$\nin a class $C_i$ are mapped to a single point $y_i$ by $f$ and the points $y_i$\nare located at the vertices of a regular $k-1$-dimensional standard simplex in\na high-dimensional Euclidean space.\n\nWe explain this observation analytically in toy models for highly expressive\ndeep neural networks. In complementary examples, we demonstrate rigorously that\neven the final output of the classifier $h$ is not uniform over data samples\nfrom a class $C_i$ if $h$ is a shallow network (or if the deeper layers do not\nbring the data samples into a convenient geometric configuration).",
          "link": "http://arxiv.org/abs/2012.05420",
          "publishedOn": "2021-06-07T03:06:14.139Z",
          "wordCount": 629,
          "title": "On the emergence of simplex symmetry in the final and penultimate layers of neural network classifiers. (arXiv:2012.05420v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1\">Federica Granese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1\">Marco Romanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1\">Daniele Gorla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Deep neural networks (DNNs) have shown to perform very well on large scale\nobject recognition problems and lead to widespread use for real-world\napplications, including situations where DNN are implemented as \"black boxes\".\nA promising approach to secure their use is to accept decisions that are likely\nto be correct while discarding the others. In this work, we propose DOCTOR, a\nsimple method that aims to identify whether the prediction of a DNN classifier\nshould (or should not) be trusted so that, consequently, it would be possible\nto accept it or to reject it. Two scenarios are investigated: Totally Black Box\n(TBB) where only the soft-predictions are available and Partially Black Box\n(PBB) where gradient-propagation to perform input pre-processing is allowed.\nEmpirically, we show that DOCTOR outperforms all state-of-the-art methods on\nvarious well-known images and sentiment analysis datasets. In particular, we\nobserve a reduction of up to $4\\%$ of the false rejection rate (FRR) in the PBB\nscenario. DOCTOR can be applied to any pre-trained model, it does not require\nprior information about the underlying dataset and is as simple as the simplest\navailable methods in the literature.",
          "link": "http://arxiv.org/abs/2106.02395",
          "publishedOn": "2021-06-07T03:06:14.132Z",
          "wordCount": 624,
          "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_V/0/1/0/all/0/1\">Vishrawas Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navalekar_S/0/1/0/all/0/1\">Sayali Navalekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Pan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooley_R/0/1/0/all/0/1\">Ryan Hooley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jacob Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_R/0/1/0/all/0/1\">Raman Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ajay Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianco_S/0/1/0/all/0/1\">Simone Bianco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufman_J/0/1/0/all/0/1\">James H. Kaufman</a>",
          "description": "Pandemic control measures like lock-down, restrictions on restaurants and\ngatherings, social-distancing have shown to be effective in curtailing the\nspread of COVID-19. However, their sustained enforcement has negative economic\neffects. To craft strategies and policies that reduce the hardship on the\npeople and the economy while being effective against the pandemic, authorities\nneed to understand the disease dynamics at the right geo-spatial granularity.\nConsidering factors like the hospitals' ability to handle the fluctuating\ndemands, evaluating various reopening scenarios, and accurate forecasting of\ncases are vital to decision making. Towards this end, we present a flexible\nend-to-end solution that seamlessly integrates public health data with tertiary\nclient data to accurately estimate the risk of reopening a community. At its\ncore lies a state-of-the-art prediction model that auto-captures changing\ntrends in transmission and mobility. Benchmarking against various published\nbaselines confirm the superiority of our forecasting algorithm. Combined with\nthe ability to extend to multiple client-specific requirements and perform\ndeductive reasoning through counter-factual analysis, this solution provides\nactionable insights to multiple client domains ranging from government to\neducational institutions, hospitals, and commercial establishments.",
          "link": "http://arxiv.org/abs/2106.02094",
          "publishedOn": "2021-06-07T03:06:14.126Z",
          "wordCount": 682,
          "title": "Adaptive Epidemic Forecasting and Community Risk Evaluation of COVID-19. (arXiv:2106.02094v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "In recent years, Generative Adversarial Networks have become ubiquitous in\nboth research and public perception, but how GANs convert an unstructured\nlatent code to a high quality output is still an open question. In this work,\nwe investigate regression into the latent space as a probe to understand the\ncompositional properties of GANs. We find that combining the regressor and a\npretrained generator provides a strong image prior, allowing us to create\ncomposite images from a collage of random image parts at inference time while\nmaintaining global consistency. To compare compositional properties across\ndifferent generators, we measure the trade-offs between reconstruction of the\nunrealistic input and image quality of the regenerated samples. We find that\nthe regression approach enables more localized editing of individual image\nparts compared to direct editing in the latent space, and we conduct\nexperiments to quantify this independence effect. Our method is agnostic to the\nsemantics of edits, and does not require labels or predefined concepts during\ntraining. Beyond image composition, our method extends to a number of related\napplications, such as image inpainting or example-based image editing, which we\ndemonstrate on several GANs and datasets, and because it uses only a single\nforward pass, it can operate in real-time. Code is available on our project\npage: https://chail.github.io/latent-composition/.",
          "link": "http://arxiv.org/abs/2103.10426",
          "publishedOn": "2021-06-07T03:06:14.106Z",
          "wordCount": 687,
          "title": "Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Desu_S/0/1/0/all/0/1\">Surya Sai Teja Desu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1\">P.K. Srijith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1\">M.V. Panduranga Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>",
          "description": "Linear regression is a popular machine learning approach to learn and predict\nreal valued outputs or dependent variables from independent variables or\nfeatures. In many real world problems, its beneficial to perform sparse linear\nregression to identify important features helpful in predicting the dependent\nvariable. It not only helps in getting interpretable results but also avoids\noverfitting when the number of features is large, and the amount of data is\nsmall. The most natural way to achieve this is by using `best subset selection'\nwhich penalizes non-zero model parameters by adding $\\ell_0$ norm over\nparameters to the least squares loss. However, this makes the objective\nfunction non-convex and intractable even for a small number of features. This\npaper aims to address the intractability of sparse linear regression with\n$\\ell_0$ norm using adiabatic quantum computing, a quantum computing paradigm\nthat is particularly useful for solving optimization problems faster. We\nformulate the $\\ell_0$ optimization problem as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem and solve it using the D-Wave adiabatic quantum\ncomputer. We study and compare the quality of QUBO solution on synthetic and\nreal world datasets. The results demonstrate the effectiveness of the proposed\nadiabatic quantum computing approach in finding the optimal solution. The QUBO\nsolution matches the optimal solution for a wide range of sparsity penalty\nvalues across the datasets.",
          "link": "http://arxiv.org/abs/2106.02357",
          "publishedOn": "2021-06-07T03:06:14.099Z",
          "wordCount": 666,
          "title": "Adiabatic Quantum Feature Selection for Sparse Linear Regression. (arXiv:2106.02357v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1\">James Mullenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1\">Yada Pruksachatkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1\">Sean Adler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1\">Jennifer Seale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1\">Jordan Swartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1\">T. Greg McKelvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>",
          "description": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.",
          "link": "http://arxiv.org/abs/2106.02524",
          "publishedOn": "2021-06-07T03:06:14.093Z",
          "wordCount": 641,
          "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noel_A/0/1/0/all/0/1\">Alejandro Daniel Noel</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hoof_C/0/1/0/all/0/1\">Charel van Hoof</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Millidge_B/0/1/0/all/0/1\">Beren Millidge</a> (2) ((1) Delft University of Technology, (2) University of Oxford)",
          "description": "Intelligent agents must pursue their goals in complex environments with\npartial information and often limited computational capacity. Reinforcement\nlearning methods have achieved great success by creating agents that optimize\nengineered reward functions, but which often struggle to learn in sparse-reward\nenvironments, generally require many environmental interactions to perform\nwell, and are typically computationally very expensive. Active inference is a\nmodel-based approach that directs agents to explore uncertain states while\nadhering to a prior model of their goal behaviour. This paper introduces an\nactive inference agent which minimizes the novel free energy of the expected\nfuture. Our model is capable of solving sparse-reward problems with a very high\nsample efficiency due to its objective function, which encourages directed\nexploration of uncertain states. Moreover, our model is computationally very\nlight and can operate in a fully online manner while achieving comparable\nperformance to offline RL methods. We showcase the capabilities of our model by\nsolving the mountain car problem, where we demonstrate its superior exploration\nproperties and its robustness to observation noise, which in fact improves\nperformance. We also introduce a novel method for approximating the prior model\nfrom the reward function, which simplifies the expression of complex objectives\nand improves performance over previous active inference approaches.",
          "link": "http://arxiv.org/abs/2106.02390",
          "publishedOn": "2021-06-07T03:06:14.085Z",
          "wordCount": 659,
          "title": "Online reinforcement learning with sparse rewards through an active inference capsule. (arXiv:2106.02390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+List_F/0/1/0/all/0/1\">Florian List</a>",
          "description": "Although ubiquitous in the sciences, histogram data have not received much\nattention by the Deep Learning community. Whilst regression and classification\ntasks for scalar and vector data are routinely solved by neural networks, a\nprincipled approach for estimating histogram labels as a function of an input\nvector or image is lacking in the literature. We present a dedicated method for\nDeep Learning-based histogram regression, which incorporates cross-bin\ninformation and yields distributions over possible histograms, expressed by\n$\\tau$-quantiles of the cumulative histogram in each bin. The crux of our\napproach is a new loss function obtained by applying the pinball loss to the\ncumulative histogram, which for 1D histograms reduces to the Earth Mover's\ndistance (EMD) in the special case of the median ($\\tau = 0.5$), and\ngeneralizes it to arbitrary quantiles. We validate our method with an\nillustrative toy example, a football-related task, and an astrophysical\ncomputer vision problem. We show that with our loss function, the accuracy of\nthe predicted median histograms is very similar to the standard EMD case (and\nhigher than for per-bin loss functions such as cross-entropy), while the\npredictions become much more informative at almost no additional computational\ncost.",
          "link": "http://arxiv.org/abs/2106.02051",
          "publishedOn": "2021-06-07T03:06:14.079Z",
          "wordCount": 638,
          "title": "The Earth Mover's Pinball Loss: Quantiles for Histogram-Valued Regression. (arXiv:2106.02051v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saito_N/0/1/0/all/0/1\">Namiko Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ogata_T/0/1/0/all/0/1\">Tetsuya Ogata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funabashi_S/0/1/0/all/0/1\">Satoshi Funabashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_H/0/1/0/all/0/1\">Hiroki Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugano_S/0/1/0/all/0/1\">Shigeki Sugano</a>",
          "description": "Selection of appropriate tools and use of them when performing daily tasks is\na critical function for introducing robots for domestic applications. In\nprevious studies, however, adaptability to target objects was limited, making\nit difficult to accordingly change tools and adjust actions. To manipulate\nvarious objects with tools, robots must both understand tool functions and\nrecognize object characteristics to discern a tool-object-action relation. We\nfocus on active perception using multimodal sensorimotor data while a robot\ninteracts with objects, and allow the robot to recognize their extrinsic and\nintrinsic characteristics. We construct a deep neural networks (DNN) model that\nlearns to recognize object characteristics, acquires tool-object-action\nrelations, and generates motions for tool selection and handling. As an example\ntool-use situation, the robot performs an ingredients transfer task, using a\nturner or ladle to transfer an ingredient from a pot to a bowl. The results\nconfirm that the robot recognizes object characteristics and servings even when\nthe target ingredients are unknown. We also examine the contributions of\nimages, force, and tactile data and show that learning a variety of multimodal\ninformation results in rich perception for tool use.",
          "link": "http://arxiv.org/abs/2106.02445",
          "publishedOn": "2021-06-07T03:06:14.061Z",
          "wordCount": 669,
          "title": "How to select and use tools? : Active Perception of Target Objects Using Multimodal Deep Learning. (arXiv:2106.02445v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02496",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Roget_M/0/1/0/all/0/1\">Mathieu Roget</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Molfetta_G/0/1/0/all/0/1\">Giuseppe Di Molfetta</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kadri_H/0/1/0/all/0/1\">Hachem Kadri</a>",
          "description": "Quantum machine learning algorithms could provide significant speed-ups over\ntheir classical counterparts; however, whether they could also achieve good\ngeneralization remains unclear. Recently, two quantum perceptron models which\ngive a quadratic improvement over the classical perceptron algorithm using\nGrover's search have been proposed by Wiebe et al. arXiv:1602.04799 . While the\nfirst model reduces the complexity with respect to the size of the training\nset, the second one improves the bound on the number of mistakes made by the\nperceptron. In this paper, we introduce a hybrid quantum-classical perceptron\nalgorithm with lower complexity and better generalization ability than the\nclassical perceptron. We show a quadratic improvement over the classical\nperceptron in both the number of samples and the margin of the data. We derive\na bound on the expected error of the hypothesis returned by our algorithm,\nwhich compares favorably to the one obtained with the classical online\nperceptron. We use numerical experiments to illustrate the trade-off between\ncomputational complexity and statistical accuracy in quantum perceptron\nlearning and discuss some of the key practical issues surrounding the\nimplementation of quantum perceptron models into near-term quantum devices,\nwhose practical implementation represents a serious challenge due to inherent\nnoise. However, the potential benefits make correcting this worthwhile.",
          "link": "http://arxiv.org/abs/2106.02496",
          "publishedOn": "2021-06-07T03:06:14.055Z",
          "wordCount": 630,
          "title": "Quantum Perceptron Revisited: Computational-Statistical Tradeoffs. (arXiv:2106.02496v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>",
          "description": "Generative adversarial networks built from deep convolutional neural networks\n(GANs) lack the ability to exactly replicate the high-frequency components of\nnatural images. To alleviate this issue, we introduce two novel training\ntechniques called frequency dropping (F-Drop) and frequency matching (F-Match).\nThe key idea of F-Drop is to filter out unnecessary high-frequency components\nfrom the input images of the discriminators. This simple modification prevents\nthe discriminators from being confused by perturbations of the high-frequency\ncomponents. In addition, F-Drop makes the GANs focus on fitting in the\nlow-frequency domain, in which there are the dominant components of natural\nimages. F-Match minimizes the difference between real and fake images in the\nfrequency domain for generating more realistic images. F-Match is implemented\nas a regularization term in the objective functions of the generators; it\npenalizes the batch mean error in the frequency domain. F-Match helps the\ngenerators to fit in the high-frequency domain filtered out by F-Drop to the\nreal image. We experimentally demonstrate that the combination of F-Drop and\nF-Match improves the generative performance of GANs in both the frequency and\nspatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,\nCelebA, and ImageNet).",
          "link": "http://arxiv.org/abs/2106.02343",
          "publishedOn": "2021-06-07T03:06:14.049Z",
          "wordCount": 634,
          "title": "F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jared Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "Approximate bi-level optimization (ABLO) consists of (outer-level)\noptimization problems, involving numerical (inner-level) optimization loops.\nWhile ABLO has many applications across deep learning, it suffers from time and\nmemory complexity proportional to the length $r$ of its inner optimization\nloop. To address this complexity, an earlier first-order method (FOM) was\nproposed as a heuristic that omits second derivative terms, yielding\nsignificant speed gains and requiring only constant memory. Despite FOM's\npopularity, there is a lack of theoretical understanding of its convergence\nproperties. We contribute by theoretically characterizing FOM's gradient bias\nunder mild assumptions. We further demonstrate a rich family of examples where\nFOM-based SGD does not converge to a stationary point of the ABLO objective. We\naddress this concern by proposing an unbiased FOM (UFOM) enjoying constant\nmemory complexity as a function of $r$. We characterize the introduced\ntime-variance tradeoff, demonstrate convergence bounds, and find an optimal\nUFOM for a given ABLO problem. Finally, we propose an efficient adaptive UFOM\nscheme.",
          "link": "http://arxiv.org/abs/2106.02487",
          "publishedOn": "2021-06-07T03:06:14.041Z",
          "wordCount": 606,
          "title": "Debiasing a First-order Heuristic for Approximate Bi-level Optimization. (arXiv:2106.02487v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-07T03:06:14.035Z",
          "wordCount": 613,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02297",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Ji-Hoon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Hoon Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or robotic sound, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.",
          "link": "http://arxiv.org/abs/2106.02297",
          "publishedOn": "2021-06-07T03:06:14.028Z",
          "wordCount": 557,
          "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis. (arXiv:2106.02297v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush K. Sharma</a>",
          "description": "Data transmission between two or more digital devices in industry and\ngovernment demands secure and agile technology. Digital information\ndistribution often requires deployment of Internet of Things (IoT) devices and\nData Fusion techniques which have also gained popularity in both, civilian and\nmilitary environments, such as, emergence of Smart Cities and Internet of\nBattlefield Things (IoBT). This usually requires capturing and consolidating\ndata from multiple sources. Because datasets do not necessarily originate from\nidentical sensors, fused data typically results in a complex Big Data problem.\nDue to potentially sensitive nature of IoT datasets, Blockchain technology is\nused to facilitate secure sharing of IoT datasets, which allows digital\ninformation to be distributed, but not copied. However, blockchain has several\nlimitations related to complexity, scalability, and excessive energy\nconsumption. We propose an approach to hide information (sensor signal) by\ntransforming it to an image or an audio signal. In one of the latest attempts\nto the military modernization, we investigate sensor fusion approach by\ninvestigating the challenges of enabling an intelligent identification and\ndetection operation and demonstrates the feasibility of the proposed Deep\nLearning and Anomaly Detection models that can support future application for\nspecific hand gesture alert system from wearable devices.",
          "link": "http://arxiv.org/abs/2106.02044",
          "publishedOn": "2021-06-07T03:06:14.010Z",
          "wordCount": 670,
          "title": "Heterogeneous Noisy Short Signal Camouflage in Multi-Domain Environment Decision-Making. (arXiv:2106.02044v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.00734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1\">Juliano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hess_G/0/1/0/all/0/1\">Georg Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ljungbergh_W/0/1/0/all/0/1\">William Ljungbergh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yuxuan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svensson_L/0/1/0/all/0/1\">Lennart Svensson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wymeersch_H/0/1/0/all/0/1\">Henk Wymeersch</a>",
          "description": "Multitarget Tracking (MTT) is the problem of tracking the states of an\nunknown number of objects using noisy measurements, with important applications\nto autonomous driving, surveillance, robotics, and others. In the model-based\nBayesian setting, there are conjugate priors that enable us to express the\nmulti-object posterior in closed form, which could theoretically provide\nBayes-optimal estimates. However, the posterior involves a super-exponential\ngrowth of the number of hypotheses over time, forcing state-of-the-art methods\nto resort to approximations for remaining tractable, which can impact their\nperformance in complex scenarios. Model-free methods based on deep-learning\nprovide an attractive alternative, as they can, in principle, learn the optimal\nfilter from data, but to the best of our knowledge were never compared to\ncurrent state-of-the-art Bayesian filters, specially not in contexts where\naccurate models are available. In this paper, we propose a high-performing\ndeep-learning method for MTT based on the Transformer architecture and compare\nit to two state-of-the-art Bayesian filters, in a setting where we assume the\ncorrect model is provided. Although this gives an edge to the model-based\nfilters, it also allows us to generate unlimited training data. We show that\nthe proposed model outperforms state-of-the-art Bayesian filters in complex\nscenarios, while matching their performance in simpler cases, which validates\nthe applicability of deep-learning also in the model-based regime. The code for\nall our implementations is made available at\nhttps://github.com/JulianoLagana/MT3 .",
          "link": "http://arxiv.org/abs/2104.00734",
          "publishedOn": "2021-06-07T03:06:14.004Z",
          "wordCount": 713,
          "title": "Next Generation Multitarget Trackers: Random Finite Set Methods vs Transformer-based Deep Learning. (arXiv:2104.00734v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05022",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kuchibhotla_A/0/1/0/all/0/1\">Arun Kumar Kuchibhotla</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinqing Zheng</a>",
          "description": "Many inference problems, such as sequential decision problems like A/B\ntesting, adaptive sampling schemes like bandit selection, are often online in\nnature. The fundamental problem for online inference is to provide a sequence\nof confidence intervals that are valid uniformly over the growing-into-infinity\nsample sizes. To address this question, we provide a near-optimal confidence\nsequence for bounded random variables by utilizing Bentkus' concentration\nresults. We show that it improves on the existing approaches that use the\nCram{\\'e}r-Chernoff technique such as the Hoeffding, Bernstein, and Bennett\ninequalities. The resulting confidence sequence is confirmed to be favorable in\nboth synthetic coverage problems and an application to adaptive stopping\nalgorithms.",
          "link": "http://arxiv.org/abs/2006.05022",
          "publishedOn": "2021-06-07T03:06:13.996Z",
          "wordCount": 574,
          "title": "Near-Optimal Confidence Sequences for Bounded Random Variables. (arXiv:2006.05022v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% in various state-of-the-art adversarially trained models on the\nAutoAttack benchmark, where every small margin of improvement is significant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-07T03:06:13.988Z",
          "wordCount": 601,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nicholas_F/0/1/0/all/0/1\">Farris Nicholas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brian_M/0/1/0/all/0/1\">Model Brian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_S/0/1/0/all/0/1\">Savery Richard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gil_W/0/1/0/all/0/1\">Weinberg Gil</a>",
          "description": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.",
          "link": "http://arxiv.org/abs/2106.02556",
          "publishedOn": "2021-06-07T03:06:13.980Z",
          "wordCount": 605,
          "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning. (arXiv:2106.02556v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1\">Sadegh Farhadkhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1\">L&#xea;-Nguy&#xea;n Hoang</a>",
          "description": "Today's large-scale machine learning algorithms harness massive amounts of\nuser-generated data to train large models. However, especially in the context\nof content recommendation with enormous social, economical and political\nincentives to promote specific views, products or ideologies, strategic users\nmight be tempted to fabricate or mislabel data in order to bias algorithms in\ntheir favor. Unfortunately, today's learning schemes strongly incentivize such\nstrategic data misreporting. This is a major concern, as it endangers the\ntrustworthiness of the entire training datasets, and questions the safety of\nany algorithm trained on such datasets. In this paper, we show that, perhaps\nsurprisingly, incentivizing data misreporting is not a fatality. We propose the\nfirst personalized collaborative learning framework, Licchavi, with provable\nstrategyproofness guarantees through a careful design of the underlying loss\nfunction. Interestingly, we also prove that Licchavi is Byzantine resilient: it\ntolerates a minority of users that provide arbitrary data.",
          "link": "http://arxiv.org/abs/2106.02398",
          "publishedOn": "2021-06-07T03:06:13.964Z",
          "wordCount": 581,
          "title": "Strategyproof Learning: Building Trustworthy User-Generated Datasets. (arXiv:2106.02398v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charles_Z/0/1/0/all/0/1\">Zachary Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>",
          "description": "The federated learning (FL) framework trains a machine learning model using\ndecentralized data stored at edge client devices by periodically aggregating\nlocally trained models. Popular optimization algorithms of FL use vanilla\n(stochastic) gradient descent for both local updates at clients and global\nupdates at the aggregating server. Recently, adaptive optimization methods such\nas AdaGrad have been studied for server updates. However, the effect of using\nadaptive optimization methods for local updates at clients is not yet\nunderstood. We show in both theory and practice that while local adaptive\nmethods can accelerate convergence, they can cause a non-vanishing solution\nbias, where the final converged solution may be different from the stationary\npoint of the global objective function. We propose correction techniques to\novercome this inconsistency and complement the local adaptive methods for FL.\nExtensive experiments on realistic federated training tasks show that the\nproposed algorithms can achieve faster convergence and higher test accuracy\nthan the baselines without local adaptivity.",
          "link": "http://arxiv.org/abs/2106.02305",
          "publishedOn": "2021-06-07T03:06:13.958Z",
          "wordCount": 597,
          "title": "Local Adaptivity in Federated Learning: Convergence and Consistency. (arXiv:2106.02305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02352",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kamyshev_I/0/1/0/all/0/1\">Ilia Kamyshev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kriukov_D/0/1/0/all/0/1\">Dmitrii Kriukov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gryazina_E/0/1/0/all/0/1\">Elena Gryazina</a>",
          "description": "The modern artificial intelligence techniques show the outstanding\nperformances in the field of Non-Intrusive Load Monitoring (NILM). However, the\nproblem related to the identification of a large number of appliances working\nsimultaneously is underestimated. One of the reasons is the absence of a\nspecific data. In this research we propose the Synthesizer of Normalized\nSignatures (SNS) algorithm to simulate the aggregated consumption with up to 10\nconcurrent loads. The results show that the synthetic data provides the models\nwith at least as a powerful identification accuracy as the real-world\nmeasurements. We have developed the neural architecture named Concurrent Loads\nDisaggregator (COLD) which is relatively simple and easy to understand in\ncomparison to the previous approaches. Our model allows identifying from 1 to\n10 appliances working simultaneously with mean F1-score 78.95%. The source code\nof the experiments performed is available at\nhttps://github.com/arx7ti/cold-nilm.",
          "link": "http://arxiv.org/abs/2106.02352",
          "publishedOn": "2021-06-07T03:06:13.951Z",
          "wordCount": 573,
          "title": "COLD: Concurrent Loads Disaggregator for Non-Intrusive Load Monitoring. (arXiv:2106.02352v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhaoyang_Z/0/1/0/all/0/1\">Zhang Zhaoyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenqi_S/0/1/0/all/0/1\">Shao Wenqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jinwei_G/0/1/0/all/0/1\">Gu Jinwei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiaogang_W/0/1/0/all/0/1\">Wang Xiaogang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_L/0/1/0/all/0/1\">Luo Ping</a>",
          "description": "Model quantization is challenging due to many tedious hyper-parameters such\nas precision (bitwidth), dynamic range (minimum and maximum discrete values)\nand stepsize (interval between discrete values). Unlike prior arts that\ncarefully tune these values, we present a fully differentiable approach to\nlearn all of them, named Differentiable Dynamic Quantization (DDQ), which has\nseveral benefits. (1) DDQ is able to quantize challenging lightweight\narchitectures like MobileNets, where different layers prefer different\nquantization parameters. (2) DDQ is hardware-friendly and can be easily\nimplemented using low-precision matrix-vector multiplication, making it capable\nin many hardware such as ARM. (3) Extensive experiments show that DDQ\noutperforms prior arts on many networks and benchmarks, especially when models\nare already efficient and compact. e.g., DDQ is the first approach that\nachieves lossless 4-bit quantization for MobileNetV2 on ImageNet.",
          "link": "http://arxiv.org/abs/2106.02295",
          "publishedOn": "2021-06-07T03:06:13.945Z",
          "wordCount": 563,
          "title": "Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution. (arXiv:2106.02295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01678",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1\">Rikiya Yamashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1\">Snikitha Banda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1\">Jeanne Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Suboptimal generalization of machine learning models on unseen data is a key\nchallenge which hampers the clinical applicability of such models to medical\nimaging. Although various methods such as domain adaptation and domain\ngeneralization have evolved to combat this challenge, learning robust and\ngeneralizable representations is core to medical image understanding, and\ncontinues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation\nfor histoPathology), a form of data augmentation based on random style transfer\nfrom non-medical style source such as artistic paintings, for learning\ndomain-agnostic visual representations in computational pathology. Style\ntransfer replaces the low-level texture content of an image with the\nuninformative style of randomly selected style source image, while preserving\nthe original high-level semantic content. This improves robustness to domain\nshift and can be used as a simple yet powerful tool for learning\ndomain-agnostic representations. We demonstrate that STRAP leads to\nstate-of-the-art performance, particularly in the presence of domain shifts, on\ntwo particular classification tasks in computational pathology.",
          "link": "http://arxiv.org/abs/2102.01678",
          "publishedOn": "2021-06-07T03:06:13.938Z",
          "wordCount": 633,
          "title": "Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sana_M/0/1/0/all/0/1\">Mohamed Sana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietro_N/0/1/0/all/0/1\">Nicola di Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strinati_E/0/1/0/all/0/1\">Emilio Calvanese Strinati</a>",
          "description": "We study the problem of user association, namely finding the optimal\nassignment of user equipment to base stations to achieve a targeted network\nperformance. In this paper, we focus on the knowledge transferability of\nassociation policies. Indeed, traditional non-trivial user association schemes\nare often scenario-specific or deployment-specific and require a policy\nre-design or re-learning when the number or the position of the users change.\nIn contrast, transferability allows to apply a single user association policy,\ndevised for a specific scenario, to other distinct user deployments, without\nneeding a substantial re-learning or re-design phase and considerably reducing\nits computational and management complexity. To achieve transferability, we\nfirst cast user association as a multi-agent reinforcement learning problem.\nThen, based on a neural attention mechanism that we specifically conceived for\nthis context, we propose a novel distributed policy network architecture, which\nis transferable among users with zero-shot generalization capability i.e.,\nwithout requiring additional training.Numerical results show the effectiveness\nof our solution in terms of overall network communication rate, outperforming\ncentralized benchmarks even when the number of users doubles with respect to\nthe initial training point.",
          "link": "http://arxiv.org/abs/2106.02540",
          "publishedOn": "2021-06-07T03:06:13.932Z",
          "wordCount": 621,
          "title": "Transferable and Distributed User Association Policies for 5G and Beyond Networks. (arXiv:2106.02540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Byeongsu Yu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_K/0/1/0/all/0/1\">Kisung You</a>",
          "description": "We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.",
          "link": "http://arxiv.org/abs/2106.02096",
          "publishedOn": "2021-06-07T03:06:13.913Z",
          "wordCount": 566,
          "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of Topological Equivalence. (arXiv:2106.02096v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02601",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kotary_J/0/1/0/all/0/1\">James Kotary</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>",
          "description": "Optimization problems are ubiquitous in our societies and are present in\nalmost every segment of the economy. Most of these optimization problems are\nNP-hard and computationally demanding, often requiring approximate solutions\nfor large-scale instances. Machine learning frameworks that learn to\napproximate solutions to such hard optimization problems are a potentially\npromising avenue to address these difficulties, particularly when many closely\nrelated problem instances must be solved repeatedly. Supervised learning\nframeworks can train a model using the outputs of pre-solved instances.\nHowever, when the outputs are themselves approximations, when the optimization\nproblem has symmetric solutions, and/or when the solver uses randomization,\nsolutions to closely related instances may exhibit large differences and the\nlearning task can become inherently more difficult. This paper demonstrates\nthis critical challenge, connects the volatility of the training data to the\nability of a model to approximate it, and proposes a method for producing\n(exact or approximate) solutions to optimization problems that are more\namenable to supervised learning tasks. The effectiveness of the method is\ntested on hard non-linear nonconvex and discrete combinatorial problems.",
          "link": "http://arxiv.org/abs/2106.02601",
          "publishedOn": "2021-06-07T03:06:13.902Z",
          "wordCount": 605,
          "title": "Learning Hard Optimization Problems: A Data Generation Perspective. (arXiv:2106.02601v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1\">Ruhi Sarikaya</a>",
          "description": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.",
          "link": "http://arxiv.org/abs/2106.02363",
          "publishedOn": "2021-06-07T03:06:13.894Z",
          "wordCount": 556,
          "title": "Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Manhyung Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jeonghyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taewoong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jung Hoon Han</a>",
          "description": "The fluctuation-dissipation theorem (FDT) is a simple yet powerful\nconsequence of the first-order differential equation governing the dynamics of\nsystems subject simultaneously to dissipative and stochastic forces. The linear\nlearning dynamics, in which the input vector maps to the output vector by a\nlinear matrix whose elements are the subject of learning, has a stochastic\nversion closely mimicking the Langevin dynamics when a full-batch gradient\ndescent scheme is replaced by that of stochastic gradient descent. We derive a\ngeneralized FDT for the stochastic linear learning dynamics and verify its\nvalidity among the well-known machine learning data sets such as MNIST,\nCIFAR-10 and EMNIST.",
          "link": "http://arxiv.org/abs/2106.02220",
          "publishedOn": "2021-06-07T03:06:13.888Z",
          "wordCount": 531,
          "title": "Fluctuation-dissipation Type Theorem in Stochastic Linear Learning. (arXiv:2106.02220v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mingde Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1\">Sitao Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "We present an end-to-end, model-based deep reinforcement learning agent which\ndynamically attends to relevant parts of its state, in order to plan and to\ngeneralize better out-of-distribution. The agent's architecture uses a set\nrepresentation and a bottleneck mechanism, forcing the number of entities to\nwhich the agent attends at each planning step to be small. In experiments with\ncustomized MiniGrid environments with different dynamics, we observe that the\ndesign allows agents to learn to plan effectively, by attending to the relevant\nobjects, leading to better out-of-distribution generalization.",
          "link": "http://arxiv.org/abs/2106.02097",
          "publishedOn": "2021-06-07T03:06:13.871Z",
          "wordCount": 518,
          "title": "A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning. (arXiv:2106.02097v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bungert_L/0/1/0/all/0/1\">Leon Bungert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roith_T/0/1/0/all/0/1\">Tim Roith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenbrinck_D/0/1/0/all/0/1\">Daniel Tenbrinck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1\">Martin Burger</a>",
          "description": "We propose a novel strategy for Neural Architecture Search (NAS) based on\nBregman iterations. Starting from a sparse neural network our gradient-based\none-shot algorithm gradually adds relevant parameters in an inverse scale space\nmanner. This allows the network to choose the best architecture in the search\nspace which makes it well-designed for a given task, e.g., by adding neurons or\nskip connections. We demonstrate that using our approach one can unveil, for\ninstance, residual autoencoders for denoising, deblurring, and classification\ntasks. Code is available at https://github.com/TimRoith/BregmanLearning.",
          "link": "http://arxiv.org/abs/2106.02479",
          "publishedOn": "2021-06-07T03:06:13.865Z",
          "wordCount": 530,
          "title": "Neural Architecture Search via Bregman Iterations. (arXiv:2106.02479v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Springer_J/0/1/0/all/0/1\">Jacob M. Springer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Melanie Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenyon_G/0/1/0/all/0/1\">Garrett T. Kenyon</a>",
          "description": "Adversarial examples for neural network image classifiers are known to be\ntransferable: examples optimized to be misclassified by a source classifier are\noften misclassified as well by classifiers with different architectures.\nHowever, targeted adversarial examples -- optimized to be classified as a\nchosen target class -- tend to be less transferable between architectures.\nWhile prior research on constructing transferable targeted attacks has focused\non improving the optimization procedure, in this work we examine the role of\nthe source classifier. Here, we show that training the source classifier to be\n\"slightly robust\" -- that is, robust to small-magnitude adversarial examples --\nsubstantially improves the transferability of targeted attacks, even between\narchitectures as different as convolutional neural networks and transformers.\nWe argue that this result supports a non-intuitive hypothesis: on the spectrum\nfrom non-robust (standard) to highly robust classifiers, those that are only\nslightly robust exhibit the most universal features -- ones that tend to\noverlap with the features learned by other classifiers trained on the same\ndataset. The results we present provide insight into the nature of adversarial\nexamples as well as the mechanisms underlying so-called \"robust\" classifiers.",
          "link": "http://arxiv.org/abs/2106.02105",
          "publishedOn": "2021-06-07T03:06:13.858Z",
          "wordCount": 634,
          "title": "A Little Robustness Goes a Long Way: Leveraging Universal Features for Targeted Transfer Attacks. (arXiv:2106.02105v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+WU_C/0/1/0/all/0/1\">Chengjie WU</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qianchuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Recently, deep multi-agent reinforcement learning (MARL) has shown the\npromise to solve complex cooperative tasks. Its success is partly because of\nparameter sharing among agents. However, such sharing may lead agents to behave\nsimilarly and limit their coordination capacity. In this paper, we aim to\nintroduce diversity in both optimization and representation of shared\nmulti-agent reinforcement learning. Specifically, we propose an\ninformation-theoretical regularization to maximize the mutual information\nbetween agents' identities and their trajectories, encouraging extensive\nexploration and diverse individualized behaviors. In representation, we\nincorporate agent-specific modules in the shared neural network architecture,\nwhich are regularized by L1-norm to promote learning sharing among agents while\nkeeping necessary diversity. Empirical results show that our method achieves\nstate-of-the-art performance on Google Research Football and super hard\nStarCraft II micromanagement tasks.",
          "link": "http://arxiv.org/abs/2106.02195",
          "publishedOn": "2021-06-07T03:06:13.852Z",
          "wordCount": 554,
          "title": "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning. (arXiv:2106.02195v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abboud_R/0/1/0/all/0/1\">Ralph Abboud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1\">&#x130;smail &#x130;lkan Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>",
          "description": "Graph neural networks (GNNs) are effective models for representation learning\non relational data. However, standard GNNs are limited in their expressive\npower, as they cannot distinguish graphs beyond the capability of the\nWeisfeiler-Leman graph isomorphism heuristic. In order to break this\nexpressiveness barrier, GNNs have been enhanced with random node initialization\n(RNI), where the idea is to train and run the models with randomized initial\nnode features. In this work, we analyze the expressive power of GNNs with RNI,\nand prove that these models are universal, a first such result for GNNs not\nrelying on computationally demanding higher-order properties. This universality\nresult holds even with partially randomized initial node features, and\npreserves the invariance properties of GNNs in expectation. We then empirically\nanalyze the effect of RNI on GNNs, based on carefully constructed datasets. Our\nempirical findings support the superior performance of GNNs with RNI over\nstandard GNNs.",
          "link": "http://arxiv.org/abs/2010.01179",
          "publishedOn": "2021-06-07T03:06:13.844Z",
          "wordCount": 638,
          "title": "The Surprising Power of Graph Neural Networks with Random Node Initialization. (arXiv:2010.01179v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jingxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shepperd_M/0/1/0/all/0/1\">Martin Shepperd</a>",
          "description": "Context: Software engineering researchers have undertaken many experiments\ninvestigating the potential of software defect prediction algorithms.\nUnfortunately, some widely used performance metrics are known to be\nproblematic, most notably F1, but nevertheless F1 is widely used.\n\nObjective: To investigate the potential impact of using F1 on the validity of\nthis large body of research.\n\nMethod: We undertook a systematic review to locate relevant experiments and\nthen extract all pairwise comparisons of defect prediction performance using F1\nand the un-biased Matthews correlation coefficient (MCC).\n\nResults: We found a total of 38 primary studies. These contain 12,471 pairs\nof results. Of these, 21.95% changed direction when the MCC metric is used\ninstead of the biased F1 metric. Unfortunately, we also found evidence\nsuggesting that F1 remains widely used in software defect prediction research.\n\nConclusions: We reiterate the concerns of statisticians that the F1 is a\nproblematic metric outside of an information retrieval context, since we are\nconcerned about both classes (defect-prone and not defect-prone units). This\ninappropriate usage has led to a substantial number (more than one fifth) of\nerroneous (in terms of direction) results. Therefore we urge researchers to (i)\nuse an unbiased metric and (ii) publish detailed results including confusion\nmatrices such that alternative analyses become possible.",
          "link": "http://arxiv.org/abs/2103.10201",
          "publishedOn": "2021-06-07T03:06:13.837Z",
          "wordCount": 706,
          "title": "The impact of using biased performance metrics on software defect prediction research. (arXiv:2103.10201v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iheme_L/0/1/0/all/0/1\">Leonardo Obinna Iheme</a>",
          "description": "This work presents a practical solution to the problem of call center agent\nmalpractice. A semi-supervised framework comprising of non-linear power\ntransformation, neural feature learning and k-means clustering is outlined. We\nput these building blocks together and tune the parameters so that the best\nperformance was obtained. The data used in the experiments is obtained from our\nin-house call center. It is made up of recorded agent-customer conversations\nwhich have been annotated using a convolutional neural network based segmenter.\nThe methods provided a means of tuning the parameters of the neural network to\nachieve a desirable result. We show that, using our proposed framework, it is\npossible to significantly reduce the malpractice classification error of a\nk-means-only clustering model which would serve the same purpose. Additionally,\nby presenting the amount of silence per call as a key performance indicator, we\nshow that the proposed system has enhanced agents performance at our call\ncenter since deployment.",
          "link": "http://arxiv.org/abs/2106.02433",
          "publishedOn": "2021-06-07T03:06:13.820Z",
          "wordCount": 598,
          "title": "A Novel Semi-supervised Framework for Call Center Agent Malpractice Detection via Neural Feature Learning. (arXiv:2106.02433v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1\">Sara Abdali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurav_R/0/1/0/all/0/1\">Rutuja Gurav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_S/0/1/0/all/0/1\">Siddharth Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_D/0/1/0/all/0/1\">Daniel Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Entezari_N/0/1/0/all/0/1\">Negin Entezari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1\">Evangelos E. Papalexakis</a>",
          "description": "Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.",
          "link": "http://arxiv.org/abs/2102.07849",
          "publishedOn": "2021-06-07T03:06:13.813Z",
          "wordCount": 706,
          "title": "Identifying Misinformation from Website Screenshots. (arXiv:2102.07849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1\">Saurabhchand Bhati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1\">Jes&#xfa;s Villalba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Velazquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1\">Najim Dehak</a>",
          "description": "Automatic detection of phoneme or word-like units is one of the core\nobjectives in zero-resource speech processing. Recent attempts employ\nself-supervised training methods, such as contrastive predictive coding (CPC),\nwhere the next frame is predicted given past context. However, CPC only looks\nat the audio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework that can model the\nsignal structure at a higher level e.g. at the phoneme level. In this\nframework, a convolutional neural network learns frame-level representation\nfrom the raw waveform via noise-contrastive estimation (NCE). A differentiable\nboundary detector finds variable-length segments, which are then used to\noptimize a segment encoder via NCE to learn segment representations. The\ndifferentiable boundary detector allows us to train frame-level and\nsegment-level encoders jointly. Typically, phoneme and word segmentation are\ntreated as separate tasks. We unify them and experimentally show that our\nsingle model outperforms existing phoneme and word segmentation methods on\nTIMIT and Buckeye datasets. We analyze the impact of boundary threshold and\nwhen is the right time to include the segmental loss in the learning process.",
          "link": "http://arxiv.org/abs/2106.02170",
          "publishedOn": "2021-06-07T03:06:13.788Z",
          "wordCount": 628,
          "title": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1\">Richard Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "Diffusion is a fundamental graph procedure and has been a basic building\nblock in a wide range of theoretical and empirical applications such as graph\npartitioning and semi-supervised learning on graphs. In this paper, we study\ncomputationally efficient diffusion primitives beyond random walk.\n\nWe design an $\\widetilde{O}(m)$-time randomized algorithm for the\n$\\ell_2$-norm flow diffusion problem, a recently proposed diffusion model based\non network flow with demonstrated graph clustering related applications both in\ntheory and in practice. Examples include finding locally-biased low conductance\ncuts. Using a known connection between the optimal dual solution of the flow\ndiffusion problem and the local cut structure, our algorithm gives an\nalternative approach for finding such cuts in nearly linear time.\n\nFrom a technical point of view, our algorithm contributes a novel way of\ndealing with inequality constraints in graph optimization problems. It adapts\nthe high-level algorithmic framework of nearly linear time Laplacian system\nsolvers, but requires several new tools: vertex elimination under constraints,\na new family of graph ultra-sparsifiers, and accelerated proximal gradient\nmethods with inexact proximal mapping computation.",
          "link": "http://arxiv.org/abs/2105.14629",
          "publishedOn": "2021-06-07T03:06:13.772Z",
          "wordCount": 619,
          "title": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time. (arXiv:2105.14629v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02626",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bena_G/0/1/0/all/0/1\">Gabriel B&#xe9;na</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Goodman_D/0/1/0/all/0/1\">Dan F. M. Goodman</a>",
          "description": "Modularity of neural networks -- both biological and artificial -- can be\nthought of either structurally or functionally, and the relationship between\nthese is an open question. We show that enforcing structural modularity via\nsparse connectivity between two dense sub-networks which need to communicate to\nsolve the task leads to functional specialization of the sub-networks, but only\nat extreme levels of sparsity. With even a moderate number of interconnections,\nthe sub-networks become functionally entangled. Defining functional\nspecialization is in itself a challenging problem without a universally agreed\nsolution. To address this, we designed three different measures of\nspecialization (based on weight masks, retraining and correlation) and found\nthem to qualitatively agree. Our results have implications in both neuroscience\nand machine learning. For neuroscience, it shows that we cannot conclude that\nthere is functional modularity simply by observing moderate levels of\nstructural modularity: knowing the brain's connectome is not sufficient for\nunderstanding how it breaks down into functional modules. For machine learning,\nusing structure to promote functional modularity -- which may be important for\nrobustness and generalization -- may require extremely narrow bottlenecks\nbetween modules.",
          "link": "http://arxiv.org/abs/2106.02626",
          "publishedOn": "2021-06-07T03:06:13.761Z",
          "wordCount": 630,
          "title": "Extreme sparsity gives rise to functional specialization. (arXiv:2106.02626v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2003.10130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyan Zhang</a>",
          "description": "Graph Neural Networks (GNNs) are gaining increasing attention on graph data\nlearning tasks in recent years. However, in many applications, graph may be\ncoming in an incomplete form where attributes of graph nodes are partially\nunknown/missing. Existing GNNs are generally designed on complete graphs which\ncan not deal with attribute-incomplete graph data directly. To address this\nproblem, we develop a novel partial aggregation based GNNs, named Partial Graph\nNeural Networks (PaGNNs), for attribute-incomplete graph representation and\nlearning. Our work is motivated by the observation that the neighborhood\naggregation function in standard GNNs can be equivalently viewed as the\nneighborhood reconstruction formulation. Based on it, we define two novel\npartial aggregation (reconstruction) functions on incomplete graph and derive\nPaGNNs for incomplete graph data learning. Extensive experiments on several\ndatasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.",
          "link": "http://arxiv.org/abs/2003.10130",
          "publishedOn": "2021-06-07T03:06:13.648Z",
          "wordCount": 600,
          "title": "Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazoure_B/0/1/0/all/0/1\">Bogdan Mazoure</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1\">Ahmed M. Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacAlpine_P/0/1/0/all/0/1\">Patrick MacAlpine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1\">R Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1\">Andrey Kolobov</a>",
          "description": "A highly desirable property of a reinforcement learning (RL) agent -- and a\nmajor difficulty for deep RL approaches -- is the ability to generalize\npolicies learned on a few tasks over a high-dimensional observation space to\nsimilar tasks not seen during training. Many promising approaches to this\nchallenge consider RL as a process of training two functions simultaneously: a\ncomplex nonlinear encoder that maps high-dimensional observations to a latent\nrepresentation space, and a simple linear policy over this space. We posit that\na superior encoder for zero-shot generalization in RL can be trained by using\nsolely an auxiliary SSL objective if the training process encourages the\nencoder to map behaviorally similar observations to similar representations, as\nreward-based signal can cause overfitting in the encoder (Raileanu et al.,\n2021). We propose Cross-Trajectory Representation Learning (CTRL), a method\nthat runs within an RL agent and conditions its encoder to recognize behavioral\nsimilarity in observations by applying a novel SSL objective to pairs of\ntrajectories from the agent's policies. CTRL can be viewed as having the same\neffect as inducing a pseudo-bisimulation metric but, crucially, avoids the use\nof rewards and associated overfitting risks. Our experiments ablate various\ncomponents of CTRL and demonstrate that in combination with PPO it achieves\nbetter generalization performance on the challenging Procgen benchmark suite\n(Cobbe et al., 2020).",
          "link": "http://arxiv.org/abs/2106.02193",
          "publishedOn": "2021-06-07T03:06:13.624Z",
          "wordCount": 653,
          "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL. (arXiv:2106.02193v1 [cs.LG])"
        }
      ]
    }
  ],
  "cliVersion": "1.10.2"
}